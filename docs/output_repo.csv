uri,name,type,n_variable,n_words,n_words_unique,n_characters,avg_char_per_word,n_loop,n_ifthen,arg_name,arg_type,arg_value,line,docs,list_functions,n_functions
github/AccessToken.py:AccessToken,AccessToken,class,16,69,40,766,11.1,0,3,[],[],[],26,[],[],0
github/AccessToken.py:AccessToken:__repr__,AccessToken:__repr__,method,2,11,11,107,9.73,0,0,['self'],[None],[None],31,[],['self.get__repr__'],1
github/AccessToken.py:AccessToken:token,AccessToken:token,method,2,2,2,23,11.5,0,0,['self'],[None],[None],41,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/AccessToken.py:AccessToken:type,AccessToken:type,method,2,2,2,22,11.0,0,0,['self'],[None],[None],48,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/AccessToken.py:AccessToken:scope,AccessToken:scope,method,2,2,2,23,11.5,0,0,['self'],[None],[None],55,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/AccessToken.py:AccessToken:_initAttributes,AccessToken:_initAttributes,method,4,6,5,115,19.17,0,0,['self'],[None],[None],61,[],[],0
github/AccessToken.py:AccessToken:_useAttributes,AccessToken:_useAttributes,method,4,30,16,313,10.43,0,3,"['self', 'attributes']","[None, None]","[None, None]",66,[],['self._makeStringAttribute'],1
github/ApplicationOAuth.py:ApplicationOAuth,ApplicationOAuth,class,30,139,92,1695,12.19,0,6,[],[],[],29,[],[],0
github/ApplicationOAuth.py:ApplicationOAuth:__repr__,ApplicationOAuth:__repr__,method,2,3,3,59,19.67,0,0,['self'],[None],[None],35,[],['self.get__repr__'],1
github/ApplicationOAuth.py:ApplicationOAuth:client_id,ApplicationOAuth:client_id,method,2,2,2,27,13.5,0,0,['self'],[None],[None],39,[],[],0
github/ApplicationOAuth.py:ApplicationOAuth:client_secret,ApplicationOAuth:client_secret,method,2,2,2,31,15.5,0,0,['self'],[None],[None],43,[],[],0
github/ApplicationOAuth.py:ApplicationOAuth:_initAttributes,ApplicationOAuth:_initAttributes,method,3,4,4,89,22.25,0,0,['self'],[None],[None],46,[],[],0
github/ApplicationOAuth.py:ApplicationOAuth:_useAttributes,ApplicationOAuth:_useAttributes,method,3,20,13,229,11.45,0,2,"['self', 'attributes']","[None, None]","[None, None]",50,[],['self._makeStringAttribute'],1
github/ApplicationOAuth.py:ApplicationOAuth:get_login_url,ApplicationOAuth:get_login_url,method,9,42,26,439,10.45,0,3,"['self', 'redirect_uri', 'state', 'login']","[None, None, None, None]","[None, 'None', 'None', 'None']",56,"['        """"""\n', '        Return the URL you need to redirect a user to in order to authorize\n', '        your App.\n', '        :type: string\n', '        """"""\n']",['isinstance'],1
github/ApplicationOAuth.py:ApplicationOAuth:get_access_token,ApplicationOAuth:get_access_token,method,10,44,43,563,12.8,0,1,"['self', 'code', 'state']","[None, None, None]","[None, None, 'None']",78,"['        """"""\n', '        :calls: `POST /login/oauth/access_token <https://docs.github.com/en/developers/apps/identifying-and-authorizing-users-for-github-apps>`_\n', '        :param code: string\n', '        :param state: string\n', '        """"""\n']","['isinstance', 'AccessToken']",2
github/AuthenticatedUser.py:AuthenticatedUser,AuthenticatedUser,class,255,2432,734,30994,12.74,1,90,[],[],[],64,[],[],0
github/AuthenticatedUser.py:AuthenticatedUser:__repr__,AuthenticatedUser:__repr__,method,2,3,3,51,17.0,0,0,['self'],[None],[None],71,[],['self.get__repr__'],1
github/AuthenticatedUser.py:AuthenticatedUser:avatar_url,AuthenticatedUser:avatar_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],75,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:bio,AuthenticatedUser:bio,method,3,3,3,55,18.33,0,0,['self'],[None],[None],83,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:blog,AuthenticatedUser:blog,method,3,3,3,57,19.0,0,0,['self'],[None],[None],91,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:collaborators,AuthenticatedUser:collaborators,method,3,3,3,75,25.0,0,0,['self'],[None],[None],99,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:company,AuthenticatedUser:company,method,3,3,3,63,21.0,0,0,['self'],[None],[None],107,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:created_at,AuthenticatedUser:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],115,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:disk_usage,AuthenticatedUser:disk_usage,method,3,3,3,69,23.0,0,0,['self'],[None],[None],123,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:email,AuthenticatedUser:email,method,3,3,3,59,19.67,0,0,['self'],[None],[None],131,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:events_url,AuthenticatedUser:events_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],139,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:followers,AuthenticatedUser:followers,method,3,3,3,67,22.33,0,0,['self'],[None],[None],147,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:followers_url,AuthenticatedUser:followers_url,method,3,3,3,75,25.0,0,0,['self'],[None],[None],155,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:following,AuthenticatedUser:following,method,3,3,3,67,22.33,0,0,['self'],[None],[None],163,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:following_url,AuthenticatedUser:following_url,method,3,3,3,75,25.0,0,0,['self'],[None],[None],171,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:gists_url,AuthenticatedUser:gists_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],179,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:gravatar_id,AuthenticatedUser:gravatar_id,method,3,3,3,71,23.67,0,0,['self'],[None],[None],187,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:hireable,AuthenticatedUser:hireable,method,3,3,3,65,21.67,0,0,['self'],[None],[None],195,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:html_url,AuthenticatedUser:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],203,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:id,AuthenticatedUser:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],211,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:location,AuthenticatedUser:location,method,3,3,3,65,21.67,0,0,['self'],[None],[None],219,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:login,AuthenticatedUser:login,method,3,3,3,59,19.67,0,0,['self'],[None],[None],227,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:name,AuthenticatedUser:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],235,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:node_id,AuthenticatedUser:node_id,method,3,3,3,63,21.0,0,0,['self'],[None],[None],243,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:organizations_url,AuthenticatedUser:organizations_url,method,3,3,3,83,27.67,0,0,['self'],[None],[None],251,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:owned_private_repos,AuthenticatedUser:owned_private_repos,method,3,3,3,87,29.0,0,0,['self'],[None],[None],259,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:plan,AuthenticatedUser:plan,method,3,3,3,57,19.0,0,0,['self'],[None],[None],267,"['        """"""\n', '        :type: :class:`github.Plan.Plan`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:private_gists,AuthenticatedUser:private_gists,method,3,3,3,75,25.0,0,0,['self'],[None],[None],275,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:public_gists,AuthenticatedUser:public_gists,method,3,3,3,73,24.33,0,0,['self'],[None],[None],283,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:public_repos,AuthenticatedUser:public_repos,method,3,3,3,73,24.33,0,0,['self'],[None],[None],291,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:received_events_url,AuthenticatedUser:received_events_url,method,3,3,3,87,29.0,0,0,['self'],[None],[None],299,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:repos_url,AuthenticatedUser:repos_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],307,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:site_admin,AuthenticatedUser:site_admin,method,3,3,3,69,23.0,0,0,['self'],[None],[None],315,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:starred_url,AuthenticatedUser:starred_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],323,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:subscriptions_url,AuthenticatedUser:subscriptions_url,method,3,3,3,83,27.67,0,0,['self'],[None],[None],331,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:total_private_repos,AuthenticatedUser:total_private_repos,method,3,3,3,87,29.0,0,0,['self'],[None],[None],339,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:type,AuthenticatedUser:type,method,3,3,3,57,19.0,0,0,['self'],[None],[None],347,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:updated_at,AuthenticatedUser:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],355,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:url,AuthenticatedUser:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],363,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthenticatedUser.py:AuthenticatedUser:add_to_emails,AuthenticatedUser:add_to_emails,method,5,18,18,189,10.5,0,0,"['self', '*emails']","[None, None]","[None, None]",370,"['        """"""\n', '        :calls: `POST /user/emails <http://docs.github.com/en/rest/reference/users#emails>`_\n', '        :param email: string\n', '        :rtype: None\n', '        """"""\n']",['all'],1
github/AuthenticatedUser.py:AuthenticatedUser:add_to_following,AuthenticatedUser:add_to_following,method,4,10,10,163,16.3,0,0,"['self', 'following']","[None, None]","[None, None]",382,"['        """"""\n', '        :calls: `PUT /user/following/{user} <http://docs.github.com/en/rest/reference/users#followers>`_\n', '        :param following: :class:`github.NamedUser.NamedUser`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:add_to_starred,AuthenticatedUser:add_to_starred,method,4,10,10,157,15.7,0,0,"['self', 'starred']","[None, None]","[None, None]",393,"['        """"""\n', '        :calls: `PUT /user/starred/{owner}/{repo} <http://docs.github.com/en/rest/reference/activity#starring>`_\n', '        :param starred: :class:`github.Repository.Repository`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:add_to_subscriptions,AuthenticatedUser:add_to_subscriptions,method,4,10,10,178,17.8,0,0,"['self', 'subscription']","[None, None]","[None, None]",404,"['        """"""\n', '        :calls: `PUT /user/subscriptions/{owner}/{repo} <http://docs.github.com/en/rest/reference/activity#watching>`_\n', '        :param subscription: :class:`github.Repository.Repository`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:add_to_watched,AuthenticatedUser:add_to_watched,method,4,12,12,192,16.0,0,0,"['self', 'watched']","[None, None]","[None, None]",415,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/subscription <http://docs.github.com/en/rest/reference/activity#watching>`_\n', '        :param watched: :class:`github.Repository.Repository`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:create_authorization,AuthenticatedUser:create_authorization,method,22,134,70,1279,9.54,0,6,"['self', 'scopes', 'note', 'note_url', 'client_id', 'client_secret', 'onetime_password', '']","[None, None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'None', None]",428,"['        """"""\n', '        :calls: `POST /authorizations <https://docs.github.com/en/developers/apps/authorizing-oauth-apps>`_\n', '        :param scopes: list of string\n', '        :param note: string\n', '        :param note_url: string\n', '        :param client_id: string\n', '        :param client_secret: string\n', '        :param onetime_password: string\n', '        :rtype: :class:`github.Authorization.Authorization`\n', '        """"""\n']","['all', 'isinstance', 'dict']",3
github/AuthenticatedUser.py:AuthenticatedUser:create_fork,AuthenticatedUser:create_fork,method,6,17,16,244,14.35,0,0,"['self', 'repo']","[None, None]","[None, None]",490,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/forks <http://docs.github.com/en/rest/reference/repos#forks>`_\n', '        :param repo: :class:`github.Repository.Repository`\n', '        :rtype: :class:`github.Repository.Repository`\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:create_gist,AuthenticatedUser:create_gist,method,17,56,47,556,9.93,1,1,"['self', 'public', 'files', 'description']","[None, None, None, None]","[None, None, None, 'github.GithubObject.NotSet']",504,"['        """"""\n', '        :calls: `POST /gists <http://docs.github.com/en/rest/reference/gists>`_\n', '        :param public: bool\n', '        :param files: dict of string to :class:`github.InputFileContent.InputFileContent`\n', '        :param description: string\n', '        :rtype: :class:`github.Gist.Gist`\n', '        """"""\n']","['isinstance', 'all', 'files.values', 'files.items']",4
github/AuthenticatedUser.py:AuthenticatedUser:create_key,AuthenticatedUser:create_key,method,7,27,24,277,10.26,0,0,"['self', 'title', 'key']","[None, None, None]","[None, None, None]",530,"['        """"""\n', '        :calls: `POST /user/keys <http://docs.github.com/en/rest/reference/users#git-ssh-keys>`_\n', '        :param title: string\n', '        :param key: string\n', '        :rtype: :class:`github.UserKey.UserKey`\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:create_project,AuthenticatedUser:create_project,method,10,33,30,370,11.21,0,0,"['self', 'name', 'body']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",548,"['        """"""\n', '        :calls: `POST /user/projects <https://docs.github.com/en/rest/reference/projects#create-a-user-project>`_\n', '        :param name: string\n', '        :param body: string\n', '        :rtype: :class:`github.Project.Project`\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:create_repo,AuthenticatedUser:create_repo,method,24,261,88,2947,11.29,0,14,"['self', 'name', 'description', 'homepage', 'private', 'has_issues', 'has_wiki', 'has_downloads', 'has_projects', 'auto_init', 'license_template', 'gitignore_template', 'allow_squash_merge', 'allow_merge_commit', 'allow_rebase_merge', 'delete_branch_on_merge', '']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",569,"['        """"""\n', '        :calls: `POST /user/repos <http://docs.github.com/en/rest/reference/repos>`_\n', '        :param name: string\n', '        :param description: string\n', '        :param homepage: string\n', '        :param private: bool\n', '        :param has_issues: bool\n', '        :param has_wiki: bool\n', '        :param has_downloads: bool\n', '        :param has_projects: bool\n', '        :param auto_init: bool\n', '        :param license_template: string\n', '        :param gitignore_template: string\n', '        :param allow_squash_merge: bool\n', '        :param allow_merge_commit: bool\n', '        :param allow_rebase_merge: bool\n', '        :param delete_branch_on_merge: bool\n', '        :rtype: :class:`github.Repository.Repository`\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:edit,AuthenticatedUser:edit,method,16,121,50,1149,9.5,0,7,"['self', 'name', 'email', 'blog', 'company', 'location', 'hireable', 'bio', '']","[None, None, None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",687,"['        """"""\n', '        :calls: `PATCH /user <http://docs.github.com/en/rest/reference/users>`_\n', '        :param name: string\n', '        :param email: string\n', '        :param blog: string\n', '        :param company: string\n', '        :param location: string\n', '        :param hireable: bool\n', '        :param bio: string\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'dict', 'self._useAttributes']",3
github/AuthenticatedUser.py:AuthenticatedUser:get_authorization,AuthenticatedUser:get_authorization,method,8,26,22,344,13.23,0,0,"['self', 'id']","[None, None]","[None, None]",741,"['        """"""\n', '        :calls: `GET /authorizations/{id} <https://docs.github.com/en/developers/apps/authorizing-oauth-apps>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.Authorization.Authorization`\n', '        """"""\n']","['isinstance', 'get_authorizations']",2
github/AuthenticatedUser.py:AuthenticatedUser:get_authorizations,AuthenticatedUser:get_authorizations,method,2,7,7,117,16.71,0,0,['self'],[None],[None],755,"['        """"""\n', '        :calls: `GET /authorizations <https://docs.github.com/en/developers/apps/authorizing-oauth-apps>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Authorization.Authorization`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:get_emails,AuthenticatedUser:get_emails,method,6,13,13,169,13.0,0,0,['self'],[None],[None],764,"['        """"""\n', '        :calls: `GET /user/emails <http://docs.github.com/en/rest/reference/users#emails>`_\n', '        :rtype: list of namedtuples with members email, primary, verified and visibility\n', '        """"""\n']",['namedtuple'],1
github/AuthenticatedUser.py:AuthenticatedUser:get_events,AuthenticatedUser:get_events,method,2,7,7,93,13.29,0,0,['self'],[None],[None],773,"['        """"""\n', '        :calls: `GET /events <http://docs.github.com/en/rest/reference/activity#events>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Event.Event`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:get_followers,AuthenticatedUser:get_followers,method,2,7,7,109,15.57,0,0,['self'],[None],[None],782,"['        """"""\n', '        :calls: `GET /user/followers <http://docs.github.com/en/rest/reference/users#followers>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:get_following,AuthenticatedUser:get_following,method,2,7,7,109,15.57,0,0,['self'],[None],[None],791,"['        """"""\n', '        :calls: `GET /user/following <http://docs.github.com/en/rest/reference/users#followers>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:get_gists,AuthenticatedUser:get_gists,method,9,26,24,308,11.85,0,1,"['self', 'since']","[None, None]","[None, 'github.GithubObject.NotSet']",800,"['        """"""\n', '        :calls: `GET /gists <http://docs.github.com/en/rest/reference/gists>`_\n', '        :param since: datetime.datetime format YYYY-MM-DDTHH:MM:SSZ\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Gist.Gist`\n', '        """"""\n']","['isinstance', 'dict', 'since.strftime']",3
github/AuthenticatedUser.py:AuthenticatedUser:get_issues,AuthenticatedUser:get_issues,method,18,113,54,1109,9.81,0,6,"['self', 'filter', 'state', 'labels', 'sort', 'direction', 'since', '']","[None, None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",816,"['        """"""\n', '        :calls: `GET /issues <http://docs.github.com/en/rest/reference/issues>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Issue.Issue`\n', '        :param filter: string\n', '        :param state: string\n', '        :param labels: list of :class:`github.Label.Label`\n', '        :param sort: string\n', '        :param direction: string\n', '        :param since: datetime.datetime\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Issue.Issue`\n', '        """"""\n']","['isinstance', 'all', 'dict', 'since.strftime']",4
github/AuthenticatedUser.py:AuthenticatedUser:get_user_issues,AuthenticatedUser:get_user_issues,method,18,113,54,1114,9.86,0,6,"['self', 'filter', 'state', 'labels', 'sort', 'direction', 'since', '']","[None, None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",865,"['        """"""\n', '        :calls: `GET /user/issues <http://docs.github.com/en/rest/reference/issues>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Issue.Issue`\n', '        :param filter: string\n', '        :param state: string\n', '        :param labels: list of :class:`github.Label.Label`\n', '        :param sort: string\n', '        :param direction: string\n', '        :param since: datetime.datetime\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Issue.Issue`\n', '        """"""\n']","['isinstance', 'all', 'dict', 'since.strftime']",4
github/AuthenticatedUser.py:AuthenticatedUser:get_key,AuthenticatedUser:get_key,method,8,22,20,296,13.45,0,0,"['self', 'id']","[None, None]","[None, None]",914,"['        """"""\n', '        :calls: `GET /user/keys/{id} <http://docs.github.com/en/rest/reference/users#git-ssh-keys>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.UserKey.UserKey`\n', '        """"""\n']","['isinstance', 'get_keys']",2
github/AuthenticatedUser.py:AuthenticatedUser:get_keys,AuthenticatedUser:get_keys,method,2,7,7,100,14.29,0,0,['self'],[None],[None],924,"['        """"""\n', '        :calls: `GET /user/keys <http://docs.github.com/en/rest/reference/users#git-ssh-keys>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.UserKey.UserKey`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:get_notification,AuthenticatedUser:get_notification,method,7,24,22,373,15.54,0,0,"['self', 'id']","[None, None]","[None, None]",933,"['        """"""\n', '        :calls: `GET /notifications/threads/{id} <http://docs.github.com/en/rest/reference/activity#notifications>`_\n', '        :rtype: :class:`github.Notification.Notification`\n', '        """"""\n']","['isinstance', 'get_notifications']",2
github/AuthenticatedUser.py:AuthenticatedUser:get_notifications,AuthenticatedUser:get_notifications,method,15,75,39,794,10.59,0,4,"['self', 'all', 'participating', 'since', 'before', '']","[None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",947,"['        """"""\n', '        :calls: `GET /notifications <http://docs.github.com/en/rest/reference/activity#notifications>`_\n', '        :param all: bool\n', '        :param participating: bool\n', '        :param since: datetime.datetime\n', '        :param before: datetime.datetime\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Notification.Notification`\n', '        """"""\n']","['isinstance', 'dict', 'since.strftime', 'before.strftime']",4
github/AuthenticatedUser.py:AuthenticatedUser:get_organization_events,AuthenticatedUser:get_organization_events,method,3,11,11,193,17.55,0,0,"['self', 'org']","[None, None]","[None, None]",988,"['        """"""\n', '        :calls: `GET /users/{user}/events/orgs/{org} <http://docs.github.com/en/rest/reference/activity#events>`_\n', '        :param org: :class:`github.Organization.Organization`\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Event.Event`\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:get_orgs,AuthenticatedUser:get_orgs,method,2,7,7,110,15.71,0,0,['self'],[None],[None],1002,"['        """"""\n', '        :calls: `GET /user/orgs <http://docs.github.com/en/rest/reference/orgs>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Organization.Organization`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:get_repo,AuthenticatedUser:get_repo,method,7,25,23,404,16.16,0,0,"['self', 'name']","[None, None]","[None, None]",1011,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo} <http://docs.github.com/en/rest/reference/repos>`_\n', '        :param name: string\n', '        :rtype: :class:`github.Repository.Repository`\n', '        """"""\n']","['isinstance', 'get_repos']",2
github/AuthenticatedUser.py:AuthenticatedUser:get_repos,AuthenticatedUser:get_repos,method,12,90,40,918,10.2,0,5,"['self', 'visibility', 'affiliation', 'type', 'sort', 'direction', '']","[None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",1025,"['        """"""\n', '        :calls: `GET /user/repos <http://docs.github.com/en/rest/reference/repos>`\n', '        :param visibility: string\n', '        :param affiliation: string\n', '        :param type: string\n', '        :param sort: string\n', '        :param direction: string\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']","['isinstance', 'dict']",2
github/AuthenticatedUser.py:AuthenticatedUser:get_starred,AuthenticatedUser:get_starred,method,3,16,12,236,14.75,0,0,['self'],[None],[None],1068,"['        """"""\n', '        :calls: `GET /user/starred <http://docs.github.com/en/rest/reference/activity#starring>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']",['get_starred_gists'],1
github/AuthenticatedUser.py:AuthenticatedUser:get_starred_gists,AuthenticatedUser:get_starred_gists,method,2,7,7,98,14.0,0,0,['self'],[None],[None],1077,"['        """"""\n', '        :calls: `GET /gists/starred <http://docs.github.com/en/rest/reference/gists>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Gist.Gist`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:get_subscriptions,AuthenticatedUser:get_subscriptions,method,2,7,7,115,16.43,0,0,['self'],[None],[None],1086,"['        """"""\n', '        :calls: `GET /user/subscriptions <http://docs.github.com/en/rest/reference/activity#watching>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:get_teams,AuthenticatedUser:get_teams,method,2,7,7,95,13.57,0,0,['self'],[None],[None],1095,"['        """"""\n', '        :calls: `GET /user/teams <http://docs.github.com/en/rest/reference/teams>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Team.Team`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:get_watched,AuthenticatedUser:get_watched,method,2,7,7,115,16.43,0,0,['self'],[None],[None],1104,"['        """"""\n', '        :calls: `GET /user/subscriptions <http://docs.github.com/en/rest/reference/activity#watching>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:get_installations,AuthenticatedUser:get_installations,method,2,10,10,205,20.5,0,0,['self'],[None],[None],1113,"['        """"""\n', '        :calls: `GET /user/installations <http://docs.github.com/en/rest/reference/apps>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Installation.Installation`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:has_in_following,AuthenticatedUser:has_in_following,method,7,14,14,180,12.86,0,0,"['self', 'following']","[None, None]","[None, None]",1127,"['        """"""\n', '        :calls: `GET /user/following/{user} <http://docs.github.com/en/rest/reference/users#followers>`_\n', '        :param following: :class:`github.NamedUser.NamedUser`\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:has_in_starred,AuthenticatedUser:has_in_starred,method,7,14,14,174,12.43,0,0,"['self', 'starred']","[None, None]","[None, None]",1139,"['        """"""\n', '        :calls: `GET /user/starred/{owner}/{repo} <http://docs.github.com/en/rest/reference/activity#starring>`_\n', '        :param starred: :class:`github.Repository.Repository`\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:has_in_subscriptions,AuthenticatedUser:has_in_subscriptions,method,7,14,14,195,13.93,0,0,"['self', 'subscription']","[None, None]","[None, None]",1151,"['        """"""\n', '        :calls: `GET /user/subscriptions/{owner}/{repo} <http://docs.github.com/en/rest/reference/activity#watching>`_\n', '        :param subscription: :class:`github.Repository.Repository`\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:has_in_watched,AuthenticatedUser:has_in_watched,method,7,14,14,180,12.86,0,0,"['self', 'watched']","[None, None]","[None, None]",1163,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/subscription <http://docs.github.com/en/rest/reference/activity#watching>`_\n', '        :param watched: :class:`github.Repository.Repository`\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:mark_notifications_as_read,AuthenticatedUser:mark_notifications_as_read,method,6,13,13,220,16.92,0,0,"['self', 'last_read_at']","[None, None]","[None, 'datetime.datetime.utcnow(']",1175,"['        """"""\n', '        :calls: `PUT /notifications <https://docs.github.com/en/rest/reference/activity#notifications>`_\n', '        :param last_read_at: datetime\n', '        """"""\n']","['isinstance', 'last_read_at.strftime']",2
github/AuthenticatedUser.py:AuthenticatedUser:remove_from_emails,AuthenticatedUser:remove_from_emails,method,5,18,18,191,10.61,0,0,"['self', '*emails']","[None, None]","[None, None]",1187,"['        """"""\n', '        :calls: `DELETE /user/emails <http://docs.github.com/en/rest/reference/users#emails>`_\n', '        :param email: string\n', '        :rtype: None\n', '        """"""\n']",['all'],1
github/AuthenticatedUser.py:AuthenticatedUser:remove_from_following,AuthenticatedUser:remove_from_following,method,4,10,10,166,16.6,0,0,"['self', 'following']","[None, None]","[None, None]",1199,"['        """"""\n', '        :calls: `DELETE /user/following/{user} <http://docs.github.com/en/rest/reference/users#followers>`_\n', '        :param following: :class:`github.NamedUser.NamedUser`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:remove_from_starred,AuthenticatedUser:remove_from_starred,method,4,10,10,160,16.0,0,0,"['self', 'starred']","[None, None]","[None, None]",1210,"['        """"""\n', '        :calls: `DELETE /user/starred/{owner}/{repo} <http://docs.github.com/en/rest/reference/activity#starring>`_\n', '        :param starred: :class:`github.Repository.Repository`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:remove_from_subscriptions,AuthenticatedUser:remove_from_subscriptions,method,4,10,10,181,18.1,0,0,"['self', 'subscription']","[None, None]","[None, None]",1221,"['        """"""\n', '        :calls: `DELETE /user/subscriptions/{owner}/{repo} <http://docs.github.com/en/rest/reference/activity#watching>`_\n', '        :param subscription: :class:`github.Repository.Repository`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:remove_from_watched,AuthenticatedUser:remove_from_watched,method,4,10,10,166,16.6,0,0,"['self', 'watched']","[None, None]","[None, None]",1232,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/subscription <http://docs.github.com/en/rest/reference/activity#watching>`_\n', '        :param watched: :class:`github.Repository.Repository`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:accept_invitation,AuthenticatedUser:accept_invitation,method,7,20,19,281,14.05,0,1,"['self', 'invitation']","[None, None]","[None, None]",1243,"['        """"""\n', '        :calls: `PATCH /user/repository_invitations/{invitation_id} <https://docs.github.com/en/rest/reference/repos/invitations#>`\n', '        :param invitation: :class:`github.Invitation.Invitation` or int\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:get_invitations,AuthenticatedUser:get_invitations,method,2,7,7,128,18.29,0,0,['self'],[None],[None],1260,"['        """"""\n', '        :calls: `GET /user/repository_invitations <https://docs.github.com/en/rest/reference/repos#invitations>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Invitation.Invitation`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:create_migration,AuthenticatedUser:create_migration,method,13,66,46,811,12.29,0,2,"['self', 'repos', 'lock_repositories', 'exclude_attachments', '']","[None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",1272,"['        """"""\n', '        :calls: `POST /user/migrations <https://docs.github.com/en/rest/reference/migrations>`_\n', '        :param repos: list or tuple of str\n', '        :param lock_repositories: bool\n', '        :param exclude_attachments: bool\n', '        :rtype: :class:`github.Migration.Migration`\n', '        """"""\n']","['isinstance', 'all']",2
github/AuthenticatedUser.py:AuthenticatedUser:get_migrations,AuthenticatedUser:get_migrations,method,2,9,9,167,18.56,0,0,['self'],[None],[None],1308,"['        """"""\n', '        :calls: `GET /user/migrations <https://docs.github.com/en/rest/reference/migrations>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Migration.Migration`\n', '        """"""\n']",[],0
github/AuthenticatedUser.py:AuthenticatedUser:get_organization_membership,AuthenticatedUser:get_organization_membership,method,6,16,15,197,12.31,0,0,"['self', 'org']","[None, None]","[None, None]",1321,"['        """"""\n', '        :calls: `GET /user/memberships/orgs/{org} <https://docs.github.com/en/rest/reference/orgs#get-an-organization-membership-for-the-authenticated-user>`_\n', '        :rtype: :class:`github.Membership.Membership`\n', '        """"""\n']",['isinstance'],1
github/AuthenticatedUser.py:AuthenticatedUser:_initAttributes,AuthenticatedUser:_initAttributes,method,38,74,39,1614,21.81,0,0,['self'],[None],[None],1334,[],[],0
github/AuthenticatedUser.py:AuthenticatedUser:_useAttributes,AuthenticatedUser:_useAttributes,method,42,381,122,4100,10.76,0,37,"['self', 'attributes']","[None, None]","[None, None]",1373,[],"['self._makeStringAttribute', 'self._makeIntAttribute', 'self._makeDatetimeAttribute', 'self._makeBoolAttribute', 'self._makeClassAttribute']",5
github/Authorization.py:Authorization,Authorization,class,52,295,126,3547,12.02,0,14,[],[],[],35,[],[],0
github/Authorization.py:Authorization:__repr__,Authorization:__repr__,method,2,3,3,53,17.67,0,0,['self'],[None],[None],40,[],['self.get__repr__'],1
github/Authorization.py:Authorization:app,Authorization:app,method,3,3,3,55,18.33,0,0,['self'],[None],[None],44,"['        """"""\n', '        :type: :class:`github.AuthorizationApplication.AuthorizationApplication`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Authorization.py:Authorization:created_at,Authorization:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Authorization.py:Authorization:id,Authorization:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Authorization.py:Authorization:note,Authorization:note,method,3,3,3,57,19.0,0,0,['self'],[None],[None],68,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Authorization.py:Authorization:note_url,Authorization:note_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],76,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Authorization.py:Authorization:scopes,Authorization:scopes,method,3,3,3,61,20.33,0,0,['self'],[None],[None],84,"['        """"""\n', '        :type: list of string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Authorization.py:Authorization:token,Authorization:token,method,3,3,3,59,19.67,0,0,['self'],[None],[None],92,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Authorization.py:Authorization:updated_at,Authorization:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],100,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Authorization.py:Authorization:url,Authorization:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],108,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Authorization.py:Authorization:delete,Authorization:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],115,"['        """"""\n', '        :calls: `DELETE /authorizations/{id} <https://docs.github.com/en/developers/apps/authorizing-oauth-apps>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Authorization.py:Authorization:edit,Authorization:edit,method,15,105,44,1015,9.67,0,5,"['self', 'scopes', 'add_scopes', 'remove_scopes', 'note', 'note_url', '']","[None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",122,"['        """"""\n', '        :calls: `PATCH /authorizations/{id} <https://docs.github.com/en/developers/apps/authorizing-oauth-apps>`_\n', '        :param scopes: list of string\n', '        :param add_scopes: list of string\n', '        :param remove_scopes: list of string\n', '        :param note: string\n', '        :param note_url: string\n', '        :rtype: None\n', '        """"""\n']","['all', 'isinstance', 'dict', 'self._useAttributes']",4
github/Authorization.py:Authorization:_initAttributes,Authorization:_initAttributes,method,10,18,11,356,19.78,0,0,['self'],[None],[None],168,[],[],0
github/Authorization.py:Authorization:_useAttributes,Authorization:_useAttributes,method,14,93,37,958,10.3,0,9,"['self', 'attributes']","[None, None]","[None, None]",179,[],"['self._makeClassAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeStringAttribute', 'self._makeListOfStringsAttribute']",5
github/AuthorizationApplication.py:AuthorizationApplication,AuthorizationApplication,class,14,46,29,553,12.02,0,2,[],[],[],34,[],[],0
github/AuthorizationApplication.py:AuthorizationApplication:__repr__,AuthorizationApplication:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/AuthorizationApplication.py:AuthorizationApplication:name,AuthorizationApplication:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthorizationApplication.py:AuthorizationApplication:url,AuthorizationApplication:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/AuthorizationApplication.py:AuthorizationApplication:_initAttributes,AuthorizationApplication:_initAttributes,method,3,4,4,74,18.5,0,0,['self'],[None],[None],58,[],[],0
github/AuthorizationApplication.py:AuthorizationApplication:_useAttributes,AuthorizationApplication:_useAttributes,method,3,20,13,184,9.2,0,2,"['self', 'attributes']","[None, None]","[None, None]",62,[],['self._makeStringAttribute'],1
github/Branch.py:Branch,Branch,class,68,804,209,11500,14.3,0,26,[],[],[],43,[],[],0
github/Branch.py:Branch:__repr__,Branch:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],48,[],['self.get__repr__'],1
github/Branch.py:Branch:commit,Branch:commit,method,2,2,2,24,12.0,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: :class:`github.Commit.Commit`\n', '        """"""\n']",[],0
github/Branch.py:Branch:name,Branch:name,method,2,2,2,22,11.0,0,0,['self'],[None],[None],59,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Branch.py:Branch:protected,Branch:protected,method,2,2,2,27,13.5,0,0,['self'],[None],[None],66,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/Branch.py:Branch:protection_url,Branch:protection_url,method,2,2,2,32,16.0,0,0,['self'],[None],[None],73,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Branch.py:Branch:_initAttributes,Branch:_initAttributes,method,5,8,6,168,21.0,0,0,['self'],[None],[None],79,[],[],0
github/Branch.py:Branch:_useAttributes,Branch:_useAttributes,method,7,45,23,448,9.96,0,4,"['self', 'attributes']","[None, None]","[None, None]",85,[],"['self._makeClassAttribute', 'self._makeStringAttribute', 'self._makeBoolAttribute']",3
github/Branch.py:Branch:get_protection,Branch:get_protection,method,5,15,14,241,16.07,0,0,['self'],[None],[None],99,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/branches/{branch}/protection <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        """"""\n']",[],0
github/Branch.py:Branch:edit_protection,Branch:edit_protection,method,19,268,84,3387,12.64,0,14,"['self', 'strict', 'contexts', 'enforce_admins', 'dismissal_users', 'dismissal_teams', 'dismiss_stale_reviews', 'require_code_owner_reviews', 'required_approving_review_count', 'user_push_restrictions', 'team_push_restrictions', '']","[None, None, None, None, None, None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",112,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/branches/{branch}/protection <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :strict: bool\n', '        :contexts: list of strings\n', '        :enforce_admins: bool\n', '        :dismissal_users: list of strings\n', '        :dismissal_teams: list of strings\n', '        :dismiss_stale_reviews: bool\n', '        :require_code_owner_reviews: bool\n', '        :required_approving_review_count: int\n', '        :user_push_restrictions: list of strings\n', '        :team_push_restrictions: list of strings\n', '\n', '        NOTE: The GitHub API groups strict and contexts together, both must\n', '        be submitted. Take care to pass both as arguments even if only one is\n', '        changing. Use edit_required_status_checks() to avoid this.\n', '        """"""\n']","['isinstance', 'all']",2
github/Branch.py:Branch:remove_protection,Branch:remove_protection,method,3,6,6,82,13.67,0,0,['self'],[None],[None],246,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/branches/{branch}/protection <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        """"""\n']",[],0
github/Branch.py:Branch:get_required_status_checks,Branch:get_required_status_checks,method,5,13,12,207,15.92,0,0,['self'],[None],[None],255,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :rtype: :class:`github.RequiredStatusChecks.RequiredStatusChecks`\n', '        """"""\n']",[],0
github/Branch.py:Branch:edit_required_status_checks,Branch:edit_required_status_checks,method,11,45,31,482,10.71,0,2,"['self', 'strict', 'contexts']","[None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet']",267,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :strict: bool\n', '        :contexts: list of strings\n', '        """"""\n']","['isinstance', 'all']",2
github/Branch.py:Branch:remove_required_status_checks,Branch:remove_required_status_checks,method,3,6,6,110,18.33,0,0,['self'],[None],[None],291,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        """"""\n']",[],0
github/Branch.py:Branch:get_required_pull_request_reviews,Branch:get_required_pull_request_reviews,method,5,15,14,296,19.73,0,0,['self'],[None],[None],300,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :rtype: :class:`github.RequiredPullRequestReviews.RequiredPullRequestReviews`\n', '        """"""\n']",[],0
github/Branch.py:Branch:edit_required_pull_request_reviews,Branch:edit_required_pull_request_reviews,method,14,114,55,1617,14.18,0,6,"['self', 'dismissal_users', 'dismissal_teams', 'dismiss_stale_reviews', 'require_code_owner_reviews', 'required_approving_review_count', '']","[None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",314,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :dismissal_users: list of strings\n', '        :dismissal_teams: list of strings\n', '        :dismiss_stale_reviews: bool\n', '        :require_code_owner_reviews: bool\n', '        :required_approving_review_count: int\n', '        """"""\n']","['all', 'isinstance']",2
github/Branch.py:Branch:remove_required_pull_request_reviews,Branch:remove_required_pull_request_reviews,method,3,6,6,117,19.5,0,0,['self'],[None],[None],369,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        """"""\n']",[],0
github/Branch.py:Branch:get_admin_enforcement,Branch:get_admin_enforcement,method,5,8,8,119,14.88,0,0,['self'],[None],[None],378,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :rtype: bool\n', '        """"""\n']",[],0
github/Branch.py:Branch:set_admin_enforcement,Branch:set_admin_enforcement,method,3,6,6,98,16.33,0,0,['self'],[None],[None],388,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        """"""\n']",[],0
github/Branch.py:Branch:remove_admin_enforcement,Branch:remove_admin_enforcement,method,3,6,6,100,16.67,0,0,['self'],[None],[None],396,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        """"""\n']",[],0
github/Branch.py:Branch:get_user_push_restrictions,Branch:get_user_push_restrictions,method,2,7,7,139,19.86,0,0,['self'],[None],[None],404,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/Branch.py:Branch:get_team_push_restrictions,Branch:get_team_push_restrictions,method,2,7,7,129,18.43,0,0,['self'],[None],[None],416,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Team.Team`\n', '        """"""\n']",[],0
github/Branch.py:Branch:add_user_push_restrictions,Branch:add_user_push_restrictions,method,4,15,15,172,11.47,0,0,"['self', '*users']","[None, None]","[None, None]",428,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :users: list of strings (user names)\n', '        """"""\n']",['all'],1
github/Branch.py:Branch:replace_user_push_restrictions,Branch:replace_user_push_restrictions,method,4,15,15,171,11.4,0,0,"['self', '*users']","[None, None]","[None, None]",439,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :users: list of strings (user names)\n', '        """"""\n']",['all'],1
github/Branch.py:Branch:remove_user_push_restrictions,Branch:remove_user_push_restrictions,method,4,15,15,174,11.6,0,0,"['self', '*users']","[None, None]","[None, None]",450,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :users: list of strings (user names)\n', '        """"""\n']",['all'],1
github/Branch.py:Branch:add_team_push_restrictions,Branch:add_team_push_restrictions,method,4,15,15,172,11.47,0,0,"['self', '*teams']","[None, None]","[None, None]",461,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :teams: list of strings (team slugs)\n', '        """"""\n']",['all'],1
github/Branch.py:Branch:replace_team_push_restrictions,Branch:replace_team_push_restrictions,method,4,15,15,171,11.4,0,0,"['self', '*teams']","[None, None]","[None, None]",472,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :teams: list of strings (team slugs)\n', '        """"""\n']",['all'],1
github/Branch.py:Branch:remove_team_push_restrictions,Branch:remove_team_push_restrictions,method,4,15,15,174,11.6,0,0,"['self', '*teams']","[None, None]","[None, None]",483,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        :teams: list of strings (team slugs)\n', '        """"""\n']",['all'],1
github/Branch.py:Branch:remove_push_restrictions,Branch:remove_push_restrictions,method,3,6,6,98,16.33,0,0,['self'],[None],[None],494,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions <https://docs.github.com/en/rest/reference/repos#branches>`_\n', '        """"""\n']",[],0
github/Branch.py:Branch:get_required_signatures,Branch:get_required_signatures,method,5,10,10,188,18.8,0,0,['self'],[None],[None],502,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures <https://docs.github.com/en/rest/reference/repos#branches>`\n', '        """"""\n']",[],0
github/Branch.py:Branch:add_required_signatures,Branch:add_required_signatures,method,3,8,8,167,20.88,0,0,['self'],[None],[None],513,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures <https://docs.github.com/en/rest/reference/repos#branches>`\n', '        """"""\n']",[],0
github/Branch.py:Branch:remove_required_signatures,Branch:remove_required_signatures,method,3,8,8,169,21.12,0,0,['self'],[None],[None],523,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures <https://docs.github.com/en/rest/reference/repos#branches>`\n', '        """"""\n']",[],0
github/BranchProtection.py:BranchProtection,BranchProtection,class,28,136,64,2226,16.37,0,7,[],[],[],30,[],[],0
github/BranchProtection.py:BranchProtection:__repr__,BranchProtection:__repr__,method,2,3,3,47,15.67,0,0,['self'],[None],[None],35,[],['self.get__repr__'],1
github/BranchProtection.py:BranchProtection:url,BranchProtection:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],39,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/BranchProtection.py:BranchProtection:required_status_checks,BranchProtection:required_status_checks,method,3,3,3,93,31.0,0,0,['self'],[None],[None],47,"['        """"""\n', '        :type: :class:`github.RequiredStatusChecks.RequiredStatusChecks`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/BranchProtection.py:BranchProtection:enforce_admins,BranchProtection:enforce_admins,method,3,3,3,77,25.67,0,0,['self'],[None],[None],55,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/BranchProtection.py:BranchProtection:required_pull_request_reviews,BranchProtection:required_pull_request_reviews,method,3,3,3,107,35.67,0,0,['self'],[None],[None],63,"['        """"""\n', '        :type: :class:`github.RequiredPullRequestReviews.RequiredPullRequestReviews`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/BranchProtection.py:BranchProtection:get_user_push_restrictions,BranchProtection:get_user_push_restrictions,method,4,13,12,195,15.0,0,1,['self'],[None],[None],70,"['        """"""\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/BranchProtection.py:BranchProtection:get_team_push_restrictions,BranchProtection:get_team_push_restrictions,method,4,13,11,181,13.92,0,1,['self'],[None],[None],83,"['        """"""\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Team.Team`\n', '        """"""\n']",[],0
github/BranchProtection.py:BranchProtection:_initAttributes,BranchProtection:_initAttributes,method,7,12,8,315,26.25,0,0,['self'],[None],[None],93,[],[],0
github/BranchProtection.py:BranchProtection:_useAttributes,BranchProtection:_useAttributes,method,10,60,29,841,14.02,0,5,"['self', 'attributes']","[None, None]","[None, None]",101,[],"['self._makeStringAttribute', 'self._makeClassAttribute', 'self._makeBoolAttribute']",3
github/CheckRun.py:CheckRun,CheckRun,class,77,526,217,6730,12.79,0,26,[],[],[],33,[],[],0
github/CheckRun.py:CheckRun:__repr__,CheckRun:__repr__,method,2,7,7,83,11.86,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/CheckRun.py:CheckRun:app,CheckRun:app,method,3,3,3,55,18.33,0,0,['self'],[None],[None],45,"['        """"""\n', '        :type: :class:`github.GithubApp.GithubApp`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:check_suite_id,CheckRun:check_suite_id,method,3,3,3,77,25.67,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:completed_at,CheckRun:completed_at,method,3,3,3,73,24.33,0,0,['self'],[None],[None],61,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:conclusion,CheckRun:conclusion,method,3,3,3,69,23.0,0,0,['self'],[None],[None],69,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:details_url,CheckRun:details_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],77,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:external_id,CheckRun:external_id,method,3,3,3,71,23.67,0,0,['self'],[None],[None],85,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:head_sha,CheckRun:head_sha,method,3,3,3,65,21.67,0,0,['self'],[None],[None],93,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:html_url,CheckRun:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],101,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:id,CheckRun:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],109,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:name,CheckRun:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],117,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:node_id,CheckRun:node_id,method,3,3,3,63,21.0,0,0,['self'],[None],[None],125,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:output,CheckRun:output,method,3,3,3,61,20.33,0,0,['self'],[None],[None],133,"['        """"""\n', '        :type: :class:`github.CheckRunOutput.CheckRunOutput`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:pull_requests,CheckRun:pull_requests,method,3,3,3,75,25.0,0,0,['self'],[None],[None],141,"['        """"""\n', '        :type: list of :class:`github.PullRequest.PullRequest`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:started_at,CheckRun:started_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],149,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:status,CheckRun:status,method,3,3,3,61,20.33,0,0,['self'],[None],[None],157,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:url,CheckRun:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],165,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckRun.py:CheckRun:get_annotations,CheckRun:get_annotations,method,2,9,9,192,21.33,0,0,['self'],[None],[None],172,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/check-runs/{check_run_id}/annotations <https://docs.github.com/en/rest/reference/checks#list-check-run-annotations>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.CheckRunAnnotation.CheckRunAnnotation`\n', '        """"""\n']",[],0
github/CheckRun.py:CheckRun:edit,CheckRun:edit,method,24,180,71,1881,10.45,0,10,"['self', 'name', 'head_sha', 'details_url', 'external_id', 'status', 'started_at', 'conclusion', 'completed_at', 'output', 'actions', '']","[None, None, None, None, None, None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",185,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/check-runs/{check_run_id} <https://docs.github.com/en/rest/reference/checks#update-a-check-run>`_\n', '        :param name: string\n', '        :param head_sha: string\n', '        :param details_url: string\n', '        :param external_id: string\n', '        :param status: string\n', '        :param started_at: datetime.datetime\n', '        :param conclusion: string\n', '        :param completed_at: datetime.datetime\n', '        :param output: dict\n', '        :param actions: list of dict\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'all', 'dict', 'started_at.strftime', 'completed_at.strftime', 'self._useAttributes']",6
github/CheckRun.py:CheckRun:_initAttributes,CheckRun:_initAttributes,method,17,34,18,711,20.91,0,0,['self'],[None],[None],266,[],[],0
github/CheckRun.py:CheckRun:_useAttributes,CheckRun:_useAttributes,method,21,177,67,1839,10.39,0,16,"['self', 'attributes']","[None, None]","[None, None]",285,[],"['self._makeClassAttribute', 'self._makeIntAttribute', 'self._makeDatetimeAttribute', 'self._makeStringAttribute', 'self._makeListOfClassesAttribute']",5
github/CheckRunAnnotation.py:CheckRunAnnotation,CheckRunAnnotation,class,35,165,64,2024,12.27,0,9,[],[],[],26,[],[],0
github/CheckRunAnnotation.py:CheckRunAnnotation:__repr__,CheckRunAnnotation:__repr__,method,2,3,3,51,17.0,0,0,['self'],[None],[None],32,[],['self.get__repr__'],1
github/CheckRunAnnotation.py:CheckRunAnnotation:annotation_level,CheckRunAnnotation:annotation_level,method,2,2,2,34,17.0,0,0,['self'],[None],[None],36,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CheckRunAnnotation.py:CheckRunAnnotation:end_column,CheckRunAnnotation:end_column,method,2,2,2,28,14.0,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/CheckRunAnnotation.py:CheckRunAnnotation:end_line,CheckRunAnnotation:end_line,method,2,2,2,26,13.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/CheckRunAnnotation.py:CheckRunAnnotation:message,CheckRunAnnotation:message,method,2,2,2,25,12.5,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CheckRunAnnotation.py:CheckRunAnnotation:path,CheckRunAnnotation:path,method,2,2,2,22,11.0,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CheckRunAnnotation.py:CheckRunAnnotation:raw_details,CheckRunAnnotation:raw_details,method,2,2,2,29,14.5,0,0,['self'],[None],[None],71,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CheckRunAnnotation.py:CheckRunAnnotation:start_column,CheckRunAnnotation:start_column,method,2,2,2,30,15.0,0,0,['self'],[None],[None],78,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/CheckRunAnnotation.py:CheckRunAnnotation:start_line,CheckRunAnnotation:start_line,method,2,2,2,28,14.0,0,0,['self'],[None],[None],85,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/CheckRunAnnotation.py:CheckRunAnnotation:title,CheckRunAnnotation:title,method,2,2,2,23,11.5,0,0,['self'],[None],[None],92,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CheckRunAnnotation.py:CheckRunAnnotation:_initAttributes,CheckRunAnnotation:_initAttributes,method,10,18,11,388,21.56,0,0,['self'],[None],[None],98,[],[],0
github/CheckRunAnnotation.py:CheckRunAnnotation:_useAttributes,CheckRunAnnotation:_useAttributes,method,11,92,36,976,10.61,0,9,"['self', 'attributes']","[None, None]","[None, None]",109,[],"['self._makeStringAttribute', 'self._makeIntAttribute']",2
github/CheckRunOutput.py:CheckRunOutput,CheckRunOutput,class,23,99,45,1201,12.13,0,5,[],[],[],26,[],[],0
github/CheckRunOutput.py:CheckRunOutput:__repr__,CheckRunOutput:__repr__,method,2,3,3,51,17.0,0,0,['self'],[None],[None],29,[],['self.get__repr__'],1
github/CheckRunOutput.py:CheckRunOutput:annotations_count,CheckRunOutput:annotations_count,method,2,2,2,35,17.5,0,0,['self'],[None],[None],33,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/CheckRunOutput.py:CheckRunOutput:annotations_url,CheckRunOutput:annotations_url,method,2,2,2,33,16.5,0,0,['self'],[None],[None],40,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CheckRunOutput.py:CheckRunOutput:summary,CheckRunOutput:summary,method,2,2,2,25,12.5,0,0,['self'],[None],[None],47,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CheckRunOutput.py:CheckRunOutput:text,CheckRunOutput:text,method,2,2,2,22,11.0,0,0,['self'],[None],[None],54,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CheckRunOutput.py:CheckRunOutput:title,CheckRunOutput:title,method,2,2,2,23,11.5,0,0,['self'],[None],[None],61,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CheckRunOutput.py:CheckRunOutput:_initAttributes,CheckRunOutput:_initAttributes,method,6,10,7,217,21.7,0,0,['self'],[None],[None],67,[],[],0
github/CheckRunOutput.py:CheckRunOutput:_useAttributes,CheckRunOutput:_useAttributes,method,7,54,25,554,10.26,0,5,"['self', 'attributes']","[None, None]","[None, None]",74,[],"['self._makeIntAttribute', 'self._makeStringAttribute']",2
github/CheckSuite.py:CheckSuite,CheckSuite,class,76,404,177,5404,13.38,0,20,[],[],[],26,[],[],0
github/CheckSuite.py:CheckSuite:__repr__,CheckSuite:__repr__,method,2,5,5,67,13.4,0,0,['self'],[None],[None],31,[],['self.get__repr__'],1
github/CheckSuite.py:CheckSuite:after,CheckSuite:after,method,3,3,3,59,19.67,0,0,['self'],[None],[None],35,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:app,CheckSuite:app,method,3,3,3,55,18.33,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: :class:`github.GithubApp.GithubApp`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:before,CheckSuite:before,method,3,3,3,61,20.33,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:check_runs_url,CheckSuite:check_runs_url,method,3,3,3,77,25.67,0,0,['self'],[None],[None],59,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:conclusion,CheckSuite:conclusion,method,3,3,3,69,23.0,0,0,['self'],[None],[None],67,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:created_at,CheckSuite:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],75,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:head_branch,CheckSuite:head_branch,method,3,3,3,71,23.67,0,0,['self'],[None],[None],83,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:head_commit,CheckSuite:head_commit,method,3,3,3,71,23.67,0,0,['self'],[None],[None],91,"['        """"""\n', '        :type: :class:`github.GitCommit.GitCommit`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:head_sha,CheckSuite:head_sha,method,3,3,3,65,21.67,0,0,['self'],[None],[None],99,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:id,CheckSuite:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],107,"['        """"""\n', '        :type: int\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:latest_check_runs_count,CheckSuite:latest_check_runs_count,method,3,3,3,95,31.67,0,0,['self'],[None],[None],115,"['        """"""\n', '        :type: int\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:pull_requests,CheckSuite:pull_requests,method,3,3,3,75,25.0,0,0,['self'],[None],[None],123,"['        """"""\n', '        :type: list of :class:`github.PullRequest.PullRequest`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:repository,CheckSuite:repository,method,3,3,3,69,23.0,0,0,['self'],[None],[None],131,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:status,CheckSuite:status,method,3,3,3,61,20.33,0,0,['self'],[None],[None],139,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:updated_at,CheckSuite:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],147,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:url,CheckSuite:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],155,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CheckSuite.py:CheckSuite:rerequest,CheckSuite:rerequest,method,7,14,14,174,12.43,0,0,['self'],[None],[None],162,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/check-suites/{check_suite_id}/rerequest <https://docs.github.com/en/rest/reference/checks#rerequest-a-check-suite>`_\n', '        :rtype: bool\n', '        """"""\n']",[],0
github/CheckSuite.py:CheckSuite:get_check_runs,CheckSuite:get_check_runs,method,11,59,35,688,11.66,0,3,"['self', 'check_name', 'status', 'filter', '']","[None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",173,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/check-suites/{check_suite_id}/check-runs <https://docs.github.com/en/rest/reference/checks#list-check-runs-in-a-check-suite>`_\n', '        :param check_name: string\n', '        :param status: string\n', '        :param filter: string\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.CheckRun.CheckRun`\n', '        """"""\n']","['isinstance', 'dict']",2
github/CheckSuite.py:CheckSuite:_initAttributes,CheckSuite:_initAttributes,method,17,32,18,688,21.5,0,0,['self'],[None],[None],207,[],[],0
github/CheckSuite.py:CheckSuite:_useAttributes,CheckSuite:_useAttributes,method,22,182,67,1974,10.85,0,17,"['self', 'attributes']","[None, None]","[None, None]",225,[],"['self._makeStringAttribute', 'self._makeClassAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeListOfClassesAttribute']",5
github/Clones.py:Clones,Clones,class,17,69,40,793,11.49,0,3,[],[],[],30,[],[],0
github/Clones.py:Clones:__repr__,Clones:__repr__,method,2,11,11,122,11.09,0,0,['self'],[None],[None],36,[],['self.get__repr__'],1
github/Clones.py:Clones:timestamp,Clones:timestamp,method,2,2,2,27,13.5,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/Clones.py:Clones:count,Clones:count,method,2,2,2,23,11.5,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Clones.py:Clones:uniques,Clones:uniques,method,2,2,2,25,12.5,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Clones.py:Clones:_initAttributes,Clones:_initAttributes,method,4,6,5,122,20.33,0,0,['self'],[None],[None],66,[],[],0
github/Clones.py:Clones:_useAttributes,Clones:_useAttributes,method,5,30,16,304,10.13,0,3,"['self', 'attributes']","[None, None]","[None, None]",71,[],"['self._makeDatetimeAttribute', 'self._makeIntAttribute']",2
github/Commit.py:Commit,Commit,class,79,533,216,6682,12.54,0,21,[],[],[],46,[],[],0
github/Commit.py:Commit:__repr__,Commit:__repr__,method,2,3,3,47,15.67,0,0,['self'],[None],[None],51,[],['self.get__repr__'],1
github/Commit.py:Commit:author,Commit:author,method,3,3,3,61,20.33,0,0,['self'],[None],[None],55,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Commit.py:Commit:comments_url,Commit:comments_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],63,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Commit.py:Commit:commit,Commit:commit,method,3,3,3,61,20.33,0,0,['self'],[None],[None],71,"['        """"""\n', '        :type: :class:`github.GitCommit.GitCommit`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Commit.py:Commit:committer,Commit:committer,method,3,3,3,67,22.33,0,0,['self'],[None],[None],79,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Commit.py:Commit:files,Commit:files,method,3,3,3,59,19.67,0,0,['self'],[None],[None],87,"['        """"""\n', '        :type: list of :class:`github.File.File`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Commit.py:Commit:html_url,Commit:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],95,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Commit.py:Commit:parents,Commit:parents,method,3,3,3,63,21.0,0,0,['self'],[None],[None],103,"['        """"""\n', '        :type: list of :class:`github.Commit.Commit`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Commit.py:Commit:sha,Commit:sha,method,3,3,3,55,18.33,0,0,['self'],[None],[None],111,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Commit.py:Commit:stats,Commit:stats,method,3,3,3,59,19.67,0,0,['self'],[None],[None],119,"['        """"""\n', '        :type: :class:`github.CommitStats.CommitStats`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Commit.py:Commit:url,Commit:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],127,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Commit.py:Commit:create_comment,Commit:create_comment,method,13,70,44,684,9.77,0,3,"['self', 'body', 'line', 'path', 'position', '']","[None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",134,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/commits/{sha}/comments <http://docs.github.com/en/rest/reference/repos#comments>`_\n', '        :param body: string\n', '        :param line: integer\n', '        :param path: string\n', '        :param position: integer\n', '        :rtype: :class:`github.CommitComment.CommitComment`\n', '        """"""\n']",['isinstance'],1
github/Commit.py:Commit:create_status,Commit:create_status,method,14,74,43,810,10.95,0,3,"['self', 'state', 'target_url', 'description', 'context', '']","[None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",171,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/statuses/{sha} <http://docs.github.com/en/rest/reference/repos#statuses>`_\n', '        :param state: string\n', '        :param target_url: string\n', '        :param description: string\n', '        :param context: string\n', '        :rtype: :class:`github.CommitStatus.CommitStatus`\n', '        """"""\n']",['isinstance'],1
github/Commit.py:Commit:get_comments,Commit:get_comments,method,2,7,7,126,18.0,0,0,['self'],[None],[None],214,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/commits/{sha}/comments <http://docs.github.com/en/rest/reference/repos#comments>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.CommitComment.CommitComment`\n', '        """"""\n']",[],0
github/Commit.py:Commit:get_statuses,Commit:get_statuses,method,3,7,7,169,24.14,0,0,['self'],[None],[None],226,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/statuses/{ref} <http://docs.github.com/en/rest/reference/repos#statuses>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.CommitStatus.CommitStatus`\n', '        """"""\n']",[],0
github/Commit.py:Commit:get_combined_status,Commit:get_combined_status,method,5,11,10,178,16.18,0,0,['self'],[None],[None],238,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/commits/{ref}/status/ <http://docs.github.com/en/rest/reference/repos#statuses>`_\n', '        :rtype: :class:`github.CommitCombinedStatus.CommitCombinedStatus`\n', '        """"""\n']",[],0
github/Commit.py:Commit:get_pulls,Commit:get_pulls,method,2,9,9,183,20.33,0,0,['self'],[None],[None],248,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/commits/{sha}/pulls <https://docs.github.com/en/rest/reference/repos#list-pull-requests-associated-with-a-commit>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.PullRequest.PullRequest`\n', '        """"""\n']",[],0
github/Commit.py:Commit:get_check_runs,Commit:get_check_runs,method,11,59,35,688,11.66,0,3,"['self', 'check_name', 'status', 'filter', '']","[None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",261,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/commits/{sha}/check-runs <https://docs.github.com/en/rest/reference/checks#list-check-runs-for-a-git-reference>`_\n', '        :param check_name: string\n', '        :param status: string\n', '        :param filter: string\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.CheckRun.CheckRun`\n', '        """"""\n']","['isinstance', 'dict']",2
github/Commit.py:Commit:get_check_suites,Commit:get_check_suites,method,10,46,33,567,12.33,0,2,"['self', 'app_id', 'check_name']","[None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet']",295,"['        """"""\n', '        :class: `GET /repos/{owner}/{repo}/commits/{ref}/check-suites <https://docs.github.com/en/rest/reference/checks#list-check-suites-for-a-git-reference>`_\n', '        :param app_id: int\n', '        :param check_name: string\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.CheckSuite.CheckSuite`\n', '        """"""\n']","['isinstance', 'dict']",2
github/Commit.py:Commit:_identity,Commit:_identity,method,2,2,2,14,7.0,0,0,['self'],[None],[None],324,[],[],0
github/Commit.py:Commit:_initAttributes,Commit:_initAttributes,method,11,20,12,403,20.15,0,0,['self'],[None],[None],327,[],[],0
github/Commit.py:Commit:_useAttributes,Commit:_useAttributes,method,13,118,45,1169,9.91,0,10,"['self', 'attributes']","[None, None]","[None, None]",339,[],"['self._makeClassAttribute', 'self._makeStringAttribute', 'self._makeListOfClassesAttribute']",3
github/CommitCombinedStatus.py:CommitCombinedStatus,CommitCombinedStatus,class,31,137,60,1615,11.79,0,7,[],[],[],32,[],[],0
github/CommitCombinedStatus.py:CommitCombinedStatus:__repr__,CommitCombinedStatus:__repr__,method,2,5,5,73,14.6,0,0,['self'],[None],[None],37,[],['self.get__repr__'],1
github/CommitCombinedStatus.py:CommitCombinedStatus:state,CommitCombinedStatus:state,method,2,2,2,23,11.5,0,0,['self'],[None],[None],41,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CommitCombinedStatus.py:CommitCombinedStatus:sha,CommitCombinedStatus:sha,method,2,2,2,21,10.5,0,0,['self'],[None],[None],48,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CommitCombinedStatus.py:CommitCombinedStatus:total_count,CommitCombinedStatus:total_count,method,2,2,2,29,14.5,0,0,['self'],[None],[None],55,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/CommitCombinedStatus.py:CommitCombinedStatus:commit_url,CommitCombinedStatus:commit_url,method,2,2,2,28,14.0,0,0,['self'],[None],[None],62,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CommitCombinedStatus.py:CommitCombinedStatus:url,CommitCombinedStatus:url,method,2,2,2,21,10.5,0,0,['self'],[None],[None],69,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CommitCombinedStatus.py:CommitCombinedStatus:repository,CommitCombinedStatus:repository,method,2,2,2,28,14.0,0,0,['self'],[None],[None],76,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",[],0
github/CommitCombinedStatus.py:CommitCombinedStatus:statuses,CommitCombinedStatus:statuses,method,2,2,2,26,13.0,0,0,['self'],[None],[None],83,"['        """"""\n', '        :type: list of :class:`CommitStatus`\n', '        """"""\n']",[],0
github/CommitCombinedStatus.py:CommitCombinedStatus:_initAttributes,CommitCombinedStatus:_initAttributes,method,8,14,9,287,20.5,0,0,['self'],[None],[None],89,[],[],0
github/CommitCombinedStatus.py:CommitCombinedStatus:_useAttributes,CommitCombinedStatus:_useAttributes,method,11,76,34,792,10.42,0,7,"['self', 'attributes']","[None, None]","[None, None]",98,[],"['self._makeStringAttribute', 'self._makeIntAttribute', 'self._makeClassAttribute', 'self._makeListOfClassesAttribute']",4
github/CommitComment.py:CommitComment,CommitComment,class,62,295,142,3785,12.83,0,11,[],[],[],40,[],[],0
github/CommitComment.py:CommitComment:__repr__,CommitComment:__repr__,method,2,5,5,62,12.4,0,0,['self'],[None],[None],45,[],['self.get__repr__'],1
github/CommitComment.py:CommitComment:body,CommitComment:body,method,3,3,3,57,19.0,0,0,['self'],[None],[None],49,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CommitComment.py:CommitComment:commit_id,CommitComment:commit_id,method,3,3,3,67,22.33,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CommitComment.py:CommitComment:created_at,CommitComment:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],65,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CommitComment.py:CommitComment:html_url,CommitComment:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],73,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CommitComment.py:CommitComment:id,CommitComment:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],81,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CommitComment.py:CommitComment:line,CommitComment:line,method,3,3,3,57,19.0,0,0,['self'],[None],[None],89,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CommitComment.py:CommitComment:path,CommitComment:path,method,3,3,3,57,19.0,0,0,['self'],[None],[None],97,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CommitComment.py:CommitComment:position,CommitComment:position,method,3,3,3,65,21.67,0,0,['self'],[None],[None],105,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CommitComment.py:CommitComment:updated_at,CommitComment:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],113,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CommitComment.py:CommitComment:url,CommitComment:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],121,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CommitComment.py:CommitComment:user,CommitComment:user,method,3,3,3,57,19.0,0,0,['self'],[None],[None],129,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/CommitComment.py:CommitComment:delete,CommitComment:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],136,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/comments/{id} <http://docs.github.com/en/rest/reference/repos#comments>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/CommitComment.py:CommitComment:edit,CommitComment:edit,method,6,17,17,181,10.65,0,0,"['self', 'body']","[None, None]","[None, None]",143,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/comments/{id} <http://docs.github.com/en/rest/reference/repos#comments>`_\n', '        :param body: string\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'self._useAttributes']",2
github/CommitComment.py:CommitComment:get_reactions,CommitComment:get_reactions,method,2,9,9,170,18.89,0,0,['self'],[None],[None],158,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/comments/{id}/reactions\n', '                <https://docs.github.com/en/rest/reference/reactions#list-reactions-for-a-commit-comment>`_\n', '        :return: :class: :class:`github.PaginatedList.PaginatedList` of :class:`github.Reaction.Reaction`\n', '        """"""\n']",[],0
github/CommitComment.py:CommitComment:create_reaction,CommitComment:create_reaction,method,7,23,22,331,14.39,0,0,"['self', 'reaction_type']","[None, None]","[None, None]",172,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/comments/{id}/reactions\n', '                <https://docs.github.com/en/rest/reference/reactions#create-reaction-for-a-commit-comment>`_\n', '        :param reaction_type: string\n', '        :rtype: :class:`github.Reaction.Reaction`\n', '        """"""\n']",['isinstance'],1
github/CommitComment.py:CommitComment:delete_reaction,CommitComment:delete_reaction,method,7,16,16,207,12.94,0,0,"['self', 'reaction_id']","[None, None]","[None, None]",191,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/comments/{comment_id}/reactions/{reaction_id}\n', '                <https://docs.github.com/en/rest/reference/reactions#delete-a-commit-comment-reaction>`_\n', '        :param reaction_id: integer\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/CommitComment.py:CommitComment:_initAttributes,CommitComment:_initAttributes,method,12,22,13,439,19.95,0,0,['self'],[None],[None],206,[],[],0
github/CommitComment.py:CommitComment:_useAttributes,CommitComment:_useAttributes,method,15,113,43,1122,9.93,0,11,"['self', 'attributes']","[None, None]","[None, None]",219,[],"['self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeClassAttribute']",4
github/CommitStats.py:CommitStats,CommitStats,class,14,56,29,658,11.75,0,3,[],[],[],33,[],[],0
github/CommitStats.py:CommitStats:additions,CommitStats:additions,method,2,2,2,27,13.5,0,0,['self'],[None],[None],39,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/CommitStats.py:CommitStats:deletions,CommitStats:deletions,method,2,2,2,27,13.5,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/CommitStats.py:CommitStats:total,CommitStats:total,method,2,2,2,23,11.5,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/CommitStats.py:CommitStats:_initAttributes,CommitStats:_initAttributes,method,4,6,5,124,20.67,0,0,['self'],[None],[None],59,[],[],0
github/CommitStats.py:CommitStats:_useAttributes,CommitStats:_useAttributes,method,4,30,16,305,10.17,0,3,"['self', 'attributes']","[None, None]","[None, None]",64,[],['self._makeIntAttribute'],1
github/CommitStatus.py:CommitStatus,CommitStatus,class,37,174,72,2012,11.56,0,9,[],[],[],37,[],[],0
github/CommitStatus.py:CommitStatus:__repr__,CommitStatus:__repr__,method,2,11,11,108,9.82,0,0,['self'],[None],[None],42,[],['self.get__repr__'],1
github/CommitStatus.py:CommitStatus:created_at,CommitStatus:created_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/CommitStatus.py:CommitStatus:creator,CommitStatus:creator,method,2,2,2,25,12.5,0,0,['self'],[None],[None],59,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/CommitStatus.py:CommitStatus:description,CommitStatus:description,method,2,2,2,29,14.5,0,0,['self'],[None],[None],66,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CommitStatus.py:CommitStatus:id,CommitStatus:id,method,2,2,2,20,10.0,0,0,['self'],[None],[None],73,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/CommitStatus.py:CommitStatus:state,CommitStatus:state,method,2,2,2,23,11.5,0,0,['self'],[None],[None],80,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CommitStatus.py:CommitStatus:context,CommitStatus:context,method,2,2,2,25,12.5,0,0,['self'],[None],[None],87,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CommitStatus.py:CommitStatus:target_url,CommitStatus:target_url,method,2,2,2,28,14.0,0,0,['self'],[None],[None],94,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CommitStatus.py:CommitStatus:updated_at,CommitStatus:updated_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],101,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/CommitStatus.py:CommitStatus:url,CommitStatus:url,method,2,2,2,21,10.5,0,0,['self'],[None],[None],108,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/CommitStatus.py:CommitStatus:_initAttributes,CommitStatus:_initAttributes,method,10,18,11,370,20.56,0,0,['self'],[None],[None],114,[],[],0
github/CommitStatus.py:CommitStatus:_useAttributes,CommitStatus:_useAttributes,method,13,93,37,961,10.33,0,9,"['self', 'attributes']","[None, None]","[None, None]",125,[],"['self._makeDatetimeAttribute', 'self._makeClassAttribute', 'self._makeStringAttribute', 'self._makeIntAttribute']",4
github/Comparison.py:Comparison,Comparison,class,48,251,97,3402,13.55,0,13,[],[],[],35,[],[],0
github/Comparison.py:Comparison:ahead_by,Comparison:ahead_by,method,3,3,3,65,21.67,0,0,['self'],[None],[None],41,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:base_commit,Comparison:base_commit,method,3,3,3,71,23.67,0,0,['self'],[None],[None],49,"['        """"""\n', '        :type: :class:`github.Commit.Commit`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:behind_by,Comparison:behind_by,method,3,3,3,67,22.33,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:commits,Comparison:commits,method,3,3,3,63,21.0,0,0,['self'],[None],[None],65,"['        """"""\n', '        :type: list of :class:`github.Commit.Commit`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:diff_url,Comparison:diff_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],73,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:files,Comparison:files,method,3,3,3,59,19.67,0,0,['self'],[None],[None],81,"['        """"""\n', '        :type: list of :class:`github.File.File`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:html_url,Comparison:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],89,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:merge_base_commit,Comparison:merge_base_commit,method,3,3,3,83,27.67,0,0,['self'],[None],[None],97,"['        """"""\n', '        :type: :class:`github.Commit.Commit`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:patch_url,Comparison:patch_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],105,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:permalink_url,Comparison:permalink_url,method,3,3,3,75,25.0,0,0,['self'],[None],[None],113,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:status,Comparison:status,method,3,3,3,61,20.33,0,0,['self'],[None],[None],121,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:total_commits,Comparison:total_commits,method,3,3,3,75,25.0,0,0,['self'],[None],[None],129,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:url,Comparison:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],137,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Comparison.py:Comparison:_initAttributes,Comparison:_initAttributes,method,14,26,15,558,21.46,0,0,['self'],[None],[None],144,[],[],0
github/Comparison.py:Comparison:_useAttributes,Comparison:_useAttributes,method,17,142,51,1507,10.61,0,13,"['self', 'attributes']","[None, None]","[None, None]",159,[],"['self._makeIntAttribute', 'self._makeClassAttribute', 'self._makeListOfClassesAttribute', 'self._makeStringAttribute']",4
github/ContentFile.py:ContentFile,ContentFile,class,61,311,131,3847,12.37,0,15,[],[],[],38,[],[],0
github/ContentFile.py:ContentFile:__repr__,ContentFile:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],43,[],['self.get__repr__'],1
github/ContentFile.py:ContentFile:content,ContentFile:content,method,3,3,3,63,21.0,0,0,['self'],[None],[None],47,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:decoded_content,ContentFile:decoded_content,method,3,9,9,124,13.78,0,0,['self'],[None],[None],55,"['        """"""\n', '        :type: bytes\n', '        """"""\n']",['base64.b64decode'],1
github/ContentFile.py:ContentFile:download_url,ContentFile:download_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],63,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:encoding,ContentFile:encoding,method,3,3,3,65,21.67,0,0,['self'],[None],[None],71,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:git_url,ContentFile:git_url,method,3,3,3,63,21.0,0,0,['self'],[None],[None],79,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:html_url,ContentFile:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],87,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:license,ContentFile:license,method,3,3,3,63,21.0,0,0,['self'],[None],[None],95,"['        """"""\n', '        :type: :class:`github.License.License`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:name,ContentFile:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],103,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:path,ContentFile:path,method,3,3,3,57,19.0,0,0,['self'],[None],[None],111,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:repository,ContentFile:repository,method,9,34,25,335,9.85,0,1,['self'],[None],[None],119,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",[],0
github/ContentFile.py:ContentFile:sha,ContentFile:sha,method,3,3,3,55,18.33,0,0,['self'],[None],[None],136,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:size,ContentFile:size,method,3,3,3,57,19.0,0,0,['self'],[None],[None],144,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:type,ContentFile:type,method,3,3,3,57,19.0,0,0,['self'],[None],[None],152,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:url,ContentFile:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],160,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:text_matches,ContentFile:text_matches,method,3,3,3,73,24.33,0,0,['self'],[None],[None],168,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/ContentFile.py:ContentFile:_initAttributes,ContentFile:_initAttributes,method,14,26,15,531,20.42,0,0,['self'],[None],[None],175,[],[],0
github/ContentFile.py:ContentFile:_useAttributes,ContentFile:_useAttributes,method,18,148,55,1484,10.03,0,14,"['self', 'attributes']","[None, None]","[None, None]",190,[],"['self._makeStringAttribute', 'self._makeClassAttribute', 'self._makeIntAttribute', 'self._makeListOfDictsAttribute']",4
github/Deployment.py:Deployment,Deployment,class,74,455,192,6199,13.62,0,20,[],[],[],30,[],[],0
github/Deployment.py:Deployment:__repr__,Deployment:__repr__,method,2,5,5,67,13.4,0,0,['self'],[None],[None],35,[],['self.get__repr__'],1
github/Deployment.py:Deployment:id,Deployment:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],39,"['        """"""\n', '        :type: int\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:url,Deployment:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],47,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:sha,Deployment:sha,method,3,3,3,55,18.33,0,0,['self'],[None],[None],55,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:task,Deployment:task,method,3,3,3,57,19.0,0,0,['self'],[None],[None],63,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:payload,Deployment:payload,method,3,3,3,63,21.0,0,0,['self'],[None],[None],71,"['        """"""\n', '        :type: dict\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:original_environment,Deployment:original_environment,method,3,3,3,89,29.67,0,0,['self'],[None],[None],79,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:environment,Deployment:environment,method,3,3,3,71,23.67,0,0,['self'],[None],[None],87,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:production_environment,Deployment:production_environment,method,3,3,3,93,31.0,0,0,['self'],[None],[None],95,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:transient_environment,Deployment:transient_environment,method,3,3,3,91,30.33,0,0,['self'],[None],[None],103,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:description,Deployment:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],111,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:creator,Deployment:creator,method,3,3,3,63,21.0,0,0,['self'],[None],[None],119,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:created_at,Deployment:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],127,"['        """"""\n', '        :type: datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:updated_at,Deployment:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],135,"['        """"""\n', '        :type: datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:statuses_url,Deployment:statuses_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],143,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:repository_url,Deployment:repository_url,method,3,3,3,77,25.67,0,0,['self'],[None],[None],151,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Deployment.py:Deployment:get_statuses,Deployment:get_statuses,method,2,9,9,178,19.78,0,0,['self'],[None],[None],158,"['        """"""\n', '        :calls: `GET /repos/{owner}/deployments/{deployment_id}/statuses <https://docs.github.com/en/rest/reference/repos#list-deployments>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.DeploymentStatus.DeploymentStatus`\n', '        """"""\n']",['self._get_accept_header'],1
github/Deployment.py:Deployment:get_status,Deployment:get_status,method,8,31,26,462,14.9,0,0,['self'],[None],[None],171,[],"['self._get_accept_header', 'get_status', 'isinstance']",3
github/Deployment.py:Deployment:create_status,Deployment:create_status,method,15,108,52,1233,11.42,0,5,"['self', 'state', 'target_url', 'description', 'environment', 'environment_url', 'auto_inactive', '']","[None, None, None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",187,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/deployments/{deployment_id}/statuses <https://docs.github.com/en/rest/reference/repos#create-a-deployment-status>`_\n', '        :param: state: string\n', '        :param: target_url: string\n', '        :param: description: string\n', '        :param: environment: string\n', '        :param: environment_url: string\n', '        :param: auto_inactive: bool\n', '        :rtype: :class:`github.DeploymentStatus.DeploymentStatus`\n', '        """"""\n']","['isinstance', 'self._get_accept_header']",2
github/Deployment.py:Deployment:_get_accept_header,Deployment:_get_accept_header,method,1,8,8,117,14.62,0,0,[],[],[],246,[],[],0
github/Deployment.py:Deployment:_initAttributes,Deployment:_initAttributes,method,16,30,17,666,22.2,0,0,['self'],[None],[None],254,[],[],0
github/Deployment.py:Deployment:_useAttributes,Deployment:_useAttributes,method,21,161,58,1731,10.75,0,15,"['self', 'attributes']","[None, None]","[None, None]",271,[],"['self._makeIntAttribute', 'self._makeBoolAttribute', 'self._makeStringAttribute', 'self._makeDictAttribute', 'self._makeClassAttribute', 'self._makeDatetimeAttribute']",6
github/DeploymentStatus.py:DeploymentStatus,DeploymentStatus,class,50,255,101,3447,13.52,0,13,[],[],[],27,[],[],0
github/DeploymentStatus.py:DeploymentStatus:__repr__,DeploymentStatus:__repr__,method,2,5,5,67,13.4,0,0,['self'],[None],[None],32,[],['self.get__repr__'],1
github/DeploymentStatus.py:DeploymentStatus:created_at,DeploymentStatus:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],36,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:creator,DeploymentStatus:creator,method,3,3,3,63,21.0,0,0,['self'],[None],[None],44,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:deployment_url,DeploymentStatus:deployment_url,method,3,3,3,77,25.67,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:description,DeploymentStatus:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:environment,DeploymentStatus:environment,method,3,3,3,71,23.67,0,0,['self'],[None],[None],68,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:environment_url,DeploymentStatus:environment_url,method,3,3,3,79,26.33,0,0,['self'],[None],[None],76,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:repository_url,DeploymentStatus:repository_url,method,3,3,3,77,25.67,0,0,['self'],[None],[None],84,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:state,DeploymentStatus:state,method,3,3,3,59,19.67,0,0,['self'],[None],[None],92,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:target_url,DeploymentStatus:target_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],100,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:updated_at,DeploymentStatus:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],108,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:url,DeploymentStatus:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],116,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:id,DeploymentStatus:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],124,"['        """"""\n', '        :type: int\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:node_id,DeploymentStatus:node_id,method,3,3,3,63,21.0,0,0,['self'],[None],[None],132,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/DeploymentStatus.py:DeploymentStatus:_initAttributes,DeploymentStatus:_initAttributes,method,14,26,15,560,21.54,0,0,['self'],[None],[None],139,[],[],0
github/DeploymentStatus.py:DeploymentStatus:_useAttributes,DeploymentStatus:_useAttributes,method,17,139,50,1457,10.48,0,13,"['self', 'attributes']","[None, None]","[None, None]",154,[],"['self._makeStringAttribute', 'self._makeIntAttribute', 'self._makeDatetimeAttribute', 'self._makeClassAttribute']",4
github/Download.py:Download,Download,class,75,541,156,5753,10.63,0,20,[],[],[],34,[],[],0
github/Download.py:Download:__repr__,Download:__repr__,method,2,3,3,45,15.0,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/Download.py:Download:accesskeyid,Download:accesskeyid,method,3,3,3,71,23.67,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:acl,Download:acl,method,3,3,3,55,18.33,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:bucket,Download:bucket,method,3,3,3,61,20.33,0,0,['self'],[None],[None],59,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:content_type,Download:content_type,method,3,3,3,73,24.33,0,0,['self'],[None],[None],67,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:created_at,Download:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],75,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:description,Download:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],83,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:download_count,Download:download_count,method,3,3,3,77,25.67,0,0,['self'],[None],[None],91,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:expirationdate,Download:expirationdate,method,3,3,3,77,25.67,0,0,['self'],[None],[None],99,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:html_url,Download:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],107,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:id,Download:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],115,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:mime_type,Download:mime_type,method,3,3,3,67,22.33,0,0,['self'],[None],[None],123,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:name,Download:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],131,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:path,Download:path,method,3,3,3,57,19.0,0,0,['self'],[None],[None],139,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:policy,Download:policy,method,3,3,3,61,20.33,0,0,['self'],[None],[None],147,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:prefix,Download:prefix,method,3,3,3,61,20.33,0,0,['self'],[None],[None],155,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:redirect,Download:redirect,method,3,3,3,65,21.67,0,0,['self'],[None],[None],163,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:s3_url,Download:s3_url,method,3,3,3,61,20.33,0,0,['self'],[None],[None],171,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:signature,Download:signature,method,3,3,3,67,22.33,0,0,['self'],[None],[None],179,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:size,Download:size,method,3,3,3,57,19.0,0,0,['self'],[None],[None],187,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:url,Download:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],195,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Download.py:Download:delete,Download:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],202,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/downloads/{id} <https://docs.github.com/en/rest/reference/repos>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Download.py:Download:_initAttributes,Download:_initAttributes,method,21,40,22,829,20.73,0,0,['self'],[None],[None],209,[],[],0
github/Download.py:Download:_useAttributes,Download:_useAttributes,method,24,365,81,2841,7.78,0,20,"['self', 'attributes']","[None, None]","[None, None]",231,[],"['self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeBoolAttribute']",4
github/Event.py:Event,Event,class,35,157,64,1734,11.04,0,8,[],[],[],37,[],[],0
github/Event.py:Event:__repr__,Event:__repr__,method,2,5,5,69,13.8,0,0,['self'],[None],[None],42,[],['self.get__repr__'],1
github/Event.py:Event:actor,Event:actor,method,2,2,2,23,11.5,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/Event.py:Event:created_at,Event:created_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/Event.py:Event:id,Event:id,method,2,2,2,20,10.0,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Event.py:Event:org,Event:org,method,2,2,2,21,10.5,0,0,['self'],[None],[None],67,"['        """"""\n', '        :type: :class:`github.Organization.Organization`\n', '        """"""\n']",[],0
github/Event.py:Event:payload,Event:payload,method,2,2,2,25,12.5,0,0,['self'],[None],[None],74,"['        """"""\n', '        :type: dict\n', '        """"""\n']",[],0
github/Event.py:Event:public,Event:public,method,2,2,2,24,12.0,0,0,['self'],[None],[None],81,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/Event.py:Event:repo,Event:repo,method,2,2,2,22,11.0,0,0,['self'],[None],[None],88,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",[],0
github/Event.py:Event:type,Event:type,method,2,2,2,22,11.0,0,0,['self'],[None],[None],95,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Event.py:Event:_initAttributes,Event:_initAttributes,method,9,16,10,312,19.5,0,0,['self'],[None],[None],101,[],[],0
github/Event.py:Event:_useAttributes,Event:_useAttributes,method,13,89,36,868,9.75,0,8,"['self', 'attributes']","[None, None]","[None, None]",111,[],"['self._makeClassAttribute', 'self._makeDatetimeAttribute', 'self._makeStringAttribute', 'self._makeDictAttribute', 'self._makeBoolAttribute']",5
github/File.py:File,File,class,41,203,77,2417,11.91,0,11,[],[],[],36,[],[],0
github/File.py:File:__repr__,File:__repr__,method,2,7,7,81,11.57,0,0,['self'],[None],[None],41,[],['self.get__repr__'],1
github/File.py:File:additions,File:additions,method,2,2,2,27,13.5,0,0,['self'],[None],[None],47,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/File.py:File:blob_url,File:blob_url,method,2,2,2,26,13.0,0,0,['self'],[None],[None],54,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/File.py:File:changes,File:changes,method,2,2,2,25,12.5,0,0,['self'],[None],[None],61,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/File.py:File:contents_url,File:contents_url,method,2,2,2,30,15.0,0,0,['self'],[None],[None],68,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/File.py:File:deletions,File:deletions,method,2,2,2,27,13.5,0,0,['self'],[None],[None],75,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/File.py:File:filename,File:filename,method,2,2,2,26,13.0,0,0,['self'],[None],[None],82,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/File.py:File:patch,File:patch,method,2,2,2,23,11.5,0,0,['self'],[None],[None],89,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/File.py:File:previous_filename,File:previous_filename,method,2,2,2,35,17.5,0,0,['self'],[None],[None],96,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/File.py:File:raw_url,File:raw_url,method,2,2,2,25,12.5,0,0,['self'],[None],[None],103,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/File.py:File:sha,File:sha,method,2,2,2,21,10.5,0,0,['self'],[None],[None],110,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/File.py:File:status,File:status,method,2,2,2,24,12.0,0,0,['self'],[None],[None],117,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/File.py:File:_initAttributes,File:_initAttributes,method,12,22,13,464,21.09,0,0,['self'],[None],[None],123,[],[],0
github/File.py:File:_useAttributes,File:_useAttributes,method,13,112,42,1167,10.42,0,11,"['self', 'attributes']","[None, None]","[None, None]",136,[],"['self._makeIntAttribute', 'self._makeStringAttribute']",2
github/Gist.py:Gist,Gist,class,103,534,231,6752,12.64,2,22,[],[],[],42,[],[],0
github/Gist.py:Gist:__repr__,Gist:__repr__,method,2,3,3,45,15.0,0,0,['self'],[None],[None],47,[],['self.get__repr__'],1
github/Gist.py:Gist:comments,Gist:comments,method,3,3,3,65,21.67,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:comments_url,Gist:comments_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],59,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:commits_url,Gist:commits_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],67,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:created_at,Gist:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],75,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:description,Gist:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],83,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:files,Gist:files,method,3,3,3,48,16.0,0,0,['self'],[None],[None],91,"['        """"""\n', '        :type: dict of string to :class:`github.GistFile.GistFile`\n', '        """"""\n']",['self._completeIfNeeded'],1
github/Gist.py:Gist:fork_of,Gist:fork_of,method,3,3,3,63,21.0,0,0,['self'],[None],[None],99,"['        """"""\n', '        :type: :class:`github.Gist.Gist`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:forks,Gist:forks,method,3,3,3,59,19.67,0,0,['self'],[None],[None],107,"['        """"""\n', '        :type: list of :class:`github.Gist.Gist`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:forks_url,Gist:forks_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],115,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:git_pull_url,Gist:git_pull_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],123,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:git_push_url,Gist:git_push_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],131,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:history,Gist:history,method,3,3,3,63,21.0,0,0,['self'],[None],[None],139,"['        """"""\n', '        :type: list of :class:`github.GistHistoryState.GistHistoryState`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:html_url,Gist:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],147,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:id,Gist:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],155,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:owner,Gist:owner,method,3,3,3,59,19.67,0,0,['self'],[None],[None],163,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:public,Gist:public,method,3,3,3,61,20.33,0,0,['self'],[None],[None],171,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:updated_at,Gist:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],179,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:url,Gist:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],187,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:user,Gist:user,method,3,3,3,57,19.0,0,0,['self'],[None],[None],195,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Gist.py:Gist:create_comment,Gist:create_comment,method,7,23,22,252,10.96,0,0,"['self', 'body']","[None, None]","[None, None]",202,"['        """"""\n', '        :calls: `POST /gists/{gist_id}/comments <http://docs.github.com/en/rest/reference/gists#comments>`_\n', '        :param body: string\n', '        :rtype: :class:`github.GistComment.GistComment`\n', '        """"""\n']",['isinstance'],1
github/Gist.py:Gist:create_fork,Gist:create_fork,method,5,9,8,132,14.67,0,0,['self'],[None],[None],219,"['        """"""\n', '        :calls: `POST /gists/{id}/forks <http://docs.github.com/en/rest/reference/gists>`_\n', '        :rtype: :class:`github.Gist.Gist`\n', '        """"""\n']",['Gist'],1
github/Gist.py:Gist:delete,Gist:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],227,"['        """"""\n', '        :calls: `DELETE /gists/{id} <http://docs.github.com/en/rest/reference/gists>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Gist.py:Gist:edit,Gist:edit,method,19,66,43,595,9.02,2,3,"['self', 'description', 'files']","[None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet']",234,"['        """"""\n', '        :calls: `PATCH /gists/{id} <http://docs.github.com/en/rest/reference/gists>`_\n', '        :param description: string\n', '        :param files: dict of string to :class:`github.InputFileContent.InputFileContent`\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'all', 'files.values', 'dict', 'files.items', 'self._useAttributes']",6
github/Gist.py:Gist:get_comment,Gist:get_comment,method,8,26,23,343,13.19,0,0,"['self', 'id']","[None, None]","[None, None]",263,"['        """"""\n', '        :calls: `GET /gists/{gist_id}/comments/{id} <http://docs.github.com/en/rest/reference/gists#comments>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.GistComment.GistComment`\n', '        """"""\n']","['isinstance', 'get_comments']",2
github/Gist.py:Gist:get_comments,Gist:get_comments,method,2,7,7,122,17.43,0,0,['self'],[None],[None],277,"['        """"""\n', '        :calls: `GET /gists/{gist_id}/comments <http://docs.github.com/en/rest/reference/gists#comments>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.GistComment.GistComment`\n', '        """"""\n']",[],0
github/Gist.py:Gist:is_starred,Gist:is_starred,method,6,8,8,91,11.38,0,0,['self'],[None],[None],289,"['        """"""\n', '        :calls: `GET /gists/{id}/star <http://docs.github.com/en/rest/reference/gists>`_\n', '        :rtype: bool\n', '        """"""\n']",[],0
github/Gist.py:Gist:reset_starred,Gist:reset_starred,method,3,6,6,79,13.17,0,0,['self'],[None],[None],297,"['        """"""\n', '        :calls: `DELETE /gists/{id}/star <http://docs.github.com/en/rest/reference/gists>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Gist.py:Gist:set_starred,Gist:set_starred,method,3,4,4,74,18.5,0,0,['self'],[None],[None],306,"['        """"""\n', '        :calls: `PUT /gists/{id}/star <http://docs.github.com/en/rest/reference/gists>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Gist.py:Gist:_initAttributes,Gist:_initAttributes,method,20,38,21,792,20.84,0,0,['self'],[None],[None],313,[],[],0
github/Gist.py:Gist:_useAttributes,Gist:_useAttributes,method,26,204,74,2162,10.6,0,19,"['self', 'attributes']","[None, None]","[None, None]",334,[],"['self._makeIntAttribute', 'self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeDictOfStringsToClassesAttribute', 'self._makeClassAttribute', 'self._makeListOfClassesAttribute', 'self._makeBoolAttribute']",7
github/GistComment.py:GistComment,GistComment,class,37,149,80,1819,12.21,0,6,[],[],[],35,[],[],0
github/GistComment.py:GistComment:__repr__,GistComment:__repr__,method,2,5,5,69,13.8,0,0,['self'],[None],[None],40,[],['self.get__repr__'],1
github/GistComment.py:GistComment:body,GistComment:body,method,3,3,3,57,19.0,0,0,['self'],[None],[None],44,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistComment.py:GistComment:created_at,GistComment:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistComment.py:GistComment:id,GistComment:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistComment.py:GistComment:updated_at,GistComment:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],68,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistComment.py:GistComment:url,GistComment:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],76,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistComment.py:GistComment:user,GistComment:user,method,3,3,3,57,19.0,0,0,['self'],[None],[None],84,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistComment.py:GistComment:delete,GistComment:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],91,"['        """"""\n', '        :calls: `DELETE /gists/{gist_id}/comments/{id} <http://docs.github.com/en/rest/reference/gists#comments>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/GistComment.py:GistComment:edit,GistComment:edit,method,6,17,17,181,10.65,0,0,"['self', 'body']","[None, None]","[None, None]",98,"['        """"""\n', '        :calls: `PATCH /gists/{gist_id}/comments/{id} <http://docs.github.com/en/rest/reference/gists#comments>`_\n', '        :param body: string\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'self._useAttributes']",2
github/GistComment.py:GistComment:_initAttributes,GistComment:_initAttributes,method,7,12,8,236,19.67,0,0,['self'],[None],[None],113,[],[],0
github/GistComment.py:GistComment:_useAttributes,GistComment:_useAttributes,method,10,63,28,619,9.83,0,6,"['self', 'attributes']","[None, None]","[None, None]",121,[],"['self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeClassAttribute']",4
github/GistFile.py:GistFile,GistFile,class,26,112,47,1299,11.6,0,6,[],[],[],34,[],[],0
github/GistFile.py:GistFile:__repr__,GistFile:__repr__,method,2,3,3,57,19.0,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/GistFile.py:GistFile:content,GistFile:content,method,2,2,2,25,12.5,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GistFile.py:GistFile:filename,GistFile:filename,method,2,2,2,26,13.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GistFile.py:GistFile:language,GistFile:language,method,2,2,2,26,13.0,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GistFile.py:GistFile:raw_url,GistFile:raw_url,method,2,2,2,25,12.5,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GistFile.py:GistFile:size,GistFile:size,method,2,2,2,22,11.0,0,0,['self'],[None],[None],71,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/GistFile.py:GistFile:type,GistFile:type,method,2,2,2,22,11.0,0,0,['self'],[None],[None],78,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GistFile.py:GistFile:_initAttributes,GistFile:_initAttributes,method,7,12,8,241,20.08,0,0,['self'],[None],[None],84,[],[],0
github/GistFile.py:GistFile:_useAttributes,GistFile:_useAttributes,method,8,60,25,602,10.03,0,6,"['self', 'attributes']","[None, None]","[None, None]",92,[],"['self._makeStringAttribute', 'self._makeIntAttribute']",2
github/GistHistoryState.py:GistHistoryState,GistHistoryState,class,75,401,149,5376,13.41,0,21,[],[],[],36,[],[],0
github/GistHistoryState.py:GistHistoryState:change_status,GistHistoryState:change_status,method,3,3,3,75,25.0,0,0,['self'],[None],[None],42,"['        """"""\n', '        :type: :class:`github.CommitStats.CommitStats`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:comments,GistHistoryState:comments,method,3,3,3,65,21.67,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:comments_url,GistHistoryState:comments_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],58,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:commits_url,GistHistoryState:commits_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],66,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:committed_at,GistHistoryState:committed_at,method,3,3,3,73,24.33,0,0,['self'],[None],[None],74,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:created_at,GistHistoryState:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],82,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:description,GistHistoryState:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],90,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:files,GistHistoryState:files,method,3,3,3,59,19.67,0,0,['self'],[None],[None],98,"['        """"""\n', '        :type: dict of string to :class:`github.GistFile.GistFile`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:forks,GistHistoryState:forks,method,3,3,3,59,19.67,0,0,['self'],[None],[None],106,"['        """"""\n', '        :type: list of :class:`github.Gist.Gist`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:forks_url,GistHistoryState:forks_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],114,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:git_pull_url,GistHistoryState:git_pull_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],122,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:git_push_url,GistHistoryState:git_push_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],130,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:history,GistHistoryState:history,method,3,3,3,63,21.0,0,0,['self'],[None],[None],138,"['        """"""\n', '        :type: list of :class:`GistHistoryState`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:html_url,GistHistoryState:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],146,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:id,GistHistoryState:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],154,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:owner,GistHistoryState:owner,method,3,3,3,59,19.67,0,0,['self'],[None],[None],162,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:public,GistHistoryState:public,method,3,3,3,61,20.33,0,0,['self'],[None],[None],170,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:updated_at,GistHistoryState:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],178,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:url,GistHistoryState:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],186,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:user,GistHistoryState:user,method,3,3,3,57,19.0,0,0,['self'],[None],[None],194,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:version,GistHistoryState:version,method,3,3,3,63,21.0,0,0,['self'],[None],[None],202,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GistHistoryState.py:GistHistoryState:_initAttributes,GistHistoryState:_initAttributes,method,22,42,23,885,21.07,0,0,['self'],[None],[None],209,[],[],0
github/GistHistoryState.py:GistHistoryState:_useAttributes,GistHistoryState:_useAttributes,method,28,228,79,2421,10.62,0,21,"['self', 'attributes']","[None, None]","[None, None]",232,[],"['self._makeClassAttribute', 'self._makeIntAttribute', 'self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeDictOfStringsToClassesAttribute', 'self._makeListOfClassesAttribute', 'self._makeBoolAttribute']",7
github/GitAuthor.py:GitAuthor,GitAuthor,class,17,61,32,678,11.11,0,3,[],[],[],34,[],[],0
github/GitAuthor.py:GitAuthor:__repr__,GitAuthor:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/GitAuthor.py:GitAuthor:date,GitAuthor:date,method,2,2,2,22,11.0,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/GitAuthor.py:GitAuthor:email,GitAuthor:email,method,2,2,2,23,11.5,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitAuthor.py:GitAuthor:name,GitAuthor:name,method,2,2,2,22,11.0,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitAuthor.py:GitAuthor:_initAttributes,GitAuthor:_initAttributes,method,4,6,5,114,19.0,0,0,['self'],[None],[None],63,[],[],0
github/GitAuthor.py:GitAuthor:_useAttributes,GitAuthor:_useAttributes,method,5,30,16,286,9.53,0,3,"['self', 'attributes']","[None, None]","[None, None]",68,[],"['self._makeDatetimeAttribute', 'self._makeStringAttribute']",2
github/GitBlob.py:GitBlob,GitBlob,class,24,100,47,1235,12.35,0,5,[],[],[],34,[],[],0
github/GitBlob.py:GitBlob:__repr__,GitBlob:__repr__,method,2,3,3,47,15.67,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/GitBlob.py:GitBlob:content,GitBlob:content,method,3,3,3,63,21.0,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitBlob.py:GitBlob:encoding,GitBlob:encoding,method,3,3,3,65,21.67,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitBlob.py:GitBlob:sha,GitBlob:sha,method,3,3,3,55,18.33,0,0,['self'],[None],[None],59,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitBlob.py:GitBlob:size,GitBlob:size,method,3,3,3,57,19.0,0,0,['self'],[None],[None],67,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitBlob.py:GitBlob:url,GitBlob:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],75,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitBlob.py:GitBlob:_initAttributes,GitBlob:_initAttributes,method,6,10,7,194,19.4,0,0,['self'],[None],[None],82,[],[],0
github/GitBlob.py:GitBlob:_useAttributes,GitBlob:_useAttributes,method,7,50,22,481,9.62,0,5,"['self', 'attributes']","[None, None]","[None, None]",89,[],"['self._makeStringAttribute', 'self._makeIntAttribute']",2
github/GitCommit.py:GitCommit,GitCommit,class,36,171,73,2097,12.26,0,8,[],[],[],36,[],[],0
github/GitCommit.py:GitCommit:__repr__,GitCommit:__repr__,method,2,3,3,47,15.67,0,0,['self'],[None],[None],41,[],['self.get__repr__'],1
github/GitCommit.py:GitCommit:author,GitCommit:author,method,3,3,3,61,20.33,0,0,['self'],[None],[None],45,"['        """"""\n', '        :type: :class:`github.GitAuthor.GitAuthor`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitCommit.py:GitCommit:committer,GitCommit:committer,method,3,3,3,67,22.33,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: :class:`github.GitAuthor.GitAuthor`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitCommit.py:GitCommit:html_url,GitCommit:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],61,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitCommit.py:GitCommit:message,GitCommit:message,method,3,3,3,63,21.0,0,0,['self'],[None],[None],69,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitCommit.py:GitCommit:parents,GitCommit:parents,method,3,3,3,63,21.0,0,0,['self'],[None],[None],77,"['        """"""\n', '        :type: list of :class:`github.GitCommit.GitCommit`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitCommit.py:GitCommit:sha,GitCommit:sha,method,3,3,3,55,18.33,0,0,['self'],[None],[None],85,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitCommit.py:GitCommit:tree,GitCommit:tree,method,3,3,3,57,19.0,0,0,['self'],[None],[None],93,"['        """"""\n', '        :type: :class:`github.GitTree.GitTree`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitCommit.py:GitCommit:url,GitCommit:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],101,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitCommit.py:GitCommit:_identity,GitCommit:_identity,method,2,2,2,14,7.0,0,0,['self'],[None],[None],109,[],[],0
github/GitCommit.py:GitCommit:_initAttributes,GitCommit:_initAttributes,method,9,16,10,318,19.88,0,0,['self'],[None],[None],112,[],[],0
github/GitCommit.py:GitCommit:_useAttributes,GitCommit:_useAttributes,method,11,92,37,895,9.73,0,8,"['self', 'attributes']","[None, None]","[None, None]",122,[],"['self._makeClassAttribute', 'self._makeStringAttribute', 'self._makeListOfClassesAttribute']",3
github/GithubApp.py:GithubApp,GithubApp,class,49,227,94,3011,13.26,0,12,[],[],[],27,[],[],0
github/GithubApp.py:GithubApp:__repr__,GithubApp:__repr__,method,2,5,5,67,13.4,0,0,['self'],[None],[None],32,[],['self.get__repr__'],1
github/GithubApp.py:GithubApp:created_at,GithubApp:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],36,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GithubApp.py:GithubApp:description,GithubApp:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],44,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GithubApp.py:GithubApp:events,GithubApp:events,method,3,3,3,61,20.33,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: list of string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GithubApp.py:GithubApp:external_url,GithubApp:external_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GithubApp.py:GithubApp:html_url,GithubApp:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],68,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GithubApp.py:GithubApp:id,GithubApp:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],76,"['        """"""\n', '        :type: int\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GithubApp.py:GithubApp:name,GithubApp:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],84,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GithubApp.py:GithubApp:owner,GithubApp:owner,method,3,3,3,59,19.67,0,0,['self'],[None],[None],92,"['        """"""\n', '        :type: :class:`Github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GithubApp.py:GithubApp:permissions,GithubApp:permissions,method,3,3,3,71,23.67,0,0,['self'],[None],[None],100,"['        """"""\n', '        :type: dict\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GithubApp.py:GithubApp:slug,GithubApp:slug,method,2,2,2,22,11.0,0,0,['self'],[None],[None],108,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GithubApp.py:GithubApp:updated_at,GithubApp:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],115,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GithubApp.py:GithubApp:url,GithubApp:url,method,2,2,2,21,10.5,0,0,['self'],[None],[None],123,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GithubApp.py:GithubApp:_initAttributes,GithubApp:_initAttributes,method,13,24,14,493,20.54,0,0,['self'],[None],[None],129,[],[],0
github/GithubApp.py:GithubApp:_useAttributes,GithubApp:_useAttributes,method,18,121,48,1327,10.97,0,12,"['self', 'attributes']","[None, None]","[None, None]",143,[],"['self._makeDatetimeAttribute', 'self._makeStringAttribute', 'self._makeListOfStringsAttribute', 'self._makeIntAttribute', 'self._makeClassAttribute', 'self._makeDictAttribute']",6
github/GithubException.py:GithubException,GithubException,class,13,37,27,384,10.38,0,0,[],[],[],34,[],[],0
github/GithubException.py:BadCredentialsException,BadCredentialsException,class,0,0,0,0,0.0,0,0,[],[],[],73,[],[],0
github/GithubException.py:UnknownObjectException,UnknownObjectException,class,0,0,0,0,0.0,0,0,[],[],[],79,[],[],0
github/GithubException.py:BadUserAgentException,BadUserAgentException,class,0,0,0,0,0.0,0,0,[],[],[],85,[],[],0
github/GithubException.py:RateLimitExceededException,RateLimitExceededException,class,0,0,0,0,0.0,0,0,[],[],[],91,[],[],0
github/GithubException.py:BadAttributeException,BadAttributeException,class,11,26,18,386,14.85,0,0,[],[],[],97,[],[],0
github/GithubException.py:TwoFactorException,TwoFactorException,class,0,0,0,0,0.0,0,0,[],[],[],129,[],[],0
github/GithubException.py:IncompletableObject,IncompletableObject,class,0,0,0,0,0.0,0,0,[],[],[],135,[],[],0
github/GithubException.py:GithubException:__init__,GithubException:__init__,method,10,11,11,111,10.09,0,0,"['self', 'status', 'data', 'headers']","[None, None, None, None]","[None, None, None, None]",41,[],['super'],1
github/GithubException.py:GithubException:status,GithubException:status,method,2,2,2,19,9.5,0,0,['self'],[None],[None],49,"['        """"""\n', '        The status returned by the Github API\n', '        """"""\n']",[],0
github/GithubException.py:GithubException:data,GithubException:data,method,2,2,2,17,8.5,0,0,['self'],[None],[None],56,"['        """"""\n', '        The (decoded) data returned by the Github API\n', '        """"""\n']",[],0
github/GithubException.py:GithubException:headers,GithubException:headers,method,2,2,2,20,10.0,0,0,['self'],[None],[None],63,"['        """"""\n', '        The headers returned by the Github API\n', '        """"""\n']",[],0
github/GithubException.py:GithubException:__str__,GithubException:__str__,method,1,4,4,76,19.0,0,0,['self'],[None],[None],69,[],[],0
github/GithubException.py:BadAttributeException:__init__,BadAttributeException:__init__,method,6,6,6,118,19.67,0,0,"['self', 'actualValue', 'expectedType', 'transformationException']","[None, None, None, None]","[None, None, None, None]",102,[],[],0
github/GithubException.py:BadAttributeException:actual_value,BadAttributeException:actual_value,method,2,2,2,24,12.0,0,0,['self'],[None],[None],108,"['        """"""\n', '        The value returned by Github\n', '        """"""\n']",[],0
github/GithubException.py:BadAttributeException:expected_type,BadAttributeException:expected_type,method,2,2,2,25,12.5,0,0,['self'],[None],[None],115,"['        """"""\n', '        The type PyGithub expected\n', '        """"""\n']",[],0
github/GithubException.py:BadAttributeException:transformation_exception,BadAttributeException:transformation_exception,method,2,2,2,36,18.0,0,0,['self'],[None],[None],122,"['        """"""\n', '        The exception raised when PyGithub tried to parse the value\n', '        """"""\n']",[],0
github/GithubObject.py:_NotSetType,_NotSetType,class,3,6,6,44,7.33,0,0,[],[],[],39,[],[],0
github/GithubObject.py:_ValuedAttribute,_ValuedAttribute,class,3,5,5,41,8.2,0,0,[],[],[],49,[],[],0
github/GithubObject.py:_BadAttribute,_BadAttribute,class,8,20,19,253,12.65,0,0,[],[],[],54,[],[],0
github/GithubObject.py:GithubObject,GithubObject,class,70,383,192,4269,11.15,4,10,[],[],[],67,[],[],0
github/GithubObject.py:NonCompletableGithubObject,NonCompletableGithubObject,class,1,3,3,32,10.67,0,0,[],[],[],276,[],[],0
github/GithubObject.py:CompletableGithubObject,CompletableGithubObject,class,41,123,79,1387,11.28,0,7,[],[],[],281,[],[],0
github/GithubObject.py:_NotSetType:__repr__,_NotSetType:__repr__,method,1,2,2,14,7.0,0,0,['self'],[None],[None],40,[],[],0
github/GithubObject.py:_ValuedAttribute:__init__,_ValuedAttribute:__init__,method,2,2,2,16,8.0,0,0,"['self', 'value']","[None, None]","[None, None]",50,[],[],0
github/GithubObject.py:_BadAttribute:__init__,_BadAttribute:__init__,method,6,6,6,78,13.0,0,0,"['self', 'value', 'expectedType', 'exception']","[None, None, None, None]","[None, None, None, 'None']",55,[],[],0
github/GithubObject.py:_BadAttribute:value,_BadAttribute:value,method,1,6,6,95,15.83,0,0,['self'],[None],[None],61,[],['GithubException.BadAttributeException'],1
github/GithubObject.py:GithubObject:setCheckAfterInitFlag,GithubObject:setCheckAfterInitFlag,method,2,2,2,30,15.0,0,0,"['cls', 'flag']","[None, None]","[None, None]",78,[],[],0
github/GithubObject.py:GithubObject:__init__,GithubObject:__init__,method,9,17,17,188,11.06,0,1,"['self', 'requester', 'headers', 'attributes', 'completed']","[None, None, None, None, None]","[None, None, None, None, None]",81,[],"['self._initAttributes', 'self._storeAndUseAttributes', 'requester.check_me']",3
github/GithubObject.py:GithubObject:_storeAndUseAttributes,GithubObject:_storeAndUseAttributes,method,5,5,5,78,15.6,0,0,"['self', 'headers', 'attributes']","[None, None, None]","[None, None, None]",91,[],['self._useAttributes'],1
github/GithubObject.py:GithubObject:raw_data,GithubObject:raw_data,method,3,3,3,44,14.67,0,0,['self'],[None],[None],99,"['        """"""\n', '        :type: dict\n', '        """"""\n']",['self._completeIfNeeded'],1
github/GithubObject.py:GithubObject:raw_headers,GithubObject:raw_headers,method,3,3,3,44,14.67,0,0,['self'],[None],[None],107,"['        """"""\n', '        :type: dict\n', '        """"""\n']",['self._completeIfNeeded'],1
github/GithubObject.py:GithubObject:_parentUrl,GithubObject:_parentUrl,method,1,2,2,35,17.5,0,0,['url'],[None],[None],115,[],[],0
github/GithubObject.py:GithubObject:__makeSimpleAttribute,GithubObject:__makeSimpleAttribute,method,6,13,12,106,8.15,0,1,"['value', 'type']","[None, None]","[None, None]",119,[],"['isinstance', '_ValuedAttribute', '_BadAttribute']",3
github/GithubObject.py:GithubObject:__makeSimpleListAttribute,GithubObject:__makeSimpleListAttribute,method,4,18,17,146,8.11,0,1,"['value', 'type']","[None, None]","[None, None]",126,[],"['isinstance', 'all', '_ValuedAttribute', '_BadAttribute']",4
github/GithubObject.py:GithubObject:__makeTransformedAttribute,GithubObject:__makeTransformedAttribute,method,5,24,20,209,8.71,0,1,"['value', 'type', 'transform']","[None, None, None]","[None, None, None]",135,[],"['_ValuedAttribute', 'isinstance', '_BadAttribute']",3
github/GithubObject.py:GithubObject:_makeStringAttribute,GithubObject:_makeStringAttribute,method,2,3,3,51,17.0,0,0,['value'],[None],[None],147,[],['GithubObject.__makeSimpleAttribute'],1
github/GithubObject.py:GithubObject:_makeIntAttribute,GithubObject:_makeIntAttribute,method,2,3,3,51,17.0,0,0,['value'],[None],[None],151,[],['GithubObject.__makeSimpleAttribute'],1
github/GithubObject.py:GithubObject:_makeFloatAttribute,GithubObject:_makeFloatAttribute,method,2,3,3,53,17.67,0,0,['value'],[None],[None],155,[],['GithubObject.__makeSimpleAttribute'],1
github/GithubObject.py:GithubObject:_makeBoolAttribute,GithubObject:_makeBoolAttribute,method,2,3,3,52,17.33,0,0,['value'],[None],[None],159,[],['GithubObject.__makeSimpleAttribute'],1
github/GithubObject.py:GithubObject:_makeDictAttribute,GithubObject:_makeDictAttribute,method,2,3,3,52,17.33,0,0,['value'],[None],[None],163,[],['GithubObject.__makeSimpleAttribute'],1
github/GithubObject.py:GithubObject:_makeTimestampAttribute,GithubObject:_makeTimestampAttribute,method,2,6,6,93,15.5,0,0,['value'],[None],[None],167,[],['GithubObject.__makeTransformedAttribute'],1
github/GithubObject.py:GithubObject:_makeDatetimeAttribute,GithubObject:_makeDatetimeAttribute,method,9,62,42,515,8.31,0,2,['value'],[None],[None],173,[],"['parseDatetime', 'len', 'datetime.timedelta', 'minutes=int', 'GithubObject.__makeTransformedAttribute']",5
github/GithubObject.py:GithubObject:_makeClassAttribute,GithubObject:_makeClassAttribute,method,2,11,11,133,12.09,0,0,"['self', 'klass', 'value']","[None, None, None]","[None, None, None]",192,[],"['GithubObject.__makeTransformedAttribute', 'klass']",2
github/GithubObject.py:GithubObject:_makeListOfStringsAttribute,GithubObject:_makeListOfStringsAttribute,method,2,3,3,55,18.33,0,0,['value'],[None],[None],200,[],['GithubObject.__makeSimpleListAttribute'],1
github/GithubObject.py:GithubObject:_makeListOfIntsAttribute,GithubObject:_makeListOfIntsAttribute,method,2,3,3,55,18.33,0,0,['value'],[None],[None],204,[],['GithubObject.__makeSimpleListAttribute'],1
github/GithubObject.py:GithubObject:_makeListOfDictsAttribute,GithubObject:_makeListOfDictsAttribute,method,2,3,3,56,18.67,0,0,['value'],[None],[None],208,[],['GithubObject.__makeSimpleListAttribute'],1
github/GithubObject.py:GithubObject:_makeListOfListOfStringsAttribute,GithubObject:_makeListOfListOfStringsAttribute,method,2,3,3,56,18.67,0,0,['value'],[None],[None],212,[],['GithubObject.__makeSimpleListAttribute'],1
github/GithubObject.py:GithubObject:_makeListOfClassesAttribute,GithubObject:_makeListOfClassesAttribute,method,6,29,24,225,7.76,1,1,"['self', 'klass', 'value']","[None, None, None]","[None, None, None]",215,[],"['isinstance', 'all', '_ValuedAttribute', 'klass', '_BadAttribute']",5
github/GithubObject.py:GithubObject:_makeDictOfStringsToClassesAttribute,GithubObject:_makeDictOfStringsToClassesAttribute,method,7,36,29,280,7.78,2,1,"['self', 'klass', 'value']","[None, None, None]","[None, None, None]",228,[],"['isinstance', 'all', 'value.items', '_ValuedAttribute', 'klass', '_BadAttribute']",6
github/GithubObject.py:GithubObject:etag,GithubObject:etag,method,2,2,2,40,20.0,0,0,['self'],[None],[None],243,"['        """"""\n', '        :type: str\n', '        """"""\n']",[],0
github/GithubObject.py:GithubObject:last_modified,GithubObject:last_modified,method,2,2,2,49,24.5,0,0,['self'],[None],[None],250,"['        """"""\n', '        :type: str\n', '        """"""\n']",[],0
github/GithubObject.py:GithubObject:get__repr__,GithubObject:get__repr__,method,11,29,25,320,11.03,1,2,"['self', 'params']","[None, None]","[None, None]",256,"['        """"""\n', '        Converts the object to a nicely printable string.\n', '        """"""\n']","['format_params', 'list', 'sorted', 'key=itemgetter', 'isinstance', 'v.decode']",6
github/GithubObject.py:NonCompletableGithubObject:_completeIfNeeded,NonCompletableGithubObject:_completeIfNeeded,method,0,1,1,4,4.0,0,0,['self'],[None],[None],277,[],[],0
github/GithubObject.py:CompletableGithubObject:__init__,CompletableGithubObject:__init__,method,3,6,6,83,13.83,0,0,"['self', 'requester', 'headers', 'attributes', 'completed']","[None, None, None, None, None]","[None, None, None, None, None]",81,"['        """"""\n', '        :type: dict\n', '        """"""\n']",['super'],1
github/GithubObject.py:CompletableGithubObject:__eq__,CompletableGithubObject:__eq__,method,6,7,7,73,10.43,0,0,"['self', 'other']","[None, None]","[None, None]",286,[],[],0
github/GithubObject.py:CompletableGithubObject:__hash__,CompletableGithubObject:__hash__,method,2,2,2,27,13.5,0,0,['self'],[None],[None],289,[],['hash'],1
github/GithubObject.py:CompletableGithubObject:__ne__,CompletableGithubObject:__ne__,method,2,4,4,20,5.0,0,0,"['self', 'other']","[None, None]","[None, None]",292,[],[],0
github/GithubObject.py:CompletableGithubObject:_completeIfNotSet,CompletableGithubObject:_completeIfNotSet,method,3,5,5,41,8.2,0,1,"['self', 'value']","[None, None]","[None, None]",295,[],['self._completeIfNeeded'],1
github/GithubObject.py:CompletableGithubObject:_completeIfNeeded,CompletableGithubObject:_completeIfNeeded,method,2,4,4,40,10.0,0,1,['self'],[None],[None],277,[],['self.__complete'],1
github/GithubObject.py:CompletableGithubObject:__complete,CompletableGithubObject:__complete,method,7,22,22,243,11.05,0,1,['self'],[None],[None],303,[],"['GithubException.IncompletableObject', 'self._storeAndUseAttributes']",2
github/GithubObject.py:CompletableGithubObject:update,CompletableGithubObject:update,method,18,49,36,606,12.37,0,4,"['self', 'additional_headers']","[None, None]","[None, 'None']",312,"['        """"""\n', '        Check and update the object with conditional request\n', '        :rtype: Boolean value indicating whether the object is changed\n', '        """"""\n']","['dict', 'conditionalRequestHeader.update', 'self._storeAndUseAttributes']",3
github/GitignoreTemplate.py:GitignoreTemplate,GitignoreTemplate,class,13,44,27,502,11.41,0,2,[],[],[],33,[],[],0
github/GitignoreTemplate.py:GitignoreTemplate:__repr__,GitignoreTemplate:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],38,[],['self.get__repr__'],1
github/GitignoreTemplate.py:GitignoreTemplate:source,GitignoreTemplate:source,method,2,2,2,24,12.0,0,0,['self'],[None],[None],42,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitignoreTemplate.py:GitignoreTemplate:name,GitignoreTemplate:name,method,2,2,2,22,11.0,0,0,['self'],[None],[None],49,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitignoreTemplate.py:GitignoreTemplate:_initAttributes,GitignoreTemplate:_initAttributes,method,3,4,4,77,19.25,0,0,['self'],[None],[None],55,[],[],0
github/GitignoreTemplate.py:GitignoreTemplate:_useAttributes,GitignoreTemplate:_useAttributes,method,3,20,13,193,9.65,0,2,"['self', 'attributes']","[None, None]","[None, None]",59,[],['self._makeStringAttribute'],1
github/GitObject.py:GitObject,GitObject,class,16,61,32,656,10.75,0,3,[],[],[],34,[],[],0
github/GitObject.py:GitObject:__repr__,GitObject:__repr__,method,2,3,3,47,15.67,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/GitObject.py:GitObject:sha,GitObject:sha,method,2,2,2,21,10.5,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitObject.py:GitObject:type,GitObject:type,method,2,2,2,22,11.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitObject.py:GitObject:url,GitObject:url,method,2,2,2,21,10.5,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitObject.py:GitObject:_initAttributes,GitObject:_initAttributes,method,4,6,5,111,18.5,0,0,['self'],[None],[None],63,[],[],0
github/GitObject.py:GitObject:_useAttributes,GitObject:_useAttributes,method,4,30,16,275,9.17,0,3,"['self', 'attributes']","[None, None]","[None, None]",68,[],['self._makeStringAttribute'],1
github/GitRef.py:GitRef,GitRef,class,29,109,70,1257,11.53,0,4,[],[],[],35,[],[],0
github/GitRef.py:GitRef:__repr__,GitRef:__repr__,method,2,3,3,47,15.67,0,0,['self'],[None],[None],40,[],['self.get__repr__'],1
github/GitRef.py:GitRef:object,GitRef:object,method,3,3,3,61,20.33,0,0,['self'],[None],[None],44,"['        """"""\n', '        :type: :class:`github.GitObject.GitObject`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRef.py:GitRef:ref,GitRef:ref,method,3,3,3,55,18.33,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRef.py:GitRef:url,GitRef:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRef.py:GitRef:delete,GitRef:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],67,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/git/refs/{ref} <http://docs.github.com/en/rest/reference/git#refs>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/GitRef.py:GitRef:edit,GitRef:edit,method,10,32,28,318,9.94,0,1,"['self', 'sha', 'force']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",74,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/git/refs/{ref} <http://docs.github.com/en/rest/reference/git#refs>`_\n', '        :param sha: string\n', '        :param force: bool\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'self._useAttributes']",2
github/GitRef.py:GitRef:_initAttributes,GitRef:_initAttributes,method,4,6,5,113,18.83,0,0,['self'],[None],[None],93,[],[],0
github/GitRef.py:GitRef:_useAttributes,GitRef:_useAttributes,method,5,33,19,309,9.36,0,3,"['self', 'attributes']","[None, None]","[None, None]",98,[],"['self._makeClassAttribute', 'self._makeStringAttribute']",2
github/GitRelease.py:GitRelease,GitRelease,class,88,455,224,6264,13.77,0,19,[],[],[],45,[],[],0
github/GitRelease.py:GitRelease:__repr__,GitRelease:__repr__,method,2,3,3,51,17.0,0,0,['self'],[None],[None],50,[],['self.get__repr__'],1
github/GitRelease.py:GitRelease:id,GitRelease:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],54,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:body,GitRelease:body,method,3,3,3,57,19.0,0,0,['self'],[None],[None],62,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:title,GitRelease:title,method,3,3,3,59,19.67,0,0,['self'],[None],[None],70,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:tag_name,GitRelease:tag_name,method,3,3,3,65,21.67,0,0,['self'],[None],[None],78,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:target_commitish,GitRelease:target_commitish,method,3,3,3,81,27.0,0,0,['self'],[None],[None],86,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:draft,GitRelease:draft,method,3,3,3,59,19.67,0,0,['self'],[None],[None],94,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:prerelease,GitRelease:prerelease,method,3,3,3,69,23.0,0,0,['self'],[None],[None],102,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:author,GitRelease:author,method,3,3,3,61,20.33,0,0,['self'],[None],[None],110,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:created_at,GitRelease:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],118,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:published_at,GitRelease:published_at,method,3,3,3,73,24.33,0,0,['self'],[None],[None],126,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:url,GitRelease:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],134,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:upload_url,GitRelease:upload_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],142,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:html_url,GitRelease:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],150,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:tarball_url,GitRelease:tarball_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],158,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:zipball_url,GitRelease:zipball_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],166,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitRelease.py:GitRelease:delete_release,GitRelease:delete_release,method,3,4,4,67,16.75,0,0,['self'],[None],[None],173,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/releases/{release_id} <https://docs.github.com/en/rest/reference/repos/releases#delete-a-release>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/GitRelease.py:GitRelease:update_release,GitRelease:update_release,method,13,86,60,835,9.71,0,2,"['self', 'name', 'message', 'draft', 'prerelease', 'tag_name', 'target_commitish', '']","[None, None, None, None, None, None, None, None]","[None, None, None, 'False', 'False', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",180,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/releases/{release_id} <https://docs.github.com/en/rest/reference/repos/releases#edit-a-release>`_\n', '        :param name: string\n', '        :param message: string\n', '        :param draft: bool\n', '        :param prerelease: bool\n', '        :param tag_name: string\n', '        :param target_commitish: string\n', '        :rtype: :class:`github.GitRelease.GitRelease`\n', '        """"""\n']",['isinstance'],1
github/GitRelease.py:GitRelease:upload_asset,GitRelease:upload_asset,method,20,61,48,733,12.02,0,2,"['self', 'path', 'label', 'content_type', 'name', '']","[None, None, None, None, None, None]","[None, None, '""""', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",229,[],"['isinstance', 'basename', 'upload_asset_from_memory']",3
github/GitRelease.py:GitRelease:upload_asset_from_memory,GitRelease:upload_asset_from_memory,method,14,49,43,591,12.06,0,0,"['self', 'file_like', 'file_size', 'name', 'content_type', 'label', '']","[None, None, None, None, None, None, None]","[None, None, None, None, 'github.GithubObject.NotSet', '""""', None]",267,"['        """"""Uploads an asset. Unlike ``upload_asset()`` this method allows you to pass in a file-like object to upload.\n', ""        Note that this method is more strict and requires you to specify the ``name``, since there's no file name to infer these from.\n"", '        :calls: `POST https://<upload_url>/repos/{owner}/{repo}/releases/{release_id}/assets <https://docs.github.com/en/rest/reference/repos/releases#upload-a-release-asset>`_\n', '        :param file_like: binary file-like object, such as those returned by ``open(""file_name"", ""rb"")``. At the very minimum, this object must implement ``read()``.\n', '        :param file_size: int, size in bytes of ``file_like``\n', '        :param content_type: string\n', '        :param name: string\n', '        :param label: string\n', '        :rtype: :class:`github.GitReleaseAsset.GitReleaseAsset`\n', '        """"""\n']","['isinstance', 'str']",2
github/GitRelease.py:GitRelease:get_assets,GitRelease:get_assets,method,2,7,7,128,18.29,0,0,['self'],[None],[None],308,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/releases/{release_id}/assets <https://docs.github.com/en/rest/reference/repos/releases#list-assets-for-a-release>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList`\n', '        """"""\n']",[],0
github/GitRelease.py:GitRelease:_initAttributes,GitRelease:_initAttributes,method,16,30,17,630,21.0,0,0,['self'],[None],[None],320,[],[],0
github/GitRelease.py:GitRelease:_useAttributes,GitRelease:_useAttributes,method,20,95,52,1392,14.65,0,15,"['self', 'attributes']","[None, None]","[None, None]",337,[],"['self._makeIntAttribute', 'self._makeStringAttribute', 'self._makeBoolAttribute', 'self._makeClassAttribute', 'self._makeDatetimeAttribute']",5
github/GitReleaseAsset.py:GitReleaseAsset,GitReleaseAsset,class,55,268,120,3476,12.97,0,12,[],[],[],29,[],[],0
github/GitReleaseAsset.py:GitReleaseAsset:__repr__,GitReleaseAsset:__repr__,method,2,3,3,40,13.33,0,0,['self'],[None],[None],34,[],['self.get__repr__'],1
github/GitReleaseAsset.py:GitReleaseAsset:url,GitReleaseAsset:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],38,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:id,GitReleaseAsset:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:name,GitReleaseAsset:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],54,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:label,GitReleaseAsset:label,method,3,3,3,59,19.67,0,0,['self'],[None],[None],62,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:content_type,GitReleaseAsset:content_type,method,3,3,3,73,24.33,0,0,['self'],[None],[None],70,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:state,GitReleaseAsset:state,method,3,3,3,59,19.67,0,0,['self'],[None],[None],78,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:size,GitReleaseAsset:size,method,3,3,3,57,19.0,0,0,['self'],[None],[None],86,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:download_count,GitReleaseAsset:download_count,method,3,3,3,77,25.67,0,0,['self'],[None],[None],94,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:created_at,GitReleaseAsset:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],102,"['        """"""\n', '        :type: datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:updated_at,GitReleaseAsset:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],110,"['        """"""\n', '        :type: datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:browser_download_url,GitReleaseAsset:browser_download_url,method,3,3,3,89,29.67,0,0,['self'],[None],[None],118,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:uploader,GitReleaseAsset:uploader,method,3,3,3,65,21.67,0,0,['self'],[None],[None],126,"['        """"""\n', '        :type: github.NamedUser.NamedUser\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitReleaseAsset.py:GitReleaseAsset:delete_asset,GitReleaseAsset:delete_asset,method,4,6,6,78,13.0,0,0,['self'],[None],[None],133,"['        """"""\n', '        Delete asset from the release.\n', '        :rtype: bool\n', '        """"""\n']",[],0
github/GitReleaseAsset.py:GitReleaseAsset:update_asset,GitReleaseAsset:update_asset,method,7,25,22,267,10.68,0,0,"['self', 'name', 'label']","[None, None, None]","[None, None, '""""']",141,"['        """"""\n', '        Update asset metadata.\n', '        :rtype: github.GitReleaseAsset.GitReleaseAsset\n', '        """"""\n']","['isinstance', 'GitReleaseAsset']",2
github/GitReleaseAsset.py:GitReleaseAsset:_initAttributes,GitReleaseAsset:_initAttributes,method,13,24,14,504,21.0,0,0,['self'],[None],[None],154,[],[],0
github/GitReleaseAsset.py:GitReleaseAsset:_useAttributes,GitReleaseAsset:_useAttributes,method,16,125,48,1299,10.39,0,12,"['self', 'attributes']","[None, None]","[None, None]",168,[],"['self._makeStringAttribute', 'self._makeIntAttribute', 'self._makeClassAttribute', 'self._makeDatetimeAttribute']",4
github/GitTag.py:GitTag,GitTag,class,27,126,59,1524,12.1,0,6,[],[],[],36,[],[],0
github/GitTag.py:GitTag:__repr__,GitTag:__repr__,method,2,5,5,69,13.8,0,0,['self'],[None],[None],41,[],['self.get__repr__'],1
github/GitTag.py:GitTag:message,GitTag:message,method,3,3,3,63,21.0,0,0,['self'],[None],[None],45,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitTag.py:GitTag:object,GitTag:object,method,3,3,3,61,20.33,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: :class:`github.GitObject.GitObject`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitTag.py:GitTag:sha,GitTag:sha,method,3,3,3,55,18.33,0,0,['self'],[None],[None],61,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitTag.py:GitTag:tag,GitTag:tag,method,3,3,3,55,18.33,0,0,['self'],[None],[None],69,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitTag.py:GitTag:tagger,GitTag:tagger,method,3,3,3,61,20.33,0,0,['self'],[None],[None],77,"['        """"""\n', '        :type: :class:`github.GitAuthor.GitAuthor`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitTag.py:GitTag:url,GitTag:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],85,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitTag.py:GitTag:_initAttributes,GitTag:_initAttributes,method,7,12,8,231,19.25,0,0,['self'],[None],[None],92,[],[],0
github/GitTag.py:GitTag:_useAttributes,GitTag:_useAttributes,method,8,66,29,631,9.56,0,6,"['self', 'attributes']","[None, None]","[None, None]",100,[],"['self._makeStringAttribute', 'self._makeClassAttribute']",2
github/GitTree.py:GitTree,GitTree,class,20,72,40,850,11.81,0,3,[],[],[],35,[],[],0
github/GitTree.py:GitTree:__repr__,GitTree:__repr__,method,2,3,3,47,15.67,0,0,['self'],[None],[None],40,[],['self.get__repr__'],1
github/GitTree.py:GitTree:sha,GitTree:sha,method,3,3,3,55,18.33,0,0,['self'],[None],[None],44,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitTree.py:GitTree:tree,GitTree:tree,method,3,3,3,57,19.0,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: list of :class:`github.GitTreeElement.GitTreeElement`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitTree.py:GitTree:url,GitTree:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/GitTree.py:GitTree:_identity,GitTree:_identity,method,2,2,2,14,7.0,0,0,['self'],[None],[None],68,[],[],0
github/GitTree.py:GitTree:_initAttributes,GitTree:_initAttributes,method,4,6,5,111,18.5,0,0,['self'],[None],[None],71,[],[],0
github/GitTree.py:GitTree:_useAttributes,GitTree:_useAttributes,method,5,33,19,321,9.73,0,3,"['self', 'attributes']","[None, None]","[None, None]",76,[],"['self._makeStringAttribute', 'self._makeListOfClassesAttribute']",2
github/GitTreeElement.py:GitTreeElement,GitTreeElement,class,26,114,49,1217,10.68,0,6,[],[],[],34,[],[],0
github/GitTreeElement.py:GitTreeElement:__repr__,GitTreeElement:__repr__,method,2,5,5,71,14.2,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/GitTreeElement.py:GitTreeElement:mode,GitTreeElement:mode,method,2,2,2,22,11.0,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitTreeElement.py:GitTreeElement:path,GitTreeElement:path,method,2,2,2,22,11.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitTreeElement.py:GitTreeElement:sha,GitTreeElement:sha,method,2,2,2,21,10.5,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitTreeElement.py:GitTreeElement:size,GitTreeElement:size,method,2,2,2,22,11.0,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/GitTreeElement.py:GitTreeElement:type,GitTreeElement:type,method,2,2,2,22,11.0,0,0,['self'],[None],[None],71,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitTreeElement.py:GitTreeElement:url,GitTreeElement:url,method,2,2,2,21,10.5,0,0,['self'],[None],[None],78,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/GitTreeElement.py:GitTreeElement:_initAttributes,GitTreeElement:_initAttributes,method,7,12,8,225,18.75,0,0,['self'],[None],[None],84,[],[],0
github/GitTreeElement.py:GitTreeElement:_useAttributes,GitTreeElement:_useAttributes,method,8,60,25,554,9.23,0,6,"['self', 'attributes']","[None, None]","[None, None]",92,[],"['self._makeStringAttribute', 'self._makeIntAttribute']",2
github/Hook.py:Hook,Hook,class,62,342,149,4192,12.26,0,15,[],[],[],36,[],[],0
github/Hook.py:Hook:__repr__,Hook:__repr__,method,2,5,5,67,13.4,0,0,['self'],[None],[None],41,[],['self.get__repr__'],1
github/Hook.py:Hook:active,Hook:active,method,3,3,3,61,20.33,0,0,['self'],[None],[None],45,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:config,Hook:config,method,3,3,3,61,20.33,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: dict\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:created_at,Hook:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],61,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:events,Hook:events,method,3,3,3,61,20.33,0,0,['self'],[None],[None],69,"['        """"""\n', '        :type: list of string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:id,Hook:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],77,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:last_response,Hook:last_response,method,3,3,3,75,25.0,0,0,['self'],[None],[None],85,"['        """"""\n', '        :type: :class:`github.HookResponse.HookResponse`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:name,Hook:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],93,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:test_url,Hook:test_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],101,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:updated_at,Hook:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],109,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:url,Hook:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],117,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:ping_url,Hook:ping_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],125,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:delete,Hook:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],132,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/hooks/{id} <http://docs.github.com/en/rest/reference/repos#webhooks>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Hook.py:Hook:edit,Hook:edit,method,14,101,49,964,9.54,0,4,"['self', 'name', 'config', 'events', 'add_events', 'remove_events', 'active', '']","[None, None, None, None, None, None, None, None]","[None, None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",139,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/hooks/{id} <http://docs.github.com/en/rest/reference/repos#webhooks>`_\n', '        :param name: string\n', '        :param config: dict\n', '        :param events: list of string\n', '        :param add_events: list of string\n', '        :param remove_events: list of string\n', '        :param active: bool\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'all', 'self._useAttributes']",3
github/Hook.py:Hook:test,Hook:test,method,3,3,3,65,21.67,0,0,['self'],[None],[None],187,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/hooks/{id}/tests <http://docs.github.com/en/rest/reference/repos#webhooks>`_\n', '        :rtype: None\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:ping,Hook:ping,method,3,3,3,65,21.67,0,0,['self'],[None],[None],194,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/hooks/{id}/pings <http://docs.github.com/en/rest/reference/repos#webhooks>`_\n', '        :rtype: None\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Hook.py:Hook:_initAttributes,Hook:_initAttributes,method,12,22,13,449,20.41,0,0,['self'],[None],[None],201,[],[],0
github/Hook.py:Hook:_useAttributes,Hook:_useAttributes,method,18,113,43,1167,10.33,0,11,"['self', 'attributes']","[None, None]","[None, None]",214,[],"['self._makeBoolAttribute', 'self._makeDictAttribute', 'self._makeDatetimeAttribute', 'self._makeListOfStringsAttribute', 'self._makeIntAttribute', 'self._makeClassAttribute', 'self._makeStringAttribute']",7
github/HookDescription.py:HookDescription,HookDescription,class,21,80,39,975,12.19,0,4,[],[],[],34,[],[],0
github/HookDescription.py:HookDescription:__repr__,HookDescription:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/HookDescription.py:HookDescription:events,HookDescription:events,method,2,2,2,24,12.0,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: list of string\n', '        """"""\n']",[],0
github/HookDescription.py:HookDescription:name,HookDescription:name,method,2,2,2,22,11.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/HookDescription.py:HookDescription:schema,HookDescription:schema,method,2,2,2,24,12.0,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: list of list of string\n', '        """"""\n']",[],0
github/HookDescription.py:HookDescription:supported_events,HookDescription:supported_events,method,2,2,2,34,17.0,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: list of string\n', '        """"""\n']",[],0
github/HookDescription.py:HookDescription:_initAttributes,HookDescription:_initAttributes,method,5,8,6,167,20.88,0,0,['self'],[None],[None],70,[],[],0
github/HookDescription.py:HookDescription:_useAttributes,HookDescription:_useAttributes,method,7,42,21,452,10.76,0,4,"['self', 'attributes']","[None, None]","[None, None]",76,[],"['self._makeListOfStringsAttribute', 'self._makeStringAttribute', 'self._makeListOfListOfStringsAttribute']",3
github/HookResponse.py:HookResponse,HookResponse,class,17,61,32,701,11.49,0,3,[],[],[],34,[],[],0
github/HookResponse.py:HookResponse:__repr__,HookResponse:__repr__,method,2,3,3,53,17.67,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/HookResponse.py:HookResponse:code,HookResponse:code,method,2,2,2,22,11.0,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/HookResponse.py:HookResponse:message,HookResponse:message,method,2,2,2,25,12.5,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/HookResponse.py:HookResponse:status,HookResponse:status,method,2,2,2,24,12.0,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/HookResponse.py:HookResponse:_initAttributes,HookResponse:_initAttributes,method,4,6,5,118,19.67,0,0,['self'],[None],[None],63,[],[],0
github/HookResponse.py:HookResponse:_useAttributes,HookResponse:_useAttributes,method,5,30,16,293,9.77,0,3,"['self', 'attributes']","[None, None]","[None, None]",68,[],"['self._makeIntAttribute', 'self._makeStringAttribute']",2
github/InputFileContent.py:InputFileContent,InputFileContent,class,12,39,32,396,10.15,0,1,[],[],[],32,[],[],0
github/InputFileContent.py:InputFileContent:__init__,InputFileContent:__init__,method,7,18,16,164,9.11,0,0,"['self', 'content', 'new_name']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",37,"['        """"""\n', '        :param content: string\n', '        :param new_name: string\n', '        """"""\n']",['isinstance'],1
github/InputFileContent.py:InputFileContent:_identity,InputFileContent:_identity,method,5,14,13,138,9.86,0,1,['self'],[None],[None],51,[],[],0
github/InputGitAuthor.py:InputGitAuthor,InputGitAuthor,class,16,55,43,503,9.15,0,1,[],[],[],34,[],[],0
github/InputGitAuthor.py:InputGitAuthor:__init__,InputGitAuthor:__init__,method,9,27,20,201,7.44,0,0,"['self', 'name', 'email', 'date']","[None, None, None, None]","[None, None, None, 'github.GithubObject.NotSet']",39,"['        """"""\n', '        :param name: string\n', '        :param email: string\n', '        :param date: string\n', '        """"""\n']",['isinstance'],1
github/InputGitAuthor.py:InputGitAuthor:__repr__,InputGitAuthor:__repr__,method,2,2,2,45,22.5,0,0,['self'],[None],[None],56,[],"[""f'InputGitAuthor""]",1
github/InputGitAuthor.py:InputGitAuthor:_identity,InputGitAuthor:_identity,method,5,16,15,144,9.0,0,1,['self'],[None],[None],60,[],[],0
github/InputGitTreeElement.py:InputGitTreeElement,InputGitTreeElement,class,18,83,56,721,8.69,0,2,[],[],[],32,[],[],0
github/InputGitTreeElement.py:InputGitTreeElement:__init__,InputGitTreeElement:__init__,method,13,46,28,339,7.37,0,0,"['self', 'path', 'mode', 'type', 'content', 'sha', '']","[None, None, None, None, None, None, None]","[None, None, None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",37,"['        """"""\n', '        :param path: string\n', '        :param mode: string\n', '        :param type: string\n', '        :param content: string\n', '        :param sha: string or None\n', '        """"""\n']",['isinstance'],1
github/InputGitTreeElement.py:InputGitTreeElement:_identity,InputGitTreeElement:_identity,method,6,25,20,243,9.72,0,2,['self'],[None],[None],69,[],[],0
github/Installation.py:Installation,Installation,class,23,91,48,1195,13.13,0,4,[],[],[],44,[],[],0
github/Installation.py:Installation:__repr__,Installation:__repr__,method,2,3,3,45,15.0,0,0,['self'],[None],[None],49,[],['self.get__repr__'],1
github/Installation.py:Installation:id,Installation:id,method,2,2,2,20,10.0,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Installation.py:Installation:app_id,Installation:app_id,method,2,2,2,24,12.0,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Installation.py:Installation:target_id,Installation:target_id,method,2,2,2,27,13.5,0,0,['self'],[None],[None],67,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Installation.py:Installation:target_type,Installation:target_type,method,2,2,2,29,14.5,0,0,['self'],[None],[None],74,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Installation.py:Installation:get_repos,Installation:get_repos,method,3,11,11,265,24.09,0,0,['self'],[None],[None],80,"['        """"""\n', '        :calls: `GET /installation/repositories <https://docs.github.com/en/rest/reference/integrations/installations#list-repositories>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']",['dict'],1
github/Installation.py:Installation:_initAttributes,Installation:_initAttributes,method,5,8,6,163,20.38,0,0,['self'],[None],[None],96,[],[],0
github/Installation.py:Installation:_useAttributes,Installation:_useAttributes,method,6,40,19,402,10.05,0,4,"['self', 'attributes']","[None, None]","[None, None]",102,[],"['self._makeIntAttribute', 'self._makeStringAttribute']",2
github/InstallationAuthorization.py:InstallationAuthorization,InstallationAuthorization,class,18,64,35,802,12.53,0,3,[],[],[],31,[],[],0
github/InstallationAuthorization.py:InstallationAuthorization:__repr__,InstallationAuthorization:__repr__,method,2,3,3,61,20.33,0,0,['self'],[None],[None],36,[],['self.get__repr__'],1
github/InstallationAuthorization.py:InstallationAuthorization:token,InstallationAuthorization:token,method,2,2,2,23,11.5,0,0,['self'],[None],[None],40,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/InstallationAuthorization.py:InstallationAuthorization:expires_at,InstallationAuthorization:expires_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],47,"['        """"""\n', '        :type: datetime\n', '        """"""\n']",[],0
github/InstallationAuthorization.py:InstallationAuthorization:on_behalf_of,InstallationAuthorization:on_behalf_of,method,2,2,2,30,15.0,0,0,['self'],[None],[None],54,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/InstallationAuthorization.py:InstallationAuthorization:_initAttributes,InstallationAuthorization:_initAttributes,method,4,6,5,128,21.33,0,0,['self'],[None],[None],60,[],[],0
github/InstallationAuthorization.py:InstallationAuthorization:_useAttributes,InstallationAuthorization:_useAttributes,method,6,33,19,356,10.79,0,3,"['self', 'attributes']","[None, None]","[None, None]",65,[],"['self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeClassAttribute']",3
github/Invitation.py:Invitation,Invitation,class,35,163,69,2113,12.96,0,8,[],[],[],28,[],[],0
github/Invitation.py:Invitation:__repr__,Invitation:__repr__,method,2,3,3,45,15.0,0,0,['self'],[None],[None],33,[],['self.get__repr__'],1
github/Invitation.py:Invitation:id,Invitation:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],37,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Invitation.py:Invitation:permissions,Invitation:permissions,method,3,3,3,71,23.67,0,0,['self'],[None],[None],45,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Invitation.py:Invitation:created_at,Invitation:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Invitation.py:Invitation:invitee,Invitation:invitee,method,3,3,3,63,21.0,0,0,['self'],[None],[None],61,"['        """"""\n', '        :type: NamedUser\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Invitation.py:Invitation:inviter,Invitation:inviter,method,3,3,3,63,21.0,0,0,['self'],[None],[None],69,"['        """"""\n', '        :type: NamedUser\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Invitation.py:Invitation:url,Invitation:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],77,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Invitation.py:Invitation:html_url,Invitation:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],85,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Invitation.py:Invitation:repository,Invitation:repository,method,3,3,3,69,23.0,0,0,['self'],[None],[None],93,"['        """"""\n', '        :type: Repository\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Invitation.py:Invitation:_initAttributes,Invitation:_initAttributes,method,9,16,10,329,20.56,0,0,['self'],[None],[None],100,[],[],0
github/Invitation.py:Invitation:_useAttributes,Invitation:_useAttributes,method,12,89,35,914,10.27,0,8,"['self', 'attributes']","[None, None]","[None, None]",110,[],"['self._makeClassAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeStringAttribute']",4
github/Issue.py:Issue,Issue,class,138,1074,380,13371,12.45,4,37,[],[],[],63,[],[],0
github/Issue.py:Issue:__repr__,Issue:__repr__,method,2,7,7,81,11.57,0,0,['self'],[None],[None],68,[],['self.get__repr__'],1
github/Issue.py:Issue:assignee,Issue:assignee,method,3,3,3,65,21.67,0,0,['self'],[None],[None],74,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:assignees,Issue:assignees,method,3,3,3,67,22.33,0,0,['self'],[None],[None],82,"['        """"""\n', '        :type: list of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:body,Issue:body,method,3,3,3,57,19.0,0,0,['self'],[None],[None],90,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:closed_at,Issue:closed_at,method,3,3,3,67,22.33,0,0,['self'],[None],[None],98,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:closed_by,Issue:closed_by,method,3,3,3,67,22.33,0,0,['self'],[None],[None],106,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:comments,Issue:comments,method,3,3,3,65,21.67,0,0,['self'],[None],[None],114,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:comments_url,Issue:comments_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],122,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:created_at,Issue:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],130,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:events_url,Issue:events_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],138,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:html_url,Issue:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],146,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:id,Issue:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],154,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:labels,Issue:labels,method,3,3,3,61,20.33,0,0,['self'],[None],[None],162,"['        """"""\n', '        :type: list of :class:`github.Label.Label`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:labels_url,Issue:labels_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],170,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:milestone,Issue:milestone,method,3,3,3,67,22.33,0,0,['self'],[None],[None],178,"['        """"""\n', '        :type: :class:`github.Milestone.Milestone`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:number,Issue:number,method,3,3,3,61,20.33,0,0,['self'],[None],[None],186,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:pull_request,Issue:pull_request,method,3,3,3,73,24.33,0,0,['self'],[None],[None],194,"['        """"""\n', '        :type: :class:`github.IssuePullRequest.IssuePullRequest`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:repository,Issue:repository,method,7,19,17,313,16.47,0,1,['self'],[None],[None],202,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:state,Issue:state,method,3,3,3,59,19.67,0,0,['self'],[None],[None],218,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:title,Issue:title,method,3,3,3,59,19.67,0,0,['self'],[None],[None],226,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:updated_at,Issue:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],234,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:url,Issue:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],242,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:user,Issue:user,method,3,3,3,57,19.0,0,0,['self'],[None],[None],250,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:locked,Issue:locked,method,3,3,3,61,20.33,0,0,['self'],[None],[None],258,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:active_lock_reason,Issue:active_lock_reason,method,3,3,3,85,28.33,0,0,['self'],[None],[None],266,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:as_pull_request,Issue:as_pull_request,method,5,14,13,187,13.36,0,0,['self'],[None],[None],273,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/{number} <http://docs.github.com/en/rest/reference/pulls>`_\n', '        :rtype: :class:`github.PullRequest.PullRequest`\n', '        """"""\n']",[],0
github/Issue.py:Issue:add_to_assignees,Issue:add_to_assignees,method,8,35,31,365,10.43,1,0,"['self', '*assignees']","[None, None]","[None, None]",285,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/issues/{number}/assignees <https://docs.github.com/en/rest/reference/issues#assignees>`_\n', '        :param assignee: :class:`github.NamedUser.NamedUser` or string\n', '        :rtype: None\n', '        """"""\n']","['all', 'isinstance', 'self._useAttributes']",3
github/Issue.py:Issue:add_to_labels,Issue:add_to_labels,method,6,31,27,279,9.0,0,0,"['self', '*labels']","[None, None]","[None, None]",308,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/issues/{number}/labels <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :param label: :class:`github.Label.Label` or string\n', '        :rtype: None\n', '        """"""\n']","['all', 'isinstance']",2
github/Issue.py:Issue:create_comment,Issue:create_comment,method,7,23,22,254,11.04,0,0,"['self', 'body']","[None, None]","[None, None]",325,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/issues/{number}/comments <http://docs.github.com/en/rest/reference/issues#comments>`_\n', '        :param body: string\n', '        :rtype: :class:`github.IssueComment.IssueComment`\n', '        """"""\n']",['isinstance'],1
github/Issue.py:Issue:delete_labels,Issue:delete_labels,method,3,6,6,81,13.5,0,0,['self'],[None],[None],342,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/issues/{number}/labels <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Issue.py:Issue:edit,Issue:edit,method,19,170,68,1623,9.55,2,9,"['self', 'title', 'body', 'assignee', 'state', 'milestone', 'labels', 'assignees', '']","[None, None, None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",351,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/issues/{number} <http://docs.github.com/en/rest/reference/issues>`_\n', '        :param title: string\n', '        :param body: string\n', '        :param assignee: string or :class:`github.NamedUser.NamedUser` or None\n', '        :param assignees: list of string or :class:`github.NamedUser.NamedUser`\n', '        :param state: string\n', '        :param milestone: :class:`github.Milestone.Milestone` or None\n', '        :param labels: list of string\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'all', 'dict', 'self._useAttributes']",4
github/Issue.py:Issue:lock,Issue:lock,method,3,3,3,61,20.33,0,0,['self'],[None],[None],421,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/issues/{issue_number}/lock <https://docs.github.com/en/rest/reference/issues>`_\n', '        :param lock_reason: string\n', '        :rtype: None\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Issue.py:Issue:unlock,Issue:unlock,method,3,6,6,79,13.17,0,0,['self'],[None],[None],437,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/issues/{issue_number}/lock <https://docs.github.com/en/rest/reference/issues>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Issue.py:Issue:get_comment,Issue:get_comment,method,14,46,40,615,13.37,0,1,"['self', 'id']","[None, None]","[None, None]",446,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/comments/{id} <http://docs.github.com/en/rest/reference/issues#comments>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.IssueComment.IssueComment`\n', '        """"""\n']","['isinstance', 'get_comments', 'dict', 'since.strftime']",4
github/Issue.py:Issue:get_comments,Issue:get_comments,method,9,26,24,342,13.15,0,1,"['self', 'since']","[None, None]","[None, 'github.GithubObject.NotSet']",460,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/{number}/comments <http://docs.github.com/en/rest/reference/issues#comments>`_\n', '        :param since: datetime.datetime format YYYY-MM-DDTHH:MM:SSZ\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.IssueComment.IssueComment`\n', '        """"""\n']","['isinstance', 'dict', 'since.strftime']",3
github/Issue.py:Issue:get_events,Issue:get_events,method,2,9,9,172,19.11,0,0,['self'],[None],[None],479,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/{issue_number}/events <http://docs.github.com/en/rest/reference/issues#events>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.IssueEvent.IssueEvent`\n', '        """"""\n']",[],0
github/Issue.py:Issue:get_labels,Issue:get_labels,method,2,7,7,104,14.86,0,0,['self'],[None],[None],492,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/{number}/labels <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Label.Label`\n', '        """"""\n']",[],0
github/Issue.py:Issue:remove_from_assignees,Issue:remove_from_assignees,method,8,35,31,367,10.49,1,0,"['self', '*assignees']","[None, None]","[None, None]",501,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/issues/{number}/assignees <https://docs.github.com/en/rest/reference/issues#assignees>`_\n', '        :param assignee: :class:`github.NamedUser.NamedUser` or string\n', '        :rtype: None\n', '        """"""\n']","['all', 'isinstance', 'self._useAttributes']",3
github/Issue.py:Issue:remove_from_labels,Issue:remove_from_labels,method,7,19,17,244,12.84,0,1,"['self', 'label']","[None, None]","[None, None]",524,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/issues/{number}/labels/{name} <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :param label: :class:`github.Label.Label` or string\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/Issue.py:Issue:set_labels,Issue:set_labels,method,6,31,27,278,8.97,0,0,"['self', '*labels']","[None, None]","[None, None]",539,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/issues/{number}/labels <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :param labels: list of :class:`github.Label.Label` or strings\n', '        :rtype: None\n', '        """"""\n']","['all', 'isinstance']",2
github/Issue.py:Issue:get_reactions,Issue:get_reactions,method,2,9,9,170,18.89,0,0,['self'],[None],[None],556,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/{number}/reactions <https://docs.github.com/en/rest/reference/reactions#list-reactions-for-an-issue>`_\n', '        :return: :class: :class:`github.PaginatedList.PaginatedList` of :class:`github.Reaction.Reaction`\n', '        """"""\n']",[],0
github/Issue.py:Issue:create_reaction,Issue:create_reaction,method,7,23,22,331,14.39,0,0,"['self', 'reaction_type']","[None, None]","[None, None]",569,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/issues/{number}/reactions <https://docs.github.com/en/rest/reference/reactions>`_\n', '        :param reaction_type: string\n', '        :rtype: :class:`github.Reaction.Reaction`\n', '        """"""\n']",['isinstance'],1
github/Issue.py:Issue:delete_reaction,Issue:delete_reaction,method,7,16,16,207,12.94,0,0,"['self', 'reaction_id']","[None, None]","[None, None]",587,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/issues/{issue_number}/reactions/{reaction_id} <https://docs.github.com/en/rest/reference/reactions#delete-an-issue-reaction>`_\n', '        :param reaction_id: integer\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/Issue.py:Issue:get_timeline,Issue:get_timeline,method,2,9,9,180,20.0,0,0,['self'],[None],[None],601,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/{number}/timeline <https://docs.github.com/en/rest/reference/issues/timeline#list-events-for-an-issue>`_\n', '        :return: :class: :class:`github.PaginatedList.PaginatedList` of :class:`github.TimelineEvent.TimelineEvent`\n', '        """"""\n']",[],0
github/Issue.py:Issue:_identity,Issue:_identity,method,2,2,2,17,8.5,0,0,['self'],[None],[None],615,[],[],0
github/Issue.py:Issue:_initAttributes,Issue:_initAttributes,method,25,48,26,1008,21.0,0,0,['self'],[None],[None],618,[],[],0
github/Issue.py:Issue:_useAttributes,Issue:_useAttributes,method,31,286,98,3046,10.65,0,25,"['self', 'attributes']","[None, None]","[None, None]",644,[],"['self._makeStringAttribute', 'self._makeClassAttribute', 'self._makeListOfClassesAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeBoolAttribute']",6
github/IssueComment.py:IssueComment,IssueComment,class,53,241,124,3125,12.97,0,8,[],[],[],41,[],[],0
github/IssueComment.py:IssueComment:__repr__,IssueComment:__repr__,method,2,5,5,69,13.8,0,0,['self'],[None],[None],46,[],['self.get__repr__'],1
github/IssueComment.py:IssueComment:body,IssueComment:body,method,3,3,3,57,19.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueComment.py:IssueComment:created_at,IssueComment:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],58,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueComment.py:IssueComment:id,IssueComment:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],66,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueComment.py:IssueComment:issue_url,IssueComment:issue_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],74,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueComment.py:IssueComment:updated_at,IssueComment:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],82,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueComment.py:IssueComment:url,IssueComment:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],90,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueComment.py:IssueComment:html_url,IssueComment:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],98,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueComment.py:IssueComment:user,IssueComment:user,method,3,3,3,57,19.0,0,0,['self'],[None],[None],106,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueComment.py:IssueComment:delete,IssueComment:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],113,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/issues/comments/{id} <http://docs.github.com/en/rest/reference/issues#comments>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/IssueComment.py:IssueComment:edit,IssueComment:edit,method,6,17,17,181,10.65,0,0,"['self', 'body']","[None, None]","[None, None]",120,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/issues/comments/{id} <http://docs.github.com/en/rest/reference/issues#comments>`_\n', '        :param body: string\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'self._useAttributes']",2
github/IssueComment.py:IssueComment:get_reactions,IssueComment:get_reactions,method,2,9,9,170,18.89,0,0,['self'],[None],[None],135,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/comments/{id}/reactions\n', '                <https://docs.github.com/en/rest/reference/reactions#list-reactions-for-an-issue-comment>`_\n', '        :return: :class: :class:`github.PaginatedList.PaginatedList` of :class:`github.Reaction.Reaction`\n', '        """"""\n']",[],0
github/IssueComment.py:IssueComment:create_reaction,IssueComment:create_reaction,method,7,23,22,331,14.39,0,0,"['self', 'reaction_type']","[None, None]","[None, None]",149,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/issues/comments/{id}/reactions\n', '                <https://docs.github.com/en/rest/reference/reactions#create-reaction-for-an-issue-comment>`_\n', '        :param reaction_type: string\n', '        :rtype: :class:`github.Reaction.Reaction`\n', '        """"""\n']",['isinstance'],1
github/IssueComment.py:IssueComment:delete_reaction,IssueComment:delete_reaction,method,7,16,16,207,12.94,0,0,"['self', 'reaction_id']","[None, None]","[None, None]",168,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions/{reaction_id}\n', '                <https://docs.github.com/en/rest/reference/reactions#delete-an-issue-comment-reaction>`_\n', '        :param reaction_id: integer\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/IssueComment.py:IssueComment:_initAttributes,IssueComment:_initAttributes,method,9,16,10,321,20.06,0,0,['self'],[None],[None],183,[],[],0
github/IssueComment.py:IssueComment:_useAttributes,IssueComment:_useAttributes,method,12,83,34,834,10.05,0,8,"['self', 'attributes']","[None, None]","[None, None]",193,[],"['self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeClassAttribute']",4
github/IssueEvent.py:IssueEvent,IssueEvent,class,66,360,132,4768,13.24,0,18,[],[],[],37,[],[],0
github/IssueEvent.py:IssueEvent:__repr__,IssueEvent:__repr__,method,2,3,3,45,15.0,0,0,['self'],[None],[None],42,[],['self.get__repr__'],1
github/IssueEvent.py:IssueEvent:actor,IssueEvent:actor,method,3,3,3,59,19.67,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:commit_id,IssueEvent:commit_id,method,3,3,3,67,22.33,0,0,['self'],[None],[None],54,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:created_at,IssueEvent:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],62,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:event,IssueEvent:event,method,3,3,3,59,19.67,0,0,['self'],[None],[None],70,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:id,IssueEvent:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],78,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:issue,IssueEvent:issue,method,3,3,3,59,19.67,0,0,['self'],[None],[None],86,"['        """"""\n', '        :type: :class:`github.Issue.Issue`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:url,IssueEvent:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],94,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:node_id,IssueEvent:node_id,method,3,3,3,63,21.0,0,0,['self'],[None],[None],102,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:commit_url,IssueEvent:commit_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],110,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:label,IssueEvent:label,method,3,3,3,59,19.67,0,0,['self'],[None],[None],118,"['        """"""\n', '        :type: :class:`github.Label.Label`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:assignee,IssueEvent:assignee,method,3,3,3,65,21.67,0,0,['self'],[None],[None],126,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:assigner,IssueEvent:assigner,method,3,3,3,65,21.67,0,0,['self'],[None],[None],134,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:review_requester,IssueEvent:review_requester,method,3,3,3,81,27.0,0,0,['self'],[None],[None],142,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:requested_reviewer,IssueEvent:requested_reviewer,method,3,3,3,85,28.33,0,0,['self'],[None],[None],150,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:milestone,IssueEvent:milestone,method,3,3,3,67,22.33,0,0,['self'],[None],[None],158,"['        """"""\n', '        :type: :class:`github.Milestone.Milestone`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:rename,IssueEvent:rename,method,3,3,3,61,20.33,0,0,['self'],[None],[None],166,"['        """"""\n', '        :type: dict\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:dismissed_review,IssueEvent:dismissed_review,method,3,3,3,81,27.0,0,0,['self'],[None],[None],174,"['        """"""\n', '        :type: dict\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:lock_reason,IssueEvent:lock_reason,method,3,3,3,71,23.67,0,0,['self'],[None],[None],182,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/IssueEvent.py:IssueEvent:_initAttributes,IssueEvent:_initAttributes,method,19,36,20,764,21.22,0,0,['self'],[None],[None],189,[],[],0
github/IssueEvent.py:IssueEvent:_useAttributes,IssueEvent:_useAttributes,method,23,206,68,2139,10.38,0,18,"['self', 'attributes']","[None, None]","[None, None]",209,[],"['self._makeClassAttribute', 'self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeDictAttribute']",5
github/IssuePullRequest.py:IssuePullRequest,IssuePullRequest,class,14,56,29,679,12.12,0,3,[],[],[],33,[],[],0
github/IssuePullRequest.py:IssuePullRequest:diff_url,IssuePullRequest:diff_url,method,2,2,2,26,13.0,0,0,['self'],[None],[None],39,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/IssuePullRequest.py:IssuePullRequest:html_url,IssuePullRequest:html_url,method,2,2,2,26,13.0,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/IssuePullRequest.py:IssuePullRequest:patch_url,IssuePullRequest:patch_url,method,2,2,2,27,13.5,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/IssuePullRequest.py:IssuePullRequest:_initAttributes,IssuePullRequest:_initAttributes,method,4,6,5,126,21.0,0,0,['self'],[None],[None],59,[],[],0
github/IssuePullRequest.py:IssuePullRequest:_useAttributes,IssuePullRequest:_useAttributes,method,4,30,16,320,10.67,0,3,"['self', 'attributes']","[None, None]","[None, None]",64,[],['self._makeStringAttribute'],1
github/Label.py:Label,Label,class,32,140,85,1737,12.41,0,5,[],[],[],39,[],[],0
github/Label.py:Label:__repr__,Label:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],44,[],['self.get__repr__'],1
github/Label.py:Label:color,Label:color,method,3,3,3,59,19.67,0,0,['self'],[None],[None],48,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Label.py:Label:description,Label:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],56,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Label.py:Label:name,Label:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Label.py:Label:url,Label:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],72,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Label.py:Label:delete,Label:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],79,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/labels/{name} <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Label.py:Label:edit,Label:edit,method,10,42,36,481,11.45,0,1,"['self', 'name', 'color', 'description']","[None, None, None, None]","[None, None, None, 'github.GithubObject.NotSet']",86,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/labels/{name} <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :param name: string\n', '        :param color: string\n', '        :param description: string\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'self._useAttributes']",2
github/Label.py:Label:_identity,Label:_identity,method,2,2,2,35,17.5,0,0,['self'],[None],[None],114,[],[],0
github/Label.py:Label:_initAttributes,Label:_initAttributes,method,5,8,6,158,19.75,0,0,['self'],[None],[None],117,[],[],0
github/Label.py:Label:_useAttributes,Label:_useAttributes,method,5,40,19,396,9.9,0,4,"['self', 'attributes']","[None, None]","[None, None]",123,[],['self._makeStringAttribute'],1
github/License.py:License,License,class,42,216,87,2818,13.05,0,11,[],[],[],26,[],[],0
github/License.py:License:__repr__,License:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],31,[],['self.get__repr__'],1
github/License.py:License:key,License:key,method,3,3,3,55,18.33,0,0,['self'],[None],[None],35,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/License.py:License:name,License:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/License.py:License:spdx_id,License:spdx_id,method,3,3,3,63,21.0,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/License.py:License:url,License:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],59,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/License.py:License:html_url,License:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],67,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/License.py:License:description,License:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],75,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/License.py:License:implementation,License:implementation,method,3,3,3,77,25.67,0,0,['self'],[None],[None],83,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/License.py:License:body,License:body,method,3,3,3,57,19.0,0,0,['self'],[None],[None],91,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/License.py:License:permissions,License:permissions,method,3,3,3,71,23.67,0,0,['self'],[None],[None],99,"['        """"""\n', '        :type: list of string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/License.py:License:conditions,License:conditions,method,3,3,3,69,23.0,0,0,['self'],[None],[None],107,"['        """"""\n', '        :type: list of string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/License.py:License:limitations,License:limitations,method,3,3,3,71,23.67,0,0,['self'],[None],[None],115,"['        """"""\n', '        :type: list of string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/License.py:License:_initAttributes,License:_initAttributes,method,12,22,13,459,20.86,0,0,['self'],[None],[None],122,[],[],0
github/License.py:License:_useAttributes,License:_useAttributes,method,13,118,44,1188,10.07,0,11,"['self', 'attributes']","[None, None]","[None, None]",135,[],"['self._makeStringAttribute', 'self._makeListOfStringsAttribute']",2
github/MainClass.py:Github,Github,class,114,1144,368,12757,11.15,6,28,[],[],[],90,[],[],0
github/MainClass.py:GithubIntegration,GithubIntegration,class,34,135,95,1772,13.13,0,3,[],[],[],793,[],[],0
github/MainClass.py:Github:__init__,Github:__init__,method,9,73,46,588,8.05,0,0,"['self', 'login_or_token', 'password', 'jwt', 'base_url', 'timeout', 'user_agent', 'per_page', 'verify', 'retry', 'pool_size', '']","[None, None, None, None, None, None, None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'DEFAULT_BASE_URL', 'DEFAULT_TIMEOUT', '""PyGithub/Python""', 'DEFAULT_PER_PAGE', 'True', 'None', 'None', None]",95,"['        """"""\n', '        :param login_or_token: string\n', '        :param password: string\n', '        :param base_url: string\n', '        :param timeout: integer\n', '        :param user_agent: string\n', '        :param per_page: int\n', '        :param verify: boolean or string\n', '        :param retry: int or urllib3.util.retry.Retry object\n', '        :param pool_size: int\n', '        """"""\n']","['isinstance', 'Requester']",2
github/MainClass.py:Github:FIX_REPO_GET_GIT_REF,Github:FIX_REPO_GET_GIT_REF,method,2,2,2,43,21.5,0,0,['self'],[None],[None],146,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/MainClass.py:Github:FIX_REPO_GET_GIT_REF,Github:FIX_REPO_GET_GIT_REF,method,2,2,2,43,21.5,0,0,['self'],[None],[None],153,"['        """"""\n', '        :type: int\n', '        """"""\n']",[],0
github/MainClass.py:Github:per_page,Github:per_page,method,2,2,2,31,15.5,0,0,['self'],[None],[None],158,"['        """"""\n', '        :type: int\n', '        """"""\n']",[],0
github/MainClass.py:Github:per_page,Github:per_page,method,2,2,2,31,15.5,0,0,['self'],[None],[None],165,"['        """"""\n', '        First value is requests remaining, second value is request limit.\n', '\n', '        :type: (int, int)\n', '        """"""\n']",[],0
github/MainClass.py:Github:rate_limiting,Github:rate_limiting,method,5,10,9,116,11.6,0,1,['self'],[None],[None],172,"['        """"""\n', '        First value is requests remaining, second value is request limit.\n', '\n', '        :type: (int, int)\n', '        """"""\n']",['self.get_rate_limit'],1
github/MainClass.py:Github:rate_limiting_resettime,Github:rate_limiting_resettime,method,3,6,5,115,19.17,0,1,['self'],[None],[None],184,"['        """"""\n', '        Unix timestamp indicating when rate limiting will reset.\n', '\n', '        :type: int\n', '        """"""\n']",['self.get_rate_limit'],1
github/MainClass.py:Github:get_rate_limit,Github:get_rate_limit,method,5,9,8,145,16.11,0,0,['self'],[None],[None],194,"['        """"""\n', '        Rate limit status for different resources (core/search/graphql).\n', '\n', '        :calls: `GET /rate_limit <http://docs.github.com/en/rest/reference/rate_limit>`_\n', '        :rtype: :class:`github.RateLimit.RateLimit`\n', '        """"""\n']",['RateLimit.RateLimit'],1
github/MainClass.py:Github:oauth_scopes,Github:oauth_scopes,method,2,2,2,35,17.5,0,0,['self'],[None],[None],205,"['        """"""\n', '        :type: list of string\n', '        """"""\n']",[],0
github/MainClass.py:Github:get_license,Github:get_license,method,9,24,22,336,14.0,0,0,"['self', 'key']","[None, None]","[None, 'github.GithubObject.NotSet']",211,"['        """"""\n', '        :calls: `GET /license/{license} <https://docs.github.com/en/rest/reference/licenses#get-an-individual-license>`_\n', '        :param key: string\n', '        :rtype: :class:`github.License.License`\n', '        """"""\n']","['isinstance', 'get_licenses', 'dict']",3
github/MainClass.py:Github:get_licenses,Github:get_licenses,method,3,9,9,132,14.67,0,0,['self'],[None],[None],222,"['        """"""\n', '        :calls: `GET /licenses <https://docs.github.com/en/rest/reference/licenses#list-all-licenses>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.License.License`\n', '        """"""\n']",['dict'],1
github/MainClass.py:Github:get_events,Github:get_events,method,2,7,7,94,13.43,0,0,['self'],[None],[None],234,"['        """"""\n', '        :calls: `GET /events <https://docs.github.com/en/rest/reference/activity/events#list-public-events>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Event.Event`\n', '        """"""\n']",[],0
github/MainClass.py:Github:get_user,Github:get_user,method,16,79,49,920,11.65,0,2,"['self', 'login']","[None, None]","[None, 'github.GithubObject.NotSet']",244,"['        """"""\n', '        :calls: `GET /users/{user} <http://docs.github.com/en/rest/reference/users>`_ or `GET /user <http://docs.github.com/en/rest/reference/users>`_\n', '        :param login: string\n', '        :rtype: :class:`github.NamedUser.NamedUser` or :class:`github.AuthenticatedUser.AuthenticatedUser`\n', '        """"""\n']","['isinstance', 'AuthenticatedUser.AuthenticatedUser', 'get_user_by_id', 'get_users', 'dict']",5
github/MainClass.py:Github:get_user_by_id,Github:get_user_by_id,method,6,15,14,194,12.93,0,0,"['self', 'user_id']","[None, None]","[None, None]",263,"['        """"""\n', '        :calls: `GET /user/{id} <http://docs.github.com/en/rest/reference/users>`_\n', '        :param user_id: int\n', '        :rtype: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['isinstance'],1
github/MainClass.py:Github:get_users,Github:get_users,method,8,24,21,272,11.33,0,1,"['self', 'since']","[None, None]","[None, 'github.GithubObject.NotSet']",275,"['        """"""\n', '        :calls: `GET /users <http://docs.github.com/en/rest/reference/users>`_\n', '        :param since: integer\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']","['isinstance', 'dict']",2
github/MainClass.py:Github:get_organization,Github:get_organization,method,13,42,36,546,13.0,0,1,"['self', 'login']","[None, None]","[None, None]",289,"['        """"""\n', '        :calls: `GET /orgs/{org} <http://docs.github.com/en/rest/reference/orgs>`_\n', '        :param login: string\n', '        :rtype: :class:`github.Organization.Organization`\n', '        """"""\n']","['isinstance', 'get_organizations', 'dict']",3
github/MainClass.py:Github:get_organizations,Github:get_organizations,method,8,24,21,290,12.08,0,1,"['self', 'since']","[None, None]","[None, 'github.GithubObject.NotSet']",301,"['        """"""\n', '        :calls: `GET /organizations <http://docs.github.com/en/rest/reference/orgs#list-all-organizations>`_\n', '        :param since: integer\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Organization.Organization`\n', '        """"""\n']","['isinstance', 'dict']",2
github/MainClass.py:Github:get_repo,Github:get_repo,method,10,38,34,478,12.58,0,2,"['self', 'full_name_or_id', 'lazy']","[None, None, None]","[None, None, 'False']",318,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo} <http://docs.github.com/en/rest/reference/repos>`_ or `GET /repositories/{id} <http://docs.github.com/en/rest/reference/repos>`_\n', '        :rtype: :class:`github.Repository.Repository`\n', '        """"""\n']","['isinstance', 'Repository.Repository', 'get_repos']",3
github/MainClass.py:Github:get_repos,Github:get_repos,method,9,37,27,416,11.24,0,2,"['self', 'since', 'visibility']","[None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet']",333,"['        """"""\n', '        :calls: `GET /repositories <http://docs.github.com/en/rest/reference/repos#list-all-public-repositories>`_\n', '        :param since: integer\n', ""        :param visibility: string ('all','public')\n"", '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']","['isinstance', 'dict']",2
github/MainClass.py:Github:get_project,Github:get_project,method,8,35,23,467,13.34,0,0,"['self', 'id']","[None, None]","[None, None]",356,"['        """"""\n', '        :calls: `GET /projects/{project_id} <https://docs.github.com/en/rest/reference/projects#get-a-project>`_\n', '        :rtype: :class:`github.Project.Project`\n', '        :param id: integer\n', '        """"""\n']",['get_project_column'],1
github/MainClass.py:Github:get_project_column,Github:get_project_column,method,5,17,16,227,13.35,0,0,"['self', 'id']","[None, None]","[None, None]",369,"['        """"""\n', '        :calls: `GET /projects/columns/{column_id} <https://docs.github.com/en/rest/reference/projects/columns#get-a-project-column>`_\n', '        :rtype: :class:`github.ProjectColumn.ProjectColumn`\n', '        :param id: integer\n', '        """"""\n']",[],0
github/MainClass.py:Github:get_gist,Github:get_gist,method,14,42,37,538,12.81,0,1,"['self', 'id']","[None, None]","[None, None]",384,"['        """"""\n', '        :calls: `GET /gists/{id} <http://docs.github.com/en/rest/reference/gists>`_\n', '        :param id: string\n', '        :rtype: :class:`github.Gist.Gist`\n', '        """"""\n']","['isinstance', 'get_gists', 'dict', 'since.strftime']",4
github/MainClass.py:Github:get_gists,Github:get_gists,method,9,26,24,316,12.15,0,1,"['self', 'since']","[None, None]","[None, 'github.GithubObject.NotSet']",394,"['        """"""\n', '        :calls: `GET /gists/public <http://docs.github.com/en/rest/reference/gists>`_\n', '        :param since: datetime.datetime format YYYY-MM-DDTHH:MM:SSZ\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Gist.Gist`\n', '        """"""\n']","['isinstance', 'dict', 'since.strftime']",3
github/MainClass.py:Github:search_repositories,Github:search_repositories,method,23,86,56,737,8.57,1,3,"['self', 'query', 'sort', 'order', '**qualifiers', '']","[None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None, None]",410,"['        """"""\n', '        :calls: `GET /search/repositories <http://docs.github.com/en/rest/reference/search>`_\n', '        :param query: string\n', ""        :param sort: string ('stars', 'forks', 'updated')\n"", ""        :param order: string ('asc', 'desc')\n"", '        :param qualifiers: keyword dict query qualifiers\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']","['isinstance', 'dict', 'query_chunks.append', 'qualifiers.items']",4
github/MainClass.py:Github:search_users,Github:search_users,method,21,61,47,634,10.39,1,3,"['self', 'query', 'sort', 'order', '**qualifiers', '']","[None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None, None]",455,"['        """"""\n', '        :calls: `GET /search/users <http://docs.github.com/en/rest/reference/search>`_\n', '        :param query: string\n', ""        :param sort: string ('followers', 'repositories', 'joined')\n"", ""        :param order: string ('asc', 'desc')\n"", '        :param qualifiers: keyword dict query qualifiers\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']","['isinstance', 'dict', 'query_chunks.append', 'qualifiers.items']",4
github/MainClass.py:Github:search_issues,Github:search_issues,method,24,68,54,650,9.56,1,3,"['self', 'query', 'sort', 'order', '**qualifiers', '']","[None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None, None]",496,"['        """"""\n', '        :calls: `GET /search/issues <http://docs.github.com/en/rest/reference/search>`_\n', '        :param query: string\n', ""        :param sort: string ('comments', 'created', 'updated')\n"", ""        :param order: string ('asc', 'desc')\n"", '        :param qualifiers: keyword dict query qualifiers\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Issue.Issue`\n', '        """"""\n']","['isinstance', 'dict', 'query_chunks.append', 'qualifiers.items']",4
github/MainClass.py:Github:search_code,Github:search_code,method,24,92,61,801,8.71,1,3,"['self', 'query', 'sort', 'order', 'highlight', '**qualifiers', '']","[None, None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'False', None, None]",534,"['        """"""\n', '        :calls: `GET /search/code <http://docs.github.com/en/rest/reference/search>`_\n', '        :param query: string\n', ""        :param sort: string ('indexed')\n"", ""        :param order: string ('asc', 'desc')\n"", '        :param highlight: boolean (True, False)\n', '        :param qualifiers: keyword dict query qualifiers\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.ContentFile.ContentFile`\n', '        """"""\n']","['isinstance', 'dict', 'query_chunks.append', 'qualifiers.items']",4
github/MainClass.py:Github:search_commits,Github:search_commits,method,23,87,57,785,9.02,1,3,"['self', 'query', 'sort', 'order', '**qualifiers', '']","[None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None, None]",584,"['        """"""\n', '        :calls: `GET /search/commits <http://docs.github.com/en/rest/reference/search>`_\n', '        :param query: string\n', ""        :param sort: string ('author-date', 'committer-date')\n"", ""        :param order: string ('asc', 'desc')\n"", '        :param qualifiers: keyword dict query qualifiers\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Commit.Commit`\n', '        """"""\n']","['isinstance', 'dict', 'query_chunks.append', 'qualifiers.items']",4
github/MainClass.py:Github:search_topics,Github:search_topics,method,19,43,42,483,11.23,1,1,"['self', 'query', '**qualifiers']","[None, None, None]","[None, None, None]",630,"['        """"""\n', '        :calls: `GET /search/topics <http://docs.github.com/en/rest/reference/search>`_\n', '        :param query: string\n', '        :param qualifiers: keyword dict query qualifiers\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Topic.Topic`\n', '        """"""\n']","['isinstance', 'dict', 'query_chunks.append', 'qualifiers.items']",4
github/MainClass.py:Github:render_markdown,Github:render_markdown,method,11,36,32,384,10.67,0,1,"['self', 'text', 'context']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",658,"['        """"""\n', '        :calls: `POST /markdown <http://docs.github.com/en/rest/reference/markdown>`_\n', '        :param text: string\n', '        :param context: :class:`github.Repository.Repository`\n', '        :rtype: string\n', '        """"""\n']",['isinstance'],1
github/MainClass.py:Github:get_hook,Github:get_hook,method,8,36,25,407,11.31,0,0,"['self', 'name']","[None, None]","[None, None]",678,"['        """"""\n', '        :calls: `GET /hooks/{name} <http://docs.github.com/en/rest/reference/repos#hooks>`_\n', '        :param name: string\n', '        :rtype: :class:`github.HookDescription.HookDescription`\n', '        """"""\n']","['isinstance', 'HookDescription.HookDescription', 'get_hooks']",3
github/MainClass.py:Github:get_hooks,Github:get_hooks,method,4,17,16,181,10.65,0,0,['self'],[None],[None],692,"['        """"""\n', '        :calls: `GET /hooks <http://docs.github.com/en/rest/reference/repos#hooks>`_\n', '        :rtype: list of :class:`github.HookDescription.HookDescription`\n', '        """"""\n']",['HookDescription.HookDescription'],1
github/MainClass.py:Github:get_gitignore_templates,Github:get_gitignore_templates,method,4,8,7,92,11.5,0,0,['self'],[None],[None],705,"['        """"""\n', '        :calls: `GET /gitignore/templates <http://docs.github.com/en/rest/reference/gitignore>`_\n', '        :rtype: list of string\n', '        """"""\n']",[],0
github/MainClass.py:Github:get_gitignore_template,Github:get_gitignore_template,method,8,28,22,354,12.64,0,0,['self'],[None],[None],715,[],"['get_gitignore_template', 'isinstance', 'GitignoreTemplate.GitignoreTemplate']",3
github/MainClass.py:Github:get_emojis,Github:get_emojis,method,4,6,5,89,14.83,0,0,['self'],[None],[None],728,"['        """"""\n', '        :calls: `GET /emojis <http://docs.github.com/en/rest/reference/emojis>`_\n', '        :rtype: dictionary of type => url for emoji`\n', '        """"""\n']",[],0
github/MainClass.py:Github:create_from_raw_data,Github:create_from_raw_data,method,2,5,5,61,12.2,0,0,"['self', 'klass', 'raw_data', 'headers']","[None, None, None, None]","[None, None, None, '{}']",736,"['        """"""\n', '        Creates an object from raw_data previously obtained by :attr:`github.GithubObject.GithubObject.raw_data`,\n', '        and optionally headers previously obtained by :attr:`github.GithubObject.GithubObject.raw_headers`.\n', '\n', '        :param klass: the class of the object to create\n', '        :param raw_data: dict\n', '        :param headers: dict\n', '        :rtype: instance of class ``klass``\n', '        """"""\n']",['klass'],1
github/MainClass.py:Github:dump,Github:dump,method,1,5,5,71,14.2,0,0,"['self', 'obj', 'file', 'protocol']","[None, None, None, None]","[None, None, None, '0']",748,"['        """"""\n', '        Dumps (pickles) a PyGithub object to a file-like object.\n', '        Some effort is made to not pickle sensitive information like the Github credentials used in the :class:`Github` instance.\n', ""        But NO EFFORT is made to remove sensitive information from the object's attributes.\n"", '\n', '        :param obj: the object to pickle\n', '        :param file: the file-like object to pickle to\n', '        :param protocol: the `pickling protocol <http://docs.python.org/2.7/library/pickle.html#data-stream-format>`_\n', '        """"""\n']",['pickle.dump'],1
github/MainClass.py:Github:load,Github:load,method,2,2,2,48,24.0,0,0,"['self', 'f']","[None, None]","[None, None]",760,"['        """"""\n', '        Loads (unpickles) a PyGithub object from a file-like object.\n', '\n', '        :param f: the file-like object to unpickle from\n', '        :return: the unpickled object\n', '        """"""\n']",['self.create_from_raw_data'],1
github/MainClass.py:Github:get_oauth_application,Github:get_oauth_application,method,2,10,10,162,16.2,0,0,"['self', 'client_id', 'client_secret']","[None, None, None]","[None, None, None]",769,[],[],0
github/MainClass.py:Github:get_app,Github:get_app,method,9,30,26,332,11.07,0,1,"['self', 'slug']","[None, None]","[None, 'github.GithubObject.NotSet']",777,"['        """"""\n', '        :calls: `GET /apps/{slug} <https://docs.github.com/en/rest/reference/apps>`_ or `GET /app <https://docs.github.com/en/rest/reference/apps>`_\n', '        :param slug: string\n', '        :rtype: :class:`github.GithubApp.GithubApp`\n', '        """"""\n']","['isinstance', 'GithubApp.GithubApp']",2
github/MainClass.py:GithubIntegration:__init__,GithubIntegration:__init__,method,7,10,10,126,12.6,0,0,"['self', 'integration_id', 'private_key', 'base_url']","[None, None, None, None]","[None, None, None, 'DEFAULT_BASE_URL']",798,"['        """"""\n', '        :param base_url: string\n', '        :param integration_id: int\n', '        :param private_key: string\n', '        """"""\n']",['isinstance'],1
github/MainClass.py:GithubIntegration:create_jwt,GithubIntegration:create_jwt,method,7,21,18,239,11.38,0,1,"['self', 'expiration']","[None, None]","[None, '60']",809,"['        """"""\n', '        Creates a signed JWT, valid for 60 seconds by default.\n', '        The expiration can be extended beyond this, to a maximum of 600 seconds.\n', '\n', '        :param expiration: int\n', '        :return string:\n', '        """"""\n']","['int', 'jwt.encode', 'isinstance', 'encrypted.decode']",4
github/MainClass.py:GithubIntegration:get_access_token,GithubIntegration:get_access_token,method,12,66,45,878,13.3,0,2,"['self', 'installation_id', 'user_id']","[None, None, None]","[None, None, 'None']",826,"['        """"""\n', '        Get an access token for the given installation id.\n', '        POSTs https://api.github.com/app/installations/<installation_id>/access_tokens\n', '        :param user_id: int\n', '        :param installation_id: int\n', '        :return: :class:`github.InstallationAuthorization.InstallationAuthorization`\n', '        """"""\n']","['requests.post', 'InstallationAuthorization.InstallationAuthorization', 'GithubException.BadCredentialsException', 'GithubException.UnknownObjectException', 'GithubException.GithubException']",5
github/MainClass.py:GithubIntegration:get_installation,GithubIntegration:get_installation,method,8,22,22,325,14.77,0,0,"['self', 'owner', 'repo']","[None, None, None]","[None, None, None]",866,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/installation <https://docs.github.com/en/rest/reference/apps#get-a-repository-installation>`_\n', '        :param owner: str\n', '        :param repo: str\n', '        :rtype: :class:`github.Installation.Installation`\n', '        """"""\n']","['requests.get', 'response.json', 'Installation.Installation']",3
github/Membership.py:Membership,Membership,class,27,126,59,1622,12.87,0,6,[],[],[],44,[],[],0
github/Membership.py:Membership:__repr__,Membership:__repr__,method,2,3,3,47,15.67,0,0,['self'],[None],[None],49,[],['self.get__repr__'],1
github/Membership.py:Membership:url,Membership:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Membership.py:Membership:state,Membership:state,method,3,3,3,59,19.67,0,0,['self'],[None],[None],61,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Membership.py:Membership:role,Membership:role,method,3,3,3,57,19.0,0,0,['self'],[None],[None],69,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Membership.py:Membership:organization_url,Membership:organization_url,method,3,3,3,81,27.0,0,0,['self'],[None],[None],77,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Membership.py:Membership:organization,Membership:organization,method,3,3,3,81,27.0,0,0,['self'],[None],[None],85,"['        """"""\n', '        :type: :class:`github.Organization.Organization`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Membership.py:Membership:user,Membership:user,method,3,3,3,57,19.0,0,0,['self'],[None],[None],93,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Membership.py:Membership:_initAttributes,Membership:_initAttributes,method,7,12,8,247,20.58,0,0,['self'],[None],[None],100,[],[],0
github/Membership.py:Membership:_useAttributes,Membership:_useAttributes,method,8,68,31,687,10.1,0,6,"['self', 'attributes']","[None, None]","[None, None]",108,[],"['self._makeStringAttribute', 'self._makeClassAttribute']",2
github/Migration.py:Migration,Migration,class,54,211,102,3256,15.43,0,10,[],[],[],40,[],[],0
github/Migration.py:Migration:__repr__,Migration:__repr__,method,2,5,5,73,14.6,0,0,['self'],[None],[None],45,[],['self.get__repr__'],1
github/Migration.py:Migration:id,Migration:id,method,2,2,2,20,10.0,0,0,['self'],[None],[None],49,"['        """"""\n', '        :type: int\n', '        """"""\n']",[],0
github/Migration.py:Migration:owner,Migration:owner,method,3,3,3,59,19.67,0,0,['self'],[None],[None],56,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Migration.py:Migration:guid,Migration:guid,method,3,3,3,57,19.0,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: str\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Migration.py:Migration:state,Migration:state,method,3,3,3,58,19.33,0,0,['self'],[None],[None],72,"['        """"""\n', '        :type: str\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Migration.py:Migration:lock_repositories,Migration:lock_repositories,method,3,3,3,78,26.0,0,0,['self'],[None],[None],80,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Migration.py:Migration:exclude_attachments,Migration:exclude_attachments,method,3,3,3,87,29.0,0,0,['self'],[None],[None],88,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Migration.py:Migration:repositories,Migration:repositories,method,3,3,3,73,24.33,0,0,['self'],[None],[None],96,"['        """"""\n', '        :type: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Migration.py:Migration:url,Migration:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],104,"['        """"""\n', '        :type: str\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Migration.py:Migration:created_at,Migration:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],112,"['        """"""\n', '        :type: datetime.datetime\n', '        :rtype: None\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Migration.py:Migration:updated_at,Migration:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],121,"['        """"""\n', '        :type: datetime.datetime\n', '        :rtype: None\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Migration.py:Migration:get_status,Migration:get_status,method,6,11,11,161,14.64,0,0,['self'],[None],[None],129,"['        """"""\n', '        :calls: `GET /user/migrations/{migration_id} <https://docs.github.com/en/rest/reference/migrations>`_\n', '        :rtype: str\n', '        """"""\n']",['self._useAttributes'],1
github/Migration.py:Migration:get_archive_url,Migration:get_archive_url,method,5,10,10,153,15.3,0,0,['self'],[None],[None],140,"['        """"""\n', '        :calls: `GET /user/migrations/{migration_id}/archive <https://docs.github.com/en/rest/reference/migrations>`_\n', '        :rtype: str\n', '        """"""\n']",[],0
github/Migration.py:Migration:delete,Migration:delete,method,3,8,8,137,17.12,0,0,['self'],[None],[None],152,"['        """"""\n', '        :calls: `DELETE /user/migrations/{migration_id}/archive <https://docs.github.com/en/rest/reference/migrations>`_\n', '        """"""\n']",[],0
github/Migration.py:Migration:unlock_repo,Migration:unlock_repo,method,4,12,12,194,16.17,0,0,"['self', 'repo_name']","[None, None]","[None, None]",162,"['        """"""\n', '        :calls: `DELETE /user/migrations/{migration_id}/repos/{repo_name}/lock <https://docs.github.com/en/rest/reference/migrations>`_\n', '        :param repo_name: str\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/Migration.py:Migration:_initAttributes,Migration:_initAttributes,method,11,20,12,426,21.3,0,0,['self'],[None],[None],175,[],[],0
github/Migration.py:Migration:_useAttributes,Migration:_useAttributes,method,16,70,39,997,14.24,0,10,"['self', 'attributes']","[None, None]","[None, None]",187,[],"['self._makeIntAttribute', 'self._makeClassAttribute', 'self._makeStringAttribute', 'self._makeBoolAttribute', 'self._makeListOfClassesAttribute', 'self._makeDatetimeAttribute']",6
github/Milestone.py:Milestone,Milestone,class,66,345,155,4384,12.71,0,16,[],[],[],39,[],[],0
github/Milestone.py:Milestone:__repr__,Milestone:__repr__,method,2,7,7,81,11.57,0,0,['self'],[None],[None],44,[],['self.get__repr__'],1
github/Milestone.py:Milestone:closed_issues,Milestone:closed_issues,method,3,3,3,75,25.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:created_at,Milestone:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],58,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:creator,Milestone:creator,method,3,3,3,63,21.0,0,0,['self'],[None],[None],66,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:description,Milestone:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],74,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:due_on,Milestone:due_on,method,3,3,3,61,20.33,0,0,['self'],[None],[None],82,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:id,Milestone:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],90,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:labels_url,Milestone:labels_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],98,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:number,Milestone:number,method,3,3,3,61,20.33,0,0,['self'],[None],[None],106,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:open_issues,Milestone:open_issues,method,3,3,3,71,23.67,0,0,['self'],[None],[None],114,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:state,Milestone:state,method,3,3,3,59,19.67,0,0,['self'],[None],[None],122,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:title,Milestone:title,method,3,3,3,59,19.67,0,0,['self'],[None],[None],130,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:updated_at,Milestone:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],138,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:url,Milestone:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],146,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Milestone.py:Milestone:delete,Milestone:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],153,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/milestones/{number} <http://docs.github.com/en/rest/reference/issues#milestones>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Milestone.py:Milestone:edit,Milestone:edit,method,14,66,40,682,10.33,0,3,"['self', 'title', 'state', 'description', 'due_on', '']","[None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",160,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/milestones/{number} <http://docs.github.com/en/rest/reference/issues#milestones>`_\n', '        :param title: string\n', '        :param state: string\n', '        :param description: string\n', '        :param due_on: date\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'due_on.strftime', 'self._useAttributes']",3
github/Milestone.py:Milestone:get_labels,Milestone:get_labels,method,2,7,7,104,14.86,0,0,['self'],[None],[None],197,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/milestones/{number}/labels <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Label.Label`\n', '        """"""\n']",[],0
github/Milestone.py:Milestone:_identity,Milestone:_identity,method,2,2,2,17,8.5,0,0,['self'],[None],[None],207,[],[],0
github/Milestone.py:Milestone:_initAttributes,Milestone:_initAttributes,method,14,26,15,540,20.77,0,0,['self'],[None],[None],210,[],[],0
github/Milestone.py:Milestone:_useAttributes,Milestone:_useAttributes,method,17,133,49,1384,10.41,0,13,"['self', 'attributes']","[None, None]","[None, None]",225,[],"['self._makeIntAttribute', 'self._makeDatetimeAttribute', 'self._makeClassAttribute', 'self._makeStringAttribute']",4
github/NamedUser.py:NamedUser,NamedUser,class,195,1138,431,15635,13.74,0,50,[],[],[],53,[],[],0
github/NamedUser.py:NamedUser:__repr__,NamedUser:__repr__,method,2,3,3,51,17.0,0,0,['self'],[None],[None],58,[],['self.get__repr__'],1
github/NamedUser.py:NamedUser:node_id,NamedUser:node_id,method,3,3,3,63,21.0,0,0,['self'],[None],[None],62,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:twitter_username,NamedUser:twitter_username,method,3,3,3,81,27.0,0,0,['self'],[None],[None],70,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:__hash__,NamedUser:__hash__,method,2,3,3,32,10.67,0,0,['self'],[None],[None],77,[],['hash'],1
github/NamedUser.py:NamedUser:__eq__,NamedUser:__eq__,method,6,11,10,86,7.82,0,0,"['self', 'other']","[None, None]","[None, None]",80,[],"['isinstance', 'type']",2
github/NamedUser.py:NamedUser:avatar_url,NamedUser:avatar_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],88,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:bio,NamedUser:bio,method,3,3,3,55,18.33,0,0,['self'],[None],[None],96,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:blog,NamedUser:blog,method,3,3,3,57,19.0,0,0,['self'],[None],[None],104,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:collaborators,NamedUser:collaborators,method,3,3,3,75,25.0,0,0,['self'],[None],[None],112,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:company,NamedUser:company,method,3,3,3,63,21.0,0,0,['self'],[None],[None],120,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:contributions,NamedUser:contributions,method,3,3,3,75,25.0,0,0,['self'],[None],[None],128,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:created_at,NamedUser:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],136,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:disk_usage,NamedUser:disk_usage,method,3,3,3,69,23.0,0,0,['self'],[None],[None],144,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:email,NamedUser:email,method,3,3,3,59,19.67,0,0,['self'],[None],[None],152,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:events_url,NamedUser:events_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],160,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:followers,NamedUser:followers,method,3,3,3,67,22.33,0,0,['self'],[None],[None],168,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:followers_url,NamedUser:followers_url,method,3,3,3,75,25.0,0,0,['self'],[None],[None],176,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:following,NamedUser:following,method,3,3,3,67,22.33,0,0,['self'],[None],[None],184,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:following_url,NamedUser:following_url,method,3,3,3,75,25.0,0,0,['self'],[None],[None],192,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:gists_url,NamedUser:gists_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],200,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:gravatar_id,NamedUser:gravatar_id,method,3,3,3,71,23.67,0,0,['self'],[None],[None],208,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:hireable,NamedUser:hireable,method,3,3,3,65,21.67,0,0,['self'],[None],[None],216,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:html_url,NamedUser:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],224,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:id,NamedUser:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],232,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:invitation_teams_url,NamedUser:invitation_teams_url,method,3,3,3,89,29.67,0,0,['self'],[None],[None],240,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:inviter,NamedUser:inviter,method,3,3,3,63,21.0,0,0,['self'],[None],[None],248,"['        """"""\n', '        :type: github.NamedUser.NamedUser\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:location,NamedUser:location,method,3,3,3,65,21.67,0,0,['self'],[None],[None],256,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:login,NamedUser:login,method,3,3,3,59,19.67,0,0,['self'],[None],[None],264,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:name,NamedUser:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],272,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:organizations_url,NamedUser:organizations_url,method,3,3,3,83,27.67,0,0,['self'],[None],[None],280,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:owned_private_repos,NamedUser:owned_private_repos,method,3,3,3,87,29.0,0,0,['self'],[None],[None],288,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:permissions,NamedUser:permissions,method,3,3,3,71,23.67,0,0,['self'],[None],[None],296,"['        """"""\n', '        :type: :class:`github.Permissions.Permissions`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:plan,NamedUser:plan,method,3,3,3,57,19.0,0,0,['self'],[None],[None],304,"['        """"""\n', '        :type: :class:`github.Plan.Plan`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:private_gists,NamedUser:private_gists,method,3,3,3,75,25.0,0,0,['self'],[None],[None],312,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:public_gists,NamedUser:public_gists,method,3,3,3,73,24.33,0,0,['self'],[None],[None],320,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:public_repos,NamedUser:public_repos,method,3,3,3,73,24.33,0,0,['self'],[None],[None],328,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:received_events_url,NamedUser:received_events_url,method,3,3,3,87,29.0,0,0,['self'],[None],[None],336,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:repos_url,NamedUser:repos_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],344,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:role,NamedUser:role,method,3,3,3,57,19.0,0,0,['self'],[None],[None],352,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:site_admin,NamedUser:site_admin,method,3,3,3,69,23.0,0,0,['self'],[None],[None],360,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:starred_url,NamedUser:starred_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],368,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:subscriptions_url,NamedUser:subscriptions_url,method,3,3,3,83,27.67,0,0,['self'],[None],[None],376,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:suspended_at,NamedUser:suspended_at,method,3,3,3,73,24.33,0,0,['self'],[None],[None],384,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:team_count,NamedUser:team_count,method,3,3,3,69,23.0,0,0,['self'],[None],[None],392,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:total_private_repos,NamedUser:total_private_repos,method,3,3,3,87,29.0,0,0,['self'],[None],[None],400,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:type,NamedUser:type,method,3,3,3,57,19.0,0,0,['self'],[None],[None],408,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:updated_at,NamedUser:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],416,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:url,NamedUser:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],424,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/NamedUser.py:NamedUser:get_events,NamedUser:get_events,method,2,7,7,104,14.86,0,0,['self'],[None],[None],431,"['        """"""\n', '        :calls: `GET /users/{user}/events <http://docs.github.com/en/rest/reference/activity#events>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Event.Event`\n', '        """"""\n']",[],0
github/NamedUser.py:NamedUser:get_followers,NamedUser:get_followers,method,2,7,7,98,14.0,0,0,['self'],[None],[None],440,"['        """"""\n', '        :calls: `GET /users/{user}/followers <http://docs.github.com/en/rest/reference/users#followers>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/NamedUser.py:NamedUser:get_following,NamedUser:get_following,method,2,7,7,98,14.0,0,0,['self'],[None],[None],449,"['        """"""\n', '        :calls: `GET /users/{user}/following <http://docs.github.com/en/rest/reference/users#followers>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/NamedUser.py:NamedUser:get_gists,NamedUser:get_gists,method,9,26,24,319,12.27,0,1,"['self', 'since']","[None, None]","[None, 'github.GithubObject.NotSet']",458,"['        """"""\n', '        :calls: `GET /users/{user}/gists <http://docs.github.com/en/rest/reference/gists>`_\n', '        :param since: datetime.datetime format YYYY-MM-DDTHH:MM:SSZ\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Gist.Gist`\n', '        """"""\n']","['isinstance', 'dict', 'since.strftime']",3
github/NamedUser.py:NamedUser:get_keys,NamedUser:get_keys,method,2,7,7,106,15.14,0,0,['self'],[None],[None],474,"['        """"""\n', '        :calls: `GET /users/{user}/keys <http://docs.github.com/en/rest/reference/users#keys>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.UserKey.UserKey`\n', '        """"""\n']",[],0
github/NamedUser.py:NamedUser:get_orgs,NamedUser:get_orgs,method,2,7,7,116,16.57,0,0,['self'],[None],[None],483,"['        """"""\n', '        :calls: `GET /users/{user}/orgs <http://docs.github.com/en/rest/reference/orgs>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Organization.Organization`\n', '        """"""\n']",[],0
github/NamedUser.py:NamedUser:get_projects,NamedUser:get_projects,method,4,16,16,241,15.06,0,0,"['self', 'state']","[None, None]","[None, '""open""']",492,"['        """"""\n', '        :calls: `GET /users/{user}/projects <https://docs.github.com/en/rest/reference/projects#list-user-projects>`_\n', '        :param state: string\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Project.Project`\n', '        """"""\n']",['isinstance'],1
github/NamedUser.py:NamedUser:get_public_events,NamedUser:get_public_events,method,2,7,7,111,15.86,0,0,['self'],[None],[None],508,"['        """"""\n', '        :calls: `GET /users/{user}/events/public <http://docs.github.com/en/rest/reference/activity#events>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Event.Event`\n', '        """"""\n']",[],0
github/NamedUser.py:NamedUser:get_public_received_events,NamedUser:get_public_received_events,method,2,7,7,124,17.71,0,0,['self'],[None],[None],517,"['        """"""\n', '        :calls: `GET /users/{user}/received_events/public <http://docs.github.com/en/rest/reference/activity#events>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Event.Event`\n', '        """"""\n']",[],0
github/NamedUser.py:NamedUser:get_received_events,NamedUser:get_received_events,method,2,7,7,113,16.14,0,0,['self'],[None],[None],529,"['        """"""\n', '        :calls: `GET /users/{user}/received_events <http://docs.github.com/en/rest/reference/activity#events>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Event.Event`\n', '        """"""\n']",[],0
github/NamedUser.py:NamedUser:get_repo,NamedUser:get_repo,method,7,23,21,325,14.13,0,0,"['self', 'name']","[None, None]","[None, None]",538,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo} <http://docs.github.com/en/rest/reference/repos>`_\n', '        :param name: string\n', '        :rtype: :class:`github.Repository.Repository`\n', '        """"""\n']","['isinstance', 'get_repos']",2
github/NamedUser.py:NamedUser:get_repos,NamedUser:get_repos,method,10,56,32,580,10.36,0,3,"['self', 'type', 'sort', 'direction', '']","[None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",552,"['        """"""\n', '        :calls: `GET /users/{user}/repos <http://docs.github.com/en/rest/reference/repos>`_\n', '        :param type: string\n', '        :param sort: string\n', '        :param direction: string\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']","['isinstance', 'dict']",2
github/NamedUser.py:NamedUser:get_starred,NamedUser:get_starred,method,2,7,7,115,16.43,0,0,['self'],[None],[None],584,"['        """"""\n', '        :calls: `GET /users/{user}/starred <http://docs.github.com/en/rest/reference/activity#starring>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']",[],0
github/NamedUser.py:NamedUser:get_subscriptions,NamedUser:get_subscriptions,method,2,7,7,125,17.86,0,0,['self'],[None],[None],593,"['        """"""\n', '        :calls: `GET /users/{user}/subscriptions <http://docs.github.com/en/rest/reference/activity#watching>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']",[],0
github/NamedUser.py:NamedUser:get_watched,NamedUser:get_watched,method,2,7,7,115,16.43,0,0,['self'],[None],[None],605,"['        """"""\n', '        :calls: `GET /users/{user}/watched <http://docs.github.com/en/rest/reference/activity#starring>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']",[],0
github/NamedUser.py:NamedUser:has_in_following,NamedUser:has_in_following,method,7,14,14,185,13.21,0,0,"['self', 'following']","[None, None]","[None, None]",614,"['        """"""\n', '        :calls: `GET /users/{user}/following/{target_user} <http://docs.github.com/en/rest/reference/users/followers#check-if-one-user-follows-another>`_\n', '        :param following: :class:`github.NamedUser.NamedUser`\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/NamedUser.py:NamedUser:_identity,NamedUser:_identity,method,2,2,2,16,8.0,0,0,['self'],[None],[None],627,[],[],0
github/NamedUser.py:NamedUser:get_organization_membership,NamedUser:get_organization_membership,method,10,27,25,327,12.11,0,1,"['self', 'org']","[None, None]","[None, None]",630,"['        """"""\n', '        :calls: `GET /orgs/{org}/memberships/{username} <https://docs.github.com/en/rest/reference/orgs/members#get-organization-membership>`_\n', '        :param org: string or :class:`github.Organization.Organization`\n', '        :rtype: :class:`github.Membership.Membership`\n', '        """"""\n']",['isinstance'],1
github/NamedUser.py:NamedUser:_initAttributes,NamedUser:_initAttributes,method,46,90,47,1979,21.99,0,0,['self'],[None],[None],648,[],[],0
github/NamedUser.py:NamedUser:_useAttributes,NamedUser:_useAttributes,method,50,467,150,5080,10.88,0,45,"['self', 'attributes']","[None, None]","[None, None]",695,[],"['self._makeStringAttribute', 'self._makeIntAttribute', 'self._makeDatetimeAttribute', 'self._makeBoolAttribute', 'self._makeClassAttribute']",5
github/Notification.py:Notification,Notification,class,46,212,94,2825,13.33,0,9,[],[],[],35,[],[],0
github/Notification.py:Notification:__repr__,Notification:__repr__,method,2,5,5,75,15.0,0,0,['self'],[None],[None],40,[],['self.get__repr__'],1
github/Notification.py:Notification:id,Notification:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],44,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Notification.py:Notification:last_read_at,Notification:last_read_at,method,3,3,3,73,24.33,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Notification.py:Notification:repository,Notification:repository,method,3,3,3,69,23.0,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Notification.py:Notification:subject,Notification:subject,method,3,3,3,63,21.0,0,0,['self'],[None],[None],68,"['        """"""\n', '        :type: :class:`github.NotificationSubject.NotificationSubject`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Notification.py:Notification:reason,Notification:reason,method,3,3,3,61,20.33,0,0,['self'],[None],[None],76,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Notification.py:Notification:subscription_url,Notification:subscription_url,method,3,3,3,81,27.0,0,0,['self'],[None],[None],84,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Notification.py:Notification:unread,Notification:unread,method,3,3,3,61,20.33,0,0,['self'],[None],[None],92,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Notification.py:Notification:updated_at,Notification:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],100,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Notification.py:Notification:url,Notification:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],108,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Notification.py:Notification:mark_as_read,Notification:mark_as_read,method,3,6,6,70,11.67,0,0,['self'],[None],[None],115,"['        """"""\n', '        :calls: `PATCH /notifications/threads/{id} <https://docs.github.com/en/rest/reference/activity#notifications>`_\n', '        """"""\n']",[],0
github/Notification.py:Notification:get_pull_request,Notification:get_pull_request,method,5,11,10,156,14.18,0,0,['self'],[None],[None],124,"['        """"""\n', '        :type: :class:github.PullRequest.PullRequest\n', '        """"""\n']",[],0
github/Notification.py:Notification:get_issue,Notification:get_issue,method,5,9,8,142,15.78,0,0,['self'],[None],[None],133,"['        """"""\n', '        :type: :class:github.Issue.Issue\n', '        """"""\n']",[],0
github/Notification.py:Notification:_initAttributes,Notification:_initAttributes,method,9,16,10,336,21.0,0,0,['self'],[None],[None],140,[],[],0
github/Notification.py:Notification:_useAttributes,Notification:_useAttributes,method,13,98,39,1035,10.56,0,9,"['self', 'attributes']","[None, None]","[None, None]",150,[],"['self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeClassAttribute', 'self._makeBoolAttribute']",4
github/NotificationSubject.py:NotificationSubject,NotificationSubject,class,19,80,39,938,11.72,0,4,[],[],[],32,[],[],0
github/NotificationSubject.py:NotificationSubject:__repr__,NotificationSubject:__repr__,method,2,3,3,51,17.0,0,0,['self'],[None],[None],37,[],['self.get__repr__'],1
github/NotificationSubject.py:NotificationSubject:title,NotificationSubject:title,method,2,2,2,23,11.5,0,0,['self'],[None],[None],41,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/NotificationSubject.py:NotificationSubject:url,NotificationSubject:url,method,2,2,2,21,10.5,0,0,['self'],[None],[None],48,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/NotificationSubject.py:NotificationSubject:latest_comment_url,NotificationSubject:latest_comment_url,method,2,2,2,36,18.0,0,0,['self'],[None],[None],55,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/NotificationSubject.py:NotificationSubject:type,NotificationSubject:type,method,2,2,2,22,11.0,0,0,['self'],[None],[None],62,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/NotificationSubject.py:NotificationSubject:_initAttributes,NotificationSubject:_initAttributes,method,5,8,6,165,20.62,0,0,['self'],[None],[None],68,[],[],0
github/NotificationSubject.py:NotificationSubject:_useAttributes,NotificationSubject:_useAttributes,method,5,42,21,419,9.98,0,4,"['self', 'attributes']","[None, None]","[None, None]",74,[],['self._makeStringAttribute'],1
github/Organization.py:Organization,Organization,class,224,2213,665,28550,12.9,1,88,[],[],[],56,[],[],0
github/Organization.py:Organization:__repr__,Organization:__repr__,method,2,3,3,51,17.0,0,0,['self'],[None],[None],61,[],['self.get__repr__'],1
github/Organization.py:Organization:avatar_url,Organization:avatar_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],65,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:billing_email,Organization:billing_email,method,3,3,3,75,25.0,0,0,['self'],[None],[None],73,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:blog,Organization:blog,method,3,3,3,57,19.0,0,0,['self'],[None],[None],81,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:collaborators,Organization:collaborators,method,3,3,3,75,25.0,0,0,['self'],[None],[None],89,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:company,Organization:company,method,3,3,3,63,21.0,0,0,['self'],[None],[None],97,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:created_at,Organization:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],105,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:default_repository_permission,Organization:default_repository_permission,method,3,3,3,107,35.67,0,0,['self'],[None],[None],113,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:description,Organization:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],121,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:disk_usage,Organization:disk_usage,method,3,3,3,69,23.0,0,0,['self'],[None],[None],129,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:email,Organization:email,method,3,3,3,59,19.67,0,0,['self'],[None],[None],137,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:events_url,Organization:events_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],145,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:followers,Organization:followers,method,3,3,3,67,22.33,0,0,['self'],[None],[None],153,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:following,Organization:following,method,3,3,3,67,22.33,0,0,['self'],[None],[None],161,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:gravatar_id,Organization:gravatar_id,method,3,3,3,71,23.67,0,0,['self'],[None],[None],169,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:has_organization_projects,Organization:has_organization_projects,method,3,3,3,99,33.0,0,0,['self'],[None],[None],177,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:has_repository_projects,Organization:has_repository_projects,method,3,3,3,95,31.67,0,0,['self'],[None],[None],185,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:hooks_url,Organization:hooks_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],193,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:html_url,Organization:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],201,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:id,Organization:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],209,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:issues_url,Organization:issues_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],217,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:location,Organization:location,method,3,3,3,65,21.67,0,0,['self'],[None],[None],225,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:login,Organization:login,method,3,3,3,59,19.67,0,0,['self'],[None],[None],233,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:members_can_create_repositories,Organization:members_can_create_repositories,method,3,3,3,111,37.0,0,0,['self'],[None],[None],241,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:members_url,Organization:members_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],249,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:name,Organization:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],257,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:owned_private_repos,Organization:owned_private_repos,method,3,3,3,87,29.0,0,0,['self'],[None],[None],265,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:plan,Organization:plan,method,3,3,3,57,19.0,0,0,['self'],[None],[None],273,"['        """"""\n', '        :type: :class:`github.Plan.Plan`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:private_gists,Organization:private_gists,method,3,3,3,75,25.0,0,0,['self'],[None],[None],281,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:public_gists,Organization:public_gists,method,3,3,3,73,24.33,0,0,['self'],[None],[None],289,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:public_members_url,Organization:public_members_url,method,3,3,3,85,28.33,0,0,['self'],[None],[None],297,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:public_repos,Organization:public_repos,method,3,3,3,73,24.33,0,0,['self'],[None],[None],305,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:repos_url,Organization:repos_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],313,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:total_private_repos,Organization:total_private_repos,method,3,3,3,87,29.0,0,0,['self'],[None],[None],321,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:two_factor_requirement_enabled,Organization:two_factor_requirement_enabled,method,3,3,3,109,36.33,0,0,['self'],[None],[None],329,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:type,Organization:type,method,3,3,3,57,19.0,0,0,['self'],[None],[None],337,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:updated_at,Organization:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],345,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:url,Organization:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],353,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Organization.py:Organization:add_to_members,Organization:add_to_members,method,9,28,24,333,11.89,0,1,"['self', 'member', 'role']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",360,"['        """"""\n', '        :calls: `PUT /orgs/{org}/memberships/{user} <https://docs.github.com/en/rest/reference/orgs/members#add-or-update-organization-membership>`_\n', '        :param member: :class:`github.NamedUser.NamedUser`\n', '        :param role: string\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:add_to_public_members,Organization:add_to_public_members,method,4,10,10,185,18.5,0,0,"['self', 'public_member']","[None, None]","[None, None]",376,"['        """"""\n', '        :calls: `PUT /orgs/{org}/public_members/{user} <http://docs.github.com/en/rest/reference/orgs#members>`_\n', '        :param public_member: :class:`github.NamedUser.NamedUser`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:create_fork,Organization:create_fork,method,7,23,22,310,13.48,0,0,"['self', 'repo']","[None, None]","[None, None]",387,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/forks <http://docs.github.com/en/rest/reference/repos#forks>`_\n', '        :param repo: :class:`github.Repository.Repository`\n', '        :rtype: :class:`github.Repository.Repository`\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:create_hook,Organization:create_hook,method,13,63,46,606,9.62,0,2,"['self', 'name', 'config', 'events', 'active', '']","[None, None, None, None, None, None]","[None, None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",406,"['        """"""\n', '        :calls: `POST /orgs/{owner}/hooks <http://docs.github.com/en/rest/reference/orgs#hooks>`_\n', '        :param name: string\n', '        :param config: dict\n', '        :param events: list of string\n', '        :param active: bool\n', '        :rtype: :class:`github.Hook.Hook`\n', '        """"""\n']","['isinstance', 'all']",2
github/Organization.py:Organization:create_project,Organization:create_project,method,11,36,30,428,11.89,0,1,"['self', 'name', 'body']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",440,"['        """"""\n', '        :calls: `POST /orgs/{org}/projects <https://docs.github.com/en/rest/reference/projects#create-an-organization-project>`_\n', '        :param name: string\n', '        :param body: string\n', '        :rtype: :class:`github.Project.Project`\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:create_repo,Organization:create_repo,method,25,278,93,3107,11.18,0,15,"['self', 'name', 'description', 'homepage', 'private', 'has_issues', 'has_wiki', 'has_downloads', 'has_projects', 'team_id', 'auto_init', 'license_template', 'gitignore_template', 'allow_squash_merge', 'allow_merge_commit', 'allow_rebase_merge', 'delete_branch_on_merge', '']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",460,"['        """"""\n', '        :calls: `POST /orgs/{org}/repos <http://docs.github.com/en/rest/reference/repos>`_\n', '        :param name: string\n', '        :param description: string\n', '        :param homepage: string\n', '        :param private: bool\n', '        :param has_issues: bool\n', '        :param has_wiki: bool\n', '        :param has_downloads: bool\n', '        :param has_projects: bool\n', '        :param team_id: : int\n', '        :param auto_init: bool\n', '        :param license_template: string\n', '        :param gitignore_template: string\n', '        :param allow_squash_merge: bool\n', '        :param allow_merge_commit: bool\n', '        :param allow_rebase_merge: bool\n', '        :param delete_branch_on_merge: bool\n', '        :rtype: :class:`github.Repository.Repository`\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:create_team,Organization:create_team,method,17,99,53,991,10.01,1,4,"['self', 'name', 'repo_names', 'permission', 'privacy', 'description', '']","[None, None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",585,"['        """"""\n', '        :calls: `POST /orgs/{org}/teams <http://docs.github.com/en/rest/reference/orgs#teams>`_\n', '        :param name: string\n', '        :param repo_names: list of :class:`github.Repository.Repository`\n', '        :param permission: string\n', '        :param privacy: string\n', '        :param description: string\n', '        :rtype: :class:`github.Team.Team`\n', '        """"""\n']","['isinstance', 'all']",2
github/Organization.py:Organization:delete_hook,Organization:delete_hook,method,4,10,10,113,11.3,0,0,"['self', 'id']","[None, None]","[None, None]",633,"['        """"""\n', '        :calls: `DELETE /orgs/{owner}/hooks/{id} <http://docs.github.com/en/rest/reference/orgs#hooks>`_\n', '        :param id: integer\n', '        :rtype: None`\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:edit,Organization:edit,method,17,131,57,1337,10.21,0,7,"['self', 'billing_email', 'blog', 'company', 'description', 'email', 'location', 'name', '']","[None, None, None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",644,[],"['isinstance', 'dict', 'self._useAttributes', 'edit_hook']",4
github/Organization.py:Organization:edit_hook,Organization:edit_hook,method,13,67,49,640,9.55,0,2,"['self', 'id', 'name', 'config', 'events', 'active', '']","[None, None, None, None, None, None, None]","[None, None, None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",700,"['        """"""\n', '        :calls: `PATCH /orgs/{owner}/hooks/{id} <http://docs.github.com/en/rest/reference/orgs#hooks>`_\n', '        :param id: integer\n', '        :param name: string\n', '        :param config: dict\n', '        :param events: list of string\n', '        :param active: bool\n', '        :rtype: :class:`github.Hook.Hook`\n', '        """"""\n']","['isinstance', 'all']",2
github/Organization.py:Organization:get_events,Organization:get_events,method,2,7,7,104,14.86,0,0,['self'],[None],[None],737,"['        """"""\n', '        :calls: `GET /orgs/{org}/events <http://docs.github.com/en/rest/reference/activity#events>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Event.Event`\n', '        """"""\n']",[],0
github/Organization.py:Organization:get_hook,Organization:get_hook,method,8,24,22,300,12.5,0,0,"['self', 'id']","[None, None]","[None, None]",746,"['        """"""\n', '        :calls: `GET /orgs/{owner}/hooks/{id} <http://docs.github.com/en/rest/reference/orgs#hooks>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.Hook.Hook`\n', '        """"""\n']","['isinstance', 'get_hooks']",2
github/Organization.py:Organization:get_hooks,Organization:get_hooks,method,2,7,7,101,14.43,0,0,['self'],[None],[None],758,"['        """"""\n', '        :calls: `GET /orgs/{owner}/hooks <http://docs.github.com/en/rest/reference/orgs#hooks>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Hook.Hook`\n', '        """"""\n']",[],0
github/Organization.py:Organization:get_issues,Organization:get_issues,method,18,113,54,1120,9.91,0,6,"['self', 'filter', 'state', 'labels', 'sort', 'direction', 'since', '']","[None, None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",767,"['        """"""\n', '        :calls: `GET /orgs/{org}/issues <http://docs.github.com/en/rest/reference/issues>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Issue.Issue`\n', '        :param filter: string\n', '        :param state: string\n', '        :param labels: list of :class:`github.Label.Label`\n', '        :param sort: string\n', '        :param direction: string\n', '        :param since: datetime.datetime\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Issue.Issue`\n', '        """"""\n']","['isinstance', 'all', 'dict', 'since.strftime']",4
github/Organization.py:Organization:get_members,Organization:get_members,method,10,41,28,430,10.49,0,2,"['self', 'filter_', 'role']","[None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet']",816,"['        """"""\n', '        :calls: `GET /orgs/{org}/members <http://docs.github.com/en/rest/reference/orgs#members>`_\n', '        :param filter_: string\n', '        :param role: string\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:get_projects,Organization:get_projects,method,6,18,18,260,14.44,0,1,"['self', 'state']","[None, None]","[None, 'github.GithubObject.NotSet']",842,"['        """"""\n', '        :calls: `GET /orgs/{org}/projects <https://docs.github.com/en/rest/reference/projects#list-organization-projects>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Project.Project`\n', '        :param state: string\n', '        """"""\n']",['dict'],1
github/Organization.py:Organization:get_public_members,Organization:get_public_members,method,2,7,7,124,17.71,0,0,['self'],[None],[None],861,"['        """"""\n', '        :calls: `GET /orgs/{org}/public_members <http://docs.github.com/en/rest/reference/orgs#members>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/Organization.py:Organization:get_outside_collaborators,Organization:get_outside_collaborators,method,8,26,23,311,11.96,0,1,"['self', 'filter_']","[None, None]","[None, 'github.GithubObject.NotSet']",873,"['        """"""\n', '        :calls: `GET /orgs/{org}/outside_collaborators <http://docs.github.com/en/rest/reference/orgs#outside_collaborators>`_\n', '        :param filter_: string\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:remove_outside_collaborator,Organization:remove_outside_collaborator,method,4,10,10,192,19.2,0,0,"['self', 'collaborator']","[None, None]","[None, None]",893,"['        """"""\n', '        :calls: `DELETE /orgs/{org}/outside_collaborators/{username} <https://docs.github.com/en/rest/reference/orgs#outside_collaborators>`_\n', '        :param collaborator: :class:`github.NamedUser.NamedUser`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:convert_to_outside_collaborator,Organization:convert_to_outside_collaborator,method,4,10,10,171,17.1,0,0,"['self', 'member']","[None, None]","[None, None]",904,"['        """"""\n', '        :calls: `PUT /orgs/{org}/outside_collaborators/{username} <https://docs.github.com/en/rest/reference/orgs#outside_collaborators>`_\n', '        :param member: :class:`github.NamedUser.NamedUser`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:get_repo,Organization:get_repo,method,7,23,21,325,14.13,0,0,"['self', 'name']","[None, None]","[None, None]",915,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo} <http://docs.github.com/en/rest/reference/repos>`_\n', '        :param name: string\n', '        :rtype: :class:`github.Repository.Repository`\n', '        """"""\n']","['isinstance', 'get_repos']",2
github/Organization.py:Organization:get_repos,Organization:get_repos,method,10,56,32,580,10.36,0,3,"['self', 'type', 'sort', 'direction', '']","[None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",929,"['        """"""\n', '        :calls: `GET /orgs/{org}/repos <http://docs.github.com/en/rest/reference/repos>`_\n', ""        :param type: string ('all', 'public', 'private', 'forks', 'sources', 'member')\n"", ""        :param sort: string ('created', 'updated', 'pushed', 'full_name')\n"", ""        :param direction: string ('asc', desc')\n"", '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Repository.Repository`\n', '        """"""\n']","['isinstance', 'dict']",2
github/Organization.py:Organization:get_team,Organization:get_team,method,9,40,29,505,12.62,0,0,"['self', 'id']","[None, None]","[None, None]",962,"['        """"""\n', '        :calls: `GET /teams/{id} <http://docs.github.com/en/rest/reference/orgs#teams>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.Team.Team`\n', '        """"""\n']","['isinstance', 'get_team_by_slug', 'get_teams']",3
github/Organization.py:Organization:get_team_by_slug,Organization:get_team_by_slug,method,6,15,14,184,12.27,0,0,"['self', 'slug']","[None, None]","[None, None]",972,"['        """"""\n', '        :calls: `GET /orgs/{org}/teams/{team_slug} <https://docs.github.com/en/rest/reference/teams>`_\n', '        :param slug: string\n', '        :rtype: :class:`github.Team.Team`\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:get_teams,Organization:get_teams,method,2,7,7,101,14.43,0,0,['self'],[None],[None],984,"['        """"""\n', '        :calls: `GET /orgs/{org}/teams <http://docs.github.com/en/rest/reference/orgs#teams>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Team.Team`\n', '        """"""\n']",[],0
github/Organization.py:Organization:invitations,Organization:invitations,method,2,9,9,187,20.78,0,0,['self'],[None],[None],993,"['        """"""\n', '        :calls: `GET /orgs/{org}/invitations <https://docs.github.com/en/rest/reference/orgs#members>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/Organization.py:Organization:invite_user,Organization:invite_user,method,17,95,60,884,9.31,0,3,"['self', 'user', 'email', 'role', 'teams', '']","[None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",1006,"['        """"""\n', '        :calls: `POST /orgs/{org}/invitations <http://docs.github.com/en/rest/reference/orgs#members>`_\n', '        :param user: :class:`github.NamedUser.NamedUser`\n', '        :param email: string\n', '        :param role: string\n', '        :param teams: array of :class:`github.Team.Team`\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'all']",2
github/Organization.py:Organization:has_in_members,Organization:has_in_members,method,7,24,17,266,11.08,0,1,"['self', 'member']","[None, None]","[None, None]",1047,"['        """"""\n', '        :calls: `GET /orgs/{org}/members/{user} <http://docs.github.com/en/rest/reference/orgs#members>`_\n', '        :param member: :class:`github.NamedUser.NamedUser`\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:has_in_public_members,Organization:has_in_public_members,method,7,14,14,202,14.43,0,0,"['self', 'public_member']","[None, None]","[None, None]",1063,"['        """"""\n', '        :calls: `GET /orgs/{org}/public_members/{user} <http://docs.github.com/en/rest/reference/orgs#members>`_\n', '        :param public_member: :class:`github.NamedUser.NamedUser`\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:remove_from_membership,Organization:remove_from_membership,method,4,10,10,164,16.4,0,0,"['self', 'member']","[None, None]","[None, None]",1075,"['        """"""\n', '        :calls: `DELETE /orgs/{org}/memberships/{user} <https://docs.github.com/en/rest/reference/orgs/members#remove-organization-membership>`_\n', '        :param member: :class:`github.NamedUser.NamedUser`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:remove_from_members,Organization:remove_from_members,method,5,23,15,362,15.74,0,0,"['self', 'member']","[None, None]","[None, None]",1086,[],"['isinstance', 'remove_from_members']",2
github/Organization.py:Organization:remove_from_public_members,Organization:remove_from_public_members,method,4,10,10,188,18.8,0,0,"['self', 'public_member']","[None, None]","[None, None]",1097,"['        """"""\n', '        :calls: `DELETE /orgs/{org}/public_members/{user} <http://docs.github.com/en/rest/reference/orgs#members>`_\n', '        :param public_member: :class:`github.NamedUser.NamedUser`\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/Organization.py:Organization:create_migration,Organization:create_migration,method,13,66,46,825,12.5,0,2,"['self', 'repos', 'lock_repositories', 'exclude_attachments', '']","[None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",1108,"['        """"""\n', '        :calls: `POST /orgs/{org}/migrations <https://docs.github.com/en/rest/reference/migrations#users>`_\n', '        :param repos: list or tuple of str\n', '        :param lock_repositories: bool\n', '        :param exclude_attachments: bool\n', '        :rtype: :class:`github.Migration.Migration`\n', '        """"""\n']","['isinstance', 'all']",2
github/Organization.py:Organization:get_migrations,Organization:get_migrations,method,2,9,9,181,20.11,0,0,['self'],[None],[None],1144,"['        """"""\n', '        :calls: `GET /orgs/{org}/migrations <https://docs.github.com/en/rest/reference/migrations#users>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Migration.Migration`\n', '        """"""\n']",[],0
github/Organization.py:Organization:get_installations,Organization:get_installations,method,2,9,8,162,18.0,0,0,['self'],[None],[None],1157,"['        """"""\n', '        :calls: `GET /orgs/{org}/installations <https://docs.github.com/en/rest/reference/orgs#list-app-installations-for-an-organization>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Installation.Installation`\n', '        """"""\n']",[],0
github/Organization.py:Organization:_initAttributes,Organization:_initAttributes,method,38,74,39,1697,22.93,0,0,['self'],[None],[None],1172,[],[],0
github/Organization.py:Organization:_useAttributes,Organization:_useAttributes,method,42,387,123,4351,11.24,0,37,"['self', 'attributes']","[None, None]","[None, None]",1211,[],"['self._makeStringAttribute', 'self._makeIntAttribute', 'self._makeDatetimeAttribute', 'self._makeBoolAttribute', 'self._makeClassAttribute']",5
github/PaginatedList.py:PaginatedListBase,PaginatedListBase,class,33,105,63,1005,9.57,3,2,[],[],[],41,[],[],0
github/PaginatedList.py:PaginatedList,PaginatedList,class,64,288,145,2995,10.4,1,17,[],[],[],91,[],[],0
github/PaginatedList.py:PaginatedListBase:__init__,PaginatedListBase:__init__,method,1,2,2,22,11.0,0,0,['self'],[None],[None],42,[],['list'],1
github/PaginatedList.py:PaginatedListBase:__getitem__,PaginatedListBase:__getitem__,method,5,14,12,152,10.86,0,1,"['self', 'index']","[None, None]","[None, None]",45,[],"['isinstance', 'self.__fetchToIndex', 'self._Slice']",3
github/PaginatedList.py:PaginatedListBase:__iter__,PaginatedListBase:__iter__,method,5,10,7,94,9.4,1,0,['self'],[None],[None],53,[],"['self._couldGrow', 'self._grow']",2
github/PaginatedList.py:PaginatedListBase:_isBiggerThan,PaginatedListBase:_isBiggerThan,method,1,6,6,51,8.5,0,0,"['self', 'index']","[None, None]","[None, None]",59,[],"['len', 'self._couldGrow']",2
github/PaginatedList.py:PaginatedListBase:__fetchToIndex,PaginatedListBase:__fetchToIndex,method,1,6,6,66,11.0,1,0,"['self', 'index']","[None, None]","[None, None]",62,[],"['len', 'self._couldGrow', 'self._grow']",3
github/PaginatedList.py:PaginatedListBase:_grow,PaginatedListBase:_grow,method,4,7,6,80,11.43,0,0,['self'],[None],[None],66,[],['self._fetchNextPage'],1
github/PaginatedList.py:PaginatedList:__init__,PaginatedList:__init__,method,20,30,27,379,12.63,0,1,"['self', 'contentClass', 'requester', 'firstUrl', 'firstParams', 'headers', 'list_item', '']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, 'None', '""items""', None]",120,[],['super'],1
github/PaginatedList.py:PaginatedList:totalCount,PaginatedList:totalCount,method,15,55,39,569,10.35,0,5,['self'],[None],[None],144,[],"['params.update', 'len', 'self.__parseLinkHeader', 'links.get', 'int']",5
github/PaginatedList.py:PaginatedList:_getLastPageUrl,PaginatedList:_getLastPageUrl,method,8,14,13,204,14.57,0,0,['self'],[None],[None],168,[],"['self.__parseLinkHeader', 'links.get']",2
github/PaginatedList.py:PaginatedList:reversed,PaginatedList:reversed,method,4,12,11,150,12.5,0,0,['self'],[None],[None],177,[],"['PaginatedList', 'r.__reverse']",2
github/PaginatedList.py:PaginatedList:__reverse,PaginatedList:__reverse,method,4,8,7,84,10.5,0,1,['self'],[None],[None],189,[],['self._getLastPageUrl'],1
github/PaginatedList.py:PaginatedList:_couldGrow,PaginatedList:_couldGrow,method,2,5,5,29,5.8,0,0,['self'],[None],[None],195,[],[],0
github/PaginatedList.py:PaginatedList:_fetchNextPage,PaginatedList:_fetchNextPage,method,16,68,45,621,9.13,0,6,['self'],[None],[None],198,[],"['len', 'self.__parseLinkHeader', 'data.get', 'self.__contentClass']",4
github/PaginatedList.py:PaginatedList:__parseLinkHeader,PaginatedList:__parseLinkHeader,method,13,26,23,185,7.12,1,1,"['self', 'headers']","[None, None]","[None, None]",227,[],['linkHeader.split'],1
github/PaginatedList.py:PaginatedList:get_page,PaginatedList:get_page,method,12,40,34,451,11.28,0,3,"['self', 'page']","[None, None]","[None, None]",238,[],"['dict', 'data.get', 'self.__contentClass']",3
github/Path.py:Path,Path,class,20,88,47,964,10.95,0,4,[],[],[],30,[],[],0
github/Path.py:Path:__repr__,Path:__repr__,method,2,13,13,139,10.69,0,0,['self'],[None],[None],36,[],['self.get__repr__'],1
github/Path.py:Path:path,Path:path,method,2,2,2,22,11.0,0,0,['self'],[None],[None],47,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Path.py:Path:title,Path:title,method,2,2,2,23,11.5,0,0,['self'],[None],[None],54,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Path.py:Path:count,Path:count,method,2,2,2,23,11.5,0,0,['self'],[None],[None],61,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Path.py:Path:uniques,Path:uniques,method,2,2,2,25,12.5,0,0,['self'],[None],[None],68,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Path.py:Path:_initAttributes,Path:_initAttributes,method,5,8,6,156,19.5,0,0,['self'],[None],[None],74,[],[],0
github/Path.py:Path:_useAttributes,Path:_useAttributes,method,6,40,19,384,9.6,0,4,"['self', 'attributes']","[None, None]","[None, None]",80,[],"['self._makeStringAttribute', 'self._makeIntAttribute']",2
github/Permissions.py:Permissions,Permissions,class,22,107,54,1181,11.04,0,5,[],[],[],34,[],[],0
github/Permissions.py:Permissions:__repr__,Permissions:__repr__,method,2,15,15,168,11.2,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/Permissions.py:Permissions:admin,Permissions:admin,method,2,2,2,23,11.5,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/Permissions.py:Permissions:maintain,Permissions:maintain,method,2,2,2,26,13.0,0,0,['self'],[None],[None],58,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/Permissions.py:Permissions:pull,Permissions:pull,method,2,2,2,22,11.0,0,0,['self'],[None],[None],65,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/Permissions.py:Permissions:push,Permissions:push,method,2,2,2,22,11.0,0,0,['self'],[None],[None],72,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/Permissions.py:Permissions:triage,Permissions:triage,method,2,2,2,24,12.0,0,0,['self'],[None],[None],79,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/Permissions.py:Permissions:_initAttributes,Permissions:_initAttributes,method,6,10,7,196,19.6,0,0,['self'],[None],[None],85,[],[],0
github/Permissions.py:Permissions:_useAttributes,Permissions:_useAttributes,method,6,50,22,480,9.6,0,5,"['self', 'attributes']","[None, None]","[None, None]",92,[],['self._makeBoolAttribute'],1
github/Plan.py:Plan,Plan,class,26,112,47,1363,12.17,0,6,[],[],[],34,[],[],0
github/Plan.py:Plan:__repr__,Plan:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/Plan.py:Plan:collaborators,Plan:collaborators,method,2,2,2,31,15.5,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Plan.py:Plan:name,Plan:name,method,2,2,2,22,11.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Plan.py:Plan:private_repos,Plan:private_repos,method,2,2,2,31,15.5,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Plan.py:Plan:space,Plan:space,method,2,2,2,23,11.5,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Plan.py:Plan:filled_seats,Plan:filled_seats,method,2,2,2,30,15.0,0,0,['self'],[None],[None],71,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Plan.py:Plan:seats,Plan:seats,method,2,2,2,23,11.5,0,0,['self'],[None],[None],78,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Plan.py:Plan:_initAttributes,Plan:_initAttributes,method,7,12,8,255,21.25,0,0,['self'],[None],[None],84,[],[],0
github/Plan.py:Plan:_useAttributes,Plan:_useAttributes,method,8,60,25,632,10.53,0,6,"['self', 'attributes']","[None, None]","[None, None]",92,[],"['self._makeIntAttribute', 'self._makeStringAttribute']",2
github/Project.py:Project,Project,class,68,396,173,5096,12.87,0,18,[],[],[],29,[],[],0
github/Project.py:Project:__repr__,Project:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],34,[],['self.get__repr__'],1
github/Project.py:Project:body,Project:body,method,3,3,3,57,19.0,0,0,['self'],[None],[None],38,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:columns_url,Project:columns_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:created_at,Project:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],54,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:creator,Project:creator,method,3,3,3,63,21.0,0,0,['self'],[None],[None],62,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:html_url,Project:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],70,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:id,Project:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],78,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:name,Project:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],86,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:node_id,Project:node_id,method,3,3,3,63,21.0,0,0,['self'],[None],[None],94,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:number,Project:number,method,3,3,3,61,20.33,0,0,['self'],[None],[None],102,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:owner_url,Project:owner_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],110,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:state,Project:state,method,3,3,3,59,19.67,0,0,['self'],[None],[None],118,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:updated_at,Project:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],126,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:url,Project:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],134,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Project.py:Project:delete,Project:delete,method,3,8,8,120,15.0,0,0,['self'],[None],[None],141,"['        """"""\n', '        :calls: `DELETE /projects/{project_id} <https://docs.github.com/en/rest/reference/projects#delete-a-project>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Project.py:Project:edit,Project:edit,method,14,91,44,1014,11.14,0,5,"['self', 'name', 'body', 'state', 'organization_permission', 'private', '']","[None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",150,"['        """"""\n', '        :calls: `PATCH /projects/{project_id} <https://docs.github.com/en/rest/reference/projects#update-a-project>`_\n', '        :param name: string\n', '        :param body: string\n', '        :param state: string\n', '        :param organization_permission: string\n', '        :param private: bool\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'dict', 'self._useAttributes']",3
github/Project.py:Project:get_columns,Project:get_columns,method,2,9,9,164,18.22,0,0,['self'],[None],[None],195,"['        """"""\n', '        :calls: `GET /projects/{project_id}/columns <https://docs.github.com/en/rest/reference/projects/columns#list-project-columns>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.ProjectColumn.ProjectColumn`\n', '        """"""\n']",[],0
github/Project.py:Project:create_column,Project:create_column,method,8,25,24,331,13.24,0,0,"['self', 'name']","[None, None]","[None, None]",209,"['        """"""\n', '        calls: `POST /projects/{project_id}/columns <https://docs.github.com/en/rest/reference/projects/columns#create-a-project-column>`_\n', '        :param name: string\n', '        """"""\n']",['isinstance'],1
github/Project.py:Project:_initAttributes,Project:_initAttributes,method,14,26,15,527,20.27,0,0,['self'],[None],[None],224,[],[],0
github/Project.py:Project:_useAttributes,Project:_useAttributes,method,17,133,49,1349,10.14,0,13,"['self', 'attributes']","[None, None]","[None, None]",239,[],"['self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeClassAttribute', 'self._makeIntAttribute']",4
github/ProjectCard.py:ProjectCard,ProjectCard,class,68,342,166,3939,11.52,0,15,[],[],[],34,[],[],0
github/ProjectCard.py:ProjectCard:__repr__,ProjectCard:__repr__,method,2,3,3,45,15.0,0,0,['self'],[None],[None],39,[],['self.get__repr__'],1
github/ProjectCard.py:ProjectCard:archived,ProjectCard:archived,method,2,2,2,26,13.0,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/ProjectCard.py:ProjectCard:column_url,ProjectCard:column_url,method,2,2,2,28,14.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/ProjectCard.py:ProjectCard:content_url,ProjectCard:content_url,method,2,2,2,29,14.5,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/ProjectCard.py:ProjectCard:created_at,ProjectCard:created_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/ProjectCard.py:ProjectCard:creator,ProjectCard:creator,method,2,2,2,25,12.5,0,0,['self'],[None],[None],71,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/ProjectCard.py:ProjectCard:id,ProjectCard:id,method,2,2,2,20,10.0,0,0,['self'],[None],[None],78,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/ProjectCard.py:ProjectCard:node_id,ProjectCard:node_id,method,2,2,2,25,12.5,0,0,['self'],[None],[None],85,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/ProjectCard.py:ProjectCard:note,ProjectCard:note,method,2,2,2,22,11.0,0,0,['self'],[None],[None],92,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/ProjectCard.py:ProjectCard:updated_at,ProjectCard:updated_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],99,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/ProjectCard.py:ProjectCard:url,ProjectCard:url,method,2,2,2,21,10.5,0,0,['self'],[None],[None],106,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/ProjectCard.py:ProjectCard:get_content,ProjectCard:get_content,method,15,50,38,544,10.88,0,2,"['self', 'content_type']","[None, None]","[None, 'github.GithubObject.NotSet']",115,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/{number} <https://docs.github.com/en/rest/reference/pulls#get-a-single-pull-request>`_\n', '        :param content_type: string, optional\n', '        :rtype: :class:`github.PullRequest.PullRequest` or :class:`github.Issue.Issue`\n', '        """"""\n']","['isinstance', 'ValueError', 'retclass']",3
github/ProjectCard.py:ProjectCard:move,ProjectCard:move,method,10,38,36,427,11.24,0,1,"['self', 'position', 'column']","[None, None, None]","[None, None, None]",138,"['        """"""\n', '        :calls: `POST /projects/columns/cards/{card_id}/moves <https://docs.github.com/en/rest/reference/projects#cards>`_\n', '        :param position: string\n', '        :param column: :class:`github.ProjectColumn.ProjectColumn` or int\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/ProjectCard.py:ProjectCard:delete,ProjectCard:delete,method,6,12,12,131,10.92,0,0,['self'],[None],[None],163,"['        """"""\n', '        :calls: `DELETE /projects/columns/cards/{card_id} <https://docs.github.com/en/rest/reference/projects#cards>`_\n', '        :rtype: bool\n', '        """"""\n']",[],0
github/ProjectCard.py:ProjectCard:edit,ProjectCard:edit,method,11,44,31,493,11.2,0,2,"['self', 'note', 'archived']","[None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet']",175,"['        """"""\n', '        :calls: `PATCH /projects/columns/cards/{card_id} <http://docs.github.com/en/rest/reference/projects#cards>`_\n', '        :param note: string\n', '        :param archived: bool\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'dict', 'self._useAttributes']",3
github/ProjectCard.py:ProjectCard:_initAttributes,ProjectCard:_initAttributes,method,11,20,12,411,20.55,0,0,['self'],[None],[None],201,[],[],0
github/ProjectCard.py:ProjectCard:_useAttributes,ProjectCard:_useAttributes,method,15,103,40,1062,10.31,0,10,"['self', 'attributes']","[None, None]","[None, None]",213,[],"['self._makeBoolAttribute', 'self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeClassAttribute', 'self._makeIntAttribute']",5
github/ProjectColumn.py:ProjectColumn,ProjectColumn,class,61,294,152,3623,12.32,0,10,[],[],[],30,[],[],0
github/ProjectColumn.py:ProjectColumn:__repr__,ProjectColumn:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],35,[],['self.get__repr__'],1
github/ProjectColumn.py:ProjectColumn:cards_url,ProjectColumn:cards_url,method,2,2,2,27,13.5,0,0,['self'],[None],[None],39,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/ProjectColumn.py:ProjectColumn:created_at,ProjectColumn:created_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/ProjectColumn.py:ProjectColumn:id,ProjectColumn:id,method,2,2,2,20,10.0,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/ProjectColumn.py:ProjectColumn:name,ProjectColumn:name,method,2,2,2,22,11.0,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/ProjectColumn.py:ProjectColumn:node_id,ProjectColumn:node_id,method,2,2,2,25,12.5,0,0,['self'],[None],[None],67,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/ProjectColumn.py:ProjectColumn:project_url,ProjectColumn:project_url,method,2,2,2,29,14.5,0,0,['self'],[None],[None],74,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/ProjectColumn.py:ProjectColumn:updated_at,ProjectColumn:updated_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],81,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/ProjectColumn.py:ProjectColumn:url,ProjectColumn:url,method,2,2,2,21,10.5,0,0,['self'],[None],[None],88,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/ProjectColumn.py:ProjectColumn:get_cards,ProjectColumn:get_cards,method,8,28,25,390,13.93,0,1,"['self', 'archived_state']","[None, None]","[None, 'github.GithubObject.NotSet']",94,"['        """"""\n', '        :calls: `GET /projects/columns/{column_id}/cards <https://docs.github.com/en/rest/reference/projects/cards#list-project-cards>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.ProjectCard.ProjectCard`\n', '        :param archived_state: string\n', '        """"""\n']","['isinstance', 'dict']",2
github/ProjectColumn.py:ProjectColumn:create_card,ProjectColumn:create_card,method,12,53,41,645,12.17,0,1,"['self', 'note', 'content_id', 'content_type', '']","[None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",116,"['        """"""\n', '        :calls: `POST /projects/columns/{column_id}/cards <https://docs.github.com/en/rest/reference/projects/cards#create-a-project-card>`_\n', '        :param note: string\n', '        :param content_id: integer\n', '        :param content_type: string\n', '\n', '        :rtype: :class:`github.ProjectCard.ProjectCard`:\n', '        """"""\n']",['isinstance'],1
github/ProjectColumn.py:ProjectColumn:move,ProjectColumn:move,method,8,20,20,241,12.05,0,0,"['self', 'position']","[None, None]","[None, None]",148,"['        """"""\n', '        :calls: `POST POST /projects/columns/{column_id}/moves <https://docs.github.com/en/rest/reference/projects/columns#move-a-project-column>`_\n', '        :param position: string\n', '\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/ProjectColumn.py:ProjectColumn:delete,ProjectColumn:delete,method,6,12,12,131,10.92,0,0,['self'],[None],[None],165,"['        """"""\n', '        :calls: `DELETE /projects/columns/{column_id} <https://docs.github.com/en/rest/reference/projects/columns#delete-a-project-column>`_\n', '        :rtype: bool\n', '        """"""\n']",[],0
github/ProjectColumn.py:ProjectColumn:edit,ProjectColumn:edit,method,6,17,17,235,13.82,0,0,"['self', 'name']","[None, None]","[None, None]",177,"['        """"""\n', '        :calls: `PATCH /projects/columns/{column_id} <https://docs.github.com/en/rest/reference/projects/columns#update-a-project-column>`_\n', '        :param name: string\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'self._useAttributes']",2
github/ProjectColumn.py:ProjectColumn:_initAttributes,ProjectColumn:_initAttributes,method,9,16,10,327,20.44,0,0,['self'],[None],[None],195,[],[],0
github/ProjectColumn.py:ProjectColumn:_useAttributes,ProjectColumn:_useAttributes,method,11,80,31,824,10.3,0,8,"['self', 'attributes']","[None, None]","[None, None]",205,[],"['self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute']",3
github/PublicKey.py:encrypt,encrypt,function,8,9,9,222,24.67,0,0,"['public_key', 'secret_value']","[' str', ' str']","[None, None]",39,"['    """"""Encrypt a Unicode string using the public key.""""""\n']","['public.PublicKey', 'encoding.Base64Encoder', 'public.SealedBox', 'sealed_box.encrypt', 'b64encode']",5
github/PublicKey.py:PublicKey,PublicKey,class,17,60,39,777,12.95,0,3,[],[],[],47,[],[],0
github/PublicKey.py:PublicKey:__repr__,PublicKey:__repr__,method,2,5,5,75,15.0,0,0,['self'],[None],[None],54,[],['self.get__repr__'],1
github/PublicKey.py:PublicKey:key,PublicKey:key,method,3,3,3,55,18.33,0,0,['self'],[None],[None],58,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PublicKey.py:PublicKey:key_id,PublicKey:key_id,method,3,3,3,61,20.33,0,0,['self'],[None],[None],66,"['        """"""\n', '        :type: string or int\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PublicKey.py:PublicKey:_initAttributes,PublicKey:_initAttributes,method,3,4,4,76,19.0,0,0,['self'],[None],[None],73,[],[],0
github/PublicKey.py:PublicKey:_useAttributes,PublicKey:_useAttributes,method,5,26,17,289,11.12,0,3,"['self', 'attributes']","[None, None]","[None, None]",77,[],"['self._makeStringAttribute', 'type', 'self._makeIntAttribute']",3
github/PublicKey.py:PublicKey:encrypt,PublicKey:encrypt,method,2,3,3,48,16.0,0,0,"['self', 'unencrypted_value']","[None, None]","[None, None]",86,[],['encrypt'],1
github/PullRequest.py:PullRequest,PullRequest,class,202,1676,551,21562,12.87,2,59,[],[],[],60,[],[],0
github/PullRequest.py:PullRequest:__repr__,PullRequest:__repr__,method,2,7,7,81,11.57,0,0,['self'],[None],[None],65,[],['self.get__repr__'],1
github/PullRequest.py:PullRequest:additions,PullRequest:additions,method,3,3,3,67,22.33,0,0,['self'],[None],[None],71,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:assignee,PullRequest:assignee,method,3,3,3,65,21.67,0,0,['self'],[None],[None],79,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:assignees,PullRequest:assignees,method,3,3,3,67,22.33,0,0,['self'],[None],[None],87,"['        """"""\n', '        :type: list of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:base,PullRequest:base,method,3,3,3,57,19.0,0,0,['self'],[None],[None],95,"['        """"""\n', '        :type: :class:`github.PullRequestPart.PullRequestPart`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:body,PullRequest:body,method,3,3,3,57,19.0,0,0,['self'],[None],[None],103,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:changed_files,PullRequest:changed_files,method,3,3,3,75,25.0,0,0,['self'],[None],[None],111,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:closed_at,PullRequest:closed_at,method,3,3,3,67,22.33,0,0,['self'],[None],[None],119,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:comments,PullRequest:comments,method,3,3,3,65,21.67,0,0,['self'],[None],[None],127,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:comments_url,PullRequest:comments_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],135,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:commits,PullRequest:commits,method,3,3,3,63,21.0,0,0,['self'],[None],[None],143,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:commits_url,PullRequest:commits_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],151,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:created_at,PullRequest:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],159,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:deletions,PullRequest:deletions,method,3,3,3,67,22.33,0,0,['self'],[None],[None],167,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:diff_url,PullRequest:diff_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],175,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:draft,PullRequest:draft,method,3,3,3,59,19.67,0,0,['self'],[None],[None],183,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:head,PullRequest:head,method,3,3,3,57,19.0,0,0,['self'],[None],[None],191,"['        """"""\n', '        :type: :class:`github.PullRequestPart.PullRequestPart`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:html_url,PullRequest:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],199,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:id,PullRequest:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],207,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:issue_url,PullRequest:issue_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],215,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:labels,PullRequest:labels,method,3,3,3,61,20.33,0,0,['self'],[None],[None],223,"['        """"""\n', '        :type: list of :class:`github.Label.Label`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:merge_commit_sha,PullRequest:merge_commit_sha,method,3,3,3,81,27.0,0,0,['self'],[None],[None],231,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:mergeable,PullRequest:mergeable,method,3,3,3,67,22.33,0,0,['self'],[None],[None],239,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:mergeable_state,PullRequest:mergeable_state,method,3,3,3,79,26.33,0,0,['self'],[None],[None],247,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:merged,PullRequest:merged,method,3,3,3,61,20.33,0,0,['self'],[None],[None],255,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:merged_at,PullRequest:merged_at,method,3,3,3,67,22.33,0,0,['self'],[None],[None],263,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:merged_by,PullRequest:merged_by,method,3,3,3,67,22.33,0,0,['self'],[None],[None],271,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:milestone,PullRequest:milestone,method,3,3,3,67,22.33,0,0,['self'],[None],[None],279,"['        """"""\n', '        :type: :class:`github.Milestone.Milestone`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:number,PullRequest:number,method,3,3,3,61,20.33,0,0,['self'],[None],[None],287,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:patch_url,PullRequest:patch_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],295,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:rebaseable,PullRequest:rebaseable,method,3,3,3,69,23.0,0,0,['self'],[None],[None],303,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:review_comment_url,PullRequest:review_comment_url,method,3,3,3,85,28.33,0,0,['self'],[None],[None],311,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:review_comments,PullRequest:review_comments,method,3,3,3,79,26.33,0,0,['self'],[None],[None],319,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:review_comments_url,PullRequest:review_comments_url,method,3,3,3,87,29.0,0,0,['self'],[None],[None],327,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:state,PullRequest:state,method,3,3,3,59,19.67,0,0,['self'],[None],[None],335,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:title,PullRequest:title,method,3,3,3,59,19.67,0,0,['self'],[None],[None],343,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:updated_at,PullRequest:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],351,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:url,PullRequest:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],359,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:user,PullRequest:user,method,3,3,3,57,19.0,0,0,['self'],[None],[None],367,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:maintainer_can_modify,PullRequest:maintainer_can_modify,method,3,3,3,91,30.33,0,0,['self'],[None],[None],375,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:as_issue,PullRequest:as_issue,method,5,9,8,140,15.56,0,0,['self'],[None],[None],382,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/{number} <http://docs.github.com/en/rest/reference/issues>`_\n', '        :rtype: :class:`github.Issue.Issue`\n', '        """"""\n']",[],0
github/PullRequest.py:PullRequest:create_comment,PullRequest:create_comment,method,2,5,5,62,12.4,0,0,"['self', 'body', 'commit_id', 'path', 'position']","[None, None, None, None, None]","[None, None, None, None, None]",390,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/pulls/{number}/comments <http://docs.github.com/en/rest/reference/pulls#review-comments>`_\n', '        :param body: string\n', '        :param commit_id: :class:`github.Commit.Commit`\n', '        :param path: string\n', '        :param position: integer\n', '        :rtype: :class:`github.PullRequestComment.PullRequestComment`\n', '        """"""\n']",['self.create_review_comment'],1
github/PullRequest.py:PullRequest:create_review_comment,PullRequest:create_review_comment,method,8,70,47,850,12.14,0,0,"['self', 'body', 'commit_id', 'path', 'position']","[None, None, None, None, None]","[None, None, None, None, None]",401,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/pulls/{number}/comments <http://docs.github.com/en/rest/reference/pulls#review-comments>`_\n', '        :param body: string\n', '        :param commit_id: :class:`github.Commit.Commit`\n', '        :param path: string\n', '        :param position: integer\n', '        :rtype: :class:`github.PullRequestComment.PullRequestComment`\n', '        """"""\n']","['isinstance', 'create_review_comment_reply']",2
github/PullRequest.py:PullRequest:create_review_comment_reply,PullRequest:create_review_comment_reply,method,7,25,23,331,13.24,0,0,"['self', 'comment_id', 'body']","[None, None, None]","[None, None, None]",427,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/pulls/{pull_number}/comments/{comment_id}/replies <http://docs.github.com/en/rest/reference/pulls#review-comments>`_\n', '        :param comment_id: int\n', '        :param body: string\n', '        :rtype: :class:`github.PullRequestComment.PullRequestComment`\n', '        """"""\n']",['isinstance'],1
github/PullRequest.py:PullRequest:create_issue_comment,PullRequest:create_issue_comment,method,7,23,22,260,11.3,0,0,"['self', 'body']","[None, None]","[None, None]",446,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/issues/{number}/comments <http://docs.github.com/en/rest/reference/issues#comments>`_\n', '        :param body: string\n', '        :rtype: :class:`github.IssueComment.IssueComment`\n', '        """"""\n']",['isinstance'],1
github/PullRequest.py:PullRequest:create_review,PullRequest:create_review,method,8,70,47,850,12.14,0,0,"['self', 'body', 'commit_id', 'path', 'position']","[None, None, None, None, None]","[None, None, None, None, None]",463,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/pulls/{number}/reviews <https://docs.github.com/en/rest/reference/pulls#reviews>`_\n', '        :param commit: github.Commit.Commit\n', '        :param body: string\n', '        :param event: string\n', '        :param comments: list\n', '        :rtype: :class:`github.PullRequestReview.PullRequestReview`\n', '        """"""\n']","['isinstance', 'create_review_comment_reply']",2
github/PullRequest.py:PullRequest:create_review_request,PullRequest:create_review_request,method,9,41,29,462,11.27,0,2,"['self', 'reviewers', 'team_reviewers', '']","[None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",505,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/pulls/{number}/requested_reviewers <https://docs.github.com/en/rest/reference/pulls#review_requests>`_\n', '        :param reviewers: list of strings\n', '        :param team_reviewers: list of strings\n', '        :rtype: None\n', '        """"""\n']","['dict', 'all', 'isinstance']",3
github/PullRequest.py:PullRequest:delete_review_request,PullRequest:delete_review_request,method,9,41,29,464,11.32,0,2,"['self', 'reviewers', 'team_reviewers', '']","[None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",529,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/pulls/{number}/requested_reviewers <https://docs.github.com/en/rest/reference/pulls#review_requests>`_\n', '        :param reviewers: list of strings\n', '        :param team_reviewers: list of strings\n', '        :rtype: None\n', '        """"""\n']","['dict', 'all', 'isinstance']",3
github/PullRequest.py:PullRequest:edit,PullRequest:edit,method,14,87,41,926,10.64,0,5,"['self', 'title', 'body', 'state', 'base', 'maintainer_can_modify', '']","[None, None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",553,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/pulls/{number} <http://docs.github.com/en/rest/reference/pulls>`_\n', '        :param title: string\n', '        :param body: string\n', '        :param state: string\n', '        :param base: string\n', '        :param maintainer_can_modify: bool\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'dict', 'self._useAttributes']",3
github/PullRequest.py:PullRequest:get_comment,PullRequest:get_comment,method,2,2,2,33,16.5,0,0,"['self', 'id']","[None, None]","[None, None]",593,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/comments/{number} <http://docs.github.com/en/rest/reference/pulls#review-comments>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.PullRequestComment.PullRequestComment`\n', '        """"""\n']",['self.get_review_comment'],1
github/PullRequest.py:PullRequest:get_review_comment,PullRequest:get_review_comment,method,6,17,16,228,13.41,0,0,"['self', 'id']","[None, None]","[None, None]",601,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/comments/{number} <http://docs.github.com/en/rest/reference/pulls#review-comments>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.PullRequestComment.PullRequestComment`\n', '        """"""\n']",['isinstance'],1
github/PullRequest.py:PullRequest:get_comments,PullRequest:get_comments,method,2,2,2,32,16.0,0,0,['self'],[None],[None],615,"['        """"""\n', '        Warning: this only returns review comments. For normal conversation comments, use get_issue_comments.\n', '\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/{number}/comments <http://docs.github.com/en/rest/reference/pulls#review-comments>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.PullRequestComment.PullRequestComment`\n', '        """"""\n']",['self.get_review_comments'],1
github/PullRequest.py:PullRequest:get_review_comments,PullRequest:get_review_comments,method,9,26,24,354,13.62,0,1,"['self', 'since']","[None, None]","[None, 'github.GithubObject.NotSet']",624,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/{number}/comments <http://docs.github.com/en/rest/reference/pulls#review-comments>`_\n', '        :param since: datetime.datetime format YYYY-MM-DDTHH:MM:SSZ\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.PullRequestComment.PullRequestComment`\n', '        """"""\n']","['isinstance', 'dict', 'since.strftime']",3
github/PullRequest.py:PullRequest:get_single_review_comments,PullRequest:get_single_review_comments,method,3,11,11,177,16.09,0,0,"['self', 'id']","[None, None]","[None, None]",643,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/{number}/review/{id}/comments <https://docs.github.com/en/rest/reference/pulls#reviews>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.PullRequestComment.PullRequestComment`\n', '        """"""\n']",['isinstance'],1
github/PullRequest.py:PullRequest:get_commits,PullRequest:get_commits,method,2,7,7,107,15.29,0,0,['self'],[None],[None],657,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/{number}/commits <http://docs.github.com/en/rest/reference/pulls>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Commit.Commit`\n', '        """"""\n']",[],0
github/PullRequest.py:PullRequest:get_files,PullRequest:get_files,method,2,7,7,101,14.43,0,0,['self'],[None],[None],666,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/{number}/files <http://docs.github.com/en/rest/reference/pulls>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.File.File`\n', '        """"""\n']",[],0
github/PullRequest.py:PullRequest:get_issue_comment,PullRequest:get_issue_comment,method,8,26,23,382,14.69,0,0,"['self', 'id']","[None, None]","[None, None]",675,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/comments/{id} <http://docs.github.com/en/rest/reference/issues#comments>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.IssueComment.IssueComment`\n', '        """"""\n']","['isinstance', 'get_issue_comments']",2
github/PullRequest.py:PullRequest:get_issue_comments,PullRequest:get_issue_comments,method,2,7,7,130,18.57,0,0,['self'],[None],[None],689,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/{number}/comments <http://docs.github.com/en/rest/reference/issues#comments>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.IssueComment.IssueComment`\n', '        """"""\n']",[],0
github/PullRequest.py:PullRequest:get_issue_events,PullRequest:get_issue_events,method,2,9,9,178,19.78,0,0,['self'],[None],[None],701,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/{issue_number}/events <http://docs.github.com/en/rest/reference/issues#events>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.IssueEvent.IssueEvent`\n', '        """"""\n']",[],0
github/PullRequest.py:PullRequest:get_review,PullRequest:get_review,method,6,17,16,228,13.41,0,0,"['self', 'id']","[None, None]","[None, None]",714,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/{number}/reviews/{id} <https://docs.github.com/en/rest/reference/pulls#reviews>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.PullRequestReview.PullRequestReview`\n', '        """"""\n']",['isinstance'],1
github/PullRequest.py:PullRequest:get_reviews,PullRequest:get_reviews,method,2,7,7,133,19.0,0,0,['self'],[None],[None],729,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/{number}/reviews <https://docs.github.com/en/rest/reference/pulls#reviews>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.PullRequestReview.PullRequestReview`\n', '        """"""\n']",[],0
github/PullRequest.py:PullRequest:get_review_requests,PullRequest:get_review_requests,method,2,17,12,287,16.88,0,0,['self'],[None],[None],741,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/{number}/requested_reviewers <https://docs.github.com/en/rest/reference/pulls#review_requests>`_\n', '        :rtype: tuple of :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser` and of :class:`github.PaginatedList.PaginatedList` of :class:`github.Team.Team`\n', '        """"""\n']",[],0
github/PullRequest.py:PullRequest:get_labels,PullRequest:get_labels,method,2,7,7,110,15.71,0,0,['self'],[None],[None],763,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/issues/{number}/labels <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Label.Label`\n', '        """"""\n']",[],0
github/PullRequest.py:PullRequest:add_to_labels,PullRequest:add_to_labels,method,6,31,27,285,9.19,0,0,"['self', '*labels']","[None, None]","[None, None]",772,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/issues/{number}/labels <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :param label: :class:`github.Label.Label` or string\n', '        :rtype: None\n', '        """"""\n']","['all', 'isinstance']",2
github/PullRequest.py:PullRequest:delete_labels,PullRequest:delete_labels,method,3,6,6,87,14.5,0,0,['self'],[None],[None],789,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/issues/{number}/labels <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/PullRequest.py:PullRequest:remove_from_labels,PullRequest:remove_from_labels,method,7,19,17,250,13.16,0,1,"['self', 'label']","[None, None]","[None, None]",798,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/issues/{number}/labels/{name} <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :param label: :class:`github.Label.Label` or string\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/PullRequest.py:PullRequest:set_labels,PullRequest:set_labels,method,6,31,27,284,9.16,0,0,"['self', '*labels']","[None, None]","[None, None]",813,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/issues/{number}/labels <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :param labels: list of :class:`github.Label.Label` or strings\n', '        :rtype: None\n', '        """"""\n']","['all', 'isinstance']",2
github/PullRequest.py:PullRequest:is_merged,PullRequest:is_merged,method,6,8,8,92,11.5,0,0,['self'],[None],[None],830,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/{number}/merge <http://docs.github.com/en/rest/reference/pulls>`_\n', '        :rtype: bool\n', '        """"""\n']",[],0
github/PullRequest.py:PullRequest:merge,PullRequest:merge,method,3,3,3,81,27.0,0,0,['self'],[None],[None],838,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/pulls/{number}/merge <http://docs.github.com/en/rest/reference/pulls>`_\n', '        :param commit_message: string\n', '        :param commit_title: string\n', '        :param merge_method: string\n', '        :param sha: string\n', '        :rtype: :class:`github.PullRequestMergeStatus.PullRequestMergeStatus`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequest.py:PullRequest:add_to_assignees,PullRequest:add_to_assignees,method,8,36,32,398,11.06,1,0,"['self', '*assignees']","[None, None]","[None, None]",879,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/issues/{number}/assignees <https://docs.github.com/en/rest/reference/issues#assignees>`_\n', '        :param assignees: list of :class:`github.NamedUser.NamedUser` or string\n', '        :rtype: None\n', '        """"""\n']","['all', 'isinstance', 'self._useAttributes']",3
github/PullRequest.py:PullRequest:remove_from_assignees,PullRequest:remove_from_assignees,method,8,36,32,400,11.11,1,0,"['self', '*assignees']","[None, None]","[None, None]",903,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/issues/{number}/assignees <https://docs.github.com/en/rest/reference/issues#assignees>`_\n', '        :param assignees: list of :class:`github.NamedUser.NamedUser` or string\n', '        :rtype: None\n', '        """"""\n']","['all', 'isinstance', 'self._useAttributes']",3
github/PullRequest.py:PullRequest:update_branch,PullRequest:update_branch,method,12,32,29,407,12.72,0,1,"['self', 'expected_head_sha']","[None, None]","[None, 'github.GithubObject.NotSet']",927,"['        """"""\n', '        :calls `PUT /repos/{owner}/{repo}/pulls/{pull_number}/update-branch <https://docs.github.com/en/rest/reference/pulls>`_\n', '        :param expected_head_sha: string\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/PullRequest.py:PullRequest:_initAttributes,PullRequest:_initAttributes,method,40,78,41,1678,21.51,0,0,['self'],[None],[None],947,[],[],0
github/PullRequest.py:PullRequest:_useAttributes,PullRequest:_useAttributes,method,46,446,144,4753,10.66,0,40,"['self', 'attributes']","[None, None]","[None, None]",988,[],"['self._makeIntAttribute', 'self._makeClassAttribute', 'self._makeListOfClassesAttribute', 'self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeBoolAttribute']",6
github/PullRequestComment.py:PullRequestComment,PullRequestComment,class,74,373,168,5033,13.49,0,15,[],[],[],42,[],[],0
github/PullRequestComment.py:PullRequestComment:__repr__,PullRequestComment:__repr__,method,2,5,5,69,13.8,0,0,['self'],[None],[None],47,[],['self.get__repr__'],1
github/PullRequestComment.py:PullRequestComment:body,PullRequestComment:body,method,3,3,3,57,19.0,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:commit_id,PullRequestComment:commit_id,method,3,3,3,67,22.33,0,0,['self'],[None],[None],59,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:created_at,PullRequestComment:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],67,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:diff_hunk,PullRequestComment:diff_hunk,method,3,3,3,67,22.33,0,0,['self'],[None],[None],75,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:id,PullRequestComment:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],83,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:in_reply_to_id,PullRequestComment:in_reply_to_id,method,3,3,3,77,25.67,0,0,['self'],[None],[None],91,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:original_commit_id,PullRequestComment:original_commit_id,method,3,3,3,85,28.33,0,0,['self'],[None],[None],99,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:original_position,PullRequestComment:original_position,method,3,3,3,83,27.67,0,0,['self'],[None],[None],107,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:path,PullRequestComment:path,method,3,3,3,57,19.0,0,0,['self'],[None],[None],115,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:position,PullRequestComment:position,method,3,3,3,65,21.67,0,0,['self'],[None],[None],123,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:pull_request_url,PullRequestComment:pull_request_url,method,3,3,3,81,27.0,0,0,['self'],[None],[None],131,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:updated_at,PullRequestComment:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],139,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:url,PullRequestComment:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],147,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:html_url,PullRequestComment:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],155,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:user,PullRequestComment:user,method,3,3,3,57,19.0,0,0,['self'],[None],[None],163,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/PullRequestComment.py:PullRequestComment:delete,PullRequestComment:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],170,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/pulls/comments/{number} <http://docs.github.com/en/rest/reference/pulls#comments>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/PullRequestComment.py:PullRequestComment:edit,PullRequestComment:edit,method,6,17,17,181,10.65,0,0,"['self', 'body']","[None, None]","[None, None]",177,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo}/pulls/comments/{number} <http://docs.github.com/en/rest/reference/pulls#comments>`_\n', '        :param body: string\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'self._useAttributes']",2
github/PullRequestComment.py:PullRequestComment:get_reactions,PullRequestComment:get_reactions,method,2,9,9,170,18.89,0,0,['self'],[None],[None],192,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/pulls/comments/{number}/reactions\n', '                <https://docs.github.com/en/rest/reference/reactions#list-reactions-for-a-pull-request-review-comment>`_\n', '        :return: :class: :class:`github.PaginatedList.PaginatedList` of :class:`github.Reaction.Reaction`\n', '        """"""\n']",[],0
github/PullRequestComment.py:PullRequestComment:create_reaction,PullRequestComment:create_reaction,method,7,23,22,331,14.39,0,0,"['self', 'reaction_type']","[None, None]","[None, None]",206,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/pulls/comments/{number}/reactions\n', '                <https://docs.github.com/en/rest/reference/reactions#create-reaction-for-a-pull-request-review-comment>`_\n', '        :param reaction_type: string\n', '        :rtype: :class:`github.Reaction.Reaction`\n', '        """"""\n']",['isinstance'],1
github/PullRequestComment.py:PullRequestComment:delete_reaction,PullRequestComment:delete_reaction,method,7,16,16,207,12.94,0,0,"['self', 'reaction_id']","[None, None]","[None, None]",225,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions/{reaction_id}\n', '                <https://docs.github.com/en/rest/reference/reactions#delete-a-pull-request-comment-reaction>`_\n', '        :param reaction_id: integer\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/PullRequestComment.py:PullRequestComment:_initAttributes,PullRequestComment:_initAttributes,method,16,30,17,645,21.5,0,0,['self'],[None],[None],240,[],[],0
github/PullRequestComment.py:PullRequestComment:_useAttributes,PullRequestComment:_useAttributes,method,19,159,58,1663,10.46,0,15,"['self', 'attributes']","[None, None]","[None, None]",257,[],"['self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeClassAttribute']",4
github/PullRequestMergeStatus.py:PullRequestMergeStatus,PullRequestMergeStatus,class,17,63,34,718,11.4,0,3,[],[],[],35,[],[],0
github/PullRequestMergeStatus.py:PullRequestMergeStatus:__repr__,PullRequestMergeStatus:__repr__,method,2,5,5,75,15.0,0,0,['self'],[None],[None],40,[],['self.get__repr__'],1
github/PullRequestMergeStatus.py:PullRequestMergeStatus:merged,PullRequestMergeStatus:merged,method,2,2,2,24,12.0,0,0,['self'],[None],[None],44,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/PullRequestMergeStatus.py:PullRequestMergeStatus:message,PullRequestMergeStatus:message,method,2,2,2,25,12.5,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/PullRequestMergeStatus.py:PullRequestMergeStatus:sha,PullRequestMergeStatus:sha,method,2,2,2,21,10.5,0,0,['self'],[None],[None],58,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/PullRequestMergeStatus.py:PullRequestMergeStatus:_initAttributes,PullRequestMergeStatus:_initAttributes,method,4,6,5,117,19.5,0,0,['self'],[None],[None],64,[],[],0
github/PullRequestMergeStatus.py:PullRequestMergeStatus:_useAttributes,PullRequestMergeStatus:_useAttributes,method,5,30,16,291,9.7,0,3,"['self', 'attributes']","[None, None]","[None, None]",69,[],"['self._makeBoolAttribute', 'self._makeStringAttribute']",2
github/PullRequestPart.py:PullRequestPart,PullRequestPart,class,23,101,47,1080,10.69,0,5,[],[],[],36,[],[],0
github/PullRequestPart.py:PullRequestPart:__repr__,PullRequestPart:__repr__,method,2,3,3,47,15.67,0,0,['self'],[None],[None],41,[],['self.get__repr__'],1
github/PullRequestPart.py:PullRequestPart:label,PullRequestPart:label,method,2,2,2,23,11.5,0,0,['self'],[None],[None],45,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/PullRequestPart.py:PullRequestPart:ref,PullRequestPart:ref,method,2,2,2,21,10.5,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/PullRequestPart.py:PullRequestPart:repo,PullRequestPart:repo,method,2,2,2,22,11.0,0,0,['self'],[None],[None],59,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",[],0
github/PullRequestPart.py:PullRequestPart:sha,PullRequestPart:sha,method,2,2,2,21,10.5,0,0,['self'],[None],[None],66,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/PullRequestPart.py:PullRequestPart:user,PullRequestPart:user,method,2,2,2,22,11.0,0,0,['self'],[None],[None],73,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/PullRequestPart.py:PullRequestPart:_initAttributes,PullRequestPart:_initAttributes,method,6,10,7,188,18.8,0,0,['self'],[None],[None],79,[],[],0
github/PullRequestPart.py:PullRequestPart:_useAttributes,PullRequestPart:_useAttributes,method,7,56,27,524,9.36,0,5,"['self', 'attributes']","[None, None]","[None, None]",86,[],"['self._makeStringAttribute', 'self._makeClassAttribute']",2
github/PullRequestReview.py:PullRequestReview,PullRequestReview,class,40,170,78,2026,11.92,0,8,[],[],[],31,[],[],0
github/PullRequestReview.py:PullRequestReview:__repr__,PullRequestReview:__repr__,method,2,5,5,69,13.8,0,0,['self'],[None],[None],36,[],['self.get__repr__'],1
github/PullRequestReview.py:PullRequestReview:id,PullRequestReview:id,method,2,2,2,20,10.0,0,0,['self'],[None],[None],40,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/PullRequestReview.py:PullRequestReview:user,PullRequestReview:user,method,2,2,2,22,11.0,0,0,['self'],[None],[None],47,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/PullRequestReview.py:PullRequestReview:body,PullRequestReview:body,method,2,2,2,22,11.0,0,0,['self'],[None],[None],54,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/PullRequestReview.py:PullRequestReview:commit_id,PullRequestReview:commit_id,method,2,2,2,27,13.5,0,0,['self'],[None],[None],61,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/PullRequestReview.py:PullRequestReview:state,PullRequestReview:state,method,2,2,2,23,11.5,0,0,['self'],[None],[None],68,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/PullRequestReview.py:PullRequestReview:html_url,PullRequestReview:html_url,method,2,2,2,26,13.0,0,0,['self'],[None],[None],75,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/PullRequestReview.py:PullRequestReview:pull_request_url,PullRequestReview:pull_request_url,method,2,2,2,34,17.0,0,0,['self'],[None],[None],82,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/PullRequestReview.py:PullRequestReview:submitted_at,PullRequestReview:submitted_at,method,2,2,2,30,15.0,0,0,['self'],[None],[None],89,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/PullRequestReview.py:PullRequestReview:dismiss,PullRequestReview:dismiss,method,5,14,14,212,15.14,0,0,"['self', 'message']","[None, None]","[None, None]",95,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/pulls/{number}/reviews/{review_id}/dismissals <https://docs.github.com/en/rest/reference/pulls#reviews>`_\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/PullRequestReview.py:PullRequestReview:_initAttributes,PullRequestReview:_initAttributes,method,9,16,10,331,20.69,0,0,['self'],[None],[None],108,[],[],0
github/PullRequestReview.py:PullRequestReview:_useAttributes,PullRequestReview:_useAttributes,method,12,85,35,864,10.16,0,8,"['self', 'attributes']","[None, None]","[None, None]",118,[],"['self._makeIntAttribute', 'self._makeClassAttribute', 'self._makeStringAttribute', 'self._makeDatetimeAttribute']",4
github/Rate.py:Rate,Rate,class,17,69,40,778,11.28,0,3,[],[],[],31,[],[],0
github/Rate.py:Rate:__repr__,Rate:__repr__,method,2,11,11,118,10.73,0,0,['self'],[None],[None],36,[],['self.get__repr__'],1
github/Rate.py:Rate:limit,Rate:limit,method,2,2,2,23,11.5,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Rate.py:Rate:remaining,Rate:remaining,method,2,2,2,27,13.5,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Rate.py:Rate:reset,Rate:reset,method,2,2,2,23,11.5,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/Rate.py:Rate:_initAttributes,Rate:_initAttributes,method,4,6,5,120,20.0,0,0,['self'],[None],[None],66,[],[],0
github/Rate.py:Rate:_useAttributes,Rate:_useAttributes,method,5,30,16,299,9.97,0,3,"['self', 'attributes']","[None, None]","[None, None]",71,[],"['self._makeIntAttribute', 'self._makeTimestampAttribute']",2
github/RateLimit.py:RateLimit,RateLimit,class,16,68,37,752,11.06,0,3,[],[],[],32,[],[],0
github/RateLimit.py:RateLimit:__repr__,RateLimit:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],37,[],['self.get__repr__'],1
github/RateLimit.py:RateLimit:core,RateLimit:core,method,2,2,2,22,11.0,0,0,['self'],[None],[None],41,"['        """"""\n', '        Rate limit for the non-search-related API\n', '\n', '        :type: class:`github.Rate.Rate`\n', '        """"""\n']",[],0
github/RateLimit.py:RateLimit:search,RateLimit:search,method,2,2,2,24,12.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        Rate limit for the Search API.\n', '\n', '        :type: class:`github.Rate.Rate`\n', '        """"""\n']",[],0
github/RateLimit.py:RateLimit:graphql,RateLimit:graphql,method,2,2,2,25,12.5,0,0,['self'],[None],[None],59,"['        """"""\n', '        (Experimental) Rate limit for GraphQL API, use with caution.\n', '\n', '        :type: class:`github.Rate.Rate`\n', '        """"""\n']",[],0
github/RateLimit.py:RateLimit:_initAttributes,RateLimit:_initAttributes,method,4,6,5,118,19.67,0,0,['self'],[None],[None],67,[],[],0
github/RateLimit.py:RateLimit:_useAttributes,RateLimit:_useAttributes,method,4,37,21,348,9.41,0,3,"['self', 'attributes']","[None, None]","[None, None]",72,[],['self._makeClassAttribute'],1
github/Reaction.py:Reaction,Reaction,class,26,95,53,1251,13.17,0,4,[],[],[],31,[],[],0
github/Reaction.py:Reaction:__repr__,Reaction:__repr__,method,2,5,5,69,13.8,0,0,['self'],[None],[None],36,[],['self.get__repr__'],1
github/Reaction.py:Reaction:content,Reaction:content,method,3,3,3,63,21.0,0,0,['self'],[None],[None],40,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Reaction.py:Reaction:created_at,Reaction:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],48,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Reaction.py:Reaction:id,Reaction:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],56,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Reaction.py:Reaction:user,Reaction:user,method,3,3,3,57,19.0,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Reaction.py:Reaction:delete,Reaction:delete,method,2,6,6,147,24.5,0,0,['self'],[None],[None],71,"['        """"""\n', '        :calls: `DELETE /reactions/{id} <https://docs.github.com/en/rest/reference/reactions#delete-a-reaction>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Reaction.py:Reaction:_initAttributes,Reaction:_initAttributes,method,5,8,6,158,19.75,0,0,['self'],[None],[None],82,[],[],0
github/Reaction.py:Reaction:_useAttributes,Reaction:_useAttributes,method,8,43,22,423,9.84,0,4,"['self', 'attributes']","[None, None]","[None, None]",88,[],"['self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeClassAttribute']",4
github/Referrer.py:Referrer,Referrer,class,17,69,40,783,11.35,0,3,[],[],[],30,[],[],0
github/Referrer.py:Referrer:__repr__,Referrer:__repr__,method,2,11,11,120,10.91,0,0,['self'],[None],[None],36,[],['self.get__repr__'],1
github/Referrer.py:Referrer:referrer,Referrer:referrer,method,2,2,2,26,13.0,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Referrer.py:Referrer:count,Referrer:count,method,2,2,2,23,11.5,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Referrer.py:Referrer:uniques,Referrer:uniques,method,2,2,2,25,12.5,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/Referrer.py:Referrer:_initAttributes,Referrer:_initAttributes,method,4,6,5,121,20.17,0,0,['self'],[None],[None],66,[],[],0
github/Referrer.py:Referrer:_useAttributes,Referrer:_useAttributes,method,5,30,16,299,9.97,0,3,"['self', 'attributes']","[None, None]","[None, None]",71,[],"['self._makeStringAttribute', 'self._makeIntAttribute']",2
github/Repository.py:Repository,Repository,class,467,4123,1326,55728,13.52,9,81,[],[],[],148,[],[],0
github/Repository.py:Repository:__repr__,Repository:__repr__,method,2,3,3,59,19.67,0,0,['self'],[None],[None],153,[],['self.get__repr__'],1
github/Repository.py:Repository:allow_merge_commit,Repository:allow_merge_commit,method,3,3,3,85,28.33,0,0,['self'],[None],[None],157,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:allow_rebase_merge,Repository:allow_rebase_merge,method,3,3,3,85,28.33,0,0,['self'],[None],[None],165,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:allow_squash_merge,Repository:allow_squash_merge,method,3,3,3,85,28.33,0,0,['self'],[None],[None],173,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:archived,Repository:archived,method,3,3,3,65,21.67,0,0,['self'],[None],[None],181,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:archive_url,Repository:archive_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],189,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:assignees_url,Repository:assignees_url,method,3,3,3,75,25.0,0,0,['self'],[None],[None],197,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:blobs_url,Repository:blobs_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],205,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:branches_url,Repository:branches_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],213,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:clone_url,Repository:clone_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],221,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:collaborators_url,Repository:collaborators_url,method,3,3,3,83,27.67,0,0,['self'],[None],[None],229,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:comments_url,Repository:comments_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],237,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:commits_url,Repository:commits_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],245,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:compare_url,Repository:compare_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],253,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:contents_url,Repository:contents_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],261,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:contributors_url,Repository:contributors_url,method,3,3,3,81,27.0,0,0,['self'],[None],[None],269,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:created_at,Repository:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],277,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:default_branch,Repository:default_branch,method,3,3,3,77,25.67,0,0,['self'],[None],[None],285,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:delete_branch_on_merge,Repository:delete_branch_on_merge,method,3,3,3,93,31.0,0,0,['self'],[None],[None],293,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:deployments_url,Repository:deployments_url,method,3,3,3,79,26.33,0,0,['self'],[None],[None],301,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:description,Repository:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],309,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:downloads_url,Repository:downloads_url,method,3,3,3,75,25.0,0,0,['self'],[None],[None],317,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:events_url,Repository:events_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],325,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:fork,Repository:fork,method,3,3,3,57,19.0,0,0,['self'],[None],[None],333,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:forks,Repository:forks,method,3,3,3,59,19.67,0,0,['self'],[None],[None],341,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:forks_count,Repository:forks_count,method,3,3,3,71,23.67,0,0,['self'],[None],[None],349,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:forks_url,Repository:forks_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],357,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:full_name,Repository:full_name,method,3,3,3,67,22.33,0,0,['self'],[None],[None],365,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:git_commits_url,Repository:git_commits_url,method,3,3,3,79,26.33,0,0,['self'],[None],[None],373,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:git_refs_url,Repository:git_refs_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],381,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:git_tags_url,Repository:git_tags_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],389,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:git_url,Repository:git_url,method,3,3,3,63,21.0,0,0,['self'],[None],[None],397,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:has_downloads,Repository:has_downloads,method,3,3,3,75,25.0,0,0,['self'],[None],[None],405,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:has_issues,Repository:has_issues,method,3,3,3,69,23.0,0,0,['self'],[None],[None],413,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:has_pages,Repository:has_pages,method,3,3,3,67,22.33,0,0,['self'],[None],[None],421,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:has_projects,Repository:has_projects,method,3,3,3,73,24.33,0,0,['self'],[None],[None],429,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:has_wiki,Repository:has_wiki,method,3,3,3,65,21.67,0,0,['self'],[None],[None],437,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:homepage,Repository:homepage,method,3,3,3,65,21.67,0,0,['self'],[None],[None],445,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:hooks_url,Repository:hooks_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],453,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:html_url,Repository:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],461,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:id,Repository:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],469,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:issue_comment_url,Repository:issue_comment_url,method,3,3,3,83,27.67,0,0,['self'],[None],[None],477,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:issue_events_url,Repository:issue_events_url,method,3,3,3,81,27.0,0,0,['self'],[None],[None],485,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:issues_url,Repository:issues_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],493,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:keys_url,Repository:keys_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],501,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:labels_url,Repository:labels_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],509,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:language,Repository:language,method,3,3,3,65,21.67,0,0,['self'],[None],[None],517,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:languages_url,Repository:languages_url,method,3,3,3,75,25.0,0,0,['self'],[None],[None],525,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:master_branch,Repository:master_branch,method,3,3,3,75,25.0,0,0,['self'],[None],[None],533,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:merges_url,Repository:merges_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],541,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:milestones_url,Repository:milestones_url,method,3,3,3,77,25.67,0,0,['self'],[None],[None],549,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:mirror_url,Repository:mirror_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],557,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:name,Repository:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],565,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:network_count,Repository:network_count,method,3,3,3,75,25.0,0,0,['self'],[None],[None],573,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:notifications_url,Repository:notifications_url,method,3,3,3,83,27.67,0,0,['self'],[None],[None],581,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:open_issues,Repository:open_issues,method,3,3,3,71,23.67,0,0,['self'],[None],[None],589,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:open_issues_count,Repository:open_issues_count,method,3,3,3,83,27.67,0,0,['self'],[None],[None],597,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:organization,Repository:organization,method,3,3,3,73,24.33,0,0,['self'],[None],[None],605,"['        """"""\n', '        :type: :class:`github.Organization.Organization`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:owner,Repository:owner,method,3,3,3,59,19.67,0,0,['self'],[None],[None],613,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:parent,Repository:parent,method,3,3,3,61,20.33,0,0,['self'],[None],[None],621,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:permissions,Repository:permissions,method,3,3,3,71,23.67,0,0,['self'],[None],[None],629,"['        """"""\n', '        :type: :class:`github.Permissions.Permissions`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:private,Repository:private,method,3,3,3,63,21.0,0,0,['self'],[None],[None],637,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:pulls_url,Repository:pulls_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],645,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:pushed_at,Repository:pushed_at,method,3,3,3,67,22.33,0,0,['self'],[None],[None],653,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:releases_url,Repository:releases_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],661,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:size,Repository:size,method,3,3,3,57,19.0,0,0,['self'],[None],[None],669,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:source,Repository:source,method,3,3,3,61,20.33,0,0,['self'],[None],[None],677,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:ssh_url,Repository:ssh_url,method,3,3,3,63,21.0,0,0,['self'],[None],[None],685,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:stargazers_count,Repository:stargazers_count,method,6,19,13,145,7.63,0,0,['self'],[None],[None],693,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:stargazers_url,Repository:stargazers_url,method,3,3,3,77,25.67,0,0,['self'],[None],[None],703,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:statuses_url,Repository:statuses_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],711,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:subscribers_url,Repository:subscribers_url,method,3,3,3,79,26.33,0,0,['self'],[None],[None],719,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:subscribers_count,Repository:subscribers_count,method,3,3,3,83,27.67,0,0,['self'],[None],[None],727,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:subscription_url,Repository:subscription_url,method,3,3,3,81,27.0,0,0,['self'],[None],[None],735,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:svn_url,Repository:svn_url,method,3,3,3,63,21.0,0,0,['self'],[None],[None],743,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:tags_url,Repository:tags_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],751,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:teams_url,Repository:teams_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],759,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:trees_url,Repository:trees_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],767,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:updated_at,Repository:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],775,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:url,Repository:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],783,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:watchers,Repository:watchers,method,3,3,3,65,21.67,0,0,['self'],[None],[None],791,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:watchers_count,Repository:watchers_count,method,3,3,3,77,25.67,0,0,['self'],[None],[None],799,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:add_to_collaborators,Repository:add_to_collaborators,method,7,36,29,368,10.22,0,2,"['self', 'collaborator', 'permission']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",806,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/collaborators/{user} <http://docs.github.com/en/rest/reference/repos#collaborators>`_\n', '        :param collaborator: string or :class:`github.NamedUser.NamedUser`\n', ""        :param permission: string 'pull', 'push' or 'admin'\n"", '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:get_collaborator_permission,Repository:get_collaborator_permission,method,0,1,1,54,54.0,0,0,"['self', 'collaborator']","[None, None]","[None, None]",839,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/collaborators/{username}/permission <http://docs.github.com/en/rest/reference/repos#collaborators>`_\n', '        :param collaborator: string or :class:`github.NamedUser.NamedUser`\n', '        :rtype: string\n', '        """"""\n']",[],0
github/Repository.py:Repository:get_pending_invitations,Repository:get_pending_invitations,method,1,2,2,56,28.0,0,0,['self'],[None],[None],856,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/invitations <https://docs.github.com/en/rest/reference/repos#invitations>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Invitation.Invitation`\n', '        """"""\n']",[],0
github/Repository.py:Repository:remove_invitation,Repository:remove_invitation,method,1,6,6,88,14.67,0,0,"['self', 'invite_id']","[None, None]","[None, None]",868,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/invitations/{invitation_id} <https://docs.github.com/en/rest/reference/repos#invitations>`_\n', '        :rtype: None\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:compare,Repository:compare,method,3,3,3,71,23.67,0,0,['self'],[None],[None],879,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/compare/{base...:head} <http://docs.github.com/en/rest/reference/repos#commits>`_\n', '        :param base: string\n', '        :param head: string\n', '        :rtype: :class:`github.Comparison.Comparison`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:create_git_blob,Repository:create_git_blob,method,1,15,13,170,11.33,0,0,"['self', 'content', 'encoding']","[None, None, None]","[None, None, None]",895,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/git/blobs <http://docs.github.com/en/rest/reference/git#blobs>`_\n', '        :param content: string\n', '        :param encoding: string\n', '        :rtype: :class:`github.GitBlob.GitBlob`\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:create_git_commit,Repository:create_git_commit,method,1,2,2,42,21.0,0,0,"['message', 'tree', 'parents', 'author', 'committer', 'message', 'str)', 'messagetree', 'github.GitTree.GitTree)', 'treeelement', 'github.GitCommit.GitCommit) for element in parentsauthor', 'github.InputGitAuthorcommitter', 'github.InputGitAuthor""message""', '""tree""', '""parents""', 'if author is not github.GithubObject.NotSet']","[None, None, None, None, None, None, None, None, None, None, None, None, ' message', ' tree._identity', ' [element._identity for element in parents]', '']","[None, None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None, None, None, None, None, None, None, None, None, None, None]",913,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/git/commits <http://docs.github.com/en/rest/reference/git#commits>`_\n', '        :param message: string\n', '        :param tree: :class:`github.GitTree.GitTree`\n', '        :param parents: list of :class:`github.GitCommit.GitCommit`\n', '        :param author: :class:`github.InputGitAuthor.InputGitAuthor`\n', '        :param committer: :class:`github.InputGitAuthor.InputGitAuthor`\n', '        :rtype: :class:`github.GitCommit.GitCommit`\n', '        """"""\n']",[],0
github/Repository.py:Repository:create_git_ref,Repository:create_git_ref,method,1,9,9,91,10.11,0,0,"['self', 'ref', 'sha']","[None, None, None]","[None, None, None]",957,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/git/refs <http://docs.github.com/en/rest/reference/git#refs>`_\n', '        :param ref: string\n', '        :param sha: string\n', '        :rtype: :class:`github.GitRef.GitRef`\n', '        """"""\n']",[],0
github/Repository.py:Repository:create_git_tag_and_release,Repository:create_git_tag_and_release,method,1,2,2,52,26.0,0,0,"['tag', 'tag_message', 'release_name', 'release_message', 'object', 'type', 'tagger', 'draft', 'prerelease', 'tag', 'tag_message', 'object', 'type', 'tagger)tag', 'release_name', 'release_message', 'draft', 'prerelease', 'target_commitish', 'tag', 'message', 'draft', 'prerelease', 'target_commitish', 'tag', 'str)', 'tagmessage', 'str)', 'messagedraft', 'bool)', 'draftprerelease', 'bool)', 'prereleasetarget_commitish', 'str', 'github.Branch.Branch', 'github.Commit.Commit', 'github.GitCommit.GitCommit', 'post_parameters = {""tag_name""', '""body""', '""draft""', '""prerelease""', '}target_commitish', 'str)']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '', ' message', ' draft', ' prerelease', None, '']","[None, None, None, None, None, None, 'github.GithubObject.NotSet', 'False', 'False', None, None, None, None, None, None, None, None, None, 'object', None, None, 'False', 'False', 'github.GithubObject.NotSet', None, None, None, None, None, None, None, None, None, None, None, None, None, ' {""tag_name"": tag', None, None, None, None, None]",975,"['        """"""\n', '        Convenience function that calls :meth:`Repository.create_git_tag` and\n', '        :meth:`Repository.create_git_release`.\n', '\n', '        :param tag: string\n', '        :param tag_message: string\n', '        :param release_name: string\n', '        :param release_message: string\n', '        :param object: string\n', '        :param type: string\n', '        :param tagger: :class:github.InputGitAuthor.InputGitAuthor\n', '        :param draft: bool\n', '        :param prerelease: bool\n', '        :rtype: :class:`github.GitRelease.GitRelease`\n', '        """"""\n']",[],0
github/Repository.py:Repository:create_git_release,Repository:create_git_release,method,1,2,2,52,26.0,0,0,"['tag', 'message', 'draft', 'prerelease', 'target_commitish', 'tag', 'str)', 'tagmessage', 'str)', 'messagedraft', 'bool)', 'draftprerelease', 'bool)', 'prereleasetarget_commitish', 'str', 'github.Branch.Branch', 'github.Commit.Commit', 'github.GitCommit.GitCommit', 'post_parameters = {""tag_name""', '""body""', '""draft""', '""prerelease""', '}target_commitish', 'str)']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '', ' message', ' draft', ' prerelease', None, '']","[None, None, 'False', 'False', 'github.GithubObject.NotSet', None, None, None, None, None, None, None, None, None, None, None, None, None, ' {""tag_name"": tag', None, None, None, None, None]",1012,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/releases <http://docs.github.com/en/rest/reference/repos#releases>`_\n', '        :param tag: string\n', '        :param name: string\n', '        :param message: string\n', '        :param draft: bool\n', '        :param prerelease: bool\n', '        :param target_commitish: string or :class:`github.Branch.Branch` or :class:`github.Commit.Commit` or :class:`github.GitCommit.GitCommit`\n', '        :rtype: :class:`github.GitRelease.GitRelease`\n', '        """"""\n']",[],0
github/Repository.py:Repository:create_git_tag,Repository:create_git_tag,method,1,2,2,52,26.0,0,0,"['tag', 'tag_message', 'release_name', 'release_message', 'object', 'type', 'tagger', 'draft', 'prerelease', 'tag', 'tag_message', 'object', 'type', 'tagger)tag', 'release_name', 'release_message', 'draft', 'prerelease', 'target_commitish', 'tag', 'message', 'draft', 'prerelease', 'target_commitish', 'tag', 'str)', 'tagmessage', 'str)', 'messagedraft', 'bool)', 'draftprerelease', 'bool)', 'prereleasetarget_commitish', 'str', 'github.Branch.Branch', 'github.Commit.Commit', 'github.GitCommit.GitCommit', 'post_parameters = {""tag_name""', '""body""', '""draft""', '""prerelease""', '}target_commitish', 'str)']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '', ' message', ' draft', ' prerelease', None, '']","[None, None, None, None, None, None, 'github.GithubObject.NotSet', 'False', 'False', None, None, None, None, None, None, None, None, None, 'object', None, None, 'False', 'False', 'github.GithubObject.NotSet', None, None, None, None, None, None, None, None, None, None, None, None, None, ' {""tag_name"": tag', None, None, None, None, None]",1067,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/git/tags <http://docs.github.com/en/rest/reference/git#tags>`_\n', '        :param tag: string\n', '        :param message: string\n', '        :param object: string\n', '        :param type: string\n', '        :param tagger: :class:`github.InputGitAuthor.InputGitAuthor`\n', '        :rtype: :class:`github.GitTag.GitTag`\n', '        """"""\n']",[],0
github/Repository.py:Repository:create_git_tree,Repository:create_git_tree,method,8,39,31,392,10.05,0,1,"['self', 'tree', 'base_tree']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",1099,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/git/trees <http://docs.github.com/en/rest/reference/git#trees>`_\n', '        :param tree: list of :class:`github.InputGitTreeElement.InputGitTreeElement`\n', '        :param base_tree: :class:`github.GitTree.GitTree`\n', '        :rtype: :class:`github.GitTree.GitTree`\n', '        """"""\n']","['all', 'isinstance']",2
github/Repository.py:Repository:create_hook,Repository:create_hook,method,1,2,2,32,16.0,0,0,"['name', 'config', 'events', 'active', 'config', 'dict)', 'configelement', 'str) for element in eventsactive', 'bool)', 'activepost_parameters = {""name""', '""config""', '}if events is not github.GithubObject.NotSet']","[None, None, None, None, None, None, None, None, None, '', ' config', '']","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None, None, None, None, None, ' {""name"": name', None, None]",1122,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/hooks <http://docs.github.com/en/rest/reference/repos#webhooks>`_\n', '        :param name: string\n', '        :param config: dict\n', '        :param events: list of string\n', '        :param active: bool\n', '        :rtype: :class:`github.Hook.Hook`\n', '        """"""\n']",[],0
github/Repository.py:Repository:create_issue,Repository:create_issue,method,1,6,5,112,18.67,0,0,"['title', 'body', 'assignees', 'title', 'str)', 'titlebody', 'str)', 'bodyelement', 'github.NamedUser.NamedUser) or isinstance(element', 'str)for element in assigneesmilestone', 'github.Milestone.Milestonepost_parameters = {""title""', '}if body is not github.GithubObject.NotSet']","[None, None, None, None, None, None, None, None, None, None, '', '']","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None, None, None, None, None, None, None, ' {""title"": title', None]",1156,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/issues <http://docs.github.com/en/rest/reference/issues>`_\n', '        :param title: string\n', '        :param body: string\n', '        :param assignee: string or :class:`github.NamedUser.NamedUser`\n', '        :param assignees: list of string or :class:`github.NamedUser.NamedUser`\n', '        :param milestone: :class:`github.Milestone.Milestone`\n', '        :param labels: list of :class:`github.Label.Label`\n', '        :rtype: :class:`github.Issue.Issue`\n', '        """"""\n']",[],0
github/Repository.py:Repository:create_key,Repository:create_key,method,2,24,21,223,9.29,0,0,"['self', 'title', 'key', 'read_only']","[None, None, None, None]","[None, None, None, 'False']",1223,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/keys <http://docs.github.com/en/rest/reference/repos#deploy-keys>`_\n', '        :param title: string\n', '        :param key: string\n', '        :param read_only: bool\n', '        :rtype: :class:`github.RepositoryKey.RepositoryKey`\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:create_label,Repository:create_label,method,7,35,29,379,10.83,0,1,"['self', 'name', 'color', 'description']","[None, None, None, None]","[None, None, None, 'github.GithubObject.NotSet']",1246,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/labels <http://docs.github.com/en/rest/reference/issues#labels>`_\n', '        :param name: string\n', '        :param color: string\n', '        :param description: string\n', '        :rtype: :class:`github.Label.Label`\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:create_milestone,Repository:create_milestone,method,1,2,2,42,21.0,0,0,"['title', 'description', 'due_on', 'title', 'str)', 'titledescription', 'strdatetime.datetime', 'datetime.date)post_parameters = {""title""', '}post_parameters[""state""] = stateif description is not github.GithubObject.NotSet']","[None, None, None, None, None, None, None, '', '']","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None, None, None, None, ' {""title"": title', ' stateif description is not github.GithubObject.NotSet:']",1273,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/milestones <http://docs.github.com/en/rest/reference/issues#milestones>`_\n', '        :param title: string\n', '        :param state: string\n', '        :param description: string\n', '        :param due_on: datetime\n', '        :rtype: :class:`github.Milestone.Milestone`\n', '        """"""\n']",[],0
github/Repository.py:Repository:create_project,Repository:create_project,method,9,36,31,403,11.19,0,1,"['self', 'name', 'body']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",1315,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/projects <https://docs.github.com/en/rest/reference/projects#create-a-repository-project>`_\n', '        :param name: string\n', '        :param body: string\n', '        :rtype: :class:`github.Project.Project`\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:create_pull,Repository:create_pull,method,3,10,9,107,10.7,0,1,"['self', '*args', '**kwds']","[None, None, None]","[None, None, None]",1335,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/pulls <http://docs.github.com/en/rest/reference/pulls>`_\n', '        :param title: string\n', '        :param body: string\n', '        :param issue: :class:`github.Issue.Issue`\n', '        :param base: string\n', '        :param head: string\n', '        :param draft: bool\n', '        :param maintainer_can_modify: bool\n', '        :rtype: :class:`github.PullRequest.PullRequest`\n', '        """"""\n']","['len', 'self.__create_pull_1', 'self.__create_pull_2']",3
github/Repository.py:Repository:__create_pull_1,Repository:__create_pull_1,method,2,15,13,209,13.93,0,0,"['title', 'body', 'base', 'head', 'maintainer_can_modify', 'draft', 'title', 'str)', 'titlebody', 'str)', 'bodybase', 'str)', 'basehead', 'str)', 'headmaintainer_can_modify', 'booldraft', 'bool)', 'draftif maintainer_can_modify is not github.GithubObject.NotSet']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, None, None, None, 'github.GithubObject.NotSet', 'False', None, None, None, None, None, None, None, None, None, None, None, None]",1352,[],['self.__create_pull'],1
github/Repository.py:Repository:__create_pull_2,Repository:__create_pull_2,method,3,16,13,180,11.25,0,0,"['self', 'issue', 'base', 'head']","[None, None, None, None]","[None, None, None, None]",1383,[],"['isinstance', 'self.__create_pull']",2
github/Repository.py:Repository:__create_pull,Repository:__create_pull,method,2,20,18,251,12.55,0,0,"['title', 'body', 'base', 'head', 'maintainer_can_modify', 'draft', 'title', 'str)', 'titlebody', 'str)', 'bodybase', 'str)', 'basehead', 'str)', 'headmaintainer_can_modify', 'booldraft', 'bool)', 'draftif maintainer_can_modify is not github.GithubObject.NotSet']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, None, None, None, 'github.GithubObject.NotSet', 'False', None, None, None, None, None, None, None, None, None, None, None, None]",1389,"['        """"""\n', '        :calls: POST /repos/{owner}/{repo}/dispatches <https://docs.github.com/en/rest/reference/repos#create-a-repository-dispatch-event>\n', '        :param event_type: string\n', '        :param client_payload: dict\n', '        :rtype: bool\n', '        """"""\n']","['self.__create_pull', '__create_pull_2']",2
github/Repository.py:Repository:create_repository_dispatch,Repository:create_repository_dispatch,method,1,5,5,102,20.4,0,0,"['self', 'event_type', 'client_payload', 'str)', 'event_typeclient_payload', 'dictpost_parameters = {""event_type""']","[None, None, None, None, None, '']","[None, None, 'github.GithubObject.NotSetevent_type', None, None, ' {""event_type"": event_type}if client_payload is not github.GithubObject.NotSet:']",1399,"['        """"""\n', '        :calls: POST /repos/{owner}/{repo}/dispatches <https://docs.github.com/en/rest/reference/repos#create-a-repository-dispatch-event>\n', '        :param event_type: string\n', '        :param client_payload: dict\n', '        :rtype: bool\n', '        """"""\n']",[],0
github/Repository.py:Repository:create_secret,Repository:create_secret,method,8,25,23,345,13.8,0,0,"['self', 'secret_name', 'unencrypted_value']","[None, None, None]","[None, None, None]",1420,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/actions/secrets/{secret_name} <https://docs.github.com/en/rest/reference/actions#get-a-repository-secret>`_\n', '        :param secret_name: string\n', '        :param unencrypted_value: string\n', '        :rtype: bool\n', '        """"""\n']","['isinstance', 'self.get_public_key', 'public_key.encrypt']",3
github/Repository.py:Repository:delete_secret,Repository:delete_secret,method,5,10,10,147,14.7,0,0,"['self', 'secret_name']","[None, None]","[None, None]",1440,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/actions/secrets/{secret_name} <https://docs.github.com/en/rest/reference/actions#delete-a-repository-secret>`_\n', '        :param secret_name: string\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:create_source_import,Repository:create_source_import,method,9,57,38,633,11.11,0,2,"['vcs', 'vcs_url', 'vcs_username', 'vcs_password', '']","[None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",1452,"['        """"""\n', '        :calls: `PUT /repos/{owner}/{repo}/import <https://docs.github.com/en/rest/reference/migration/source_imports#start-an-import>`_\n', '        :param vcs: string\n', '        :param vcs_url: string\n', '        :param vcs_username: string\n', '        :param vcs_password: string\n', '        :rtype: :class:`github.SourceImport.SourceImport`\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:delete,Repository:delete,method,3,3,3,93,31.0,0,0,['self'],[None],[None],1493,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo} <http://docs.github.com/en/rest/reference/repos>`_\n', '        :rtype: None\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Repository.py:Repository:edit,Repository:edit,method,21,244,82,2645,10.84,0,14,"['name', 'description', 'homepage', 'private', 'has_issues', 'has_projects', 'has_wiki', 'has_downloads', 'default_branch', 'allow_squash_merge', 'allow_merge_commit', 'allow_rebase_merge', 'delete_branch_on_merge', 'archived', '']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]","['None', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",1500,"['        """"""\n', '        :calls: `PATCH /repos/{owner}/{repo} <http://docs.github.com/en/rest/reference/repos>`_\n', '        :param name: string\n', '        :param description: string\n', '        :param homepage: string\n', '        :param private: bool\n', '        :param has_issues: bool\n', '        :param has_projects: bool\n', '        :param has_wiki: bool\n', '        :param has_downloads: bool\n', '        :param default_branch: string\n', '        :param allow_squash_merge: bool\n', '        :param allow_merge_commit: bool\n', '        :param allow_rebase_merge: bool\n', '        :param delete_branch_on_merge: bool\n', '        :param archived: bool. Unarchiving repositories is currently not supported through API (https://docs.github.com/en/rest/reference/repos#edit)\n', '        :rtype: None\n', '        """"""\n']","['isinstance', 'self._useAttributes']",2
github/Repository.py:Repository:get_archive_link,Repository:get_archive_link,method,7,15,14,187,12.47,0,0,"['self', 'archive_format', 'ref']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",1611,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/{archive_format}/{ref} <http://docs.github.com/en/rest/reference/repos#contents>`_\n', '        :param archive_format: string\n', '        :param ref: string\n', '        :rtype: string\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:get_assignees,Repository:get_assignees,method,2,4,4,71,17.75,0,0,['self'],[None],[None],1626,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/assignees <http://docs.github.com/en/rest/reference/issues#assignees>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/Repository.py:Repository:get_branch,Repository:get_branch,method,6,17,17,233,13.71,0,0,"['self', 'branch']","[None, None]","[None, None]",1635,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/branches/{branch} <https://docs.github.com/en/rest/reference/repos/branches#get-branch>`_\n', '        :param branch: string\n', '        :rtype: :class:`github.Branch.Branch`\n', '        """"""\n']","['isinstance', 'get_branches']",2
github/Repository.py:Repository:get_branches,Repository:get_branches,method,2,4,4,64,16.0,0,0,['self'],[None],[None],1647,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/branches <http://docs.github.com/en/rest/reference/repos>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Branch.Branch`\n', '        """"""\n']",[],0
github/Repository.py:Repository:get_collaborators,Repository:get_collaborators,method,5,29,26,311,10.72,0,1,"['self', 'affiliation']","[None, None]","[None, 'github.GithubObject.NotSet']",1656,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/collaborators <http://docs.github.com/en/rest/reference/repos#collaborators>`_\n', '        :param affiliation: string\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:get_comment,Repository:get_comment,method,0,2,2,33,16.5,0,0,"['self', 'id']","[None, None]","[None, None]",1679,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/comments/{id} <http://docs.github.com/en/rest/reference/repos#comments>`_\n', '        :param id: integer\n', '        :rtype: :class:`github.CommitComment.CommitComment`\n', '        """"""\n']",[],0
github/Repository.py:Repository:get_comments,Repository:get_comments,method,1,2,2,59,29.5,0,0,['self'],[None],[None],1693,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/comments <http://docs.github.com/en/rest/reference/repos#comments>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.CommitComment.CommitComment`\n', '        """"""\n']",[],0
github/Repository.py:Repository:get_commit,Repository:get_commit,method,0,2,2,33,16.5,0,0,"['self', 'sha']","[None, None]","[None, None]",1705,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/commits/{sha} <http://docs.github.com/en/rest/reference/repos#commits>`_\n', '        :param sha: string\n', '        :rtype: :class:`github.Commit.Commit`\n', '        """"""\n']",[],0
github/Repository.py:Repository:get_commits,Repository:get_commits,method,13,82,39,885,10.79,0,5,"['self', 'sha', 'path', 'until', 'author', '']","[None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",1717,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/commits <http://docs.github.com/en/rest/reference/repos#commits>`_\n', '        :param sha: string\n', '        :param path: string\n', '        :param since: datetime.datetime\n', '        :param until: datetime.datetime\n', '        :param author: string or :class:`github.NamedUser.NamedUser` or :class:`github.AuthenticatedUser.AuthenticatedUser`\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Commit.Commit`\n', '        """"""\n']","['isinstance', 'until.strftime']",2
github/Repository.py:Repository:get_contents,Repository:get_contents,method,11,46,38,479,10.41,1,4,"['self', 'path', 'ref']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",1774,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/contents/{path} <http://docs.github.com/en/rest/reference/repos#contents>`_\n', '        :param path: string\n', '        :param ref: string\n', '        :rtype: :class:`github.ContentFile.ContentFile` or a list of them\n', '        """"""\n']","['isinstance', 'headers.get']",2
github/Repository.py:Repository:get_deployments,Repository:get_deployments,method,13,69,34,687,9.96,0,4,"['self', 'sha', 'ref', 'task', 'environment', '']","[None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",1814,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/deployments <https://docs.github.com/en/rest/reference/repos#deployments>`_\n', '        :param: sha: string\n', '        :param: ref: string\n', '        :param: task: string\n', '        :param: environment: string\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Deployment.Deployment`\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:get_deployment,Repository:get_deployment,method,16,81,43,872,10.77,0,4,"['self', 'sha', 'ref', 'task', 'environment', '']","[None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",1852,[],"['isinstance', 'get_deployment']",2
github/Repository.py:Repository:create_deployment,Repository:create_deployment,method,16,149,61,1691,11.35,0,8,"['self', 'ref', 'task', 'auto_merge', 'required_contexts', 'payload', 'environment', 'description', 'transient_environment', 'production_environment', '']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",1868,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/deployments <https://docs.github.com/en/rest/reference/repos#deployments>`_\n', '        :param: ref: string\n', '        :param: task: string\n', '        :param: auto_merge: bool\n', '        :param: required_contexts: list of status contexts\n', '        :param: payload: dict\n', '        :param: environment: string\n', '        :param: description: string\n', '        :param: transient_environment: bool\n', '        :param: production_environment: bool\n', '        :rtype: :class:`github.Deployment.Deployment`\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:get_top_referrers,Repository:get_top_referrers,method,0,2,2,45,22.5,0,0,['self'],[None],[None],1946,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/traffic/popular/referrers <https://docs.github.com/en/rest/reference/repos#traffic>`_\n', '        :rtype: :class:`list` of :class:`github.Referrer.Referrer`\n', '        """"""\n']",[],0
github/Repository.py:Repository:get_top_paths,Repository:get_top_paths,method,0,2,2,41,20.5,0,0,['self'],[None],[None],1960,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/traffic/popular/paths <https://docs.github.com/en/rest/reference/repos#traffic>`_\n', '        :rtype: :class:`list` of :class:`github.Path.Path`\n', '        """"""\n']",[],0
github/Repository.py:Repository:get_views_traffic,Repository:get_views_traffic,method,10,59,48,448,7.59,1,2,"['self', 'per']","[None, None]","[None, 'github.GithubObject.NotSet']",1974,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/traffic/views <https://docs.github.com/en/rest/reference/repos#traffic>`_\n', '        :param per: string, must be one of day or week, day by default\n', '        :rtype: None or list of :class:`github.View.View`\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:get_clones_traffic,Repository:get_clones_traffic,method,10,59,48,457,7.75,1,2,"['self', 'per']","[None, None]","[None, 'github.GithubObject.NotSet']",2000,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/traffic/clones <https://docs.github.com/en/rest/reference/repos#traffic>`_\n', '        :param per: string, must be one of day or week, day by default\n', '        :rtype: None or list of :class:`github.Clones.Clones`\n', '        """"""\n']",['isinstance'],1
github/Repository.py:Repository:get_projects,Repository:get_projects,method,1,4,4,91,22.75,0,0,"['self', 'state']","[None, None]","[None, 'github.GithubObject.NotSet']",2026,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/projects <https://docs.github.com/en/rest/reference/projects#list-repository-projects>`_\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.Project.Project`\n', '        :param state: string\n', '        """"""\n']",[],0
github/Repository.py:Repository:create_file,Repository:create_file,method,18,81,51,970,11.98,0,2,"['self', 'path', 'message', 'content', 'committer', 'author', '']","[None, None, None, None, None, None, None]","[None, None, None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",2045,"['        """"""Create a file in this repository.\n', '\n', '        :calls: `PUT /repos/{owner}/{repo}/contents/{path} <https://docs.github.com/en/rest/reference/repos#create-or-update-file-contents>`_\n', '        :param path: string, (required), path of the file in the repository\n', '        :param message: string, (required), commit message\n', '        :param content: string, (required), the actual data in the file\n', '        :param branch: string, (optional), branch to create the commit on. Defaults to the default branch of the repository\n', ""        :param committer: InputGitAuthor, (optional), if no information is given the authenticated user's information will be used. You must specify both a name and email.\n"", '        :param author: InputGitAuthor, (optional), if omitted this will be filled in with committer information. If passed, you must specify both a name and email.\n', '        :rtype: {\n', ""            'content': :class:`ContentFile <github.ContentFile.ContentFile>`:,\n"", ""            'commit': :class:`Commit <github.Commit.Commit>`}\n"", '        """"""\n']","['isinstance', 'content.encode', 'b64encode']",3
github/Repository.py:Repository:update_file,Repository:update_file,method,18,91,54,1047,11.51,0,3,"['self', 'path', 'message', 'content', 'sha', 'branch', 'committer', 'author', '']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",2105,"['        """"""This method updates a file in a repository\n', '\n', '        :calls: `PUT /repos/{owner}/{repo}/contents/{path} <https://docs.github.com/en/rest/reference/repos#create-or-update-file-contents>`_\n', '        :param path: string, Required. The content path.\n', '        :param message: string, Required. The commit message.\n', '        :param content: string, Required. The updated file content, either base64 encoded, or ready to be encoded.\n', '        :param sha: string, Required. The blob SHA of the file being replaced.\n', '        :param branch: string. The branch name. Default: the repositorys default branch (usually master)\n', ""        :param committer: InputGitAuthor, (optional), if no information is given the authenticated user's information will be used. You must specify both a name and email.\n"", '        :param author: InputGitAuthor, (optional), if omitted this will be filled in with committer information. If passed, you must specify both a name and email.\n', '        :rtype: {\n', ""            'content': :class:`ContentFile <github.ContentFile.ContentFile>`:,\n"", ""            'commit': :class:`Commit <github.Commit.Commit>`}\n"", '        """"""\n']","['isinstance', 'content.encode', 'b64encode']",3
github/Repository.py:Repository:delete_file,Repository:delete_file,method,14,110,58,1042,9.47,0,3,"['self', 'path', 'message', 'sha', 'branch', 'committer', 'author', '']","[None, None, None, None, None, None, None, None]","[None, None, None, None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",2169,"['        """"""This method deletes a file in a repository\n', '\n', '        :calls: `DELETE /repos/{owner}/{repo}/contents/{path} <https://docs.github.com/en/rest/reference/repos/contents#delete-a-file>`_\n', '        :param path: string, Required. The content path.\n', '        :param message: string, Required. The commit message.\n', '        :param sha: string, Required. The blob SHA of the file being replaced.\n', '        :param branch: string. The branch name. Default: the repositorys default branch (usually master)\n', ""        :param committer: InputGitAuthor, (optional), if no information is given the authenticated user's information will be used. You must specify both a name and email.\n"", '        :param author: InputGitAuthor, (optional), if omitted this will be filled in with committer information. If passed, you must specify both a name and email.\n', '        :rtype: {\n', ""            'content': :class:`null <github.GithubObject.NotSet>`:,\n"", ""            'commit': :class:`Commit <github.Commit.Commit>`}\n"", '        """"""\n']",['isinstance'],1
github/RepositoryKey.py:RepositoryKey,RepositoryKey,class,36,144,66,1821,12.65,0,7,[],[],[],39,[],[],0
github/RepositoryKey.py:RepositoryKey:__repr__,RepositoryKey:__repr__,method,2,5,5,71,14.2,0,0,['self'],[None],[None],44,[],['self.get__repr__'],1
github/RepositoryKey.py:RepositoryKey:created_at,RepositoryKey:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],48,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RepositoryKey.py:RepositoryKey:id,RepositoryKey:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],56,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RepositoryKey.py:RepositoryKey:key,RepositoryKey:key,method,3,3,3,55,18.33,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RepositoryKey.py:RepositoryKey:title,RepositoryKey:title,method,3,3,3,59,19.67,0,0,['self'],[None],[None],72,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RepositoryKey.py:RepositoryKey:url,RepositoryKey:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],80,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RepositoryKey.py:RepositoryKey:verified,RepositoryKey:verified,method,3,3,3,65,21.67,0,0,['self'],[None],[None],88,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RepositoryKey.py:RepositoryKey:read_only,RepositoryKey:read_only,method,3,3,3,67,22.33,0,0,['self'],[None],[None],96,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RepositoryKey.py:RepositoryKey:delete,RepositoryKey:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],103,"['        """"""\n', '        :calls: `DELETE /repos/{owner}/{repo}/keys/{id} <http://docs.github.com/en/rest/reference/repos#deploy-keys>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/RepositoryKey.py:RepositoryKey:_initAttributes,RepositoryKey:_initAttributes,method,8,14,9,277,19.79,0,0,['self'],[None],[None],110,[],[],0
github/RepositoryKey.py:RepositoryKey:_useAttributes,RepositoryKey:_useAttributes,method,11,70,28,688,9.83,0,7,"['self', 'attributes']","[None, None]","[None, None]",119,[],"['self._makeDatetimeAttribute', 'self._makeIntAttribute', 'self._makeStringAttribute', 'self._makeBoolAttribute']",4
github/RepositoryPreferences.py:RepositoryPreferences,RepositoryPreferences,class,12,42,27,527,12.55,0,2,[],[],[],27,[],[],0
github/RepositoryPreferences.py:RepositoryPreferences:preferences,RepositoryPreferences:preferences,method,2,2,2,29,14.5,0,0,['self'],[None],[None],34,"['        """"""\n', '        :type: dict\n', '        """"""\n']",[],0
github/RepositoryPreferences.py:RepositoryPreferences:repository,RepositoryPreferences:repository,method,2,2,2,28,14.0,0,0,['self'],[None],[None],41,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",[],0
github/RepositoryPreferences.py:RepositoryPreferences:_initAttributes,RepositoryPreferences:_initAttributes,method,3,4,4,88,22.0,0,0,['self'],[None],[None],47,[],[],0
github/RepositoryPreferences.py:RepositoryPreferences:_useAttributes,RepositoryPreferences:_useAttributes,method,4,23,16,254,11.04,0,2,"['self', 'attributes']","[None, None]","[None, None]",51,[],"['self._makeDictAttribute', 'self._makeClassAttribute']",2
github/Requester.py:RequestsResponse,RequestsResponse,class,11,17,13,165,9.71,0,0,[],[],[],68,[],[],0
github/Requester.py:HTTPSRequestsConnectionClass,HTTPSRequestsConnectionClass,class,36,89,76,1020,11.46,0,3,[],[],[],82,[],[],0
github/Requester.py:HTTPRequestsConnectionClass,HTTPRequestsConnectionClass,class,36,89,76,1017,11.43,0,3,[],[],[],141,[],[],0
github/Requester.py:Requester,Requester,class,205,1080,530,10898,10.09,0,37,[],[],[],200,[],[],0
github/Requester.py:RequestsResponse:__init__,RequestsResponse:__init__,method,6,6,6,65,10.83,0,0,"['self', 'r']","[None, None]","[None, None]",70,[],[],0
github/Requester.py:RequestsResponse:getheaders,RequestsResponse:getheaders,method,2,2,2,26,13.0,0,0,['self'],[None],[None],75,[],[],0
github/Requester.py:RequestsResponse:read,RequestsResponse:read,method,2,2,2,15,7.5,0,0,['self'],[None],[None],78,[],[],0
github/Requester.py:HTTPSRequestsConnectionClass:__init__,HTTPSRequestsConnectionClass:__init__,method,20,43,35,514,11.95,0,3,"['self', 'host', 'port', 'strict', 'timeout', 'retry', 'pool_size', '**kwargs', '']","[None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'False', 'None', 'None', 'None', None, None]",84,[],"['kwargs.get', 'requests.Session']",2
github/Requester.py:HTTPSRequestsConnectionClass:request,HTTPSRequestsConnectionClass:request,method,8,8,8,65,8.12,0,0,"['self', 'verb', 'url', 'input', 'headers']","[None, None, None, None, None]","[None, None, None, None, None]",118,[],[],0
github/Requester.py:HTTPSRequestsConnectionClass:getresponse,HTTPSRequestsConnectionClass:getresponse,method,6,16,16,248,15.5,0,0,['self'],[None],[None],124,[],"['getattr', 'verb', 'RequestsResponse']",3
github/Requester.py:HTTPSRequestsConnectionClass:close,HTTPSRequestsConnectionClass:close,method,1,1,1,6,6.0,0,0,['self'],[None],[None],137,[],[],0
github/Requester.py:HTTPRequestsConnectionClass:__init__,HTTPRequestsConnectionClass:__init__,method,20,43,35,511,11.88,0,3,"['self', 'host', 'port', 'strict', 'timeout', 'retry', 'pool_size', '**kwargs', '']","[None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'False', 'None', 'None', 'None', None, None]",84,[],"['kwargs.get', 'requests.Session']",2
github/Requester.py:HTTPRequestsConnectionClass:request,HTTPRequestsConnectionClass:request,method,8,8,8,65,8.12,0,0,"['self', 'verb', 'url', 'input', 'headers']","[None, None, None, None, None]","[None, None, None, None, None]",118,[],[],0
github/Requester.py:HTTPRequestsConnectionClass:getresponse,HTTPRequestsConnectionClass:getresponse,method,6,16,16,248,15.5,0,0,['self'],[None],[None],124,[],"['getattr', 'verb', 'RequestsResponse']",3
github/Requester.py:HTTPRequestsConnectionClass:close,HTTPRequestsConnectionClass:close,method,1,1,1,6,6.0,0,0,['self'],[None],[None],137,[],[],0
github/Requester.py:Requester:injectConnectionClasses,Requester:injectConnectionClasses,method,5,6,6,113,18.83,0,0,"['cls', 'httpConnectionClass', 'httpsConnectionClass']","[None, None, None]","[None, None, None]",208,[],[],0
github/Requester.py:Requester:resetConnectionClasses,Requester:resetConnectionClasses,method,5,6,6,128,21.33,0,0,['cls'],[None],[None],214,[],[],0
github/Requester.py:Requester:injectLogger,Requester:injectLogger,method,2,2,2,19,9.5,0,0,"['cls', 'logger']","[None, None]","[None, None]",220,[],[],0
github/Requester.py:Requester:resetLogger,Requester:resetLogger,method,1,2,2,17,8.5,0,0,['cls'],[None],[None],224,[],[],0
github/Requester.py:Requester:setDebugFlag,Requester:setDebugFlag,method,2,2,2,19,9.5,0,0,"['cls', 'flag']","[None, None]","[None, None]",230,[],[],0
github/Requester.py:Requester:setOnCheckMe,Requester:setOnCheckMe,method,2,2,2,25,12.5,0,0,"['cls', 'onCheckMe']","[None, None]","[None, None]",234,[],[],0
github/Requester.py:Requester:NEW_DEBUG_FRAME,Requester:NEW_DEBUG_FRAME,method,11,44,30,329,7.48,0,2,"['self', 'requestHeader']","[None, None]","[None, None]",245,"['        """"""\n', '        Initialize a debug frame with requestHeader\n', '        Frame count is updated and will be attached to respond header\n', '        The structure of a frame: [requestHeader, statusCode, responseHeader, raw_data]\n', '        Some of them may be None\n', '        """"""\n']",['len'],1
github/Requester.py:Requester:DEBUG_ON_RESPONSE,Requester:DEBUG_ON_RESPONSE,method,10,19,19,189,9.95,0,1,"['self', 'statusCode', 'responseHeader', 'data']","[None, None, None, None]","[None, None, None, None]",263,"['        """"""\n', '        Update current frame with response\n', '        Current frame index will be attached to responseHeader\n', '        """"""\n']",[],0
github/Requester.py:Requester:check_me,Requester:check_me,method,7,30,26,250,8.33,0,2,"['self', 'obj']","[None, None]","[None, None]",276,[],['self.ON_CHECK_ME'],1
github/Requester.py:Requester:_initializeDebugFeature,Requester:_initializeDebugFeature,method,2,4,4,39,9.75,0,0,['self'],[None],[None],286,[],[],0
github/Requester.py:Requester:__init__,Requester:__init__,method,50,115,92,1164,10.12,0,2,"['self', 'login_or_token', 'password', 'jwt', 'base_url', 'timeout', 'user_agent', 'per_page', 'verify', 'retry', 'pool_size', '']","[None, None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, None, None, None]",84,[],"['self._initializeDebugFeature', 'base64.b64encode']",2
github/Requester.py:Requester:requestJsonAndCheck,Requester:requestJsonAndCheck,method,2,11,11,105,9.55,0,0,"['self', 'verb', 'url', 'parameters', 'headers', 'input']","[None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None']",352,[],"['self.__check', 'self.__customConnection']",2
github/Requester.py:Requester:requestMultipartAndCheck,Requester:requestMultipartAndCheck,method,2,11,11,110,10.0,0,0,"['self', 'verb', 'url', 'parameters', 'headers', 'input']","[None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None']",359,[],"['self.__check', 'self.__customConnection']",2
github/Requester.py:Requester:requestBlobAndCheck,Requester:requestBlobAndCheck,method,2,11,11,105,9.55,0,0,"['self', 'verb', 'url', 'parameters', 'headers', 'input']","[None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None']",368,[],"['self.__check', 'self.__customConnection']",2
github/Requester.py:Requester:__check,Requester:__check,method,6,12,10,143,11.92,0,1,"['self', 'status', 'responseHeaders', 'output']","[None, None, None, None]","[None, None, None, None]",375,[],"['self.__structuredFromJson', 'self.__createException']",2
github/Requester.py:Requester:__customConnection,Requester:__customConnection,method,10,53,35,477,9.0,0,3,"['self', 'url']","[None, None]","[None, None]",381,[],"['url.startswith', 'self.__httpConnectionClass', 'self.__httpsConnectionClass']",3
github/Requester.py:Requester:__createException,Requester:__createException,method,12,77,54,767,9.96,0,1,"['self', 'status', 'headers', 'output']","[None, None, None, None]","[None, None, None, None]",409,[],"['output.get', 're.match', 'cls']",3
github/Requester.py:Requester:__structuredFromJson,Requester:__structuredFromJson,method,7,24,20,202,8.42,0,3,"['self', 'data']","[None, None]","[None, None]",435,[],"['len', 'isinstance', 'data.decode', 'json.loads', 'data.startswith']",5
github/Requester.py:Requester:requestJson,Requester:requestJson,method,2,11,11,105,9.55,0,0,"['self', 'verb', 'url', 'parameters', 'headers', 'input']","[None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None']",448,[],"['self.__check', 'self.__customConnection']",2
github/Requester.py:Requester:requestMultipart,Requester:requestMultipart,method,2,11,11,110,10.0,0,0,"['self', 'verb', 'url', 'parameters', 'headers', 'input']","[None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None']",456,[],"['self.__check', 'self.__customConnection']",2
github/Requester.py:Requester:requestBlob,Requester:requestBlob,method,2,11,11,105,9.55,0,0,"['self', 'verb', 'url', 'parameters', 'headers', 'input']","[None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None']",474,[],"['self.__check', 'self.__customConnection']",2
github/Requester.py:Requester:requestMemoryBlobAndCheck,Requester:requestMemoryBlobAndCheck,method,6,22,21,192,8.73,0,1,"['self', 'verb', 'url', 'parameters', 'headers', 'file_like', 'cnx']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, 'None']",492,[],"['encode', 'self.__customConnection', 'self.__check']",3
github/Requester.py:Requester:__requestEncode,Requester:__requestEncode,method,26,87,59,1077,12.38,0,6,"['self', 'cnx', 'verb', 'url', 'parameters', 'requestHeaders', 'input', 'encode']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",507,[],"['dict', 'self.__authenticate', 'self.__makeAbsoluteUrl', 'self.__addParametersToUrl', 'encode', 'self.NEW_DEBUG_FRAME', 'self.__requestRaw', 'int', 'self.DEBUG_ON_RESPONSE']",9
github/Requester.py:Requester:__requestRaw,Requester:__requestRaw,method,24,88,62,781,8.88,0,5,"['self', 'cnx', 'verb', 'url', 'requestHeaders', 'input']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",550,[],"['self.__createConnection', 'cnx.request', 'cnx.getresponse', 'response.getheaders', 'response.read', 'cnx.close', 'isinstance', 'input.close', 'self.__log', 'time.sleep', 'self.__requestRaw']",11
github/Requester.py:Requester:__authenticate,Requester:__authenticate,method,2,7,6,97,13.86,0,1,"['self', 'url', 'requestHeaders', 'parameters']","[None, None, None, None]","[None, None, None, None]",580,[],[],0
github/Requester.py:Requester:__makeAbsoluteUrl,Requester:__makeAbsoluteUrl,method,11,33,27,322,9.76,0,2,"['self', 'url']","[None, None]","[None, None]",584,[],['url.startswith'],1
github/Requester.py:Requester:__addParametersToUrl,Requester:__addParametersToUrl,method,3,8,7,89,11.12,0,1,"['self', 'url', 'parameters']","[None, None, None]","[None, None, None]",604,[],['len'],1
github/Requester.py:Requester:__createConnection,Requester:__createConnection,method,7,25,22,292,11.68,0,1,['self'],[None],[None],610,[],['self.__connectionClass'],1
github/Requester.py:Requester:__log,Requester:__log,method,12,97,66,917,9.45,0,4,"['self', 'verb', 'url', 'requestHeaders', 'input', 'status', 'responseHeaders', 'output']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",628,[],"['logging.getLogger', 'requestHeaders.copy']",2
github/RequiredPullRequestReviews.py:RequiredPullRequestReviews,RequiredPullRequestReviews,class,29,140,69,2210,15.79,0,7,[],[],[],28,[],[],0
github/RequiredPullRequestReviews.py:RequiredPullRequestReviews:__repr__,RequiredPullRequestReviews:__repr__,method,2,11,11,180,16.36,0,0,['self'],[None],[None],33,[],['self.get__repr__'],1
github/RequiredPullRequestReviews.py:RequiredPullRequestReviews:dismiss_stale_reviews,RequiredPullRequestReviews:dismiss_stale_reviews,method,3,3,3,91,30.33,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RequiredPullRequestReviews.py:RequiredPullRequestReviews:require_code_owner_reviews,RequiredPullRequestReviews:require_code_owner_reviews,method,3,3,3,101,33.67,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RequiredPullRequestReviews.py:RequiredPullRequestReviews:required_approving_review_count,RequiredPullRequestReviews:required_approving_review_count,method,3,3,3,111,37.0,0,0,['self'],[None],[None],59,"['        """"""\n', '        :type: int\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RequiredPullRequestReviews.py:RequiredPullRequestReviews:url,RequiredPullRequestReviews:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],67,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RequiredPullRequestReviews.py:RequiredPullRequestReviews:dismissal_users,RequiredPullRequestReviews:dismissal_users,method,3,3,3,59,19.67,0,0,['self'],[None],[None],75,"['        """"""\n', '        :type: list of :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RequiredPullRequestReviews.py:RequiredPullRequestReviews:dismissal_teams,RequiredPullRequestReviews:dismissal_teams,method,3,3,3,59,19.67,0,0,['self'],[None],[None],83,"['        """"""\n', '        :type: list of :class:`github.Team.Team`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RequiredPullRequestReviews.py:RequiredPullRequestReviews:_initAttributes,RequiredPullRequestReviews:_initAttributes,method,6,10,7,257,25.7,0,0,['self'],[None],[None],90,[],[],0
github/RequiredPullRequestReviews.py:RequiredPullRequestReviews:_useAttributes,RequiredPullRequestReviews:_useAttributes,method,10,76,34,971,12.78,0,7,"['self', 'attributes']","[None, None]","[None, None]",97,[],"['self._makeListOfClassesAttribute', 'self._makeBoolAttribute', 'self._makeIntAttribute', 'self._makeStringAttribute']",4
github/RequiredStatusChecks.py:RequiredStatusChecks,RequiredStatusChecks,class,19,66,37,841,12.74,0,3,[],[],[],26,[],[],0
github/RequiredStatusChecks.py:RequiredStatusChecks:__repr__,RequiredStatusChecks:__repr__,method,2,5,5,75,15.0,0,0,['self'],[None],[None],31,[],['self.get__repr__'],1
github/RequiredStatusChecks.py:RequiredStatusChecks:strict,RequiredStatusChecks:strict,method,3,3,3,61,20.33,0,0,['self'],[None],[None],35,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RequiredStatusChecks.py:RequiredStatusChecks:contexts,RequiredStatusChecks:contexts,method,3,3,3,65,21.67,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: list of string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RequiredStatusChecks.py:RequiredStatusChecks:url,RequiredStatusChecks:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/RequiredStatusChecks.py:RequiredStatusChecks:_initAttributes,RequiredStatusChecks:_initAttributes,method,4,6,5,118,19.67,0,0,['self'],[None],[None],58,[],[],0
github/RequiredStatusChecks.py:RequiredStatusChecks:_useAttributes,RequiredStatusChecks:_useAttributes,method,6,30,16,301,10.03,0,3,"['self', 'attributes']","[None, None]","[None, None]",63,[],"['self._makeBoolAttribute', 'self._makeListOfStringsAttribute', 'self._makeStringAttribute']",3
github/SelfHostedActionsRunner.py:SelfHostedActionsRunner,SelfHostedActionsRunner,class,28,103,49,1146,11.13,0,6,[],[],[],26,[],[],0
github/SelfHostedActionsRunner.py:SelfHostedActionsRunner:__repr__,SelfHostedActionsRunner:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],32,[],['self.get__repr__'],1
github/SelfHostedActionsRunner.py:SelfHostedActionsRunner:id,SelfHostedActionsRunner:id,method,2,2,2,20,10.0,0,0,['self'],[None],[None],36,"['        """"""\n', '        :type: int\n', '        """"""\n']",[],0
github/SelfHostedActionsRunner.py:SelfHostedActionsRunner:name,SelfHostedActionsRunner:name,method,2,2,2,22,11.0,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/SelfHostedActionsRunner.py:SelfHostedActionsRunner:os,SelfHostedActionsRunner:os,method,2,2,2,20,10.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/SelfHostedActionsRunner.py:SelfHostedActionsRunner:status,SelfHostedActionsRunner:status,method,2,2,2,24,12.0,0,0,['self'],[None],[None],57,"['        """"""\n', '        :type: str\n', '        """"""\n']",[],0
github/SelfHostedActionsRunner.py:SelfHostedActionsRunner:busy,SelfHostedActionsRunner:busy,method,2,2,2,22,11.0,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/SelfHostedActionsRunner.py:SelfHostedActionsRunner:labels,SelfHostedActionsRunner:labels,method,2,2,2,24,12.0,0,0,['self'],[None],[None],70,"['        """"""\n', '        :type: list of dicts\n', '        """"""\n']",[],0
github/SelfHostedActionsRunner.py:SelfHostedActionsRunner:_initAttributes,SelfHostedActionsRunner:_initAttributes,method,7,12,8,203,16.92,0,0,['self'],[None],[None],76,[],[],0
github/SelfHostedActionsRunner.py:SelfHostedActionsRunner:_useAttributes,SelfHostedActionsRunner:_useAttributes,method,10,52,26,533,10.25,0,6,"['self', 'attributes']","[None, None]","[None, None]",84,[],"['self._makeIntAttribute', 'self._makeStringAttribute', 'self._makeBoolAttribute', 'self._makeListOfDictsAttribute']",4
github/SourceImport.py:SourceImport,SourceImport,class,53,269,114,3710,13.79,0,13,[],[],[],27,[],[],0
github/SourceImport.py:SourceImport:__repr__,SourceImport:__repr__,method,2,13,13,157,12.08,0,0,['self'],[None],[None],32,[],['self.get__repr__'],1
github/SourceImport.py:SourceImport:authors_count,SourceImport:authors_count,method,3,3,3,75,25.0,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:authors_url,SourceImport:authors_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:has_large_files,SourceImport:has_large_files,method,3,3,3,79,26.33,0,0,['self'],[None],[None],59,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:html_url,SourceImport:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],67,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:large_files_count,SourceImport:large_files_count,method,3,3,3,83,27.67,0,0,['self'],[None],[None],75,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:large_files_size,SourceImport:large_files_size,method,3,3,3,81,27.0,0,0,['self'],[None],[None],83,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:repository_url,SourceImport:repository_url,method,3,3,3,77,25.67,0,0,['self'],[None],[None],91,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:status,SourceImport:status,method,3,3,3,61,20.33,0,0,['self'],[None],[None],99,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:status_text,SourceImport:status_text,method,3,3,3,71,23.67,0,0,['self'],[None],[None],107,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:url,SourceImport:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],115,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:use_lfs,SourceImport:use_lfs,method,3,3,3,63,21.0,0,0,['self'],[None],[None],123,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:vcs,SourceImport:vcs,method,3,3,3,55,18.33,0,0,['self'],[None],[None],131,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:vcs_url,SourceImport:vcs_url,method,3,3,3,63,21.0,0,0,['self'],[None],[None],139,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/SourceImport.py:SourceImport:update,SourceImport:update,method,3,5,5,109,21.8,0,0,['self'],[None],[None],146,[],['super'],1
github/SourceImport.py:SourceImport:_initAttributes,SourceImport:_initAttributes,method,14,26,15,572,22.0,0,0,['self'],[None],[None],150,[],[],0
github/SourceImport.py:SourceImport:_useAttributes,SourceImport:_useAttributes,method,16,138,50,1455,10.54,0,13,"['self', 'attributes']","[None, None]","[None, None]",165,[],"['self._makeIntAttribute', 'self._makeStringAttribute', 'self._makeBoolAttribute']",3
github/Stargazer.py:Stargazer,Stargazer,class,15,41,27,576,14.05,0,2,[],[],[],30,[],[],0
github/Stargazer.py:Stargazer:__repr__,Stargazer:__repr__,method,2,3,3,62,20.67,0,0,['self'],[None],[None],35,[],['self.get__repr__'],1
github/Stargazer.py:Stargazer:starred_at,Stargazer:starred_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],39,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/Stargazer.py:Stargazer:user,Stargazer:user,method,2,2,2,22,11.0,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: :class:`github.NamedUser`\n', '        """"""\n']",[],0
github/Stargazer.py:Stargazer:_initAttributes,Stargazer:_initAttributes,method,4,6,5,118,19.67,0,0,['self'],[None],[None],52,[],[],0
github/Stargazer.py:Stargazer:_useAttributes,Stargazer:_useAttributes,method,4,15,12,205,13.67,0,2,"['self', 'attributes']","[None, None]","[None, None]",57,[],"['self._makeDatetimeAttribute', 'self._makeClassAttribute']",2
github/StatsCodeFrequency.py:StatsCodeFrequency,StatsCodeFrequency,class,15,32,19,512,16.0,0,0,[],[],[],30,[],[],0
github/StatsCodeFrequency.py:StatsCodeFrequency:week,StatsCodeFrequency:week,method,2,2,2,22,11.0,0,0,['self'],[None],[None],36,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/StatsCodeFrequency.py:StatsCodeFrequency:additions,StatsCodeFrequency:additions,method,2,2,2,27,13.5,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: int\n', '        """"""\n']",[],0
github/StatsCodeFrequency.py:StatsCodeFrequency:deletions,StatsCodeFrequency:deletions,method,2,2,2,27,13.5,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: int\n', '        """"""\n']",[],0
github/StatsCodeFrequency.py:StatsCodeFrequency:_initAttributes,StatsCodeFrequency:_initAttributes,method,4,6,5,123,20.5,0,0,['self'],[None],[None],56,[],[],0
github/StatsCodeFrequency.py:StatsCodeFrequency:_useAttributes,StatsCodeFrequency:_useAttributes,method,5,6,6,162,27.0,0,0,"['self', 'attributes']","[None, None]","[None, None]",61,[],"['self._makeTimestampAttribute', 'self._makeIntAttribute']",2
github/StatsCommitActivity.py:StatsCommitActivity,StatsCommitActivity,class,16,56,29,611,10.91,0,3,[],[],[],30,[],[],0
github/StatsCommitActivity.py:StatsCommitActivity:week,StatsCommitActivity:week,method,2,2,2,22,11.0,0,0,['self'],[None],[None],36,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/StatsCommitActivity.py:StatsCommitActivity:total,StatsCommitActivity:total,method,2,2,2,23,11.5,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: int\n', '        """"""\n']",[],0
github/StatsCommitActivity.py:StatsCommitActivity:days,StatsCommitActivity:days,method,2,2,2,22,11.0,0,0,['self'],[None],[None],50,"['        """"""\n', '        :type: list of int\n', '        """"""\n']",[],0
github/StatsCommitActivity.py:StatsCommitActivity:_initAttributes,StatsCommitActivity:_initAttributes,method,4,6,5,114,19.0,0,0,['self'],[None],[None],56,[],[],0
github/StatsCommitActivity.py:StatsCommitActivity:_useAttributes,StatsCommitActivity:_useAttributes,method,6,30,16,288,9.6,0,3,"['self', 'attributes']","[None, None]","[None, None]",61,[],"['self._makeTimestampAttribute', 'self._makeIntAttribute', 'self._makeListOfIntsAttribute']",3
github/StatsContributor.py:StatsContributor,StatsContributor,class,30,137,57,1432,10.45,0,7,[],[],[],31,[],[],0
github/StatsContributor.py:StatsContributor:author,StatsContributor:author,method,2,2,2,24,12.0,0,0,['self'],[None],[None],86,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/StatsContributor.py:StatsContributor:total,StatsContributor:total,method,2,2,2,23,11.5,0,0,['self'],[None],[None],93,"['        """"""\n', '        :type: int\n', '        """"""\n']",[],0
github/StatsContributor.py:StatsContributor:weeks,StatsContributor:weeks,method,2,2,2,23,11.5,0,0,['self'],[None],[None],100,"['        """"""\n', '        :type: list of :class:`.Week`\n', '        """"""\n']",[],0
github/StatsContributor.py:StatsContributor:_initAttributes,StatsContributor:_initAttributes,method,4,6,5,117,19.5,0,0,['self'],[None],[None],106,[],[],0
github/StatsContributor.py:StatsContributor:_useAttributes,StatsContributor:_useAttributes,method,6,36,22,337,9.36,0,3,"['self', 'attributes']","[None, None]","[None, None]",111,[],"['self._makeClassAttribute', 'self._makeIntAttribute', 'self._makeListOfClassesAttribute']",3
github/StatsParticipation.py:StatsParticipation,StatsParticipation,class,11,39,24,429,11.0,0,2,[],[],[],30,[],[],0
github/StatsParticipation.py:StatsParticipation:all,StatsParticipation:all,method,2,2,2,21,10.5,0,0,['self'],[None],[None],36,"['        """"""\n', '        :type: list of int\n', '        """"""\n']",[],0
github/StatsParticipation.py:StatsParticipation:owner,StatsParticipation:owner,method,2,2,2,23,11.5,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: list of int\n', '        """"""\n']",[],0
github/StatsParticipation.py:StatsParticipation:_initAttributes,StatsParticipation:_initAttributes,method,3,4,4,75,18.75,0,0,['self'],[None],[None],49,[],[],0
github/StatsParticipation.py:StatsParticipation:_useAttributes,StatsParticipation:_useAttributes,method,3,20,13,195,9.75,0,2,"['self', 'attributes']","[None, None]","[None, None]",53,[],['self._makeListOfIntsAttribute'],1
github/StatsPunchCard.py:StatsPunchCard,StatsPunchCard,class,10,23,18,191,8.3,1,0,[],[],[],31,[],[],0
github/StatsPunchCard.py:StatsPunchCard:get,StatsPunchCard:get,method,2,3,3,28,9.33,0,0,"['self', 'day', 'hour']","[None, None, None]","[None, None, None]",36,"['        """"""\n', '        Get a specific element\n', '\n', '        :param day: int\n', '        :param hour: int\n', '        :rtype: int\n', '        """"""\n']",[],0
github/StatsPunchCard.py:StatsPunchCard:_initAttributes,StatsPunchCard:_initAttributes,method,1,2,2,13,6.5,0,0,['self'],[None],[None],46,[],[],0
github/StatsPunchCard.py:StatsPunchCard:_useAttributes,StatsPunchCard:_useAttributes,method,5,9,8,63,7.0,1,0,"['self', 'attributes']","[None, None]","[None, None]",49,[],[],0
github/Tag.py:Tag,Tag,class,20,85,43,998,11.74,0,4,[],[],[],36,[],[],0
github/Tag.py:Tag:__repr__,Tag:__repr__,method,2,7,7,79,11.29,0,0,['self'],[None],[None],41,[],['self.get__repr__'],1
github/Tag.py:Tag:commit,Tag:commit,method,2,2,2,24,12.0,0,0,['self'],[None],[None],47,"['        """"""\n', '        :type: :class:`github.Commit.Commit`\n', '        """"""\n']",[],0
github/Tag.py:Tag:name,Tag:name,method,2,2,2,22,11.0,0,0,['self'],[None],[None],54,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Tag.py:Tag:tarball_url,Tag:tarball_url,method,2,2,2,29,14.5,0,0,['self'],[None],[None],61,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Tag.py:Tag:zipball_url,Tag:zipball_url,method,2,2,2,29,14.5,0,0,['self'],[None],[None],68,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Tag.py:Tag:_initAttributes,Tag:_initAttributes,method,5,8,6,167,20.88,0,0,['self'],[None],[None],74,[],[],0
github/Tag.py:Tag:_useAttributes,Tag:_useAttributes,method,6,43,22,445,10.35,0,4,"['self', 'attributes']","[None, None]","[None, None]",80,[],"['self._makeClassAttribute', 'self._makeStringAttribute']",2
github/Team.py:Team,Team,class,67,375,180,5681,15.15,0,3,[],[],[],55,[],[],0
github/Team.py:Team:__repr__,Team:__repr__,method,2,5,5,69,13.8,0,0,['self'],[None],[None],60,[],['self.get__repr__'],1
github/Team.py:Team:id,Team:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],64,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:members_count,Team:members_count,method,3,3,3,75,25.0,0,0,['self'],[None],[None],72,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:members_url,Team:members_url,method,3,3,3,71,23.67,0,0,['self'],[None],[None],80,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:name,Team:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],88,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:description,Team:description,method,3,3,3,71,23.67,0,0,['self'],[None],[None],96,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:permission,Team:permission,method,3,3,3,69,23.0,0,0,['self'],[None],[None],104,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:repos_count,Team:repos_count,method,3,3,3,71,23.67,0,0,['self'],[None],[None],112,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:repositories_url,Team:repositories_url,method,3,3,3,81,27.0,0,0,['self'],[None],[None],120,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:slug,Team:slug,method,3,3,3,57,19.0,0,0,['self'],[None],[None],128,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:url,Team:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],136,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:organization,Team:organization,method,3,3,3,73,24.33,0,0,['self'],[None],[None],144,"['        """"""\n', '        :type: :class:`github.Organization.Organization`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:privacy,Team:privacy,method,3,3,3,63,21.0,0,0,['self'],[None],[None],152,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:parent,Team:parent,method,3,3,3,61,20.33,0,0,['self'],[None],[None],160,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Team.py:Team:add_to_members,Team:add_to_members,method,0,2,2,46,23.0,0,0,"['self', 'member']","[None, None]","[None, None]",167,"['        """"""\n', '        This API call is deprecated. Use `add_membership` instead.\n', '        https://docs.github.com/en/rest/reference/teams#add-or-update-team-membership-for-a-user-legacy\n', '\n', '        :calls: `PUT /teams/{id}/members/{user} <http://docs.github.com/en/rest/reference/teams>`_\n', '        :param member: :class:`github.NamedUser.NamedUser`\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Team.py:Team:add_membership,Team:add_membership,method,2,10,10,67,6.7,0,0,"['self', 'member', 'role']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",181,"['        """"""\n', '        :calls: `PUT /teams/{id}/memberships/{user} <http://docs.github.com/en/rest/reference/teams>`_\n', '        :param member: :class:`github.Nameduser.NamedUser`\n', '        :param role: string\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Team.py:Team:get_team_membership,Team:get_team_membership,method,7,22,21,278,12.64,0,1,"['self', 'member']","[None, None]","[None, None]",203,"['        """"""\n', '        :calls: `GET /orgs/{org}/memberships/team/{team_id}/{username} <https://docs.github.com/en/rest/reference/teams#get-team-membership-for-a-user>`_\n', '        :param member: string or :class:`github.NamedUser.NamedUser`\n', '        :rtype: :class:`github.Membership.Membership`\n', '        """"""\n']",['isinstance'],1
github/Team.py:Team:add_to_repos,Team:add_to_repos,method,0,2,2,42,21.0,0,0,"['self', 'repo']","[None, None]","[None, None]",221,"['        """"""\n', '        :calls: `PUT /teams/{id}/repos/{org}/{repo} <http://docs.github.com/en/rest/reference/teams>`_\n', '        :param repo: :class:`github.Repository.Repository`\n', '        :rtype: None\n', '        """"""\n']",[],0
github/Team.py:Team:get_repo_permission,Team:get_repo_permission,method,2,2,2,19,9.5,0,0,"['self', 'repo']","[None, None]","[None, None]",232,"['        """"""\n', '        :calls: `GET /teams/{id}/repos/{org}/{repo} <http://docs.github.com/en/rest/reference/teams>`_\n', '        :param repo: string or :class:`github.Repository.Repository`\n', '        :rtype: None or :class:`github.Permissions.Permissions`\n', '        """"""\n']",[],0
github/TeamDiscussion.py:TeamDiscussion,TeamDiscussion,class,63,321,127,4339,13.52,0,17,[],[],[],28,[],[],0
github/TeamDiscussion.py:TeamDiscussion:__repr__,TeamDiscussion:__repr__,method,2,7,7,81,11.57,0,0,['self'],[None],[None],33,[],['self.get__repr__'],1
github/TeamDiscussion.py:TeamDiscussion:author,TeamDiscussion:author,method,3,3,3,61,20.33,0,0,['self'],[None],[None],39,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:body,TeamDiscussion:body,method,3,3,3,57,19.0,0,0,['self'],[None],[None],47,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:body_html,TeamDiscussion:body_html,method,3,3,3,67,22.33,0,0,['self'],[None],[None],55,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:body_version,TeamDiscussion:body_version,method,3,3,3,73,24.33,0,0,['self'],[None],[None],63,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:comments_count,TeamDiscussion:comments_count,method,3,3,3,77,25.67,0,0,['self'],[None],[None],71,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:comments_url,TeamDiscussion:comments_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],79,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:created_at,TeamDiscussion:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],87,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:html_url,TeamDiscussion:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],95,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:last_edited_at,TeamDiscussion:last_edited_at,method,3,3,3,77,25.67,0,0,['self'],[None],[None],103,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:node_id,TeamDiscussion:node_id,method,3,3,3,63,21.0,0,0,['self'],[None],[None],111,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:number,TeamDiscussion:number,method,3,3,3,61,20.33,0,0,['self'],[None],[None],119,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:pinned,TeamDiscussion:pinned,method,3,3,3,61,20.33,0,0,['self'],[None],[None],127,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:private,TeamDiscussion:private,method,3,3,3,63,21.0,0,0,['self'],[None],[None],135,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:team_url,TeamDiscussion:team_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],143,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:title,TeamDiscussion:title,method,3,3,3,59,19.67,0,0,['self'],[None],[None],151,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:updated_at,TeamDiscussion:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],159,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:url,TeamDiscussion:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],167,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/TeamDiscussion.py:TeamDiscussion:_initAttributes,TeamDiscussion:_initAttributes,method,18,34,19,718,21.12,0,0,['self'],[None],[None],174,[],[],0
github/TeamDiscussion.py:TeamDiscussion:_useAttributes,TeamDiscussion:_useAttributes,method,22,171,63,1827,10.68,0,17,"['self', 'attributes']","[None, None]","[None, None]",193,[],"['self._makeClassAttribute', 'self._makeStringAttribute', 'self._makeIntAttribute', 'self._makeDatetimeAttribute', 'self._makeBoolAttribute']",5
github/TimelineEvent.py:TimelineEvent,TimelineEvent,class,44,239,88,2672,11.18,0,14,[],[],[],28,[],[],0
github/TimelineEvent.py:TimelineEvent:__repr__,TimelineEvent:__repr__,method,2,3,3,45,15.0,0,0,['self'],[None],[None],33,[],['self.get__repr__'],1
github/TimelineEvent.py:TimelineEvent:actor,TimelineEvent:actor,method,2,2,2,23,11.5,0,0,['self'],[None],[None],37,"['        """"""\n', '        :type: :class:`github.NamedUser.NamedUser`\n', '        """"""\n']",[],0
github/TimelineEvent.py:TimelineEvent:commit_id,TimelineEvent:commit_id,method,2,2,2,27,13.5,0,0,['self'],[None],[None],44,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/TimelineEvent.py:TimelineEvent:created_at,TimelineEvent:created_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],51,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/TimelineEvent.py:TimelineEvent:event,TimelineEvent:event,method,2,2,2,23,11.5,0,0,['self'],[None],[None],58,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/TimelineEvent.py:TimelineEvent:id,TimelineEvent:id,method,2,2,2,20,10.0,0,0,['self'],[None],[None],65,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/TimelineEvent.py:TimelineEvent:node_id,TimelineEvent:node_id,method,2,2,2,25,12.5,0,0,['self'],[None],[None],72,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/TimelineEvent.py:TimelineEvent:commit_url,TimelineEvent:commit_url,method,2,2,2,28,14.0,0,0,['self'],[None],[None],79,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/TimelineEvent.py:TimelineEvent:source,TimelineEvent:source,method,2,14,13,120,8.57,0,1,['self'],[None],[None],86,"['        """"""\n', '        :type: :class:`github.TimelineEventSource.TimelineEventSource`\n', '        """"""\n']",[],0
github/TimelineEvent.py:TimelineEvent:body,TimelineEvent:body,method,3,12,11,104,8.67,0,1,['self'],[None],[None],99,"['        """"""\n', '        :type string\n', '        """"""\n']",[],0
github/TimelineEvent.py:TimelineEvent:author_association,TimelineEvent:author_association,method,2,14,13,137,9.79,0,1,['self'],[None],[None],108,"['        """"""\n', '        :type string\n', '        """"""\n']",[],0
github/TimelineEvent.py:TimelineEvent:url,TimelineEvent:url,method,2,2,2,21,10.5,0,0,['self'],[None],[None],120,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/TimelineEvent.py:TimelineEvent:_initAttributes,TimelineEvent:_initAttributes,method,12,22,13,452,20.55,0,0,['self'],[None],[None],126,[],[],0
github/TimelineEvent.py:TimelineEvent:_useAttributes,TimelineEvent:_useAttributes,method,15,118,45,1215,10.3,0,11,"['self', 'attributes']","[None, None]","[None, None]",139,[],"['self._makeClassAttribute', 'self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeIntAttribute']",4
github/TimelineEventSource.py:TimelineEventSource,TimelineEventSource,class,14,47,30,516,10.98,0,2,[],[],[],27,[],[],0
github/TimelineEventSource.py:TimelineEventSource:__repr__,TimelineEventSource:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],32,[],['self.get__repr__'],1
github/TimelineEventSource.py:TimelineEventSource:type,TimelineEventSource:type,method,2,2,2,22,11.0,0,0,['self'],[None],[None],36,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/TimelineEventSource.py:TimelineEventSource:issue,TimelineEventSource:issue,method,2,2,2,23,11.5,0,0,['self'],[None],[None],43,"['        """"""\n', '        :type: :class:`github.Issue.Issue`\n', '        """"""\n']",[],0
github/TimelineEventSource.py:TimelineEventSource:_initAttributes,TimelineEventSource:_initAttributes,method,3,4,4,76,19.0,0,0,['self'],[None],[None],49,[],[],0
github/TimelineEventSource.py:TimelineEventSource:_useAttributes,TimelineEventSource:_useAttributes,method,4,23,16,210,9.13,0,2,"['self', 'attributes']","[None, None]","[None, None]",53,[],"['self._makeStringAttribute', 'self._makeClassAttribute']",2
github/Topic.py:Topic,Topic,class,43,199,74,2459,12.36,0,11,[],[],[],26,[],[],0
github/Topic.py:Topic:__repr__,Topic:__repr__,method,2,3,3,49,16.33,0,0,['self'],[None],[None],31,[],['self.get__repr__'],1
github/Topic.py:Topic:name,Topic:name,method,2,2,2,22,11.0,0,0,['self'],[None],[None],35,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Topic.py:Topic:display_name,Topic:display_name,method,2,2,2,30,15.0,0,0,['self'],[None],[None],42,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Topic.py:Topic:short_description,Topic:short_description,method,2,2,2,35,17.5,0,0,['self'],[None],[None],49,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Topic.py:Topic:description,Topic:description,method,2,2,2,29,14.5,0,0,['self'],[None],[None],56,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Topic.py:Topic:created_by,Topic:created_by,method,2,2,2,28,14.0,0,0,['self'],[None],[None],63,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Topic.py:Topic:released,Topic:released,method,2,2,2,26,13.0,0,0,['self'],[None],[None],70,"['        """"""\n', '        :type: string\n', '        """"""\n']",[],0
github/Topic.py:Topic:created_at,Topic:created_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],77,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/Topic.py:Topic:updated_at,Topic:updated_at,method,2,2,2,28,14.0,0,0,['self'],[None],[None],84,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/Topic.py:Topic:featured,Topic:featured,method,2,2,2,26,13.0,0,0,['self'],[None],[None],91,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/Topic.py:Topic:curated,Topic:curated,method,2,2,2,25,12.5,0,0,['self'],[None],[None],98,"['        """"""\n', '        :type: bool\n', '        """"""\n']",[],0
github/Topic.py:Topic:score,Topic:score,method,2,2,2,23,11.5,0,0,['self'],[None],[None],105,"['        """"""\n', '        :type: float\n', '        """"""\n']",[],0
github/Topic.py:Topic:_initAttributes,Topic:_initAttributes,method,12,22,13,475,21.59,0,0,['self'],[None],[None],111,[],[],0
github/Topic.py:Topic:_useAttributes,Topic:_useAttributes,method,15,112,42,1208,10.79,0,11,"['self', 'attributes']","[None, None]","[None, None]",124,[],"['self._makeStringAttribute', 'self._makeDatetimeAttribute', 'self._makeBoolAttribute', 'self._makeFloatAttribute']",4
github/UserKey.py:UserKey,UserKey,class,29,108,54,1314,12.17,0,5,[],[],[],35,[],[],0
github/UserKey.py:UserKey:__repr__,UserKey:__repr__,method,2,5,5,71,14.2,0,0,['self'],[None],[None],40,[],['self.get__repr__'],1
github/UserKey.py:UserKey:id,UserKey:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],44,"['        """"""\n', '        :type: integer\n', '        """"""\n']",['self._completeIfNotSet'],1
github/UserKey.py:UserKey:key,UserKey:key,method,3,3,3,55,18.33,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/UserKey.py:UserKey:title,UserKey:title,method,3,3,3,59,19.67,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/UserKey.py:UserKey:url,UserKey:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],68,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/UserKey.py:UserKey:verified,UserKey:verified,method,3,3,3,65,21.67,0,0,['self'],[None],[None],76,"['        """"""\n', '        :type: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/UserKey.py:UserKey:delete,UserKey:delete,method,3,4,4,67,16.75,0,0,['self'],[None],[None],83,"['        """"""\n', '        :calls: `DELETE /user/keys/{id} <http://docs.github.com/en/rest/reference/users#keys>`_\n', '        :rtype: None\n', '        """"""\n']",[],0
github/UserKey.py:UserKey:_initAttributes,UserKey:_initAttributes,method,6,10,7,190,19.0,0,0,['self'],[None],[None],90,[],[],0
github/UserKey.py:UserKey:_useAttributes,UserKey:_useAttributes,method,8,50,22,467,9.34,0,5,"['self', 'attributes']","[None, None]","[None, None]",97,[],"['self._makeIntAttribute', 'self._makeStringAttribute', 'self._makeBoolAttribute']",3
github/View.py:View,View,class,17,69,40,793,11.49,0,3,[],[],[],30,[],[],0
github/View.py:View:__repr__,View:__repr__,method,2,11,11,122,11.09,0,0,['self'],[None],[None],36,[],['self.get__repr__'],1
github/View.py:View:timestamp,View:timestamp,method,2,2,2,27,13.5,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",[],0
github/View.py:View:count,View:count,method,2,2,2,23,11.5,0,0,['self'],[None],[None],53,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/View.py:View:uniques,View:uniques,method,2,2,2,25,12.5,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: integer\n', '        """"""\n']",[],0
github/View.py:View:_initAttributes,View:_initAttributes,method,4,6,5,122,20.33,0,0,['self'],[None],[None],66,[],[],0
github/View.py:View:_useAttributes,View:_useAttributes,method,5,30,16,304,10.13,0,3,"['self', 'attributes']","[None, None]","[None, None]",71,[],"['self._makeDatetimeAttribute', 'self._makeIntAttribute']",2
github/Workflow.py:Workflow,Workflow,class,58,339,150,3975,11.73,0,15,[],[],[],27,[],[],0
github/Workflow.py:Workflow:__repr__,Workflow:__repr__,method,2,5,5,71,14.2,0,0,['self'],[None],[None],32,[],['self.get__repr__'],1
github/Workflow.py:Workflow:id,Workflow:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],36,"['        """"""\n', '        :type: int\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Workflow.py:Workflow:name,Workflow:name,method,3,3,3,57,19.0,0,0,['self'],[None],[None],44,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Workflow.py:Workflow:path,Workflow:path,method,3,3,3,57,19.0,0,0,['self'],[None],[None],52,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Workflow.py:Workflow:state,Workflow:state,method,3,3,3,59,19.67,0,0,['self'],[None],[None],60,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Workflow.py:Workflow:created_at,Workflow:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],68,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Workflow.py:Workflow:updated_at,Workflow:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],76,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Workflow.py:Workflow:url,Workflow:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],84,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Workflow.py:Workflow:html_url,Workflow:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],92,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Workflow.py:Workflow:badge_url,Workflow:badge_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],100,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/Workflow.py:Workflow:create_dispatch,Workflow:create_dispatch,method,13,58,40,547,9.43,0,2,"['self', 'ref', 'inputs']","[None, None, None]","[None, None, 'github.GithubObject.NotSet']",107,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches <https://docs.github.com/en/rest/reference/actions#create-a-workflow-dispatch-event>`_\n', '        :param ref: :class:`github.Branch.Branch` or :class:`github.Tag.Tag` or :class:`github.Commit.Commit` or string\n', '        :param inputs: dict\n', '        :rtype: bool\n', '        """"""\n']",['isinstance'],1
github/Workflow.py:Workflow:get_runs,Workflow:get_runs,method,13,95,46,981,10.33,0,4,"['self', 'actor', 'branch', 'event', 'status', '']","[None, None, None, None, None, None]","[None, 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', 'github.GithubObject.NotSet', None]",134,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs <https://docs.github.com/en/rest/reference/actions#workflow-runs>`_\n', '        :param actor: :class:`github.NamedUser.NamedUser` or string\n', '        :param branch: :class:`github.Branch.Branch` or string\n', '        :param event: string\n', '        :param status: string\n', '        :rtype: :class:`github.PaginatedList.PaginatedList` of :class:`github.WorkflowRun.WorkflowRun`\n', '        """"""\n']","['isinstance', 'dict']",2
github/Workflow.py:Workflow:_initAttributes,Workflow:_initAttributes,method,10,18,11,360,20.0,0,0,['self'],[None],[None],185,[],[],0
github/Workflow.py:Workflow:_useAttributes,Workflow:_useAttributes,method,12,90,34,903,10.03,0,9,"['self', 'attributes']","[None, None]","[None, None]",196,[],"['self._makeIntAttribute', 'self._makeStringAttribute', 'self._makeDatetimeAttribute']",3
github/WorkflowRun.py:WorkflowRun,WorkflowRun,class,94,471,185,6474,13.75,0,23,[],[],[],29,[],[],0
github/WorkflowRun.py:WorkflowRun:__repr__,WorkflowRun:__repr__,method,2,5,5,67,13.4,0,0,['self'],[None],[None],34,[],['self.get__repr__'],1
github/WorkflowRun.py:WorkflowRun:id,WorkflowRun:id,method,3,3,3,53,17.67,0,0,['self'],[None],[None],38,"['        """"""\n', '        :type: int\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:head_branch,WorkflowRun:head_branch,method,3,3,3,71,23.67,0,0,['self'],[None],[None],46,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:head_sha,WorkflowRun:head_sha,method,3,3,3,65,21.67,0,0,['self'],[None],[None],54,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:run_number,WorkflowRun:run_number,method,3,3,3,69,23.0,0,0,['self'],[None],[None],62,"['        """"""\n', '        :type: int\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:event,WorkflowRun:event,method,3,3,3,59,19.67,0,0,['self'],[None],[None],70,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:status,WorkflowRun:status,method,3,3,3,61,20.33,0,0,['self'],[None],[None],78,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:conclusion,WorkflowRun:conclusion,method,3,3,3,69,23.0,0,0,['self'],[None],[None],86,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:workflow_id,WorkflowRun:workflow_id,method,3,3,3,71,23.67,0,0,['self'],[None],[None],94,"['        """"""\n', '        :type: int\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:url,WorkflowRun:url,method,3,3,3,55,18.33,0,0,['self'],[None],[None],102,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:html_url,WorkflowRun:html_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],110,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:pull_requests,WorkflowRun:pull_requests,method,3,3,3,75,25.0,0,0,['self'],[None],[None],118,"['        """"""\n', '        :type: list of :class:`github.PullRequest.PullRequest`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:created_at,WorkflowRun:created_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],126,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:updated_at,WorkflowRun:updated_at,method,3,3,3,69,23.0,0,0,['self'],[None],[None],134,"['        """"""\n', '        :type: datetime.datetime\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:jobs_url,WorkflowRun:jobs_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],142,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:logs_url,WorkflowRun:logs_url,method,3,3,3,65,21.67,0,0,['self'],[None],[None],150,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:check_suite_url,WorkflowRun:check_suite_url,method,3,3,3,79,26.33,0,0,['self'],[None],[None],158,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:artifacts_url,WorkflowRun:artifacts_url,method,3,3,3,75,25.0,0,0,['self'],[None],[None],166,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:cancel_url,WorkflowRun:cancel_url,method,3,3,3,69,23.0,0,0,['self'],[None],[None],174,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:rerun_url,WorkflowRun:rerun_url,method,3,3,3,67,22.33,0,0,['self'],[None],[None],182,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:workflow_url,WorkflowRun:workflow_url,method,3,3,3,73,24.33,0,0,['self'],[None],[None],190,"['        """"""\n', '        :type: string\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:head_commit,WorkflowRun:head_commit,method,3,3,3,71,23.67,0,0,['self'],[None],[None],198,"['        """"""\n', '        :type: :class:`github.GitCommit.GitCommit`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:repository,WorkflowRun:repository,method,3,3,3,69,23.0,0,0,['self'],[None],[None],206,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:head_repository,WorkflowRun:head_repository,method,3,3,3,79,26.33,0,0,['self'],[None],[None],214,"['        """"""\n', '        :type: :class:`github.Repository.Repository`\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:cancel,WorkflowRun:cancel,method,3,3,3,69,23.0,0,0,['self'],[None],[None],221,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/actions/runs/{run_id}/cancel <https://docs.github.com/en/rest/reference/actions#workflow-runs>`_\n', '        :rtype: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:rerun,WorkflowRun:rerun,method,3,3,3,67,22.33,0,0,['self'],[None],[None],229,"['        """"""\n', '        :calls: `POST /repos/{owner}/{repo}/actions/runs/{run_id}/rerun <https://docs.github.com/en/rest/reference/actions#workflow-runs>`_\n', '        :rtype: bool\n', '        """"""\n']",['self._completeIfNotSet'],1
github/WorkflowRun.py:WorkflowRun:timing,WorkflowRun:timing,method,7,9,9,162,18.0,0,0,['self'],[None],[None],237,"['        """"""\n', '        :calls: `GET /repos/{owner}/{repo}/actions/runs/{run_id}/timing <https://docs.github.com/en/rest/reference/actions#workflow-runs>`_\n', '        :rtype: namedtuple with billable and run_duration_ms members\n', '        """"""\n']","['namedtuple', 'data.keys', 'timingdata._make']",3
github/WorkflowRun.py:WorkflowRun:_initAttributes,WorkflowRun:_initAttributes,method,24,46,25,999,21.72,0,0,['self'],[None],[None],246,[],[],0
github/WorkflowRun.py:WorkflowRun:_useAttributes,WorkflowRun:_useAttributes,method,28,244,84,2664,10.92,0,23,"['self', 'attributes']","[None, None]","[None, None]",271,[],"['self._makeIntAttribute', 'self._makeStringAttribute', 'self._makeListOfClassesAttribute', 'self._makeDatetimeAttribute', 'self._makeClassAttribute']",5
github/__init__.py:enable_console_debug_logging,enable_console_debug_logging,function,0,0,0,0,0,0,0,[],[],[],73,"['    """"""\n', '    This function sets up a very simple logging configuration (log everything on standard output) that is useful for troubleshooting.\n', '    """"""\n']",[],0
scripts/fix_headers.py:generateLicenseSection,generateLicenseSection,function,12,190,100,1044,5.49,1,0,['filename'],[None],[None],34,[],"['sorted', 'len']",2
scripts/fix_headers.py:listContributors,listContributors,function,9,23,22,219,9.52,1,0,['filename'],[None],[None],61,[],"['set', 'subprocess.check_output', 'contributors.add']",3
scripts/fix_headers.py:extractBodyLines,extractBodyLines,function,7,27,20,202,7.48,1,3,['lines'],[None],[None],72,[],"['len', 'bodyLines.append']",2
scripts/fix_headers.py:findHeadersAndFiles,findHeadersAndFiles,function,11,67,44,591,8.82,2,4,[],[],[],136,[],"['os.walk', 'dirs.remove', 'filename.endswith', 'fullname.endswith', 'print']",5
scripts/fix_headers.py:main,main,function,11,39,29,287,7.36,2,1,[],[],[],163,[],"['findHeadersAndFiles', 'print', 'open', 'list', 'header.fix', 'f.write']",6
scripts/fix_headers.py:PythonHeader,PythonHeader,class,10,53,42,507,9.57,1,3,[],[],[],92,[],[],0
scripts/fix_headers.py:StandardHeader,StandardHeader,class,8,26,24,233,8.96,1,1,[],[],[],120,[],[],0
scripts/fix_headers.py:PythonHeader:fix,PythonHeader:fix,method,9,49,38,478,9.76,1,3,"['self', 'filename', 'lines']","[None, None, None]","[None, None, None]",93,[],"['newLines.append', 'generateLicenseSection', 'extractBodyLines', 'len']",4
scripts/fix_headers.py:StandardHeader:fix,StandardHeader:fix,method,7,22,20,204,9.27,1,1,"['self', 'filename', 'lines']","[None, None, None]","[None, None, None]",93,[],"['generateLicenseSection', 'newLines.append', 'extractBodyLines', 'len']",4
tests/ApplicationOAuth.py:ApplicationOAuth,ApplicationOAuth,class,15,69,45,1275,18.48,0,0,[],[],[],26,[],[],0
tests/ApplicationOAuth.py:ApplicationOAuth:setUp,ApplicationOAuth:setUp,method,5,8,8,166,20.75,0,0,['self'],[None],[None],27,[],['super'],1
tests/ApplicationOAuth.py:ApplicationOAuth:testLoginURL,ApplicationOAuth:testLoginURL,method,5,38,20,717,18.87,0,0,['self'],[None],[None],33,[],"['self.assertEqual', 'self.assertTrue']",2
tests/ApplicationOAuth.py:ApplicationOAuth:testGetAccessToken,ApplicationOAuth:testGetAccessToken,method,3,17,16,322,18.94,0,0,['self'],[None],[None],59,[],"['self.assertEqual', 'str']",2
tests/AuthenticatedUser.py:AuthenticatedUser,AuthenticatedUser,class,108,1038,555,15983,15.4,0,0,[],[],[],40,[],[],0
tests/AuthenticatedUser.py:AuthenticatedUser:setUp,AuthenticatedUser:setUp,method,3,3,3,43,14.33,0,0,['self'],[None],[None],41,[],['super'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testAttributes,AuthenticatedUser:testAttributes,method,2,68,64,1677,24.66,0,0,['self'],[None],[None],45,[],"['self.assertEqual', 'datetime.datetime', 'self.assertFalse']",3
tests/AuthenticatedUser.py:AuthenticatedUser:testEditWithoutArguments,AuthenticatedUser:testEditWithoutArguments,method,1,1,1,16,16.0,0,0,['self'],[None],[None],80,[],[],0
tests/AuthenticatedUser.py:AuthenticatedUser:testEditWithAllArguments,AuthenticatedUser:testEditWithAllArguments,method,3,58,21,560,9.66,0,0,['self'],[None],[None],83,[],"['self.assertEqual', 'self.assertTrue']",2
tests/AuthenticatedUser.py:AuthenticatedUser:testEmails,AuthenticatedUser:testEmails,method,6,41,26,677,16.51,0,0,['self'],[None],[None],101,[],"['self.assertEqual', 'self.assertTrue']",2
tests/AuthenticatedUser.py:AuthenticatedUser:testFollowing,AuthenticatedUser:testFollowing,method,10,60,42,815,13.58,0,0,['self'],[None],[None],126,[],"['self.assertListKeyEqual', 'self.assertTrue', 'self.assertFalse']",3
tests/AuthenticatedUser.py:AuthenticatedUser:testWatching,AuthenticatedUser:testWatching,method,10,49,48,790,16.12,0,0,['self'],[None],[None],183,[],"['self.assertListKeyEqual', 'self.assertTrue', 'self.assertFalse']",3
tests/AuthenticatedUser.py:AuthenticatedUser:testStarring,AuthenticatedUser:testStarring,method,10,50,49,799,15.98,0,0,['self'],[None],[None],231,[],"['self.assertListKeyEqual', 'self.assertTrue', 'self.assertFalse']",3
tests/AuthenticatedUser.py:AuthenticatedUser:testSubscriptions,AuthenticatedUser:testSubscriptions,method,10,46,30,803,17.46,0,0,['self'],[None],[None],280,[],"['self.assertListKeyEqual', 'self.assertTrue', 'self.assertFalse']",3
tests/AuthenticatedUser.py:AuthenticatedUser:testGetAuthorizations,AuthenticatedUser:testGetAuthorizations,method,1,7,7,79,11.29,0,0,['self'],[None],[None],325,[],['self.assertListKeyEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateRepository,AuthenticatedUser:testCreateRepository,method,3,4,4,127,31.75,0,0,['self'],[None],[None],330,[],['self.assertEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateProject,AuthenticatedUser:testCreateProject,method,3,8,8,146,18.25,0,0,['self'],[None],[None],334,[],['self.assertEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateRepositoryWithAllArguments,AuthenticatedUser:testCreateRepositoryWithAllArguments,method,3,20,20,394,19.7,0,0,['self'],[None],[None],338,[],['self.assertEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateRepositoryWithAutoInit,AuthenticatedUser:testCreateRepositoryWithAutoInit,method,3,8,8,172,21.5,0,0,['self'],[None],[None],355,[],['self.assertEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateAuthorizationWithoutArguments,AuthenticatedUser:testCreateAuthorizationWithoutArguments,method,3,4,4,88,22.0,0,0,['self'],[None],[None],361,[],['self.assertEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateAuthorizationWithAllArguments,AuthenticatedUser:testCreateAuthorizationWithAllArguments,method,3,11,11,160,14.55,0,0,['self'],[None],[None],365,[],['self.assertEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateAuthorizationWithClientIdAndSecret,AuthenticatedUser:testCreateAuthorizationWithClientIdAndSecret,method,3,7,7,181,25.86,0,0,['self'],[None],[None],371,[],['self.assertEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateGist,AuthenticatedUser:testCreateGist,method,7,45,23,630,14.0,0,0,['self'],[None],[None],379,[],"['github.InputFileContent', 'self.assertEqual', 'testCreateGistWithoutDescription']",3
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateGistWithoutDescription,AuthenticatedUser:testCreateGistWithoutDescription,method,3,18,16,270,15.0,0,0,['self'],[None],[None],389,[],"['github.InputFileContent', 'self.assertEqual']",2
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateKey,AuthenticatedUser:testCreateKey,method,3,12,12,482,40.17,0,0,['self'],[None],[None],397,[],['self.assertEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testGetEvents,AuthenticatedUser:testGetEvents,method,3,10,10,127,12.7,0,0,['self'],[None],[None],404,[],['self.assertListKeyBegin'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testGetOrganizationEvents,AuthenticatedUser:testGetOrganizationEvents,method,3,12,12,177,14.75,0,0,['self'],[None],[None],411,[],['self.assertListKeyBegin'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testGetGists,AuthenticatedUser:testGetGists,method,4,27,23,299,11.07,0,0,['self'],[None],[None],420,[],['self.assertListKeyEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testGetStarredGists,AuthenticatedUser:testGetStarredGists,method,4,8,8,107,13.38,0,0,['self'],[None],[None],438,[],['self.assertListKeyEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testGetIssues,AuthenticatedUser:testGetIssues,method,8,112,92,1134,10.12,0,0,['self'],[None],[None],445,[],"['self.assertListKeyEqual', 'testGetIssuesWithAllArguments', 'datetime.datetime']",3
tests/AuthenticatedUser.py:AuthenticatedUser:testGetIssuesWithAllArguments,AuthenticatedUser:testGetIssuesWithAllArguments,method,5,71,71,674,9.49,0,0,['self'],[None],[None],468,[],"['datetime.datetime', 'self.assertListKeyEqual']",2
tests/AuthenticatedUser.py:AuthenticatedUser:testGetUserIssues,AuthenticatedUser:testGetUserIssues,method,9,89,82,874,9.82,0,0,['self'],[None],[None],530,[],"['self.assertListKeyEqual', 'testGetUserIssuesWithAllArguments', 'datetime.datetime']",3
tests/AuthenticatedUser.py:AuthenticatedUser:testGetUserIssuesWithAllArguments,AuthenticatedUser:testGetUserIssuesWithAllArguments,method,5,71,71,679,9.56,0,0,['self'],[None],[None],546,[],"['datetime.datetime', 'self.assertListKeyEqual']",2
tests/AuthenticatedUser.py:AuthenticatedUser:testGetKeys,AuthenticatedUser:testGetKeys,method,4,10,10,131,13.1,0,0,['self'],[None],[None],608,[],['self.assertListKeyEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testGetOrgs,AuthenticatedUser:testGetOrgs,method,1,7,7,82,11.71,0,0,['self'],[None],[None],615,[],['self.assertListKeyEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testGetRepos,AuthenticatedUser:testGetRepos,method,5,48,32,625,13.02,0,0,['self'],[None],[None],620,[],"['self.assertListKeyEqual', 'testGetReposWithArguments']",2
tests/AuthenticatedUser.py:AuthenticatedUser:testGetReposWithArguments,AuthenticatedUser:testGetReposWithArguments,method,4,22,22,272,12.36,0,0,['self'],[None],[None],644,[],['self.assertListKeyEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateFork,AuthenticatedUser:testCreateFork,method,3,4,4,126,31.5,0,0,['self'],[None],[None],662,[],['self.assertEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testGetNotification,AuthenticatedUser:testGetNotification,method,6,56,44,1075,19.2,0,0,['self'],[None],[None],666,[],"['self.assertEqual', 'datetime.datetime', 'repr', 'testGetNotifications', 'self.assertListKeyEqual', 'testGetNotificationsWithOtherArguments']",6
tests/AuthenticatedUser.py:AuthenticatedUser:testGetNotifications,AuthenticatedUser:testGetNotifications,method,2,16,12,229,14.31,0,0,['self'],[None],[None],688,[],"['self.assertListKeyEqual', 'testGetNotificationsWithOtherArguments']",2
tests/AuthenticatedUser.py:AuthenticatedUser:testGetNotificationsWithOtherArguments,AuthenticatedUser:testGetNotificationsWithOtherArguments,method,1,7,7,80,11.43,0,0,['self'],[None],[None],693,[],['self.assertListKeyEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testMarkNotificationsAsRead,AuthenticatedUser:testMarkNotificationsAsRead,method,1,9,8,81,9.0,0,0,['self'],[None],[None],698,[],['datetime.datetime'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testGetTeams,AuthenticatedUser:testGetTeams,method,4,18,10,206,11.44,0,0,['self'],[None],[None],703,[],['self.assertListKeyEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testAcceptInvitation,AuthenticatedUser:testAcceptInvitation,method,1,2,2,59,29.5,0,0,['self'],[None],[None],721,[],['self.assertEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testGetInvitations,AuthenticatedUser:testGetInvitations,method,5,30,28,647,21.57,0,0,['self'],[None],[None],724,[],"['self.assertEqual', 'datetime.datetime']",2
tests/AuthenticatedUser.py:AuthenticatedUser:testCreateMigration,AuthenticatedUser:testCreateMigration,method,1,6,6,103,17.17,0,0,['self'],[None],[None],742,[],"['self.assertTrue', 'isinstance']",2
tests/AuthenticatedUser.py:AuthenticatedUser:testGetMigrations,AuthenticatedUser:testGetMigrations,method,1,2,2,58,29.0,0,0,['self'],[None],[None],749,[],['self.assertEqual'],1
tests/AuthenticatedUser.py:AuthenticatedUser:testInstallations,AuthenticatedUser:testInstallations,method,3,12,12,288,24.0,0,0,['self'],[None],[None],752,[],['self.assertEqual'],1
tests/Authentication.py:Authentication,Authentication,class,13,51,25,952,18.67,0,0,[],[],[],34,[],[],0
tests/Authentication.py:Authentication:testNoAuthentication,Authentication:testNoAuthentication,method,3,5,5,80,16.0,0,0,['self'],[None],[None],35,[],"['github.Github', 'self.assertEqual']",2
tests/Authentication.py:Authentication:testBasicAuthentication,Authentication:testBasicAuthentication,method,3,6,6,104,17.33,0,0,['self'],[None],[None],39,[],"['github.Github', 'self.assertEqual']",2
tests/Authentication.py:Authentication:testOAuthAuthentication,Authentication:testOAuthAuthentication,method,3,5,5,96,19.2,0,0,['self'],[None],[None],43,[],"['github.Github', 'self.assertEqual']",2
tests/Authentication.py:Authentication:testJWTAuthentication,Authentication:testJWTAuthentication,method,3,5,5,92,18.4,0,0,['self'],[None],[None],47,[],"['github.Github', 'self.assertEqual']",2
tests/Authentication.py:Authentication:testUserAgent,Authentication:testUserAgent,method,3,5,5,107,21.4,0,0,['self'],[None],[None],51,[],"['github.Github', 'self.assertEqual']",2
tests/Authentication.py:Authentication:testAuthorizationHeaderWithLogin,Authentication:testAuthorizationHeaderWithLogin,method,5,6,6,110,18.33,0,0,['self'],[None],[None],55,[],"['github.Github', 'self.assertRaises', 'g.get_user']",3
tests/Authentication.py:Authentication:testAuthorizationHeaderWithToken,Authentication:testAuthorizationHeaderWithToken,method,5,5,5,116,23.2,0,0,['self'],[None],[None],61,[],"['github.Github', 'self.assertRaises', 'g.get_user']",3
tests/Authorization.py:Authorization,Authorization,class,10,93,57,1795,19.3,0,0,[],[],[],33,[],[],0
tests/Authorization.py:Authorization:setUp,Authorization:setUp,method,3,3,3,78,26.0,0,0,['self'],[None],[None],34,[],['super'],1
tests/Authorization.py:Authorization:testAttributes,Authorization:testAttributes,method,1,48,32,879,18.31,0,0,['self'],[None],[None],38,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/Authorization.py:Authorization:testEdit,Authorization:testEdit,method,2,33,25,727,22.03,0,0,['self'],[None],[None],65,[],['self.assertEqual'],1
tests/Authorization.py:Authorization:testDelete,Authorization:testDelete,method,1,1,1,27,27.0,0,0,['self'],[None],[None],85,[],[],0
tests/BadAttributes.py:BadAttributes,BadAttributes,class,33,346,258,5138,14.85,2,2,[],[],[],35,[],[],0
tests/BadAttributes.py:BadAttributes:testBadSimpleAttribute,BadAttributes:testBadSimpleAttribute,method,6,20,20,354,17.7,0,0,['self'],[None],[None],36,[],"['self.assertEqual', 'datetime.datetime', 'self.assertRaises']",3
tests/BadAttributes.py:BadAttributes:testBadAttributeTransformation,BadAttributes:testBadAttributeTransformation,method,6,30,29,491,16.37,0,0,['self'],[None],[None],46,[],"['self.assertEqual', 'self.assertRaises']",2
tests/BadAttributes.py:BadAttributes:testBadTransformedAttribute,BadAttributes:testBadTransformedAttribute,method,6,17,17,335,19.71,0,0,['self'],[None],[None],62,[],"['self.assertEqual', 'self.assertRaises']",2
tests/BadAttributes.py:BadAttributes:testBadSimpleAttributeInList,BadAttributes:testBadSimpleAttributeInList,method,6,16,16,344,21.5,0,0,['self'],[None],[None],72,[],"['self.assertEqual', 'self.assertRaises']",2
tests/BadAttributes.py:BadAttributes:testBadAttributeInClassAttribute,BadAttributes:testBadAttributeInClassAttribute,method,8,13,13,227,17.46,0,0,['self'],[None],[None],82,[],"['self.assertEqual', 'self.assertRaises']",2
tests/BadAttributes.py:BadAttributes:testBadTransformedAttributeInList,BadAttributes:testBadTransformedAttributeInList,method,6,16,16,370,23.12,0,0,['self'],[None],[None],91,[],"['self.assertRaises', 'self.assertEqual']",2
tests/BadAttributes.py:BadAttributes:testBadTransformedAttributeInDict,BadAttributes:testBadTransformedAttributeInDict,method,6,15,15,303,20.2,0,0,['self'],[None],[None],102,[],"['self.assertRaises', 'self.assertEqual']",2
tests/BadAttributes.py:BadAttributes:testIssue195,BadAttributes:testIssue195,method,9,203,191,2402,11.83,2,2,['self'],[None],[None],111,[],"['self.assertListKeyEqual', 'self.assertRaises', 'self.assertEqual']",3
tests/Branch.py:Branch,Branch,class,71,414,198,8959,21.64,0,0,[],[],[],36,[],[],0
tests/Branch.py:Branch:setUp,Branch:setUp,method,8,12,12,285,23.75,0,0,['self'],[None],[None],37,[],['super'],1
tests/Branch.py:Branch:testAttributes,Branch:testAttributes,method,2,15,12,428,28.53,0,0,['self'],[None],[None],46,[],"['self.assertEqual', 'self.assertFalse', 'repr']",3
tests/Branch.py:Branch:testEditProtection,Branch:testEditProtection,method,17,122,69,2332,19.11,0,0,['self'],[None],[None],60,[],"['self.assertTrue', 'self.assertEqual', 'self.assertFalse', 'testEditProtectionDismissalUsersWithUserOwnedBranch', 'self.assertRaises', 'testEditProtectionPushRestrictionsWithUserOwnedBranch', 'testEditProtectionPushRestrictionsAndDismissalUser', 'self.assertListKeyEqual', 'branch_protection.get_user_push_restrictions', 'branch_protection.get_team_push_restrictions']",10
tests/Branch.py:Branch:testEditProtectionDismissalUsersWithUserOwnedBranch,Branch:testEditProtectionDismissalUsersWithUserOwnedBranch,method,4,29,29,427,14.72,0,0,['self'],[None],[None],81,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Branch.py:Branch:testEditProtectionPushRestrictionsWithUserOwnedBranch,Branch:testEditProtectionPushRestrictionsWithUserOwnedBranch,method,4,32,32,462,14.44,0,0,['self'],[None],[None],96,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Branch.py:Branch:testEditProtectionPushRestrictionsAndDismissalUser,Branch:testEditProtectionPushRestrictionsAndDismissalUser,method,7,34,20,601,17.68,0,0,['self'],[None],[None],113,[],"['self.assertListKeyEqual', 'branch_protection.get_user_push_restrictions', 'branch_protection.get_team_push_restrictions']",3
tests/Branch.py:Branch:testRemoveProtection,Branch:testRemoveProtection,method,9,23,23,506,22.0,0,0,['self'],[None],[None],137,[],"['self.assertTrue', 'self.assertFalse', 'self.assertRaises', 'protected_branch.get_protection', 'self.assertEqual']",5
tests/Branch.py:Branch:testEditRequiredStatusChecks,Branch:testEditRequiredStatusChecks,method,5,6,6,245,40.83,0,0,['self'],[None],[None],153,[],"['self.assertTrue', 'self.assertEqual']",2
tests/Branch.py:Branch:testRemoveRequiredStatusChecks,Branch:testRemoveRequiredStatusChecks,method,5,21,21,424,20.19,0,0,['self'],[None],[None],159,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Branch.py:Branch:testEditRequiredPullRequestReviews,Branch:testEditRequiredPullRequestReviews,method,8,73,51,1498,20.52,0,0,['self'],[None],[None],172,[],"['self.assertTrue', 'self.assertEqual', 'testEditRequiredPullRequestReviewsWithTooLargeApprovingReviewCount', 'self.assertRaises', 'testEditRequiredPullRequestReviewsWithUserBranchAndDismissalUsers']",5
tests/Branch.py:Branch:testEditRequiredPullRequestReviewsWithTooLargeApprovingReviewCount,Branch:testEditRequiredPullRequestReviewsWithTooLargeApprovingReviewCount,method,4,27,27,440,16.3,0,0,['self'],[None],[None],185,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Branch.py:Branch:testEditRequiredPullRequestReviewsWithUserBranchAndDismissalUsers,Branch:testEditRequiredPullRequestReviewsWithUserBranchAndDismissalUsers,method,4,28,28,464,16.57,0,0,['self'],[None],[None],199,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Branch.py:Branch:testRemoveRequiredPullRequestReviews,Branch:testRemoveRequiredPullRequestReviews,method,4,11,11,381,34.64,0,0,['self'],[None],[None],213,[],"['self.assertFalse', 'self.assertEqual']",2
tests/Branch.py:Branch:testAdminEnforcement,Branch:testAdminEnforcement,method,4,4,4,221,55.25,0,0,['self'],[None],[None],224,[],"['self.assertFalse', 'self.assertTrue']",2
tests/Branch.py:Branch:testAddUserPushRestrictions,Branch:testAddUserPushRestrictions,method,5,9,9,181,20.11,0,0,['self'],[None],[None],230,[],['self.assertListKeyEqual'],1
tests/Branch.py:Branch:testReplaceUserPushRestrictions,Branch:testReplaceUserPushRestrictions,method,5,15,10,287,19.13,0,0,['self'],[None],[None],238,[],['self.assertListKeyEqual'],1
tests/Branch.py:Branch:testRemoveUserPushRestrictions,Branch:testRemoveUserPushRestrictions,method,5,8,8,176,22.0,0,0,['self'],[None],[None],251,[],['self.assertListKeyEqual'],1
tests/Branch.py:Branch:testAddTeamPushRestrictions,Branch:testAddTeamPushRestrictions,method,5,8,8,189,23.62,0,0,['self'],[None],[None],259,[],['self.assertListKeyEqual'],1
tests/Branch.py:Branch:testReplaceTeamPushRestrictions,Branch:testReplaceTeamPushRestrictions,method,5,15,10,298,19.87,0,0,['self'],[None],[None],267,[],['self.assertListKeyEqual'],1
tests/Branch.py:Branch:testRemoveTeamPushRestrictions,Branch:testRemoveTeamPushRestrictions,method,5,8,8,185,23.12,0,0,['self'],[None],[None],280,[],['self.assertListKeyEqual'],1
tests/Branch.py:Branch:testRemovePushRestrictions,Branch:testRemovePushRestrictions,method,4,20,20,423,21.15,0,0,['self'],[None],[None],288,[],"['self.assertRaises', 'list', 'self.assertEqual']",3
tests/Branch.py:Branch:testGetRequiredSignatures,Branch:testGetRequiredSignatures,method,2,4,3,91,22.75,0,0,['self'],[None],[None],301,[],[],0
tests/Branch.py:Branch:testRemoveRequiredSignatures,Branch:testRemoveRequiredSignatures,method,1,1,1,50,50.0,0,0,['self'],[None],[None],305,[],[],0
tests/Branch.py:Branch:testAddRequiredSignatures,Branch:testAddRequiredSignatures,method,1,1,1,47,47.0,0,0,['self'],[None],[None],308,[],[],0
tests/BranchProtection.py:BranchProtection,BranchProtection,class,6,25,20,619,24.76,0,0,[],[],[],26,[],[],0
tests/BranchProtection.py:BranchProtection:setUp,BranchProtection:setUp,method,2,8,8,128,16.0,0,0,['self'],[None],[None],27,[],['super'],1
tests/BranchProtection.py:BranchProtection:testAttributes,BranchProtection:testAttributes,method,2,13,10,449,34.54,0,0,['self'],[None],[None],36,[],"['self.assertTrue', 'self.assertEqual']",2
tests/CheckRun.py:CheckRun,CheckRun,class,47,724,343,10181,14.06,0,0,[],[],[],28,[],[],0
tests/CheckRun.py:CheckRun:setUp,CheckRun:setUp,method,10,13,13,326,25.08,0,0,['self'],[None],[None],29,[],['super'],1
tests/CheckRun.py:CheckRun:testAttributes,CheckRun:testAttributes,method,1,65,46,1304,20.06,0,0,['self'],[None],[None],38,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/CheckRun.py:CheckRun:testCheckRunOutputAttributes,CheckRun:testCheckRunOutputAttributes,method,4,31,26,527,17.0,0,0,['self'],[None],[None],77,[],"['self.assertEqual', 'self.assertIsNone', 'repr']",3
tests/CheckRun.py:CheckRun:testGetCheckRunsForRef,CheckRun:testGetCheckRunsForRef,method,12,86,46,1444,16.79,0,0,['self'],[None],[None],94,[],"['self.assertEqual', 'self.assertListEqual', 'testGetCheckRunsForRefFilterByCheckName', 'testGetCheckRunsForRefFilterByStatus', 'testGetCheckRunsForRefFilterByFilter']",5
tests/CheckRun.py:CheckRun:testGetCheckRunsForRefFilterByCheckName,CheckRun:testGetCheckRunsForRefFilterByCheckName,method,4,12,12,183,15.25,0,0,['self'],[None],[None],102,[],"['self.assertEqual', 'self.assertListEqual']",2
tests/CheckRun.py:CheckRun:testGetCheckRunsForRefFilterByStatus,CheckRun:testGetCheckRunsForRefFilterByStatus,method,6,23,23,477,20.74,0,0,['self'],[None],[None],107,[],"['self.assertEqual', 'self.assertListEqual']",2
tests/CheckRun.py:CheckRun:testGetCheckRunsForRefFilterByFilter,CheckRun:testGetCheckRunsForRefFilterByFilter,method,5,30,20,445,14.83,0,0,['self'],[None],[None],119,[],"['self.assertEqual', 'self.assertListEqual']",2
tests/CheckRun.py:CheckRun:testCreateCheckRunInProgress,CheckRun:testCreateCheckRunInProgress,method,6,53,44,962,18.15,0,0,['self'],[None],[None],133,[],"['self.assertEqual', 'datetime.datetime', 'self.assertIsNone', 'check_run.edit']",4
tests/CheckRun.py:CheckRun:testCreateCheckRunCompleted,CheckRun:testCreateCheckRunCompleted,method,7,156,107,1463,9.38,0,0,['self'],[None],[None],157,[],"['self.assertEqual', 'datetime.datetime']",2
tests/CheckRun.py:CheckRun:testUpdateCheckRunSuccess,CheckRun:testUpdateCheckRunSuccess,method,5,78,51,911,11.68,0,0,['self'],[None],[None],216,[],"['self.assertEqual', 'check_run.edit']",2
tests/CheckRun.py:CheckRun:testUpdateCheckRunFailure,CheckRun:testUpdateCheckRunFailure,method,5,105,87,1050,10.0,0,0,['self'],[None],[None],246,[],"['self.assertEqual', 'check_run.edit']",2
tests/CheckRun.py:CheckRun:testUpdateCheckRunAll,CheckRun:testUpdateCheckRunAll,method,6,61,46,815,13.36,0,0,['self'],[None],[None],290,[],"['check_run.edit', 'self.assertEqual', 'datetime.datetime']",3
tests/CheckRun.py:CheckRun:testCheckRunAnnotationAttributes,CheckRun:testCheckRunAnnotationAttributes,method,6,35,34,676,19.31,0,0,['self'],[None],[None],318,[],"['self.assertEqual', 'check_run.get_annotations', 'self.assertIsNone']",3
tests/CheckRun.py:CheckRun:testListCheckRunAnnotations,CheckRun:testListCheckRunAnnotations,method,6,19,19,318,16.74,0,0,['self'],[None],[None],333,[],"['self.assertEqual', 'check_run.get_annotations', 'self.assertListEqual']",3
tests/CheckSuite.py:CheckSuite,CheckSuite,class,47,259,149,4462,17.23,2,2,[],[],[],29,[],[],0
tests/CheckSuite.py:CheckSuite:setUp,CheckSuite:setUp,method,13,17,17,475,27.94,0,0,['self'],[None],[None],30,[],['super'],1
tests/CheckSuite.py:CheckSuite:testAttributes,CheckSuite:testAttributes,method,3,54,43,1147,21.24,0,0,['self'],[None],[None],41,[],"['self.assertEqual', 'datetime']",2
tests/CheckSuite.py:CheckSuite:testGetCheckSuitesForRef,CheckSuite:testGetCheckSuitesForRef,method,6,41,27,637,15.54,0,0,['self'],[None],[None],70,[],"['self.assertEqual', 'self.assertListEqual', 'testGetCheckSuitesForRefFilterByAppId', 'testGetCheckSuitesForRefFilterByCheckName']",4
tests/CheckSuite.py:CheckSuite:testGetCheckSuitesForRefFilterByAppId,CheckSuite:testGetCheckSuitesForRefFilterByAppId,method,4,10,10,161,16.1,0,0,['self'],[None],[None],78,[],"['self.assertEqual', 'self.assertListEqual']",2
tests/CheckSuite.py:CheckSuite:testGetCheckSuitesForRefFilterByCheckName,CheckSuite:testGetCheckSuitesForRefFilterByCheckName,method,4,10,10,166,16.6,0,0,['self'],[None],[None],83,[],"['self.assertEqual', 'self.assertListEqual']",2
tests/CheckSuite.py:CheckSuite:testCheckSuiteRerequest,CheckSuite:testCheckSuiteRerequest,method,5,5,5,86,17.2,0,0,['self'],[None],[None],88,[],"['cs.rerequest', 'self.assertTrue']",2
tests/CheckSuite.py:CheckSuite:testGetCheckRuns,CheckSuite:testGetCheckRuns,method,7,79,33,1052,13.32,0,0,['self'],[None],[None],93,[],"['self.assertEqual', 'self.assertListEqual', 'testGetCheckRunsFilterByCheckName', 'testGetCheckRunsFilterByStatus', 'testGetCheckRunsFilterByFilter']",5
tests/CheckSuite.py:CheckSuite:testGetCheckRunsFilterByCheckName,CheckSuite:testGetCheckRunsFilterByCheckName,method,3,10,10,167,16.7,0,0,['self'],[None],[None],110,[],['self.assertEqual'],1
tests/CheckSuite.py:CheckSuite:testGetCheckRunsFilterByStatus,CheckSuite:testGetCheckRunsFilterByStatus,method,4,21,21,260,12.38,0,0,['self'],[None],[None],115,[],"['self.assertEqual', 'self.assertListEqual']",2
tests/CheckSuite.py:CheckSuite:testGetCheckRunsFilterByFilter,CheckSuite:testGetCheckRunsFilterByFilter,method,4,21,21,254,12.1,0,0,['self'],[None],[None],132,[],"['self.assertEqual', 'self.assertListEqual']",2
tests/CheckSuite.py:CheckSuite:testCreateCheckSuite,CheckSuite:testCreateCheckSuite,method,5,9,9,237,26.33,0,0,['self'],[None],[None],149,[],"['self.assertEqual', 'self.assertIsNone']",2
tests/CheckSuite.py:CheckSuite:testUpdateCheckSuitesPreferences,CheckSuite:testUpdateCheckSuitesPreferences,method,10,40,24,611,15.28,2,2,['self'],[None],[None],156,[],"['self.assertFalse', 'self.assertEqual', 'self.assertTrue']",3
tests/Commit.py:Commit,Commit,class,27,200,117,3981,19.91,0,0,[],[],[],33,[],[],0
tests/Commit.py:Commit:setUp,Commit:setUp,method,7,13,13,174,13.38,0,0,['self'],[None],[None],34,[],['super'],1
tests/Commit.py:Commit:testAttributes,Commit:testAttributes,method,2,62,41,1762,28.42,0,0,['self'],[None],[None],43,[],"['self.assertEqual', 'self.assertTrue', 'repr']",3
tests/Commit.py:Commit:testGetComments,Commit:testGetComments,method,4,10,10,103,10.3,0,0,['self'],[None],[None],90,[],['self.assertListKeyEqual'],1
tests/Commit.py:Commit:testCreateComment,Commit:testCreateComment,method,5,56,29,975,17.41,0,0,['self'],[None],[None],97,[],"['self.assertEqual', 'testCreateCommentOnFileLine', 'testCreateCommentOnFilePosition']",3
tests/Commit.py:Commit:testCreateCommentOnFileLine,Commit:testCreateCommentOnFileLine,method,3,19,18,338,17.79,0,0,['self'],[None],[None],104,[],['self.assertEqual'],1
tests/Commit.py:Commit:testCreateCommentOnFilePosition,Commit:testCreateCommentOnFilePosition,method,3,20,19,344,17.2,0,0,['self'],[None],[None],117,[],['self.assertEqual'],1
tests/Commit.py:Commit:testCreateStatusWithoutOptionalParameters,Commit:testCreateStatusWithoutOptionalParameters,method,3,10,10,202,20.2,0,0,['self'],[None],[None],130,[],['self.assertEqual'],1
tests/Commit.py:Commit:testCreateStatusWithAllParameters,Commit:testCreateStatusWithAllParameters,method,3,24,19,371,15.46,0,0,['self'],[None],[None],137,[],['self.assertEqual'],1
tests/Commit.py:Commit:testGetPulls,Commit:testGetPulls,method,2,11,11,174,15.82,0,0,['self'],[None],[None],150,[],['self.assertListKeyEqual'],1
tests/CommitCombinedStatus.py:CommitCombinedStatus,CommitCombinedStatus,class,5,72,50,1703,23.65,0,0,[],[],[],32,[],[],0
tests/CommitCombinedStatus.py:CommitCombinedStatus:setUp,CommitCombinedStatus:setUp,method,2,8,8,165,20.62,0,0,['self'],[None],[None],33,[],['super'],1
tests/CommitCombinedStatus.py:CommitCombinedStatus:testAttributes,CommitCombinedStatus:testAttributes,method,1,60,40,1496,24.93,0,0,['self'],[None],[None],41,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/CommitComment.py:CommitComment,CommitComment,class,18,83,57,1486,17.9,0,0,[],[],[],36,[],[],0
tests/CommitComment.py:CommitComment:setUp,CommitComment:setUp,method,3,3,3,88,29.33,0,0,['self'],[None],[None],37,[],['super'],1
tests/CommitComment.py:CommitComment:testAttributes,CommitComment:testAttributes,method,1,50,33,894,17.88,0,0,['self'],[None],[None],41,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/CommitComment.py:CommitComment:testEdit,CommitComment:testEdit,method,1,4,4,44,11.0,0,0,['self'],[None],[None],70,[],[],0
tests/CommitComment.py:CommitComment:testDelete,CommitComment:testDelete,method,1,1,1,21,21.0,0,0,['self'],[None],[None],73,[],[],0
tests/CommitComment.py:CommitComment:testGetReactions,CommitComment:testGetReactions,method,3,4,4,82,20.5,0,0,['self'],[None],[None],76,[],['self.assertEqual'],1
tests/CommitComment.py:CommitComment:testCreateReaction,CommitComment:testCreateReaction,method,3,6,6,130,21.67,0,0,['self'],[None],[None],80,[],['self.assertEqual'],1
tests/CommitComment.py:CommitComment:testDeleteReaction,CommitComment:testDeleteReaction,method,1,1,1,55,55.0,0,0,['self'],[None],[None],86,[],['self.assertTrue'],1
tests/CommitStatus.py:CommitStatus,CommitStatus,class,5,62,46,1009,16.27,0,0,[],[],[],36,[],[],0
tests/CommitStatus.py:CommitStatus:setUp,CommitStatus:setUp,method,2,8,8,149,18.62,0,0,['self'],[None],[None],37,[],"['super', 'list']",2
tests/CommitStatus.py:CommitStatus:testAttributes,CommitStatus:testAttributes,method,1,50,36,818,16.36,0,0,['self'],[None],[None],46,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/ConditionalRequestUpdate.py:ConditionalRequestUpdate,ConditionalRequestUpdate,class,19,40,31,430,10.75,0,0,[],[],[],31,[],[],0
tests/ConditionalRequestUpdate.py:ConditionalRequestUpdate:setUp,ConditionalRequestUpdate:setUp,method,3,4,4,71,17.75,0,0,['self'],[None],[None],32,[],['super'],1
tests/ConditionalRequestUpdate.py:ConditionalRequestUpdate:testDidNotUpdate,ConditionalRequestUpdate:testDidNotUpdate,method,1,11,11,83,7.55,0,0,['self'],[None],[None],36,[],"['self.assertFalse', 'update']",2
tests/ConditionalRequestUpdate.py:ConditionalRequestUpdate:testDidUpdate,ConditionalRequestUpdate:testDidUpdate,method,10,13,13,91,7.0,0,0,['self'],[None],[None],41,[],"['self.assertTrue', 'update']",2
tests/ConditionalRequestUpdate.py:ConditionalRequestUpdate:testUpdateObjectWithoutEtag,ConditionalRequestUpdate:testUpdateObjectWithoutEtag,method,3,4,4,77,19.25,0,0,['self'],[None],[None],47,[],['self.assertTrue'],1
tests/conftest.py:pytest_addoption,pytest_addoption,function,1,17,13,225,13.24,0,0,['parser'],[None],[None],26,[],['parser.addoption'],1
tests/conftest.py:pytest_configure,pytest_configure,function,4,9,7,202,22.44,0,3,['config'],[None],[None],34,[],"['config.getoption', 'Framework.activateRecordMode', 'Framework.activateTokenAuthMode', 'Framework.activateJWTAuthMode']",4
tests/Connection.py:testRecordAndReplay,testRecordAndReplay,function,35,70,63,1074,15.34,0,0,"['replaying_connection_class', 'protocol', 'response_body', 'expected_recording']","[None, None, None, None]","[None, None, None, None]",69,[],"['StringIO', 'Mock', 'RecordingMockConnection', 'recording_connection.request', 'recording_connection.getresponse', 'recording_connection.close', 'file.getvalue', 'eval', 'httpretty.enable', 'file.seek', 'replaying_connection_class', 'replaying_connection.request', 'replaying_connection.getresponse', 'httpretty.disable', 'httpretty.reset']",15
tests/Connection.py:RecordingMockConnection,RecordingMockConnection,class,4,13,11,135,10.38,0,0,[],[],[],59,[],[],0
tests/Connection.py:RecordingMockConnection:__init__,RecordingMockConnection:__init__,method,3,6,6,77,12.83,0,0,"['self', 'file', 'protocol', 'host', 'port', 'realConnection']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",60,[],['super'],1
tests/ContentFile.py:ContentFile,ContentFile,class,7,30,27,727,24.23,0,0,[],[],[],34,[],[],0
tests/ContentFile.py:ContentFile:setUp,ContentFile:setUp,method,3,3,3,77,25.67,0,0,['self'],[None],[None],35,[],['super'],1
tests/ContentFile.py:ContentFile:testAttributes,ContentFile:testAttributes,method,2,23,21,608,26.43,0,0,['self'],[None],[None],39,[],"['self.assertEqual', 'self.assertIsNone']",2
tests/Deployment.py:Deployment,Deployment,class,7,61,50,1389,22.77,0,0,[],[],[],29,[],[],0
tests/Deployment.py:Deployment:setUp,Deployment:setUp,method,2,5,5,100,20.0,0,0,['self'],[None],[None],30,[],['super'],1
tests/Deployment.py:Deployment:testAttributes,Deployment:testAttributes,method,3,52,43,1247,23.98,0,0,['self'],[None],[None],36,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/DeploymentStatus.py:DeploymentStatus,DeploymentStatus,class,16,91,72,1929,21.2,0,0,[],[],[],29,[],[],0
tests/DeploymentStatus.py:DeploymentStatus:setUp,DeploymentStatus:setUp,method,4,7,7,150,21.43,0,0,['self'],[None],[None],30,[],['super'],1
tests/DeploymentStatus.py:DeploymentStatus:testAttributes,DeploymentStatus:testAttributes,method,3,47,39,1161,24.7,0,0,['self'],[None],[None],37,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/DeploymentStatus.py:DeploymentStatus:testCreate,DeploymentStatus:testCreate,method,3,18,18,404,22.44,0,0,['self'],[None],[None],69,[],['self.assertEqual'],1
tests/DeploymentStatus.py:DeploymentStatus:testGetStatuses,DeploymentStatus:testGetStatuses,method,3,11,11,123,11.18,0,0,['self'],[None],[None],85,[],['self.assertListKeyEqual'],1
tests/Download.py:Download,Download,class,8,63,46,1318,20.92,0,0,[],[],[],34,[],[],0
tests/Download.py:Download:setUp,Download:setUp,method,3,3,3,89,29.67,0,0,['self'],[None],[None],35,[],['super'],1
tests/Download.py:Download:testAttributes,Download:testAttributes,method,1,53,38,1143,21.57,0,0,['self'],[None],[None],39,[],"['self.assertEqual', 'datetime.datetime']",2
tests/Download.py:Download:testDelete,Download:testDelete,method,1,1,1,22,22.0,0,0,['self'],[None],[None],70,[],[],0
tests/Enterprise.py:Enterprise,Enterprise,class,16,148,56,2004,13.54,0,0,[],[],[],34,[],[],0
tests/Enterprise.py:Enterprise:testHttps,Enterprise:testHttps,method,6,30,30,400,13.33,0,0,['self'],[None],[None],35,[],"['github.Github', 'self.assertListKeyEqual', 'g.get_user']",3
tests/Enterprise.py:Enterprise:testHttp,Enterprise:testHttp,method,7,62,33,819,13.21,0,0,['self'],[None],[None],62,[],"['github.Github', 'self.assertListKeyEqual', 'g.get_user', 'testHttp']",4
tests/Enterprise.py:Enterprise:testUnknownUrlScheme,Enterprise:testUnknownUrlScheme,method,4,13,13,194,14.92,0,0,['self'],[None],[None],89,[],"['self.assertRaises', 'github.Github', 'self.assertEqual']",3
tests/Enterprise.py:Enterprise:testLongUrl,Enterprise:testLongUrl,method,6,35,34,484,13.83,0,0,['self'],[None],[None],96,[],"['github.Github', 'g.get_user', 'self.assertListKeyEqual', 'self.assertEqual']",4
tests/Enterprise.py:Enterprise:testSpecificPort,Enterprise:testSpecificPort,method,6,30,30,404,13.47,0,0,['self'],[None],[None],127,[],"['github.Github', 'self.assertListKeyEqual', 'g.get_user']",3
tests/Equality.py:Equality,Equality,class,12,30,21,474,15.8,0,0,[],[],[],29,[],[],0
tests/Equality.py:Equality:testUserEquality,Equality:testUserEquality,method,4,8,7,121,15.12,0,0,['self'],[None],[None],30,[],"['self.assertEqual', 'hash']",2
tests/Equality.py:Equality:testUserDifference,Equality:testUserDifference,method,4,8,8,127,15.88,0,0,['self'],[None],[None],36,[],"['self.assertNotEqual', 'hash']",2
tests/Equality.py:Equality:testBranchEquality,Equality:testBranchEquality,method,6,8,7,139,17.38,0,0,['self'],[None],[None],42,[],"['r.get_branch', 'self.assertNotEqual']",2
tests/Event.py:Event,Event,class,7,283,114,4131,14.6,0,0,[],[],[],34,[],[],0
tests/Event.py:Event:setUp,Event:setUp,method,3,3,3,70,23.33,0,0,['self'],[None],[None],35,[],['super'],1
tests/Event.py:Event:testAttributes,Event:testAttributes,method,2,276,108,4019,14.56,0,0,['self'],[None],[None],39,[],"['self.assertEqual', 'datetime.datetime', 'self.assertTrue']",3
tests/Exceptions.py:Exceptions,Exceptions,class,13,141,87,1934,13.72,0,0,[],[],[],39,[],[],0
tests/Exceptions.py:SpecificExceptions,SpecificExceptions,class,22,75,52,1190,15.87,2,0,[],[],[],101,[],[],0
tests/Exceptions.py:Exceptions:testInvalidInput,Exceptions:testInvalidInput,method,4,49,45,412,8.41,0,0,['self'],[None],[None],40,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Exceptions.py:Exceptions:testNonJsonDataReturnedByGithub,Exceptions:testNonJsonDataReturnedByGithub,method,4,23,23,291,12.65,0,0,['self'],[None],[None],59,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Exceptions.py:Exceptions:testUnknownObject,Exceptions:testUnknownObject,method,4,16,14,277,17.31,0,0,['self'],[None],[None],71,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Exceptions.py:Exceptions:testUnknownUser,Exceptions:testUnknownUser,method,4,16,14,291,18.19,0,0,['self'],[None],[None],78,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Exceptions.py:Exceptions:testBadAuthentication,Exceptions:testBadAuthentication,method,4,17,15,311,18.29,0,0,['self'],[None],[None],85,[],"['self.assertRaises', 'github.Github', 'self.assertEqual']",3
tests/Exceptions.py:Exceptions:testExceptionPickling,Exceptions:testExceptionPickling,method,1,3,3,68,22.67,0,0,['self'],[None],[None],92,[],['pickle.loads'],1
tests/Exceptions.py:Exceptions:testJSONParseError,Exceptions:testJSONParseError,method,3,3,3,62,20.67,0,0,['self'],[None],[None],95,[],['self.assertRaises'],1
tests/Exceptions.py:SpecificExceptions:testBadCredentials,SpecificExceptions:testBadCredentials,method,1,6,6,116,19.33,0,0,['self'],[None],[None],102,[],"['self.assertRaises', 'github.Github']",2
tests/Exceptions.py:SpecificExceptions:test2FARequired,SpecificExceptions:test2FARequired,method,1,6,6,108,18.0,0,0,['self'],[None],[None],108,[],"['self.assertRaises', 'github.Github']",2
tests/Exceptions.py:SpecificExceptions:testUnknownObject,SpecificExceptions:testUnknownObject,method,1,5,5,91,18.2,0,0,['self'],[None],[None],71,[],['self.assertRaises'],1
tests/Exceptions.py:SpecificExceptions:testBadUserAgent,SpecificExceptions:testBadUserAgent,method,1,9,9,130,14.44,0,0,['self'],[None],[None],119,[],"['self.assertRaises', 'github.Github']",2
tests/Exceptions.py:SpecificExceptions:testRateLimitExceeded,SpecificExceptions:testRateLimitExceeded,method,7,11,11,131,11.91,1,0,['self'],[None],[None],127,[],"['github.Github', 'exceed', 'range', 'g.get_user', 'self.assertRaises']",5
tests/Exceptions.py:SpecificExceptions:testAuthenticatedRateLimitExceeded,SpecificExceptions:testAuthenticatedRateLimitExceeded,method,9,16,16,223,13.94,1,0,['self'],[None],[None],136,[],"['exceed', 'range', 'res.get_page', 'self.assertRaises', 'self.assertEqual']",5
tests/Exceptions.py:SpecificExceptions:testIncompletableObject,SpecificExceptions:testIncompletableObject,method,4,8,7,164,20.5,0,0,['self'],[None],[None],146,[],['self.assertRaises'],1
tests/ExposeAllAttributes.py:ExposeAllAttributes,ExposeAllAttributes,class,112,212,185,3287,15.5,4,5,[],[],[],29,[],[],0
tests/ExposeAllAttributes.py:ExposeAllAttributes:testAllClasses,ExposeAllAttributes:testAllClasses,method,94,157,151,2613,16.64,2,0,['self'],[None],[None],30,[],"['authenticatedUser.get_repo', 'repository.get_branch', 'repository.get_commit', 'commit.get_statuses', 'repository.get_milestone', 'gist.get_comment', 'repository.get_git_commit', 'repository.get_git_tree', 'repository.get_git_blob', 'repository.get_git_ref', 'repository.get_issue', 'issue.get_comment', 'issue.get_events', 'organization.get_team', 'repository.get_label', 'repository.get_pull', 'pullRequest.get_review_comment', 'pullRequest.get_files', 'repository.get_comment', 'repository.get_hooks', 'repository.compare', 'repository.get_contents', 'repository.get_events', 'authenticatedUser.get_notification', 'self.gatherMissingAttributes', 'sorted', 'print', 'repr', 'self.assertEqual', 'missingAttributes.values']",30
tests/ExposeAllAttributes.py:ExposeAllAttributes:findMissingAttributes,ExposeAllAttributes:findMissingAttributes,method,10,24,20,260,10.83,1,3,"['self', 'obj']","[None, None]","[None, None]",139,[],"['hasattr', 'obj.update']",2
tests/ExposeAllAttributes.py:ExposeAllAttributes:gatherMissingAttributes,ExposeAllAttributes:gatherMissingAttributes,method,10,23,19,312,13.57,1,2,"['self', 'objs']","[None, None]","[None, None]",150,[],"['dict', 'self.findMissingAttributes', 'len']",3
tests/Framework.py:readLine,readLine,function,6,9,8,92,10.22,0,1,['file_'],[None],[None],50,[],"['file_.readline', 'isinstance', 'line.decode', 'line.strip']",4
tests/Framework.py:fixAuthorizationHeader,fixAuthorizationHeader,function,3,25,18,414,16.56,0,2,['headers'],[None],[None],70,[],[],0
tests/Framework.py:activateRecordMode,activateRecordMode,function,2,2,2,25,12.5,0,0,"[')', 'not used during automated tests)BasicTestCase.recordMode = True)', 'not used during automated tests)BasicTestCase.tokenAuthMode = True)', 'not used during automated tests)BasicTestCase.jwtAuthMode = Trueretry)']","['  # pragma no cover (Function useful only when recording new tests', '', '', '']","[None, ' True):  # pragma no cover (Function useful only when recording new tests', ' True):  # pragma no cover (Function useful only when recording new tests', ' Trueretry):']",364,[],[],0
tests/Framework.py:activateTokenAuthMode,activateTokenAuthMode,function,2,2,2,25,12.5,0,0,"[')', 'not used during automated tests)BasicTestCase.tokenAuthMode = True)', 'not used during automated tests)BasicTestCase.jwtAuthMode = Trueretry)']","['  # pragma no cover (Function useful only when recording new tests', '', '']","[None, ' True):  # pragma no cover (Function useful only when recording new tests', ' Trueretry):']",368,[],[],0
tests/Framework.py:activateJWTAuthMode,activateJWTAuthMode,function,2,2,2,25,12.5,0,0,"[')', 'not used during automated tests)BasicTestCase.jwtAuthMode = Trueretry)']","['  # pragma no cover (Function useful only when recording new tests', '']","[None, ' Trueretry):']",372,[],[],0
tests/Framework.py:enableRetry,enableRetry,function,2,2,2,25,12.5,0,0,['retry'],[None],[None],376,[],[],0
tests/Framework.py:setPoolSize,setPoolSize,function,2,2,2,33,16.5,0,0,['pool_size'],[None],[None],380,[],[],0
tests/Framework.py:FakeHttpResponse,FakeHttpResponse,class,10,19,15,180,9.47,0,0,[],[],[],57,[],[],0
tests/Framework.py:RecordingConnection,RecordingConnection,class,33,73,64,984,13.48,0,0,[],[],[],86,[],[],0
tests/Framework.py:RecordingHttpConnection,RecordingHttpConnection,class,4,11,10,140,12.73,0,0,[],[],[],136,[],[],0
tests/Framework.py:RecordingHttpsConnection,RecordingHttpsConnection,class,4,11,10,142,12.91,0,0,[],[],[],143,[],[],0
tests/Framework.py:ReplayingConnection,ReplayingConnection,class,54,150,108,1968,13.12,0,3,[],[],[],150,[],[],0
tests/Framework.py:ReplayingHttpConnection,ReplayingHttpConnection,class,4,11,10,140,12.73,0,0,[],[],[],228,[],[],0
tests/Framework.py:ReplayingHttpsConnection,ReplayingHttpsConnection,class,4,11,10,142,12.91,0,0,[],[],[],235,[],[],0
tests/Framework.py:BasicTestCase,BasicTestCase,class,46,219,129,2328,10.63,1,6,[],[],[],242,[],[],0
tests/Framework.py:TestCase,TestCase,class,20,61,42,747,12.25,0,3,[],[],[],331,[],[],0
tests/Framework.py:FakeHttpResponse:__init__,FakeHttpResponse:__init__,method,6,6,6,62,10.33,0,0,"['self', 'status', 'headers', 'output']","[None, None, None, None]","[None, None, None, None]",58,[],[],0
tests/Framework.py:FakeHttpResponse:getheaders,FakeHttpResponse:getheaders,method,2,2,2,20,10.0,0,0,['self'],[None],[None],63,[],[],0
tests/Framework.py:FakeHttpResponse:read,FakeHttpResponse:read,method,2,2,2,19,9.5,0,0,['self'],[None],[None],66,[],[],0
tests/Framework.py:RecordingConnection:__init__,RecordingConnection:__init__,method,11,16,16,168,10.5,0,0,"['self', 'file', 'protocol', 'host', 'port', '*args', '**kwds']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",87,[],"['isinstance', 'self._realConnection']",2
tests/Framework.py:RecordingConnection:request,RecordingConnection:request,method,5,16,16,355,22.19,0,0,"['self', 'verb', 'url', 'input', 'headers']","[None, None, None, None, None]","[None, None, None, None, None]",96,[],"['headers.copy', 'fixAuthorizationHeader', 'self.__writeLine']",3
tests/Framework.py:RecordingConnection:getresponse,RecordingConnection:getresponse,method,11,15,15,217,14.47,0,0,['self'],[None],[None],115,[],"['res.getheaders', 'res.read', 'self.__writeLine', 'FakeHttpResponse']",4
tests/Framework.py:RecordingConnection:close,RecordingConnection:close,method,3,3,3,45,15.0,0,0,['self'],[None],[None],128,[],['self.__writeLine'],1
tests/Framework.py:RecordingConnection:__writeLine,RecordingConnection:__writeLine,method,1,2,2,33,16.5,0,0,"['self', 'line']","[None, None]","[None, None]",132,[],[],0
tests/Framework.py:RecordingHttpConnection:__init__,RecordingHttpConnection:__init__,method,1,4,4,42,10.5,0,0,"['self', 'file', '*args', '**kwds']","[None, None, None, None]","[None, None, None, None]",139,[],['super'],1
tests/Framework.py:RecordingHttpsConnection:__init__,RecordingHttpsConnection:__init__,method,1,4,4,43,10.75,0,0,"['self', 'file', '*args', '**kwds']","[None, None, None, None]","[None, None, None, None]",139,[],['super'],1
tests/Framework.py:ReplayingConnection:__init__,ReplayingConnection:__init__,method,12,15,15,175,11.67,0,0,"['self', 'file', 'protocol', 'host', 'port', '*args', '**kwds']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",87,[],"['CaseInsensitiveDict', 'self._realConnection']",2
tests/Framework.py:ReplayingConnection:request,ReplayingConnection:request,method,4,14,14,195,13.93,0,0,"['self', 'verb', 'url', 'input', 'headers']","[None, None, None, None, None]","[None, None, None, None, None]",96,[],"['Url', 'httpretty.register_uri']",2
tests/Framework.py:ReplayingConnection:__readNextRequest,ReplayingConnection:__readNextRequest,method,15,39,25,540,13.85,0,2,"['self', 'verb', 'url', 'input', 'headers']","[None, None, None, None, None]","[None, None, None, None, None]",169,[],"['fixAuthorizationHeader', 'readLine', 'str', 'self.__splitUrl', 'eval', 'isinstance', 'input.replace', 'input.startswith', 'json.loads']",9
tests/Framework.py:ReplayingConnection:__splitUrl,ReplayingConnection:__splitUrl,method,5,16,13,143,8.94,0,1,"['self', 'url']","[None, None]","[None, None]",188,[],"['url.split', 'len', 'sorted']",3
tests/Framework.py:ReplayingConnection:__request_callback,ReplayingConnection:__request_callback,method,13,27,25,535,19.81,0,0,"['self', 'request', 'uri', 'response_headers']","[None, None, None, None]","[None, None, None, None]",196,[],"['self.__readNextRequest', 'int', 'CaseInsensitiveDict', 'bytearray', 'readLine', 'adding_headers.pop', 'response_headers.update']",7
tests/Framework.py:ReplayingConnection:getresponse,ReplayingConnection:getresponse,method,5,6,5,87,14.5,0,0,['self'],[None],[None],115,[],[],0
tests/Framework.py:ReplayingConnection:close,ReplayingConnection:close,method,1,1,1,18,18.0,0,0,['self'],[None],[None],128,[],[],0
tests/Framework.py:ReplayingHttpConnection:__init__,ReplayingHttpConnection:__init__,method,1,4,4,42,10.5,0,0,"['self', 'file', '*args', '**kwds']","[None, None, None, None]","[None, None, None, None]",139,[],['super'],1
tests/Framework.py:ReplayingHttpsConnection:__init__,ReplayingHttpsConnection:__init__,method,1,4,4,43,10.75,0,0,"['self', 'file', '*args', '**kwds']","[None, None, None, None]","[None, None, None, None]",139,[],['super'],1
tests/Framework.py:BasicTestCase:setUp,BasicTestCase:setUp,method,21,88,57,949,10.78,0,1,['self'],[None],[None],250,[],"['super', 'RecordingHttpConnection', 'self.__openFile', 'RecordingHttpsConnection', 'ReplayingHttpConnection', 'ReplayingHttpsConnection', 'httpretty.enable']",7
tests/Framework.py:BasicTestCase:tearDown,BasicTestCase:tearDown,method,5,5,5,141,28.2,0,0,['self'],[None],[None],287,[],"['super', 'httpretty.disable', 'httpretty.reset', 'self.__closeReplayFileIfNeeded']",4
tests/Framework.py:BasicTestCase:__openFile,BasicTestCase:__openFile,method,9,48,39,495,10.31,1,3,"['self', 'mode']","[None, None]","[None, None]",294,[],"['traceback.extract_stack', 'functionName.startswith', 'Hook', 'self.__closeReplayFileIfNeeded', 'open']",5
tests/Framework.py:BasicTestCase:__closeReplayFileIfNeeded,BasicTestCase:__closeReplayFileIfNeeded,method,3,29,26,194,6.69,0,2,['self'],[None],[None],314,[],['self.assertEqual'],1
tests/Framework.py:BasicTestCase:assertListKeyEqual,BasicTestCase:assertListKeyEqual,method,2,8,8,83,10.38,0,0,"['self', 'elements', 'key', 'expectedKeys']","[None, None, None, None]","[None, None, None, None]",322,[],['self.assertEqual'],1
tests/Framework.py:BasicTestCase:assertListKeyBegin,BasicTestCase:assertListKeyBegin,method,2,9,9,103,11.44,0,0,"['self', 'elements', 'key', 'expectedKeys']","[None, None, None, None]","[None, None, None, None]",326,[],"['len', 'self.assertEqual']",2
tests/Framework.py:TestCase:doCheckFrame,TestCase:doCheckFrame,method,5,18,12,121,6.72,0,2,"['self', 'obj', 'frame']","[None, None, None]","[None, None, None]",332,[],['self.assertEqual'],1
tests/Framework.py:TestCase:getFrameChecker,TestCase:getFrameChecker,method,6,7,7,60,8.57,0,0,['self'],[None],[None],339,[],['self.doCheckFrame'],1
tests/Framework.py:TestCase:setUp,TestCase:setUp,method,8,28,19,489,17.46,0,1,['self'],[None],[None],250,[],"['super', 'github.Github']",2
tests/Gist.py:Gist,Gist,class,25,227,142,4141,18.24,0,0,[],[],[],36,[],[],0
tests/Gist.py:Gist:testAttributes,Gist:testAttributes,method,4,96,66,2239,23.32,0,0,['self'],[None],[None],37,[],"['self.assertEqual', 'datetime.datetime', 'self.assertTrue', 'repr']",4
tests/Gist.py:Gist:testEditWithoutParameters,Gist:testEditWithoutParameters,method,4,15,15,172,11.47,0,0,['self'],[None],[None],86,[],"['gist.edit', 'self.assertEqual', 'datetime.datetime']",3
tests/Gist.py:Gist:testEditWithAllParameters,Gist:testEditWithAllParameters,method,4,29,25,348,12.0,0,0,['self'],[None],[None],92,[],"['gist.edit', 'github.InputFileContent', 'self.assertEqual', 'datetime.datetime']",4
tests/Gist.py:Gist:testDeleteFile,Gist:testDeleteFile,method,4,9,9,185,20.56,0,0,['self'],[None],[None],102,[],"['self.assertEqual', 'gist.edit']",2
tests/Gist.py:Gist:testRenameFile,Gist:testRenameFile,method,4,15,13,248,16.53,0,0,['self'],[None],[None],108,[],"['self.assertEqual', 'gist.edit', 'github.InputFileContent']",3
tests/Gist.py:Gist:testCreateComment,Gist:testCreateComment,method,5,9,9,123,13.67,0,0,['self'],[None],[None],120,[],"['gist.create_comment', 'self.assertEqual']",2
tests/Gist.py:Gist:testGetComments,Gist:testGetComments,method,3,7,7,98,14.0,0,0,['self'],[None],[None],125,[],['self.assertListKeyEqual'],1
tests/Gist.py:Gist:testStarring,Gist:testStarring,method,6,7,7,178,25.43,0,0,['self'],[None],[None],129,[],"['self.assertFalse', 'gist.set_starred', 'self.assertTrue', 'gist.reset_starred']",4
tests/Gist.py:Gist:testFork,Gist:testFork,method,6,17,16,232,13.65,0,0,['self'],[None],[None],137,[],"['gist.create_fork', 'self.assertEqual']",2
tests/Gist.py:Gist:testDelete,Gist:testDelete,method,4,9,9,185,20.56,0,0,['self'],[None],[None],145,[],"['self.assertEqual', 'gist.edit']",2
tests/GistComment.py:GistComment,GistComment,class,10,66,36,874,13.24,0,0,[],[],[],34,[],[],0
tests/GistComment.py:GistComment:setUp,GistComment:setUp,method,3,3,3,75,25.0,0,0,['self'],[None],[None],35,[],['super'],1
tests/GistComment.py:GistComment:testAttributes,GistComment:testAttributes,method,1,36,24,507,14.08,0,0,['self'],[None],[None],39,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/GistComment.py:GistComment:testEdit,GistComment:testEdit,method,2,18,15,187,10.39,0,0,['self'],[None],[None],57,[],"['self.assertEqual', 'datetime.datetime']",2
tests/GistComment.py:GistComment:testDelete,GistComment:testDelete,method,1,1,1,21,21.0,0,0,['self'],[None],[None],64,[],[],0
tests/GitBlob.py:GitBlob,GitBlob,class,6,37,29,947,25.59,0,0,[],[],[],33,[],[],0
tests/GitBlob.py:GitBlob:setUp,GitBlob:setUp,method,2,7,7,127,18.14,0,0,['self'],[None],[None],34,[],['super'],1
tests/GitBlob.py:GitBlob:testAttributes,GitBlob:testAttributes,method,2,26,20,778,29.92,0,0,['self'],[None],[None],42,[],"['self.assertTrue', 'self.assertEqual', 'repr']",3
tests/GitCommit.py:GitCommit,GitCommit,class,5,70,46,1376,19.66,0,0,[],[],[],35,[],[],0
tests/GitCommit.py:GitCommit:setUp,GitCommit:setUp,method,2,7,7,131,18.71,0,0,['self'],[None],[None],36,[],['super'],1
tests/GitCommit.py:GitCommit:testAttributes,GitCommit:testAttributes,method,1,59,37,1203,20.39,0,0,['self'],[None],[None],44,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/GithubApp.py:GithubApp,GithubApp,class,10,188,130,2464,13.11,0,0,[],[],[],28,[],[],0
tests/GithubApp.py:GithubApp:setUp,GithubApp:setUp,method,2,3,3,46,15.33,0,0,['self'],[None],[None],29,[],['super'],1
tests/GithubApp.py:GithubApp:testGetPublicApp,GithubApp:testGetPublicApp,method,5,108,93,1418,13.13,0,0,['self'],[None],[None],33,[],"['self.assertEqual', 'datetime', 'self.assertListEqual', 'self.assertDictEqual']",4
tests/GithubApp.py:GithubApp:testGetAuthenticatedApp,GithubApp:testGetAuthenticatedApp,method,5,71,57,921,12.97,0,0,['self'],[None],[None],101,[],"['self.assertEqual', 'datetime', 'self.assertListEqual', 'self.assertDictEqual']",4
tests/Github_.py:Github,Github,class,41,643,486,7596,11.81,0,0,[],[],[],40,[],[],0
tests/Github_.py:Github:testGetGists,Github:testGetGists,method,5,134,126,1492,11.13,0,0,['self'],[None],[None],41,[],"['self.assertListKeyBegin', 'testGetGistsWithSince']",2
tests/Github_.py:Github:testGetGistsWithSince,Github:testGetGistsWithSince,method,4,24,23,294,12.25,0,0,['self'],[None],[None],149,[],['self.assertListKeyBegin'],1
tests/Github_.py:Github:testGetHooks,Github:testGetHooks,method,5,25,20,323,12.92,0,0,['self'],[None],[None],166,[],['self.assertEqual'],1
tests/Github_.py:Github:testGetEmojis,Github:testGetEmojis,method,5,8,8,143,17.88,0,0,['self'],[None],[None],183,[],"['emojis.get', 'self.assertEqual']",2
tests/Github_.py:Github:testGetHook,Github:testGetHook,method,5,25,20,323,12.92,0,0,['self'],[None],[None],190,[],['self.assertEqual'],1
tests/Github_.py:Github:testGetRepoFromFullName,Github:testGetRepoFromFullName,method,1,11,11,116,10.55,0,0,['self'],[None],[None],207,[],['self.assertEqual'],1
tests/Github_.py:Github:testGetRepoFromId,Github:testGetRepoFromId,method,1,11,11,104,9.45,0,0,['self'],[None],[None],213,[],['self.assertEqual'],1
tests/Github_.py:Github:testGetGitignoreTemplates,Github:testGetGitignoreTemplates,method,1,81,81,890,10.99,0,0,['self'],[None],[None],219,[],['self.assertEqual'],1
tests/Github_.py:Github:testGetGitignoreTemplate,Github:testGetGitignoreTemplate,method,4,122,114,1655,13.57,0,0,['self'],[None],[None],302,[],"['self.assertEqual', 'testGetGitignoreTemplate']",2
tests/Github_.py:Github:testStringOfNotSet,Github:testStringOfNotSet,method,1,2,2,58,29.0,0,0,['self'],[None],[None],318,[],['self.assertEqual'],1
tests/Github_.py:Github:testGetUserById,Github:testGetUserById,method,1,2,2,63,31.5,0,0,['self'],[None],[None],321,[],['self.assertEqual'],1
tests/Github_.py:Github:testGetUsers,Github:testGetUsers,method,5,118,115,1375,11.65,0,0,['self'],[None],[None],324,[],"['self.assertListKeyBegin', 'testGetUsersSince']",2
tests/Github_.py:Github:testGetUsersSince,Github:testGetUsersSince,method,1,7,7,83,11.86,0,0,['self'],[None],[None],433,[],['self.assertListKeyBegin'],1
tests/Github_.py:Github:testGetOrganizations,Github:testGetOrganizations,method,5,33,27,392,11.88,0,0,['self'],[None],[None],438,[],"['self.assertListKeyBegin', 'testGetOrganizationsSince']",2
tests/Github_.py:Github:testGetOrganizationsSince,Github:testGetOrganizationsSince,method,4,16,16,184,11.5,0,0,['self'],[None],[None],453,[],['self.assertListKeyBegin'],1
tests/Github_.py:Github:testGetRepos,Github:testGetRepos,method,5,31,25,372,12.0,0,0,['self'],[None],[None],469,[],"['self.assertListKeyBegin', 'testGetReposSince']",2
tests/Github_.py:Github:testGetReposSince,Github:testGetReposSince,method,4,13,13,182,14.0,0,0,['self'],[None],[None],485,[],['self.assertListKeyBegin'],1
tests/Github_.py:Github:testGetLicenses,Github:testGetLicenses,method,4,46,28,319,6.93,0,0,['self'],[None],[None],498,[],['self.assertListKeyBegin'],1
tests/Github_.py:Github:testGetLicense,Github:testGetLicense,method,6,83,61,605,7.29,0,0,['self'],[None],[None],514,[],"['self.assertListKeyBegin', 'testGetLicense', 'self.assertEqual']",3
tests/Github_.py:Github:testGetEvents,Github:testGetEvents,method,3,10,10,124,12.4,0,0,['self'],[None],[None],520,[],['self.assertListKeyBegin'],1
tests/GitMembership.py:GitMembership,GitMembership,class,6,14,13,321,22.93,0,0,[],[],[],44,[],[],0
tests/GitMembership.py:GitMembership:testGetMembership,GitMembership:testGetMembership,method,5,12,11,293,24.42,0,0,['self'],[None],[None],45,[],"['self.assertEqual', 'octocat.get_organization_membership']",2
tests/GitRef.py:GitRef,GitRef,class,10,45,32,1024,22.76,0,0,[],[],[],32,[],[],0
tests/GitRef.py:GitRef:setUp,GitRef:setUp,method,2,7,7,114,16.29,0,0,['self'],[None],[None],33,[],['super'],1
tests/GitRef.py:GitRef:testAttributes,GitRef:testAttributes,method,1,24,17,655,27.29,0,0,['self'],[None],[None],41,[],"['self.assertEqual', 'repr']",2
tests/GitRef.py:GitRef:testEdit,GitRef:testEdit,method,2,5,5,154,30.8,0,0,['self'],[None],[None],64,[],['testEditWithForce'],1
tests/GitRef.py:GitRef:testEditWithForce,GitRef:testEditWithForce,method,1,2,2,68,34.0,0,0,['self'],[None],[None],67,[],[],0
tests/GitRef.py:GitRef:testDelete,GitRef:testDelete,method,1,1,1,17,17.0,0,0,['self'],[None],[None],70,[],[],0
tests/GitRelease.py:FileLikeStub,FileLikeStub,class,12,54,42,344,6.37,0,1,[],[],[],44,[],[],0
tests/GitRelease.py:GitRelease,GitRelease,class,70,326,195,5010,15.37,3,2,[],[],[],71,[],[],0
tests/GitRelease.py:FileLikeStub:__init__,FileLikeStub:__init__,method,3,25,23,133,5.32,0,0,['self'],[None],[None],45,[],['len'],1
tests/GitRelease.py:FileLikeStub:read,FileLikeStub:read,method,9,24,18,168,7.0,0,1,"['self', 'size']","[None, None]","[None, '-1']",50,[],[],0
tests/GitRelease.py:GitRelease:setUp,GitRelease:setUp,method,15,29,28,407,14.03,0,0,['self'],[None],[None],72,[],"['super', 'open', 'zip_content.write', 'zipfile.ZipFile', 'artifact.write', 'artifact.close']",6
tests/GitRelease.py:GitRelease:tearDown,GitRelease:tearDown,method,3,7,6,152,21.71,0,2,['self'],[None],[None],87,[],"['os.remove', 'super']",2
tests/GitRelease.py:GitRelease:setUpNewRelease,GitRelease:setUpNewRelease,method,8,23,21,245,10.65,0,0,['self'],[None],[None],95,[],"['repo.get_commits', 'repo.create_git_tag_and_release']",2
tests/GitRelease.py:GitRelease:tearDownNewRelease,GitRelease:tearDownNewRelease,method,6,10,10,131,13.1,0,0,['self'],[None],[None],108,[],['new_release.delete_release'],1
tests/GitRelease.py:GitRelease:testAttributes,GitRelease:testAttributes,method,4,64,44,1256,19.62,0,0,['self'],[None],[None],115,[],"['self.assertEqual', 'self.assertFalse']",2
tests/GitRelease.py:GitRelease:testGetRelease,GitRelease:testGetRelease,method,5,6,6,115,19.17,0,0,['self'],[None],[None],160,[],['self.assertEqual'],1
tests/GitRelease.py:GitRelease:testGetLatestRelease,GitRelease:testGetLatestRelease,method,3,4,4,91,22.75,0,0,['self'],[None],[None],165,[],['self.assertEqual'],1
tests/GitRelease.py:GitRelease:testGetAssets,GitRelease:testGetAssets,method,13,28,25,322,11.5,1,0,['self'],[None],[None],169,[],"['self.assertEqual', 'release.get_assets', 'self.assertTrue', 'repo.get_release_asset']",4
tests/GitRelease.py:GitRelease:testDelete,GitRelease:testDelete,method,3,3,3,82,27.33,0,0,['self'],[None],[None],183,[],"['self.setUpNewRelease', 'self.tearDownNewRelease']",2
tests/GitRelease.py:GitRelease:testUpdate,GitRelease:testUpdate,method,7,15,12,236,15.73,0,0,['self'],[None],[None],188,[],"['self.setUpNewRelease', 'release.update_release', 'self.assertEqual', 'self.tearDownNewRelease']",4
tests/GitRelease.py:GitRelease:testUploadAsset,GitRelease:testUploadAsset,method,8,27,21,442,16.37,0,0,['self'],[None],[None],196,[],"['self.setUpNewRelease', 'self.assertEqual', 'release.upload_asset', 'self.tearDownNewRelease', 'testUploadAssetWithName']",5
tests/GitRelease.py:GitRelease:testUploadAssetWithName,GitRelease:testUploadAssetWithName,method,7,12,12,205,17.08,0,0,['self'],[None],[None],206,[],"['self.setUpNewRelease', 'release.upload_asset', 'self.assertEqual', 'self.tearDownNewRelease']",4
tests/GitRelease.py:GitRelease:testCreateGitTagAndRelease,GitRelease:testCreateGitTagAndRelease,method,5,22,21,392,17.82,0,0,['self'],[None],[None],215,[],"['self.setUpNewRelease', 'self.assertEqual', 'self.tearDownNewRelease']",3
tests/GitRelease.py:GitRelease:testUploadAssetFromMemory,GitRelease:testUploadAssetFromMemory,method,14,32,32,396,12.38,1,0,['self'],[None],[None],231,[],"['self.setUpNewRelease', 'open', 'release.upload_asset_from_memory', 'release.get_assets', 'self.assertTrue', 'self.assertEqual', 'self.tearDownNewRelease']",7
tests/GitRelease.py:GitRelease:testUploadAssetFileLike,GitRelease:testUploadAssetFileLike,method,12,28,28,360,12.86,1,0,['self'],[None],[None],248,[],"['self.setUpNewRelease', 'FileLikeStub', 'release.upload_asset_from_memory', 'release.get_assets', 'self.assertTrue', 'self.assertEqual', 'self.tearDownNewRelease']",7
tests/GitTag.py:GitTag,GitTag,class,5,51,42,1047,20.53,0,0,[],[],[],35,[],[],0
tests/GitTag.py:GitTag:setUp,GitTag:setUp,method,2,7,7,125,17.86,0,0,['self'],[None],[None],36,[],['super'],1
tests/GitTag.py:GitTag:testAttributes,GitTag:testAttributes,method,1,40,33,880,22.0,0,0,['self'],[None],[None],44,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/GitTree.py:GitTree,GitTree,class,5,60,47,1515,25.25,0,0,[],[],[],33,[],[],0
tests/GitTree.py:GitTree:setUp,GitTree:setUp,method,2,7,7,127,18.14,0,0,['self'],[None],[None],34,[],['super'],1
tests/GitTree.py:GitTree:testAttributes,GitTree:testAttributes,method,1,49,38,1346,27.47,0,0,['self'],[None],[None],42,[],"['self.assertEqual', 'repr']",2
tests/Hook.py:Hook,Hook,class,16,128,76,2082,16.27,0,0,[],[],[],35,[],[],0
tests/Hook.py:Hook:setUp,Hook:setUp,method,3,3,3,81,27.0,0,0,['self'],[None],[None],36,[],['super'],1
tests/Hook.py:Hook:testAttributes,Hook:testAttributes,method,2,53,43,1047,19.75,0,0,['self'],[None],[None],40,[],"['self.assertTrue', 'self.assertEqual', 'datetime.datetime', 'repr']",4
tests/Hook.py:Hook:testEditWithMinimalParameters,Hook:testEditWithMinimalParameters,method,2,13,10,197,15.15,0,0,['self'],[None],[None],71,[],"['self.assertEqual', 'datetime.datetime']",2
tests/Hook.py:Hook:testDelete,Hook:testDelete,method,1,1,1,18,18.0,0,0,['self'],[None],[None],76,[],[],0
tests/Hook.py:Hook:testTest,Hook:testTest,method,1,9,9,50,5.56,0,0,['self'],[None],[None],79,[],[],0
tests/Hook.py:Hook:testPing,Hook:testPing,method,1,9,9,50,5.56,0,0,['self'],[None],[None],82,[],[],0
tests/Hook.py:Hook:testEditWithAllParameters,Hook:testEditWithAllParameters,method,3,26,12,457,17.58,0,0,['self'],[None],[None],85,[],"['self.assertEqual', 'self.assertTrue']",2
tests/Issue.py:Issue,Issue,class,69,509,237,7496,14.73,1,2,[],[],[],40,[],[],0
tests/Issue.py:Issue:setUp,Issue:setUp,method,5,5,5,99,19.8,0,0,['self'],[None],[None],41,[],['super'],1
tests/Issue.py:Issue:testAttributes,Issue:testAttributes,method,4,98,69,1509,15.4,0,0,['self'],[None],[None],46,[],"['self.assertEqual', 'self.assertListKeyEqual', 'datetime.datetime', 'self.assertFalse', 'self.assertIsNone', 'repr']",6
tests/Issue.py:Issue:testEditWithoutParameters,Issue:testEditWithoutParameters,method,1,1,1,17,17.0,0,0,['self'],[None],[None],90,[],[],0
tests/Issue.py:Issue:testEditWithAllParameters,Issue:testEditWithAllParameters,method,7,47,34,565,12.02,0,0,['self'],[None],[None],93,[],"['self.assertEqual', 'self.assertListKeyEqual']",2
tests/Issue.py:Issue:testEditResetMilestone,Issue:testEditResetMilestone,method,2,6,6,133,22.17,0,0,['self'],[None],[None],114,[],['self.assertEqual'],1
tests/Issue.py:Issue:testEditResetAssignee,Issue:testEditResetAssignee,method,2,5,5,128,25.6,0,0,['self'],[None],[None],119,[],['self.assertEqual'],1
tests/Issue.py:Issue:testLock,Issue:testLock,method,1,1,1,27,27.0,0,0,['self'],[None],[None],124,[],[],0
tests/Issue.py:Issue:testUnlock,Issue:testUnlock,method,1,1,1,19,19.0,0,0,['self'],[None],[None],127,[],[],0
tests/Issue.py:Issue:testCreateComment,Issue:testCreateComment,method,3,7,7,98,14.0,0,0,['self'],[None],[None],130,[],['self.assertEqual'],1
tests/Issue.py:Issue:testGetComments,Issue:testGetComments,method,5,23,19,268,11.65,0,0,['self'],[None],[None],134,[],"['self.assertListKeyEqual', 'testGetCommentsSince']",2
tests/Issue.py:Issue:testGetCommentsSince,Issue:testGetCommentsSince,method,4,13,13,138,10.62,0,0,['self'],[None],[None],139,[],['self.assertListKeyEqual'],1
tests/Issue.py:Issue:testGetEvents,Issue:testGetEvents,method,1,8,8,83,10.38,0,0,['self'],[None],[None],146,[],['self.assertListKeyEqual'],1
tests/Issue.py:Issue:testGetLabels,Issue:testGetLabels,method,4,10,10,107,10.7,0,0,['self'],[None],[None],151,[],['self.assertListKeyEqual'],1
tests/Issue.py:Issue:testAddAndRemoveAssignees,Issue:testAddAndRemoveAssignees,method,6,34,21,427,12.56,0,0,['self'],[None],[None],158,[],['self.assertListKeyEqual'],1
tests/Issue.py:Issue:testAddAndRemoveLabels,Issue:testAddAndRemoveLabels,method,10,92,27,1193,12.97,0,0,['self'],[None],[None],175,[],"['self.assertListKeyEqual', 'testAddAndRemoveLabelsWithStringArguments']",2
tests/Issue.py:Issue:testAddAndRemoveLabelsWithStringArguments,Issue:testAddAndRemoveLabelsWithStringArguments,method,8,45,23,549,12.2,0,0,['self'],[None],[None],200,[],['self.assertListKeyEqual'],1
tests/Issue.py:Issue:testDeleteAndSetLabels,Issue:testDeleteAndSetLabels,method,10,58,28,779,13.43,0,0,['self'],[None],[None],225,[],"['self.assertListKeyEqual', 'testDeleteAndSetLabelsWithStringArguments']",2
tests/Issue.py:Issue:testDeleteAndSetLabelsWithStringArguments,Issue:testDeleteAndSetLabelsWithStringArguments,method,8,28,24,342,12.21,0,0,['self'],[None],[None],240,[],['self.assertListKeyEqual'],1
tests/Issue.py:Issue:testGetReactions,Issue:testGetReactions,method,3,4,4,80,20.0,0,0,['self'],[None],[None],255,[],['self.assertEqual'],1
tests/Issue.py:Issue:testCreateReaction,Issue:testCreateReaction,method,3,6,6,128,21.33,0,0,['self'],[None],[None],259,[],['self.assertEqual'],1
tests/Issue.py:Issue:testDeleteReaction,Issue:testDeleteReaction,method,1,1,1,53,53.0,0,0,['self'],[None],[None],265,[],['self.assertTrue'],1
tests/Issue.py:Issue:testGetTimeline,Issue:testGetTimeline,method,11,64,59,1232,19.25,1,2,['self'],[None],[None],268,[],"['self.assertEqual', 'self.assertIsNone', 'self.assertIn', 'self.assertIsNotNone', 'repr']",5
tests/Issue131.py:Issue131,Issue131,class,16,37,34,544,14.7,1,1,[],[],[],29,[],[],0
tests/Issue131.py:Issue131:setUp,Issue131:setUp,method,4,5,5,117,23.4,0,0,['self'],[None],[None],30,[],['super'],1
tests/Issue131.py:Issue131:testGetPullWithOrgHeadUser,Issue131:testGetPullWithOrgHeadUser,method,3,12,12,192,16.0,0,0,['self'],[None],[None],35,[],['self.assertEqual'],1
tests/Issue131.py:Issue131:testGetPullsWithOrgHeadUser,Issue131:testGetPullsWithOrgHeadUser,method,8,14,14,142,10.14,1,1,['self'],[None],[None],41,[],"['self.assertEqual', 'self.assertTrue']",2
tests/Issue133.py:Issue133,Issue133,class,6,9,8,168,18.67,0,0,[],[],[],29,[],[],0
tests/Issue133.py:Issue133:setUp,Issue133:setUp,method,3,3,3,43,14.33,0,0,['self'],[None],[None],30,[],['super'],1
tests/Issue133.py:Issue133:testGetPageWithoutInitialArguments,Issue133:testGetPageWithoutInitialArguments,method,1,2,2,63,31.5,0,0,['self'],[None],[None],34,[],['self.assertEqual'],1
tests/Issue134.py:Issue134,Issue134,class,1,1,1,23,23.0,0,0,[],[],[],32,[],[],0
tests/Issue139.py:Issue139,Issue139,class,8,14,13,336,24.0,0,0,[],[],[],29,[],[],0
tests/Issue139.py:Issue139:setUp,Issue139:setUp,method,3,3,3,84,28.0,0,0,['self'],[None],[None],30,[],['super'],1
tests/Issue139.py:Issue139:testCompletion,Issue139:testCompletion,method,3,7,7,210,30.0,0,0,['self'],[None],[None],34,[],"['self.assertFalse', 'self.assertEqual', 'self.assertTrue']",3
tests/Issue140.py:Issue140,Issue140,class,13,64,53,881,13.77,1,1,[],[],[],29,[],[],0
tests/Issue140.py:Issue140:setUp,Issue140:setUp,method,3,3,3,62,20.67,0,0,['self'],[None],[None],30,[],['super'],1
tests/Issue140.py:Issue140:testGetDirContentsThenLazyCompletionOfFile,Issue140:testGetDirContentsThenLazyCompletionOfFile,method,6,36,30,317,8.81,1,1,['self'],[None],[None],34,[],['self.assertEqual'],1
tests/Issue140.py:Issue140:testGetFileContents,Issue140:testGetFileContents,method,3,10,10,261,26.1,0,0,['self'],[None],[None],47,[],['self.assertEqual'],1
tests/Issue140.py:Issue140:testGetDirContentsWithRef,Issue140:testGetDirContentsWithRef,method,1,7,7,103,14.71,0,0,['self'],[None],[None],56,[],"['self.assertEqual', 'len']",2
tests/Issue142.py:Issue142,Issue142,class,2,4,4,89,22.25,0,0,[],[],[],32,[],[],0
tests/Issue142.py:Issue142:testDecodeJson,Issue142:testDecodeJson,method,1,2,2,64,32.0,0,0,['self'],[None],[None],33,[],['self.assertEqual'],1
tests/Issue174.py:Issue174,Issue174,class,8,11,10,198,18.0,0,0,[],[],[],29,[],[],0
tests/Issue174.py:Issue174:setUp,Issue174:setUp,method,3,3,3,62,20.67,0,0,['self'],[None],[None],30,[],['super'],1
tests/Issue174.py:Issue174:testGetDirContentsWhithHttpRedirect,Issue174:testGetDirContentsWhithHttpRedirect,method,3,4,4,73,18.25,0,0,['self'],[None],[None],34,[],['self.assertEqual'],1
tests/Issue214.py:Issue214,Issue214,class,21,50,39,1176,23.52,1,0,[],[],[],29,[],[],0
tests/Issue214.py:Issue214:setUp,Issue214:setUp,method,5,5,5,98,19.6,0,0,['self'],[None],[None],30,[],['super'],1
tests/Issue214.py:Issue214:testAssignees,Issue214:testAssignees,method,2,2,2,105,52.5,0,0,['self'],[None],[None],35,[],"['self.assertTrue', 'self.assertFalse']",2
tests/Issue214.py:Issue214:testCollaborators,Issue214:testCollaborators,method,4,7,7,396,56.57,0,0,['self'],[None],[None],39,[],"['self.assertTrue', 'self.assertFalse']",2
tests/Issue214.py:Issue214:testEditIssue,Issue214:testEditIssue,method,2,8,7,202,25.25,0,0,['self'],[None],[None],50,[],['self.assertEqual'],1
tests/Issue214.py:Issue214:testCreateIssue,Issue214:testCreateIssue,method,3,8,8,118,14.75,0,0,['self'],[None],[None],59,[],['self.assertEqual'],1
tests/Issue214.py:Issue214:testGetIssues,Issue214:testGetIssues,method,4,8,8,110,13.75,1,0,['self'],[None],[None],63,[],['self.assertEqual'],1
tests/Issue216.py:Issue216,Issue216,class,8,11,10,202,18.36,0,0,[],[],[],30,[],[],0
tests/Issue216.py:Issue216:setUp,Issue216:setUp,method,5,5,5,119,23.8,0,0,['self'],[None],[None],31,[],['super'],1
tests/Issue216.py:Issue216:testIteration,Issue216:testIteration,method,1,2,2,42,21.0,0,0,['self'],[None],[None],36,[],['self.assertEqual'],1
tests/Issue278.py:Issue278,Issue278,class,8,11,10,202,18.36,0,0,[],[],[],29,[],[],0
tests/Issue278.py:Issue278:setUp,Issue278:setUp,method,5,5,5,119,23.8,0,0,['self'],[None],[None],30,[],['super'],1
tests/Issue278.py:Issue278:testIteration,Issue278:testIteration,method,1,2,2,42,21.0,0,0,['self'],[None],[None],35,[],['self.assertEqual'],1
tests/Issue33.py:Issue33,Issue33,class,7,13,11,280,21.54,0,0,[],[],[],31,[],[],0
tests/Issue33.py:Issue33:setUp,Issue33:setUp,method,3,3,3,86,28.67,0,0,['self'],[None],[None],32,[],['super'],1
tests/Issue33.py:Issue33:testOpenIssues,Issue33:testOpenIssues,method,1,2,2,55,27.5,0,0,['self'],[None],[None],36,[],['self.assertEqual'],1
tests/Issue33.py:Issue33:testClosedIssues,Issue33:testClosedIssues,method,1,2,2,69,34.5,0,0,['self'],[None],[None],39,[],['self.assertEqual'],1
tests/Issue494.py:Issue494,Issue494,class,9,24,23,309,12.88,0,0,[],[],[],27,[],[],0
tests/Issue494.py:Issue494:setUp,Issue494:setUp,method,5,6,6,111,18.5,0,0,['self'],[None],[None],28,[],['super'],1
tests/Issue494.py:Issue494:testRepr,Issue494:testRepr,method,2,14,14,162,11.57,0,0,['self'],[None],[None],33,[],['self.assertEqual'],1
tests/Issue50.py:Issue50,Issue50,class,38,114,80,1665,14.61,0,0,[],[],[],31,[],[],0
tests/Issue50.py:Issue50:setUp,Issue50:setUp,method,11,13,13,158,12.15,0,0,['self'],[None],[None],32,[],['super'],1
tests/Issue50.py:Issue50:testCreateLabel,Issue50:testCreateLabel,method,3,5,5,97,19.4,0,0,['self'],[None],[None],38,[],['self.assertEqual'],1
tests/Issue50.py:Issue50:testGetLabel,Issue50:testGetLabel,method,8,24,24,309,12.88,0,0,['self'],[None],[None],42,[],"['self.assertEqual', 'testGetLabels', 'self.assertListKeyEqual']",3
tests/Issue50.py:Issue50:testGetLabels,Issue50:testGetLabels,method,4,18,18,199,11.06,0,0,['self'],[None],[None],46,[],['self.assertListKeyEqual'],1
tests/Issue50.py:Issue50:testAddLabelToIssue,Issue50:testAddLabelToIssue,method,1,1,1,61,61.0,0,0,['self'],[None],[None],62,[],[],0
tests/Issue50.py:Issue50:testRemoveLabelFromIssue,Issue50:testRemoveLabelFromIssue,method,1,1,1,66,66.0,0,0,['self'],[None],[None],65,[],[],0
tests/Issue50.py:Issue50:testSetIssueLabels,Issue50:testSetIssueLabels,method,2,5,5,129,25.8,0,0,['self'],[None],[None],68,[],[],0
tests/Issue50.py:Issue50:testIssueLabels,Issue50:testIssueLabels,method,1,9,9,103,11.44,0,0,['self'],[None],[None],75,[],['self.assertListKeyEqual'],1
tests/Issue50.py:Issue50:testIssueGetLabels,Issue50:testIssueGetLabels,method,5,9,9,109,12.11,0,0,['self'],[None],[None],82,[],['self.assertListKeyEqual'],1
tests/Issue50.py:Issue50:testGetIssuesWithLabel,Issue50:testGetIssuesWithLabel,method,4,8,8,121,15.12,0,0,['self'],[None],[None],89,[],['self.assertListKeyEqual'],1
tests/Issue50.py:Issue50:testCreateIssueWithLabel,Issue50:testCreateIssueWithLabel,method,4,19,18,221,11.63,0,0,['self'],[None],[None],96,[],"['self.assertListKeyEqual', 'self.assertEqual']",2
tests/Issue54.py:Issue54,Issue54,class,8,37,33,386,10.43,0,0,[],[],[],33,[],[],0
tests/Issue54.py:Issue54:setUp,Issue54:setUp,method,3,3,3,64,21.33,0,0,['self'],[None],[None],34,[],['super'],1
tests/Issue54.py:Issue54:testConversion,Issue54:testConversion,method,3,30,27,280,9.33,0,0,['self'],[None],[None],38,[],"['self.assertEqual', 'datetime.datetime']",2
tests/Issue572.py:Issue572,Issue572,class,14,25,21,466,18.64,0,0,[],[],[],28,[],[],0
tests/Issue572.py:Issue572:setUp,Issue572:setUp,method,3,3,3,64,21.33,0,0,['self'],[None],[None],29,[],['super'],1
tests/Issue572.py:Issue572:testIssueAsPullRequest,Issue572:testIssueAsPullRequest,method,6,8,8,169,21.12,0,0,['self'],[None],[None],33,[],"['issue.as_pull_request', 'self.assertEqual', 'self.assertTrue']",3
tests/Issue572.py:Issue572:testPullReqeustAsIssue,Issue572:testPullReqeustAsIssue,method,6,8,8,149,18.62,0,0,['self'],[None],[None],39,[],"['pull.as_issue', 'self.assertEqual', 'self.assertTrue']",3
tests/Issue80.py:Issue80,Issue80,class,1,1,1,23,23.0,0,0,[],[],[],33,[],[],0
tests/Issue823.py:Issue823,Issue823,class,18,29,28,616,21.24,0,0,[],[],[],29,[],[],0
tests/Issue823.py:Issue823:setUp,Issue823:setUp,method,7,7,7,147,21.0,0,0,['self'],[None],[None],30,[],['super'],1
tests/Issue823.py:Issue823:testGetPendingInvitationAttributes,Issue823:testGetPendingInvitationAttributes,method,9,18,18,407,22.61,0,0,['self'],[None],[None],36,[],['self.assertEqual'],1
tests/Issue87.py:Issue87,Issue87,class,11,67,34,720,10.75,0,0,[],[],[],31,[],[],0
tests/Issue87.py:Issue87:setUp,Issue87:setUp,method,3,3,3,64,21.33,0,0,['self'],[None],[None],32,[],['super'],1
tests/Issue87.py:Issue87:testCreateIssueWithPercentInTitle,Issue87:testCreateIssueWithPercentInTitle,method,3,14,14,109,7.79,0,0,['self'],[None],[None],36,[],['self.assertEqual'],1
tests/Issue87.py:Issue87:testCreateIssueWithPercentInBody,Issue87:testCreateIssueWithPercentInBody,method,3,11,11,105,9.55,0,0,['self'],[None],[None],42,[],['self.assertEqual'],1
tests/Issue87.py:Issue87:testCreateIssueWithEscapedPercentInTitle,Issue87:testCreateIssueWithEscapedPercentInTitle,method,3,15,15,118,7.87,0,0,['self'],[None],[None],46,[],['self.assertEqual'],1
tests/Issue87.py:Issue87:testCreateIssueWithEscapedPercentInBody,Issue87:testCreateIssueWithEscapedPercentInBody,method,3,14,14,116,8.29,0,0,['self'],[None],[None],52,[],['self.assertEqual'],1
tests/Issue937.py:Issue937,Issue937,class,12,19,18,366,19.26,0,0,[],[],[],25,[],[],0
tests/Issue937.py:Issue937:setUp,Issue937:setUp,method,5,5,5,84,16.8,0,0,['self'],[None],[None],26,[],['super'],1
tests/Issue937.py:Issue937:testCollaboratorsAffiliation,Issue937:testCollaboratorsAffiliation,method,5,10,10,226,22.6,0,0,['self'],[None],[None],31,[],"['self.assertListKeyEqual', 'self.assertRaises']",2
tests/Issue945.py:Issue945,Issue945,class,15,65,45,1495,23.0,0,0,[],[],[],26,[],[],0
tests/Issue945.py:Issue945:setUp,Issue945:setUp,method,7,7,7,180,25.71,0,0,['self'],[None],[None],27,[],['super'],1
tests/Issue945.py:Issue945:testReservedPaginatedListAttributePreservation,Issue945:testReservedPaginatedListAttributePreservation,method,6,54,35,1241,22.98,0,0,['self'],[None],[None],33,[],"['self.assertEqual', 'self.assertTrue']",2
tests/IssueComment.py:IssueComment,IssueComment,class,17,89,54,1402,15.75,0,0,[],[],[],36,[],[],0
tests/IssueComment.py:IssueComment:setUp,IssueComment:setUp,method,2,5,5,106,21.2,0,0,['self'],[None],[None],37,[],['super'],1
tests/IssueComment.py:IssueComment:testAttributes,IssueComment:testAttributes,method,1,40,27,648,16.2,0,0,['self'],[None],[None],43,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/IssueComment.py:IssueComment:testEdit,IssueComment:testEdit,method,2,18,15,188,10.44,0,0,['self'],[None],[None],66,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueComment.py:IssueComment:testDelete,IssueComment:testDelete,method,1,1,1,21,21.0,0,0,['self'],[None],[None],73,[],[],0
tests/IssueComment.py:IssueComment:testGetReactions,IssueComment:testGetReactions,method,3,4,4,82,20.5,0,0,['self'],[None],[None],76,[],['self.assertEqual'],1
tests/IssueComment.py:IssueComment:testCreateReaction,IssueComment:testCreateReaction,method,3,6,6,130,21.67,0,0,['self'],[None],[None],80,[],['self.assertEqual'],1
tests/IssueComment.py:IssueComment:testDeleteReaction,IssueComment:testDeleteReaction,method,1,1,1,55,55.0,0,0,['self'],[None],[None],86,[],['self.assertTrue'],1
tests/IssueEvent.py:IssueEvent,IssueEvent,class,60,1504,841,38538,25.62,0,0,[],[],[],35,[],[],0
tests/IssueEvent.py:IssueEvent:setUp,IssueEvent:setUp,method,31,58,58,1651,28.47,0,0,['self'],[None],[None],36,[],"['super', 'repo.get_issues_event']",2
tests/IssueEvent.py:IssueEvent:testEvent_subscribed_Attributes,IssueEvent:testEvent_subscribed_Attributes,method,1,49,34,1222,24.94,0,0,['self'],[None],[None],75,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_assigned_Attributes,IssueEvent:testEvent_assigned_Attributes,method,1,49,35,1203,24.55,0,0,['self'],[None],[None],103,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_referenced_Attributes,IssueEvent:testEvent_referenced_Attributes,method,1,53,37,1359,25.64,0,0,['self'],[None],[None],131,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_closed_Attributes,IssueEvent:testEvent_closed_Attributes,method,1,47,35,1136,24.17,0,0,['self'],[None],[None],164,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_labeled_Attributes,IssueEvent:testEvent_labeled_Attributes,method,1,47,36,1161,24.7,0,0,['self'],[None],[None],190,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_mentioned_Attributes,IssueEvent:testEvent_mentioned_Attributes,method,1,49,35,1216,24.82,0,0,['self'],[None],[None],216,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_merged_Attributes,IssueEvent:testEvent_merged_Attributes,method,1,53,37,1289,24.32,0,0,['self'],[None],[None],244,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_review_requested_Attributes,IssueEvent:testEvent_review_requested_Attributes,method,1,53,36,1399,26.4,0,0,['self'],[None],[None],277,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_reopened_Attributes,IssueEvent:testEvent_reopened_Attributes,method,1,49,34,1186,24.2,0,0,['self'],[None],[None],311,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_unassigned_Attributes,IssueEvent:testEvent_unassigned_Attributes,method,1,49,32,1243,25.37,0,0,['self'],[None],[None],339,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_unlabeled_Attributes,IssueEvent:testEvent_unlabeled_Attributes,method,1,49,35,1225,25.0,0,0,['self'],[None],[None],367,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_renamed_Attributes,IssueEvent:testEvent_renamed_Attributes,method,1,70,51,1287,18.39,0,0,['self'],[None],[None],395,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_base_ref_changed_Attributes,IssueEvent:testEvent_base_ref_changed_Attributes,method,1,49,35,1361,27.78,0,0,['self'],[None],[None],429,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_head_ref_deleted_Attributes,IssueEvent:testEvent_head_ref_deleted_Attributes,method,1,49,35,1361,27.78,0,0,['self'],[None],[None],459,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_head_ref_restored_Attributes,IssueEvent:testEvent_head_ref_restored_Attributes,method,1,51,36,1385,27.16,0,0,['self'],[None],[None],489,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/IssueEvent.py:IssueEvent:testEvent_milestoned_Attributes,IssueEvent:testEvent_milestoned_Attributes,method,1,50,37,1247,24.94,0,0,['self'],[None],[None],521,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_demilestoned_Attributes,IssueEvent:testEvent_demilestoned_Attributes,method,1,50,37,1295,25.9,0,0,['self'],[None],[None],549,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_locked_Attributes,IssueEvent:testEvent_locked_Attributes,method,1,50,37,1156,23.12,0,0,['self'],[None],[None],579,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_unlocked_Attributes,IssueEvent:testEvent_unlocked_Attributes,method,1,49,35,1188,24.24,0,0,['self'],[None],[None],607,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_review_dismissed_Attributes,IssueEvent:testEvent_review_dismissed_Attributes,method,1,58,43,1447,24.95,0,0,['self'],[None],[None],635,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_review_request_removed_Attributes,IssueEvent:testEvent_review_request_removed_Attributes,method,1,57,38,1518,26.63,0,0,['self'],[None],[None],672,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/IssueEvent.py:IssueEvent:testEvent_marked_as_duplicate_Attributes,IssueEvent:testEvent_marked_as_duplicate_Attributes,method,1,51,36,1425,27.94,0,0,['self'],[None],[None],710,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/IssueEvent.py:IssueEvent:testEvent_unmarked_as_duplicate_Attributes,IssueEvent:testEvent_unmarked_as_duplicate_Attributes,method,1,53,36,1470,27.74,0,0,['self'],[None],[None],742,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/IssueEvent.py:IssueEvent:testEvent_added_to_project_Attributes,IssueEvent:testEvent_added_to_project_Attributes,method,1,49,34,1358,27.71,0,0,['self'],[None],[None],776,[],"['self.assertEqual', 'datetime.datetime']",2
tests/IssueEvent.py:IssueEvent:testEvent_moved_columns_in_project_Attributes,IssueEvent:testEvent_moved_columns_in_project_Attributes,method,1,53,35,1534,28.94,0,0,['self'],[None],[None],806,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/IssueEvent.py:IssueEvent:testEvent_removed_from_project_Attributes,IssueEvent:testEvent_removed_from_project_Attributes,method,1,51,35,1447,28.37,0,0,['self'],[None],[None],840,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/IssueEvent.py:IssueEvent:testEvent_converted_note_to_issue_Attributes,IssueEvent:testEvent_converted_note_to_issue_Attributes,method,1,53,35,1510,28.49,0,0,['self'],[None],[None],872,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/Label.py:Label,Label,class,11,42,32,843,20.07,0,0,[],[],[],33,[],[],0
tests/Label.py:Label:setUp,Label:setUp,method,3,3,3,82,27.33,0,0,['self'],[None],[None],34,[],['super'],1
tests/Label.py:Label:testAttributes,Label:testAttributes,method,2,11,11,275,25.0,0,0,['self'],[None],[None],38,[],"['self.assertEqual', 'self.assertIsNone']",2
tests/Label.py:Label:testEdit,Label:testEdit,method,2,19,17,383,20.16,0,0,['self'],[None],[None],47,[],['self.assertEqual'],1
tests/Label.py:Label:testDelete,Label:testDelete,method,1,1,1,19,19.0,0,0,['self'],[None],[None],59,[],[],0
tests/License.py:License,License,class,8,51,45,515,10.1,0,0,[],[],[],26,[],[],0
tests/License.py:License:setUp,License:setUp,method,3,3,3,54,18.0,0,0,['self'],[None],[None],27,[],['super'],1
tests/License.py:License:testAttributes,License:testAttributes,method,3,44,39,419,9.52,0,0,['self'],[None],[None],31,[],['self.assertEqual'],1
tests/Logging_.py:Logging,Logging,class,39,401,184,7573,18.89,0,0,[],[],[],35,[],[],0
tests/Logging_.py:Logging:setUp,Logging:setUp,method,4,4,4,98,24.5,0,0,['self'],[None],[None],70,[],"['super', 'self.MockLogger']",2
tests/Logging_.py:Logging:tearDown,Logging:tearDown,method,2,2,2,59,29.5,0,0,['self'],[None],[None],75,[],['super'],1
tests/Logging_.py:Logging:assertLogging,Logging:assertLogging,method,2,13,13,321,24.69,0,0,"['self', 'verb', 'url', 'requestHeaders', 'responseHeaders', 'output']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",79,[],"['self.assertEqual', 'self.assertIsNone']",2
tests/Logging_.py:Logging:testLoggingWithBasicAuthentication,Logging:testLoggingWithBasicAuthentication,method,6,78,73,1639,21.01,0,0,['self'],[None],[None],88,[],"['self.assertEqual', 'github.Github', 'self.assertLogging']",3
tests/Logging_.py:Logging:testLoggingWithOAuthAuthentication,Logging:testLoggingWithOAuthAuthentication,method,6,80,73,1502,18.77,0,0,['self'],[None],[None],117,[],"['self.assertEqual', 'github.Github', 'self.assertLogging']",3
tests/Logging_.py:Logging:testLoggingWithoutAuthentication,Logging:testLoggingWithoutAuthentication,method,6,65,60,1380,21.23,0,0,['self'],[None],[None],148,[],"['self.assertEqual', 'self.assertLogging']",2
tests/Logging_.py:Logging:testLoggingWithBaseUrl,Logging:testLoggingWithBaseUrl,method,6,69,64,1443,20.91,0,0,['self'],[None],[None],172,[],"['self.assertEqual', 'github.Github', 'self.assertLogging']",3
tests/Logging_.py:Logging:testLoggingDoesNotModifyRequestHeaders,Logging:testLoggingDoesNotModifyRequestHeaders,method,7,18,17,286,15.89,0,0,['self'],[None],[None],202,[],"['github.Github', 'self.assertEqual']",2
tests/Markdown.py:Markdown,Markdown,class,11,34,31,585,17.21,0,0,[],[],[],31,[],[],0
tests/Markdown.py:Markdown:setUp,Markdown:setUp,method,4,6,6,104,17.33,0,0,['self'],[None],[None],32,[],['super'],1
tests/Markdown.py:Markdown:testRenderMarkdown,Markdown:testRenderMarkdown,method,3,10,10,182,18.2,0,0,['self'],[None],[None],37,[],['self.assertEqual'],1
tests/Markdown.py:Markdown:testRenderGithubFlavoredMarkdown,Markdown:testRenderGithubFlavoredMarkdown,method,2,12,12,209,17.42,0,0,['self'],[None],[None],43,[],['self.assertEqual'],1
tests/Migration.py:Migration,Migration,class,15,84,56,2038,24.26,0,0,[],[],[],55,[],[],0
tests/Migration.py:Migration:setUp,Migration:setUp,method,5,5,5,88,17.6,0,0,['self'],[None],[None],56,[],['super'],1
tests/Migration.py:Migration:testAttributes,Migration:testAttributes,method,1,43,32,837,19.47,0,0,['self'],[None],[None],61,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/Migration.py:Migration:testGetArchiveUrlWhenNotExported,Migration:testGetArchiveUrlWhenNotExported,method,1,5,5,90,18.0,0,0,['self'],[None],[None],84,[],['self.assertRaises'],1
tests/Migration.py:Migration:testGetStatus,Migration:testGetStatus,method,1,2,2,56,28.0,0,0,['self'],[None],[None],89,[],['self.assertEqual'],1
tests/Migration.py:Migration:testGetArchiveUrlWhenExported,Migration:testGetArchiveUrlWhenExported,method,1,4,4,527,131.75,0,0,['self'],[None],[None],92,[],['self.assertEqual'],1
tests/Migration.py:Migration:testDelete,Migration:testDelete,method,1,2,2,46,23.0,0,0,['self'],[None],[None],98,[],['self.assertEqual'],1
tests/Migration.py:Migration:testGetArchiveUrlWhenDeleted,Migration:testGetArchiveUrlWhenDeleted,method,1,5,5,90,18.0,0,0,['self'],[None],[None],101,[],['self.assertRaises'],1
tests/Migration.py:Migration:testUnlockRepo,Migration:testUnlockRepo,method,1,2,2,64,32.0,0,0,['self'],[None],[None],106,[],['self.assertEqual'],1
tests/Milestone.py:Milestone,Milestone,class,16,113,71,1615,14.29,0,0,[],[],[],34,[],[],0
tests/Milestone.py:Milestone:setUp,Milestone:setUp,method,3,3,3,86,28.67,0,0,['self'],[None],[None],35,[],['super'],1
tests/Milestone.py:Milestone:testAttributes,Milestone:testAttributes,method,1,43,38,728,16.93,0,0,['self'],[None],[None],39,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/Milestone.py:Milestone:testEditWithMinimalParameters,Milestone:testEditWithMinimalParameters,method,2,9,7,107,11.89,0,0,['self'],[None],[None],60,[],['self.assertEqual'],1
tests/Milestone.py:Milestone:testEditWithAllParameters,Milestone:testEditWithAllParameters,method,2,35,23,392,11.2,0,0,['self'],[None],[None],64,[],"['self.assertEqual', 'datetime.datetime']",2
tests/Milestone.py:Milestone:testGetLabels,Milestone:testGetLabels,method,4,10,10,112,11.2,0,0,['self'],[None],[None],76,[],['self.assertListKeyEqual'],1
tests/Milestone.py:Milestone:testDelete,Milestone:testDelete,method,1,1,1,23,23.0,0,0,['self'],[None],[None],83,[],[],0
tests/NamedUser.py:NamedUser,NamedUser,class,56,581,332,9063,15.6,0,0,[],[],[],37,[],[],0
tests/NamedUser.py:NamedUser:setUp,NamedUser:setUp,method,3,3,3,53,17.67,0,0,['self'],[None],[None],38,[],['super'],1
tests/NamedUser.py:NamedUser:testAttributesOfOtherUser,NamedUser:testAttributesOfOtherUser,method,4,70,60,1632,23.31,0,0,['self'],[None],[None],42,[],"['self.assertEqual', 'datetime.datetime', 'self.assertFalse']",3
tests/NamedUser.py:NamedUser:testAttributesOfSelf,NamedUser:testAttributesOfSelf,method,3,80,73,1854,23.18,0,0,['self'],[None],[None],79,[],"['self.assertEqual', 'datetime.datetime', 'self.assertFalse', 'self.assertIsNone']",4
tests/NamedUser.py:NamedUser:testGetGists,NamedUser:testGetGists,method,7,50,43,397,7.94,0,0,['self'],[None],[None],119,[],['self.assertListKeyEqual'],1
tests/NamedUser.py:NamedUser:testGetFollowers,NamedUser:testGetFollowers,method,4,21,21,224,10.67,0,0,['self'],[None],[None],136,[],['self.assertListKeyEqual'],1
tests/NamedUser.py:NamedUser:testGetFollowing,NamedUser:testGetFollowing,method,4,32,32,339,10.59,0,0,['self'],[None],[None],157,[],['self.assertListKeyEqual'],1
tests/NamedUser.py:NamedUser:testHasInFollowing,NamedUser:testHasInFollowing,method,3,3,3,78,26.0,0,0,['self'],[None],[None],189,[],['self.assertTrue'],1
tests/NamedUser.py:NamedUser:testGetOrgs,NamedUser:testGetOrgs,method,1,7,7,82,11.71,0,0,['self'],[None],[None],193,[],['self.assertListKeyEqual'],1
tests/NamedUser.py:NamedUser:testGetOrganizationMembership,NamedUser:testGetOrganizationMembership,method,11,35,31,794,22.69,0,0,['self'],[None],[None],198,[],"['self.assertEqual', 'repr', 'testGetOrganizationMembershipNotMember', 'self.assertRaises']",4
tests/NamedUser.py:NamedUser:testGetOrganizationMembershipNotMember,NamedUser:testGetOrganizationMembershipNotMember,method,5,9,9,140,15.56,0,0,['self'],[None],[None],217,[],['self.assertRaises'],1
tests/NamedUser.py:NamedUser:testGetRepo,NamedUser:testGetRepo,method,7,54,45,709,13.13,0,0,['self'],[None],[None],226,[],"['self.assertEqual', 'testGetRepos', 'self.assertListKeyEqual', 'testGetReposWithAllArgs']",4
tests/NamedUser.py:NamedUser:testGetRepos,NamedUser:testGetRepos,method,5,41,34,575,14.02,0,0,['self'],[None],[None],232,[],"['self.assertListKeyEqual', 'testGetReposWithAllArgs']",2
tests/NamedUser.py:NamedUser:testGetReposWithAllArgs,NamedUser:testGetReposWithAllArgs,method,4,20,20,293,14.65,0,0,['self'],[None],[None],251,[],['self.assertListKeyEqual'],1
tests/NamedUser.py:NamedUser:testGetWatched,NamedUser:testGetWatched,method,4,42,41,511,12.17,0,0,['self'],[None],[None],269,[],['self.assertListKeyEqual'],1
tests/NamedUser.py:NamedUser:testGetStarred,NamedUser:testGetStarred,method,4,43,42,520,12.09,0,0,['self'],[None],[None],311,[],['self.assertListKeyEqual'],1
tests/NamedUser.py:NamedUser:testGetSubscriptions,NamedUser:testGetSubscriptions,method,4,38,22,483,12.71,0,0,['self'],[None],[None],354,[],['self.assertListKeyEqual'],1
tests/NamedUser.py:NamedUser:testGetEvents,NamedUser:testGetEvents,method,3,10,10,127,12.7,0,0,['self'],[None],[None],392,[],['self.assertListKeyBegin'],1
tests/NamedUser.py:NamedUser:testGetPublicEvents,NamedUser:testGetPublicEvents,method,3,10,10,128,12.8,0,0,['self'],[None],[None],399,[],['self.assertListKeyBegin'],1
tests/NamedUser.py:NamedUser:testGetPublicReceivedEvents,NamedUser:testGetPublicReceivedEvents,method,3,12,9,171,14.25,0,0,['self'],[None],[None],406,[],['self.assertListKeyBegin'],1
tests/NamedUser.py:NamedUser:testGetReceivedEvents,NamedUser:testGetReceivedEvents,method,3,12,9,164,13.67,0,0,['self'],[None],[None],418,[],['self.assertListKeyBegin'],1
tests/NamedUser.py:NamedUser:testGetKeys,NamedUser:testGetKeys,method,4,11,11,105,9.55,0,0,['self'],[None],[None],430,[],['self.assertListKeyEqual'],1
tests/NamedUser.py:NamedUser:testUserEquality,NamedUser:testUserEquality,method,5,10,8,147,14.7,0,0,['self'],[None],[None],437,[],"['self.assertTrue', 'self.assertEqual', 'u2.__hash__']",3
tests/NamedUser1430.py:NamedUser1430,NamedUser1430,class,8,14,13,181,12.93,0,0,[],[],[],26,[],[],0
tests/NamedUser1430.py:NamedUser1430:setUp,NamedUser1430:setUp,method,3,3,3,50,16.67,0,0,['self'],[None],[None],27,[],['super'],1
tests/NamedUser1430.py:NamedUser1430:testGetProjects,NamedUser1430:testGetProjects,method,3,7,7,88,12.57,0,0,['self'],[None],[None],31,[],['self.assertListKeyBegin'],1
tests/Notification.py:Notification,Notification,class,6,8,7,148,18.5,0,0,[],[],[],32,[],[],0
tests/Notification.py:Notification:setUp,Notification:setUp,method,3,3,3,74,24.67,0,0,['self'],[None],[None],33,[],['super'],1
tests/Notification.py:Notification:testMarkAsRead,Notification:testMarkAsRead,method,1,1,1,32,32.0,0,0,['self'],[None],[None],37,[],[],0
tests/Organization.py:Organization,Organization,class,87,664,363,11172,16.83,0,0,[],[],[],42,[],[],0
tests/Organization.py:Organization:setUp,Organization:setUp,method,3,3,3,66,22.0,0,0,['self'],[None],[None],43,[],['super'],1
tests/Organization.py:Organization:testAttributes,Organization:testAttributes,method,3,85,71,1995,23.47,0,0,['self'],[None],[None],47,[],"['self.assertEqual', 'datetime.datetime', 'self.assertTrue', 'self.assertFalse']",4
tests/Organization.py:Organization:testAddMembersDefaultRole,Organization:testAddMembersDefaultRole,method,5,8,7,261,32.62,0,0,['self'],[None],[None],92,[],['self.assertFalse'],1
tests/Organization.py:Organization:testAddMembersAdminRole,Organization:testAddMembersAdminRole,method,5,8,7,260,32.5,0,0,['self'],[None],[None],101,[],['self.assertFalse'],1
tests/Organization.py:Organization:testEditWithoutArguments,Organization:testEditWithoutArguments,method,1,1,1,15,15.0,0,0,['self'],[None],[None],110,[],[],0
tests/Organization.py:Organization:testEditWithAllArguments,Organization:testEditWithAllArguments,method,2,47,22,693,14.74,0,0,['self'],[None],[None],113,[],['self.assertEqual'],1
tests/Organization.py:Organization:testEditHookWithMinimalParameters,Organization:testEditHookWithMinimalParameters,method,4,11,9,167,15.18,0,0,['self'],[None],[None],131,[],['self.assertEqual'],1
tests/Organization.py:Organization:testEditHookWithAllParameters,Organization:testEditHookWithAllParameters,method,4,23,20,276,12.0,0,0,['self'],[None],[None],136,[],['self.assertEqual'],1
tests/Organization.py:Organization:testCreateTeam,Organization:testCreateTeam,method,6,35,23,386,11.03,0,0,['self'],[None],[None],147,[],"['self.assertEqual', 'testCreateTeamWithAllArguments']",2
tests/Organization.py:Organization:testCreateTeamWithAllArguments,Organization:testCreateTeamWithAllArguments,method,5,26,18,261,10.04,0,0,['self'],[None],[None],151,[],['self.assertEqual'],1
tests/Organization.py:Organization:testDeleteHook,Organization:testDeleteHook,method,3,5,5,90,18.0,0,0,['self'],[None],[None],163,[],[],0
tests/Organization.py:Organization:testPublicMembers,Organization:testPublicMembers,method,6,7,7,278,39.71,0,0,['self'],[None],[None],167,[],"['self.assertFalse', 'self.assertTrue']",2
tests/Organization.py:Organization:testGetPublicMembers,Organization:testGetPublicMembers,method,1,7,7,85,12.14,0,0,['self'],[None],[None],175,[],['self.assertListKeyEqual'],1
tests/Organization.py:Organization:testGetHook,Organization:testGetHook,method,5,11,11,155,14.09,0,0,['self'],[None],[None],180,[],"['self.assertEqual', 'testGetHooks', 'self.assertListKeyEqual']",3
tests/Organization.py:Organization:testGetHooks,Organization:testGetHooks,method,1,5,5,67,13.4,0,0,['self'],[None],[None],184,[],['self.assertListKeyEqual'],1
tests/Organization.py:Organization:testGetIssues,Organization:testGetIssues,method,5,32,28,365,11.41,0,0,['self'],[None],[None],187,[],"['self.assertListKeyEqual', 'testGetIssuesWithAllArguments', 'datetime.datetime']",3
tests/Organization.py:Organization:testGetIssuesWithAllArguments,Organization:testGetIssuesWithAllArguments,method,4,25,24,262,10.48,0,0,['self'],[None],[None],190,[],"['datetime.datetime', 'self.assertListKeyEqual']",2
tests/Organization.py:Organization:testGetMembers,Organization:testGetMembers,method,1,9,9,96,10.67,0,0,['self'],[None],[None],204,[],['self.assertListKeyEqual'],1
tests/Organization.py:Organization:testGetOutsideCollaborators,Organization:testGetOutsideCollaborators,method,1,7,7,91,13.0,0,0,['self'],[None],[None],209,[],['self.assertListKeyEqual'],1
tests/Organization.py:Organization:testOutsideCollaborators,Organization:testOutsideCollaborators,method,6,13,13,286,22.0,0,0,['self'],[None],[None],214,[],"['self.assertListKeyEqual', 'self.assertEqual']",2
tests/Organization.py:Organization:testMembers,Organization:testMembers,method,5,5,5,163,32.6,0,0,['self'],[None],[None],223,[],"['self.assertTrue', 'self.assertFalse']",2
tests/Organization.py:Organization:testGetRepos,Organization:testGetRepos,method,5,59,31,674,11.42,0,0,['self'],[None],[None],229,[],"['self.assertListKeyEqual', 'testGetReposSorted', 'testGetReposWithType']",3
tests/Organization.py:Organization:testGetReposSorted,Organization:testGetReposSorted,method,3,19,15,209,11.0,0,0,['self'],[None],[None],237,[],['self.assertListKeyEqual'],1
tests/Organization.py:Organization:testGetReposWithType,Organization:testGetReposWithType,method,3,14,11,171,12.21,0,0,['self'],[None],[None],250,[],['self.assertListKeyEqual'],1
tests/Organization.py:Organization:testGetEvents,Organization:testGetEvents,method,3,34,12,432,12.71,0,0,['self'],[None],[None],255,[],['self.assertListKeyEqual'],1
tests/Organization.py:Organization:testGetTeams,Organization:testGetTeams,method,1,8,8,83,10.38,0,0,['self'],[None],[None],289,[],['self.assertListKeyEqual'],1
tests/Organization.py:Organization:testGetTeamBySlug,Organization:testGetTeamBySlug,method,3,4,4,74,18.5,0,0,['self'],[None],[None],294,[],['self.assertEqual'],1
tests/Organization.py:Organization:testCreateHookWithMinimalParameters,Organization:testCreateHookWithMinimalParameters,method,3,6,6,93,15.5,0,0,['self'],[None],[None],298,[],['self.assertEqual'],1
tests/Organization.py:Organization:testCreateHookWithAllParameters,Organization:testCreateHookWithAllParameters,method,4,11,11,139,12.64,0,0,['self'],[None],[None],302,[],"['self.assertTrue', 'self.assertEqual']",2
tests/Organization.py:Organization:testCreateRepoWithMinimalArguments,Organization:testCreateRepoWithMinimalArguments,method,4,8,8,197,24.62,0,0,['self'],[None],[None],309,[],"['self.assertEqual', 'self.assertTrue']",2
tests/Organization.py:Organization:testCreateRepoWithAllArguments,Organization:testCreateRepoWithAllArguments,method,6,27,26,516,19.11,0,0,['self'],[None],[None],317,[],"['self.assertEqual', 'self.assertFalse']",2
tests/Organization.py:Organization:testCreateRepositoryWithAutoInit,Organization:testCreateRepositoryWithAutoInit,method,4,12,11,242,20.17,0,0,['self'],[None],[None],340,[],"['self.assertEqual', 'self.assertTrue']",2
tests/Organization.py:Organization:testCreateFork,Organization:testCreateFork,method,6,10,10,242,24.2,0,0,['self'],[None],[None],350,[],"['self.assertEqual', 'self.assertFalse']",2
tests/Organization.py:Organization:testInviteUserWithNeither,Organization:testInviteUserWithNeither,method,4,13,13,145,11.15,0,0,['self'],[None],[None],359,[],"['self.assertRaises', 'self.assertEqual', 'str']",3
tests/Organization.py:Organization:testInviteUserWithBoth,Organization:testInviteUserWithBoth,method,6,16,16,207,12.94,0,0,['self'],[None],[None],364,[],"['self.assertRaises', 'self.assertEqual', 'str']",3
tests/Organization.py:Organization:testInviteUserByName,Organization:testInviteUserByName,method,3,3,3,72,24.0,0,0,['self'],[None],[None],370,[],[],0
tests/Organization.py:Organization:testInviteUserByEmail,Organization:testInviteUserByEmail,method,1,1,1,45,45.0,0,0,['self'],[None],[None],374,[],[],0
tests/Organization.py:Organization:testInviteUserWithRoleAndTeam,Organization:testInviteUserWithRoleAndTeam,method,3,10,10,134,13.4,0,0,['self'],[None],[None],377,[],[],0
tests/Organization.py:Organization:testInviteUserAsNonOwner,Organization:testInviteUserAsNonOwner,method,4,27,24,370,13.7,0,0,['self'],[None],[None],383,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Organization.py:Organization:testCreateMigration,Organization:testCreateMigration,method,3,8,8,163,20.38,0,0,['self'],[None],[None],395,[],"['self.assertTrue', 'isinstance']",2
tests/Organization.py:Organization:testGetMigrations,Organization:testGetMigrations,method,3,4,4,117,29.25,0,0,['self'],[None],[None],403,[],['self.assertEqual'],1
tests/Organization.py:Organization:testGetInstallations,Organization:testGetInstallations,method,3,12,12,287,23.92,0,0,['self'],[None],[None],407,[],['self.assertEqual'],1
tests/Organization1437.py:Organization1437,Organization1437,class,8,16,15,214,13.38,0,0,[],[],[],26,[],[],0
tests/Organization1437.py:Organization1437:setUp,Organization1437:setUp,method,3,3,3,69,23.0,0,0,['self'],[None],[None],27,[],['super'],1
tests/Organization1437.py:Organization1437:testCreateProject,Organization1437:testCreateProject,method,3,9,9,100,11.11,0,0,['self'],[None],[None],31,[],['self.assertEqual'],1
tests/OrganizationHasInMembers.py:OrganizationHasInMembers,OrganizationHasInMembers,class,10,12,11,240,20.0,0,0,[],[],[],27,[],[],0
tests/OrganizationHasInMembers.py:OrganizationHasInMembers:setUp,OrganizationHasInMembers:setUp,method,7,7,7,160,22.86,0,0,['self'],[None],[None],28,[],['super'],1
tests/OrganizationHasInMembers.py:OrganizationHasInMembers:testHasInMembers,OrganizationHasInMembers:testHasInMembers,method,1,1,1,36,36.0,0,0,['self'],[None],[None],34,[],['self.assertTrue'],1
tests/PaginatedList.py:PaginatedList,PaginatedList,class,51,409,248,4778,11.68,3,2,[],[],[],35,[],[],0
tests/PaginatedList.py:PaginatedList:setUp,PaginatedList:setUp,method,5,5,5,119,23.8,0,0,['self'],[None],[None],36,[],['super'],1
tests/PaginatedList.py:PaginatedList:testIteration,PaginatedList:testIteration,method,1,2,2,42,21.0,0,0,['self'],[None],[None],41,[],['self.assertEqual'],1
tests/PaginatedList.py:PaginatedList:testSeveralIterations,PaginatedList:testSeveralIterations,method,1,8,3,171,21.38,0,0,['self'],[None],[None],44,[],['self.assertEqual'],1
tests/PaginatedList.py:PaginatedList:testIntIndexingInFirstPage,PaginatedList:testIntIndexingInFirstPage,method,1,4,4,84,21.0,0,0,['self'],[None],[None],50,[],['self.assertEqual'],1
tests/PaginatedList.py:PaginatedList:testReversedIterationWithSinglePage,PaginatedList:testReversedIterationWithSinglePage,method,3,6,6,88,14.67,0,0,['self'],[None],[None],54,[],['self.assertEqual'],1
tests/PaginatedList.py:PaginatedList:testReversedIterationWithMultiplePages,PaginatedList:testReversedIterationWithMultiplePages,method,3,12,12,187,15.58,0,0,['self'],[None],[None],59,[],['self.assertEqual'],1
tests/PaginatedList.py:PaginatedList:testReversedIterationSupportsIterator,PaginatedList:testReversedIterationSupportsIterator,method,6,11,11,94,8.55,1,0,['self'],[None],[None],67,[],"['self.assertEqual', 'self.fail']",2
tests/PaginatedList.py:PaginatedList:testGettingTheReversedListDoesNotModifyTheOriginalList,PaginatedList:testGettingTheReversedListDoesNotModifyTheOriginalList,method,3,14,10,261,18.64,0,0,['self'],[None],[None],74,[],['self.assertEqual'],1
tests/PaginatedList.py:PaginatedList:testIntIndexingInThirdPage,PaginatedList:testIntIndexingInThirdPage,method,1,4,4,85,21.25,0,0,['self'],[None],[None],83,[],['self.assertEqual'],1
tests/PaginatedList.py:PaginatedList:testGetFirstPage,PaginatedList:testGetFirstPage,method,4,33,33,293,8.88,0,0,['self'],[None],[None],87,[],['self.assertListKeyEqual'],1
tests/PaginatedList.py:PaginatedList:testGetThirdPage,PaginatedList:testGetThirdPage,method,4,33,33,293,8.88,0,0,['self'],[None],[None],120,[],['self.assertListKeyEqual'],1
tests/PaginatedList.py:PaginatedList:testIntIndexingAfterIteration,PaginatedList:testIntIndexingAfterIteration,method,1,8,8,170,21.25,0,0,['self'],[None],[None],153,[],['self.assertEqual'],1
tests/PaginatedList.py:PaginatedList:testSliceIndexingInFirstPage,PaginatedList:testSliceIndexingInFirstPage,method,1,50,37,447,8.94,0,0,['self'],[None],[None],159,[],['self.assertListKeyEqual'],1
tests/PaginatedList.py:PaginatedList:testSliceIndexingUntilFourthPage,PaginatedList:testSliceIndexingUntilFourthPage,method,1,40,29,360,9.0,0,0,['self'],[None],[None],191,[],['self.assertListKeyEqual'],1
tests/PaginatedList.py:PaginatedList:testSliceIndexingUntilEnd,PaginatedList:testSliceIndexingUntilEnd,method,1,45,41,364,8.09,0,0,['self'],[None],[None],219,[],['self.assertListKeyEqual'],1
tests/PaginatedList.py:PaginatedList:testInterruptedIteration,PaginatedList:testInterruptedIteration,method,9,44,23,231,5.25,2,2,['self'],[None],[None],255,[],['testInterruptedIterationInSlice'],1
tests/PaginatedList.py:PaginatedList:testInterruptedIterationInSlice,PaginatedList:testInterruptedIterationInSlice,method,7,21,19,97,4.62,1,1,['self'],[None],[None],263,[],[],0
tests/PaginatedList.py:PaginatedList:testTotalCountWithNoLastPage,PaginatedList:testTotalCountWithNoLastPage,method,3,4,4,61,15.25,0,0,['self'],[None],[None],271,[],['self.assertEqual'],1
tests/PaginatedList.py:PaginatedList:testCustomPerPage,PaginatedList:testCustomPerPage,method,8,46,37,672,14.61,0,0,['self'],[None],[None],276,[],"['self.assertEqual', 'testCustomPerPageWithNoUrlParams', 'PaginatedListImpl', 'testCustomPerPageWithNoUrlParams2', 'testCustomPerPageWithGetPage']",5
tests/PaginatedList.py:PaginatedList:testCustomPerPageWithNoUrlParams,PaginatedList:testCustomPerPageWithNoUrlParams,method,6,30,28,357,11.9,0,0,['self'],[None],[None],282,[],"['PaginatedListImpl', 'testCustomPerPageWithNoUrlParams2', 'self.assertEqual']",3
tests/PaginatedList.py:PaginatedList:testCustomPerPageWithNoUrlParams2,PaginatedList:testCustomPerPageWithNoUrlParams2,method,2,4,4,77,19.25,0,0,['self'],[None],[None],295,[],['self.assertEqual'],1
tests/PaginatedList.py:PaginatedList:testCustomPerPageWithGetPage,PaginatedList:testCustomPerPageWithGetPage,method,2,4,4,81,20.25,0,0,['self'],[None],[None],302,[],['self.assertEqual'],1
tests/PaginatedList.py:PaginatedList:testNoFirstPage,PaginatedList:testNoFirstPage,method,1,2,2,44,22.0,0,0,['self'],[None],[None],306,[],['self.assertFalse'],1
tests/Permissions.py:Permissions,Permissions,class,10,24,21,555,23.12,0,0,[],[],[],26,[],[],0
tests/Permissions.py:Permissions:setUp,Permissions:setUp,method,3,3,3,66,22.0,0,0,['self'],[None],[None],27,[],['super'],1
tests/Permissions.py:Permissions:testUserRepoPermissionAttributes,Permissions:testUserRepoPermissionAttributes,method,3,7,7,254,36.29,0,0,['self'],[None],[None],31,[],"['self.assertFalse', 'self.assertIs', 'self.assertTrue']",3
tests/Permissions.py:Permissions:testUserRepoPermissionRepresentation,Permissions:testUserRepoPermissionRepresentation,method,1,8,8,127,15.88,0,0,['self'],[None],[None],40,[],"['self.assertEqual', 'repr']",2
tests/Persistence.py:Persistence,Persistence,class,16,35,28,708,20.23,0,0,[],[],[],34,[],[],0
tests/Persistence.py:Persistence:setUp,Persistence:setUp,method,7,8,8,144,18.0,0,0,['self'],[None],[None],35,[],"['super', 'IO']",2
tests/Persistence.py:Persistence:tearDown,Persistence:tearDown,method,2,2,2,42,21.0,0,0,['self'],[None],[None],43,[],['super'],1
tests/Persistence.py:Persistence:testLoad,Persistence:testLoad,method,5,19,15,466,24.53,0,0,['self'],[None],[None],47,[],"['self.assertTrue', 'self.assertEqual', 'testLoadAndUpdate']",3
tests/Persistence.py:Persistence:testLoadAndUpdate,Persistence:testLoadAndUpdate,method,3,3,3,76,25.33,0,0,['self'],[None],[None],55,[],['self.assertTrue'],1
tests/PoolSize.py:PoolSize,PoolSize,class,12,27,21,545,20.19,0,0,[],[],[],8,[],[],0
tests/PoolSize.py:PoolSize:setUp,PoolSize:setUp,method,2,2,2,41,20.5,0,0,['self'],[None],[None],9,[],"['Framework.setPoolSize', 'super']",2
tests/PoolSize.py:PoolSize:testReturnsRepoAfterSettingPoolSize,PoolSize:testReturnsRepoAfterSettingPoolSize,method,8,21,17,441,21.0,0,0,['self'],[None],[None],13,[],"['self.assertIsInstance', 'self.assertEqual', 'testReturnsRepoAfterSettingPoolSizeHttp', 'github.Github', 'g.get_repo']",5
tests/PoolSize.py:PoolSize:testReturnsRepoAfterSettingPoolSizeHttp,PoolSize:testReturnsRepoAfterSettingPoolSizeHttp,method,6,13,13,241,18.54,0,0,['self'],[None],[None],18,[],"['github.Github', 'g.get_repo', 'self.assertIsInstance', 'self.assertEqual']",4
tests/Project.py:Project,Project,class,65,373,211,5573,14.94,5,0,[],[],[],28,[],[],0
tests/Project.py:Project:setUp,Project:setUp,method,3,3,3,64,21.33,0,0,['self'],[None],[None],29,[],['super'],1
tests/Project.py:Project:testGetProject,Project:testGetProject,method,4,10,10,171,17.1,0,0,['self'],[None],[None],33,[],['self.assertEqual'],1
tests/Project.py:Project:testGetOrganizationProjects,Project:testGetOrganizationProjects,method,8,15,15,216,14.4,1,0,['self'],[None],[None],40,[],"['org.get_projects', 'projects.append', 'self.assertEqual']",3
tests/Project.py:Project:testGetRepositoryProjects,Project:testGetRepositoryProjects,method,6,12,12,175,14.58,1,0,['self'],[None],[None],48,[],"['projects.append', 'self.assertEqual']",2
tests/Project.py:Project:testProjectAttributes,Project:testProjectAttributes,method,5,48,41,781,16.27,0,0,['self'],[None],[None],56,[],"['self.assertEqual', 'self.assertTrue']",2
tests/Project.py:Project:testProjectColumnAttributes,Project:testProjectColumnAttributes,method,6,26,26,580,22.31,0,0,['self'],[None],[None],82,[],"['proj.get_columns', 'self.assertEqual', 'self.assertTrue']",3
tests/Project.py:Project:testProjectCardAttributes,Project:testProjectCardAttributes,method,9,40,36,740,18.5,0,0,['self'],[None],[None],98,[],"['proj.get_columns', 'col.get_cards', 'self.assertEqual', 'self.assertTrue', 'self.assertFalse']",5
tests/Project.py:Project:testGetProjectCardContent,Project:testGetProjectCardContent,method,21,42,42,569,13.55,0,0,['self'],[None],[None],120,[],"['proj.get_columns', 'col.get_cards', 'pull_card.get_content', 'self.assertIsInstance', 'self.assertEqual', 'self.assertRaises', 'issue_card.get_content', 'note_card.get_content']",8
tests/Project.py:Project:testProjectCardMove,Project:testProjectCardMove,method,7,10,10,174,17.4,0,0,['self'],[None],[None],142,[],"['proj.get_columns', 'self.assertTrue']",2
tests/Project.py:Project:testProjectCardDelete,Project:testProjectCardDelete,method,7,7,7,115,16.43,0,0,['self'],[None],[None],149,[],"['proj.get_columns', 'self.assertTrue']",2
tests/Project.py:Project:testGetAllProjectCards,Project:testGetAllProjectCards,method,12,28,23,280,10.0,3,0,['self'],[None],[None],155,[],"['projects.append', 'proj.get_columns', 'col.get_cards', 'self.assertEqual']",4
tests/Project.py:Project:testCreateColumn,Project:testCreateColumn,method,5,19,14,178,9.37,0,0,['self'],[None],[None],168,[],"['project.create_column', 'self.assertEqual']",2
tests/Project.py:Project:testCreateCardWithNote,Project:testCreateCardWithNote,method,7,22,17,223,10.14,0,0,['self'],[None],[None],177,[],"['project.create_column', 'column.create_card', 'self.assertEqual']",3
tests/Project.py:Project:testCreateCardFromIssue,Project:testCreateCardFromIssue,method,9,27,20,306,11.33,0,0,['self'],[None],[None],187,[],"['project.create_column', 'column.create_card', 'self.assertEqual']",3
tests/Project.py:Project:testEditCardWithoutParameters,Project:testEditCardWithoutParameters,method,7,8,8,111,13.88,0,0,['self'],[None],[None],198,[],"['proj.get_columns', 'col.create_card', 'card.edit']",3
tests/Project.py:Project:testEditCardNote,Project:testEditCardNote,method,8,12,11,169,14.08,0,0,['self'],[None],[None],204,[],"['proj.get_columns', 'col.create_card', 'card.edit', 'self.assertEqual']",4
tests/Project.py:Project:testEditCardArchived,Project:testEditCardArchived,method,8,10,10,161,16.1,0,0,['self'],[None],[None],211,[],"['proj.get_columns', 'col.create_card', 'card.edit', 'self.assertEqual']",4
tests/Project1434.py:Project1434,Project1434,class,12,34,25,488,14.35,0,0,[],[],[],26,[],[],0
tests/Project1434.py:Project1434:setUp,Project1434:setUp,method,1,1,1,15,15.0,0,0,['self'],[None],[None],27,[],['super'],1
tests/Project1434.py:Project1434:testDelete,Project1434:testDelete,method,3,3,3,52,17.33,0,0,['self'],[None],[None],30,[],['project.delete'],1
tests/Project1434.py:Project1434:testEditWithoutParameters,Project1434:testEditWithoutParameters,method,6,7,7,112,16.0,0,0,['self'],[None],[None],34,[],"['project.edit', 'self.assertEqual']",2
tests/Project1434.py:Project1434:testEditWithAllParameters,Project1434:testEditWithAllParameters,method,4,15,13,197,13.13,0,0,['self'],[None],[None],40,[],"['project.edit', 'self.assertEqual']",2
tests/ProjectColumn.py:ProjectColumn,ProjectColumn,class,24,132,82,2746,20.8,0,0,[],[],[],26,[],[],0
tests/ProjectColumn.py:ProjectColumn:setUp,ProjectColumn:setUp,method,4,5,5,134,26.8,0,0,['self'],[None],[None],27,[],['super'],1
tests/ProjectColumn.py:ProjectColumn:testGetProjectColumn,ProjectColumn:testGetProjectColumn,method,1,38,27,692,18.21,0,0,['self'],[None],[None],32,[],"['self.assertEqual', 'datetime.datetime']",2
tests/ProjectColumn.py:ProjectColumn:testGetAllCards,ProjectColumn:testGetAllCards,method,3,16,16,335,20.94,0,0,['self'],[None],[None],59,[],['self.assertEqual'],1
tests/ProjectColumn.py:ProjectColumn:testGetArchivedCards,ProjectColumn:testGetArchivedCards,method,3,8,8,182,22.75,0,0,['self'],[None],[None],69,[],['self.assertEqual'],1
tests/ProjectColumn.py:ProjectColumn:testGetNotArchivedCards,ProjectColumn:testGetNotArchivedCards,method,3,12,12,265,22.08,0,0,['self'],[None],[None],75,[],['self.assertEqual'],1
tests/ProjectColumn.py:ProjectColumn:testGetCards,ProjectColumn:testGetCards,method,3,12,12,236,19.67,0,0,['self'],[None],[None],83,[],['self.assertEqual'],1
tests/ProjectColumn.py:ProjectColumn:testCreateCard,ProjectColumn:testCreateCard,method,3,6,6,141,23.5,0,0,['self'],[None],[None],91,[],['self.assertEqual'],1
tests/ProjectColumn.py:ProjectColumn:testDelete,ProjectColumn:testDelete,method,3,3,3,90,30.0,0,0,['self'],[None],[None],96,[],['self.assertTrue'],1
tests/ProjectColumn.py:ProjectColumn:testEdit,ProjectColumn:testEdit,method,2,5,5,164,32.8,0,0,['self'],[None],[None],100,[],['self.assertEqual'],1
tests/ProjectColumn.py:ProjectColumn:testMoveFirst,ProjectColumn:testMoveFirst,method,1,1,1,64,64.0,0,0,['self'],[None],[None],105,[],['self.assertTrue'],1
tests/ProjectColumn.py:ProjectColumn:testMoveLast,ProjectColumn:testMoveLast,method,1,1,1,63,63.0,0,0,['self'],[None],[None],108,[],['self.assertTrue'],1
tests/ProjectColumn.py:ProjectColumn:testMoveAfter,ProjectColumn:testMoveAfter,method,1,1,1,72,72.0,0,0,['self'],[None],[None],111,[],['self.assertTrue'],1
tests/PublicKey.py:PublicKey,PublicKey,class,5,30,17,775,25.83,0,0,[],[],[],33,[],[],0
tests/PublicKey.py:PublicKey:testAttributes,PublicKey:testAttributes,method,4,28,16,750,26.79,0,0,['self'],[None],[None],34,[],"['self.assertEqual', 'repr', 'testAttributes_with_int_key_id']",3
tests/PublicKey.py:PublicKey:testAttributes_with_int_key_id,PublicKey:testAttributes_with_int_key_id,method,3,13,12,352,27.08,0,0,['self'],[None],[None],45,[],"['self.assertEqual', 'repr']",2
tests/PullRequest.py:PullRequest,PullRequest,class,86,653,354,11364,17.4,0,0,[],[],[],37,[],[],0
tests/PullRequest.py:PullRequest:setUp,PullRequest:setUp,method,15,20,20,451,22.55,0,0,['self'],[None],[None],38,[],"['super', 'marco_repo.get_pull', 'flo_repo.get_pull']",3
tests/PullRequest.py:PullRequest:testAttributesIssue256,PullRequest:testAttributesIssue256,method,3,49,36,1232,25.14,0,0,['self'],[None],[None],52,[],"['self.assertEqual', 'datetime.datetime', 'self.assertFalse', 'self.assertTrue']",4
tests/PullRequest.py:PullRequest:testAttributes,PullRequest:testAttributes,method,5,184,124,3712,20.17,0,0,['self'],[None],[None],84,[],"['self.assertEqual', 'datetime.datetime', 'self.assertFalse', 'self.assertTrue', 'testAttributes', 'self.assertListKeyEqual', 'repr']",7
tests/PullRequest.py:PullRequest:testCreateComment,PullRequest:testCreateComment,method,5,14,14,201,14.36,0,0,['self'],[None],[None],150,[],['self.assertEqual'],1
tests/PullRequest.py:PullRequest:testGetComments,PullRequest:testGetComments,method,1,5,5,71,14.2,0,0,['self'],[None],[None],157,[],['self.assertListKeyEqual'],1
tests/PullRequest.py:PullRequest:testCreateIssueComment,PullRequest:testCreateIssueComment,method,3,8,7,108,13.5,0,0,['self'],[None],[None],160,[],['self.assertEqual'],1
tests/PullRequest.py:PullRequest:testGetIssueComments,PullRequest:testGetIssueComments,method,1,7,7,80,11.43,0,0,['self'],[None],[None],164,[],['self.assertListKeyEqual'],1
tests/PullRequest.py:PullRequest:testGetIssueComment,PullRequest:testGetIssueComment,method,5,17,16,218,12.82,0,0,['self'],[None],[None],169,[],"['self.assertListKeyEqual', 'testGetIssueComment', 'self.assertEqual']",3
tests/PullRequest.py:PullRequest:testGetIssueEvents,PullRequest:testGetIssueEvents,method,3,12,12,127,10.58,0,0,['self'],[None],[None],173,[],['self.assertListKeyEqual'],1
tests/PullRequest.py:PullRequest:testGetReviewComments,PullRequest:testGetReviewComments,method,5,13,12,148,11.38,0,0,['self'],[None],[None],180,[],"['datetime.datetime', 'self.assertListKeyEqual']",2
tests/PullRequest.py:PullRequest:testReviewRequests,PullRequest:testReviewRequests,method,6,30,19,510,17.0,0,0,['self'],[None],[None],185,[],"['self.assertListKeyEqual', 'self.assertEqual']",2
tests/PullRequest.py:PullRequest:testEditWithoutArguments,PullRequest:testEditWithoutArguments,method,1,1,1,16,16.0,0,0,['self'],[None],[None],201,[],[],0
tests/PullRequest.py:PullRequest:testEditWithAllArguments,PullRequest:testEditWithAllArguments,method,3,28,18,454,16.21,0,0,['self'],[None],[None],204,[],"['self.assertEqual', 'self.assertTrue']",2
tests/PullRequest.py:PullRequest:testGetCommits,PullRequest:testGetCommits,method,4,11,11,203,18.45,0,0,['self'],[None],[None],218,[],['self.assertListKeyEqual'],1
tests/PullRequest.py:PullRequest:testGetFiles,PullRequest:testGetFiles,method,4,53,53,1370,25.85,0,0,['self'],[None],[None],229,[],['self.assertListKeyEqual'],1
tests/PullRequest.py:PullRequest:testGetLabels,PullRequest:testGetLabels,method,1,8,8,86,10.75,0,0,['self'],[None],[None],282,[],['self.assertListKeyEqual'],1
tests/PullRequest.py:PullRequest:testAddAndRemoveLabels,PullRequest:testAddAndRemoveLabels,method,10,84,27,1167,13.89,0,0,['self'],[None],[None],287,[],"['self.assertListKeyEqual', 'testAddAndRemoveLabelsWithStringArguments']",2
tests/PullRequest.py:PullRequest:testAddAndRemoveLabelsWithStringArguments,PullRequest:testAddAndRemoveLabelsWithStringArguments,method,8,41,23,536,13.07,0,0,['self'],[None],[None],310,[],['self.assertListKeyEqual'],1
tests/PullRequest.py:PullRequest:testDeleteAndSetLabels,PullRequest:testDeleteAndSetLabels,method,10,56,27,787,14.05,0,0,['self'],[None],[None],333,[],"['self.assertListKeyEqual', 'testDeleteAndSetLabelsWithStringArguments']",2
tests/PullRequest.py:PullRequest:testDeleteAndSetLabelsWithStringArguments,PullRequest:testDeleteAndSetLabelsWithStringArguments,method,8,27,23,346,12.81,0,0,['self'],[None],[None],348,[],['self.assertListKeyEqual'],1
tests/PullRequest.py:PullRequest:testMerge,PullRequest:testMerge,method,12,27,27,528,19.56,0,0,['self'],[None],[None],363,[],"['self.assertFalse', 'self.assertEqual', 'self.assertTrue', 'repr', 'testMergeWithCommitMessage']",5
tests/PullRequest.py:PullRequest:testMergeWithCommitMessage,PullRequest:testMergeWithCommitMessage,method,6,8,8,99,12.38,0,0,['self'],[None],[None],375,[],[],0
tests/PullRequest.py:PullRequest:testAddAndRemoveAssignees,PullRequest:testAddAndRemoveAssignees,method,9,40,27,512,12.8,0,0,['self'],[None],[None],380,[],"['self.assertListKeyEqual', 'self.assertEqual']",2
tests/PullRequest.py:PullRequest:testUpdateBranch,PullRequest:testUpdateBranch,method,1,4,4,129,32.25,0,0,['self'],[None],[None],400,[],['self.assertTrue'],1
tests/PullRequest1168.py:PullRequest1168,PullRequest1168,class,12,39,29,512,13.13,0,0,[],[],[],26,[],[],0
tests/PullRequest1168.py:PullRequest1168:setUp,PullRequest1168:setUp,method,4,5,5,101,20.2,0,0,['self'],[None],[None],27,[],['super'],1
tests/PullRequest1168.py:PullRequest1168:testGetPullRequest,PullRequest1168:testGetPullRequest,method,3,14,14,174,12.43,0,0,['self'],[None],[None],33,[],['self.assertEqual'],1
tests/PullRequest1168.py:PullRequest1168:testGetIssue,PullRequest1168:testGetIssue,method,3,14,14,167,11.93,0,0,['self'],[None],[None],39,[],['self.assertEqual'],1
tests/PullRequest1169.py:PullRequest1169,PullRequest1169,class,10,16,15,285,17.81,0,0,[],[],[],26,[],[],0
tests/PullRequest1169.py:PullRequest1169:setUp,PullRequest1169:setUp,method,5,6,6,114,19.0,0,0,['self'],[None],[None],27,[],"['super', 'ferada_repo.get_pull']",2
tests/PullRequest1169.py:PullRequest1169:testReviewApproveWithoutBody,PullRequest1169:testReviewApproveWithoutBody,method,3,6,6,115,19.17,0,0,['self'],[None],[None],32,[],['self.assertEqual'],1
tests/PullRequest1375.py:PullRequest1375,PullRequest1375,class,23,46,38,672,14.61,0,0,[],[],[],26,[],[],0
tests/PullRequest1375.py:PullRequest1375:setUp,PullRequest1375:setUp,method,3,3,3,73,24.33,0,0,['self'],[None],[None],27,[],['super'],1
tests/PullRequest1375.py:PullRequest1375:testCreateReviewCommentReply,PullRequest1375:testCreateReviewCommentReply,method,18,39,32,543,13.92,0,0,['self'],[None],[None],31,[],['self.assertEqual'],1
tests/PullRequest1682.py:PullRequest1682,PullRequest1682,class,14,45,31,909,20.2,0,0,[],[],[],26,[],[],0
tests/PullRequest1682.py:PullRequest1682:setUp,PullRequest1682:setUp,method,3,3,3,72,24.0,0,0,['self'],[None],[None],27,[],['super'],1
tests/PullRequest1682.py:PullRequest1682:test_no_parameters,PullRequest1682:test_no_parameters,method,3,4,4,73,18.25,0,0,['self'],[None],[None],31,[],['self.assertEqual'],1
tests/PullRequest1682.py:PullRequest1682:test_object_parameters,PullRequest1682:test_object_parameters,method,7,14,13,284,20.29,0,0,['self'],[None],[None],35,[],['self.assertEqual'],1
tests/PullRequest1682.py:PullRequest1682:test_string_parameters,PullRequest1682:test_string_parameters,method,3,16,11,366,22.88,0,0,['self'],[None],[None],45,[],['self.assertEqual'],1
tests/PullRequest1684.py:PullRequest1684,PullRequest1684,class,27,79,55,1343,17.0,3,0,[],[],[],26,[],[],0
tests/PullRequest1684.py:PullRequest1684:setUp,PullRequest1684:setUp,method,5,5,5,104,20.8,0,0,['self'],[None],[None],27,[],['super'],1
tests/PullRequest1684.py:PullRequest1684:testGetRunners,PullRequest1684:testGetRunners,method,8,25,25,482,19.28,0,0,['self'],[None],[None],32,[],"['self.assertEqual', 'self.assertFalse', 'runner.labels', 'len']",4
tests/PullRequest1684.py:PullRequest1684:testDeleteRunnerObject,PullRequest1684:testDeleteRunnerObject,method,13,22,20,392,17.82,1,0,['self'],[None],[None],47,[],"['self.assertTrue', 'self.assertEqual', 'self.assertNotIn']",3
tests/PullRequest1684.py:PullRequest1684:testDeleteRunnerId,PullRequest1684:testDeleteRunnerId,method,9,19,13,259,13.63,2,0,['self'],[None],[None],60,[],"['self.assertTrue', 'self.assertNotIn']",2
tests/PullRequestComment.py:PullRequestComment,PullRequestComment,class,17,94,60,1650,17.55,0,0,[],[],[],36,[],[],0
tests/PullRequestComment.py:PullRequestComment:setUp,PullRequestComment:setUp,method,2,5,5,104,20.8,0,0,['self'],[None],[None],37,[],['super'],1
tests/PullRequestComment.py:PullRequestComment:testAttributes,PullRequestComment:testAttributes,method,1,54,35,980,18.15,0,0,['self'],[None],[None],43,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/PullRequestComment.py:PullRequestComment:testEdit,PullRequestComment:testEdit,method,2,9,7,106,11.78,0,0,['self'],[None],[None],75,[],['self.assertEqual'],1
tests/PullRequestComment.py:PullRequestComment:testDelete,PullRequestComment:testDelete,method,1,1,1,21,21.0,0,0,['self'],[None],[None],79,[],[],0
tests/PullRequestComment.py:PullRequestComment:testGetReactions,PullRequestComment:testGetReactions,method,3,4,4,82,20.5,0,0,['self'],[None],[None],82,[],['self.assertEqual'],1
tests/PullRequestComment.py:PullRequestComment:testCreateReaction,PullRequestComment:testCreateReaction,method,3,6,6,130,21.67,0,0,['self'],[None],[None],86,[],['self.assertEqual'],1
tests/PullRequestComment.py:PullRequestComment:testDeleteReaction,PullRequestComment:testDeleteReaction,method,1,1,1,55,55.0,0,0,['self'],[None],[None],92,[],['self.assertTrue'],1
tests/PullRequestFile.py:PullRequestFile,PullRequestFile,class,6,110,70,1370,12.45,0,0,[],[],[],32,[],[],0
tests/PullRequestFile.py:PullRequestFile:setUp,PullRequestFile:setUp,method,3,3,3,92,30.67,0,0,['self'],[None],[None],33,[],['super'],1
tests/PullRequestFile.py:PullRequestFile:testAttributes,PullRequestFile:testAttributes,method,1,103,65,1236,12.0,0,0,['self'],[None],[None],37,[],"['self.assertEqual', '__useAttributes', 'repr']",3
tests/PullRequestReview.py:PullRequestReview,PullRequestReview,class,23,75,63,1390,18.53,0,0,[],[],[],32,[],[],0
tests/PullRequestReview.py:PullRequestReview:setUp,PullRequestReview:setUp,method,15,19,19,342,18.0,0,0,['self'],[None],[None],33,[],['super'],1
tests/PullRequestReview.py:PullRequestReview:testDoesNotModifyPullRequest,PullRequestReview:testDoesNotModifyPullRequest,method,1,2,2,40,20.0,0,0,['self'],[None],[None],50,[],['self.assertEqual'],1
tests/PullRequestReview.py:PullRequestReview:testDismiss,PullRequestReview:testDismiss,method,4,6,6,113,18.83,0,0,['self'],[None],[None],53,[],['self.assertEqual'],1
tests/PullRequestReview.py:PullRequestReview:testAttributes,PullRequestReview:testAttributes,method,2,40,33,790,19.75,0,0,['self'],[None],[None],58,[],"['self.assertEqual', 'datetime.datetime', 'self.assertIn', 'repr']",4
tests/RateLimiting.py:RateLimiting,RateLimiting,class,7,44,34,743,16.89,0,0,[],[],[],34,[],[],0
tests/RateLimiting.py:RateLimiting:testRateLimiting,RateLimiting:testRateLimiting,method,2,9,7,189,21.0,0,0,['self'],[None],[None],35,[],['self.assertEqual'],1
tests/RateLimiting.py:RateLimiting:testResetTime,RateLimiting:testResetTime,method,1,2,2,59,29.5,0,0,['self'],[None],[None],41,[],['self.assertEqual'],1
tests/RateLimiting.py:RateLimiting:testGetRateLimit,RateLimiting:testGetRateLimit,method,3,27,23,415,15.37,0,0,['self'],[None],[None],44,[],"['self.assertEqual', 'repr', 'datetime.datetime']",3
tests/RawData.py:RawData,RawData,class,13,128,103,2392,18.69,0,0,[],[],[],31,[],[],0
tests/RawData.py:RawData:testCompletedObject,RawData:testCompletedObject,method,4,5,5,146,29.2,0,0,['self'],[None],[None],82,[],"['self.assertTrue', 'self.assertEqual']",2
tests/RawData.py:RawData:testNotYetCompletedObject,RawData:testNotYetCompletedObject,method,5,6,6,222,37.0,0,0,['self'],[None],[None],87,[],"['self.assertFalse', 'self.assertEqual', 'self.assertTrue']",3
tests/RawData.py:RawData:testNonCompletableObject,RawData:testNonCompletableObject,method,3,4,4,79,19.75,0,0,['self'],[None],[None],93,[],['self.assertEqual'],1
tests/RawData.py:RawData:testCreateObjectFromRawData,RawData:testCreateObjectFromRawData,method,3,10,10,195,19.5,0,0,['self'],[None],[None],97,[],['self.assertEqual'],1
tests/Reaction.py:Reaction,Reaction,class,7,35,30,562,16.06,0,0,[],[],[],29,[],[],0
tests/Reaction.py:Reaction:setUp,Reaction:setUp,method,2,8,8,116,14.5,0,0,['self'],[None],[None],30,[],['super'],1
tests/Reaction.py:Reaction:testAttributes,Reaction:testAttributes,method,1,20,19,356,17.8,0,0,['self'],[None],[None],39,[],"['self.assertEqual', 'datetime.datetime']",2
tests/Reaction.py:Reaction:testDelete,Reaction:testDelete,method,1,1,1,26,26.0,0,0,['self'],[None],[None],52,[],[],0
tests/ReleaseAsset.py:ReleaseAsset,ReleaseAsset,class,16,82,65,1553,18.94,0,0,[],[],[],30,[],[],0
tests/ReleaseAsset.py:ReleaseAsset:setUp,ReleaseAsset:setUp,method,5,5,5,125,25.0,0,0,['self'],[None],[None],31,[],['super'],1
tests/ReleaseAsset.py:ReleaseAsset:testAttributes,ReleaseAsset:testAttributes,method,1,52,40,982,18.88,0,0,['self'],[None],[None],36,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/ReleaseAsset.py:ReleaseAsset:testDelete,ReleaseAsset:testDelete,method,1,1,1,42,42.0,0,0,['self'],[None],[None],65,[],['self.assertTrue'],1
tests/ReleaseAsset.py:ReleaseAsset:testUpdate,ReleaseAsset:testUpdate,method,6,16,15,318,19.88,0,0,['self'],[None],[None],68,[],"['self.assertEqual', 'self.assertNotEqual']",2
tests/Repository.py:Repository,Repository,class,318,2745,1486,41768,15.22,3,3,[],[],[],57,[],[],0
tests/Repository.py:LazyRepository,LazyRepository,class,33,100,53,2187,21.87,0,0,[],[],[],1701,[],[],0
tests/Repository.py:Repository:setUp,Repository:setUp,method,5,5,5,84,16.8,0,0,['self'],[None],[None],58,[],['super'],1
tests/Repository.py:Repository:testAttributes,Repository:testAttributes,method,4,110,84,2339,21.26,0,0,['self'],[None],[None],63,[],"['self.assertEqual', 'datetime.datetime', 'self.assertFalse', 'self.assertTrue', 'self.assertIn']",5
tests/Repository.py:Repository:testEditWithoutArguments,Repository:testEditWithoutArguments,method,1,1,1,26,26.0,0,0,['self'],[None],[None],123,[],[],0
tests/Repository.py:Repository:testEditWithAllArguments,Repository:testEditWithAllArguments,method,4,51,40,903,17.71,0,0,['self'],[None],[None],126,[],"['self.assertEqual', 'self.assertFalse', 'self.assertTrue']",3
tests/Repository.py:Repository:testEditWithDefaultBranch,Repository:testEditWithDefaultBranch,method,2,6,5,148,24.67,0,0,['self'],[None],[None],156,[],['self.assertEqual'],1
tests/Repository.py:Repository:testDelete,Repository:testDelete,method,3,3,3,61,20.33,0,0,['self'],[None],[None],161,[],['repo.delete'],1
tests/Repository.py:Repository:testGetContributors,Repository:testGetContributors,method,3,9,9,111,12.33,0,0,['self'],[None],[None],165,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testCreateMilestone,Repository:testCreateMilestone,method,4,27,20,355,13.15,0,0,['self'],[None],[None],172,[],"['self.assertEqual', 'testCreateMilestoneWithMinimalArguments']",2
tests/Repository.py:Repository:testCreateMilestoneWithMinimalArguments,Repository:testCreateMilestoneWithMinimalArguments,method,3,8,8,107,13.38,0,0,['self'],[None],[None],181,[],['self.assertEqual'],1
tests/Repository.py:Repository:testCreateIssue,Repository:testCreateIssue,method,11,59,30,718,12.17,0,0,['self'],[None],[None],185,[],"['self.assertEqual', 'testCreateIssueWithAllArguments', 'testCreateIssueWithAllArgumentsStringLabel']",3
tests/Repository.py:Repository:testCreateIssueWithAllArguments,Repository:testCreateIssueWithAllArguments,method,10,50,26,587,11.74,0,0,['self'],[None],[None],189,[],"['self.assertEqual', 'testCreateIssueWithAllArgumentsStringLabel']",2
tests/Repository.py:Repository:testCreateIssueWithAllArgumentsStringLabel,Repository:testCreateIssueWithAllArgumentsStringLabel,method,7,23,20,247,10.74,0,0,['self'],[None],[None],203,[],['self.assertEqual'],1
tests/Repository.py:Repository:testCreateLabel,Repository:testCreateLabel,method,3,40,25,439,10.97,0,0,['self'],[None],[None],216,[],['self.assertEqual'],1
tests/Repository.py:Repository:testGetLabel,Repository:testGetLabel,method,3,24,17,318,13.25,0,0,['self'],[None],[None],230,[],['self.assertEqual'],1
tests/Repository.py:Repository:testCreateHookWithMinimalParameters,Repository:testCreateHookWithMinimalParameters,method,3,6,6,94,15.67,0,0,['self'],[None],[None],239,[],['self.assertEqual'],1
tests/Repository.py:Repository:testCreateHookWithAllParameters,Repository:testCreateHookWithAllParameters,method,4,13,13,144,11.08,0,0,['self'],[None],[None],243,[],"['self.assertTrue', 'self.assertEqual']",2
tests/Repository.py:Repository:testCreateGitRef,Repository:testCreateGitRef,method,3,9,9,231,25.67,0,0,['self'],[None],[None],250,[],['self.assertEqual'],1
tests/Repository.py:Repository:testCreateGitBlob,Repository:testCreateGitBlob,method,3,8,8,134,16.75,0,0,['self'],[None],[None],260,[],['self.assertEqual'],1
tests/Repository.py:Repository:testCreateGitTree,Repository:testCreateGitTree,method,9,71,36,1021,14.38,0,0,['self'],[None],[None],264,[],"['github.InputGitTreeElement', 'self.assertEqual', 'testCreateGitTreeWithBaseTree', 'testCreateGitTreeWithSha', 'testCreateGitTreeWithNullSha']",5
tests/Repository.py:Repository:testCreateGitTreeWithBaseTree,Repository:testCreateGitTreeWithBaseTree,method,6,23,21,313,13.61,0,0,['self'],[None],[None],274,[],"['github.InputGitTreeElement', 'self.assertEqual']",2
tests/Repository.py:Repository:testCreateGitTreeWithSha,Repository:testCreateGitTreeWithSha,method,3,13,12,217,16.69,0,0,['self'],[None],[None],291,[],"['github.InputGitTreeElement', 'self.assertEqual']",2
tests/Repository.py:Repository:testCreateGitTreeWithNullSha,Repository:testCreateGitTreeWithNullSha,method,3,13,12,176,13.54,0,0,['self'],[None],[None],304,[],"['github.InputGitTreeElement', 'self.assertEqual']",2
tests/Repository.py:Repository:testCreateGitCommit,Repository:testCreateGitCommit,method,9,58,35,1076,18.55,0,0,['self'],[None],[None],317,[],"['self.assertEqual', 'testCreateGitCommitWithParents', 'testCreateGitCommitWithAllArguments', 'github.InputGitAuthor']",4
tests/Repository.py:Repository:testCreateGitCommitWithParents,Repository:testCreateGitCommitWithParents,method,6,18,18,372,20.67,0,0,['self'],[None],[None],322,[],['self.assertEqual'],1
tests/Repository.py:Repository:testCreateGitCommitWithAllArguments,Repository:testCreateGitCommitWithAllArguments,method,6,25,19,402,16.08,0,0,['self'],[None],[None],333,[],"['github.InputGitAuthor', 'self.assertEqual']",2
tests/Repository.py:Repository:testCreateGitRelease,Repository:testCreateGitRelease,method,5,80,44,1071,13.39,0,0,['self'],[None],[None],348,[],"['self.assertEqual', 'testCreateGitReleaseWithAllArguments']",2
tests/Repository.py:Repository:testCreateGitReleaseWithAllArguments,Repository:testCreateGitReleaseWithAllArguments,method,4,48,38,628,13.08,0,0,['self'],[None],[None],360,[],['self.assertEqual'],1
tests/Repository.py:Repository:testCreateGitTag,Repository:testCreateGitTag,method,4,33,24,537,16.27,0,0,['self'],[None],[None],381,[],"['self.assertEqual', 'testCreateGitTagWithAllArguments', 'github.InputGitAuthor']",3
tests/Repository.py:Repository:testCreateGitTagWithAllArguments,Repository:testCreateGitTagWithAllArguments,method,3,19,19,295,15.53,0,0,['self'],[None],[None],390,[],"['github.InputGitAuthor', 'self.assertEqual']",2
tests/Repository.py:Repository:testCreateKey,Repository:testCreateKey,method,3,12,12,482,40.17,0,0,['self'],[None],[None],402,[],['self.assertEqual'],1
tests/Repository.py:Repository:testCreateSourceImport,Repository:testCreateSourceImport,method,5,35,26,922,26.34,0,0,['self'],[None],[None],409,[],"['import_repo.create_source_import', 'self.assertEqual']",2
tests/Repository.py:Repository:testCreateRepositoryDispatch,Repository:testCreateRepositoryDispatch,method,4,8,8,195,24.38,0,0,['self'],[None],[None],438,[],['self.assertTrue'],1
tests/Repository.py:Repository:testCreateSecret,Repository:testCreateSecret,method,2,4,4,174,43.5,0,0,"['self', 'encrypt']","[None, None]","[None, None]",445,[],['self.assertTrue'],1
tests/Repository.py:Repository:testDeleteSecret,Repository:testDeleteSecret,method,1,1,1,55,55.0,0,0,['self'],[None],[None],450,[],['self.assertTrue'],1
tests/Repository.py:Repository:testCollaborators,Repository:testCollaborators,method,12,31,28,637,20.55,1,1,['self'],[None],[None],453,[],"['self.assertFalse', 'self.assertTrue', 'self.assertListKeyEqual']",3
tests/Repository.py:Repository:testCollaboratorPermission,Repository:testCollaboratorPermission,method,1,2,2,75,37.5,0,0,['self'],[None],[None],468,[],['self.assertEqual'],1
tests/Repository.py:Repository:testGetPendingInvitations,Repository:testGetPendingInvitations,method,6,10,10,187,18.7,0,0,['self'],[None],[None],471,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testRemoveInvitation,Repository:testRemoveInvitation,method,1,1,1,37,37.0,0,0,['self'],[None],[None],477,[],[],0
tests/Repository.py:Repository:testCollaboratorPermissionNoPushAccess,Repository:testCollaboratorPermissionNoPushAccess,method,4,23,23,373,16.22,0,0,['self'],[None],[None],480,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Repository.py:Repository:testCompare,Repository:testCompare,method,4,59,43,1247,21.14,0,0,['self'],[None],[None],492,[],"['self.assertEqual', 'self.assertListKeyEqual']",2
tests/Repository.py:Repository:testGetComments,Repository:testGetComments,method,4,244,168,1349,5.53,0,0,['self'],[None],[None],542,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetCommits,Repository:testGetCommits,method,12,192,160,6492,33.81,0,0,['self'],[None],[None],554,[],"['self.assertListKeyBegin', 'testGetCommitsWithArguments', 'self.assertListKeyEqual', 'testGetCommitsWithSinceUntil', 'testGetCommitsWithAuthor']",5
tests/Repository.py:Repository:testGetCommitsWithArguments,Repository:testGetCommitsWithArguments,method,4,18,18,439,24.39,0,0,['self'],[None],[None],635,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetCommitsWithSinceUntil,Repository:testGetCommitsWithSinceUntil,method,5,62,61,2211,35.66,0,0,['self'],[None],[None],652,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetCommitsWithAuthor,Repository:testGetCommitsWithAuthor,method,7,25,16,444,17.76,0,0,['self'],[None],[None],710,[],['self.assertListKeyBegin'],1
tests/Repository.py:Repository:testGetDownloads,Repository:testGetDownloads,method,1,5,5,72,14.4,0,0,['self'],[None],[None],729,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetEvents,Repository:testGetEvents,method,3,14,12,163,11.64,0,0,['self'],[None],[None],732,[],['self.assertListKeyBegin'],1
tests/Repository.py:Repository:testGetForks,Repository:testGetForks,method,1,7,7,84,12.0,0,0,['self'],[None],[None],746,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testCreateFork,Repository:testCreateFork,method,1,4,4,83,20.75,0,0,['self'],[None],[None],751,[],['self.assertEqual'],1
tests/Repository.py:Repository:testGetGitRefs,Repository:testGetGitRefs,method,4,19,19,322,16.95,0,0,['self'],[None],[None],756,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetGitRef,Repository:testGetGitRef,method,10,38,32,826,21.74,0,0,['self'],[None],[None],775,[],"['self.assertListKeyEqual', 'testGetGitRef', 'self.assertTrue', 'self.assertEqual', 'testGetGitRefWithIssue102Reverted', 'self.assertFalse']",6
tests/Repository.py:Repository:testGetGitRefWithIssue102Reverted,Repository:testGetGitRefWithIssue102Reverted,method,4,10,9,276,27.6,0,0,['self'],[None],[None],782,[],"['self.assertFalse', 'self.assertEqual', 'self.assertTrue']",3
tests/Repository.py:Repository:testGetGitTreeWithRecursive,Repository:testGetGitTreeWithRecursive,method,3,7,7,180,25.71,0,0,['self'],[None],[None],792,[],['self.assertEqual'],1
tests/Repository.py:Repository:testGetHooks,Repository:testGetHooks,method,1,5,5,68,13.6,0,0,['self'],[None],[None],797,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetIssues,Repository:testGetIssues,method,13,163,89,1770,10.86,0,0,['self'],[None],[None],800,[],"['self.assertListKeyEqual', 'testGetIssuesWithArguments', 'testGetIssuesWithWildcards']",3
tests/Repository.py:Repository:testGetIssuesWithArguments,Repository:testGetIssuesWithArguments,method,11,81,57,918,11.33,0,0,['self'],[None],[None],824,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetIssuesWithWildcards,Repository:testGetIssuesWithWildcards,method,4,54,41,563,10.43,0,0,['self'],[None],[None],869,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetKeys,Repository:testGetKeys,method,1,10,10,91,9.1,0,0,['self'],[None],[None],903,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetLabels,Repository:testGetLabels,method,4,16,16,164,10.25,0,0,['self'],[None],[None],908,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetLanguages,Repository:testGetLanguages,method,1,5,5,73,14.6,0,0,['self'],[None],[None],922,[],['self.assertEqual'],1
tests/Repository.py:Repository:testGetMilestones,Repository:testGetMilestones,method,5,19,17,236,12.42,0,0,['self'],[None],[None],925,[],"['self.assertListKeyEqual', 'testGetMilestonesWithArguments']",2
tests/Repository.py:Repository:testGetMilestonesWithArguments,Repository:testGetMilestonesWithArguments,method,4,12,12,122,10.17,0,0,['self'],[None],[None],928,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetIssuesEvents,Repository:testGetIssuesEvents,method,3,11,11,130,11.82,0,0,['self'],[None],[None],935,[],['self.assertListKeyBegin'],1
tests/Repository.py:Repository:testGetNetworkEvents,Repository:testGetNetworkEvents,method,3,13,12,156,12.0,0,0,['self'],[None],[None],942,[],['self.assertListKeyBegin'],1
tests/Repository.py:Repository:testGetTeams,Repository:testGetTeams,method,3,7,7,140,20.0,0,0,['self'],[None],[None],955,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetWatchers,Repository:testGetWatchers,method,4,23,23,262,11.39,0,0,['self'],[None],[None],959,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetWorkflows,Repository:testGetWorkflows,method,3,12,12,140,11.67,0,0,['self'],[None],[None],982,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetWorkflowRuns,Repository:testGetWorkflowRuns,method,4,11,11,151,13.73,0,0,['self'],[None],[None],988,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetSourceImport,Repository:testGetSourceImport,method,5,40,32,1057,26.43,0,0,['self'],[None],[None],995,[],"['import_repo.get_source_import', 'self.assertEqual']",2
tests/Repository.py:Repository:testGetStargazers,Repository:testGetStargazers,method,10,134,114,1483,11.07,0,0,['self'],[None],[None],1026,[],"['self.assertListKeyEqual', 'testGetStargazersWithDates', 'repo.get_stargazers_with_dates', 'self.assertEqual']",4
tests/Repository.py:Repository:testGetStargazersWithDates,Repository:testGetStargazersWithDates,method,6,57,42,579,10.16,0,0,['self'],[None],[None],1101,[],"['repo.get_stargazers_with_dates', 'self.assertListKeyEqual', 'self.assertEqual']",3
tests/Repository.py:Repository:testGetSubscribers,Repository:testGetSubscribers,method,4,19,19,209,11.0,0,0,['self'],[None],[None],1118,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testCreatePull,Repository:testCreatePull,method,3,18,17,184,10.22,0,0,['self'],[None],[None],1137,[],['self.assertEqual'],1
tests/Repository.py:Repository:testCreateProject,Repository:testCreateProject,method,3,13,13,118,9.08,0,0,['self'],[None],[None],1147,[],['self.assertEqual'],1
tests/Repository.py:Repository:testCreatePullFromIssue,Repository:testCreatePullFromIssue,method,5,10,10,156,15.6,0,0,['self'],[None],[None],1153,[],['self.assertEqual'],1
tests/Repository.py:Repository:testGetPulls,Repository:testGetPulls,method,2,16,13,201,12.56,0,0,['self'],[None],[None],1160,[],"['self.assertListKeyEqual', 'testGetPullsWithArguments']",2
tests/Repository.py:Repository:testGetPullsWithArguments,Repository:testGetPullsWithArguments,method,1,9,9,95,10.56,0,0,['self'],[None],[None],1163,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testLegacySearchIssues,Repository:testLegacySearchIssues,method,4,58,49,713,12.29,0,0,['self'],[None],[None],1168,[],"['self.assertListKeyEqual', 'self.assertEqual', 'datetime.datetime']",3
tests/Repository.py:Repository:testMarkNotificationsAsRead,Repository:testMarkNotificationsAsRead,method,3,9,8,117,13.0,0,0,['self'],[None],[None],1190,[],['repo.mark_notifications_as_read'],1
tests/Repository.py:Repository:testAssignees,Repository:testAssignees,method,8,18,18,447,24.83,0,0,['self'],[None],[None],1194,[],"['self.assertTrue', 'self.assertFalse', 'self.assertListKeyEqual']",3
tests/Repository.py:Repository:testGetContents,Repository:testGetContents,method,7,41,28,742,18.1,0,0,['self'],[None],[None],1207,[],"['self.assertEqual', 'len', 'testGetContentsDir', 'self.assertTrue', 'testGetContentsDirWithSlash', 'testGetContentsWithRef']",6
tests/Repository.py:Repository:testGetContentsDir,Repository:testGetContentsDir,method,5,14,10,266,19.0,0,0,['self'],[None],[None],1213,[],"['self.assertTrue', 'self.assertEqual', 'testGetContentsDirWithSlash']",3
tests/Repository.py:Repository:testGetContentsDirWithSlash,Repository:testGetContentsDirWithSlash,method,4,6,6,114,19.0,0,0,['self'],[None],[None],1218,[],"['self.assertTrue', 'self.assertEqual']",2
tests/Repository.py:Repository:testGetContentsWithRef,Repository:testGetContentsWithRef,method,1,17,13,262,15.41,0,0,['self'],[None],[None],1223,[],"['self.assertEqual', 'len']",2
tests/Repository.py:Repository:testCreateDeployment,Repository:testCreateDeployment,method,3,16,16,317,19.81,0,0,['self'],[None],[None],1242,[],['self.assertEqual'],1
tests/Repository.py:Repository:testGetDeployments,Repository:testGetDeployments,method,3,8,8,111,13.88,0,0,['self'],[None],[None],1256,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testCreateFile,Repository:testCreateFile,method,6,26,26,360,13.85,0,0,['self'],[None],[None],1260,[],"['github.InputGitAuthor', 'self.assertEqual']",2
tests/Repository.py:Repository:testUpdateFile,Repository:testUpdateFile,method,6,29,24,413,14.24,0,0,['self'],[None],[None],1276,[],[],0
tests/Repository.py:Repository:testDeleteFile,Repository:testDeleteFile,method,4,13,13,196,15.08,0,0,['self'],[None],[None],1294,[],[],0
tests/Repository.py:Repository:testGetArchiveLink,Repository:testGetArchiveLink,method,1,18,12,511,28.39,0,0,['self'],[None],[None],1304,[],['self.assertEqual'],1
tests/Repository.py:Repository:testGetBranch,Repository:testGetBranch,method,3,4,4,117,29.25,0,0,['self'],[None],[None],1322,[],['self.assertEqual'],1
tests/Repository.py:Repository:testMergeWithoutMessage,Repository:testMergeWithoutMessage,method,3,10,10,135,13.5,0,0,['self'],[None],[None],1326,[],['self.assertEqual'],1
tests/Repository.py:Repository:testMergeWithMessage,Repository:testMergeWithMessage,method,3,16,12,163,10.19,0,0,['self'],[None],[None],1332,[],['self.assertEqual'],1
tests/Repository.py:Repository:testMergeWithNothingToDo,Repository:testMergeWithNothingToDo,method,3,12,12,120,10.0,0,0,['self'],[None],[None],1338,[],['self.assertEqual'],1
tests/Repository.py:Repository:testMergeWithConflict,Repository:testMergeWithConflict,method,4,12,12,226,18.83,0,0,['self'],[None],[None],1344,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Repository.py:Repository:testGetIssuesComments,Repository:testGetIssuesComments,method,4,152,77,1404,9.24,0,0,['self'],[None],[None],1350,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testGetPullsComments,Repository:testGetPullsComments,method,4,29,20,321,11.07,0,0,['self'],[None],[None],1492,[],['self.assertListKeyEqual'],1
tests/Repository.py:Repository:testSubscribePubSubHubbub,Repository:testSubscribePubSubHubbub,method,1,3,3,76,25.33,0,0,['self'],[None],[None],1509,[],[],0
tests/Repository.py:Repository:testBadSubscribePubSubHubbub,Repository:testBadSubscribePubSubHubbub,method,4,17,17,280,16.47,0,0,['self'],[None],[None],1512,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Repository.py:Repository:testUnsubscribePubSubHubbub,Repository:testUnsubscribePubSubHubbub,method,1,2,2,68,34.0,0,0,['self'],[None],[None],1522,[],[],0
tests/Repository.py:Repository:testStatisticsContributors,Repository:testStatisticsContributors,method,14,37,30,336,9.08,2,1,['self'],[None],[None],1525,[],"['self.assertEqual', 'datetime.datetime', 'self.assertTrue']",3
tests/Repository.py:Repository:testStatisticsCommitActivity,Repository:testStatisticsCommitActivity,method,3,18,16,193,10.72,0,0,['self'],[None],[None],1541,[],"['self.assertEqual', 'datetime.datetime']",2
tests/Repository.py:Repository:testStatisticsCodeFrequency,Repository:testStatisticsCodeFrequency,method,3,12,12,192,16.0,0,0,['self'],[None],[None],1547,[],"['self.assertEqual', 'datetime.datetime']",2
tests/Repository.py:Repository:testStatisticsParticipation,Repository:testStatisticsParticipation,method,3,116,29,460,3.97,0,0,['self'],[None],[None],1553,[],['self.assertEqual'],1
tests/Repository.py:Repository:testStatisticsPunchCard,Repository:testStatisticsPunchCard,method,3,8,8,110,13.75,0,0,['self'],[None],[None],1670,[],['self.assertEqual'],1
tests/Repository.py:Repository:testGetLicense,Repository:testGetLicense,method,1,2,2,60,30.0,0,0,['self'],[None],[None],1675,[],['self.assertEqual'],1
tests/Repository.py:Repository:testGetTopics,Repository:testGetTopics,method,4,6,6,80,13.33,0,0,['self'],[None],[None],1678,[],['self.assertIn'],1
tests/Repository.py:Repository:testReplaceTopics,Repository:testReplaceTopics,method,1,2,2,46,23.0,0,0,['self'],[None],[None],1683,[],[],0
tests/Repository.py:Repository:testGetRepositoryWith301Redirect,Repository:testGetRepositoryWith301Redirect,method,3,4,4,99,24.75,0,0,['self'],[None],[None],1686,[],['self.assertEqual'],1
tests/Repository.py:Repository:testGetMatchingRefs,Repository:testGetMatchingRefs,method,3,16,16,396,24.75,0,0,['self'],[None],[None],1690,[],['self.assertEqual'],1
tests/Repository.py:LazyRepository:setUp,LazyRepository:setUp,method,5,5,5,94,18.8,0,0,['self'],[None],[None],58,[],['super'],1
tests/Repository.py:LazyRepository:getLazyRepository,LazyRepository:getLazyRepository,method,2,3,3,53,17.67,0,0,['self'],[None],[None],1707,[],[],0
tests/Repository.py:LazyRepository:getEagerRepository,LazyRepository:getEagerRepository,method,2,3,3,54,18.0,0,0,['self'],[None],[None],1710,[],[],0
tests/Repository.py:LazyRepository:testGetIssues,LazyRepository:testGetIssues,method,9,15,15,185,12.33,0,0,['self'],[None],[None],800,[],"['self.getLazyRepository', 'lazy_repo.get_issues', 'self.getEagerRepository', 'eager_repo.get_issues', 'self.assertListKeyEqual']",5
tests/Repository.py:LazyRepository:testOwner,LazyRepository:testOwner,method,7,8,8,134,16.75,0,0,['self'],[None],[None],1720,[],"['self.getLazyRepository', 'self.getEagerRepository', 'self.assertEqual']",3
tests/Repository.py:LazyRepository:testEnableVulnerabilityAlert,LazyRepository:testEnableVulnerabilityAlert,method,5,7,6,193,27.57,0,0,['self'],[None],[None],1726,[],"['self.getLazyRepository', 'self.assertTrue', 'self.assertFalse']",3
tests/Repository.py:LazyRepository:testEnableAutomatedSecurityFixes,LazyRepository:testEnableAutomatedSecurityFixes,method,5,7,6,203,29.0,0,0,['self'],[None],[None],1733,[],"['self.getLazyRepository', 'self.assertTrue', 'self.assertFalse']",3
tests/Repository.py:LazyRepository:testDisableAutomatedSecurityFixes,LazyRepository:testDisableAutomatedSecurityFixes,method,5,7,6,205,29.29,0,0,['self'],[None],[None],1740,[],"['self.getLazyRepository', 'self.assertTrue', 'self.assertFalse']",3
tests/Repository.py:LazyRepository:testGetVulnerabilityAlert,LazyRepository:testGetVulnerabilityAlert,method,5,7,6,188,26.86,0,0,['self'],[None],[None],1747,[],"['self.getEagerRepository', 'self.assertTrue', 'self.assertFalse']",3
tests/Repository.py:LazyRepository:testDisableVulnerabilityAlert,LazyRepository:testDisableVulnerabilityAlert,method,5,7,6,195,27.86,0,0,['self'],[None],[None],1754,[],"['self.getLazyRepository', 'self.assertTrue', 'self.assertFalse']",3
tests/Repository.py:LazyRepository:testChangeAutomateFixWhenNoVulnerabilityAlert,LazyRepository:testChangeAutomateFixWhenNoVulnerabilityAlert,method,3,4,4,159,39.75,0,0,['self'],[None],[None],1761,[],"['self.getLazyRepository', 'self.assertFalse']",2
tests/Repository.py:LazyRepository:testGetVulnerabilityAlertWhenTurnedOff,LazyRepository:testGetVulnerabilityAlertWhenTurnedOff,method,3,3,3,89,29.67,0,0,['self'],[None],[None],1766,[],"['self.getEagerRepository', 'self.assertFalse']",2
tests/RepositoryKey.py:RepositoryKey,RepositoryKey,class,9,41,34,994,24.24,0,0,[],[],[],37,[],[],0
tests/RepositoryKey.py:RepositoryKey:setUp,RepositoryKey:setUp,method,3,3,3,84,28.0,0,0,['self'],[None],[None],38,[],['super'],1
tests/RepositoryKey.py:RepositoryKey:testAttributes,RepositoryKey:testAttributes,method,2,31,27,829,26.74,0,0,['self'],[None],[None],44,[],"['self.assertEqual', 'datetime.datetime', 'self.assertTrue', 'repr']",4
tests/RepositoryKey.py:RepositoryKey:testDelete,RepositoryKey:testDelete,method,1,1,1,17,17.0,0,0,['self'],[None],[None],61,[],[],0
tests/RequiredPullRequestReviews.py:RequiredPullRequestReviews,RequiredPullRequestReviews,class,10,55,40,1428,25.96,0,0,[],[],[],26,[],[],0
tests/RequiredPullRequestReviews.py:RequiredPullRequestReviews:setUp,RequiredPullRequestReviews:setUp,method,2,8,8,159,19.88,0,0,['self'],[None],[None],27,[],['super'],1
tests/RequiredPullRequestReviews.py:RequiredPullRequestReviews:testAttributes,RequiredPullRequestReviews:testAttributes,method,3,20,16,829,41.45,0,0,['self'],[None],[None],36,[],"['self.assertTrue', 'self.assertEqual', 'self.assertIs']",3
tests/RequiredPullRequestReviews.py:RequiredPullRequestReviews:testOrganizationOwnedTeam,RequiredPullRequestReviews:testOrganizationOwnedTeam,method,2,21,18,361,17.19,0,0,['self'],[None],[None],53,[],['self.assertListKeyEqual'],1
tests/RequiredStatusChecks.py:RequiredStatusChecks,RequiredStatusChecks,class,6,24,21,670,27.92,0,0,[],[],[],26,[],[],0
tests/RequiredStatusChecks.py:RequiredStatusChecks:setUp,RequiredStatusChecks:setUp,method,2,8,8,145,18.12,0,0,['self'],[None],[None],27,[],['super'],1
tests/RequiredStatusChecks.py:RequiredStatusChecks:testAttributes,RequiredStatusChecks:testAttributes,method,2,12,11,483,40.25,0,0,['self'],[None],[None],36,[],"['self.assertTrue', 'self.assertEqual']",2
tests/Retry.py:Retry,Retry,class,22,87,53,1583,18.2,3,0,[],[],[],38,[],[],0
tests/Retry.py:Retry:setUp,Retry:setUp,method,5,13,13,157,12.08,0,0,['self'],[None],[None],39,[],"['urllib3.Retry', 'Framework.enableRetry', 'super']",3
tests/Retry.py:Retry:testShouldNotRetryWhenStatusNotOnList,Retry:testShouldNotRetryWhenStatusNotOnList,method,4,5,5,124,24.8,0,0,['self'],[None],[None],49,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Retry.py:Retry:testReturnsRepoAfter3Retries,Retry:testReturnsRepoAfter3Retries,method,6,15,15,290,19.33,1,0,['self'],[None],[None],54,[],"['self.assertEqual', 'self.assertIsInstance']",2
tests/Retry.py:Retry:testReturnsRepoAfter1Retry,Retry:testReturnsRepoAfter1Retry,method,6,15,15,290,19.33,1,0,['self'],[None],[None],63,[],"['self.assertEqual', 'self.assertIsInstance']",2
tests/Retry.py:Retry:testRaisesRetryErrorAfterMaxRetries,Retry:testRaisesRetryErrorAfterMaxRetries,method,6,11,11,239,21.73,1,0,['self'],[None],[None],72,[],"['self.assertRaises', 'self.assertEqual']",2
tests/Retry.py:Retry:testReturnsRepoAfterSettingRetryHttp,Retry:testReturnsRepoAfterSettingRetryHttp,method,6,16,16,245,15.31,0,0,['self'],[None],[None],79,[],"['github.Github', 'g.get_repo', 'self.assertIsInstance', 'self.assertEqual']",4
tests/Search.py:Search,Search,class,35,293,232,4322,14.75,0,1,[],[],[],30,[],[],0
tests/Search.py:Search:setUp,Search:setUp,method,1,1,1,15,15.0,0,0,['self'],[None],[None],31,[],['super'],1
tests/Search.py:Search:testSearchUsers,Search:testSearchUsers,method,3,6,6,106,17.67,0,0,['self'],[None],[None],34,[],['self.assertEqual'],1
tests/Search.py:Search:testPaginateSearchUsers,Search:testPaginateSearchUsers,method,4,48,48,513,10.69,0,0,['self'],[None],[None],38,[],"['self.assertListKeyBegin', 'self.assertEqual']",2
tests/Search.py:Search:testGetPageOnSearchUsers,Search:testGetPageOnSearchUsers,method,3,42,42,463,11.02,0,0,['self'],[None],[None],83,[],"['self.assertEqual', 'users.get_page']",2
tests/Search.py:Search:testSearchRepos,Search:testSearchRepos,method,5,56,54,1065,19.02,0,0,['self'],[None],[None],121,[],"['self.assertListKeyBegin', 'testSearchReposWithNoResults', 'self.assertEqual']",3
tests/Search.py:Search:testSearchReposWithNoResults,Search:testSearchReposWithNoResults,method,3,4,4,85,21.25,0,0,['self'],[None],[None],167,[],['self.assertEqual'],1
tests/Search.py:Search:testSearchIssues,Search:testSearchIssues,method,3,25,25,236,9.44,0,0,['self'],[None],[None],171,[],['self.assertListKeyBegin'],1
tests/Search.py:Search:testPaginateSearchCommits,Search:testPaginateSearchCommits,method,3,6,6,125,20.83,0,0,['self'],[None],[None],192,[],['self.assertEqual'],1
tests/Search.py:Search:testSearchTopics,Search:testSearchTopics,method,3,15,15,169,11.27,0,0,['self'],[None],[None],198,[],['self.assertListKeyBegin'],1
tests/Search.py:Search:testPaginateSearchTopics,Search:testPaginateSearchTopics,method,3,5,5,93,18.6,0,0,['self'],[None],[None],206,[],['self.assertEqual'],1
tests/Search.py:Search:testSearchCode,Search:testSearchCode,method,8,38,37,726,19.11,0,1,['self'],[None],[None],210,[],"['self.assertListKeyEqual', 'self.assertEqual', 'isinstance', 'content.decode']",4
tests/Search.py:Search:testSearchHighlightingCode,Search:testSearchHighlightingCode,method,3,9,9,131,14.56,0,0,['self'],[None],[None],238,[],['self.assertTrue'],1
tests/Search.py:Search:testUrlquotingOfQualifiers,Search:testUrlquotingOfQualifiers,method,3,8,8,139,17.38,0,0,['self'],[None],[None],244,[],['self.assertEqual'],1
tests/Search.py:Search:testUrlquotingOfQuery,Search:testUrlquotingOfQuery,method,3,8,8,136,17.0,0,0,['self'],[None],[None],251,[],['self.assertEqual'],1
tests/SelfHostedActionsRunner.py:SelfHostedActionsRunner,SelfHostedActionsRunner,class,13,30,29,568,18.93,0,0,[],[],[],26,[],[],0
tests/SelfHostedActionsRunner.py:SelfHostedActionsRunner:setUp,SelfHostedActionsRunner:setUp,method,5,5,5,104,20.8,0,0,['self'],[None],[None],27,[],['super'],1
tests/SelfHostedActionsRunner.py:SelfHostedActionsRunner:testAttributes,SelfHostedActionsRunner:testAttributes,method,6,21,21,422,20.1,0,0,['self'],[None],[None],32,[],"['self.assertEqual', 'self.assertFalse', 'runner.labels', 'len']",4
tests/SourceImport.py:SourceImport,SourceImport,class,14,61,47,1632,26.75,0,0,[],[],[],26,[],[],0
tests/SourceImport.py:SourceImport:setUp,SourceImport:setUp,method,7,7,7,154,22.0,0,0,['self'],[None],[None],27,[],['super'],1
tests/SourceImport.py:SourceImport:testAttributes,SourceImport:testAttributes,method,1,43,33,1293,30.07,0,0,['self'],[None],[None],33,[],['self.assertEqual'],1
tests/SourceImport.py:SourceImport:testUpdate,SourceImport:testUpdate,method,4,5,5,121,24.2,0,0,['self'],[None],[None],67,[],"['self.assertTrue', 'self.assertEqual']",2
tests/Tag.py:Tag,Tag,class,6,26,20,544,20.92,0,0,[],[],[],32,[],[],0
tests/Tag.py:Tag:setUp,Tag:setUp,method,3,3,3,77,25.67,0,0,['self'],[None],[None],33,[],['super'],1
tests/Tag.py:Tag:testAttributes,Tag:testAttributes,method,1,19,14,425,22.37,0,0,['self'],[None],[None],37,[],"['self.assertEqual', 'repr', 'commit=Commit']",3
tests/Team.py:Team,Team,class,49,254,163,4641,18.27,0,0,[],[],[],42,[],[],0
tests/Team.py:Team:setUp,Team:setUp,method,5,5,5,102,20.4,0,0,['self'],[None],[None],43,[],['super'],1
tests/Team.py:Team:testAttributes,Team:testAttributes,method,1,29,26,514,17.72,0,0,['self'],[None],[None],48,[],"['self.assertEqual', 'repr']",2
tests/Team.py:Team:testDiscussions,Team:testDiscussions,method,4,57,48,1075,18.86,0,0,['self'],[None],[None],62,[],"['list', 'self.assertEqual', 'datetime']",3
tests/Team.py:Team:testMembers,Team:testMembers,method,10,27,23,589,21.81,0,0,['self'],[None],[None],91,[],"['self.assertListKeyEqual', 'self.assertFalse', 'self.assertTrue', 'self.assertRaises']",4
tests/Team.py:Team:testTeamMembership,Team:testTeamMembership,method,9,22,22,517,23.5,0,0,['self'],[None],[None],107,[],"['self.assertEqual', 'self.assertFalse', 'self.assertListKeyEqual', 'self.assertTrue']",4
tests/Team.py:Team:testRepoPermission,Team:testRepoPermission,method,5,7,7,169,24.14,0,0,['self'],[None],[None],121,[],"['warnings.filterwarnings', 'warnings.resetwarnings']",2
tests/Team.py:Team:testUpdateTeamRepository,Team:testUpdateTeamRepository,method,3,4,4,102,25.5,0,0,['self'],[None],[None],128,[],['self.assertTrue'],1
tests/Team.py:Team:testRepos,Team:testRepos,method,10,24,21,569,23.71,0,0,['self'],[None],[None],132,[],"['self.assertListKeyEqual', 'self.assertFalse', 'self.assertIsNone', 'self.assertTrue']",4
tests/Team.py:Team:testEditWithoutArguments,Team:testEditWithoutArguments,method,2,9,7,94,10.44,0,0,['self'],[None],[None],148,[],['self.assertEqual'],1
tests/Team.py:Team:testEditWithAllArguments,Team:testEditWithAllArguments,method,2,28,17,319,11.39,0,0,['self'],[None],[None],152,[],['self.assertEqual'],1
tests/Team.py:Team:testGetTeams,Team:testGetTeams,method,6,17,17,246,14.47,0,0,['self'],[None],[None],164,[],"['self.assertListKeyEqual', 'self.assertEqual']",2
tests/Team.py:Team:testDelete,Team:testDelete,method,1,1,1,18,18.0,0,0,['self'],[None],[None],173,[],[],0
tests/Time.py:UTCtzinfo,UTCtzinfo,class,5,15,9,109,7.27,0,0,[],[],[],26,[],[],0
tests/Time.py:UTCtzinfo:utcoffset,UTCtzinfo:utcoffset,method,2,2,2,18,9.0,0,0,"['self', 'dt']","[None, None]","[None, None]",27,[],['timedelta'],1
tests/Time.py:UTCtzinfo:tzname,UTCtzinfo:tzname,method,1,2,2,11,5.5,0,0,"['self', 'dt']","[None, None]","[None, None]",30,[],[],0
tests/Time.py:UTCtzinfo:dst,UTCtzinfo:dst,method,2,2,2,18,9.0,0,0,"['self', 'dt']","[None, None]","[None, None]",33,[],['timedelta'],1
tests/Topic.py:Topic,Topic,class,10,143,120,1606,11.23,0,0,[],[],[],30,[],[],0
tests/Topic.py:Topic:setUp,Topic:setUp,method,2,3,3,64,21.33,0,0,['self'],[None],[None],31,[],"['super', 'list']",2
tests/Topic.py:Topic:testAllFields,Topic:testAllFields,method,3,98,77,907,9.26,0,0,['self'],[None],[None],35,[],"['self.assertEqual', 'datetime']",2
tests/Topic.py:Topic:testNamesFromSearchResults,Topic:testNamesFromSearchResults,method,2,36,36,556,15.44,0,0,['self'],[None],[None],58,[],"['self.assertListKeyEqual', 'attrgetter']",2
tests/Traffic.py:Traffic,Traffic,class,24,120,87,1944,16.2,0,0,[],[],[],32,[],[],0
tests/Traffic.py:Traffic:setUp,Traffic:setUp,method,5,5,5,84,16.8,0,0,['self'],[None],[None],33,[],['super'],1
tests/Traffic.py:Traffic:testGetReferrers,Traffic:testGetReferrers,method,4,16,15,349,21.81,0,0,['self'],[None],[None],38,[],"['self.assertGreaterEqual', 'self.assertEqual', 'repr']",3
tests/Traffic.py:Traffic:testGetPaths,Traffic:testGetPaths,method,3,35,28,482,13.77,0,0,['self'],[None],[None],49,[],"['self.assertEqual', 'repr']",2
tests/Traffic.py:Traffic:testGetViews,Traffic:testGetViews,method,5,27,26,450,16.67,0,0,['self'],[None],[None],64,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/Traffic.py:Traffic:testGetClones,Traffic:testGetClones,method,5,27,24,462,17.11,0,0,['self'],[None],[None],77,[],"['self.assertEqual', 'datetime.datetime', 'repr']",3
tests/UserKey.py:UserKey,UserKey,class,9,33,27,853,25.85,0,0,[],[],[],33,[],[],0
tests/UserKey.py:UserKey:setUp,UserKey:setUp,method,3,3,3,59,19.67,0,0,['self'],[None],[None],34,[],['super'],1
tests/UserKey.py:UserKey:testAttributes,UserKey:testAttributes,method,2,23,20,713,31.0,0,0,['self'],[None],[None],38,[],"['self.assertEqual', 'self.assertTrue', 'repr']",3
tests/UserKey.py:UserKey:testDelete,UserKey:testDelete,method,1,1,1,17,17.0,0,0,['self'],[None],[None],52,[],[],0
tests/Workflow.py:Workflow,Workflow,class,32,155,102,2750,17.74,1,1,[],[],[],28,[],[],0
tests/Workflow.py:Workflow:setUp,Workflow:setUp,method,3,3,3,92,30.67,0,0,['self'],[None],[None],29,[],['super'],1
tests/Workflow.py:Workflow:testAttributes,Workflow:testAttributes,method,3,36,30,850,23.61,0,0,['self'],[None],[None],33,[],"['self.assertEqual', 'repr', 'datetime.datetime']",3
tests/Workflow.py:Workflow:testGetRunsWithNoArguments,Workflow:testGetRunsWithNoArguments,method,4,10,10,109,10.9,0,0,['self'],[None],[None],58,[],['self.assertListKeyEqual'],1
tests/Workflow.py:Workflow:testGetRunsWithObjects,Workflow:testGetRunsWithObjects,method,8,19,19,261,13.74,0,0,['self'],[None],[None],65,[],['self.assertListKeyEqual'],1
tests/Workflow.py:Workflow:testGetRunsWithStrings,Workflow:testGetRunsWithStrings,method,4,13,13,166,12.77,0,0,['self'],[None],[None],76,[],['self.assertListKeyEqual'],1
tests/Workflow.py:Workflow:testCreateDispatchWithBranch,Workflow:testCreateDispatchWithBranch,method,5,16,15,294,18.38,0,0,['self'],[None],[None],83,[],['self.assertTrue'],1
tests/Workflow.py:Workflow:testCreateDispatchWithTag,Workflow:testCreateDispatchWithTag,method,8,23,22,316,13.74,1,1,['self'],[None],[None],93,[],['self.assertTrue'],1
tests/Workflow.py:Workflow:testCreateDispatchWithString,Workflow:testCreateDispatchWithString,method,5,14,14,226,16.14,0,0,['self'],[None],[None],102,[],['self.assertTrue'],1
tests/Workflow.py:Workflow:testCreateDispatchForNonTriggerEnabled,Workflow:testCreateDispatchForNonTriggerEnabled,method,3,3,3,121,40.33,0,0,['self'],[None],[None],110,[],['self.assertFalse'],1
tests/WorkflowRun.py:WorkflowRun,WorkflowRun,class,20,115,85,2777,24.15,0,0,[],[],[],28,[],[],0
tests/WorkflowRun.py:WorkflowRun:setUp,WorkflowRun:setUp,method,5,5,5,118,23.6,0,0,['self'],[None],[None],29,[],['super'],1
tests/WorkflowRun.py:WorkflowRun:testAttributes,WorkflowRun:testAttributes,method,4,87,63,2235,25.69,0,0,['self'],[None],[None],34,[],"['self.assertEqual', 'repr', 'datetime.datetime']",3
tests/WorkflowRun.py:WorkflowRun:test_timing,WorkflowRun:test_timing,method,3,6,6,118,19.67,0,0,['self'],[None],[None],94,[],['self.assertEqual'],1
tests/WorkflowRun.py:WorkflowRun:test_rerun,WorkflowRun:test_rerun,method,5,6,6,153,25.5,0,0,['self'],[None],[None],99,[],"['self.assertTrue', 'test_rerun_with_successful_run', 'self.assertFalse']",3
tests/WorkflowRun.py:WorkflowRun:test_rerun_with_successful_run,WorkflowRun:test_rerun_with_successful_run,method,3,3,3,69,23.0,0,0,['self'],[None],[None],102,[],['self.assertFalse'],1
tests/WorkflowRun.py:WorkflowRun:test_cancel,WorkflowRun:test_cancel,method,1,1,1,43,43.0,0,0,['self'],[None],[None],106,[],['self.assertTrue'],1
uri,name,type,n_variable,n_words,n_words_unique,n_characters,avg_char_per_word,n_loop,n_ifthen,arg_name,arg_type,arg_value,line,docs,list_functions,n_functions
utilmy/dates.py:log,log,function,1,1,1,9,9.0,0,0,['*s'],[None],[None],6,[],['print'],1
utilmy/dates.py:pd_date_split,pd_date_split,function,31,153,68,1005,6.57,1,2,"['df', 'coldate ', 'prefix_col ', 'verbose']","[None, None, None, None]","[None, ""  'time_key'"", '""""', 'False']",11,[],"['df.drop_duplicates', 'pd.to_datetime', 'x.weekday', 'date_weekmonth', 'date_weekmonth2', 'x.isocalendar', 'date_weekyear2', 'df.apply', 'int', 'merge1', 'date_is_holiday', 'log']",12
utilmy/dates.py:date_now,date_now,function,14,17,15,220,12.94,0,0,"['fmt=""%Y-%m-%d %H', 'add_days', 'timezone']","['', None, None]","['""%Y-%m-%d %H:%M:%S %Z%z""', '0', ""'Asia/Tokyo'""]",41,[],"['datetime.now', 'datetime.timedelta', 'now_new.astimezone', 'now_pacific.strftime']",4
utilmy/dates.py:date_is_holiday,date_is_holiday,function,8,23,21,146,6.35,0,0,['array'],[None],[None],53,"['    """"""\n', '      is_holiday([ pd.to_datetime(""2015/1/1"") ] * 10)\n', '\n', '    """"""\n']","['holidays.CountryHoliday', 'np.array', 'x.astype']",3
utilmy/dates.py:date_weekmonth2,date_weekmonth2,function,3,17,12,51,3.0,0,1,['d'],[None],[None],63,[],[],0
utilmy/dates.py:date_weekmonth,date_weekmonth,function,4,37,18,194,5.24,0,2,['d'],[None],[None],71,[],"['date_weekmonth', 'date_value.replace']",2
utilmy/dates.py:date_weekyear2,date_weekyear2,function,1,6,6,53,8.83,0,0,['dt'],[None],[None],80,[],['datetime.datetime'],1
utilmy/dates.py:date_weekday_excel,date_weekday_excel,function,7,17,15,98,5.76,0,1,['x'],[None],[None],84,[],"['arrow.get', 'str']",2
utilmy/dates.py:date_weekyear_excel,date_weekyear_excel,function,14,47,40,302,6.43,0,1,['x'],[None],[None],91,[],"['arrow.get', 'str', 'dd.isocalendar', 'date_weekday_excel', 'int']",5
utilmy/dates.py:date_generate,date_generate,function,8,17,16,174,10.24,0,0,"['start', 'ndays']","[None, None]","[""'2018-01-01'"", '100']",110,[],"['relativedelta', 'range']",2
utilmy/decorators.py:thread_decorator,thread_decorator,function,6,14,13,185,13.21,0,0,['func'],[None],[None],11,"['    """""" A decorator to run function in background on thread\n', '\tReturn:\n', '\t\tbackground_thread: ``Thread``\n', '    """"""\n']","['wrapper', 'Thread', 'background_thread.start']",3
utilmy/decorators.py:timeout_decorator,timeout_decorator,function,11,25,21,297,11.88,0,0,"['seconds', 'error_message']","[None, None]","['10', 'os.strerror(errno.ETIME']",36,"['    """"""Decorator to throw timeout error, if function doesnt complete in certain time\n', '    Args:\n', '        seconds:``int``\n', '            No of seconds to wait\n', '        error_message:``str``\n', '            Error message\n', '            \n', '    """"""\n']","['decorator', '_handle_timeout', '_TimeoutError', 'wrapper', 'signal.signal', 'signal.alarm', 'func', 'wraps']",8
utilmy/decorators.py:timer_decorator,timer_decorator,function,8,22,20,208,9.45,0,0,['func'],[None],[None],63,"['    """"""\n', '    Decorator to show the execution time of a function or a method in a class.\n', '    """"""\n']","['wrapper', 'time.perf_counter', 'func', 'print']",4
utilmy/decorators.py:profiler_context,profiler_context,function,9,20,20,191,9.55,0,0,[],[],[],81,"['    """"""\n', ""    Context Manager the will profile code inside it's bloc.\n"", '    And print the result of profiler.\n', '    Example:\n', '        with profiler_context():\n', '            # code to profile here\n', '    """"""\n']","['Profiler', 'profiler.start', 'profiler.stop', 'print']",4
utilmy/decorators.py:profiler_decorator,profiler_decorator,function,26,45,39,511,11.36,0,0,['func'],[None],[None],101,"['    """"""\n', '    A decorator that will profile a function\n', '    And print the result of profiler.\n', '    """"""\n']","['wrapper', 'Profiler', 'profiler.start', 'func', 'profiler.stop', 'print', 'profiler_decorator_base', 'inner', 'cProfile.Profile', 'pr.enable', 'fnc', 'pr.disable', 'io.StringIO', 'pstats.Stats', 'ps.print_stats']",15
utilmy/decorators.py:profiler_decorator_base,profiler_decorator_base,function,15,23,22,245,10.65,0,0,['fnc'],[None],[None],119,"['    """"""\n', '    A decorator that uses cProfile to profile a function\n', '    And print the result\n', '    """"""\n']","['inner', 'cProfile.Profile', 'pr.enable', 'fnc', 'pr.disable', 'io.StringIO', 'pstats.Stats', 'ps.print_stats', 'print']",9
utilmy/decorators.py:_TimeoutError,_TimeoutError,class,0,1,1,4,4.0,0,0,[],[],[],30,[],[],0
utilmy/deeplearning.py:tensorboard_log,tensorboard_log,function,23,58,46,498,8.59,2,4,"['pars_dict', 'writer', 'verbose']","['dict', None, None]","['None', 'None', 'True']",6,"['    """"""\n', '    #### Usage 1 \n', ""    logdir = 'logs/params'\n"", '\n', '    from tensorboardX import SummaryWriter\n', '    # from tensorboard import SummaryWriter\n', '    tb_writer = SummaryWriter(logdir)\n', '    tensorboard_log(cc, writer= tb_writer)\n', '\n', '    %reload_ext tensorboard\n', '    %tensorboard --logdir logs/params/\n', '    """"""\n']","['dict_flatten', 'd.items', 'isinstance', 'items.extend', 'items.append', 'dict', 'print', 'flatten_box.items', 'writer.add_scalar', 'writer.add_text', 'str', 'writer.close']",12
utilmy/distributed.py:log_mem,log_mem,function,3,9,9,76,8.44,0,0,['*s'],[None],[None],11,[],"['log2', 'str']",2
utilmy/distributed.py:date_now,date_now,function,11,14,12,174,12.43,0,0,"['fmt = ""%Y-%m-%d %H']",[''],"[' ""%Y-%m-%d %H:%M:%S %Z%z""']",22,[],"['datetime.now', 'now_utc.astimezone', 'now_pacific.strftime']",3
utilmy/distributed.py:sleep_random,sleep_random,function,4,6,6,52,8.67,0,0,['nmax'],[None],['5'],31,[],"['time.sleep', 'random.randrange']",2
utilmy/distributed.py:load_serialize,load_serialize,function,5,10,9,66,6.6,0,0,['name'],[None],[None],36,[],"['log2', 'load']",2
utilmy/distributed.py:save_serialize,save_serialize,function,3,8,7,56,7.0,0,0,"['name', 'value']","[None, None]","[None, None]",44,[],"['log2', 'save']",2
utilmy/distributed.py:os_lock_acquireLock,os_lock_acquireLock,function,6,12,11,144,12.0,0,0,['plock'],[None],[None],51,[],"['open', 'fcntl.flock']",2
utilmy/distributed.py:os_lock_releaseLock,os_lock_releaseLock,function,3,4,4,61,15.25,0,0,['locked_file_descriptor'],[None],[None],59,[],['fcntl.flock'],1
utilmy/distributed.py:os_lock_execute,os_lock_execute,function,8,25,20,160,6.4,1,0,"['fun_run', 'pars', 'ntry', 'plock']","[None, None, None, None]","[None, None, '5', '""tmp/plock.lock""']",66,[],"['acquireLock', 'fun_run', 'releaseLock', 'log2', 'time.sleep']",5
utilmy/distributed.py:IndexLock,IndexLock,class,20,78,52,564,7.23,1,1,[],[],[],82,[],[],0
utilmy/distributed.py:IndexLock:__init__,IndexLock:__init__,method,4,4,4,35,8.75,0,0,"['self', 'findex', 'plock']","[None, None, None]","[None, None, None]",89,[],[],0
utilmy/distributed.py:IndexLock:get,IndexLock:get,method,5,10,9,66,6.6,0,0,"['self', 'val', 'ntry', 'plock']","[None, None, None, None]","[None, '""""', '5', '""tmp/plock.lock""']",94,[],"['open', 'fp.readlines']",2
utilmy/distributed.py:IndexLock:put,IndexLock:put,method,13,48,38,327,6.81,1,1,"['self', 'val', 'ntry', 'plock']","[None, None, None, None]","[None, '""""', '5', '""tmp/plock.lock""']",100,[],"['os_lock_acquireLock', 'open', 'fp.readlines', 'set', 'fp.write', 'fpath.strip', 'os_lock_releaseLock', 'print', 'time.sleep']",9
utilmy/images.py:log,log,function,1,1,1,8,8.0,0,0,['*s'],[None],[None],13,[],['print'],1
utilmy/images.py:deps,deps,function,5,7,7,74,10.57,0,0,[],[],[],17,[],"['open', 'fp.readlines', 'print']",3
utilmy/images.py:read_image,read_image,function,18,50,37,703,14.06,0,4,"['filepath_or_buffer', 'io.BytesIO]']","[' typing.Union[str', None]","[None, None]",24,"['    """"""Read a file into an image object\n', '    Args:\n', '        filepath_or_buffer: The path to the file, a URL, or any object\n', '            with a `read` method (such as `io.BytesIO`)\n', '    """"""\n']","['isinstance', 'hasattr', 'np.asarray', 'cv2.imdecode', 'validators.url', 'read', 'filepath_or_buffer.endswith', 'tifffile.imread', 'cv2.imread', 'cv2.cvtColor']",10
utilmy/images.py:visualize_in_row,visualize_in_row,function,12,24,24,239,9.96,1,0,['**images'],[None],[None],53,"['    """"""Plot images in one row.""""""\n']","['len', 'plt.figure', 'enumerate', 'plt.subplot', 'plt.xticks', 'plt.yticks', 'plt.title', 'plt.imshow', 'plt.show']",9
utilmy/images.py:maintain_aspect_ratio_resize,maintain_aspect_ratio_resize,function,10,40,29,229,5.72,0,2,"['image', 'width', 'height', 'inter']","[None, None, None, None]","[None, 'None', 'None', 'cv2.INTER_AREA']",68,[],"['float', 'int', 'cv2.resize']",3
utilmy/io.py:screenshot,screenshot,function,9,22,16,132,6.0,0,0,"['output', 'monitors']","[None, None]","[""'fullscreen.png'"", '-1']",4,"['  """"""\n', '  with mss() as sct:\n', '    for _ in range(100):\n', '        sct.shot()\n', '  # MacOS X\n', '  from mss.darwin import MSS as mss\n', '  \n', '  \n', '  """"""\n']","['sct.shot', 'print']",2
utilmy/multithread.py:multithread_run,multithread_run,function,38,114,84,1004,8.81,7,2,"['fun_async', 'input_list', 'n_pool', 'verbose']","[None, 'list', None, None]","[None, None, '5', 'True']",8,"['    """"""  input is as list of tuples  [(x1,x2,x3), (y1,y2,y3) ]\n', '    def fun_async(xlist):\n', '      for x in xlist :\n', '            hdfs.upload(x[0], x[1])\n', '    """"""\n']","['range', 'enumerate', 'ThreadPool', 'job_list.append', 'pool.apply_async', 'log', 'len', 'res_list.append', 'pool.terminate', 'pool.join', 'multithread_run_list', 'ThreadWithResult', '__init__', 'function', 'target', 'super', 'kwargs.values', 'list_of_threads.append', 'thread.start', 'zip', 'kwargs.keys', 'thread.join', 'results.append']",23
utilmy/multithread.py:multithread_run_list,multithread_run_list,function,19,48,40,530,11.04,3,0,['**kwargs'],[None],[None],37,"['    """""" Creating n number of threads:  1 thread per function,    starting them and waiting for their subsequent completion\n', '    os_multithread(function1=(test_print, (""some text"",)),\n', '                          function2=(test_print, (""bbbbb"",)),\n', '                          function3=(test_print, (""ccccc"",)))\n', '    """"""\n']","['ThreadWithResult', '__init__', 'function', 'target', 'super', 'kwargs.values', 'list_of_threads.append', 'thread.start', 'zip', 'kwargs.keys', 'thread.join', 'results.append']",12
utilmy/tabular.py:log,log,function,1,1,1,8,8.0,0,0,['*s'],[None],[None],12,[],['print'],1
utilmy/tabular.py:test_anova,test_anova,function,23,78,55,663,8.5,2,1,"['df', 'col1', 'col2']","[None, None, None]","[None, None, None]",19,"['    """"""\n', '    ANOVA test two categorical features\n', '    Input dfframe, 1st feature and 2nd feature\n', '    """"""\n']","['edu_frame.groupby', 'groups.keys', 'globals', 'lg.append', 'dfd=len', 'print', 'stats.f_oneway', 'dfn=len']",8
utilmy/tabular.py:test_normality2,test_normality2,function,19,122,59,890,7.3,1,6,"['df', 'column', 'test_type']","[None, None, None]","[None, None, None]",48,"['    """"""\n', '    Function to check Normal Distribution of a Feature by 3 methods\n', '    Input dfframe, feature name, and a test type\n', '    Three types of test\n', ""    1)'Shapiro'\n"", ""    2)'Normal'\n"", ""    3)'Anderson'\n"", '\n', '    output the statistical test score and result whether accept or reject\n', '    Accept mean the feature is Gaussain\n', '    Reject mean the feature is not Gaussain\n', '    """"""\n']","['shapiro', 'print', 'normaltest', 'anderson', 'range']",5
utilmy/tabular.py:test_plot_qqplot,test_plot_qqplot,function,15,29,25,338,11.66,0,0,"['df', 'col_name']","[None, None]","[None, None]",95,"['    """"""\n', '    Function to plot boxplot, histplot and qqplot for numerical feature analyze\n', '    """"""\n']","['plt.subplots', 'fig.suptitle', 'sns.boxplot', 'sns.histplot', 'sm.qqplot', 'print']",6
utilmy/tabular.py:test_heteroscedacity,test_heteroscedacity,function,61,111,85,993,8.95,0,0,"['y', 'y_pred', 'pred_value_only']","[None, None, None]","[None, None, '1']",112,[],"['Linear', 'custom_stat', 'np.sqrt', 'print', 'df.profile_report', 'profile.to_file', 'profile.get_rejected_variables']",7
utilmy/tabular.py:pd_stat_distribution_colnum,pd_stat_distribution_colnum,function,23,84,72,646,7.69,1,3,"['df', 'nrows', 'verbose']","[None, None, None]","[None, '2000', 'False']",289,"['    """""" Stats the tables\n', '    """"""\n']","['df.sample', 'getstat', 'str', 'len', 'pd.DataFrame', 'pd.concat', 'print', 'np.arange']",8
utilmy/tabular.py:pd_stat_histogram,pd_stat_histogram,function,10,21,20,220,10.48,0,0,"['df', 'bins', 'coltarget']","[None, None, None]","[None, '50', '""diff""']",329,"['    """"""\n', '    :param df:\n', '    :param bins:\n', '    :param coltarget:\n', '    :return:\n', '    """"""\n']","['np.histogram', 'pd.DataFrame']",2
utilmy/tabular.py:np_col_extractname,np_col_extractname,function,7,38,24,216,5.68,1,5,['col_onehot'],[None],[None],344,"['    """"""\n', '    Column extraction from onehot name\n', '    :param col_onehotp\n', '    :return:\n', '    """"""\n']","['len', 'colnew.append']",2
utilmy/tabular.py:np_list_remove,np_list_remove,function,12,42,26,214,5.1,3,4,"['cols', 'colsremove', 'mode']","[None, None, None]","[None, None, '""exact""']",367,"['    """"""\n', '    """"""\n']","['cols.remove', 'cols3.append']",2
utilmy/tabular.py:pd_stat_shift_trend_changes,pd_stat_shift_trend_changes,function,20,41,35,660,16.1,0,0,"['df', 'feature', 'target_col', 'threshold']","[None, None, None, None]","[None, None, None, '0.03']",392,"['    """"""\n', '    Calculates number of times the trend of feature wrt target changed direction.\n', '    :param df: df_grouped dataset\n', '    :param feature: feature column name\n', '    :param target_col: target column\n', '    :param threshold: minimum % difference required to count as trend change\n', '    :return: number of trend chagnes for the feature\n', '    """"""\n']","['target_diffs.fillna', 'target_diffs.divide', 'target_diffs_norm.diff', 'target_diffs_lvl2.fillna', 'int']",5
utilmy/tabular.py:pd_stat_shift_trend_correlation,pd_stat_shift_trend_correlation,function,19,63,55,788,12.51,0,2,"['df', 'df_test', 'colname', 'target_col']","[None, None, None, None]","[None, None, None, None]",416,"['    """"""\n', '    Calculates correlation between train and test trend of colname wrt target.\n', '    :param df: train df data\n', '    :param df_test: test df data\n', '    :param colname: colname column name\n', '    :param target_col: target column name\n', '    :return: trend correlation between train and test\n', '    """"""\n']","['df.merge', 'pd.isnull', 'len', 'np.corrcoef', 'print']",5
utilmy/tabular.py:pd_stat_shift_changes,pd_stat_shift_changes,function,33,99,81,1236,12.48,1,4,"['df', 'target_col', 'features_list', 'bins', 'df_test']","[None, None, None, None, None]","[None, None, '0', '10', '0']",447,"['    """"""\n', '    Calculates trend changes and correlation between train/test for list of features\n', '    :param df: dfframe containing features and target columns\n', '    :param target_col: target column name\n', '    :param features_list: by default creates plots for all features. If list passed, creates plots of only those features.\n', '    :param bins: number of bins to be created from continuous colname\n', '    :param df_test: test df which has to be compared with input df for correlation\n', '    :return: dfframe with trend changes and trend correlation (if test df passed)\n', '    """"""\n']","['type', 'list', 'features_list.remove', 'ignored.append', 'pd_colnum_tocat_stat', 'pd_stat_shift_trend_correlation', 'pd_stat_shift_changes', 'stats_all.append', 'pd.DataFrame', 'len', 'print', 'str']",12
utilmy/tabular.py:np_conv_to_one_col,np_conv_to_one_col,function,5,11,10,137,12.45,0,0,"['np_array', 'sep_char']","[None, None]","[None, '""_""']",492,"['    """"""\n', '    converts string/numeric columns to one string column\n', '    :param np_array: the numpy array with more than one column\n', '    :param sep_char: the separator character\n', '    """"""\n']","['row2string', 'sep_char.join']",2
utilmy/text.py:log,log,function,1,1,1,8,8.0,0,0,['*s'],[None],[None],17,[],['print'],1
utilmy/text.py:pd_text_hash_create_lsh,pd_text_hash_create_lsh,function,22,32,29,327,10.22,2,0,"['df', 'col', 'sep', 'threshold', 'num_perm']","[None, None, None, None, None]","[None, None, '"" ""', '0.7', '10']",24,"[""    '''\n"", '    For each of the entry create a hash function\n', ""    '''\n""]","['MinHashLSH', 'enumerate', 'sentence.split', 'MinHash', 'set', 'v.update', 'hash_lines.append', 'lsh.insert']",8
utilmy/text.py:pd_text_getcluster,pd_text_getcluster,function,16,37,32,367,9.92,1,1,"['df', 'col', 'threshold', 'num_perm']","[None, None, None, None]","[None, None, None, None]",53,"[""    '''\n"", '    For each of the hash function find a cluster and assign unique id to the dataframe cluster_id\n', ""    '''\n""]","['pd_text_hash_create_lsh', 'enumerate', 'lsh.query', 'list']",4
utilmy/text.py:pd_similarity,pd_similarity,function,20,65,51,548,8.43,1,3,"['df', 'cols', 'algo']","[' pd.DataFrame', None, None]","[None, '[]', ""''""]",81,"[""    '''\n"", '        Return similarities between two columns with \n', ""        python's SequenceMatcher algorithm\n"", '\n', '        Args:\n', '            df (pd.DataFrame): Pandas Dataframe.\n', '            algo (String)    : rapidfuzz | editdistance \n', '            cols (list[str]) : List of of columns name (2 columns)\n', '\n', '        Returns:\n', '            pd.DataFrame\n', '\n', ""    '''\n""]","['len', 'Exception', 'find_similarity', 'fuzz.ratio', 'editdistance.eval', 'SequenceMatcher', 'df.apply']",7
utilmy/text.py:test_lsh,test_lsh,function,10,28,27,222,7.93,0,0,[],[],[],120,[],"['pd.DataFrame', 'pd_text_getcluster', 'df.head', 'print']",4
utilmy/utilmy.py:log,log,function,3,10,9,76,7.6,0,1,['*s'],[None],[None],6,[],"['print', 'log2']",2
utilmy/utilmy.py:log2,log2,function,2,6,6,32,5.33,0,1,"['*s', 'verbose']","[None, None]","[None, '1']",9,[],['print'],1
utilmy/utilmy.py:pd_merge,pd_merge,function,3,17,16,120,7.06,0,0,"['df1', 'df2', 'on', 'colkeep']","[None, None, None, None]","[None, None, 'None', 'None']",15,[],"['list', 'df1.join']",2
utilmy/utilmy.py:pd_plot_multi,pd_plot_multi,function,40,109,78,1103,10.12,2,3,"['df', 'plot_type', 'cols_axe1', 'cols_axe2', 'figsize', '4']","[None, None, 'list', 'list', None, None]","[None, 'None', '[]', '[]', '(8', None]",21,[],"['plt.figure', 'len', 'getattr', 'df.plot', 'plt.show', 'ax.set_ylabel', 'range', 'ax.get_legend_handles_labels', 'ax.twinx', 'ax_new.set_ylabel', 'ax_new.get_legend_handles_labels', 'ax.legend']",12
utilmy/utilmy.py:pd_filter,pd_filter,function,18,106,52,531,5.01,2,7,"['df', 'filter_dict', 'verbose']","[None, None, None]","[None, '""shop_id=11, l1_genre_id>600, l2_genre_id<80311,""', 'False']",70,"['    """"""\n', '     dfi = pd_filter2(dfa, ""shop_id=11, l1_genre_id>600, l2_genre_id<80311,"" )\n', '     dfi2 = pd_filter(dfa, {""shop_id"" : 11} )\n', '     ### Dilter dataframe with basic expr\n', '    """"""\n']","['isinstance', 'filter_dict.items', 'filter_dict.split', 'x_convert', 'str', 'dict', 'float', 'x.strip', 'print', 'len', 'x.split']",11
utilmy/utilmy.py:pd_to_file,pd_to_file,function,14,35,24,272,7.77,0,3,"['df', 'filei', 'check', 'verbose', '**kw']","[None, None, None, None, None]","[None, None, '""check""', 'True', None]",108,[],"['Path', 'os.makedirs', 'df.to_pickle', 'df.to_parquet', 'df.to_csv', 'gc.collect']",6
utilmy/utilmy.py:pd_read_file,pd_read_file,function,66,249,142,1645,6.61,4,18,"['path_glob', 'ignore_index', 'cols', 'verbose', 'nrows', 'concat_sort', 'n_pool', 'drop_duplicates', 'col_filter', 'col_filter_val', 'dtype_reduce', '**kw']","[None, None, None, None, None, None, None, None, None, None, None, None]","['""*.pkl""', 'True', 'None', 'False', '-1', 'True', '1', 'None', 'None', 'None', 'None', None]",134,"['  """"""  Read file in parallel from disk : very Fast\n', '  :param path_glob: list of pattern, or sep by "";""\n', '  :return:\n', '  """"""\n']","['log', 'print', 'isinstance', 'path_glob.split', 'file_list.extend', 'sorted', 'glob.glob', 'len', 'ThreadPool', 'pd.DataFrame', 'range', 'job_list.append', 'pool.apply_async', 'pd_dtype_reduce', 'dfi.drop_duplicates', 'gc.collect', 'pd.concat', 'pool.terminate', 'pool.join']",19
utilmy/utilmy.py:pd_sample_strat,pd_sample_strat,function,5,10,9,104,10.4,0,0,"['df', 'col', 'n']","[None, None, None]","[None, None, None]",217,[],"['df.groupby', 'x.sample']",2
utilmy/utilmy.py:pd_cartesian,pd_cartesian,function,12,22,18,154,7.0,0,0,"['df1', 'df2']","[None, None]","[None, None]",225,[],"['list', 'pd.merge']",2
utilmy/utilmy.py:pd_plot_histogram,pd_plot_histogram,function,24,71,45,428,6.03,0,4,"['dfi', 'path_save', 'nbin', 'q5', 'q95', 'nsample', 'show', 'clear']","[None, None, None, None, None, None, None, None]","[None, 'None', '20.0', '0.005', '0.995', ' -1', 'False', 'True']",237,[],"['dfi.quantile', 'dfi.hist', 'dfi.sample', 'plt.title', 'path_save.split', 'plt.show', 'os.makedirs', 'plt.savefig', 'print', 'plt.close']",10
utilmy/utilmy.py:pd_col_bins,pd_col_bins,function,8,19,18,128,6.74,0,0,"['df', 'col', 'nbins']","[None, None, None]","[None, None, '5']",262,[],"['pd.qcut', 'np.arange']",2
utilmy/utilmy.py:pd_dtype_reduce,pd_dtype_reduce,function,9,35,23,238,6.8,1,1,"['dfm', 'int0 ', 'float0 ']","[None, None, None]","[None, ""'int32'"", "" 'float32'""]",269,[],['np.dtype'],1
utilmy/utilmy.py:pd_dtype_count_unique,pd_dtype_count_unique,function,17,73,57,539,7.38,1,3,"['df', 'col_continuous']","[None, None]","[None, '[]']",278,"['    """"""Learns the number of categories in each variable and standardizes the data.\n', '        ----------\n', '        data: pd.DataFrame\n', '        continuous_ids: list of ints\n', '            List containing the indices of known continuous variables. Useful for\n', '            discrete data like age, which is better modeled as continuous.\n', '        Returns\n', '        -------\n', '        ncat:  number of categories of each variable. -1 if the variable is  continuous.\n', '    """"""\n']","['gef_is_continuous', 'np.sum', 'np.round', 'len', 'n', 'any', 'list', 'n=min']",8
utilmy/utilmy.py:pd_dtype_to_category,pd_dtype_to_category,function,15,36,29,350,9.72,1,3,"['df', 'col_exclude', 'treshold']","[None, None, None]","[None, None, '0.5']",317,"['  """"""\n', '    Convert string to category\n', '  """"""\n']","['isinstance', 'df.select_dtypes', 'len', 'float', 'pd.to_datetime', 'print']",6
utilmy/utilmy.py:pd_dtype_getcontinuous,pd_dtype_getcontinuous,function,10,43,29,261,6.07,1,2,"['df', 'cols_exclude', 'nsample']","[None, 'list', None]","[None, '[]', '-1']",336,[],"['len', 'str']",2
utilmy/utilmy.py:pd_del,pd_del,function,6,13,13,50,3.85,1,0,"['df', 'cols']","[None, 'list']","[None, None]",352,[],[],0
utilmy/utilmy.py:pd_add_noise,pd_add_noise,function,18,41,33,295,7.2,1,1,"['df', 'level', 'cols_exclude']","[None, None, 'list']","[None, '0.05', '[]']",361,[],"['pd.DataFrame', 'pd_dtype_getcontinuous', 'print']",3
utilmy/utilmy.py:pd_cols_unique_count,pd_cols_unique_count,function,10,43,29,261,6.07,1,2,"['df', 'cols_exclude', 'nsample']","[None, 'list', None]","[None, '[]', '-1']",375,[],"['len', 'str']",2
utilmy/utilmy.py:pd_show,pd_show,function,6,10,10,116,11.6,0,0,"['df', 'nrows', 'reader', '**kw']","[None, None, None, None]","[None, '100', ""'notepad.exe'"", None]",393,"['    """""" Show from Dataframe\n', '    """"""\n']",['os_makedirs'],1
utilmy/utilmy.py:diskcache_save,diskcache_save,function,20,55,44,366,6.65,1,1,"['df', 'colkey', 'colvalue', 'db_path', 'size_limit', 'timeout', 'shards']","[None, 'str', 'str', 'str', None, None, 'int']","[None, None, None, '""""', '50000000000', '999', '1']",407,"['    """""" Create dict type on disk, < 100 Gb\n', '       shards>1 : disk spaced is BLOCKED in advance, so high disk usage\n', '       shards is for concurrent writes\n', '    """"""\n']","['dc.Cache', 'FanoutCache', 'range', 'print', 'len']",5
utilmy/utilmy.py:diskcache_load,diskcache_load,function,11,34,29,213,6.26,0,1,"['db_path', 'size_limit', 'timeout', 'force_create']","[None, None, None, None]","['""""', '50000000000', '2', 'False']",427,"['    """""" Load cache dict from disk and use as dict\n', '       val = cache[mykey]\n', '    \n', '    """"""\n']","['dc.Cache', 'print', 'len']",3
utilmy/utilmy.py:to_dict,to_dict,function,2,2,2,8,4.0,0,0,['**kw'],[None],[None],448,[],[],0
utilmy/utilmy.py:to_timeunix,to_timeunix,function,2,16,12,187,11.69,0,2,['datex'],[None],"['""2018-01-16""']",453,[],"['isinstance', 'int', 'datex.timetuple']",3
utilmy/utilmy.py:to_datetime,to_datetime,function,5,8,8,45,5.62,0,0,['x'],[None],[None],461,[],"['pd.to_datetime', 'str']",2
utilmy/utilmy.py:np_list_intersection,np_list_intersection,function,4,10,8,24,2.4,1,1,"['l1', 'l2']","[None, None]","[None, None]",466,[],[],0
utilmy/utilmy.py:np_add_remove,np_add_remove,function,7,10,9,116,11.6,1,0,"['set_', 'to_remove', 'to_add']","[None, None, None]","[None, None, None]",470,[],"['set_.copy', 'result_temp.remove', 'result_temp.add']",3
utilmy/utilmy.py:to_float,to_float,function,1,8,6,46,5.75,0,0,['x'],[None],[None],479,[],['float'],1
utilmy/utilmy.py:to_int,to_int,function,1,8,6,44,5.5,0,0,['x'],[None],[None],486,[],"['int', 'float']",2
utilmy/utilmy.py:is_int,is_int,function,1,9,7,42,4.67,0,0,['x'],[None],[None],493,[],['int'],1
utilmy/utilmy.py:is_float,is_float,function,1,9,7,44,4.89,0,0,['x'],[None],[None],500,[],['float'],1
utilmy/utilmy.py:config_load,config_load,function,31,126,90,1072,8.51,2,4,"['config_path', 'path_default', 'config_default']","['str ', 'str', 'dict']","[' None', 'None', 'None']",512,"['    """"""Load Config file into a dict  from .json or .yaml file\n', '    TODO .cfg file\n', '    1) load config_path\n', '    2) If not, load default from HOME USER\n', '    3) If not, create default on in python code\n', '    Args:\n', ""        config_path: path of config or 'default' tag value\n"", '    Returns: dict config\n', '    """"""\n']","['str', 'log', 'pathlib.Path', 'yaml.load', 'x.items', 'json.load', 'os.makedirs', 'open', 'yaml.dump']",9
utilmy/utilmy.py:os_path_split,os_path_split,function,10,27,21,215,7.96,0,2,['fpath'],['str'],"['""""']",574,[],"['fpath.replace', 'fpath.split']",2
utilmy/utilmy.py:os_file_replacestring,os_file_replacestring,function,13,35,30,416,11.89,2,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",591,"['    """""" #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",\n', '        pattern=""*.html"", dirlevel=5  )\n', '    """"""\n']","['os_file_replacestring1', 'fileinput.FileInput', 'line.replace', 'file1.close', 'print', 'format', 'os_walk']",7
utilmy/utilmy.py:os_walk,os_walk,function,26,64,44,507,7.92,4,2,"['path', 'pattern', 'dirlevel']","[None, None, None]","[None, '""*""', '50']",613,"['    """""" dirlevel=0 : root directory\n', '        dirlevel=1 : 1 path below\n', '\n', '    """"""\n']","['path.replace', 'dir1.count', 'os.walk', 'root.replace', 'root.count', 'fnmatch.filter']",6
utilmy/utilmy.py:z_os_search_fast,z_os_search_fast,function,29,122,72,893,7.32,4,4,"['fname', 'texts', 'mode']","[None, None, None]","[None, 'None', '""regex/str""']",640,[],"['re.compile', 'enumerate', 're.search', 'line.decode', 'res.append', 'found.start', 'text.encode', 'line.find', 'print']",9
utilmy/utilmy.py:os_search_content,os_search_content,function,13,37,33,301,8.14,1,1,"['srch_pattern', 'mode', 'dir1', 'file_pattern', 'dirlevel']","[None, None, None, None, None]","['None', '""str""', '""""', '""*.*""', '1']",684,"['    """"""  search inside the files\n', '\n', '    """"""\n']","['os_walk', 'z_os_search_fast', 'pd.DataFrame']",3
utilmy/utilmy.py:os_get_function_name,os_get_function_name,function,6,31,18,199,6.42,0,0,[],[],[],700,[],"['str', 'socket.gethostname', 'sys._getframe']",3
utilmy/utilmy.py:os_variable_init,os_variable_init,function,3,12,10,45,3.75,1,0,"['ll', 'globs']","[None, None]","[None, None]",713,[],[],0
utilmy/utilmy.py:os_import,os_import,function,14,59,37,426,7.22,3,3,"['mod_name', 'globs', 'verbose']","[None, None, None]","['""myfile.config.model""', 'None', 'True']",721,[],"['__import__', 'hasattr', 'dir', 'name.startswith', 'all_names2.append', 'print', 'globs.update', 'getattr']",8
utilmy/utilmy.py:os_variable_exist,os_variable_exist,function,4,19,16,111,5.84,0,1,"['x', 'globs', 'msg']","[None, None, None]","[None, None, '""""']",748,[],"['str', 'log']",2
utilmy/utilmy.py:os_variable_check,os_variable_check,function,9,31,26,149,4.81,1,2,"['ll', 'globs', 'do_terminate']","[None, None, None]","[None, 'None', 'True']",758,[],"['Exception', 'log', 'sys.exit']",3
utilmy/utilmy.py:os_clean_memory,os_clean_memory,function,5,13,12,56,4.31,1,0,"['varlist', 'globx']","[None, None]","[None, None]",770,[],['gc.collect'],1
utilmy/utilmy.py:os_system_list,os_system_list,function,11,45,38,219,4.87,1,1,"['ll', 'logfile', 'sleep_sec']","[None, None, None]","[None, 'None', '10']",778,[],"['len', 'enumerate', 'log', 'os.system', 'time.sleep']",5
utilmy/utilmy.py:os_file_check,os_file_check,function,4,16,14,121,7.56,0,0,['fp'],[None],[None],800,[],"['log', 'os.stat', 'time.ctime']",3
utilmy/utilmy.py:os_to_file,os_to_file,function,3,7,7,52,7.43,0,0,"['txt', 'filename', 'mode']","[None, None, None]","['""""', '""ztmp.txt""', ""'a'""]",808,[],"['open', 'fp.write']",2
utilmy/utilmy.py:os_platform_os,os_platform_os,function,2,2,2,18,9.0,0,0,[],[],[],813,[],[],0
utilmy/utilmy.py:os_cpu,os_cpu,function,2,2,2,20,10.0,0,0,[],[],[],818,[],['os.cpu_count'],1
utilmy/utilmy.py:os_platform_ip,os_platform_ip,function,0,1,1,4,4.0,0,0,[],[],[],823,[],[],0
utilmy/utilmy.py:os_memory,os_memory,function,13,36,30,278,7.72,1,1,[],[],[],828,"['    """""" Get node total memory and memory usage in linux\n', '    """"""\n']","['open', 'i.split', 'str', 'int']",4
utilmy/utilmy.py:os_sleep_cpu,os_sleep_cpu,function,8,19,14,169,8.89,1,0,"['priority', 'cpu_min', 'sleep']","[None, None, None]","['300', '50', '10']",845,[],"['psutil.cpu_percent', 'time.sleep']",2
utilmy/utilmy.py:os_ram_object,os_ram_object,function,17,58,39,319,5.5,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",859,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'o.items']",7
utilmy/utilmy.py:os_copy,os_copy,function,11,21,21,231,11.0,1,1,"['src', 'dst', 'overwrite', 'exclude']","[None, None, None, None]","[None, None, 'False', '""""']",890,[],"['ignore_pyc_files', 'name.endswith', 'exclude.split', 'os.makedirs', 'shutil.copytree', 'shutil.ignore_patterns']",6
utilmy/utilmy.py:os_removedirs,os_removedirs,function,12,48,32,294,6.12,3,1,['path'],[None],[None],902,"['    """"""  issues with no empty Folder\n', ""    # Delete everything reachable from the directory named in 'top',\n"", '    # assuming there are no symbolic links.\n', ""    # CAUTION:  This is dangerous!  For example, if top == '/', it could delete all your disk files.\n"", '    """"""\n']","['len', 'print', 'os.walk', 'os.remove', 'os.rmdir']",5
utilmy/utilmy.py:os_getcwd,os_getcwd,function,3,6,5,66,11.0,0,0,[],[],[],929,[],[],0
utilmy/utilmy.py:os_system,os_system,function,11,45,38,219,4.87,1,1,"['ll', 'logfile', 'sleep_sec']","[None, None, None]","[None, 'None', '10']",935,"['  """""" get values\n', '       os_system( f""   ztmp "",  doprint=True)\n', '  """"""\n']","['len', 'enumerate', 'log', 'os.system', 'time.sleep']",5
utilmy/utilmy.py:os_makedirs,os_makedirs,function,2,13,12,198,15.23,0,1,['dir_or_file'],[None],[None],952,[],"['dir_or_file.split', 'os.makedirs']",2
utilmy/utilmy.py:global_verbosity,global_verbosity,function,10,54,35,442,8.19,0,2,"['cur_path', 'path_relative', 'default', 'key', '']","[None, None, None, None, None]","[None, '""/../../config.json""', '5', ""'verbosity'"", None]",961,"['    """""" Get global verbosity\n', '    verbosity = global_verbosity(__file__, ""/../../config.json"", default=5 )\n', '\n', '    verbosity = global_verbosity(""repo_root"", ""config/config.json"", default=5 )\n', '\n', '    :param cur_path:\n', '    :param path_relative:\n', '    :param key:\n', '    :param default:\n', '    :return:\n', '    """"""\n']","['git_repo_root', 'json.load', 'yaml.load', 'Exception', 'int']",5
utilmy/utilmy.py:hdfs_put,hdfs_put,function,52,179,108,1171,6.54,7,2,"['from_dir', 'to_dir', 'verbose', 'n_pool', 'dirlevel', '**kw']","[None, None, None, None, None, None]","['""""', '""""', 'True', '25', '50', None]",1005,"['    """""" \n', '     hdfs_put LocalFile into HDFS in multi-thread\n', '    from_dir = ""hdfs://nameservice1/user/\n', '    to_dir   = ""data/""\n', '    \n', '    """"""\n']","['log', 'print', 'hdfs.mkdir', 'os_walk', 'sorted', 'len', 'enumerate', 'file_list2.append', 'filei.replace', 't.replace', 'range', 'fun_async', 'open', 'hdfs.upload', 'time.sleep', 'ThreadPool', 'job_list.append', 'pool.apply_async', 'res_list.append', 'pool.terminate', 'pool.join']",21
utilmy/utilmy.py:hdfs_walk,hdfs_walk,function,9,30,19,121,4.03,2,1,"['path=""hdfs', 'dirlevel', 'hdfs=None)']","['', None, '']","['""hdfs://nameservice1/user/""', '3', 'None):   ### python  prepro.py hdfs_walkimport pyarrow as pa) if hdfs is None else hdfspath = ""hdfs://nameservice1/"" + path if \'hdfs://\' not in path else pathfdirs):']",1078,[],"['flist3.extend', 'hdfs.ls', 'hdfs.isdir']",3
utilmy/utilmy.py:hdfs_get,hdfs_get,function,40,135,94,981,7.27,5,3,"['from_dir', 'to_dir', 'verbose', 'n_pool', '**kw']","[None, None, None, None, None]","['""""', '""""', 'True', '20', None]",1101,"['    """""" \n', '    import fastcounter\n', '    counter = fastcounter.FastWriteCounter,()\n', '    counter.increment(1)    \n', '    cnt.value\n', '    """"""\n']","['log', 'print', 'os.makedirs', 'hdfs_walk', 'fun_async', 'hdfs.download', 'time.sleep', 'sorted', 'len', 'range', 'enumerate', 'filei.split', 'ThreadPool', 'job_list.append', 'pool.apply_async', 'res_list.append', 'pool.terminate', 'pool.join']",18
utilmy/utilmy.py:git_repo_root,git_repo_root,function,7,23,19,142,6.17,0,1,[],[],[],1173,[],"['os_system', 'mout.split', 'len']",3
utilmy/utilmy.py:git_current_hash,git_current_hash,function,6,12,10,123,10.25,0,0,['mode'],[None],"[""'full'""]",1183,[],"['subprocess.check_output', 'label.decode']",2
utilmy/utilmy.py:plot_to_html,plot_to_html,function,21,53,39,426,8.04,1,1,"['dir_input', 'out_file', 'title', 'verbose']","[None, None, None, None]","['""*.png""', '""graph.html""', '""""', 'False']",1195,"['    """"""\n', '      plot_to_html( model_path + ""/graph_shop_17_past/*.png"" , model_path + ""shop_17.html"" )\n', '\n', '    """"""\n']","['glob.glob', 'flist.sorted', 'print', 'open', 'base64.b64encode', 'f.write']",6
utilmy/utilmy.py:save,save,function,5,10,10,140,14.0,0,0,"['dd', 'to_file', 'verbose']","[None, None, None]","[None, '""""', 'False']",1294,[],"['os.makedirs', 'pickle.dump', 'open']",3
utilmy/utilmy.py:load,load,function,5,7,6,61,8.71,0,0,['to_file'],[None],"['""""']",1301,[],['pickle.load'],1
utilmy/utilmy.py:print_everywhere,print_everywhere,function,14,35,32,209,5.97,1,0,[],[],[],1311,"['    """"""\n', '    https://github.com/alexmojaki/snoop\n', '    """"""\n']","['snoop.install', 'myfun', 'pp', 'print', 'type', 'str']",6
utilmy/utilmy.py:log5,log5,function,5,6,6,33,5.5,0,0,['*s'],[None],[None],1341,"['    """"""    ### Equivalent of print, but more :  https://github.com/gruns/icecream\n', '    pip install icrecream\n', '    ic()  --->  ic| example.py:4 in foo()\n', ""    ic(var)  -->   ic| d['key'][1]: 'one'\n"", '    \n', '    """"""\n']",['ic'],1
utilmy/utilmy.py:log_trace,log_trace,function,4,4,4,37,9.25,0,0,"['msg', 'dump_path', 'globs']","[None, None, None]","['""""', '""""', 'None']",1352,[],"['print', 'pdb.set_trace']",2
utilmy/utilmy.py:profiler_start,profiler_start,function,6,9,9,82,9.11,0,0,[],[],[],1358,[],"['Profiler', 'profiler.start']",2
utilmy/utilmy.py:profiler_stop,profiler_stop,function,3,5,5,83,16.6,0,0,[],[],[],1366,[],"['profiler.stop', 'print']",2
utilmy/utilmy.py:dict_to_namespace,dict_to_namespace,class,3,5,5,36,7.2,0,0,[],[],[],442,[],[],0
utilmy/utilmy.py:Session,Session,class,42,178,114,1402,7.88,3,2,[],[],[],1225,[],[],0
utilmy/utilmy.py:dict_to_namespace:__init__,dict_to_namespace:__init__,method,2,2,2,15,7.5,0,0,"['self', 'd']","[None, None]","[None, None]",444,[],[],0
utilmy/utilmy.py:Session:__init__,Session:__init__,method,5,7,7,113,16.14,0,0,"['self', 'dir_session', '']","[None, None, None]","[None, '""ztmp/session/""', None]",1231,[],"['os.makedirs', 'print']",2
utilmy/utilmy.py:Session:show,Session:show,method,5,7,7,62,8.86,0,0,['self'],[None],[None],1237,[],"['glob.glob', 'print']",2
utilmy/utilmy.py:Session:save,Session:save,method,4,8,8,146,18.25,0,0,"['self', 'name', 'glob', 'tag']","[None, None, None, None]","[None, None, 'None', '""""']",1242,[],"['os.makedirs', 'self.save_session']",2
utilmy/utilmy.py:Session:load,Session:load,method,4,9,9,126,14.0,0,0,"['self', 'name', 'glob', 'tag']","[None, None, 'dict', None]","[None, None, 'None', '""""']",1248,[],"['print', 'self.load_session']",2
utilmy/utilmy.py:Session:save_session,Session:save_session,method,19,82,58,516,6.29,1,2,"['self', 'folder', 'globs', 'tag']","[None, None, None, None]","[None, None, None, '""""']",1255,[],"['os.makedirs', 'globs.items', 'x.startswith', 'str', 'pd.to_pickle', 'save', 'print']",7
utilmy/utilmy.py:Session:load_session,Session:load_session,method,11,33,28,208,6.3,2,0,"['self', 'folder', 'globs']","[None, None, None]","[None, None, 'None']",1278,"['      """"""\n', '      """"""\n']","['print', 'os.walk', 'x.replace', 'load']",4
utilmy/util_default.py:log,log,function,10,39,25,357,9.15,0,0,['*s'],[None],[None],18,[],"['logger.info', 'log2', 'logger.debug', 'logw', 'logger.warning', 'loge', 'logger.error', 'logger_setup', 'logger.configure']",9
utilmy/util_default.py:log2,log2,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],22,[],['logger.debug'],1
utilmy/util_default.py:logw,logw,function,1,5,5,41,8.2,0,0,['*s'],[None],[None],26,[],['logger.warning'],1
utilmy/util_default.py:loge,loge,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],30,[],['logger.error'],1
utilmy/util_default.py:logger_setup,logger_setup,function,2,15,13,138,9.2,0,0,[],[],[],34,[],['logger.configure'],1
utilmy/util_default.py:config_load,config_load,function,16,74,63,807,10.91,0,1,"['config_path', 'pathlib.Path]] ']","[' Optional[Union[str', None]","[None, ' None']",51,"['    """"""Load Config file into a dict\n', '    1) load config_path\n', '    2) If not, load in HOME USER\n', '    3) If not, create default one\n', ""    # config_default = yaml.load(os.path.join(os.path.dirname(__file__), 'config', 'config.yaml'))\n"", '\n', '    Args:\n', ""        config_path: path of config or 'default' tag value\n"", '    Returns: dict config\n', '    """"""\n']","['str', 'logw', 'log2', 'yaml.load', 'log', 'os.makedirs', 'open', 'json.dump']",8
utilmy/util_default.py:dataset_donwload,dataset_donwload,function,9,19,17,246,12.95,0,0,"['url', 'path_target']","[None, None]","[None, None]",99,"['    """"""Donwload on disk the tar.gz file\n', '    Args:\n', '        url:\n', '        path_target:\n', '    Returns:\n', '\n', '    """"""\n']","['log', 'os.makedirs', 'wget.download', 'url.split', 'os_extract_archive', 'log2']",6
utilmy/util_default.py:os_extract_archive,os_extract_archive,function,19,63,47,671,10.65,1,8,"['file_path', 'path', 'archive_format']","[None, None, None]","[None, '"".""', '""auto""']",117,"['    """"""Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n', '    Args:\n', '        file_path: path to the archive file\n', '        path: path to extract the archive file\n', '        archive_format: Archive format to try for extracting the file.\n', ""            Options are 'auto', 'tar', 'zip', and None.\n"", ""            'tar' includes tar, tar.gz, and tar.bz files.\n"", ""            The default 'auto' is ['tar', 'zip'].\n"", '            None or an empty list will return no matches found.\n', '    Returns:\n', '        True if a match was found and an archive extraction was completed,\n', '        False otherwise.\n', '    """"""\n']","['isinstance', 'is_match_fn', 'open_fn', 'archive.extractall', 'os.remove', 'shutil.rmtree']",6
utilmy/util_default.py:to_file,to_file,function,3,7,7,51,7.29,0,0,"['s', 'filep']","[None, None]","[None, None]",164,[],"['open', 'fp.write']",2
utilmy/zutil.py:session_load_function,session_load_function,function,6,9,9,88,9.78,0,0,['name'],[None],"['""test_20160815""']",66,[],"['dill.load_session', 'print']",2
utilmy/zutil.py:session_save_function,session_save_function,function,6,11,10,111,10.09,0,0,['name'],[None],"['""test""']",75,[],"['date_now', 'dill.dump_session', 'print']",3
utilmy/zutil.py:py_save_obj_dill,py_save_obj_dill,function,16,52,42,502,9.65,0,1,"['obj1', 'keyname', 'otherfolder']","[None, None, None]","[None, '""""', '0']",83,[],"['z_key_splitinto_dir_name', 'os_folder_create', 'open', 'dill.dumps', 'print']",5
utilmy/zutil.py:aa_unicode_ascii_utf8_issue,aa_unicode_ascii_utf8_issue,function,0,0,0,0,0.0,0,0,[],[],[],111,"['    """"""Take All csv in a folder and provide Table, Column Schema, type\n', '\n', ' METHOD FOR Unicode / ASCII issue\n', '1. Decode early\n', ""Decode to <type 'unicode'> ASAP\n"", ""df['PREF_NAME']=       df['PREF_NAME'].apply(to_unicode)\n"", '\n', '2. Unicode everywhere\n', '\n', '\n', '3. Encode late\n', ""# >>> f = open('/tmp/ivan_out.txt','w')\n"", ""# >>> f.write(ivan_uni.encode('utf-8'))\n"", '\n', 'Important methods\n', ""s.decode(encoding)  <type 'str'> to <type 'unicode'>\n"", ""u.encode(encoding)  <type 'unicode'> to <type 'str'>\n"", '\n', 'http://farmdev.com/talks/unicode/\n', '\n', '   """"""\n']",[],0
utilmy/zutil.py:isfloat,isfloat,function,4,13,11,79,6.08,0,1,['x'],[None],[None],135,[],['float'],1
utilmy/zutil.py:isint,isint,function,2,6,6,50,8.33,0,0,['x'],[None],[None],145,[],['isinstance'],1
utilmy/zutil.py:isanaconda,isanaconda,function,4,10,9,65,6.5,0,1,[],[],[],149,[],['txt.find'],1
utilmy/zutil.py:a_run_ipython,a_run_ipython,function,1,1,1,33,33.0,0,0,['cmd1'],[None],[None],157,"['    """""" Execute Ipython Command in python code\n', '     run -i :  run including current interprete variable\n', ' """"""\n']",['IPython.get_ipython'],1
utilmy/zutil.py:py_autoreload,py_autoreload,function,1,4,4,64,16.0,0,0,[],[],[],164,[],['a_run_ipython'],1
utilmy/zutil.py:os_platform,os_platform,function,1,2,2,8,4.0,0,0,[],[],[],169,[],[],0
utilmy/zutil.py:a_start_log,a_start_log,function,3,15,14,103,6.87,0,0,"['id1', 'folder']","[None, None]","['""""', '""aaserialize/log/""']",173,[],"['a_run_ipython', 'str', 'os_platform', 'date_now']",4
utilmy/zutil.py:a_cleanmemory,a_cleanmemory,function,3,3,3,21,7.0,0,0,[],[],[],187,[],['gc.collect'],1
utilmy/zutil.py:a_info_conda_jupyter,a_info_conda_jupyter,function,1,2,2,5,2.5,0,0,[],[],[],193,[],[],0
utilmy/zutil.py:print_object_tofile,print_object_tofile,function,15,45,35,236,5.24,2,2,"['vv', 'txt', 'file1=""d']","[None, None, '']","[None, None, '""d:/regression_output.py""']",355,"['    """""" #Print to file Object   Table   """"""\n']","['open', 'file1.write', 'np.shape', 'range', 'str']",5
utilmy/zutil.py:print_progressbar,print_progressbar,function,9,32,29,316,9.88,0,1,"['iteration', 'total', 'prefix', 'suffix', 'decimals', 'bar_length']","[None, None, None, None, None, None]","[None, None, '""""', '""""', '1', '100']",372,"['    """"""# Print iterations progress\n', '     Call in a loop to create terminal progress bar\n', '    @params:\n', '        iteration   - Required  : current iteration (Int)\n', '        total       - Required  : total iterations (Int)\n', '        prefix      - Optional  : prefix string (Str)\n', '        suffix      - Optional  : suffix string (Str)\n', '        decimals    - Optional  : positive number of decimals in percent complete (Int)\n', '        bar_length   - Optional  : character length of bar (Int)\n', '    """"""\n']","['str', 'format_str.format', 'float', 'int']",4
utilmy/zutil.py:os_zip_checkintegrity,os_zip_checkintegrity,function,7,27,24,173,6.41,0,1,['filezip1'],[None],[None],401,[],"['zipfile.ZipFile', 'zip_file.testzip', 'print']",3
utilmy/zutil.py:os_zipfile,os_zipfile,function,19,37,32,376,10.16,2,2,"['folderin', 'folderzipname', 'iscompress']","[None, None, None]","[None, None, 'True']",414,[],"['zipfile.ZipFile', 'os.walk', 'zf.write', 'zf.close', 'os_zip_checkintegrity', 'print']",6
utilmy/zutil.py:os_zipfolder,os_zipfolder,function,2,8,5,116,14.5,0,0,"['dir_tozip', 'zipname', 'dir_prefix', 'iscompress=Trueimport shutil_ = iscompressdir_tozip = dir_tozip if dir_tozip[-1] != ""/"" else dir_tozip[']","[None, None, None, '']","['""/zdisks3/output""', '""/zdisk3/output.zip""', 'True', 'Trueimport shutil_ = iscompressdir_tozip = dir_tozip if dir_tozip[-1] != ""/"" else dir_tozip[:-1]if dir_prefix:']",432,"['    """"""\n', "" shutil.make_archive('/zdisks3/results/output', 'zip',\n"", ""                     root_dir=/zdisks3/results/',\n"", ""                     base_dir='output')\n"", ' os_zipfolder(\'zdisk/test/aapackage\', \'zdisk/test/aapackage.zip\', \'zdisk/test\')""""""\n']",['dir_tozip.split'],1
utilmy/zutil.py:os_zipextractall,os_zipextractall,function,23,61,51,536,8.79,1,3,"['filezip_or_dir', 'tofolderextract', 'isprint']","[None, None, None]","['""folder1/*.zip""', '""zdisk/test""', '1']",484,"['    """"""os_zipextractall( \'aapackage.zip\',\'zdisk/test/\'      )  """"""\n']","['filezip_or_dir.find', 'os_file_listall', 'os_file_getname', 'zipfile.ZipFile', 'zip_ref.extractall', 'zip_ref.close', 'print']",7
utilmy/zutil.py:os_folder_copy,os_folder_copy,function,15,39,36,391,10.03,0,2,"['src', 'dst', 'symlinks', 'pattern1', 'fun_file_toignore']","[None, None, None, None, None]","[None, None, 'False', '""*.py""', 'None']",518,"['    """"""\n', '       callable(src, names) -> ignored_names\n', ""       'src' parameter, which is the directory being visited by copytree(), and\n"", ""       'names' which is the list of `src` contents, as returned by os.listdir():\n"", '\n', '    Since copytree() is called recursively, the callable will be called once for each\n', '    directory that is copied.\n', '    It returns a  list of names relative to the `src` directory that should not be copied.\n', '   """"""\n']","['_default_fun_file_toignore', 'fnmatch.filter', 'shutil.copytree', 'shutil.copy']",4
utilmy/zutil.py:os_folder_create,os_folder_create,function,5,7,7,86,12.29,0,1,['directory'],[None],[None],548,[],"['os.getcwd', 'os.makedirs', 'os.chdir']",3
utilmy/zutil.py:os_folder_robocopy,os_folder_robocopy,function,3,15,15,163,10.87,0,1,"['from_folder', 'to_folder', 'my_log=""H']","[None, None, '']","['""""', '""""', '""H:/robocopy_log.txt""']",555,"['    """"""\n', '    Copy files to working directory\n', '    robocopy <Source> <Destination> [<File>[ ...]] [<Options>]\n', '    We want to copy the files to a fast SSD drive\n', '    """"""\n']","['subprocess.call', 'print']",2
utilmy/zutil.py:os_file_replace,os_file_replace,function,27,73,56,824,11.29,3,0,"['source_file_path', 'pattern', 'substring']","[None, None, None]","[None, None, None]",568,[],"['mkstemp', 'open', 'target_file.write', 'remove', 'move', 'os_file_replacestring1', 'fileinput.FileInput', 'line.replace', 'file1.close', 'print', 'format', 'os_file_replacestring2', 'os_file_listall']",13
utilmy/zutil.py:os_file_replacestring1,os_file_replacestring1,function,9,18,17,201,11.17,1,0,"['find_str', 'rep_str', 'file_path']","[None, None, None]","[None, None, None]",582,"['    """"""replaces all find_str by rep_str in file file_path""""""\n']","['fileinput.FileInput', 'line.replace', 'file1.close', 'print', 'format']",5
utilmy/zutil.py:os_file_replacestring2,os_file_replacestring2,function,5,13,12,162,12.46,1,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",594,"['    """""" #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",\n', '    pattern=""*.html"", dirlevel=5  )\n', '  """"""\n']","['os_file_listall', 'os_file_replacestring1']",2
utilmy/zutil.py:os_file_getname,os_file_getname,function,8,9,8,75,8.33,0,0,['path'],[None],[None],604,[],"['ntpath.split', 'ntpath.basename']",2
utilmy/zutil.py:os_file_getpath,os_file_getpath,function,7,7,7,52,7.43,0,0,['path'],[None],[None],611,[],['ntpath.split'],1
utilmy/zutil.py:os_file_gettext,os_file_gettext,function,4,8,8,55,6.88,0,0,['file1'],[None],[None],618,[],"['open', 'f.read']",2
utilmy/zutil.py:os_file_listall,os_file_listall,function,23,40,34,476,11.9,2,1,"['dir1', 'pattern', 'dirlevel', 'onlyfolder']","[None, None, None, None]","[None, '""*.*""', '1', '0']",625,[],"['dir1.rstrip', 'dir1.count', 'os.walk', 'root.count', 'fnmatch.filter']",5
utilmy/zutil.py:_os_file_search_fast,_os_file_search_fast,function,27,120,70,884,7.37,4,4,"['fname', 'texts', 'mode']","[None, None, None]","[None, 'None', '""regex/str""']",695,[],"['re.compile', 'enumerate', 're.search', 'line.decode', 'res.append', 'found.start', 'text.encode', 'line.find', 'print']",9
utilmy/zutil.py:os_file_search_content,os_file_search_content,function,10,33,29,296,8.97,1,1,"['srch_pattern', 'mode', 'dir1', 'file_pattern', 'dirlevel']","[None, None, None, None, None]","['None', '""str""', '""""', '""*.*""', '1']",740,[],"['os_file_listall', '_os_file_search_fast', 'pd.DataFrame']",3
utilmy/zutil.py:os_file_rename,os_file_rename,function,33,53,45,644,12.15,2,1,"['some_dir', 'pattern', 'pattern2', 'dirlevel']","[None, None, None, None]","[None, '""*.*""', '""""', '1']",758,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 're.sub', 'os.rename', 'np.array']",9
utilmy/zutil.py:os_gui_popup_show,os_gui_popup_show,function,25,37,36,408,11.03,0,0,['txt'],[None],[None],788,[],"['os_gui_popup_show2', 'Tk', 'Scrollbar', 'Text', 'scrollbar.pack', 'text.pack', 'scrollbar.config', 'text.config', 'text.insert', 'root.attributes', 'mainloop']",11
utilmy/zutil.py:os_print_tofile,os_print_tofile,function,1,1,1,24,24.0,0,0,"['vv', 'file1', 'mode1=""a"")', 'mode1) as text_file']","[None, None, '', '']","[None, None, '""a""):  # print into a file=\'afile1', None]",808,"['    """"""\n', '    Here is a list of the different modes of opening a file:\n', 'r\n', 'Opens a file for reading only. The file pointer is placed at the beginning of the file.\n', 'This is the default mode.\n', '\n', 'rb\n', '\n', 'Opens a file for reading only in binary format. The file pointer is placed at the\n', 'beginning of the file. This is the default mode.\n', 'r+\n', '\n', 'Opens a file for both reading and writing. The file pointer will be at the beginning of the file.\n', 'rb+\n', '\n', 'Opens a file for both reading and writing in binary format. The file pointer will be at the\n', 'beginning of the file.\n', 'w\n', '\n', 'Opens a file for writing only. Overwrites the file if the file exists. If the file does not exist,\n', 'creates a new file for writing.\n', 'wb\n', '\n', 'Opens a file for writing only in binary format. Overwrites the file if the file exists.\n', 'If the file does not exist, creates a new file for writing.\n', 'w+\n', '\n', 'Opens a file for both writing and reading. Overwrites the existing file if the file exists.\n', 'If the file does not exist, creates a new file for reading and writing.\n', 'wb+\n', '\n', 'Opens a file for both writing and reading in binary format. Overwrites the existing file if\n', 'the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'a\n', '\n', 'Opens a file for appending. The file pointer is at the end of the file if the file exists. That is,\n', 'the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'ab\n', '\n', 'Opens a file for appending in binary format. The file pointer is at the end of the file if the file\n', 'exists. That is, the file is in the append mode. If the file does not exist, it creates a new file\n', 'for writing.\n', 'a+\n', '\n', 'Opens a file for both appending and reading. The file pointer is at the end of the file if the\n', 'file exists. The file opens in the append mode. If the file does not exist, it creates a new file\n', 'for reading and writing.\n', 'ab+\n', '\n', 'Opens a file for both appending and reading in binary format. The file pointer is at the end of\n', 'the file if the file exists. The file opens in the append mode. If the file does not exist,\n', 'it creates a new file for reading and writing.\n', 'To open a text file, use:\n', 'fh = open(""hello.txt"", ""r"")\n', '\n', 'To read a text file, use:\n', 'print fh.read()\n', '\n', 'To read one line at a time, use:\n', 'print fh.readline()\n', '\n', 'To read a list of lines use:\n', 'print fh.readlines()\n', '\n', 'To write to a file, use:\n', 'fh = open(""hello.txt"", ""w"")\n', 'lines_of_text = [""a line of text"", ""another line of text"", ""a third line""]\n', 'fh.writelines(lines_of_text)\n', 'fh.close()\n', '\n', 'To append to file, use:\n', 'fh = open(""Hello.txt"", ""a"")\n', 'fh.close()\n', '\n', '    """"""\n']",['text_file.write'],1
utilmy/zutil.py:os_path_norm,os_path_norm,function,8,20,18,175,8.75,0,1,['pth)'],"['  # Normalize path for Python directoryr"""""" #r""D:\\_devs\\Python01\\project\\03-Connect_Java_CPP_Excel\\PyBindGen\\examples"" """""") ']",['= 2:'],888,[],"['pth.find', 'b.lstrip']",2
utilmy/zutil.py:os_path_change,os_path_change,function,3,8,8,68,8.5,0,0,['path1'],[None],[None],902,[],"['os_path_norm', 'os.chdir']",2
utilmy/zutil.py:os_path_current,os_path_current,function,2,2,2,17,8.5,0,0,[],[],[],907,[],['os.getcwd'],1
utilmy/zutil.py:os_file_exist,os_file_exist,function,2,2,2,27,13.5,0,0,['file1'],[None],[None],911,[],[],0
utilmy/zutil.py:os_file_size,os_file_size,function,2,2,2,28,14.0,0,0,['file1'],[None],[None],915,[],[],0
utilmy/zutil.py:os_file_read,os_file_read,function,4,5,5,34,6.8,0,0,['file1'],[None],[None],919,[],"['open', 'fh.read']",2
utilmy/zutil.py:os_file_isame,os_file_isame,function,4,5,5,44,8.8,0,0,"['file1', 'file2']","[None, None]","[None, None]",924,[],['filecmp.cmp'],1
utilmy/zutil.py:os_file_get_extension,os_file_get_extension,function,5,12,10,98,8.17,0,2,['file_path'],[None],[None],930,"['    """"""\n', '    # >>> get_file_extension(""/a/b/c"")\n', ""    ''\n"", '    # >>> get_file_extension(""/a/b/c.tar.xz"")\n', ""    'xz'\n"", '    """"""\n']",['_ext.startswith'],1
utilmy/zutil.py:os_file_normpath,os_file_normpath,function,2,8,8,67,8.38,0,0,['path'],[None],[None],944,"['    """"""Normalize path.\n', '    - eliminating double slashes, etc. (os.path.normpath)\n', '    - ensure paths contain ~[user]/ expanded.\n', '\n', '    :param path: Path string :: str\n', '    """"""\n']",[],0
utilmy/zutil.py:os_folder_is_path,os_folder_is_path,function,2,3,3,36,12.0,0,0,['path_or_stream'],[None],[None],954,"['    """"""\n', '    Is given object `path_or_stream` a file path?\n', '    :param path_or_stream: file path or stream, file/file-like object\n', '    :return: True if `path_or_stream` is a file path\n', '    """"""\n']",['isinstance'],1
utilmy/zutil.py:os_file_get_path_from_stream,os_file_get_path_from_stream,function,7,20,15,187,9.35,0,2,['maybe_stream'],[None],[None],963,"['    """"""\n', '    Try to get file path from given stream `stream`.\n', '\n', '    :param maybe_stream: A file or file-like object\n', '    :return: Path of given file or file-like object or None\n', '\n', '    # >>> __file__ == get_path_from_stream(__file__)\n', '    True\n', ""    # >>> __file__ == get_path_from_stream(open(__file__, 'r'))\n"", '    True\n', '    # >>> strm = anyconfig.compat.StringIO()\n', '    # >>> get_path_from_stream(strm) is None\n', '    True\n', '    """"""\n']","['os_folder_is_path', 'getattr']",2
utilmy/zutil.py:os_file_try_to_get_extension,os_file_try_to_get_extension,function,4,12,10,112,9.33,0,1,['path_or_strm'],[None],[None],988,"['    """"""\n', '    Try to get file extension from given path or file object.\n', '    :return: File extension or None\n', '    """"""\n']","['os_file_get_path_from_stream', 'os_file_get_extension']",2
utilmy/zutil.py:os_file_are_same_file_types,os_file_are_same_file_types,function,5,20,14,154,7.7,0,2,['paths'],[None],[None],1000,"['    """"""\n', '    Are given (maybe) file paths same type (extension) ?\n', '    :param paths: A list of file path or file(-like) objects\n', '\n', '    # >>> are_same_file_types([])\n', '    False\n', '    # >>> are_same_file_types([""a.conf""])\n', '    True\n', '    # >>> are_same_file_types([""a.yml"", ""b.json""])\n', '    False\n', '    # >>> strm = anyconfig.compat.StringIO()\n', '    # >>> are_same_file_types([""a.yml"", ""b.yml"", strm])\n', '    False\n', '    """"""\n']","['os_file_try_to_get_extension', 'all']",2
utilmy/zutil.py:os_file_norm_paths,os_file_norm_paths,function,18,54,35,387,7.17,2,3,"['paths', 'marker']","[None, None]","[None, '""*""']",1024,"['    """"""\n', '    :param paths:\n', '        A glob path pattern string, or a list consists of path strings or glob\n', '        path pattern strings or file objects\n', ""    :param marker: Glob marker character or string, e.g. '*'\n"", '    :return: List of path strings\n', '    # >>> norm_paths([])\n', '    []\n', '    # >>> norm_paths(""/usr/lib/a/b.conf /etc/a/b.conf /run/a/b.conf"".split())\n', ""    ['/usr/lib/a/b.conf', '/etc/a/b.conf', '/run/a/b.conf']\n"", '    # >>> paths_s = os.path.join(os.path.dirname(__file__), ""u*.py"")\n', '    # >>> ref = sglob(paths_s)\n', '    # >>> ref = [""/etc/a.conf""] + ref\n', '    # >>> assert norm_paths([""/etc/a.conf"", paths_s]) == ref\n', '    # >>> strm = anyconfig.compat.StringIO()\n', '    # >>> assert norm_paths([""/etc/a.conf"", strm]) == [""/etc/a.conf"", strm]\n', '    """"""\n']","['sglob', 'sorted', '_norm_paths_itr', 'os_folder_is_path', 'list']",5
utilmy/zutil.py:os_file_mergeall,os_file_mergeall,function,10,19,19,173,9.11,1,0,"['nfile', 'dir1', 'pattern1', 'deepness']","[None, None, None, None]","[None, None, None, '2']",1068,[],"['os_file_listall', 'open', 'os_file_gettext', 'nfile1.write', 'nfile1.close']",5
utilmy/zutil.py:os_file_extracttext,os_file_extracttext,function,16,32,30,285,8.91,1,0,"['output_file', 'dir1', 'pattern1', 'htmltag', 'deepness']","[None, None, None, None, None]","[None, None, '""*.html""', '""p""', '2']",1077,"['    """""" Extract text from html """"""\n']","['os_file_listall', 'open', 'os_file_gettext', 'BeautifulSoup', 'soup.find_all', 'txt2.strip', 'output_file1.write']",7
utilmy/zutil.py:os_path_append,os_path_append,function,4,19,11,124,6.53,0,3,"['p1', 'p2', 'p3', 'p4']","[None, None, None, None]","[None, 'None', 'None', 'None']",1093,[],[],0
utilmy/zutil.py:os_wait_cpu,os_wait_cpu,function,5,21,16,257,12.24,1,0,"['priority', 'cpu_min']","[None, None]","['300', '50']",1104,[],"['psutil.cpu_percent', 'print', 'arrow.utcnow', 'time.sleep']",4
utilmy/zutil.py:os_split_dir_file,os_split_dir_file,function,7,15,13,114,7.6,0,1,['dirfile'],[None],[None],1116,[],"['dirfile.split', 'len']",2
utilmy/zutil.py:os_process_run,os_process_run,function,11,31,30,281,9.06,0,1,"['cmd_list', 'capture_output']","[None, None]","[None, 'False']",1126,"['    """"""os_process_run\n', '    \n', '    Args:\n', '         cmd_list: list [""program"", ""arg1"", ""arg2""]\n', '         capture_output: bool\n', '    """"""\n']","['subprocess.Popen', 'proc.communicate', 'print', 'str']",4
utilmy/zutil.py:os_process_2,os_process_2,function,0,1,1,4,4.0,0,0,[],[],[],1149,[],[],0
utilmy/zutil.py:py_importfromfile,py_importfromfile,function,12,24,20,269,11.21,0,1,"['modulename', 'dir1']","[None, None]","[None, None]",1183,[],"['a_get_pythonversion', 'SourceFileLoader', 'foo.MyClass', 'importlib.import_module']",4
utilmy/zutil.py:py_memorysize,py_memorysize,function,17,58,39,319,5.5,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",1199,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'o.items']",7
utilmy/zutil.py:save,save,function,2,4,4,64,16.0,0,0,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, '""/folder1/keyname""', '0']",1229,[],['py_save_obj'],1
utilmy/zutil.py:load,load,function,2,3,3,60,20.0,0,0,"['folder', 'isabsolutpath']","[None, None]","['""/folder1/keyname""', '0']",1233,[],['py_load_obj'],1
utilmy/zutil.py:save_test,save_test,function,5,10,10,126,12.6,0,0,"['folder', 'isabsolutpath']","[None, None]","['""/folder1/keyname""', '0']",1237,[],"['py_load_obj', 'print', 'str', 'gc.collect']",4
utilmy/zutil.py:py_save_obj,py_save_obj,function,16,52,42,502,9.65,0,1,"['obj1', 'keyname', 'otherfolder']","[None, None, None]","[None, '""""', '0']",1244,[],"['z_key_splitinto_dir_name', 'os_folder_create', 'open', 'dill.dumps', 'print']",5
utilmy/zutil.py:py_load_obj,py_load_obj,function,18,33,30,277,8.39,0,1,"['folder', 'isabsolutpath', 'encoding1']","[None, None, None]","['""/folder1/keyname""', '0', '""utf-8""']",1257,"['    """"""def load_obj(name, encoding1=\'utf-8\' ):\n', ""         with open('D:/_devs/Python01/aaserialize/' + name + '.pkl', 'rb') as f:\n"", '            return pickle.load(f, encoding=encoding1)\n', '    """"""\n']","['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.load']",5
utilmy/zutil.py:z_key_splitinto_dir_name,z_key_splitinto_dir_name,function,7,15,13,114,7.6,0,1,['keyname'],[None],[None],1277,[],"['keyname.split', 'len']",2
utilmy/zutil.py:os_config_setfile,os_config_setfile,function,9,32,23,223,6.97,1,1,"['dict_params', 'outfile', 'mode1']","[None, None, None]","[None, None, '""w+""']",1287,[],"['open', 'dict_params.items', 'isinstance', 'f1.write', 'str', 'f1.close', 'print']",7
utilmy/zutil.py:os_config_getfile,os_config_getfile,function,6,14,14,73,5.21,1,0,['file1'],[None],[None],1299,[],"['open', 'f1.readlines', 'print']",3
utilmy/zutil.py:os_csv_process,os_csv_process,function,2,2,2,7,3.5,0,0,['file1'],[None],[None],1307,[],[],0
utilmy/zutil.py:pd_toexcel,pd_toexcel,function,24,91,60,862,9.47,0,8,"['df', 'outfile', 'sheet_name', 'append', 'returnfile']","[None, None, None, None, None]","[None, '""file.xlsx""', '""sheet1""', '1', '1']",1427,"['    """"""\n', '# Create a Pandas Excel writer using XlsxWriter as the engine.\n', ""writer = pd.ExcelWriter('test.xlsx', engine='xlsxwriter')\n"", ""df.to_excel(writer, sheet_name='Sheet1')\n"", 'writer.save()\n', '\n', '# Get the xlsxwriter objects from the dataframe writer object.\n', 'workbook  = writer.book\n', ""worksheet = writer.sheets['Sheet1']\n"", '\n', '# Add some cell formats.\n', ""format1 = workbook.add_format({'num_format': '#,##0.00'})\n"", ""format2 = workbook.add_format({'num_format': '0%'})\n"", ""format3 = workbook.add_format({'num_format': 'h:mm:ss AM/PM'})\n"", '\n', '# Set the column width and format.\n', ""worksheet.set_column('B:B', 18, format1)\n"", '\n', '# Set the format but not the column width.\n', ""worksheet.set_column('C:C', None, format2)\n"", '\n', ""worksheet.set_column('D:D', 16, format3)\n"", '\n', '# Close the Pandas Excel writer and output the Excel file.\n', 'writer.save()\n', '\n', 'from openpyxl import load_workbook\n', 'wb = load_workbook(outfile)\n', 'ws = wb.active\n', ""ws.title = 'Table 1'\n"", '\n', 'tableshape = np.shape(table)\n', 'alph = list(string.ascii_uppercase)\n', '\n', 'for i in range(tableshape[0]):\n', '    for j in range(tableshape[1]):\n', '        ws[alph[i]+str(j+1)] = table[i, j]\n', '\n', ""for cell in ws['A'] + ws[1]:\n"", ""    cell.style = 'Pandas'\n"", '\n', ""wb.save('Scores.xlsx')\n"", '\n', '   """"""\n']","['os_file_exist', 'load_workbook', 'pd.ExcelWriter', 'dict', 'df.to_excel', 'writer.save', 'pd_toexcel_many', 'pd_toexcel']",8
utilmy/zutil.py:pd_toexcel_many,pd_toexcel_many,function,1,3,3,40,13.33,0,0,"['outfile', 'df1', 'df2', 'df3', 'df4', 'df5', 'df6', 'outfile', 'sheet_name=""df1"")if df2 is not None']","[None, None, None, None, None, None, None, None, '']","['""file1.xlsx""', 'None', 'None', 'None', 'None', 'None', 'Nonedf1', None, '""df1"")if df2 is not None:']",1492,[],['pd_toexcel'],1
utilmy/zutil.py:find_fuzzy,find_fuzzy,function,4,10,10,49,4.9,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1509,"['    """""" if xstring matches partially, add to the list   """"""\n']",['xi.find'],1
utilmy/zutil.py:str_match_fuzzy,str_match_fuzzy,function,4,12,11,65,5.42,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1514,"['    """""" if any of list_strinf elt matches partially xstring """"""\n']",['xstring.find'],1
utilmy/zutil.py:str_parse_stringcalendar,str_parse_stringcalendar,function,14,40,30,282,7.05,3,1,['cal'],[None],[None],1522,"['    """"""----------Parse Calendar  --------""""""\n']","['cal.split', 'x.find', 'cal4.append', 'np.array', 'print']",5
utilmy/zutil.py:str_make_unicode,str_make_unicode,function,6,13,10,123,9.46,0,1,"['input_str', 'errors']","[None, None]","[None, '""replace""']",1539,[],"['type', 'input_str.decode']",2
utilmy/zutil.py:str_empty_string_array,str_empty_string_array,function,8,33,23,182,5.52,2,1,"['x', 'y']","[None, None]","[None, '1']",1548,[],"['range', 'str_empty_string_array_numpy', 'np.empty']",3
utilmy/zutil.py:str_empty_string_array_numpy,str_empty_string_array_numpy,function,4,9,8,56,6.22,0,0,"['nx', 'ny']","[None, None]","[None, '1']",1555,[],['np.empty'],1
utilmy/zutil.py:str_isfloat,str_isfloat,function,2,8,7,58,7.25,0,0,['value'],[None],[None],1561,[],['float'],1
utilmy/zutil.py:str_is_azchar,str_is_azchar,function,2,8,7,54,6.75,0,0,['x'],[None],[None],1569,[],['float'],1
utilmy/zutil.py:str_is_az09char,str_is_az09char,function,2,8,7,54,6.75,0,0,['x'],[None],[None],1577,[],['float'],1
utilmy/zutil.py:str_reindent,str_reindent,function,3,8,7,65,8.12,0,0,"['s', 'num_spaces)', 'string', 'maxsplit=0)', 'delimiters))regex_pattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, '  # change indentation of multine string""\\n"")num_spaces * "" "") + line.lstrip() for line in s]s)return sdelimiters', None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, None, '0):  # Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, '0):  # Find Sentence Patternimport re_ = maxsplitsep2)""("" + regex_pat + r"")|(?:(?!"" + regex_pat + "").)*""', None, None]",1585,"['    """"""\n', '   if args:\n', ""       aux= name1+'.'+obj.__name__ +'('+ str(args) +')  \\n' + str(inspect.getdoc(obj))\n"", ""       aux= aux.replace('\\n', '\\n       ')\n"", '       aux= aux.rstrip()\n', ""       aux= aux + ' \\n'\n"", '       wi( aux)\n', '    """"""\n']",['x.decode'],1
utilmy/zutil.py:str_split2,str_split2,function,3,8,7,65,8.12,0,0,"['delimiters', 'string', 'maxsplit=0)', 'delimiters))regex_pattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, '0):  # Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, '0):  # Find Sentence Patternimport re_ = maxsplitsep2)""("" + regex_pat + r"")|(?:(?!"" + regex_pat + "").)*""', None, None]",1600,[],['x.decode'],1
utilmy/zutil.py:str_split_pattern,str_split_pattern,function,3,8,7,65,8.12,0,0,"['sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, '0):  # Find Sentence Patternimport re_ = maxsplitsep2)""("" + regex_pat + r"")|(?:(?!"" + regex_pat + "").)*""', None, None]",1607,[],['x.decode'],1
utilmy/zutil.py:pd_str_isascii,pd_str_isascii,function,3,8,7,65,8.12,0,0,['x'],[None],[None],1619,[],['x.decode'],1
utilmy/zutil.py:str_to_utf8,str_to_utf8,function,2,2,2,23,11.5,0,0,['x'],[None],[None],1627,"['    """""" Do it before saving/output to external printer """"""\n']",['x.encode'],1
utilmy/zutil.py:str_to_unicode,str_to_unicode,function,4,13,9,80,6.15,0,2,"['x', 'encoding']","[None, None]","[None, '""utf-8""']",1632,"['    """""" Do it First after Loading some text """"""\n']","['isinstance', 'str']",2
utilmy/zutil.py:np_minimize,np_minimize,function,28,116,91,902,7.78,2,5,"['fun_obj', 'x0', 'argext', '0']","[None, None, None, None]","[None, 'None', '(0', None]",1642,[],"['penalty', 'enumerate', 'max', 'loss', 'fun_obj', 'np_minimize_de', 'range', 'next', 'print', 'save', 'date_now', 'np_int_tostr', 'np.mod', 'np.abs']",14
utilmy/zutil.py:np_minimize_de,np_minimize_de,function,17,56,47,452,8.07,1,3,"['fun_obj', 'bounds', 'name1', 'maxiter', 'popsize', 'solver']","[None, None, None, None, None, None]","[None, None, None, '10', '5', 'None']",1662,[],"['range', 'next', 'print', 'save', 'date_now', 'np_int_tostr', 'np.mod', 'np.abs']",8
utilmy/zutil.py:np_remove_na_inf_2d,np_remove_na_inf_2d,function,12,26,23,117,4.5,2,1,['x'],[None],[None],1686,[],"['np.shape', 'range', 'np.isnan', 'np.isinf']",4
utilmy/zutil.py:np_addcolumn,np_addcolumn,function,7,10,9,85,8.5,0,0,"['arr', 'nbcol']","[None, None]","[None, None]",1695,[],"['np.shape', 'np.zeros', 'np.column_stack']",3
utilmy/zutil.py:np_addrow,np_addrow,function,8,18,17,138,7.67,0,1,"['arr', 'nbrow']","[None, None]","[None, None]",1702,[],"['np.shape', 'len', 'np.zeros', 'np.row_stack', 'np.append']",5
utilmy/zutil.py:np_int_tostr,np_int_tostr,function,3,17,12,72,4.24,0,1,['i'],[None],[None],1712,[],['str'],1
utilmy/zutil.py:np_dictordered_create,np_dictordered_create,function,5,6,6,52,8.67,0,0,[],[],[],1721,[],['OrderedDict'],1
utilmy/zutil.py:np_list_unique,np_list_unique,function,1,2,2,20,10.0,0,0,['seq'],[None],[None],1727,[],['list'],1
utilmy/zutil.py:np_list_tofreqdict,np_list_tofreqdict,function,10,41,25,214,5.22,2,2,"['l1', 'wweight']","[None, None]","[None, 'None']",1731,[],"['dict', 'len', 'enumerate']",3
utilmy/zutil.py:np_list_flatten,np_list_flatten,function,11,25,19,132,5.28,2,1,['seq'],[None],[None],1754,[],"['type', 'np_list_flatten', 'ret.append']",3
utilmy/zutil.py:np_dict_tolist,np_dict_tolist,function,6,18,14,100,5.56,2,1,"['dd', 'withkey']","[None, None]","[None, '0']",1766,[],['list'],1
utilmy/zutil.py:np_dict_tostr_val,np_dict_tostr_val,function,1,7,7,52,7.43,0,0,['dd'],[None],[None],1773,[],['list'],1
utilmy/zutil.py:np_dict_tostr_key,np_dict_tostr_key,function,1,7,7,52,7.43,0,0,['dd'],[None],[None],1777,[],['list'],1
utilmy/zutil.py:np_removelist,np_removelist,function,7,20,16,100,5.0,1,2,"['x0', 'xremove']","[None, None]","[None, 'None']",1781,[],"['np_findfirst', 'xnew.append']",2
utilmy/zutil.py:np_transform2d_int_1d,np_transform2d_int_1d,function,18,47,39,238,5.06,2,0,"['m2d', 'onlyhalf']","[None, None]","[None, 'False']",1792,[],"['np.shape', 'np.zeros', 'range', 'np.abs', 'np_sortbycol']",5
utilmy/zutil.py:np_mergelist,np_mergelist,function,5,9,9,55,6.11,1,0,"['x0', 'x1']","[None, None]","[None, None]",1809,[],"['list', 'xnew.append']",2
utilmy/zutil.py:np_enumerate2,np_enumerate2,function,8,16,14,84,5.25,1,0,['vec_1d'],[None],[None],1816,[],"['np.empty', 'enumerate']",2
utilmy/zutil.py:np_pivottable_count,np_pivottable_count,function,10,24,21,170,7.08,1,0,['mylist'],[None],[None],1825,[],"['np_dict_tolist', 'sorted', 'int']",3
utilmy/zutil.py:np_nan_helper,np_nan_helper,function,2,5,5,40,8.0,0,0,['y'],[None],[None],1834,"['    """""" Input:  - y, 1d numpy array with possible NaNs\n', '        Output - nans, logical indices of NaNs - index, a function, with signature\n', '              indices= index(logical_indices),\n', ""              to convert logical indices of NaNs to 'equivalent' indices\n"", '    """"""\n']","['np.isnan', 'z.nonzero']",2
utilmy/zutil.py:np_interpolate_nan,np_interpolate_nan,function,7,9,9,76,8.44,0,0,['y'],[None],[None],1843,[],"['np_nan_helper', 'np.interp', 'x']",3
utilmy/zutil.py:np_and1,np_and1,function,8,69,25,362,5.25,0,6,"['x', 'y', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']","[None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None', 'None', 'None']",1849,[],[],0
utilmy/zutil.py:np_sortcol,np_sortcol,function,6,7,7,77,11.0,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",1864,"['    """""" df.sort([\'A\', \'B\'], ascending=[1, 0])  """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zutil.py:np_ma,np_ma,function,2,6,6,45,7.5,0,0,"['vv', 'n']","[None, None]","[None, None]",1871,"['    """"""Moving average """"""\n']","['np.convolve', 'np.ones']",2
utilmy/zutil.py:np_cleanmatrix,np_cleanmatrix,function,12,25,21,125,5.0,2,1,['m'],[None],[None],1877,[],"['np.nan_to_num', 'np.shape', 'range', 'abs']",4
utilmy/zutil.py:np_torecarray,np_torecarray,function,2,6,6,105,17.5,0,0,"['arr', 'colname']","[None, None]","[None, None]",1887,[],['np.shape'],1
utilmy/zutil.py:np_sortbycolumn,np_sortbycolumn,function,6,7,7,77,11.0,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1893,[],"['pd.DataFrame', 'df.sort_values']",2
utilmy/zutil.py:np_sortbycol,np_sortbycol,function,8,26,19,257,9.88,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1899,[],"['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zutil.py:np_min_kpos,np_min_kpos,function,2,5,5,36,7.2,0,0,"['arr', 'kth']","[None, None]","[None, None]",1912,"['    """""" return kth mininimun """"""\n']",['np.partition'],1
utilmy/zutil.py:np_max_kpos,np_max_kpos,function,3,10,8,53,5.3,0,0,"['arr', 'kth']","[None, None]","[None, None]",1917,"['    """""" return kth mininimun """"""\n']","['len', 'np.partition']",2
utilmy/zutil.py:np_findfirst,np_findfirst,function,5,11,10,55,5.0,1,1,"['item', 'vec']","[None, None]","[None, None]",1924,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zutil.py:np_find,np_find,function,5,11,10,55,5.0,1,1,"['item', 'vec']","[None, None]","[None, None]",1933,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zutil.py:find,find,function,4,10,10,49,4.9,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1941,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xi.find'],1
utilmy/zutil.py:findnone,findnone,function,4,12,11,55,4.58,1,1,['vec'],[None],[None],1949,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zutil.py:findx,findx,function,8,24,19,130,5.42,0,2,"['item', 'vec']","[None, None]","[None, None]",1957,"['    """"""return the index of the first occurence of item in vec""""""\n']","['type', 'vec.index', 'np.where', 'len']",4
utilmy/zutil.py:finds,finds,function,9,30,20,158,5.27,2,3,"['itemlist', 'vec']","[None, None]","[None, None]",1970,"['    """"""return the index of the first occurence of item in vec""""""\n']","['range', 'idlist.append']",2
utilmy/zutil.py:findhigher,findhigher,function,5,12,11,51,4.25,1,1,"['x', 'vec']","[None, None]","[None, None]",1987,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zutil.py:findlower,findlower,function,5,12,11,51,4.25,1,1,"['x', 'vec']","[None, None]","[None, None]",1995,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zutil.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],2003,[],['min'],1
utilmy/zutil.py:np_find_maxpos,np_find_maxpos,function,16,47,35,274,5.83,1,3,['values'],[None],[None],2008,[],"['max', 'np_find_maxpos_2nd', 'float', 'enumerate']",4
utilmy/zutil.py:np_find_maxpos_2nd,np_find_maxpos_2nd,function,12,39,29,146,3.74,1,3,['numbers'],[None],[None],2013,[],"['float', 'enumerate']",2
utilmy/zutil.py:np_findlocalmax2,np_findlocalmax2,function,32,141,83,689,4.89,2,5,"['v', 'trig']","[None, None]","[None, None]",2028,[],"['len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'np_sortbycolumn', 'range', 'findhigher', 'np.abs']",8
utilmy/zutil.py:np_findlocalmin2,np_findlocalmin2,function,32,145,83,702,4.84,2,6,"['v', 'trig']","[None, None]","[None, None]",2064,[],"['len', 'np.zeros', 'np_find_minpos', 'enumerate', 'np_sortbycolumn', 'range', 'findlower', 'np.abs']",8
utilmy/zutil.py:np_findlocalmax,np_findlocalmax,function,32,141,83,689,4.89,2,5,"['v', 'trig']","[None, None]","[None, None]",2100,[],"['len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'np_sortbycolumn', 'range', 'findhigher', 'np.abs']",8
utilmy/zutil.py:np_findlocalmin,np_findlocalmin,function,32,145,83,702,4.84,2,6,"['v', 'trig']","[None, None]","[None, None]",2116,[],"['len', 'np.zeros', 'np_find_minpos', 'enumerate', 'np_sortbycolumn', 'range', 'findlower', 'np.abs']",8
utilmy/zutil.py:np_stack,np_stack,function,11,63,21,347,5.51,0,7,"['v1', 'v2', 'v3', 'v4', 'v5']","[None, None, None, None, None]","[None, 'None', 'None', 'None', 'None']",2134,[],"['np.shape', 'np.row_stack', 'np.column_stack']",3
utilmy/zutil.py:np_uniquerows,np_uniquerows,function,6,9,9,148,16.44,0,0,['a'],[None],[None],2156,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zutil.py:np_remove_zeros,np_remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",2162,[],[],0
utilmy/zutil.py:np_sort,np_sort,function,6,7,7,77,11.0,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2166,"['    """"""\n', '    Creates a cross-tab or pivot table from a normalised input table. Use this\n', ""    function to 'denormalize' a table of normalized records.\n"", '\n', '    * The table argument can be a list of dictionaries or a Table object.\n', '    (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/334621)\n', '    * The left argument is a tuple of headings which are displayed down the\n', '    left side of the new table.\n', '    * The top argument is a tuple of headings which are displayed across the\n', '    top of the new table.\n', '    Tuples are used so that multiple element headings and columns can be used.\n', '\n', '    E.g. To transform the list (listOfDicts):\n', '\n', '    Name,   Year,  Value\n', '    -----------------------\n', ""    'Simon', 2004, 32\n"", ""    'Simon', 2005, 128\n"", ""    'Russel', 2004, 64\n"", ""    'Eric', 2004, 52\n"", ""    'Russel', 2005, 32\n"", '\n', '    into the new list:\n', '\n', ""    'Name',   2004, 2005\n"", '    ------------------------\n', ""    'Simon',  32,     128\n"", ""    'Russel',  64,     32\n"", ""    'Eric',   52,     NA\n"", '\n', '    you would call pivot with the arguments:\n', '\n', ""    newList = pivot(listOfDicts, ('Name',), ('Year',), 'Value')\n"", '\n', '    """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zutil.py:np_memory_array_adress,np_memory_array_adress,function,2,2,2,38,19.0,0,0,['x'],[None],[None],2170,[],[],0
utilmy/zutil.py:np_pivotable_create,np_pivotable_create,function,28,100,60,701,7.01,4,5,"['table', 'left', 'top', 'value']","[None, None, None, None]","[None, None, None, None]",2175,"['    """"""\n', '    Creates a cross-tab or pivot table from a normalised input table. Use this\n', ""    function to 'denormalize' a table of normalized records.\n"", '\n', '    * The table argument can be a list of dictionaries or a Table object.\n', '    (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/334621)\n', '    * The left argument is a tuple of headings which are displayed down the\n', '    left side of the new table.\n', '    * The top argument is a tuple of headings which are displayed across the\n', '    top of the new table.\n', '    Tuples are used so that multiple element headings and columns can be used.\n', '\n', '    E.g. To transform the list (listOfDicts):\n', '\n', '    Name,   Year,  Value\n', '    -----------------------\n', ""    'Simon', 2004, 32\n"", ""    'Simon', 2005, 128\n"", ""    'Russel', 2004, 64\n"", ""    'Eric', 2004, 52\n"", ""    'Russel', 2005, 32\n"", '\n', '    into the new list:\n', '\n', ""    'Name',   2004, 2005\n"", '    ------------------------\n', ""    'Simon',  32,     128\n"", ""    'Russel',  64,     32\n"", ""    'Eric',   52,     NA\n"", '\n', '    you would call pivot with the arguments:\n', '\n', ""    newList = pivot(listOfDicts, ('Name',), ('Year',), 'Value')\n"", '\n', '    """"""\n']","['tuple', 'ysort.append', 'xsort.append', 'len', 'list', 'xsort.sort', 'headings.extend', 'sortedkeys.sort', 'row.extend', 't.append']",10
utilmy/zutil.py:pd_info,pd_info,function,12,24,22,257,10.71,1,2,"['df', 'doreturn']","[None, None]","[None, '1']",2259,[],"['df.info', 'print', 'type', 'pd_info_memsize', 'pd_info', 'df.memory_usage']",6
utilmy/zutil.py:pd_info_memsize,pd_info_memsize,function,5,7,7,85,12.14,0,1,"['df', 'memusage']","[None, None]","[None, '0']",2268,[],"['df.info', 'pd_info', 'df.memory_usage']",3
utilmy/zutil.py:pd_row_findlast,pd_row_findlast,function,7,11,11,58,5.27,1,1,"['df', 'colid', 'emptyrowid']","[None, None, None]","[None, '0', 'None']",2275,[],['df.iterrows'],1
utilmy/zutil.py:pd_row_select,pd_row_select,function,13,112,53,862,7.7,1,3,"['df', '**conditions']","[None, None]","[None, None]",2282,"['    """"""Select rows from a df according to conditions\n', '    pdselect(data, a=2, b__lt=3) __gt __ge __lte  __in  __not_in\n', ""    will select all rows where 'a' is 2 and 'b' is less than 3\n"", '    """"""\n']","['type', 'pd.DataFrame', 'list', 'c.endswith', 'np.in1d', 'ValueError']",6
utilmy/zutil.py:pd_csv_randomread,pd_csv_randomread,function,13,47,38,267,5.68,0,1,"['filename', 'nsample', 'filemaxline', 'dtype']","[None, None, None, None]","[None, '10000', '-1', 'None']",2328,[],"['sum', 'open', 'np.sort', 'pd.read_csv']",4
utilmy/zutil.py:pd_array_todataframe,pd_array_todataframe,function,14,37,30,313,8.46,0,2,"['array', 'colname', 'index1', 'dotranspose']","[None, None, None, None]","[None, 'None', 'None', 'False']",2341,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zutil.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,11,10,103,9.36,0,0,['df'],[None],[None],2352,[],['df.reset_index'],1
utilmy/zutil.py:pd_createdf,pd_createdf,function,2,4,4,55,13.75,0,0,"['array1', 'col1', 'idx1']","[None, None, None]","[None, 'None', 'None']",2359,[],['pd.DataFrame'],1
utilmy/zutil.py:pd_create_colmapdict_nametoint,pd_create_colmapdict_nametoint,function,9,13,12,77,5.92,1,0,['df'],[None],[None],2363,"['    """""" \'close\' ---> 5    """"""\n']",['enumerate'],1
utilmy/zutil.py:pd_extract_col_idx_val,pd_extract_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],2373,[],[],0
utilmy/zutil.py:pd_extract_col_uniquevalue_tocsv,pd_extract_col_uniquevalue_tocsv,function,5,7,6,101,14.43,0,0,"['df', 'colname', 'csvfile']","[None, None, None]","[None, '""""', '""""']",2377,"['    """""" Write one column into a file   """"""\n']","['np.array', 'pd.DataFrame', 'print']",3
utilmy/zutil.py:pd_split_col_idx_val,pd_split_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],2385,[],[],0
utilmy/zutil.py:pd_splitdf_inlist,pd_splitdf_inlist,function,14,34,25,254,7.47,3,2,"['df', 'colid', 'type1']","[None, None, None]","[None, None, '""dict""']",2389,"['    """""" Split df into dictionnary of dict/list """"""\n']","['list', 'l1.append']",2
utilmy/zutil.py:pd_find,pd_find,function,35,142,88,1051,7.4,4,8,"['df', 'regex_pattern', 'col_restrict', 'isnumeric', 'doreturnposition']","[None, None, None, None, None]","[None, '""*""', 'None', 'False', 'False']",2405,"['    """""" Find string / numeric values inside df columns, return position where found\n', '     col_restrict : restrict to these columns """"""\n']","['str', 'print', 'enumerate', 'np.column_stack', 'len', 'gc.collect', 'np_dictordered_create', 'range', 'np.array']",9
utilmy/zutil.py:pd_dtypes_totype2,pd_dtypes_totype2,function,6,8,8,59,7.38,1,0,"['df', 'columns']","[None, None]","[None, '(']",2466,[],[],0
utilmy/zutil.py:pd_dtypes,pd_dtypes,function,21,58,46,358,6.17,2,2,"['df', 'columns']","[None, None]","[None, '(']",2472,[],"['pd_dtypes', 'OrderedDict', 'enumerate', 'eval', 'print']",5
utilmy/zutil.py:pd_df_todict2,pd_df_todict2,function,14,31,26,249,8.03,1,2,"['df', 'colkey', 'excludekey', '']","[None, None, None, None]","[None, '""table""', '(""""', None]",2492,[],"['df.drop_duplicates', 'range', 'len', 'dict0.setdefault']",4
utilmy/zutil.py:pd_df_todict,pd_df_todict,function,21,49,39,414,8.45,2,2,"['df', 'colkey', 'excludekey', '']","[None, None, None, None]","[None, '""table""', '(""""', None]",2507,[],"['df.drop_duplicates', 'range', 'len', 'dict0.setdefault', 'pd_df_todict', 'df.iterrows']",6
utilmy/zutil.py:pd_col_addfrom_dfmap,pd_col_addfrom_dfmap,function,4,7,6,69,9.86,0,0,"['df', 'dfmap', 'colkey', 'colval', 'df_colused', 'df_colnew', 'exceptval', 'inplace', 'colkey', 'colval=colval)rowi)']","[None, None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, '-1', 'Truedfmap', 'colkey', 'colval)rowi):']",2518,"['    """""" Add new columns based on df_map:  In Place Modification of df\n', '    df:     Dataframe of transactions.\n', '    dfmap:  FSMaster Dataframe\n', '      colkey: colum used for dict key.  machine_code\n', '      colval: colum used for dict val.  adress\n', '\n', '    df_colused  :     ""machine_code""\n', ""    exception val:  -1 or ''\n"", '  """"""\n']",[],0
utilmy/zutil.py:pd_applyfun_col,pd_applyfun_col,function,5,10,9,109,10.9,0,1,"['df', 'newcol', 'ff', 'use_colname']","[None, None, None, None]","[None, None, None, '""all/[colname]""']",2578,"['    """""" use all Columns to compute values """"""\n']",['ff'],1
utilmy/zutil.py:pd_date_intersection,pd_date_intersection,function,7,17,13,157,9.24,1,0,['qlist'],[None],[None],2599,[],"['set', 'set.intersection', 'list', 'sorted']",4
utilmy/zutil.py:pd_is_categorical,pd_is_categorical,function,3,13,11,118,9.08,0,1,['z'],[None],[None],2609,[],['isinstance'],1
utilmy/zutil.py:pd_str_encoding_change,pd_str_encoding_change,function,6,8,8,76,9.5,1,0,"['df', 'cols', 'fromenc', 'toenc']","[None, None, None, None]","[None, None, '""iso-8859-1""', '""utf-8""']",2618,[],[],0
utilmy/zutil.py:pd_str_unicode_tostr,pd_str_unicode_tostr,function,4,6,6,72,12.0,0,0,"['df', 'targetype']","[None, None]","[None, 'str']",2625,"['    """"""\n', ' https://www.azavea.com/blog/2014/03/24/solving-unicode-problems-in-python-2-7/\n', ' Nearly every Unicode problem can be solved by the proper application of these tools;\n', ' they will help you build an airlock to keep the inside of your code nice and clean:\n', '\n', 'encode(): Gets you from Unicode -> bytes\n', 'decode(): Gets you from bytes -> Unicode\n', 'codecs.open(encoding=""utf-8""): Read and write files directly to/from Unicode (you can use any\n', 'encoding,\n', ' not just utf-8, but utf-8 is most common).\n', 'u"": Makes your string literals into Unicode objects rather than byte sequences.\n', ""Warning: Don't use encode() on bytes or decode() on Unicode objects\n"", '\n', '# >>> uni_greeting % utf8_name\n', 'Traceback (most recent call last):\n', ' File ""<stdin>"", line 1, in <module>\n', ""UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 3: ordinal not in range(128)\n"", '# Solution:\n', ""# >>> uni_greeting % utf8_name.decode('utf-8')\n"", ""u'Hi, my name is Josxe9.'\n"", '\n', ' """"""\n']",['pd_dtypes_type1_totype2'],1
utilmy/zutil.py:pd_dtypes_type1_totype2,pd_dtypes_type1_totype2,function,7,11,11,100,9.09,1,1,"['df', 'fromtype', 'targetype']","[None, None, None]","[None, 'str', 'str']",2653,[],['isinstance'],1
utilmy/zutil.py:pd_resetindex,pd_resetindex,function,3,5,5,50,10.0,0,0,['df'],[None],[None],2661,[],"['list', 'len']",2
utilmy/zutil.py:pd_insertdatecol,pd_insertdatecol,function,4,7,7,71,10.14,0,0,"['df', 'col', 'format1=""%Y-%m-%d %H']","[None, None, '']","[None, None, '""%Y-%m-%d %H:%M:%S:%f""']",2666,[],['date_nowtime'],1
utilmy/zutil.py:pd_replacevalues,pd_replacevalues,function,11,14,14,104,7.43,1,0,"['df', 'matrix']","[None, None]","[None, None]",2671,"['    """""" Matrix replaces df.values  """"""\n']",['np.shape'],1
utilmy/zutil.py:pd_removerow,pd_removerow,function,2,2,2,29,14.5,0,0,"['df', 'row_list_index', '45']","[None, None, None]","[None, '(23', None]",2681,[],['df.drop'],1
utilmy/zutil.py:pd_removecol,pd_removecol,function,2,3,3,28,9.33,0,0,"['df1', 'name1']","[None, None]","[None, None]",2685,[],['df1.drop'],1
utilmy/zutil.py:pd_insertrow,pd_insertrow,function,7,11,10,112,10.18,0,0,"['df', 'rowval', 'index1', 'isreset']","[None, None, None, None]","[None, None, 'None', '1']",2689,[],"['pd_array_todataframe', 'df.append']",2
utilmy/zutil.py:pd_h5_cleanbeforesave,pd_h5_cleanbeforesave,function,4,13,11,91,7.0,0,0,['df'],[None],[None],2699,"['    """"""Clean Column type before Saving in HDFS: Unicode, Datetime  """"""\n']","['pd_resetindex', 'pd_str_unicode_tostr']",2
utilmy/zutil.py:pd_h5_addtable,pd_h5_addtable,function,6,16,16,148,9.25,0,1,"['df', 'tablename', 'dbfile=""F']","[None, None, '']","[None, None, '""F:\\temp_pandas.h5""']",2716,[],"['pd.HDFStore', 'find', 'list', 'print', 'store.append', 'store.close']",6
utilmy/zutil.py:pd_h5_tableinfo,pd_h5_tableinfo,function,4,4,4,65,16.25,0,0,"['filenameh5', 'table']","[None, None]","[None, None]",2726,[],"['pd.HDFStore', 'store.get_storer']",2
utilmy/zutil.py:pd_h5_dumpinfo,pd_h5_dumpinfo,function,13,28,26,334,11.93,1,0,"['dbfile=r""E']",[''],"['r""E:\\_data\\stock\\intraday_google.h5""']",2731,[],"['pd.HDFStore', 'list', 'pd.DataFrame', 'extract.append', 'datetime_tostring', 'errsym.append', 'np.array']",7
utilmy/zutil.py:pd_h5_save,pd_h5_save,function,4,5,5,64,12.8,0,0,"['df', 'filenameh5=""E', 'key']","[None, '', None]","[None, '""E:/_data/_data_outlier.h5""', '""data""']",2753,"['    """""" File is release after saving it""""""\n']","['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zutil.py:pd_h5_load,pd_h5_load,function,9,24,20,210,8.75,0,2,"['filenameh5=""E', 'table_id', 'exportype', 'rowstart', 'rowend', ')', '']","['', None, None, None, None, None, None]","['""E:/_data/_data_outlier.h5""', '""data""', '""pandas""', '-1', '-1', None, None]",2760,[],"['pd.read_hdf', 'pd.DataFrame']",2
utilmy/zutil.py:pd_h5_fromcsv_tohdfs,pd_h5_fromcsv_tohdfs,function,29,80,63,661,8.26,3,2,"['dircsv', 'filepattern', 'tofilehdfs', 'tablename', ')', 'dtype0', 'encoding', 'chunksize', 'mode', 'form', 'complib', '']","[None, None, None, None, None, None, None, None, None, None, None, None]","['""dir1/dir2/""', '""*.csv""', '""file1.h5""', '""df""', None, 'None', '""utf-8""', '2000000', '""a""', '""table""', 'None', None]",2780,[],"['os_file_listall', 'pd.HDFStore', 'enumerate', 'pd.read_csv', 'print', 'store.append', 'store.close', 'os_file_exist']",8
utilmy/zutil.py:pd_np_toh5file,pd_np_toh5file,function,6,8,7,82,10.25,0,0,"['numpyarr', 'fileout', 'table1']","[None, None, None]","[None, '""file.h5""', '""data""']",2837,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zutil.py:date_allinfo,date_allinfo,function,0,0,0,0,0.0,0,0,[],[],[],2844,"['    """"""\n', '\n', 'https://aboutsimon.com/blog/2016/08/04/datetime-vs-Arrow-vs-Pendulum-vs-Delorean-vs-udatetime.html\n', '\n', '\n', '   """"""\n']",[],0
utilmy/zutil.py:datetime_tostring,datetime_tostring,function,9,21,15,245,11.67,1,2,['datelist1'],[None],[None],2853,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zutil.py:date_remove_bdays,date_remove_bdays,function,14,36,26,354,9.83,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2866,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zutil.py:date_add_bdays,date_add_bdays,function,14,36,27,353,9.81,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2884,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zutil.py:datenumpy_todatetime,datenumpy_todatetime,function,9,40,24,384,9.6,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",2902,[],['type'],1
utilmy/zutil.py:datetime_tonumpydate,datetime_tonumpydate,function,4,4,4,36,9.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",2919,[],['np.datetime64'],1
utilmy/zutil.py:datestring_todatetime,datestring_todatetime,function,9,16,14,136,8.5,1,1,"['datelist1', 'format1']","[None, None]","[None, '""%Y%m%d""']",2925,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zutil.py:datetime_toint,datetime_toint,function,6,14,12,156,11.14,1,1,['datelist1'],[None],[None],2937,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zutil.py:date_holiday,date_holiday,function,0,0,0,0,0.0,0,0,[],[],[],2946,"['    """"""\n', '   https://jakevdp.github.io/blog/2015/07/23/learning-seattles-work-habits-from-bicycle-counts/\n', '\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'cal = USFederalHolidayCalendar()\n', ""holidays = cal.holidays('2012', '2016', return_name=True)\n"", 'holidays.head()\n', '\n', 'holidays_all = pd.concat([holidays, ""Day Before "" + holidays.shift(-1, \'D\'),  ""Day After ""\n', ""+ holidays.shift(1, 'D')])\n"", 'holidays_all = holidays_all.sort_index()\n', 'holidays_all.head()\n', '\n', 'from pandas.tseries.offsets import CustomBusinessDay\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'bday_us = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n', 'dateref[-1] - bday_us- bday_us\n', '\n', '   """"""\n']",[],0
utilmy/zutil.py:date_add_bday,date_add_bday,function,14,36,27,353,9.81,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2968,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zutil.py:dateint_todatetime,dateint_todatetime,function,7,14,12,136,9.71,1,1,['datelist1'],[None],[None],2983,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zutil.py:date_diffinday,date_diffinday,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",2993,[],['dateint_todatetime'],1
utilmy/zutil.py:date_diffinbday,date_diffinbday,function,7,11,9,112,10.18,0,0,"['intd2', 'intd1']","[None, None]","[None, None]",2998,[],"['dateint_todatetime', 'd1.date', 'd2.date', 'np.busday_count']",4
utilmy/zutil.py:date_gencalendar,date_gencalendar,function,11,16,14,242,15.12,0,0,"['start', 'end', 'country']","[None, None, None]","['""2010-01-01""', '""2010-01-15""', '""us""']",3007,[],"['CustomBusinessDay', 'np.array']",2
utilmy/zutil.py:date_finddateid,date_finddateid,function,3,75,12,447,5.96,0,10,"['date1', 'dateref']","[None, None]","[None, None]",3017,[],['np_findfirst'],1
utilmy/zutil.py:datestring_toint,datestring_toint,function,6,14,12,108,7.71,1,1,['datelist1'],[None],[None],3042,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zutil.py:date_now,date_now,function,14,44,29,401,9.11,0,2,['i'],[None],['0'],3051,[],"['datetime.now', 'date_add_bdays', 'date_remove_bdays', 'str', 'date_nowtime', 'datetime.today', 'd.strftime']",7
utilmy/zutil.py:date_nowtime,date_nowtime,function,8,22,18,208,9.45,0,1,"['type1', 'format1=""%Y-%m-%d %H']","[None, '']","['""str""', '""%Y-%m-%d %H:%M:%S:%f""']",3062,"['    """""" str / stamp /  """"""\n']","['datetime.today', 'd.strftime']",2
utilmy/zutil.py:date_generatedatetime,date_generatedatetime,function,17,32,28,268,8.38,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",3076,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zutil.py:np_numexpr_vec_calc,np_numexpr_vec_calc,function,5,12,12,110,9.17,0,0,[],[],[],3088,[],[],0
utilmy/zutil_features.py:log,log,function,6,30,20,188,6.27,0,2,"['*s', 'n', 'm', '**kw']","[None, None, None, None]","[None, '0', '1', None]",12,[],"['print', 'log2', 'log3']",3
utilmy/zutil_features.py:log2,log2,function,2,7,7,40,5.71,0,1,"['*s', '**kw']","[None, None]","[None, None]",18,[],['print'],1
utilmy/zutil_features.py:log3,log3,function,2,7,7,40,5.71,0,1,"['*s', '**kw']","[None, None]","[None, None]",21,[],['print'],1
utilmy/zutil_features.py:os_get_function_name,os_get_function_name,function,4,4,4,47,11.75,0,0,[],[],[],32,[],['sys._getframe'],1
utilmy/zutil_features.py:os_getcwd,os_getcwd,function,3,6,5,66,11.0,0,0,[],[],[],37,[],[],0
utilmy/zutil_features.py:pa_read_file,pa_read_file,function,38,129,74,709,5.5,2,9,"['path', 'cols', 'n_rows', 'file_start', 'file_end', 'verbose', '']","[None, None, None, None, None, None, None]","[""  'folder_parquet/'"", 'None', '1000', '0', '100000', '1', None]",43,"['    """"""Requied HDFS connection\n', '       http://arrow.apache.org/docs/python/parquet.html\n', '\n', '       conda install libhdfs3 pyarrow\n', '       in your script.py:\n', '        import os\n', ""        os.environ['ARROW_LIBHDFS_DIR'] = '/opt/cloudera/parcels/CDH/lib64/'\n"", '\n', '       https://stackoverflow.com/questions/18123144/missing-server-jvm-java-jre7-bin-server-jvm-dll\n', '\n', '    """"""\n']","['hdfs.ls', 'glob.glob', 'fi.split', 'print', 'pq.read_table', 'arr_table.to_pandas', 'gc.collect', 'pd.concat', 'len', 'dfall.head']",10
utilmy/zutil_features.py:pa_write_file,pa_write_file,function,23,62,45,599,9.66,0,4,"['df', 'path', 'cols', 'n_rows', 'partition_cols', 'overwrite', 'verbose', 'filesystem ']","[None, None, None, None, None, None, None, None]","[None, ""  'folder_parquet/'"", 'None', '1000', 'None', 'True', '1', "" 'hdfs'""]",97,"['    """""" Pandas to HDFS\n', ""      pyarrow.parquet.write_table(table, where, row_group_size=None, version='1.0',\n"", ""      use_dictionary=True, compression='snappy', write_statistics=True, use_deprecated_int96_timestamps=None,\n"", '      coerce_timestamps=None, allow_truncated_timestamps=False, data_page_size=None,\n', ""      flavor=None, filesystem=None, compression_level=None, use_byte_stream_split=False, data_page_version='1.0', **kwargs)\n"", '\n', '      https://arrow.apache.org/docs/python/generated/pyarrow.parquet.write_to_dataset.html#pyarrow.parquet.write_to_dataset\n', '\n', '    """"""\n']","['hdfs.rm', 'hdfs.mkdir', 'pq.write_to_dataset', 'hdfs.ls', 'print', 'os.removedirs', 'os.makedirs', 'os.listdir']",8
utilmy/zutil_features.py:test_get_classification_data,test_get_classification_data,function,20,44,40,470,10.68,1,0,['name'],[None],['None'],143,[],"['make_classification', 'range', 'pd.DataFrame', 'np.arange', 'len', 'dfX.set_index', 'dfy.set_index']",7
utilmy/zutil_features.py:params_check,params_check,function,7,56,26,259,4.62,1,5,"['pars', 'check_list', 'name']","[None, None, None]","[None, None, '""""']",160,"['    """"""\n', '      Validate a dict parans\n', '    :param pars:\n', '    :param check_list:\n', '    :param name:\n', '    :return:\n', '    """"""\n']","['isinstance', 'Exception']",2
utilmy/zutil_features.py:save_features,save_features,function,7,30,26,275,9.17,0,2,"['df', 'name', 'path']","[None, None, None]","[None, None, 'None']",186,"['    """""" Save dataframe on disk\n', '    :param df:\n', '    :param name:\n', '    :param path:\n', '    :return:\n', '    """"""\n']","['os.makedirs', 'isinstance', 'log', 'list', 'df0.to_parquet']",5
utilmy/zutil_features.py:load_features,load_features,function,3,10,9,110,11.0,0,0,"['name', 'path']","[None, None]","[None, None]",206,[],"['pd.read_parquet', 'log']",2
utilmy/zutil_features.py:save_list,save_list,function,8,21,20,166,7.9,1,0,"['path', 'name_list', 'glob']","[None, None, None]","[None, None, None]",214,[],"['os.makedirs', 'log', 'pickle.dump', 'open']",4
utilmy/zutil_features.py:save,save,function,7,30,26,275,9.17,0,2,"['df', 'name', 'path']","[None, None, None]","[None, None, 'None']",221,"['  """"""\n', '      Read file in parallel from disk : very Fast\n', '  :param path_glob:\n', '  :param ignore_index:\n', '  :param cols:\n', '  :param verbose:\n', '  :param nrows:\n', '  :param concat_sort:\n', '  :param n_pool:\n', '  :param drop_duplicates:\n', '  :param shop_id:\n', '  :param kw:\n', '  :return:\n', '  """"""\n']","['os.makedirs', 'isinstance', 'log', 'list', 'df0.to_parquet']",5
utilmy/zutil_features.py:load,load,function,3,10,9,110,11.0,0,0,"['name', 'path']","[None, None]","[None, None]",228,"['  """"""\n', '      Read file in parallel from disk : very Fast\n', '  :param path_glob:\n', '  :param ignore_index:\n', '  :param cols:\n', '  :param verbose:\n', '  :param nrows:\n', '  :param concat_sort:\n', '  :param n_pool:\n', '  :param drop_duplicates:\n', '  :param shop_id:\n', '  :param kw:\n', '  :return:\n', '  """"""\n']","['pd.read_parquet', 'log']",2
utilmy/zutil_features.py:pd_read_file,pd_read_file,function,52,161,100,1083,6.73,3,10,"['path_glob', 'ignore_index', 'cols', 'verbose', 'nrows', 'concat_sort', 'n_pool', 'drop_duplicates', 'col_filter', 'col_filter_val', '**kw']","[None, None, None, None, None, None, None, None, None, None, None]","['""*.pkl""', 'True', 'None', 'False', '-1', 'True', '1', 'None', 'None', 'None', None]",233,"['  """"""\n', '      Read file in parallel from disk : very Fast\n', '  :param path_glob:\n', '  :param ignore_index:\n', '  :param cols:\n', '  :param verbose:\n', '  :param nrows:\n', '  :param concat_sort:\n', '  :param n_pool:\n', '  :param drop_duplicates:\n', '  :param shop_id:\n', '  :param kw:\n', '  :return:\n', '  """"""\n']","['ThreadPool', 'glob.glob', 'pd.DataFrame', 'len', 'log', 'range', 'job_list.append', 'pool.apply_async', 'dfi.drop_duplicates', 'gc.collect', 'pd.concat']",11
utilmy/zutil_features.py:load_dataset,load_dataset,function,35,207,126,1727,8.34,3,11,"['path_data_x', 'path_data_y', 'colid', 'n_sample']","[None, None, None, None]","[None, ""''"", '""jobId""', '-1']",300,"['    """"""\n', '      return a datraframe\n', '      https://raw.github.com/someguy/brilliant/master/somefile.txt\n', '\n', '    :param path_data_x:\n', '    :param path_data_y:\n', '    :param colid:\n', '    :param n_sample:\n', '    :return:\n', '    """"""\n']","['log', 'fetch_spark_koalas', 'fetch_dataset', 'glob.glob', 'ntpath.dirname', 'ntpath.basename', 'len', 'print', 'pd.read_csv', 'fi.endswith', 'pd.read_parquet', 'pd.read_pickle', 'pd.concat', 'df.head', 'list', 'np.arange', 'df.set_index', 'pd_read_file', 'dfy.head', 'df.join']",20
utilmy/zutil_features.py:fetch_spark_koalas,fetch_spark_koalas,function,9,11,11,109,9.91,0,0,"['path_data_x', 'path_data_y', 'colid', 'n_sample']","[None, None, None, None]","[None, ""''"", '""jobId""', '-1']",378,[],"['path_data_x.replace', 'ks.read_parquet']",2
utilmy/zutil_features.py:fetch_dataset,fetch_dataset,function,52,177,125,1978,11.18,1,6,"['url_dataset', 'path_target', 'file_target']","[None, None, None]","[None, 'None', 'None']",386,"['    """"""Fetch dataset from a given URL and save it.\n', '\n', '    Currently `github`, `gdrive` and `dropbox` are the only supported sources of\n', '    data. Also only zip files are supported.\n', '\n', '    :param url_dataset:   URL to send\n', '    :param path_target:   Path to save dataset\n', '    :param file_target:   File to save dataset\n', '\n', '    """"""\n']","['log', 'mkdtemp', 'pathlib.Path', 'mktemp', 'url_dataset.replace', 'urlx.replace', 'urlpath.split', 'os.makedirs', 'requests.Session', 's.get', 'print', 'open', 'f.write', 'res.raise_for_status', 'urlparse', 'parse_qs', 'download_googledrive', 'download_dtopbox', 'os.listdir', 'os.unlink', 'os.link']",21
utilmy/zutil_features.py:load_function_uri,load_function_uri,function,25,66,59,691,10.47,0,0,"['uri_name=""myfolder/myfile.py']",[''],"['""myfolder/myfile.py::myFunction""']",491,"['    """"""\n', '    #load dynamically function from URI pattern\n', '    #""dataset""        : ""mlmodels.preprocess.generic:pandasDataset""\n', '    ###### External File processor :\n', '    #""dataset""        : ""MyFolder/preprocess/myfile.py:pandasDataset""\n', '    """"""\n']","['uri_name.split', 'len', 'package_path.replace', 'getattr', 'str', 'log', 'Path', 'NameError']",8
utilmy/zutil_features.py:metrics_eval,metrics_eval,function,23,71,52,902,12.7,2,3,"['metric_list', 'ytrue', 'ypred', 'ypred_proba', 'return_dict']","[None, None, None, None, None]","['[""mean_squared_error""]', 'None', 'None', 'None', 'False']",531,"['    """"""\n', '      Generic metrics calculation, using sklearn naming pattern\n', '    """"""\n']","['len', 'isinstance', 'getattr', 'range', 'mval_.append', 'np.mean', 'np.sqrt', 'metric_scorer', 'pd.DataFrame']",9
utilmy/zutil_features.py:pd_stat_dataset_shift,pd_stat_dataset_shift,function,14,24,23,328,13.67,1,0,"['dftrain', 'dftest', 'colused', 'nsample', 'buckets', 'axis']","[None, None, None, None, None, None]","[None, None, None, '10000', '5', '0']",572,[],"['print', 'pd_stat_datashift_psi', 'pd.DataFrame']",3
utilmy/zutil_features.py:pd_stat_datashift_psi,pd_stat_datashift_psi,function,25,122,83,1188,9.74,1,5,"['expected', 'actual', 'buckettype', 'buckets', 'axis']","[None, None, None, None, None]","[None, None, ""'bins'"", '10', '0']",588,"[""    '''Calculate the PSI (population stability index) across all variables\n"", '    Args:\n', '       expected: numpy matrix of original values\n', '       actual: numpy matrix of new values, same size as expected\n', '       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n', '       buckets: number of quantiles to use in bucketing variables\n', '       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n', '    Returns:\n', '       psi_values: ndarray of psi values for each variable\n', ""    '''\n""]","['psi', 'scale_range', 'np.max', 'np.arange', 'np.min', 'np.stack', 'np.histogram', 'len', 'sub_psi', 'np.log', 'np.sum', 'range', 'np.empty']",13
utilmy/zutil_features.py:feature_importance_perm,feature_importance_perm,function,31,57,54,761,13.35,1,1,"['clf', 'Xtrain', 'ytrain', 'cols', 'n_repeats', 'scoring', 'show_graph']","[None, None, None, None, None, None, None]","[None, None, None, None, '8', ""'neg_root_mean_squared_error'"", '1']",660,[],"['permutation_importance', 'list', 'pd.DataFrame', 'np.arange', 'min', 'len', 'plt.subplots', 'ax1.boxplot', 'ax1.set_yticklabels', 'ax1.set_ylim', 'fig.tight_layout', 'plt.show']",12
utilmy/zutil_features.py:feature_selection_multicolinear,feature_selection_multicolinear,function,25,44,36,510,11.59,3,0,"['df', 'threshold']","[None, None]","[None, '1.0']",694,[],"['list', 'spearmanr', 'hierarchy.ward', 'hierarchy.fcluster', 'defaultdict', 'enumerate', 'cluster_id_to_feature_ids.values']",7
utilmy/zutil_features.py:feature_correlation_cat,feature_correlation_cat,function,24,45,41,582,12.93,0,0,"['df', 'colused']","[None, None]","[None, None]",712,[],"['plt.subplots', 'spearmanr', 'hierarchy.ward', 'hierarchy.dendrogram', 'np.arange', 'len', 'ax2.imshow', 'ax2.set_xticks', 'ax2.set_yticks', 'ax2.set_xticklabels', 'ax2.set_yticklabels', 'fig.tight_layout', 'plt.show']",13
utilmy/zutil_features.py:pd_feature_generate_cross,pd_feature_generate_cross,function,33,70,59,485,6.93,2,2,"['df', 'cols', 'cols_cross_input', 'pct_threshold', 'm_combination']","[None, None, None, None, None]","[None, None, 'None', '0.2', '2']",735,"['    """"""\n', '       Generate Xi.Xj features and filter based on stats threshold\n', '    """"""\n']","['len', 'itertools.combinations', 'range', 'y.sum', 'col_cross.append']",5
utilmy/zutil_features.py:pd_col_to_onehot,pd_col_to_onehot,function,20,94,61,616,6.55,3,6,"['dfref', 'colname', 'colonehot', 'return_val']","[None, None, None, None]","[None, 'None', 'None', '""dataframe,column""']",770,"['    """"""\n', '    :param df:\n', '    :param colname:\n', '    :param colonehot: previous one hot columns\n', '    :param returncol:\n', '    :return:\n', '    """"""\n']","['copy.deepcopy', 'list', 'len', 'print', 'pd.concat', 'pd.get_dummies', 'coladded.append']",7
utilmy/zutil_features.py:pd_colcat_mergecol,pd_colcat_mergecol,function,17,41,32,255,6.22,2,1,"['df', 'col_list', 'x0', 'colid']","[None, None, None, None]","[None, None, None, '""easy_id""']",813,"['    """"""\n', '       Merge category onehot column\n', '    :param df:\n', '    :param l:\n', '    :param x0:\n', '    :return:\n', '    """"""\n']","['pd.DataFrame', 't.rfind', 'int', 'print', 'dfz.set_index']",5
utilmy/zutil_features.py:pd_colcat_tonum,pd_colcat_tonum,function,21,62,43,534,8.61,1,4,"['df', 'colcat', 'drop_single_label', 'drop_fact_dict']","[None, None, None, None]","[None, '""all""', 'False', 'True']",837,"['    """"""\n', '    Encoding a data-set with mixed data (numerical and categorical) to a numerical-only data-set,\n', '    using the following logic:\n', '    * categorical with only a single value will be marked as zero (or dropped, if requested)\n', '    * categorical with two values will be replaced with the result of Pandas `factorize`\n', '    * categorical with more than two values will be replaced with the result of Pandas `get_dummies`\n', '    * numerical columns will not be modified\n', '    **Returns:** DataFrame or (DataFrame, dict). If `drop_fact_dict` is True, returns the encoded DataFrame.\n', '    else, returns a tuple of the encoded DataFrame and dictionary, where each key is a two-value column, and the\n', '    value is the original labels, as supplied by Pandas `factorize`. Will be empty if no two-value columns are\n', '    present in the data-set\n', '    Parameters\n', '    ----------\n', '    df : NumPy ndarray / Pandas DataFrame\n', '        The data-set to encode\n', '    colcat : sequence / string\n', ""        A sequence of the nominal (categorical) columns in the dataset. If string, must be 'all' to state that\n"", ""        all columns are nominal. If None, nothing happens. Default: 'all'\n"", '    drop_single_label : Boolean, default = False\n', '        If True, nominal columns with a only a single value will be dropped.\n', '    drop_fact_dict : Boolean, default = True\n', '        If True, the return value will be the encoded DataFrame alone. If False, it will be a tuple of\n', '        the DataFrame and the dictionary of the binary factorization (originating from pd.factorize)\n', '    """"""\n']","['pd.DataFrame', 'dict', 'pd.unique', 'len', 'pd.factorize', 'pd.get_dummies', 'pd.concat']",7
utilmy/zutil_features.py:pd_colcat_mapping,pd_colcat_mapping,function,9,35,20,271,7.74,4,0,"['df', 'colname']","[None, None]","[None, None]",889,"['    """"""\n', '       map category to integers\n', '    :param df:\n', '    :param colname:\n', '    :return:\n', '    """"""\n']",['enumerate'],1
utilmy/zutil_features.py:pd_colcat_toint,pd_colcat_toint,function,28,78,50,628,8.05,4,2,"['dfref', 'colname', 'colcat_map', 'suffix']","[None, None, None, None]","[None, None, 'None', 'None']",909,[],"['isinstance', 'pd.DataFrame', 'print', 'ddict.get', 'colname_new.append', 'enumerate']",6
utilmy/zutil_features.py:pd_colnum_tocat,pd_colnum_tocat,function,42,147,98,1134,7.71,2,6,"['df', 'colname', 'colexclude', 'colbinmap', 'bins', 'suffix', 'method', 'na_value', 'return_val', 'params={""KMeans_n_clusters""', '""KMeans_init""', '""KMeans_n_init""']","[None, None, None, None, None, None, None, None, None, '', "" 'k-means++'"", ' 10,""KMeans_max_iter"": 300, ""KMeans_tol"": 0.0001, ""KMeans_precompute_distances"": \'auto\',""KMeans_verbose"": 0, ""KMeans_random_state"": None,""KMeans_copy_x"": True, ""KMeans_n_jobs"": None, ""KMeans_algorithm"": \'auto\'}']","[None, 'None', 'None', 'None', '5', '""_bin""', '""uniform""', '-1', '""dataframe,param""', '{""KMeans_n_clusters"": 8', None, None]",948,"['    """"""\n', '    colbinmap = for each column, definition of bins\n', '    https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n', '       :param df:\n', '       :param method:\n', '       :return:\n', '    """"""\n']","['list', 'OrderedDict', 'bin_create', 'dfc.min', 'dfc.max', 'range', 'bin_create_quantile', 'np.arange', 'dfc.quantile', 'print', 'colbinmap.get', 'len', 'pd.cut', 'df.groupby', 'colnew.append']",15
utilmy/zutil_features.py:pd_colnum_normalize,pd_colnum_normalize,function,29,134,64,840,6.27,3,6,"['df0', 'colname', 'pars', 'suffix', 'return_val']","[None, None, None, None, None]","[None, None, None, '""_norm""', ""'dataframe,param'""]",1039,"['    """"""\n', '    :param df:\n', '    :param colnum_log:\n', '    :param colproba:\n', '    :return:\n', '    """"""\n']","['np.log', 'max', 'min', 'log', 'list']",5
utilmy/zutil_features.py:pd_col_merge_onehot,pd_col_merge_onehot,function,11,26,20,136,5.23,2,1,"['df', 'colname']","[None, None]","[None, None]",1085,"['    """"""\n', '      Merge columns into single (hotn\n', '    :param df:\n', '    :param colname:\n', '    :return :\n', '    """"""\n']","['t[len', 'len', 'merge_array.append']",3
utilmy/zutil_features.py:pd_col_to_num,pd_col_to_num,function,9,27,24,184,6.81,1,0,"['df', 'colname', 'default']","[None, None, None]","[None, 'None', 'np.nan']",1102,[],"['to_float', 'float', 'list']",3
utilmy/zutil_features.py:pd_col_filter,pd_col_filter,function,12,28,23,186,6.64,1,2,"['df', 'filter_val', 'iscol']","[None, None, None]","[None, 'None', '1']",1115,"['    """"""\n', '   # Remove Columns where Index Value is not in the filter_value\n', ""   # filter1= X_client['client_id'].values\n"", '   :param df:\n', '   :param filter_val:\n', '   :param iscol:\n', '   :return:\n', '   """"""\n']","['col_delete.append', 'df.drop']",2
utilmy/zutil_features.py:pd_col_fillna,pd_col_fillna,function,22,70,49,586,8.37,1,6,"['dfref', 'colname', 'method', 'value', 'colgroupby', 'return_val', '']","[None, None, None, None, None, None, None]","[None, 'None', '""frequent""', 'None', 'None', '""dataframe,param""', None]",1134,"['    """"""\n', '    Function to fill NaNs with a specific value in certain columns\n', '    Arguments:\n', '        df:            dataframe\n', '        colname:      list of columns to remove text\n', '        value:         value to replace NaNs with\n', '    Returns:\n', '        df:            new dataframe with filled values\n', '    """"""\n']","['list', 'df.groupby', 'print']",3
utilmy/zutil_features.py:pd_pipeline_apply,pd_pipeline_apply,function,8,29,22,259,8.93,1,0,"['df', 'pipeline']","[None, None]","[None, None]",1180,"['    """"""\n', '      pipe_preprocess_colnum = [\n', '      (pd_col_to_num, {""val"": ""?"", })\n', '    , (pd_colnum_tocat, {""colname"": None, ""colbinmap"": colnum_binmap, \'bins\': 5,\n', '                         ""method"": ""uniform"", ""suffix"": ""_bin"",\n', '                         ""return_val"": ""dataframe""})\n', '    , (pd_col_to_onehot, {""colname"": None, ""colonehot"": colnum_onehot,\n', '                          ""return_val"": ""dataframe""})\n', '      ]\n', '    :param df:\n', '    :param pipeline:\n', '    :return:\n', '    """"""\n']","['copy.deepcopy', 'enumerate', 'print', 'str']",4
utilmy/zutil_features.py:pd_stat_correl_pair,pd_stat_correl_pair,function,12,33,30,316,9.58,1,1,"['df', 'coltarget', 'colname']","[None, None, None]","[None, 'None', 'None']",1204,"['    """"""\n', '      Genearte correletion between the column and target column\n', '      df represents the dataframe comprising the column and colname comprising the target column\n', '    :param df:\n', '    :param colname: list of columns\n', '    :param coltarget : target column\n', '    :return:\n', '    """"""\n']","['list', 'target_corr.append', 'pd.DataFrame', 'len']",4
utilmy/zutil_features.py:pd_stat_pandas_profile,pd_stat_pandas_profile,function,7,9,8,175,19.44,0,0,"['df', 'savefile', 'title']","[None, None, None]","[None, '""report.html""', '""Pandas Profile""']",1225,"['    """""" Describe the tables\n', '        #Pandas-Profiling 2.0.0\n', '        df.profile_report()\n', '    """"""\n']","['print', 'df.profile_report', 'profile.to_file', 'profile.get_rejected_variables']",4
utilmy/zutil_features.py:pd_stat_distribution_colnum,pd_stat_distribution_colnum,function,23,84,72,646,7.69,1,3,"['df', 'nrows', 'verbose']","[None, None, None]","[None, '2000', 'False']",1238,"['    """""" Stats the tables\n', '    """"""\n']","['df.sample', 'getstat', 'str', 'len', 'pd.DataFrame', 'pd.concat', 'print', 'np.arange']",8
utilmy/zutil_features.py:pd_stat_histogram,pd_stat_histogram,function,8,19,18,210,11.05,0,0,"['df', 'bins', 'coltarget']","[None, None, None]","[None, '50', '""diff""']",1278,"['    """"""\n', '    :param df:\n', '    :param bins:\n', '    :param coltarget:\n', '    :return:\n', '    """"""\n']","['np.histogram', 'pd.DataFrame']",2
utilmy/zutil_features.py:col_extractname,col_extractname,function,7,37,23,207,5.59,1,5,['col_onehot'],[None],[None],1293,"['    """"""\n', '    Column extraction from onehot name\n', '    :param col_onehot\n', '    :return:\n', '    """"""\n']","['len', 'colnew.append']",2
utilmy/zutil_features.py:col_remove,col_remove,function,12,42,26,214,5.1,3,4,"['cols', 'colsremove', 'mode']","[None, None, None]","[None, None, '""exact""']",1316,"['    """"""\n', '    """"""\n']","['cols.remove', 'cols3.append']",2
utilmy/zutil_features.py:pd_colnum_tocat_stat,pd_colnum_tocat_stat,function,53,152,107,1986,13.07,1,5,"['df', 'feature', 'target_col', 'bins', 'cuts']","[None, None, None, None, None]","[None, None, None, None, '0']",1341,"['    """"""\n', '    Bins continuous features into equal sample size buckets and returns the target mean in each bucket. Separates out\n', '    nulls into another bucket.\n', '    :param df: dataframe containg features and target column\n', '    :param feature: feature column name\n', '    :param target_col: target column\n', '    :param bins: Number bins required\n', '    :param cuts: if buckets of certain specific cuts are required. Used on test data to use cuts from train.\n', '    :return: If cuts are passed only df_grouped data is returned, else cuts and df_grouped data is returned\n', '    """"""\n']","['pd.isnull', 'df.reset_index', 'min', 'range', 'np.percentile', 'cuts.append', 'pd.cut', 'df.groupby', 'df_grouped.reset_index', 'list', 'df_grouped.rename', 'str', 'len', 'pd.concat']",14
utilmy/zutil_features.py:pd_stat_shift_trend_changes,pd_stat_shift_trend_changes,function,20,41,35,660,16.1,0,0,"['df', 'feature', 'target_col', 'threshold']","[None, None, None, None]","[None, None, None, '0.03']",1410,"['    """"""\n', '    Calculates number of times the trend of feature wrt target changed direction.\n', '    :param df: df_grouped dataset\n', '    :param feature: feature column name\n', '    :param target_col: target column\n', '    :param threshold: minimum % difference required to count as trend change\n', '    :return: number of trend chagnes for the feature\n', '    """"""\n']","['target_diffs.fillna', 'target_diffs.divide', 'target_diffs_norm.diff', 'target_diffs_lvl2.fillna', 'int']",5
utilmy/zutil_features.py:pd_stat_shift_trend_correlation,pd_stat_shift_trend_correlation,function,19,63,55,788,12.51,0,2,"['df', 'df_test', 'colname', 'target_col']","[None, None, None, None]","[None, None, None, None]",1434,"['    """"""\n', '    Calculates correlation between train and test trend of colname wrt target.\n', '    :param df: train df data\n', '    :param df_test: test df data\n', '    :param colname: colname column name\n', '    :param target_col: target column name\n', '    :return: trend correlation between train and test\n', '    """"""\n']","['df.merge', 'pd.isnull', 'len', 'np.corrcoef', 'print']",5
utilmy/zutil_features.py:pd_stat_shift_changes,pd_stat_shift_changes,function,33,99,81,1236,12.48,1,4,"['df', 'target_col', 'features_list', 'bins', 'df_test']","[None, None, None, None, None]","[None, None, '0', '10', '0']",1465,"['    """"""\n', '    Calculates trend changes and correlation between train/test for list of features\n', '    :param df: dfframe containing features and target columns\n', '    :param target_col: target column name\n', '    :param features_list: by default creates plots for all features. If list passed, creates plots of only those features.\n', '    :param bins: number of bins to be created from continuous colname\n', '    :param df_test: test df which has to be compared with input df for correlation\n', '    :return: dfframe with trend changes and trend correlation (if test df passed)\n', '    """"""\n']","['type', 'list', 'features_list.remove', 'ignored.append', 'pd_colnum_tocat_stat', 'pd_stat_shift_trend_correlation', 'pd_stat_shift_changes', 'stats_all.append', 'pd.DataFrame', 'len', 'print', 'str']",12
utilmy/zutil_features.py:np_conv_to_one_col,np_conv_to_one_col,function,5,11,10,137,12.45,0,0,"['np_array', 'sep_char']","[None, None]","[None, '""_""']",1510,"['    """"""\n', '    converts string/numeric columns to one string column\n', '    :param np_array: the numpy array with more than one column\n', '    :param sep_char: the separator character\n', '    """"""\n']","['row2string', 'sep_char.join']",2
utilmy/zutil_features.py:dict2,dict2,class,3,5,5,36,7.2,0,0,[],[],[],28,[],[],0
utilmy/zutil_features.py:dict2:__init__,dict2:__init__,method,2,2,2,15,7.5,0,0,"['self', 'd']","[None, None]","[None, None]",29,[],[],0
utilmy/configs/util_config.py:log,log,function,2,5,4,54,10.8,0,0,['*s'],[None],[None],23,[],"['print', 'loge']",2
utilmy/configs/util_config.py:loge,loge,function,1,2,2,20,10.0,0,0,['*s'],[None],[None],27,[],['print'],1
utilmy/configs/util_config.py:config_load,config_load,function,31,124,88,1231,9.93,0,5,"['config_path', 'path_default', 'config_default', 'save_default', 'to_dataclass', '']","[' str ', ' str ', ' dict ', ' bool ', ' bool ', None]","[' None', ' None', ' None', ' False', ' True', None]",32,"['    """"""Load Config file into a dict\n', '    1) load config_path\n', '    2) If not, load in USER/.myconfig/.config.yaml\n', '    3) If not, create default save in USER/.myconfig/.config.yaml\n', '    Args:\n', ""        config_path:   path of config or 'default' tag value\n"", '        path_default : path of default config\n', '        config_default: dict value of default config\n', '        save_default: save default config on disk\n', '    Returns: dict config\n', '    """"""\n']","['log', 'pathlib.Path', 'yaml.safe_load', 'json.loads', 'SafeConfigParser', 'cfg.read', 'toml.loads', 'Exception', 'Box', 'os.makedirs', 'open', 'yaml.dump']",12
utilmy/configs/util_config.py:config_isvalid_yamlschema,config_isvalid_yamlschema,function,6,21,20,242,11.52,0,1,"['config_dict', 'schema_path', 'silent']","[' dict', ' str ', ' bool ']","[None, "" 'config_val.yaml'"", ' False']",105,"['    """"""Validate using a  yaml file\n', '    Args:\n', '        config_dict:\n', '        schema_path:\n', '        silent:\n', '    Returns: True/False\n', '    """"""\n']","['schema.validate', 'result.isValid', 'yamale.YamaleError', 'loge']",4
utilmy/configs/util_config.py:config_isvalid_pydantic,config_isvalid_pydantic,function,2,9,8,56,6.22,0,0,"['config_dict', 'pydanctic_schema', 'silent']","[' dict', ' str ', ' bool ']","[None, "" 'config_py.yaml'"", ' False']",129,"['    """"""Validate using a pydantic files\n', '    Args:\n', '        config_dict:\n', '        pydanctic_schema:\n', '        silent:\n', '    Returns: True/False\n', '    """"""\n']",[],0
utilmy/configs/util_config.py:convert_yaml_to_box,convert_yaml_to_box,function,6,8,8,57,7.12,0,0,['yaml_path'],[' str'],[None],147,[],"['open', 'yaml.load', 'Box']",3
utilmy/configs/util_config.py:convert_dict_to_pydantic,convert_dict_to_pydantic,function,10,13,13,253,19.46,0,0,"['config_dict', 'schema_name']","[' dict', ' str']","[None, None]",153,[],"['SchemaGen', 'generated.to_file', 'importlib.import_module', 'pydantic_module.MainSchema']",4
utilmy/configs/util_config.py:pydantic_model_generator,pydantic_model_generator,function,8,34,32,299,8.79,0,0,"['input_file', 'str]', 'input_file_type', 'output_file', '**kwargs', '']","[' Union[Path', None, None, ' Path', None, None]","[None, None, None, None, None, None]",166,"['    """"""\n', '    Args:\n', '        input_file:\n', '        input_file_type:\n', '        output_file:\n', '        **kwargs:\n', '\n', '    Returns:\n', '    # https://github.com/koxudaxi/datamodel-code-generator\n', '    # pip install datamodel-code-generator\n', '\n', '    """"""\n']","['generate', 'loge', 'log']",3
utilmy/configs/util_config.py:test_yamlschema,test_yamlschema,function,5,6,6,104,17.33,0,0,[],[],[],200,[],"['config_load', 'config_isvalid_yamlschema', 'log']",3
utilmy/configs/util_config.py:test_pydanticgenrator,test_pydanticgenrator,function,6,26,20,373,14.35,0,0,[],[],[],206,[],"['pydantic_model_generator', 'Path']",2
utilmy/configs/util_config.py:test4,test4,function,5,8,8,155,19.38,0,0,[],[],[],221,[],"['config_load', 'convert_dict_to_pydantic', 'isinstance']",3
utilmy/configs/util_config.py:test_example,test_example,function,1,2,2,6,3.0,0,0,[],[],[],227,[],[],0
utilmy/docs/code_parser.py:export_stats_pertype,export_stats_pertype,function,9,46,22,381,8.28,0,4,"['in_path', 'type', 'out_path']","['str', 'str', 'str']","['None', 'None', 'None']",55,"['    """"""\n', '        python code_parser.py type <in_path> <type> <out_path>\n', '    Returns:\n', '\n', '    """"""\n']","['get_list_function_stats', 'print', 'df.to_csv', 'get_list_class_stats', 'get_list_method_stats']",5
utilmy/docs/code_parser.py:export_stats_perfile,export_stats_perfile,function,8,36,16,336,9.33,0,3,"['in_path', 'out_path']","['str', 'str']","['None', 'None']",81,"['    """"""\n', '        python code_parser.py  export_stats_perfile <in_path> <out_path>\n', '\n', '    Returns:\n', '\n', '    """"""\n']","['get_list_function_stats', 'print', 'df.to_csv', 'get_list_class_stats', 'get_list_method_stats']",5
utilmy/docs/code_parser.py:export_stats_perrepo_txt,export_stats_perrepo_txt,function,1,4,4,59,14.75,0,0,"['in_path', 'out_path', 'repo_name']","['str', 'str', 'str']","['None', 'None', 'None']",105,"['    """"""\n', '        python code_parser.py  repo_txt   parser/test3    parser/output/output_repo.csv\n', '\n', '    Returns:\n', '        1  txt file\n', '    """"""\n']",['export_stats_perrepo'],1
utilmy/docs/code_parser.py:export_stats_perrepo,export_stats_perrepo,function,31,235,87,2231,9.49,5,15,"['in_path', 'out_path', 'repo_name']","['str', 'str', 'str']","['None', 'None', 'None']",115,[],"['export_stats_perrepo', 'glob.glob', 'range', 'get_list_function_stats', 'print', 'open', 'f.write', 'x.replace', 'df.to_csv', 'df.iterrows', 'zip', 'get_list_class_stats', 'get_list_method_stats']",13
utilmy/docs/code_parser.py:export_stats_repolink_txt,export_stats_repolink_txt,function,1,3,3,52,17.33,0,0,"['repo_link', 'out_path']","[' str', 'str']","[None, 'None']",202,"['    """"""\n', '        python code_parser.py repo_url_txt https://github.com/lucidrains/DALLE-pytorch.git docs/test_example1.csv\n', '\n', '    Returns:\n', '        1  txt   --->  data info detail\n', '    """"""\n']",['export_stats_repolink'],1
utilmy/docs/code_parser.py:export_stats_repolink,export_stats_repolink,function,9,39,35,479,12.28,0,2,"['repo_link', 'out_path']","[' str', 'str']","[None, 'None']",212,[],"['export_stats_repolink', 'repo_link.split', 'shutil.rmtree', 'print', 'os.system', 'export_stats_perrepo']",6
utilmy/docs/code_parser.py:export_call_graph_url,export_call_graph_url,function,6,17,16,219,12.88,0,1,"['repo_link', 'out_path']","[' str', 'str']","[None, 'None']",238,"['    """"""\n', '        python code_parser.py  export_call_graph_url <repo_link> <out_path>\n', '    Returns:\n', '        1  csv output\n', '    """"""\n']","['repo_link.split', 'print', 'os.system', 'export_call_graph']",4
utilmy/docs/code_parser.py:export_call_graph,export_call_graph,function,34,220,93,2216,10.07,9,8,"['repo_link', 'out_path']","[' str', 'str']","[None, 'None']",256,[],"['repo_link.split', 'print', 'os.system', 'export_call_graph', 'glob.glob', 'range', 'get_list_class_stats', 'zip', 'list_classes.append', 'get_list_function_stats', 'get_list_imported_func', 'get_list_import_class_as', 'open', 'f.write', 'write_to_file', 'get_list_method_stats']",16
utilmy/docs/code_parser.py:get_list_function_name,get_list_function_name,function,17,27,26,352,13.04,1,1,['file_path'],[None],[None],366,"['    """"""The function use to get all functions of the python file\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: list_functions   - List all python functions in the input file\n', '    Example Output:\n', ""        ['func1', 'func2']\n"", '    """"""\n']","['_get_all_line', '_get_and_clean_all_lines', 'list', 're.match', 'line.rstrip', 're_response.group', 'all_lines.index', 'list_functions.append']",8
utilmy/docs/code_parser.py:get_list_class_name,get_list_class_name,function,17,27,26,347,12.85,1,1,['file_path'],[None],[None],388,"['    """"""The function use to get all classes of the python file\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: list_classes     - List all python classes in the input file\n', '    Example Output:\n', ""        ['Class1', 'Class1']\n"", '    """"""\n']","['_get_all_line', '_get_and_clean_all_lines', 'list', 're.match', 'line.rstrip', 're_response.group', 'all_lines.index', 'list_classes.append']",8
utilmy/docs/code_parser.py:get_list_class_methods,get_list_class_methods,function,26,42,37,620,14.76,2,1,['file_path'],[None],[None],413,"['    """"""The function use to get all classes and all methods in this class of the python file\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: An array of class info [{dict}, {dict}, ...]\n', '    Example Output:\n', '    [\n', '        {""class_name"": ""Class1"", ""listMethods"": [""method1"", ""method2"", ""method3""]},\n', '        {""class_name"": ""Class2"", ""listMethods"": [""method4"", ""method5"", ""method6""]},\n', '    ]\n', '    """"""\n']","['_get_all_line', '_get_and_clean_all_lines', 'get_list_class_name', '_get_all_lines_in_class', 're.match', 'line.rstrip', 're_response.group', 'all_lines.index', 'list_names.append']",9
utilmy/docs/code_parser.py:get_list_variable_global,get_list_variable_global,function,12,26,24,357,13.73,1,2,['file_path'],[None],[None],445,"['    """"""The function use to get all global variable of the python file\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: list_var         - Array of all global variable\n', '    Example Output:\n', ""        ['Var1', 'Var2']\n"", '    """"""\n']","['_get_and_clean_all_lines', 're.match', 'line.rstrip', 'list_var.append', 'list']",5
utilmy/docs/code_parser.py:_get_docs,_get_docs,function,12,77,32,669,8.69,1,6,"['all_lines', 'index_1', 'func_lines']","[None, None, None]","[None, None, None]",467,[],"['line.strip', 'len', 'response.append']",3
utilmy/docs/code_parser.py:get_list_function_info,get_list_function_info,function,29,55,48,787,14.31,2,0,['file_path'],[None],[None],507,"['    """"""The function use to get functions stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Array of functions, lines of the function, and variable in function\n', '    Example Output:\n', '        [\n', '            {""name"": ""function_name1"", ""lines"": 20, ""variables"": [""a"", ""b"", ""c""]},\n', '            {""name"": ""function_name2"", ""lines"": 30, ""variables"": []},\n', '        ]\n', '    """"""\n']","['_get_all_line', '_get_and_clean_all_lines', 'get_list_function_name', '_get_all_lines_in_function', 'len', '_get_function_stats', '_get_docs', '_get_all_lines_define_function', '_get_define_function_stats', 'output.append']",10
utilmy/docs/code_parser.py:get_list_class_info,get_list_class_info,function,20,49,42,584,11.92,2,0,['file_path'],[None],[None],545,"['    """"""The class use to get functions stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Array of functions, lines of the function, and variable in function\n', '    Example Output:\n', '        [\n', '            {""function"": ""function_name1"", ""lines"": 20, ""variables"": [""a"", ""b"", ""c""]},\n', '            {""function"": ""function_name2"", ""lines"": 30, ""variables"": []},\n', '        ]\n', '    """"""\n']","['_get_and_clean_all_lines', 'get_list_class_name', '_get_all_lines_in_class', 'len', '_get_function_stats', 'output.append']",6
utilmy/docs/code_parser.py:get_list_method_info,get_list_method_info,function,35,65,54,966,14.86,3,0,['file_path'],[None],[None],581,"['    """"""get_list_method_info\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Array of methods in class\n', '    Example Output:\n', '        [\n', '            {""function"": ""function_name1"", ""lines"": 20, ""variables"": [""a"", ""b"", ""c""]},\n', '            {""function"": ""function_name2"", ""lines"": 30, ""variables"": []},\n', '        ]\n', '    """"""\n']","['_get_all_line', '_get_and_clean_all_lines', 'get_list_class_methods', '_get_all_lines_in_class', '_get_all_lines_in_function', 'len', '_get_function_stats', '_get_docs', '_get_all_lines_define_function', '_get_define_function_stats', 'output.append']",11
utilmy/docs/code_parser.py:get_list_method_stats,get_list_method_stats,function,6,12,11,148,12.33,0,1,['file_path'],[None],[None],623,"['    """"""The function use to get methods stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Dataframe with bellow fields\n', '            uri:   path1/path2/filename.py:function1\n', '            name: function1\n', '            n_lines\n', '            n_words\n', '            n_words_unqiue\n', '            n_characters\n', '            avg_char_per_word = n_charaecter / n_words\n', '            n_loop  : nb of for, while loop\n', '            n_ifthen  : nb of if_then\n', '        \n', '        **** return None if no function in file\n', '    Example Output:\n', '                                                    uri                                               name    type  n_variable  n_words  n_words_unique  n_characters  avg_char_per_word  n_loop  n_ifthen\n', '    0   d:/Project/job/test2/zz936/parser/test/keys.py...                              VerifyingKey:__init__  method           2       11              11           100           9.090909       0         1      \n', '    1   d:/Project/job/test2/zz936/parser/test/keys.py...                     VerifyingKey:from_public_point  method          10       13              12           185          14.230769       0         0      \n', '    2   d:/Project/job/test2/zz936/parser/test/keys.py...                           VerifyingKey:from_string  method          17       45              39           504          11.200000       0         1      \n', '    3   d:/Project/job/test2/zz936/parser/test/keys.py...                              VerifyingKey:from_pem  method           2        2               2            39          19.500000       0         0      \n', '    4   d:/Project/job/test2/zz936/parser/test/keys.py...                              VerifyingKey:from_der  method          19       64              38           683          10.671875       0         3      \n', '    5   d:/Project/job/test2/zz936/parser/test/keys.py...              VerifyingKey:from_public_key_recovery  method           4        8               8           137          17.125000       0         0      \n', '    6   d:/Project/job/test2/zz936/parser/test/keys.py...  VerifyingKey:from_public_key_recovery_with_digest  method          13       24              23           288          12.000000       0         0      \n', '    7   d:/Project/job/test2/zz936/parser/test/keys.py...                             VerifyingKey:to_string  method           6       11               8           145          13.181818       0         0      \n', '    8   d:/Project/job/test2/zz936/parser/test/keys.py...                                VerifyingKey:to_pem  method           2        4               4            42          10.500000       0         0  \n', '    """"""\n']","['get_list_method_info', 'get_stats']",2
utilmy/docs/code_parser.py:get_list_class_stats,get_list_class_stats,function,6,12,11,147,12.25,0,1,['file_path'],[None],[None],659,"['    """"""The class use to get functions stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Dataframe with bellow fields\n', '            uri:   path1/path2/filename.py:function1\n', '            name: function1\n', '            n_lines\n', '            n_words\n', '            n_words_unqiue\n', '            n_characters\n', '            avg_char_per_word = n_charaecter / n_words\n', '            n_loop  : nb of for, while loop\n', '            n_ifthen  : nb of if_then\n', '        \n', '        **** return None if no function in file\n', '    Example Output:\n', '                                                    uri               name   type  n_variable  n_words  n_words_unique  n_characters  avg_char_per_word  n_loop  n_ifthen\n', '    0  d:/Project/job/test2/zz936/parser/test/keys.py...  BadSignatureError  class           0        1               1             4           4.000000       0         0\n', '    1  d:/Project/job/test2/zz936/parser/test/keys.py...     BadDigestError  class           0        1               1             4           4.000000       0         0\n', '    2  d:/Project/job/test2/zz936/parser/test/keys.py...       VerifyingKey  class          84      301             189          3584          11.906977       0         7\n', '    3  d:/Project/job/test2/zz936/parser/test/keys.py...         SigningKey  class         138      482             310          4615           9.574689       3         9\n', '    """"""\n']","['get_list_class_info', 'get_stats']",2
utilmy/docs/code_parser.py:get_list_function_stats,get_list_function_stats,function,6,12,11,150,12.5,0,1,['file_path'],[None],[None],690,"['    """"""The function use to get functions stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Dataframe with bellow fields\n', '            uri:   path1/path2/filename.py:function1\n', '            name: function1\n', '            n_lines\n', '            n_words\n', '            n_words_unqiue\n', '            n_characters\n', '            avg_char_per_word = n_charaecter / n_words\n', '            n_loop  : nb of for, while loop\n', '            n_ifthen  : nb of if_then\n', '        \n', '        **** return None if no function in file\n', '    Example Output:\n', '            uri                                 name  n_variable  n_words  n_words_unique  n_characters  avg_char_per_word  n_loop  n_ifthen\n', '        0   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...     prepare_target_and_clean_up_test           8       92              32           535           5.815217       0         0\n', '        1   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...                 clean_up_config_test           6       55              19           241           4.381818       0         1\n', '        2   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...         check_default_network_config          22      388              74           955           2.461340       1         5\n', '        3   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...                     check_module_env           9      250              54           553           2.212000       1         1\n', '        4   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...     provision_certificates_to_target           7      101              29           384           3.801980       0         3\n', '        5   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...            config_session_connection           2       14               8            97           6.928571       0         0\n', '        6   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...  config_cipher_suite_and_tcps_action           8      101              30           335           3.316832       0         3\n', '    """"""\n']","['get_list_function_info', 'get_stats']",2
utilmy/docs/code_parser.py:get_stats,get_stats,function,19,84,52,808,9.62,0,0,"['df', 'file_path']","['pd.DataFrame', 'str']","[None, None]",726,"['    """""" Calculate stats from datafaframe\n', '    Args:\n', '        df: pandas DataFrame\n', '\n', '    Returns:\n', '        pandas DataFrame\n', '\n', '    """"""\n']","['len', 'df.apply', '_get_words', '_get_avg_char_per_word', '_get_functions']",5
utilmy/docs/code_parser.py:get_file_stats,get_file_stats,function,11,21,19,244,11.62,1,0,['file_path'],[None],[None],759,"['    """"""The function use to get file stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Dict of file stars\n', '    Example Output:\n', '        {\n', '            ""total_functions"": 22,\n', '            ""avg_lines"" : 110.2,\n', '            ""total_class"": 3\n', '        }\n', '    """"""\n']","['get_list_function_stats', 'len', 'avg_lines/len']",3
utilmy/docs/code_parser.py:get_list_imported_func,get_list_imported_func,function,13,44,30,467,10.61,2,3,['file_path'],[' str'],[None],782,"['    """"""Get list funtions was imported in python file.\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: List function\n', '    Example Output:\n', '        [\n', ""            {'func1': 'zc.Class'},\n"", ""            {'func2': 'Hola'}\n"", '        ]\n', '    """"""\n']","['dict', '_get_and_clean_all_lines', 're.search', 'line.rstrip', 'line.split', 'functions.split']",6
utilmy/docs/code_parser.py:get_list_import_class_as,get_list_import_class_as,function,18,41,37,463,11.29,1,1,['file_path'],[' str'],[None],816,"['    """"""Get list funtions was imported in python file.\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: List function\n', '    Example Output:\n', '        [\n', ""            {'class': 'zc.Class'},\n"", ""            {'class': 'Hola'}\n"", '        ]\n', '    """"""\n']","['dict', '_get_and_clean_all_lines', 're.match', 'line.rstrip', 'print', 'line.split', 'importlib.import_module']",7
utilmy/docs/code_parser.py:_get_words,_get_words,function,6,23,21,154,6.7,1,1,['row'],[None],[None],853,[],[],0
utilmy/docs/code_parser.py:_get_functions,_get_functions,function,10,32,26,389,12.16,1,2,['row'],[None],[None],863,[],"['re.match', 'list_funcs.append', 'list', 'return']",4
utilmy/docs/code_parser.py:_get_avg_char_per_word,_get_avg_char_per_word,function,1,9,9,76,8.44,0,0,['row'],[None],[None],883,[],[],0
utilmy/docs/code_parser.py:_validate_file,_validate_file,function,5,34,18,227,6.68,0,3,['file_path'],[None],[None],887,"['    """"""Check if the file is existed and it\'s a python file\n', '    """"""\n']",['print'],1
utilmy/docs/code_parser.py:_clean_data,_clean_data,function,10,75,27,699,9.32,3,9,['array'],[None],[None],902,"['    """"""Remove empty lines and comment lines start with #\n', '    """"""\n']","['array.copy', '_remove_empty_line', '_remmove_commemt_line', 'response.remove', 'response.copy', 'line.strip', 'len']",7
utilmy/docs/code_parser.py:_remove_empty_line,_remove_empty_line,function,2,7,7,37,5.29,0,1,['line'],[None],[None],945,[],['line.strip'],1
utilmy/docs/code_parser.py:_remmove_commemt_line,_remmove_commemt_line,function,2,17,14,97,5.71,0,1,['line'],[None],[None],949,[],['line.strip'],1
utilmy/docs/code_parser.py:_get_and_clean_all_lines,_get_and_clean_all_lines,function,5,11,8,124,11.27,0,1,['file_path'],[None],[None],955,"['    """"""Prepare all lines of the file\n', '    """"""\n']","['_validate_file', '_get_all_line', '_clean_data']",3
utilmy/docs/code_parser.py:_get_all_line,_get_all_line,function,33,247,85,2442,9.89,7,17,['file_path'],[None],[None],965,[],"['open', '_get_all_lines_in_function', 'array.copy', 're.match', 'line.rstrip', 'response.remove', 'len', 'range', 'list', 'list_lines.append', '_get_all_lines_in_class', '_get_all_lines_define_function']",12
utilmy/docs/code_parser.py:_get_all_lines_in_function,_get_all_lines_in_function,function,21,87,52,810,9.31,3,7,"['function_name', 'array', 'indentMethod']","[None, None, None]","[None, None, ""''""]",971,"['    """"""The function use to get all lines of the function\n', '    Args:\n', '        IN: function_name - name of the function will be used to get all line\n', '        IN: array         - list all lines of the file have this input function\n', '        OUT: list_lines   - Array of all line of this function\n', '        OUT: indent       - The indent of this function (this will be used for another calculation)\n', '    """"""\n']","['array.copy', 're.match', 'line.rstrip', 'response.remove', 'len', 'range', 'list', 'list_lines.append']",8
utilmy/docs/code_parser.py:_get_all_lines_in_class,_get_all_lines_in_class,function,16,71,46,670,9.44,2,4,"['class_name', 'array']","[None, None]","[None, None]",1023,"['    """"""The function use to get all lines of the class\n', '    Args:\n', '        IN: class_name    - name of the class will be used to get all line\n', '        IN: array         - list all lines of the file have this input class\n', '        OUT: list_lines   - Array of all line of this class\n', '    """"""\n']","['array.copy', 're.match', 'line.rstrip', 'response.remove', 'len', 'list', 'list_lines.append']",7
utilmy/docs/code_parser.py:_get_all_lines_define_function,_get_all_lines_define_function,function,20,71,46,687,9.68,2,6,"['function_name', 'array', 'indentMethod']","[None, None, None]","[None, None, ""''""]",1065,"['    """"""The function use to get all lines define_function\n', '    Args:\n', '        IN: function_name - name of the function will be used to get all line\n', '        IN: array         - list all lines of the file have this input function\n', '        OUT: list_lines   - Array of all line used to define the function\n', '        OUT: indent       - The indent of this function (this will be used for another calculation)\n', '    """"""\n']","['list', 'array.copy', 're.match', 'line.rstrip', 'response.remove', 'len', 'list_lines.append', 'range']",8
utilmy/docs/code_parser.py:_get_define_function_stats,_get_define_function_stats,function,24,145,71,1337,9.22,4,8,['array'],[None],[None],1109,"['    """"""The function use to get define function stats: arg_name, arg_type, arg_value\n', '    Args:\n', '        IN: array         - list all lines of function to get variables\n', '        OUT: function stats: arg_name, arg_type, arg_value\n', '    """"""\n']","['len', 'line.strip', 'print', 'i.start', 're.finditer', 'range', 'data.split', 'arg.replace', 'arg.strip', 'arg.find', 'arg_name.append', 'arg_type.append', 'arg_value.append']",13
utilmy/docs/code_parser.py:_get_function_stats,_get_function_stats,function,16,206,105,1958,9.5,4,11,"['array', 'indent']","[None, None]","[None, None]",1170,"['    """"""The function use to get all lines of the function\n', '    Args:\n', '        IN: indent        - indent string\n', '        IN: array         - list all lines of function to get variables\n', '        OUT: list_var     - Array of all variables\n', '    """"""\n']","['array.copy', 'check_array.copy', 'line.rstrip', 'check_array.remove', 'line.split', 're.match', 'list_var.append', 'list']",8
utilmy/docs/code_parser.py:write_to_file,write_to_file,function,25,163,71,1808,11.09,1,8,"['uri', 'type', 'list_functions', 'list_classes', 'list_imported', 'dict_functions', 'list_class_as', 'out_path']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",1259,[],"['importlib.import_module', 'function.split', 'print', 'open', 'f.write']",5
utilmy/docs/code_parser.py:test_example,test_example,function,3,7,7,233,33.29,0,0,[],[],[],1338,[],"['export_stats_pertype', 'export_stats_perfile', 'export_stats_perrepo']",3
utilmy/docs/generate_doc.py:markdown_create_function,markdown_create_function,function,21,81,65,768,9.48,2,0,"['uri', 'name', 'type', 'args_name', 'args_type', 'args_value', 'start_line', 'list_docs', 'prefix']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, '""""']",22,[],"['uri.split', 'literal_eval', 'zip', 'rsp.format']",4
utilmy/docs/generate_doc.py:markdown_create_file,markdown_create_file,function,1,2,2,7,3.5,0,0,"['list_info', 'prefix']","[None, None]","[None, ""''""]",58,[],[],0
utilmy/docs/test.py:log,log,function,3,10,9,81,8.1,0,0,['data'],[None],[None],20,[],"['open', 'f.write', 'str']",3
utilmy/docs/test.py:list_buy_price,list_buy_price,function,8,32,28,256,8.0,1,1,"['start', 'bottom', 'delta']","[None, None, None]","[None, None, None]",27,[],"['while', 'list_output.insert', 'round', 'log', 'list']",5
utilmy/docs/test.py:calculateSellPrice,calculateSellPrice,function,2,3,3,40,13.33,0,0,"['enter', 'profit']","[None, None]","[None, None]",42,[],['round'],1
utilmy/docs/test.py:list_sell_price,list_sell_price,function,8,32,28,248,7.75,1,1,"['start', 'top', 'delta']","[None, None, None]","[None, None, None]",46,[],"['while', 'list_output.insert', 'round', 'log', 'list']",5
utilmy/docs/test.py:calculateBuyPrice,calculateBuyPrice,function,2,3,3,40,13.33,0,0,"['enter', 'profit']","[None, None]","[None, None]",61,[],['round'],1
utilmy/docs/test.py:get_list_price,get_list_price,function,19,151,84,1833,12.14,4,9,[],[],[],69,[],"['list_buy_price', 'str', 'print', 'gInfoTradingUp[str', 'calculateSellPrice', 'len', 'float', 'list_sell_price', 'gInfoTradingDown[str', 'calculateBuyPrice', 'threading.Timer', 't.start']",12
utilmy/docs/test.py:trading_up,trading_up,function,28,178,97,2240,12.58,1,11,[],[],[],144,[],"['exchange.fetch_orders', 'print', 'exchange.create_order', 'log', 'str', 'threading.Timer', 't.start']",7
utilmy/docs/test.py:trading_down,trading_down,function,28,175,95,2315,13.23,1,11,[],[],[],218,[],"['exchange.fetch_orders', 'print', 'exchange.create_order', 'log', 'str', 'threading.Timer', 't.start']",7
utilmy/docs/test.py:update_price,update_price,function,5,8,8,89,11.12,0,0,[],[],[],289,[],"['threading.Timer', 't.start']",2
utilmy/logs/test_log.py:test1,test1,function,17,28,28,206,7.36,0,0,[],[],[],9,[],"['log3', 'log2', 'log', 'logw', 'logc', 'logr', 'loge']",7
utilmy/logs/test_log.py:test2,test2,function,19,35,34,331,9.46,0,0,[],[],[],28,[],"['print', 'util_log.logger_setup', 'log3', 'log2', 'log', 'logw', 'logc', 'logr', 'loge']",9
utilmy/logs/test_log.py:test_launch_server,test_launch_server,function,12,16,16,155,9.69,0,0,[],[],[],81,"[""\t'''\n"", '\tServer code from loguru.readthedocs.io\n', '\tUse to test network logging\n', '\n', '     python   test.py test_launch_server\n', '\n', '\n', ""\t'''\n""]",['socketserver.TCPServer'],1
utilmy/logs/test_log.py:test_server,test_server,function,19,35,34,337,9.63,0,0,[],[],[],95,[],"['print', 'util_log.logger_setup', 'log3', 'log2', 'log', 'logw', 'logc', 'logr', 'loge']",9
utilmy/logs/test_log.py:LoggingStreamHandler,LoggingStreamHandler,class,13,34,28,381,11.21,2,1,[],[],[],65,[],[],0
utilmy/logs/test_log.py:LoggingStreamHandler:handle,LoggingStreamHandler:handle,method,12,32,26,364,11.38,2,1,['self'],[None],[None],66,[],"['len', 'struct.unpack', 'pickle.loads', 'json.loads', 'logger.patch', 'record.update']",6
utilmy/logs/util_log.py:logger_setup,logger_setup,function,33,105,82,1013,9.65,2,3,"['log_config_path', 'log_template', '**kwargs']","[' str ', ' str ', None]","[' None', ' ""default""', None]",34,"['    """""" Generic Logging setup\n', '      Overide logging using loguru setup\n', '      1) Custom config from log_config_path .yaml file\n', '      2) Use shortname log, log2, logw, loge for logging output\n', '\n', '    Args:\n', '        log_config_path:\n', '        template_name:\n', '        **kwargs:\n', '    Returns:None\n', '\n', '    TODO:\n', '\n', '\n', '    """"""\n']","['open', 'yaml.safe_load', 'print', 'cfg.pop', 'globals_.pop', 'int', 'SocketHandler', 'handler.get', 'handler.items', 'handler.update', 'logger.configure', 'logger.level']",12
utilmy/logs/util_log.py:log,log,function,33,105,82,1013,9.65,2,3,"['log_config_path', 'log_template', '**kwargs']","[' str ', ' str ', None]","[' None', ' ""default""', None]",115,[],"['open', 'yaml.safe_load', 'print', 'cfg.pop', 'globals_.pop', 'int', 'SocketHandler', 'handler.get', 'handler.items', 'handler.update', 'logger.configure', 'logger.level']",12
utilmy/logs/util_log.py:log2,log2,function,1,6,6,62,10.33,0,0,['*s'],[None],[None],119,[],['logger.opt'],1
utilmy/logs/util_log.py:log3,log3,function,1,6,6,64,10.67,0,0,['*s)'],['  ### Debuggine level 2depth'],"['1, lazy=True).log(""DEBUG_2"", "","".join([str(t) for t in s]))*s):']",123,[],['logger.opt'],1
utilmy/logs/util_log.py:logw,logw,function,1,6,6,64,10.67,0,0,['*s'],[None],[None],128,[],['logger.opt'],1
utilmy/logs/util_log.py:logc,logc,function,1,6,6,65,10.83,0,0,['*s'],[None],[None],132,[],['logger.opt'],1
utilmy/logs/util_log.py:loge,loge,function,1,6,6,66,11.0,0,0,['*s'],[None],[None],136,[],['logger.opt'],1
utilmy/logs/util_log.py:logr,logr,function,1,6,6,62,10.33,0,0,['*s'],[None],[None],140,[],['logger.opt'],1
utilmy/logs/util_log.py:test,test,function,8,18,18,151,8.39,0,0,[],[],[],145,[],"['log3', 'log2', 'log', 'logw', 'loge', 'logc', 'logr']",7
utilmy/logs/util_log.py:z_logger_stdout_override,z_logger_stdout_override,function,18,36,33,384,10.67,1,0,[],[],[],162,"['    """""" Redirect stdout --> logger\n', '    Returns:\n', '    """"""\n']","['__init__', 'write', 'buffer.rstrip', 'logger.opt', 'line.rstrip', 'flush', 'logger.remove', 'logger.add', 'StreamToLogger', 'contextlib.redirect_stdout', 'print']",11
utilmy/logs/util_log.py:z_logger_custom_1,z_logger_custom_1,function,38,110,92,1250,11.36,2,1,[],[],[],187,[],"['InterceptHandler', 'emit', 'logger.level', 'str', 'logging.currentframe', 'logger.opt', 'record.getMessage', 'format_record', 'pformat', 'setup_logging', 'logging.getLogger', 'logger.configure']",12
utilmy/templates/cli.py:run_cli,run_cli,function,9,30,23,332,11.07,0,2,[],[],[],5,"['    """""" USage\n', '    \n', '    template  copy  --repo_dir utilmy/\n', '    """"""\n']","['argparse.ArgumentParser', 'add', 'p.parse_args', 'template_show', 'template_copy']",5
utilmy/templates/cli.py:template_show,template_show,function,7,9,9,115,12.78,0,0,[],[],[],26,[],"['os.walk', 'print']",2
utilmy/templates/cli.py:template_copy,template_copy,function,12,26,22,249,9.58,0,0,"['name', 'out_dir']","[None, None]","[None, None]",33,[],"['os_copy', 'print', 'Path']",3
utilmy/viz/embedding.py:log,log,function,1,2,2,23,11.5,0,0,['*s'],[None],[None],38,[],['print'],1
utilmy/viz/toptoolbar.py:TopToolbar,TopToolbar,class,35,67,55,571,8.52,0,2,[],[],[],4,[],[],0
utilmy/viz/vizhtml.py:log,log,function,1,2,2,20,10.0,0,0,['*s'],[None],[None],23,[],['print'],1
utilmy/viz/vizhtml.py:test_getdata,test_getdata,function,14,38,34,669,17.61,1,1,['verbose'],[None],['True'],29,"['    """"""\n', '    data = test_get_data()\n', ""    df   = data['housing.csv']\n"", '    df.head(3)\n', '    https://github.com/szrlee/Stock-Time-Series-Analysis/tree/master/data\n', '    """"""\n']","['url.split', 'print', 'pd.read_csv']",3
utilmy/viz/vizhtml.py:test1,test1,function,60,278,175,3222,11.59,0,5,[],[],[],57,[],"['htmlDoc', 'vi.test2', 'pretty_html_table.build_table', 'random.randint', 'html_code.replace', 'pd_plot_tseries_matplot', 'mpld3.fig_to_html', 'pd_plot_tseries_highcharts', 'plot_histogram', 'pd_plot_histogram_matplot', 'self.fig_to_html', 'pd_plot_histogram_highcharts', 'plot_scatter', 'pd_plot_scatter_matplot', 'pd_plot_scatter_highcharts', 'images_dir', 'images_to_html', 'pd_plot_network']",18
utilmy/viz/vizhtml.py:pd_plot_tseries_highcharts,pd_plot_tseries_highcharts,function,35,218,133,1815,8.33,2,1,"['df', 'coldate', 'date_format', 'cols_axe1', 'cols_axe2', 'figsize', 'title', 'x_label', 'axe1_label', 'axe2_label', 'cfg', 'mode', 'save_img']","[None, 'str', 'str', 'list ', 'list ', 'tuple ', 'str', 'str', 'str', 'str', 'dict', None, None]","[None, 'None', ""'%m/%d/%Y'"", '[]', '[]', '  None', 'None', 'None', 'None', 'None', '{}', ""'d3'"", '""""']",872,"[""    '''\n"", '        function to return highchart json cord for time_series.\n', '        input parameter\n', '        df : panda dataframe on which you want to apply time_series\n', '        cols_axe1: column name for y-axis one\n', '        cols_axe2: column name for y-axis second\n', '        x_label : label of x-axis\n', '        cols_axe1_label : label for yaxis 1\n', '        cols_axe2_label : label for yaxis 2\n', '        date_format : %m for moth , %d for day and %Y for Year.\n', ""    '''\n""]","['Box', 'cc.get', 'str', 'pd.to_datetime', 'Highchart', 'H.set_dict_options', 'float', 'range', 'H.add_data_set', 'H.buildcontent']",10
utilmy/viz/vizhtml.py:pd_plot_histogram_highcharts,pd_plot_histogram_highcharts,function,25,128,97,1201,9.38,0,0,"['df', 'colname', 'binsNumber', 'binWidth', 'title', 'xaxis_label', 'yaxis_label', 'cfg', 'mode', 'save_img', 'show']","['pd.DataFrame', 'str', None, None, 'str', 'str', 'str', 'dict', None, None, None]","[None, 'None', 'None', 'None', '""""', ' ""x-axis""', '""y-axis""', '{}', ""'d3'"", '""""', 'False']",967,"[""    ''' function to return highchart json code for histogram.\n"", '        input parameter\n', '        df : panda dataframe on which you want to apply histogram\n', '        colname : column name from dataframe in which histogram will apply\n', '        xaxis_label: label for x-axis\n', '        yaxis_label: label for y-axis\n', '        binsNumber: Number of bin in bistogram.\n', '        binWidth : width of each bin in histogram\n', '        title : title of histogram\n', '        cols_axe2_label : label for yaxis 2\n', '        date_format : %m for moth , %d for day and %Y for Year.\n', '\n', ""        df        = data['housing.csv']\n"", '        html_code = pd_plot_histogram_hcharts(df,colname=""median_income"",xaxis_label= ""x-axis"",yaxis_label=""y-axis"",cfg={}, mode=\'d3\', save_img=False)\n', '        # highcharts_show_chart(html_code)\n', ""    '''\n""]","['Box', 'cc.get', 'str']",3
utilmy/viz/vizhtml.py:html_show_chart_highchart,html_show_chart_highchart,function,14,19,17,194,10.21,0,1,"['html_code', 'verbose']","[None, None]","[None, 'True']",1061,[],"['Highchart', 'hc.buildhtmlheader', 'print', 'display']",4
utilmy/viz/vizhtml.py:html_show,html_show,function,15,28,21,300,10.71,0,1,"['html_code', 'verbose']","[None, None]","[None, 'True']",1074,[],"['Highchart', 'hc.buildhtmlheader', 'print', 'display', 'html_show']",5
utilmy/viz/vizhtml.py:images_to_html,images_to_html,function,22,43,36,343,7.98,1,1,"['dir_input', 'title', 'verbose']","[None, None, None]","['""*.png""', '""""', 'False']",1084,"['    """"""\n', '        images_to_html( model_path + ""/graph_shop_17_past/*.png"" , model_path + ""shop_17.html"" )\n', '    """"""\n']","['glob.glob', 'flist.sorted', 'print', 'open', 'fp2.read', 'base64.b64encode']",6
utilmy/viz/vizhtml.py:pd_plot_network,pd_plot_network,function,50,136,104,1484,10.91,3,4,"['df', 'cola', 'colb', 'coledge', 'colweight', 'html_code']","['pd.DataFrame', ' str', ' str', ' str', ' str', 'bool ']","[None, ""'col_node1'"", ""'col_node2'"", ""'col_edge'"", '""weight""', ' True']",1109,"['    """"""\n', '        https://pyviz.org/tools.html\n', '    """"""\n']","['convert_to_networkx', 'nx.Graph', 'df.iterrows', 'g.add_edge', 'nx.draw', 'draw_graph', 'net.Network', 'networkx_graph.nodes', 'pyvis_graph.add_node', 'networkx_graph.edges', 'pyvis_graph.add_edge', 'str', 'pyvis_graph.show_buttons', 'pyvis_graph.show', 'extract_text', 're.findall', 'open', 'f.read']",18
utilmy/viz/vizhtml.py:help_get_codesource,help_get_codesource,function,7,15,14,177,11.8,0,0,['func'],[None],[None],1230,"['    """""" Using the magic method __doc__, we KNOW the size of the docstring.\n', '        We then, just substract this from the total length of the function\n', '    """"""\n']","['len', 'inspect.getsourcelines']",2
utilmy/viz/vizhtml.py:zz_test_get_random_data,zz_test_get_random_data,function,10,38,30,290,7.63,1,0,['n'],[None],['100'],1260,[],"['pd.DataFrame', 'size=len']",2
utilmy/viz/vizhtml.py:zz_pd_plot_histogram_highcharts_old,zz_pd_plot_histogram_highcharts_old,function,19,64,56,539,8.42,0,0,"['df', 'col', 'figsize', 'title', 'cfg', 'mode', 'save_img']","[None, None, None, None, 'dict', None, None]","[None, None, 'None', 'None', '{}', ""'d3'"", ""''""]",1274,[],"['Box', 'cc.get', 'np.histogram', 'range', 'hist.tolist', 'pd_plot_histogram_highcharts_base']",6
utilmy/viz/zvizhtml2.py:log,log,function,1,2,2,20,10.0,0,0,['*s'],[None],[None],21,[],['print'],1
utilmy/viz/zvizhtml2.py:test_getdata,test_getdata,function,14,38,34,669,17.61,1,1,['verbose'],[None],['True'],27,"['    """"""\n', '    data = test_get_data()\n', ""    df   = data['housing.csv']\n"", '    df.head(3)\n', '\n', '    https://github.com/szrlee/Stock-Time-Series-Analysis/tree/master/data\n', '    """"""\n']","['url.split', 'print', 'pd.read_csv']",3
utilmy/viz/zvizhtml2.py:test1,test1,function,57,244,157,2843,11.65,0,5,[],[],[],56,[],"['htmlDoc', 'vi.test2', 'pretty_html_table.build_table', 'random.randint', 'html_code.replace', 'pd_plot_tseries_matplot', 'mpld3.fig_to_html', 'pd_plot_tseries_highcharts', 'plot_histogram', 'pd_plot_histogram_matplot', 'self.fig_to_html', 'pd_plot_histogram_highcharts', 'plot_scatter', 'pd_plot_scatter_matplot', 'pd_plot_scatter_highcharts']",15
utilmy/viz/zvizhtml2.py:pd_plot_tseries_highcharts,pd_plot_tseries_highcharts,function,33,204,125,1714,8.4,2,1,"['df', 'coldate', 'date_format', 'cols_axe1', 'cols_axe2', 'figsize', 'title', 'x_label', 'axe1_label', 'axe2_label', 'cfg', 'mode', 'save_img']","[None, 'str', None, None, None, None, None, None, None, None, 'dict', None, None]","[None, 'None', ""'%m/%d/%Y'"", '[]', '[]', 'None', 'None', 'None', 'None', 'None', '{}', ""'d3'"", '""""']",864,"[""    '''\n"", '        function to return highchart json cord for time_series.\n', '        input parameter\n', '        df : panda dataframe on which you want to apply time_series\n', '        cols_axe1: column name for y-axis one\n', '        cols_axe2: column name for y-axis second\n', '        x_label : label of x-axis\n', '        cols_axe1_label : label for yaxis 1\n', '        cols_axe2_label : label for yaxis 2\n', '        date_format : %m for moth , %d for day and %Y for Year.\n', ""    '''\n""]","['Box', 'cc.get', 'str', 'pd.to_datetime', 'Highchart', 'H.set_dict_options', 'float', 'range', 'H.add_data_set', 'H.buildcontent']",10
utilmy/viz/zvizhtml2.py:pd_plot_histogram_highcharts,pd_plot_histogram_highcharts,function,25,128,97,1201,9.38,0,0,"['df', 'colname', 'binsNumber', 'binWidth', 'title', 'xaxis_label', 'yaxis_label', 'cfg', 'mode', 'save_img', 'show']","['pd.DataFrame', ' str', None, None, ' str', ' str', ' str', 'dict', None, None, None]","[None, 'None', 'None', 'None', '""""', ' ""x-axis""', '""y-axis""', '{}', ""'d3'"", '""""', 'False']",960,"[""    ''' function to return highchart json code for histogram.\n"", '\n', ""        df        = data['housing.csv']\n"", '        html_code = pd_plot_histogram_hcharts(df,colname=""median_income"",xaxis_label= ""x-axis"",yaxis_label=""y-axis"",cfg={}, mode=\'d3\', save_img=False)\n', '        # highcharts_show_chart(html_code)\n', '\n', '        input parameter\n', '        df : panda dataframe on which you want to apply histogram\n', '        colname : column name from dataframe in which histogram will apply\n', '        xaxis_label: label for x-axis\n', '        yaxis_label: label for y-axis\n', '        binsNumber: Number of bin in bistogram.\n', '        binWidth : width of each bin in histogram\n', '        title : title of histogram\n', '        cols_axe2_label : label for yaxis 2\n', '        date_format : %m for moth , %d for day and %Y for Year.\n', ""    '''\n""]","['Box', 'cc.get', 'str']",3
utilmy/viz/zvizhtml2.py:html_show_chart_highchart,html_show_chart_highchart,function,14,19,17,194,10.21,0,1,"['html_code', 'verbose']","[None, None]","[None, 'True']",1055,[],"['Highchart', 'hc.buildhtmlheader', 'print', 'display']",4
utilmy/viz/zvizhtml2.py:html_show,html_show,function,15,28,21,300,10.71,0,1,"['html_code', 'verbose']","[None, None]","[None, 'True']",1068,[],"['Highchart', 'hc.buildhtmlheader', 'print', 'display', 'html_show']",5
utilmy/viz/zvizhtml2.py:images_to_html,images_to_html,function,22,43,36,343,7.98,1,1,"['dir_input', 'title', 'verbose']","[None, None, None]","['""*.png""', '""""', 'False']",1078,"['    """"""\n', '        images_to_html( model_path + ""/graph_shop_17_past/*.png"" , model_path + ""shop_17.html"" )\n', '    """"""\n']","['glob.glob', 'flist.sorted', 'print', 'open', 'fp2.read', 'base64.b64encode']",6
utilmy/viz/zvizhtml2.py:pd_plot_network,pd_plot_network,function,49,134,103,1475,11.01,3,4,"['df', 'cola', 'colb', 'coledge', 'colweight', 'html_code']","['pd.DataFrame', ' str', ' str', ' str', ' str', 'bool ']","[None, ""'col_node1'"", ""'col_node2'"", ""'col_edge'"", '""weight""', ' True']",1103,"['    """"""\n', '        https://pyviz.org/tools.html\n', '    """"""\n']","['convert_to_networkx', 'nx.Graph', 'df.iterrows', 'g.add_edge', 'nx.draw', 'draw_graph', 'net.Network', 'networkx_graph.nodes', 'pyvis_graph.add_node', 'networkx_graph.edges', 'pyvis_graph.add_edge', 'str', 'pyvis_graph.show_buttons', 'pyvis_graph.show', 'extract_text', 're.findall', 'open', 'f.read']",18
utilmy/viz/zvizhtml2.py:help,help,function,35,128,101,1009,7.88,2,1,[],[],[],1248,[],"['pd_plot_tseries_highcharts', 'highcharts_show_chart', 'vi.test_getdata', 'vi.htmlDoc', 'doc.h1', 'doc.hr', 'doc.br', 'doc.h2', 'range', 'len', 'doc.plot_tseries', 'doc.table', 'doc.save', 'doc.open_browser', 'Box', 'cc.get']",16
utilmy/zarchive/allmodule.py:pprint,pprint,function,10,32,23,378,11.81,0,1,"['table1', 'tablefmt']","[None, None]","[None, '""simple""']",34,"[' """"""To print nice column headers, supply the second argument (`headers`):\n', '      - `headers` can be an explicit list of column headers\n', '      - if `headers=""firstrow""`, then the first row of data is used\n', '      - if `headers=""keys""`, then dictionary keys or column indices are used\n', '    print(tabulate([[1, 2.34], [-56, ""8.999""], [""2"", ""10001""]]))\n', '  """"""\n']","['isinstance', 'tabulate', 'pprint2', 'pprint.PrettyPrinter', 'pp.pprint']",5
utilmy/zarchive/allmodule.py:pprint2,pprint2,function,5,5,5,59,11.8,0,0,['x'],[None],[None],51,"[""  '''import pprint\n"", ""     stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']\n"", 'stuff.insert(0, stuff[:])\n', 'pp = pprint.PrettyPrinter(indent=4)\n', 'pp.pprint(ALLDB)\n', ""  '''\n""]","['pprint.PrettyPrinter', 'pp.pprint']",2
utilmy/zarchive/allmodule.py:str_convert_beforeprint,str_convert_beforeprint,function,2,2,2,23,11.5,0,0,['x'],[None],[None],64,"[""  ''' #Before writing/output to printer put in utf-8 '''\n""]",['x.encode'],1
utilmy/zarchive/allmodule.py:str_to_utf8,str_to_utf8,function,2,2,2,23,11.5,0,0,['x'],[None],[None],69,"[""  ''' #Before writing/output to printer put in utf-8 '''\n""]",['x.encode'],1
utilmy/zarchive/allmodule.py:str_to_unicode,str_to_unicode,function,4,16,12,98,6.12,0,2,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",74,"[""  ''' #After Loading Text from CSV ---> Immediately in unicode '''\n""]","['isinstance', 'unicode']",2
utilmy/zarchive/coke_functions.py:date_diffsecond,date_diffsecond,function,4,8,7,71,8.88,0,0,"['str_t1', 'str_t0', ""fmt='YYYY-MM-DD HH""]","[None, None, '']","[None, None, ""'YYYY-MM-DD HH:mm:SS'""]",8,[],"['arrow.get', 'dd.total_seconds']",2
utilmy/zarchive/coke_functions.py:date_diffstart,date_diffstart,function,4,9,8,31,3.44,1,0,"['t) ', 'str_t0=t0)t) ', 'str_t0=t)dd) ']","[' return date_diffsecond(str_t1', '', '']","['t', 't0)t) :   return date_diffsecond(str_t1=t1', 't)dd) :']",13,[],['dd.items'],1
utilmy/zarchive/coke_functions.py:date_diffend,date_diffend,function,4,9,8,31,3.44,1,0,"['t) ', 'str_t0=t)dd) ']","['   return date_diffsecond(str_t1', '']","['t1', 't)dd) :']",14,[],['dd.items'],1
utilmy/zarchive/coke_functions.py:np_dict_tolist,np_dict_tolist,function,4,9,8,31,3.44,1,0,['dd'],[None],[None],17,[],['dd.items'],1
utilmy/zarchive/coke_functions.py:np_dict_tostr_val,np_dict_tostr_val,function,1,9,9,46,5.11,0,0,['dd'],[None],[None],20,[],"['str', 'dd.items']",2
utilmy/zarchive/coke_functions.py:np_dict_tostr_key,np_dict_tostr_key,function,1,8,8,46,5.75,0,0,['dd'],[None],[None],23,[],"['str', 'dd.items']",2
utilmy/zarchive/coke_functions.py:day,day,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['    return int(s[8:10])s):  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",31,[],['arrow.get'],1
utilmy/zarchive/coke_functions.py:month,month,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",32,[],['arrow.get'],1
utilmy/zarchive/coke_functions.py:year,year,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",33,[],['arrow.get'],1
utilmy/zarchive/coke_functions.py:hour,hour,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",34,[],['arrow.get'],1
utilmy/zarchive/coke_functions.py:weekday,weekday,function,9,16,15,117,7.31,0,0,"['s', 'fmt', 'i0', 'i1']","[None, None, None, None]","[None, ""'YYYY-MM-DD'"", '0', '10']",38,[],['arrow.get'],1
utilmy/zarchive/coke_functions.py:season,season,function,4,15,13,47,3.13,0,1,['d'],[None],[None],48,[],['int'],1
utilmy/zarchive/coke_functions.py:daytime,daytime,function,7,42,23,123,2.93,0,1,['d'],[None],[None],53,[],['int'],1
utilmy/zarchive/coke_functions.py:pd_date_splitall,pd_date_splitall,function,11,22,17,255,11.59,0,0,"['df', 'coldate']","[None, None]","[None, ""'purchased_at'""]",62,[],['copy.deepcopy'],1
utilmy/zarchive/datanalysis.py:pd_filter_column,pd_filter_column,function,12,25,22,218,8.72,1,2,"['df_client_product', 'filter_val', 'iscol']","[None, None, None]","[None, '[]', '1']",73,"[""   '''\n"", '   # Remove Columns where Index Value is not in the filter_value\n', ""   # filter1= X_client['client_id'].values\n"", '   :param df_client_product:\n', '   :param filter_val:\n', '   :param iscol:\n', '   :return:\n', ""   '''\n""]",['col_delete1.append'],1
utilmy/zarchive/datanalysis.py:pd_missing_show,pd_missing_show,function,0,1,1,4,4.0,0,0,[],[],[],90,[],[],0
utilmy/zarchive/datanalysis.py:pd_describe,pd_describe,function,22,86,65,578,6.72,1,2,['df'],[None],[None],119,"[""   ''' Describe the tables\n"", '        \n', '       \n', ""   '''\n""]","['getstat', 'list', 'str', 'len', 'pd.Series', 'pd.DataFrame', 'pd.concat']",7
utilmy/zarchive/datanalysis.py:pd_stack_dflist,pd_stack_dflist,function,8,29,24,157,5.41,1,1,['df_list'],[None],[None],158,[],"['enumerate', 'df0.append', 'print']",3
utilmy/zarchive/datanalysis.py:pd_validation_struct,pd_validation_struct,function,0,1,1,4,4.0,0,0,[],[],[],168,[],[],0
utilmy/zarchive/datanalysis.py:pd_checkpoint,pd_checkpoint,function,0,1,1,4,4.0,0,0,[],[],[],178,[],[],0
utilmy/zarchive/datanalysis.py:xl_setstyle,xl_setstyle,function,34,82,50,743,9.06,2,0,['file1'],[None],[None],237,"["" '''\n"", '   http://openpyxl.readthedocs.io/en/default/styles.html#cell-styles-and-named-styles\n', '  import openpyxl.styles.builtins  as bi\n', '  import openpyxl.styles.builtins\n', '\n', ""  col = ws.column_dimensions['A']\n"", '  col.font = Font(bold=True)\n', '\n', ""  for cell in ws['A'] + ws[1]:\n"", ""    cell.style = 'data01'\n"", '\n', '  bd = Side(style=\'thick\', color=""000000"")\n', '  highlight.border = BORDER_NONE\n', '  from openpyxl.styles import\n', "" '''\n""]","['load_workbook', 'print', 'named_styles.NamedStyle', 'Font', 'wb.get_sheet_names', 'wb.get_sheet_by_name', 'range', 'wb.save']",8
utilmy/zarchive/datanalysis.py:xl_val,xl_val,function,7,14,13,108,7.71,0,0,"['ws', 'colj', 'rowi']","[None, None, None]","[None, None, None]",282,[],"['ws[gcol', 'str']",2
utilmy/zarchive/datanalysis.py:isnull,isnull,function,4,6,6,20,3.33,0,0,['x'],[None],[None],289,[],[],0
utilmy/zarchive/datanalysis.py:xl_get_rowcol,xl_get_rowcol,function,8,44,37,220,5.0,1,1,"['ws', 'i0', 'j0', 'imax', 'jmax']","[None, None, None, None, None]","[None, None, None, None, None]",292,[],"['range', 'isnull', 'rmat.append']",3
utilmy/zarchive/datanalysis.py:xl_getschema,xl_getschema,function,71,250,174,1902,7.61,4,8,"['dirxl', 'filepattern', 'dirlevel', 'outfile']","[None, None, None, None]","['""""', ""'*.xlsx'"", '1', ""'.xlsx'""]",302,"["" '''Take All excel in a folder and provide Table, Column Schema, type into master file\n"", "" '''\n""]","['xl_is_data_block_start', 'isnull', 'xl_find_start_block', 'range', '_xl_getschema', 'util.os_file_getname', 'load_workbook', 'print', 'wb.get_sheet_names', 'wb.get_sheet_by_name', 'gcol', 'str', 'np.array', 'np.column_stack', 'df_list.append', 'pd_stack_dflist', 'util.os_file_listall', 'enumerate', 'df0.append', 'util.pd_toexcel']",20
utilmy/zarchive/datanalysis.py:str_to_unicode,str_to_unicode,function,4,13,11,63,4.85,0,1,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",381,[],"['isinstance', 'str']",2
utilmy/zarchive/datanalysis.py:csv_dtypes_getdict,csv_dtypes_getdict,function,6,20,16,122,6.1,0,1,"['df', 'csvfile']","[None, None]","['None', 'None']",389,[],['pd.read_csv'],1
utilmy/zarchive/datanalysis.py:csv_fast_processing,csv_fast_processing,function,0,0,0,0,0.0,0,0,[],[],[],396,"[""   '''\n"", '   http://word.bitly.com/post/74069870671/optimizing-text-processing\n', '\n', 'import sys\n', 'from collections import defaultdict\n', 'OUT_FILES = defaultdict(dict)\n', '\n', 'open_outfiles()  # open all files I could possibly need\n', '\n', 'for line in sys.stdin:\n', '    # 1. parse line for account_id and metric_type\n', ""    key = line.split(',')\n"", '    account_id = key[ACCOUNT_ID_INDEX][1:] # strip leading quote\n', '\n', '    # 2. write to appropriate file for account_id and metric_type\n', '    OUT_FILES[account_id][key[METRIC_TYPE_INDEX]].write(line)\n', '\n', '   close_outfiles()  # close all the files we opened\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/datanalysis.py:csv_col_schema_toexcel,csv_col_schema_toexcel,function,87,291,205,2615,8.99,3,8,"['dircsv', 'filepattern', 'outfile', 'returntable', 'maxrow', 'maxcol_pertable', 'maxstrlen']","[None, None, None, None, None, None, None]","['""""', ""'*.csv'"", ""'.xlsx'"", '1', '5000000', '90', ""'U80'""]",418,"["" '''Take All csv in a folder and provide Table, Column Schema, type\n"", ' str(df[col].dtype)  USE str always, otherwise BIG Issue\n', '\n', 'METHOD FOR Unicode / ASCII issue\n', ""1. Decode early:  Decode to <type 'unicode'> ASAP\n"", ""    df['PREF_NAME']=       df['PREF_NAME'].apply(to_unicode)\n"", '2. Unicode everywhere\n', ""3. Encode late :f = open('/tmp/ivan_out.txt','w')\n"", ""                f.write(ivan_uni.encode('utf-8'))\n"", "" '''\n""]","['util.os_file_listall', 'len', 'np.array', 'enumerate', 'print', 'pd.read_csv', 'str', 'util.pd_toexcel', 'df.apply', 'np.zeros', 'range', 'float', 'gc.collect', 'pd.DataFrame', 'util.save', 'outfile.replace']",16
utilmy/zarchive/datanalysis.py:csv_col_get_dict_categoryfreq,csv_col_get_dict_categoryfreq,function,39,80,64,553,6.91,4,4,"['dircsv', 'filepattern', 'category_cols', 'maxline', 'fileencoding']","[None, None, None, None, None]","[None, '""*.csv""', '[]', '-1', '""utf-8""']",510,"[""  ''' Find Category Freq in large CSV Transaction Column   '''\n""]","['datetime.now', 'defaultdict', 'util.os_file_listall', 'enumerate', 'line.split', 'print']",6
utilmy/zarchive/datanalysis.py:csv_row_reduce_line,csv_row_reduce_line,function,22,80,63,477,5.96,1,5,"['fromfile', 'tofile', 'condfilter', 'catval_tokeep', 'header', 'maxline']","[None, None, None, None, None, None]","[None, None, None, None, 'True', '-1']",536,"[""  ''' Reduce Data Row by filtering on some Category\n"", '    file_category=  in1+ ""offers.csv""\n', '    ncol= 8\n', '    catval_tokeep=[ {} for i in xrange(0, ncol)]\n', '    for i, line in enumerate(open(file_category)):\n', '      ll=  line.split("","")\n', '      catval_tokeep[3][  ll[1] ]  = 1  # Offer_file_col1 --> Transact_file_col_4\n', '      catval_tokeep[4][  ll[3] ] =  1  # Offer_file_col3 --> Transact_file_col_4\n', '\n', '  def condfilter(colk, catval_tokeep) :\n', '    if colk[3] in catval_tokeep[3] or colk[4] in catval_tokeep[4]: return True\n', '    else: return False\n', ""  '''\n""]","['datetime.now', 'open', 'next', 'outfile.write', 'enumerate', 'line.split', 'condfilter', 'print']",8
utilmy/zarchive/datanalysis.py:csv_analysis,csv_analysis,function,0,0,0,0,0.0,0,0,[],[],[],576,"[""   '''\n"", '   https://csvkit.readthedocs.io/en/540/tutorial/1_getting_started.html\n', '\n', '   sudo pip install csvkit\n', '\n', '   :return:\n', ""   '''\n""]",[],0
utilmy/zarchive/datanalysis.py:csv_row_reduce_line_manual,csv_row_reduce_line_manual,function,25,77,54,499,6.48,2,4,"['file_category', 'file_transact', 'file_reduced']","[None, None, None]","[None, None, None]",587,"[""  ''' Reduce Data by filtering on some Category '''\n""]","['datetime.now', 'enumerate', 'line.split', 'open', 'outfile.write', 'print']",6
utilmy/zarchive/datanalysis.py:csv_row_mapreduce,csv_row_mapreduce,function,17,29,26,282,9.72,2,0,"['dircsv', 'outfile', 'type_mapreduce', 'nrow', 'chunk']","[None, None, None, None, None]","['""""', '""""', ""'sum'"", '1000000', ' 5000000']",617,"["" '''Take All csv in a folder and provide Table, Column Schema'''\n""]","['util.os_file_listall', 'int', 'pd.DataFrame', 'enumerate', 'range', 'pd.read_csv']",6
utilmy/zarchive/datanalysis.py:csv_pivotable,csv_pivotable,function,13,57,38,576,10.11,1,4,"['dircsv', 'filepattern', 'fileh5', 'leftX', 'topY', 'centerZ', 'mapreduce', 'chunksize', 'tablename']","[None, None, None, None, None, None, None, None, None]","['""""', ""'*.csv'"", ""'.h5'"", ""'col0'"", ""'col2'"", ""'coli'"", ""'sum'"", ' 500000', ""'df'""]",634,"["" ''' return df Pivot Table from series of csv file (transfer to d5 temporary)\n"", '\n', 'Edit: you can groupby/sum from the store iteratively since this ""map-reduces"" over the chunks:\n', '\n', 'reduce(lambda x, y: x.add(y, fill_value=0),\n', ""       (df.groupby().sum() for df in store.select('df', chunksize=50000)))\n"", '\n', "" '''\n""]","['util.pd_h5_fromcsv_tohdfs', 'pd.HDFStore', 'store.select', 'pd.concat']",4
utilmy/zarchive/datanalysis.py:csv_bigcompute,csv_bigcompute,function,0,1,1,4,4.0,0,0,[],[],[],664,[],[],0
utilmy/zarchive/datanalysis.py:db_getdata,db_getdata,function,0,1,1,4,4.0,0,0,[],[],[],671,[],[],0
utilmy/zarchive/datanalysis.py:db_sql,db_sql,function,0,1,1,4,4.0,0,0,[],[],[],674,[],[],0
utilmy/zarchive/datanalysis.py:db_meta_add,db_meta_add,function,26,85,61,761,8.95,1,4,"['metadb', 'dbname', 'new_table', '[]']","[None, None, None, None]","[None, None, ""(''"", None]",677,"[""   ''' Create Meta database to store infos on the tables : csv, zip, HFS, Postgres\n"", ""ALL_DB['japancoupon']= {}\n"", ""ALL_DB['japancoupon']['schema']=    df_schema\n"", ""ALL_DB['japancoupon']['df_table_uri']= df_schema_dictionnary\n"", ""ALL_DB['japancoupon']['df_table_columns']= df_schema_dict\n"", '        DBname, db_schema, db_table_uri, db_table_columns(dict_table->colum_list),\n', ""   '''\n""]","['pd_df_todict', 'df.drop_duplicates', 'range', 'dict0.setdefault']",4
utilmy/zarchive/datanalysis.py:db_meta_find,db_meta_find,function,22,86,67,617,7.17,3,4,"['ALLDB', 'query', 'filter_db', 'filter_table', 'filter_column']","[None, None, None, None, None]","[None, ""''"", '[]', '[]', '[]']",714,"[""  ''' Find string in all the meta table name, column\n"", ""  db_meta_find(ALLDB, query='bottler', filter_db=['cokeon'],   filter_table=['table'], filter_column=['table'] )\n"", '  dbname: should be exact name\n', '  fitler_table: partial match is ok\n', '  fitler_column : partial name is ok\n', '  return   (dbname, meta_table_name,  meta_table_filtered_by_row_containing query)\n', ""  '''\n""]","['list', 'len', 'isinstance', 'util.str_match_fuzzy', 'util.find_fuzzy', 'util.pd_find', 'rs.append']",7
utilmy/zarchive/datanalysis.py:col_study_getcategorydict_freq,col_study_getcategorydict_freq,function,16,26,25,408,15.69,1,0,['catedict'],[None],[None],745,"[""  ''' Generate Frequency of category : Id, Freq, Freqin%, CumSum%, ZScore\n"", '      given a dictionnary of category parsed previously\n', ""  '''\n""]","['list', 'util.pd_array_todataframe', 'df.sort_values', 'np.arange', 'catlist.append']",5
utilmy/zarchive/datanalysis.py:col_feature_importance,col_feature_importance,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",760,"[""   ''' random forest for column importance '''\n""]",[],0
utilmy/zarchive/datanalysis.py:pd_col_study_distribution_show,pd_col_study_distribution_show,function,22,96,71,1000,10.42,3,3,"['df', 'col_include', 'col_exclude', ""pars={'binsize'""]","[None, None, None, '']","[None, 'None', 'None', ""{'binsize':20}""]",764,"["" '''  Perfom Full Study of the pandas columns'''\n""]","['np.count_nonzero', 'sorted', 'print', 'len', 'np.max', 'np.min', 'np.median', 'np.mean', 'np.std', 'plot_Y', 'plt.title', 'plt.plot', 'plt.hist', 'plt.show', 'plt.figure', 'np.percentile', 'list']",17
utilmy/zarchive/datanalysis.py:col_study_summary,col_study_summary,function,18,57,53,606,10.63,1,3,"['Xmat', '0.0]', 'Xcolname', ""'col2']"", 'Xcolselect', '9]', 'isprint']","[None, None, None, None, None, None, None]","['[0.0', None, ""['col1'"", None, '[9', None, '0']",794,[],"['np.arange', 'len', 'print', 'np.min', 'np.max', 'np.median', 'np.mean', 'np.std', 'colanalysis.append', 'pd.DataFrame', 'np.shape']",11
utilmy/zarchive/datanalysis.py:pd_col_pair_plot,pd_col_pair_plot,function,14,34,32,261,7.68,1,1,"['dfX', 'Xcolname_selectlist', 'dfY', 'Ycolname']","[None, None, None, None]","[None, 'None', 'None', 'None']",811,[],"['str', 'plt.scatter', 'plt.autoscale', 'plt.title', 'plt.show']",5
utilmy/zarchive/datanalysis.py:col_pair_correl,col_pair_correl,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",825,[],[],0
utilmy/zarchive/datanalysis.py:col_pair_interaction,col_pair_interaction,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",828,"[""   ''' random forest for pairwise interaction '''\n""]",[],0
utilmy/zarchive/datanalysis.py:plot_col_pair,plot_col_pair,function,1,4,4,69,17.25,0,0,"['dfX', 'Xcolname_selectlist', 'dfY', 'Ycolname']","[None, None, None, None]","[None, 'None', 'None', 'None']",832,[],['pd_col_pair_plot'],1
utilmy/zarchive/datanalysis.py:tf_transform_catlabel_toint,tf_transform_catlabel_toint,function,13,18,18,218,12.11,1,0,['Xmat'],[None],[None],838,"[""   '''\n"", '     # [""paris"", ""paris"", ""tokyo"", ""amsterdam""]  --> 2 ,5,6\n', '     # np.array(le.inverse_transform([2, 2, 1]))\n', '     le = preprocessing.LabelEncoder()\n', '     le.fit([""paris"", ""paris"", ""tokyo"", ""amsterdam""])\n', 'LabelEncoder()\n', 'list(le.classes_)\n', ""['amsterdam', 'paris', 'tokyo']\n"", 'le.transform([""tokyo"", ""tokyo"", ""paris""])\n', 'array([2, 2, 1]...)\n', 'list(le.inverse_transform([2, 2, 1]))\n', ""['tokyo', 'tokyo', 'paris']\n"", ""   '''\n""]","['range', 'le.get_params']",2
utilmy/zarchive/datanalysis.py:tf_transform_pca,tf_transform_pca,function,3,4,4,78,19.5,0,0,"['Xmat', 'dimpca', 'whiten']","[None, None, None]","[None, '2', 'True']",863,"[""   '''Project ndim data into dimpca sub-space  '''\n""]","['pca=PCA', 'pca.transform']",2
utilmy/zarchive/datanalysis.py:plot_distance_heatmap,plot_distance_heatmap,function,19,30,29,363,12.1,0,0,"['Xmat_dist', 'Xcolname']","[None, None]","[None, None]",872,[],"['pd.DataFrame', 'plt.figure', 'fig.add_subplot', 'ax.imshow', 'pyplot.get_cmap', 'ax.set_xlabel', 'ax.set_ylabel', 'ax.set_title', 'plt.colorbar']",9
utilmy/zarchive/datanalysis.py:plot_cluster_2D,plot_cluster_2D,function,10,20,20,237,11.85,1,0,"['X_2dim', 'target_class', 'target_names']","[None, None, None]","[None, None, None]",888,"[""   ''' Plot 2d of Clustering Class,\n"", '       X2d: Nbsample x 2 dim  (projection on 2D sub-space)\n', ""   '''\n""]","['target_ids=range', 'len', 'pl.figure', 'zip', 'pl.scatter', 'pl.legend', 'pl.show']",7
utilmy/zarchive/datanalysis.py:plot_cluster_tsne,plot_cluster_tsne,function,23,53,46,590,11.13,0,3,"['Xmat', 'Xcluster_label', 'metric', 'perplexity', 'ncomponent', 'savefile', 'isprecompute', 'returnval']","[None, None, None, None, None, None, None, None]","[None, 'None', ""'euclidean'"", '50', '2', ""''"", 'False', 'True']",901,"["" '''Plot High dimemnsionnal State using TSNE method\n"", ""   'euclidean, 'minkowski', 'cityblock', 'seuclidean', 'sqeuclidean, 'cosine, 'correlation, 'hamming, 'jaccard, 'chebyshev,\n"", ""   'canberra, 'braycurtis, 'mahalanobis', VI=None) 'yule, 'matching, 'dice, 'kulsinski, 'rogerstanimoto, 'russellrao, 'sokalmichener, 'sokalsneath,\n"", '\n', '   Xtsne= da.plot_cluster_tsne(Xtrain_dist, Xcluster_label=None, perplexity=40, ncomponent=2, isprecompute=True)\n', '\n', '   Xtrain_dist= sci.spatial.distance.squareform(sci.spatial.distance.pdist(Xtrain_d,\n', ""               metric='cityblock', p=2, w=None, V=None, VI=None))\n"", ""   '''\n""]","['np.set_printoptions', 'model.fit_transform', 'np.arange', 'plot_XY']",4
utilmy/zarchive/datanalysis.py:plot_cluster_pca,plot_cluster_pca,function,22,51,44,480,9.41,0,3,"['Xmat', 'Xcluster_label', 'metric', 'dimpca', 'whiten', 'isprecompute', 'savefile', 'doreturn']","[None, None, None, None, None, None, None, None]","[None, 'None', ""'euclidean'"", '2', 'True', 'False', ""''"", '1']",930,[],"['PCA', 'model.fit_transform', 'np.zeros', 'plot_XY']",4
utilmy/zarchive/datanalysis.py:plot_cluster_hiearchy,plot_cluster_hiearchy,function,30,87,78,957,11.0,1,3,"['Xmat_dist', 'p', 'truncate_mode', 'color_threshold', 'get_leaves', 'orientation', 'labels', 'count_sort', 'distance_sort', 'show_leaf_counts', 'do_plot', 'no_labels', 'leaf_font_size', 'leaf_rotation', 'leaf_label_func', 'show_contracted', 'link_color_func', 'ax', 'above_threshold_color', 'annotate_above']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]","[None, '30', 'None', 'None', 'True', ""'top'"", 'None', 'False', 'False', 'True', '1', 'False', 'None', 'None', 'None', 'False', 'None', 'None', ""'b'"", '0']",948,[],"['dendrogram', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'zip', 'sum', 'plt.plot', 'plt.annotate', 'plt.axhline']",9
utilmy/zarchive/datanalysis.py:plot_distribution_density,plot_distribution_density,function,28,58,52,631,10.88,0,0,"['Xsample', 'kernel', 'N', 'bandwith']","[None, None, None, None]","[None, ""'gaussian'"", '10', '1 / 10.0']",978,[],"['plt.subplots', 'len', 'np.min', 'np.max', 'np.linspace', 'np.ones_like', 'np.ones', 'ax.hist', 'kde.score_samples', 'np.log', 'ax.plot', 'np.exp', 'ax.set_xlim', 'plt.show']",14
utilmy/zarchive/datanalysis.py:plot_Y,plot_Y,function,4,7,7,88,12.57,0,0,"['Yval', 'typeplot', 'tsize', 'labels', 'title', 'xlabel', 'ylabel', 'zcolor_label', 'figsize', '6']","[None, None, None, None, None, None, None, None, None, None]","[None, ""'.b'"", 'None', 'None', ""''"", ""''"", ""''"", ""''"", '(8', None]",1021,[],"['plt.figure', 'plt.title', 'plt.plot', 'plt.show']",4
utilmy/zarchive/datanalysis.py:plot_XY,plot_XY,function,72,197,147,1805,9.16,0,7,"['xx', 'yy', 'zcolor', 'tsize', 'labels', 'title', 'xlabel', 'ylabel', 'zcolor_label', 'figsize', '6']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', ""''"", ""''"", ""''"", ""''"", '(8', None]",1028,"[""  '''\n"", '      labels= numpy array, ---> Generate HTML File with the labels interactives\n', '      Color: Plasma\n', ""  '''\n""]","['isinstance', 'np.array', 'np.abs', 'plt.get_cmap', 'np.min', 'plt.subplots', 'fig.set_size_inches', 'fig.set_dpi', 'fig.tight_layout', 'ax1.scatter', 'ax1.set_xlabel', 'ax1.set_ylabel', 'ax1.set_title', 'ax1.grid', 'np.max', 'scatter.set_clim', 'fig.colorbar', 'cb.set_label', 'list', 'mpld3.save_html', 'plt.show', 'util.os_folder_create', 'plt.savefig', 'plot_XY_plotly', 'go.Scatter', 'py.iplot', 'py.plot', 'plot_XY_seaborn', 'sns.set_context', 'sns.set_color_codes', 'sns.color_palette', 'np.unique', 'plt.scatter', 'plt.gca', 'plt.title']",35
utilmy/zarchive/datanalysis.py:plot_XY_plotly,plot_XY_plotly,function,15,31,26,261,8.42,0,1,"['xx', 'yy', 'towhere']","[None, None, None]","[None, None, ""'url'""]",1095,"[""  ''' Create Interactive Plotly   '''\n""]","['go.Scatter', 'py.iplot', 'py.plot']",3
utilmy/zarchive/datanalysis.py:plot_XY_seaborn,plot_XY_seaborn,function,14,44,42,400,9.09,0,1,"['X', 'Y', 'Zcolor']","[None, None, None]","[None, None, 'None']",1118,[],"['sns.set_context', 'sns.set_color_codes', 'sns.color_palette', 'np.unique', 'plt.scatter', 'plt.gca', 'plt.title']",7
utilmy/zarchive/datanalysis.py:optim_is_pareto_efficient,optim_is_pareto_efficient,function,15,35,31,304,8.69,1,2,"['Xmat_cost', 'epsilon', 'ret_boolean']","[None, None, None]","[None, ' 0.01', '1']",1160,"['    """""" Calculate Pareto Frontier of Multi-criteria Optimization program\n', '    c1, c2  has to be minimized : -Sharpe, -Perf, +Drawdown\n', '    :param Xmat_cost: An (n_points, k_costs) array\n', '    :return: A (n_points, ) boolean array, indicating whether each point is Pareto efficient\n', '    """"""\n']","['np.ones', 'enumerate', 'np.any']",3
utilmy/zarchive/datanalysis.py:sk_catboost_classifier,sk_catboost_classifier,function,22,54,51,581,10.76,0,2,"['Xtrain', 'Ytrain', 'Xcolname', 'pars= {""learning_rate""', '""iterations""', '""random_seed""', '""loss_function""', 'isprint']","[None, None, None, '', '1000', '0', ' ""MultiClass"" }', None]","[None, None, 'None', ' {""learning_rate"":0.1', None, None, None, '0']",1245,"[""  '''\n"", '  from catboost import Pool, CatBoostClassifier\n', '\n', ""TRAIN_FILE = '../data/cloudness_small/train_small'\n"", ""TEST_FILE = '../data/cloudness_small/test_small'\n"", ""CD_FILE = '../data/cloudness_small/train.cd'\n"", '# Load data from files to Pool\n', 'train_pool = Pool(TRAIN_FILE, column_description=CD_FILE)\n', 'test_pool = Pool(TEST_FILE, column_description=CD_FILE)\n', '# Initialize CatBoostClassifier\n', ""model = CatBoostClassifier(iterations=2, learning_rate=1, depth=2, loss_function='MultiClass')\n"", '# Fit model\n', 'model.fit(train_pool)\n', '# Get predicted classes\n', 'preds_class = model.predict(test_pool)\n', '# Get predicted probabilities for each class\n', 'preds_proba = model.predict_proba(test_pool)\n', '# Get predicted RawFormulaVal\n', ""  preds_raw = model.predict(test_pool, prediction_type='RawFormulaVal')  \n"", '  \n', '  \n', '  https://tech.yandex.com/catboost/doc/dg/concepts/python-usages-examples-docpage/\n', '  \n', ""  '''\n""]","['dict2', 'str', 'range', 'pd.DataFrame', 'catboost.CatBoostClassifier', 'clf.fit', 'clf.predict', 'cm.astype', 'cm.sum', 'print']",10
utilmy/zarchive/datanalysis.py:sk_catboost_regressor,sk_catboost_regressor,function,0,1,1,4,4.0,0,0,[],[],[],1291,[],[],0
utilmy/zarchive/datanalysis.py:sk_model_auto_tpot,sk_model_auto_tpot,function,21,41,36,562,13.71,0,1,"['Xmat', 'y', 'outfolder', 'model_type', 'train_size', 'generation', 'population_size', 'verbosity']","[None, None, None, None, None, None, None, None]","[None, None, ""'aaserialize/'"", ""'regressor/classifier'"", '0.5', '1', '5', '2']",1308,"[""  ''' Automatic training of Xmat--->Y, Generate SKlearn code in outfile\n"", '      Very Slow Process, use lower number of Sample\n', '  :param Xmat:\n', '  :param y:\n', '  :param outfolder:\n', '  :param model_type:\n', '  :param train_size:\n', '  :param generation: \n', '  :param population_size:\n', '  :param verbosity:\n', '  :return:\n', ""  '''\n""]","['train_test_split', 'TPOTRegressor', 'TPOTClassifier', 'tpot.fit', 'print', 'str', 'tpot.export']",7
utilmy/zarchive/datanalysis.py:sk_params_search_best,sk_params_search_best,function,30,61,50,840,13.77,0,3,"['Xmat', 'Ytarget', 'model1', ""param_grid={'alpha'"", '1', '5) }', 'method', ""param_search= {'scoretype'"", ""'cv'"", ""'population_size'"", ""'generations_number'""]","[None, None, None, '', None, None, None, '', '5', '5', '3 }']","[None, None, None, ""{'alpha':  np.linspace(0"", None, None, ""'gridsearch'"", "" {'scoretype':'r2'"", None, None, None]",1336,"[""  '''\n"", '   genetic: population_size=5, ngene_mutation_prob=0.10,,gene_crossover_prob=0.5, tournament_size=3,  generations_number=3\n', '\n', '  :param Xmat:\n', '  :param Ytarget:\n', '  :param model1:\n', '  :param param_grid:\n', '  :param method:\n', '  :param param_search:\n', '  :return:\n', ""  '''\n""]","['make_scorer', 'GridSearchCV', 'grid.fit', 'EvolutionaryAlgorithmSearchCV', 'cv=StratifiedKFold', 'cv.fit']",6
utilmy/zarchive/datanalysis.py:sk_distribution_kernel_bestbandwidth,sk_distribution_kernel_bestbandwidth,function,8,17,17,176,10.35,0,0,['kde'],[None],[None],1403,"["" '''Find best Bandwidht for a  given kernel\n"", '  :param kde:\n', '  :return:\n', "" '''\n""]","['GridSearchCV', 'np.linspace', 'grid.fit']",3
utilmy/zarchive/datanalysis.py:sk_distribution_kernel_sample,sk_distribution_kernel_sample,function,15,31,29,211,6.81,1,0,"['kde', 'n']","[None, None]","['None', '1']",1414,"["" ''' \n"", '  kde = sm.nonparametric.KDEUnivariate(np.array(Y[Y_cluster==0],dtype=np.float64))\n', '  kde = sm.nonparametric.KDEMultivariate()  # ... you already did this\n', "" '''\n""]","['np.zeros', 'func', 'kde.cdf', 'range', 'brentq']",5
utilmy/zarchive/datanalysis.py:sk_correl_rank,sk_correl_rank,function,16,38,31,289,7.61,2,0,"['correl', '0]', '[0', '1]]']","[None, None, None, None]","['[[1', None, None, None]",1432,"[' """""" Correl Ranking:  Col i, Col j, Correl_i_j, Abs_Correl_i_j    """"""\n']","['np.shape', 'np.zeros', 'range', 'abs', 'util.sortcol']",5
utilmy/zarchive/datanalysis.py:sk_error_r2,sk_error_r2,function,8,19,16,175,9.21,0,1,"['Ypred', 'y_true', 'sample_weight', 'multioutput']","[None, None, None, None]","[None, None, 'None', 'None']",1447,[],"['r2_score', 'np.sign']",2
utilmy/zarchive/datanalysis.py:sk_error_rmse,sk_error_rmse,function,6,10,10,100,10.0,0,0,"['Ypred', 'Ytrue']","[None, None]","[None, None]",1454,[],"['np.sqrt', 'len', 'np.std']",3
utilmy/zarchive/datanalysis.py:sk_cluster_distance_pair,sk_cluster_distance_pair,function,5,16,14,195,12.19,0,2,"['Xmat', 'metric']","[None, None]","[None, ""'jaccard'""]",1458,"[""   '''\n"", ""    'euclidean, 'minkowski', 'cityblock', 'seuclidean', 'sqeuclidean, 'cosine, 'correlation, 'hamming, 'jaccard, 'chebyshev, 'canberra, 'braycurtis, 'mahalanobis', VI=None) 'yule, 'matching, 'dice, 'kulsinski, 'rogerstanimoto, 'russellrao, 'sokalmichener, 'sokalsneath,\n"", '\n', ""    'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance,\n"", "" 'canberra': hdbscan.dist_metrics.CanberraDistance,\n"", "" 'chebyshev': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'cityblock': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'dice': hdbscan.dist_metrics.DiceDistance,\n"", "" 'euclidean': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'hamming': hdbscan.dist_metrics.HammingDistance,\n"", "" 'haversine': hdbscan.dist_metrics.HaversineDistance,\n"", "" 'infinity': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'jaccard': hdbscan.dist_metrics.JaccardDistance,\n"", "" 'kulsinski': hdbscan.dist_metrics.KulsinskiDistance,\n"", "" 'l1': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'l2': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance,\n"", "" 'manhattan': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'matching': hdbscan.dist_metrics.MatchingDistance,\n"", "" 'minkowski': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'p': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'pyfunc': hdbscan.dist_metrics.PyFuncDistance,\n"", "" 'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance,\n"", "" 'russellrao': hdbscan.dist_metrics.RussellRaoDistance,\n"", "" 'seuclidean': hdbscan.dist_metrics.SEuclideanDistance,\n"", "" 'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance,\n"", "" 'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance,\n"", "" 'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance}\n"", '   #Visualize discretization scheme\n', '\n', '   Xtrain_dist= sci.spatial.distance.squareform(sci.spatial.distance.pdist(Xtrain_d,\n', ""             metric='cityblock', p=2, w=None, V=None, VI=None))\n"", '\n', ""   Xtsne= da.plot_cluster_tsne(Xtrain_dist, metric='', perplexity=40, ncomponent=2, isprecompute=True)\n"", '\n', ""   '''\n""]",['fast.distance_jaccard_X'],1
utilmy/zarchive/datanalysis.py:sk_cluster,sk_cluster,function,52,173,122,1635,9.45,2,11,"['Xmat', 'metric']","[None, None]","[None, ""'jaccard'""]",1500,[],"['fast.distance_jaccard_X', 'sk_cluster', 'hdbscan.HDBSCAN', 'print', 'len', 'np.std', 'np.mean', 'Xmat.reshape', 'KMeans', 'kmeans.fit', 'range', 'plt.plot', 'plt.show', 'sk_cluster_algo_custom', 'algorithm']",15
utilmy/zarchive/datanalysis.py:sk_cluster_algo_custom,sk_cluster_algo_custom,function,9,17,15,174,10.24,0,1,"['Xmat', 'algorithm', 'args', 'kwds', 'returnval']","[None, None, None, None, None]","[None, None, None, None, '1']",1563,"[""    ''' Plot the cLuster using specific Algo\n"", '    distance_matrix = pairwise_distances(blobs)\n', ""    clusterer = hdbscan.HDBSCAN(metric='precomputed')\n"", '    clusterer.fit(distance_matrix)\n', '    clusterer.labels_\n', '\n', ""    {'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance,\n"", "" 'canberra': hdbscan.dist_metrics.CanberraDistance,\n"", "" 'chebyshev': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'cityblock': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'dice': hdbscan.dist_metrics.DiceDistance,\n"", "" 'euclidean': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'hamming': hdbscan.dist_metrics.HammingDistance,\n"", "" 'haversine': hdbscan.dist_metrics.HaversineDistance,\n"", "" 'infinity': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'jaccard': hdbscan.dist_metrics.JaccardDistance,\n"", "" 'kulsinski': hdbscan.dist_metrics.KulsinskiDistance,\n"", "" 'l1': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'l2': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance,\n"", "" 'manhattan': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'matching': hdbscan.dist_metrics.MatchingDistance,\n"", "" 'minkowski': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'p': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'pyfunc': hdbscan.dist_metrics.PyFuncDistance,\n"", "" 'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance,\n"", "" 'russellrao': hdbscan.dist_metrics.RussellRaoDistance,\n"", "" 'seuclidean': hdbscan.dist_metrics.SEuclideanDistance,\n"", "" 'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance,\n"", "" 'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance,\n"", "" 'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance}\n"", '\n', ""    '''\n""]","['algorithm', 'print', 'len']",3
utilmy/zarchive/datanalysis.py:sk_optim_de,sk_optim_de,function,35,125,96,1182,9.46,1,4,"['obj_fun', 'bounds', 'maxiter', 'name1', 'solver1', 'isreset', 'popsize']","[None, None, None, None, None, None, None]","[None, None, '1', ""''"", 'None', '1', '15']",1636,"[""    ''' Optimization and Save Data into file'''\n""]","['print', 'load_obj', 'int', 'copy.deepcopy', 'range', 'next', 'util.save_obj', 'util.date_now', 'util.np_int_tostr', 'np.mod', 'np.abs']",11
utilmy/zarchive/datanalysis.py:sk_feature_importance,sk_feature_importance,function,8,19,19,230,12.11,1,1,"['clfrf', 'feature_name']","[None, None]","[None, None]",1739,[],"['np.argsort', 'range', 'len', 'print', 'str']",5
utilmy/zarchive/datanalysis.py:sk_showconfusion,sk_showconfusion,function,11,22,21,246,11.18,0,1,"['clfrf', 'X_train', 'Y_train', 'isprint']","[None, None, None, None]","[None, None, None, 'True']",1747,[],"['clfrf.predict', 'cm.astype', 'cm.sum', 'print']",4
utilmy/zarchive/datanalysis.py:sk_tree,sk_tree,function,13,33,32,447,13.55,0,1,"['Xtrain', 'Ytrain', 'nbtree', 'maxdepth', 'isprint1', 'njobs']","[None, None, None, None, None, None]","[None, None, None, None, '1', '1']",1756,[],"['clfrf.fit', 'clfrf.predict', 'cm.astype', 'cm.sum', 'print']",5
utilmy/zarchive/datanalysis.py:sk_gen_ensemble_weight,sk_gen_ensemble_weight,function,14,29,27,213,7.34,1,0,"['vv', 'acclevel', 'maxlevel']","[None, None, None]","[None, None, '0.88']",1768,[],"['min', 'np.empty', 'range', 'estww.append', 'np.log', 'np.array']",6
utilmy/zarchive/datanalysis.py:sk_votingpredict,sk_votingpredict,function,19,33,28,267,8.09,2,1,"['estimators', 'voting', 'ww', 'X_test']","[None, None, None, None]","[None, None, None, None]",1782,[],"['np.zeros', 'enumerate', 'clf.predict_proba', 'range', 'len']",5
utilmy/zarchive/datanalysis.py:sk_tree_get_ifthen,sk_tree_get_ifthen,function,26,91,64,780,8.57,2,3,"['tree', 'feature_names', 'target_names', 'spacer_base']","[None, None, None, None]","[None, None, None, '"" ""']",1797,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['recurse', 'print', 'str', 'zip', 'int']",5
utilmy/zarchive/datanalysis.py:sk_model_template1,sk_model_template1,class,39,143,87,1197,8.37,0,3,[],[],[],1683,[],[],0
utilmy/zarchive/datanalysis.py:sk_stateRule,sk_stateRule,class,38,138,104,1121,8.12,0,5,[],[],[],1868,[],[],0
utilmy/zarchive/datanalysis.py:sk_model_template1:__init__,sk_model_template1:__init__,method,10,13,13,166,12.77,0,0,"['self', 'alpha', 'low_y_cut', 'high_y_cut', 'ww0']","[None, None, None, None, None]","[None, '0.5', '-0.09', '0.09', '0.95']",1684,[],['Ridge'],1
utilmy/zarchive/datanalysis.py:sk_model_template1:fit,sk_model_template1:fit,method,17,46,40,471,10.24,0,1,"['self', 'X', 'Y']","[None, None, None]","[None, None, 'None']",1690,[],"['len', 'print', 'np.median']",3
utilmy/zarchive/datanalysis.py:sk_model_template1:predict,sk_model_template1:predict,method,10,27,21,166,6.15,0,1,"['self', 'X', 'y', 'ymedian']","[None, None, None, None]","[None, None, 'None', 'None']",1708,[],['Y.clip'],1
utilmy/zarchive/datanalysis.py:sk_model_template1:score,sk_model_template1:score,method,14,32,27,216,6.75,0,1,"['self', 'X', 'Ytrue', 'ymedian']","[None, None, None, None]","[None, None, 'None', 'None']",1719,[],"['Y.clip', 'r2_score']",2
utilmy/zarchive/datanalysis.py:sk_stateRule:__init__,sk_stateRule:__init__,method,8,44,37,370,8.41,0,1,"['self', 'state', 'trigger', 'colname']","[None, None, None, None]","[None, None, None, '[]']",1871,[],"['np.empty', 'np.shape', 'len', 'range', 'util.np_torecarray']",5
utilmy/zarchive/datanalysis.py:sk_stateRule:addrule,sk_stateRule:addrule,method,20,47,42,383,8.15,0,2,"['self', 'rulefun', 'name', 'desc']","[None, None, None, None]","[None, None, ""''"", ""''""]",1883,[],"['util.findnone', 'util.find', 'print', 'util.np_addcolumn', 'rulefun', 'copy.deepcopy']",6
utilmy/zarchive/datanalysis.py:sk_stateRule:eval,sk_stateRule:eval,method,9,29,24,233,8.03,0,2,"['self', 'idrule', 't', 'ktrig']","[None, None, None, None]","[None, None, None, '0']",1901,[],"['isinstance', 'util.find', 'print']",3
utilmy/zarchive/datanalysis.py:sk_stateRule:help,sk_stateRule:help,method,0,0,0,0,0.0,0,0,[],[],[],1909,"[""    '''\n"", 's1= np.arange(5000).reshape((1000, 5))\n', 'trig1= np.ones((1,5))\n', ""state1= sk_stateRule(aa, trig1, ['drawdown','ma100d','ret10d','state_1','state_2'] )\n"", '\n', 'def fun1(s, tr,t):\n', '  return  s.drawdown[t] < tr.drawdown[0] and  s.drawdown[t] < tr.drawdown[0]\n', '\n', 'def fun2(s, tr,t):\n', ' return  s.drawdown[t] > tr.drawdown[0] and  s.drawdown[t] < tr.drawdown[0]\n', '\n', ""state1.addrule(fun1, 'rule6')\n"", ""state1.addrule(fun2, 'rule5')\n"", '\n', 'state1.eval(idrule=0,t=5)\n', '\n', 'state1.eval(idrule=1,t=5)\n', '\n', ""state1.eval(idrule='rule5',t=6)\n"", '\n', ""util.save_obj(state1, 'state1')\n"", '\n', 'np.shape(aa2)\n', '\n', ""aa2= util.np_torecarray(aa,  ['drawdown','a2','a3','a4','a5'])\n"", '\n', 'util.find(5.0, aa2[0])\n', '\n', 'recordarr = np.rec.array([(1,2.,7),(2,3.,5)],\n', ""                   dtype=[('col1', 'f8'),('col2', 'f8'), ('col3', 'f8')])\n"", 'recordarr.col3[0]\n', '\n', 'state1= stateRule(np.ones((100,10)), np.ones((1,10)))\n', '\n', 'col= aa2.a2\n', '\n', ""'''\n""]",[],0
utilmy/zarchive/excel.py:get_workbook_name,get_workbook_name,function,3,5,5,48,9.6,0,0,[],[],[],9,"['    """"""Writes the name of the Workbook into Range(""D3"") of Sheet 1""""""\n']","['Workbook.caller', 'Range']",2
utilmy/zarchive/excel.py:double_sum,double_sum,function,1,4,4,13,3.25,0,0,"['x', 'y']","[None, None]","[None, None]",16,"['    """"""Returns twice the sum of the two arguments""""""\n']",[],0
utilmy/zarchive/excel.py:add_one,add_one,function,5,11,9,40,3.64,2,0,['data'],[None],[None],23,"['    """"""Adds 1 to every cell in Range""""""\n']",[],0
utilmy/zarchive/excel.py:matrix_mult,matrix_mult,function,2,2,2,14,7.0,0,0,"['x', 'y']","[None, None]","[None, None]",31,"['    """"""Alternative implementation of Excel\'s MMULT, requires NumPy""""""\n']",['x.dot'],1
utilmy/zarchive/excel.py:npdot,npdot,function,0,0,0,0,0.0,0,0,[],[],[],43,[],[],0
utilmy/zarchive/fast.py:day,day,function,9,15,14,125,8.33,0,0,['s)'],['    return int(s[8:10])s):  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],130,[],['arrow.get'],1
utilmy/zarchive/fast.py:month,month,function,9,15,14,125,8.33,0,0,['s)'],['  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],131,[],['arrow.get'],1
utilmy/zarchive/fast.py:year,year,function,9,15,14,125,8.33,0,0,['s)'],['   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],132,[],['arrow.get'],1
utilmy/zarchive/fast.py:hour,hour,function,9,15,14,125,8.33,0,0,['s)'],['   return int(s[11:13])cache_weekday'],[' {}s):'],133,[],['arrow.get'],1
utilmy/zarchive/fast.py:weekday,weekday,function,9,15,14,125,8.33,0,0,['s'],[None],[None],139,[],['arrow.get'],1
utilmy/zarchive/fast.py:season,season,function,4,15,13,47,3.13,0,1,['d'],[None],[None],148,[],['int'],1
utilmy/zarchive/fast.py:daytime,daytime,function,5,40,23,123,3.08,0,1,['d'],[None],[None],154,[],['int'],1
utilmy/zarchive/fast.py:fastStrptime,fastStrptime,function,8,46,35,288,6.26,0,2,"['val', 'format']","[None, None]","[None, None]",164,[],"['len', 'int', 'datetime.datetime']",3
utilmy/zarchive/fast.py:drawdown_calc_fast,drawdown_calc_fast,function,36,80,63,618,7.72,1,3,['price'],[None],[None],190,[],"['len', 'np.zeros', 'range']",3
utilmy/zarchive/fast.py:std,std,function,6,12,12,61,5.08,0,0,['x'],[None],[None],225,"['    """"""Std Deviation 1D array""""""\n']","['x.sum', 'sqrt']",2
utilmy/zarchive/fast.py:mean,mean,function,2,3,3,24,8.0,0,0,['x'],[None],[None],236,"['    """"""Mean  """"""\n']",['x.sum'],1
utilmy/zarchive/fast.py:_compute_overlaps,_compute_overlaps,function,13,27,20,108,4.0,1,0,"['u', 'v']","[None, None]","[None, None]",249,[],['xrange'],1
utilmy/zarchive/fast.py:distance_jaccard2,distance_jaccard2,function,5,11,11,55,5.0,0,0,"['u', 'v']","[None, None]","[None, None]",260,[],"['_compute_overlaps', 'float']",2
utilmy/zarchive/fast.py:distance_jaccard,distance_jaccard,function,5,11,11,55,5.0,0,0,"['u', 'v']","[None, None]","[None, None]",266,[],"['_compute_overlaps', 'float']",2
utilmy/zarchive/fast.py:distance_jaccard_X,distance_jaccard_X,function,13,21,19,163,7.76,2,0,['X'],[None],[None],277,[],"['np.zeros', 'xrange', 'distance_jaccard']",3
utilmy/zarchive/fast.py:cosine,cosine,function,11,43,26,262,6.09,0,2,"['u', 'v']","[None, None]","[None, None]",292,[],['np.sqrt'],1
utilmy/zarchive/fast.py:rmse,rmse,function,1,7,6,31,4.43,0,0,"['y', 'yhat']","[None, None]","[None, None]",321,"['    """""" Calculate and return Root Mean Squared Error (RMSE)\n', '    Returns: float: Root Mean Squared Error\n', '    """"""\n']",[],0
utilmy/zarchive/fast.py:cross,cross,function,17,31,25,211,6.81,0,0,"['vec1', 'vec2']","[None, None]","[None, None]",329,"['    """""" Calculate the dot product of two 3d vectors. """"""\n']","['double', 'np.zeros']",2
utilmy/zarchive/fast.py:norm,norm,function,4,8,8,61,7.62,1,0,['vec'],[None],[None],341,"['    """""" Calculate the norm of a 3d vector. """"""\n']","['sqrt', 'range']",2
utilmy/zarchive/fast.py:log_exp_sum2,log_exp_sum2,function,0,1,1,5,5.0,0,0,"['a', 'b']","[None, None]","[None, None]",242,[],[],0
utilmy/zarchive/fast_parallel.py:task_summary,task_summary,function,4,17,17,142,8.35,1,0,['tasks'],[None],[None],76,[],"['print', 'enumerate', 't.get']",3
utilmy/zarchive/fast_parallel.py:task_progress,task_progress,function,8,26,23,161,6.19,1,1,['tasks'],[None],[None],83,"[""  ''' Monitor progress '''\n""]","['np.mean', 'print']",2
utilmy/zarchive/fast_parallel.py:task_find_best,task_find_best,function,3,11,11,80,7.27,0,0,"['tasks', 'n_top']","[None, None]","[None, '5']",94,"['    """"""Compute the best score of tasks_folder""""""\n']","['t.ready', 'sorted']",2
utilmy/zarchive/fast_parallel.py:task_parallel_job_01,task_parallel_job_01,function,19,33,32,336,10.18,0,0,"['name', 'param', 'datadict']","[None, None, None]","[None, None, None]",101,"[""   ''' Sample task run in Parallel '''\n""]","['os.chdir', 'util.a_run_ipython', 'str']",3
utilmy/zarchive/filelock.py:FileLock,FileLock,class,41,133,94,1246,9.37,2,6,[],[],[],36,[],[],0
utilmy/zarchive/filelock.py:FileLock:__init__,FileLock:__init__,method,11,27,23,279,10.33,1,1,"['self', 'protected_file_path', 'timeout', 'delay', 'lock_file_contents']","[None, None, None, None, None]","[None, None, 'None', '1', 'None']",53,"['        """""" Prepare the file locker. Specify the file to lock and optionally\n', '            the maximum timeout and the delay between each attempt to lock.\n', '        """"""\n']",[],0
utilmy/zarchive/filelock.py:FileLock:locked,FileLock:locked,method,2,2,2,20,10.0,0,0,['self'],[None],[None],67,"['        """"""\n', '        Returns True iff the file is owned by THIS FileLock instance.\n', '        (Even if this returns false, the file could be owned by another FileLock instance, possibly in a different thread or process).\n', '        """"""\n']",[],0
utilmy/zarchive/filelock.py:FileLock:available,FileLock:available,method,2,3,3,38,12.67,0,0,['self'],[None],[None],74,"['        """"""\n', '        Returns True iff the file is currently available to be locked.\n', '        """"""\n']",[],0
utilmy/zarchive/filelock.py:FileLock:acquire,FileLock:acquire,method,18,55,48,410,7.45,1,3,"['self', 'blocking']","[None, None]","[None, 'True']",80,"['        """""" Acquire the lock, if possible. If the lock is in use, and `blocking` is False, return False.\n', '            Otherwise, check again every `self.delay` seconds until it either gets the lock or\n', '            exceeds `timeout` number of seconds, in which case it raises an exception.\n', '        """"""\n']","['time.time', 'os.open', 'os.fdopen', 'f.write', 'FileLock.FileLockException', 'time.sleep']",6
utilmy/zarchive/filelock.py:FileLock:release,FileLock:release,method,2,3,3,45,15.0,0,0,['self'],[None],[None],106,"['        """""" Get rid of the lock by deleting the lockfile.\n', '            When working in a `with` statement, this gets automatically\n', '            called at the end.\n', '        """"""\n']",['os.unlink'],1
utilmy/zarchive/filelock.py:FileLock:__enter__,FileLock:__enter__,method,2,3,3,25,8.33,0,0,['self'],[None],[None],115,"['        """""" Activated when used in the with statement.\n', '            Should automatically acquire a lock to be used in the with block.\n', '        """"""\n']",['self.acquire'],1
utilmy/zarchive/filelock.py:FileLock:__exit__,FileLock:__exit__,method,1,1,1,14,14.0,0,0,"['self', 'type', 'value', 'traceback']","[None, None, None, None]","[None, None, None, None]",123,"['        """""" Activated at the end of the with statement.\n', ""            It automatically releases the lock if it isn't locked.\n"", '        """"""\n']",['self.release'],1
utilmy/zarchive/filelock.py:FileLock:__del__,FileLock:__del__,method,2,3,3,32,10.67,0,1,['self'],[None],[None],130,"['        """""" Make sure this ``FileLock`` instance doesn\'t leave a .lock file\n', '            lying around.\n', '        """"""\n']",['self.release'],1
utilmy/zarchive/filelock.py:FileLock:purge,FileLock:purge,method,3,7,6,70,10.0,0,1,['self'],[None],[None],137,"['        """"""\n', '        For debug purposes only.  Removes the lock file from the hard disk.\n', '        """"""\n']",['self.release'],1
utilmy/zarchive/function_custom.py:mapping_calc_risk_elvis_v03,mapping_calc_risk_elvis_v03,function,4,9,9,63,7.0,0,0,"['ss', 'tr', 't', 'riskout']","[None, None, None, None]","[None, None, None, None]",18,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",['mapping_calc_risk_v01'],1
utilmy/zarchive/function_custom.py:mapping_calc_risk_v02,mapping_calc_risk_v02,function,18,190,75,704,3.71,0,2,"['ss', 'tr', 't', 'risk0']","[None, None, None, None]","[None, None, None, None]",31,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",[],0
utilmy/zarchive/function_custom.py:mapping_calc_risk_v01,mapping_calc_risk_v01,function,19,130,56,532,4.09,0,2,"['ss', 'tr', 't', 'risk0']","[None, None, None, None]","[None, None, None, None]",72,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",[],0
utilmy/zarchive/function_custom.py:mapping_risk_ww_v01,mapping_risk_ww_v01,function,12,56,29,245,4.38,0,1,"['risk', 'wwmat', 'ww2']","[None, None, None]","[None, None, None]",98,[],"['np.sum', 'np.array']",2
utilmy/zarchive/function_custom.py:mapping_calc_risk_v00,mapping_calc_risk_v00,function,16,68,45,286,4.21,0,1,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",107,[],[],0
utilmy/zarchive/function_custom.py:getweight,getweight,function,7,13,12,70,5.38,0,1,"['ww', 'size', '3']","[None, None, None]","[None, '(9', None]",133,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/function_custom.py:fun_obj,fun_obj,function,6,11,11,120,10.91,0,0,"['vv', 'ext']","[None, None]","[None, None]",139,[],"['pf.folio_volta', 'int', 'pf.volhisto_fromprice', 'len']",4
utilmy/zarchive/geospatial.py:coordinates_box,coordinates_box,class,1,2,2,16,8.0,0,0,[],[],[],33,[],[],0
utilmy/zarchive/kagglegym.py:r_score,r_score,function,4,15,12,146,9.73,0,1,"['y_true', 'y_pred', 'sample_weight', 'multioutput']","[None, None, None, None]","[None, None, 'None', 'None']",77,[],['r2_score'],1
utilmy/zarchive/kagglegym.py:make,make,function,2,2,2,19,9.5,0,0,[],[],[],175,[],['Environment'],1
utilmy/zarchive/kagglegym.py:Observation,Observation,class,7,11,11,99,9.0,0,0,[],[],[],86,[],[],0
utilmy/zarchive/kagglegym.py:Environment,Environment,class,49,148,101,1719,11.61,0,1,[],[],[],93,[],[],0
utilmy/zarchive/kagglegym.py:Observation:__init__,Observation:__init__,method,6,6,6,58,9.67,0,0,"['self', 'train', 'target', 'features']","[None, None, None, None]","[None, None, None, None]",87,[],[],0
utilmy/zarchive/kagglegym.py:Environment:__init__,Environment:__init__,method,21,37,35,452,12.22,0,0,['self'],[None],[None],94,[],"['pd.HDFStore', 'hfdata.get', 'len', 'int']",4
utilmy/zarchive/kagglegym.py:Environment:reset,Environment:reset,method,16,36,34,403,11.19,0,0,['self'],[None],[None],115,[],"['int', 'Observation']",2
utilmy/zarchive/kagglegym.py:Environment:step,Environment:step,method,29,64,52,765,11.95,0,1,"['self', 'target']","[None, None]","[None, None]",135,[],"['r_score', 'Observation']",2
utilmy/zarchive/kagglegym.py:Environment:__str__,Environment:__str__,method,1,2,2,21,10.5,0,0,['self'],[None],[None],171,[],[],0
utilmy/zarchive/linux.py:load_session,load_session,function,4,7,7,86,12.29,0,0,['name'],[None],"[""'test_20160815'""]",100,[],['dill.load_session'],1
utilmy/zarchive/linux.py:save_session,save_session,function,6,9,9,107,11.89,0,0,['name'],[None],"[""''""]",106,[],"['date_now', 'dill.dump_session']",2
utilmy/zarchive/linux.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],121,[],['float'],1
utilmy/zarchive/linux.py:isint,isint,function,6,15,14,80,5.33,0,1,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, None, '']","[None, None, None, None, None, None]",129,[],['txt.find'],1
utilmy/zarchive/linux.py:aa_isanaconda,aa_isanaconda,function,6,15,14,80,5.33,0,1,[],[],[],132,[],['txt.find'],1
utilmy/zarchive/linux.py:aa_cleanmemory,aa_cleanmemory,function,3,3,3,21,7.0,0,0,[],[],[],147,[],['gc.collect'],1
utilmy/zarchive/linux.py:aa_getmodule_doc,aa_getmodule_doc,function,8,13,13,110,8.46,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",150,[],"['ca.getmodule_doc', 'np.isnan', 'z.nonzero']",3
utilmy/zarchive/linux.py:np_interpolate_nan,np_interpolate_nan,function,7,9,9,78,8.67,0,0,['y'],[None],[None],1176,[],"['__np_nan_helper', 'np.interp', 'x']",3
utilmy/zarchive/linux.py:and1,and1,function,8,55,22,356,6.47,0,6,"['x', 'y', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']","[None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None', 'None', 'None']",1182,[],[],0
utilmy/zarchive/linux.py:sortcol,sortcol,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",1192,"[' """""" df.sort([\'A\', \'B\'], ascending=[1, 0])  """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/linux.py:sort,sort,function,7,20,12,181,9.05,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",1198,[],"['pd.DataFrame', 'df.sort_values', 'sort']",3
utilmy/zarchive/linux.py:np_ma,np_ma,function,2,3,3,45,15.0,0,0,"['vv', 'n']","[None, None]","[None, None]",1205,"[""  '''Moving average '''\n""]","['np.convolve', 'np.ones']",2
utilmy/zarchive/linux.py:np_cleanmatrix,np_cleanmatrix,function,11,22,20,124,5.64,2,1,['m'],[None],[None],1211,[],"['np.nan_to_num', 'np.shape', 'range', 'abs']",4
utilmy/zarchive/linux.py:np_sortbycolumn,np_sortbycolumn,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1222,[],"['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/linux.py:np_sortbycol,np_sortbycol,function,8,30,20,257,8.57,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1227,[],"['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/linux.py:np_findfirst,np_findfirst,function,5,11,10,55,5.0,1,1,"['item', 'vec']","[None, None]","[None, None]",1238,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/linux.py:np_find,np_find,function,6,24,13,133,5.54,2,2,"['item', 'vec']","[None, None]","[None, None]",1244,[],"['xrange', 'np_find']",2
utilmy/zarchive/linux.py:find,find,function,12,42,30,219,5.21,1,3,"['item', 'vec']","[None, None]","[None, None]",1250,"['    """"""return the index of the first occurence of item in vec""""""\n']","['xrange', 'findx', 'type', 'vec.index', 'len', 'finds']",6
utilmy/zarchive/linux.py:findx,findx,function,6,27,18,119,4.41,0,2,"['item', 'vec']","[None, None]","[None, None]",1257,"['    """"""return the index of the first occurence of item in vec""""""\n']","['type', 'vec.index', 'len']",3
utilmy/zarchive/linux.py:finds,finds,function,12,34,23,156,4.59,2,3,"['itemlist', 'vec']","[None, None]","[None, None]",1268,"['  """"""return the index of the first occurence of item in vec""""""\n']","['xrange', 'idlist.append']",2
utilmy/zarchive/linux.py:findhigher,findhigher,function,5,13,12,51,3.92,1,1,"['x', 'vec']","[None, None]","[None, None]",1280,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/linux.py:findlower,findlower,function,5,12,11,51,4.25,1,1,"['x', 'vec']","[None, None]","[None, None]",1287,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/linux.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],1297,[],['min'],1
utilmy/zarchive/linux.py:np_find_maxpos,np_find_maxpos,function,17,45,34,266,5.91,1,3,['values'],[None],[None],1301,[],"['max', 'np_find_maxpos_2nd', 'float', 'enumerate']",4
utilmy/zarchive/linux.py:np_find_maxpos_2nd,np_find_maxpos_2nd,function,13,37,28,138,3.73,1,3,['numbers'],[None],[None],1306,[],"['float', 'enumerate']",2
utilmy/zarchive/linux.py:np_findlocalmax2,np_findlocalmax2,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",1320,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/linux.py:np_findlocalmin2,np_findlocalmin2,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",1355,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/linux.py:np_findlocalmax,np_findlocalmax,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",1392,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/linux.py:np_findlocalmin,np_findlocalmin,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",1407,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/linux.py:np_stack,np_stack,function,12,53,25,323,6.09,0,7,"['v1', 'v2', 'v3', 'v4', 'v5']","[None, None, None, None, None]","[None, 'None', 'None', 'None', 'None']",1428,[],"['np.shape', 'np.row_stack', 'np.column_stack']",3
utilmy/zarchive/linux.py:np_uniquerows,np_uniquerows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],1443,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/linux.py:np_remove_zeros,np_remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",1448,[],[],0
utilmy/zarchive/linux.py:np_sort,np_sort,function,8,30,20,257,8.57,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1451,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/linux.py:np_memory_array_adress,np_memory_array_adress,function,2,2,2,38,19.0,0,0,['x'],[None],[None],1454,[],[],0
utilmy/zarchive/linux.py:sk_featureimportance,sk_featureimportance,function,9,21,21,228,10.86,1,1,"['clfrf', 'feature_name']","[None, None]","[None, None]",1463,[],"['np.argsort', 'range', 'len', 'str']",4
utilmy/zarchive/linux.py:sk_showconfusion,sk_showconfusion,function,11,22,21,244,11.09,0,1,"['clfrf', 'X_train', 'Y_train', 'isprint']","[None, None, None, None]","[None, None, None, 'True']",1471,[],"['clfrf.predict', 'cm.astype', 'cm.sum', 'print']",4
utilmy/zarchive/linux.py:sk_tree,sk_tree,function,13,34,32,430,12.65,0,1,"['Xtrain', 'Ytrain', 'nbtree', 'maxdepth', 'print1']","[None, None, None, None, None]","[None, None, None, None, None]",1479,[],"['clfrf.fit', 'clfrf.predict', 'cm.astype', 'cm.sum', 'print']",5
utilmy/zarchive/linux.py:sk_gen_ensemble_weight,sk_gen_ensemble_weight,function,14,30,28,213,7.1,1,0,"['vv', 'acclevel', 'maxlevel']","[None, None, None]","[None, None, '0.88']",1492,[],"['min', 'np.empty', 'range', 'estww.append', 'np.log', 'np.array']",6
utilmy/zarchive/linux.py:sk_votingpredict,sk_votingpredict,function,19,33,28,267,8.09,2,1,"['estimators', 'voting', 'ww', 'X_test']","[None, None, None, None]","[None, None, None, None]",1506,[],"['np.zeros', 'enumerate', 'clf.predict_proba', 'range', 'len']",5
utilmy/zarchive/linux.py:sk_tree_get_ifthen,sk_tree_get_ifthen,function,26,89,62,768,8.63,2,3,"['tree', 'feature_names', 'target_names', 'spacer_base']","[None, None, None, None]","[None, None, None, '"" ""']",1524,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['recurse', 'print', 'str', 'zip', 'int']",5
utilmy/zarchive/linux.py:pd_array_todataframe,pd_array_todataframe,function,13,45,29,277,6.16,0,2,"['price', 'symbols', 'date1', 'dotranspose']","[None, None, None, None]","[None, 'None', 'None', 'False']",1562,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/linux.py:pd_date_intersection,pd_date_intersection,function,7,18,15,157,8.72,1,0,['qlist'],[None],[None],1574,[],"['set', 'set.intersection', 'list', 'sorted']",4
utilmy/zarchive/linux.py:pd_resetindex,pd_resetindex,function,3,4,4,50,12.5,0,0,['df'],[None],[None],1585,[],['list'],1
utilmy/zarchive/linux.py:pd_create_colmap_nametoid,pd_create_colmap_nametoid,function,9,12,12,77,6.42,1,0,['df'],[None],[None],1591,"[""  ''' 'close' ---> 5    '''\n""]",['enumerate'],1
utilmy/zarchive/linux.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],1599,[],[],0
utilmy/zarchive/linux.py:pd_changeencoding,pd_changeencoding,function,6,8,8,89,11.12,1,0,"['data', 'cols']","[None, None]","[None, None]",1606,[],[],0
utilmy/zarchive/linux.py:pd_createdf,pd_createdf,function,2,4,4,53,13.25,0,0,"['val1', 'col1', 'idx1']","[None, None, None]","[None, 'None', 'None']",1613,[],['pd.DataFrame'],1
utilmy/zarchive/linux.py:pd_insertcolumn,pd_insertcolumn,function,12,29,27,179,6.17,1,1,"['df', 'colname', 'vec']","[None, None, None]","[None, None, None]",1618,"["" ''' Vec and Colname must be aligned '''\n""]","['len', 'np.shape', 'range', 'df.insert']",4
utilmy/zarchive/linux.py:pd_insertrows,pd_insertrows,function,17,31,30,237,7.65,1,1,"['df', 'rowval', 'index1']","[None, None, None]","[None, None, 'None']",1632,[],"['np.shape', 'np.arange', 'pd.DataFrame', 'range', 'df.append']",5
utilmy/zarchive/linux.py:pd_replacevalues,pd_replacevalues,function,11,14,14,101,7.21,1,0,"['df', 'matrix']","[None, None]","[None, None]",1645,"["" ''' Matrix replaces df.values  '''\n""]",['np.shape'],1
utilmy/zarchive/linux.py:pd_storeadddf,pd_storeadddf,function,6,15,15,113,7.53,0,1,"['df', 'dfname', ""dbfile='F""]","[None, None, '']","[None, None, ""'F:\\temp_pandas.h5'""]",1655,[],"['pd.HDFStore', 'find', 'store.keys', 'store.append', 'store.close']",5
utilmy/zarchive/linux.py:pd_storedumpinfo,pd_storedumpinfo,function,13,29,24,298,10.28,1,0,"[""dbfile='E""]",[''],"[""'E:\\_data\\stock\\intraday_google.h5'""]",1663,[],"['pd.HDFStore', 'store.keys', 'pd.read_hdf', 'extract.append', 'datetime_tostring', 'errsym.append', 'np.array']",7
utilmy/zarchive/linux.py:pd_remove_row,pd_remove_row,function,2,2,2,29,14.5,0,0,"['df', 'row_list_index', '45]']","[None, None, None]","[None, '[23', None]",1677,[],['df.drop'],1
utilmy/zarchive/linux.py:pd_extract_col_idx_val,pd_extract_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],1680,[],[],0
utilmy/zarchive/linux.py:pd_split_col_idx_val,pd_split_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],1684,[],[],0
utilmy/zarchive/linux.py:pd_addcolumn,pd_addcolumn,function,10,23,19,190,8.26,1,1,"['df1', 'name1']","[None, None]","[None, ""'new'""]",1688,[],"['len', 'type', 'pd.Series']",3
utilmy/zarchive/linux.py:pd_removecolumn,pd_removecolumn,function,2,3,3,23,7.67,0,0,"['df1', 'name1']","[None, None]","[None, None]",1697,[],['df1.drop'],1
utilmy/zarchive/linux.py:pd_save_vectopanda,pd_save_vectopanda,function,9,22,19,182,8.27,1,0,"['vv', 'filenameh5)', 'pdf); store.close()filenameh5', ""store_id='data')"", 'store_id)    #from filereturn pdf.values   #to numpy vectorfilein1', 'filename', ""tablen='data')""]","[None, ""  # 'E:\\_data\\_data_outlier.h5'filenameh5)vv); store.append('data'"", None, '', None, None, '']","[None, None, None, ""'data'):  # 'E:\\_data\\_data_outlier.h5'filenameh5"", None, None, ""'data'):""]",1701,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/linux.py:pd_load_panda2vec,pd_load_panda2vec,function,9,22,19,182,8.27,1,0,"['filenameh5', ""store_id='data')"", 'store_id)    #from filereturn pdf.values   #to numpy vectorfilein1', 'filename', ""tablen='data')""]","[None, '', None, None, '']","[None, ""'data'):  # 'E:\\_data\\_data_outlier.h5'filenameh5"", None, None, ""'data'):""]",1706,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/linux.py:pd_csv_topanda,pd_csv_topanda,function,9,22,19,182,8.27,1,0,"['filein1', 'filename', 'tablen']","[None, None, None]","[None, None, ""'data'""]",1711,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/linux.py:pd_getpanda_tonumpy,pd_getpanda_tonumpy,function,6,10,10,92,9.2,0,0,"['filename', 'nsize', 'tablen']","[None, None, None]","[None, None, ""'data'""]",1723,[],['pd.read_hdf'],1
utilmy/zarchive/linux.py:pd_getrandom_tonumpy,pd_getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample', 'tablen']","[None, None, None, None]","[None, None, None, ""'data'""]",1728,[],['pd.read_hdf'],1
utilmy/zarchive/linux.py:sk_cluster_kmeans,sk_cluster_kmeans,function,21,38,37,375,9.87,1,1,"['x', 'nbcluster', 'isplot']","[None, None, None]","[None, '5', 'True']",1861,[],"['np.std', 'kmeans.fit', 'range', 'plt.plot', 'plt.show']",5
utilmy/zarchive/linux.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],1885,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/linux.py:date_remove_bdays,date_remove_bdays,function,16,41,28,351,8.56,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",1896,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/linux.py:date_add_bdays,date_add_bdays,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",1914,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/linux.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",1929,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/linux.py:datetime_toint,datetime_toint,function,6,15,13,155,10.33,1,1,['datelist1'],[None],[None],1938,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/linux.py:dateint_todatetime,dateint_todatetime,function,6,15,13,135,9.0,1,1,['datelist1'],[None],[None],1946,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/linux.py:date_diffindays,date_diffindays,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",1955,[],['dateint_todatetime'],1
utilmy/zarchive/linux.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",1960,[],['util.np_findfirst'],1
utilmy/zarchive/linux.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],1974,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/linux.py:date_now,date_now,function,10,18,16,130,7.22,0,1,['i'],[None],['0'],1981,[],"['datetime.now', 'date_add_bdays', 'date_remove_bdays', 'str']",4
utilmy/zarchive/linux.py:date_as_float,date_as_float,function,11,28,23,273,9.75,0,1,['dt'],[None],[None],1989,[],"['datetime.datetime', 'isleap', 'timedelta']",3
utilmy/zarchive/linux.py:datediff_inyear,datediff_inyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",2001,[],['date_as_float'],1
utilmy/zarchive/linux.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",2005,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/linux.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],1885,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/linux.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",1929,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/linux.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],1974,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/linux.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",2048,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/linux.py:numexpr_topanda,numexpr_topanda,function,10,28,22,248,8.86,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",2060,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/linux.py:textvect_topanda,textvect_topanda,function,2,8,8,70,8.75,0,0,"['vv', 'fileout']","[None, None]","[None, '""""']",2070,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zarchive/linux.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",2093,[],['ne.evaluate'],1
utilmy/zarchive/linux.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],2101,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/linux.py:plotsave,plotsave,function,7,16,16,199,12.44,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",2124,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/linux.py:plotshow,plotshow,function,4,9,9,101,11.22,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",2135,[],"['plt.scatter', 'plt.autoscale', 'plt.title', 'plt.show']",4
utilmy/zarchive/linux.py:compileVSsolution,compileVSsolution,function,5,33,19,239,7.24,0,4,"['dir1', 'flags1', 'type1', 'compilerdir']","[None, None, None, None]","[None, '""""', '""devenv""', '""""']",2568,[],['os.system'],1
utilmy/zarchive/linux.py:VS_start,VS_start,function,18,56,52,881,15.73,0,2,"['self', 'version']","[None, None]","[None, None]",2597,[],"['os.getenv', 'Exception', 'default.append', 'libs.append']",4
utilmy/zarchive/linux.py:VS_build,VS_build,function,16,62,54,614,9.9,1,2,"['self', 'lib_to_build']","[None, None]","[None, None]",2632,[],"['print', 'subprocess.Popen', 'process.poll', 'process.communicate']",4
utilmy/zarchive/linux.py:set_rc_version,set_rc_version,function,12,43,39,500,11.63,0,0,"['rcfile', 'target_version']","[None, None]","[None, None]",2666,[],"['open', 'f.read', 're.compile', 're.sub', 'f.seek', 'f.write', 'f.truncate']",7
utilmy/zarchive/multiprocessfunc.py:multigbm_paralell_func,multigbm_paralell_func,function,34,117,81,913,7.8,1,4,"['nbsimul', 'ww', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price', 'type1', 'strike', 'cp']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, '0', '0', '1']",20,[],"['np.zeros', 'range', 'np.dot', 'np.multiply', 'np.exp', 'np.cumprod', 'np.maximum', 'sum', 'sum1/float']",9
utilmy/zarchive/multiprocessfunc.py:func,func,function,6,10,10,56,5.6,1,0,"['val', 'lock']","[None, None]","[None, None]",73,[],"['range', 'time.sleep']",2
utilmy/zarchive/multiprocessfunc.py:multigbm_processfast7,multigbm_processfast7,function,24,48,44,419,8.73,3,0,"['nbsimul', 's0', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",150,[],"['range', 'np.dot', 'bm_generator', 'np.exp', 'sum', 'sum1/float']",6
utilmy/zarchive/multiprocessfunc.py:bm_generator,bm_generator,function,5,9,8,43,4.78,0,1,"['bm', 'dt', 'n', 'type1']","[None, None, None, None]","[None, None, None, None]",177,[],[],0
utilmy/zarchive/multiprocessfunc.py:merge,merge,function,6,20,17,106,5.3,1,1,['d2'],[None],[None],211,[],"['time.sleep', 'd2.keys']",2
utilmy/zarchive/multiprocessfunc.py:integratenp2,integratenp2,function,10,29,25,184,6.34,1,0,"['its', 'nchunk']","[None, None]","[None, None]",222,[],"['range', 'ne.evaluate']",2
utilmy/zarchive/multiprocessfunc.py:integratenp,integratenp,function,27,77,47,454,5.9,2,0,"['its', 'nchunk']","[None, None]","[None, None]",234,[],"['range', 'ne.evaluate', 'integratenp', 'np.sum', 'float']",5
utilmy/zarchive/multiprocessfunc.py:integratene,integratene,function,12,44,38,275,6.25,1,0,['its'],[None],[None],247,[],"['range', 'ne.evaluate', 'float']",3
utilmy/zarchive/multiprocessfunc.py:parzen_estimation,parzen_estimation,function,7,30,26,185,6.17,2,1,"['x_samples', 'point_x', 'h']","[None, None, None]","[None, None, None]",268,[],"['np.abs', 'len']",2
utilmy/zarchive/multiprocessfunc.py:init2,init2,function,2,4,4,13,3.25,0,0,['d'],[None],[None],282,[],[],0
utilmy/zarchive/multiprocessfunc.py:init_global1,init_global1,function,2,2,2,37,18.5,0,0,"['l', 'r']","[None, None]","[None, None]",286,[],[],0
utilmy/zarchive/multiprocessfunc.py:np_sin,np_sin,function,2,2,2,19,9.5,0,0,['value'],[None],[None],291,[],['np.sin'],1
utilmy/zarchive/multiprocessfunc.py:ne_sin,ne_sin,function,2,2,2,27,13.5,0,0,['x'],[None],[None],294,[],['ne.evaluate'],1
utilmy/zarchive/multiprocessfunc.py:res_shared2,res_shared2,function,4,16,14,94,5.88,0,0,[],[],[],297,[],['float'],1
utilmy/zarchive/multiprocessfunc.py:list_append,list_append,function,3,4,4,54,13.5,1,0,"['count', 'id', 'out_list']","[None, None, None]","[None, None, None]",261,"['\t""""""Creates an empty list and then appends a random number to the list \'count\' number of times. A CPU-heavy operation!""""""\n']",['range'],1
utilmy/zarchive/portfolio.py:data_jpsector,data_jpsector,function,3,4,4,47,11.75,0,0,[],[],[],37,[],['util.load_obj'],1
utilmy/zarchive/portfolio.py:date_earningquater,date_earningquater,function,9,103,42,604,5.86,0,5,['t1'],[None],[None],47,[],['datetime.datetime'],1
utilmy/zarchive/portfolio.py:date_is_3rdfriday,date_is_3rdfriday,function,4,14,13,67,4.79,0,0,['s'],[None],[None],66,[],"['datetime.strptime', 'd.weekday']",2
utilmy/zarchive/portfolio.py:date_option_expiry,date_option_expiry,function,10,50,33,354,7.08,0,2,['date'],[None],[None],71,[],['datetime.datetime'],1
utilmy/zarchive/portfolio.py:date_find_kday_fromintradaydate,date_find_kday_fromintradaydate,function,2,3,3,68,22.67,0,0,"['kintraday', 'intradaydate', 'dailydate']","[None, None, None]","[None, None, None]",88,[],['util.np_find'],1
utilmy/zarchive/portfolio.py:date_find_kintraday_fromdate,date_find_kintraday_fromdate,function,4,10,10,88,8.8,0,0,"['d1', 'intradaydate1', 'h1', 'm1']","[None, None, None, None]","[None, None, '9', '30']",92,[],"['datetime.datetime', 'util.np_find']",2
utilmy/zarchive/portfolio.py:date_find_intradateid,date_find_intradateid,function,8,13,13,96,7.38,1,0,"['datetimelist', 'stringdate']","[None, None]","[None, ""['20160420223000']""]",99,[],"['datestring_todatetime', 'util.np_find', 'str']",3
utilmy/zarchive/portfolio.py:datetime_convertzone1_tozone2,datetime_convertzone1_tozone2,function,16,29,25,343,11.83,1,1,"['tt', 'fromzone', 'tozone']","[None, None, None]","[None, ""'Japan'"", ""'US/Eastern'""]",110,[],"['pytz.timezone', 'type', 'tz.localize', 't2.append']",4
utilmy/zarchive/portfolio.py:date_extract_dailyopenclosetime,date_extract_dailyopenclosetime,function,23,51,35,431,8.45,2,3,"['spdateref1', 'market']","[None, None]","[None, ""'us'""]",127,[],"['enumerate', 'spdailyopendate.append', 'np.array', 'spdailyclosedate.append']",4
utilmy/zarchive/portfolio.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",147,[],['util.np_findfirst'],1
utilmy/zarchive/portfolio.py:date_alignfromdateref,date_alignfromdateref,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",162,[],"['range', 'np.float', 'len']",3
utilmy/zarchive/portfolio.py:_date_align,_date_align,function,16,42,33,256,6.1,2,2,"['dateref', 'datei', 'tmax', 'closei']","[None, None, None, None]","[None, None, None, None]",187,[],"['np.zeros', 'range', 'len']",3
utilmy/zarchive/portfolio.py:date_align,date_align,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",201,"["" ''' #Aligne the price with the same dates date\tyear\tmonth\tday\td\topen\tclose\thigh\tlow\tvolume\taclose '''\n""]","['range', 'np.float', 'len']",3
utilmy/zarchive/portfolio.py:min_withposition,min_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],249,[],['min'],1
utilmy/zarchive/portfolio.py:max_withposition,max_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],253,[],['max'],1
utilmy/zarchive/portfolio.py:_reshape,_reshape,function,2,14,12,68,4.86,0,1,['x'],[None],[None],259,[],"['len', 'np.reshape', 'np.size']",3
utilmy/zarchive/portfolio.py:_notnone,_notnone,function,39,211,114,1769,8.38,1,11,"['x)', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5)', 'label', ""'Time'"", ""'Y')"", 'legendloc', 'dpi', 'isband=0) ']","['  return not x is Noneasset', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None, ""('title'"", None, None, '""upper left""', '150', '0) :']",263,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend']",23
utilmy/zarchive/portfolio.py:plot_price,plot_price,function,69,272,170,2746,10.1,2,11,"['asset', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None]",267,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend', 'plot_priceintraday', 'np.loadtxt', 'np.unique', 'xdays.append', 'np.hstack', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick']",35
utilmy/zarchive/portfolio.py:plot_priceintraday,plot_priceintraday,function,32,59,57,947,16.05,1,0,['data'],[None],[None],346,[],"['np.loadtxt', 'np.unique', 'np.arange', 'xdays.append', 'np.hstack', 'plt.figure', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plt.show']",14
utilmy/zarchive/portfolio.py:plot_check,plot_check,function,8,19,19,257,13.53,0,0,"['close', 'tt0i', 'tt1i', 'dateref', 'sym', 'tickperday']","[None, None, None, None, None, None]","[None, '20140102', '20160815', '[]', '[]', '120']",388,[],"['util.find', 'getret_fromquotes', 'price_normalize100', 'plot_price']",4
utilmy/zarchive/portfolio.py:plot_pricedate,plot_pricedate,function,18,61,49,534,8.75,1,4,"['date1', 'sym1', 'asset1', 'sym2', 'bsk1', 'verticaldate', 'savename1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None', ""''"", '(10', None]",398,[],"['type', 'datestring_todatetime', 'np.row_stack', 'np.concatenate', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'np.arange', 'int', 'len', 'ax.savefig']",11
utilmy/zarchive/portfolio.py:generate_sepvertical,generate_sepvertical,function,9,13,12,149,11.46,0,1,"['asset1', 'tt', 'tmax', 'start', 'datebar']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",480,[],"['np.zeros', 'datestring_todatetime']",2
utilmy/zarchive/portfolio.py:save_asset_tofile,save_asset_tofile,function,31,129,87,978,7.58,5,9,"['file1', 'asset1', 'asset2', 'asset3', 'date1', 'title1']","[None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None']",495,[],"['np.shape', 'len', 'np.reshape', 'print', 'np.zeros', 'range', 'int', 'np.row_stack', 'np.savetxt']",9
utilmy/zarchive/portfolio.py:load_asset_fromfile,load_asset_fromfile,function,1,4,4,51,12.75,0,0,['file1'],[None],[None],534,[],[],0
utilmy/zarchive/portfolio.py:array_todataframe,array_todataframe,function,11,41,27,259,6.32,0,2,"['price', 'symbols', 'date1']","[None, None, None]","[None, 'None', 'None']",538,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/portfolio.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],549,[],[],0
utilmy/zarchive/portfolio.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],558,[],['float'],1
utilmy/zarchive/portfolio.py:isint,isint,function,32,105,61,1036,9.87,0,8,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) )Xmat', 'type1', 'type2=""correl"") ']","[' return isinstance(x', None, None, None, None, None, None, '']","[None, None, None, None, None, None, '""robust""', '""correl"") :']",566,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/portfolio.py:correlation_mat,correlation_mat,function,32,105,61,1036,9.87,0,8,"['Xmat', 'type1', 'type2']","[None, None, None]","[None, '""robust""', '""correl""']",573,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/portfolio.py:correl_reducebytrigger,correl_reducebytrigger,function,9,22,18,128,5.82,2,1,"['correl2', 'trigger']","[None, None]","[None, None]",621,"[""  ''' Put Zero below trigger  '''\n""]","['correl2.copy', 'range', 'abs']",3
utilmy/zarchive/portfolio.py:sk_cov_fromcorrel,sk_cov_fromcorrel,function,8,14,13,115,8.21,0,0,"['correl', 'ret_close1']","[None, None]","[None, None]",633,[],"['volhisto_fromret', 'np.diag', 'np.dot']",3
utilmy/zarchive/portfolio.py:cointegration,cointegration,function,18,47,37,385,8.19,0,0,"['x', 'y']","[None, None]","[None, None]",639,"['  """""" Output :\n', '    coint_t :t-statistic of unit-root test on residuals\n', ""    pvalue :   MacKinnon's approximate p-value based on MacKinnon (1994)\n"", '    crit_value : Critical values for the test statistic at the 1 %, 5 %, and 10 %  Signifiance levels.\n', '\n', '    The Null hypothesis is that there is no cointegration, the alt hypothesis is that there is cointegrating relationship. \n', '    If the pvalue is small, below a critical size:  Reject Null Hypothesis -->  Cointegration\n', '           pvalue is high --> No Cointegration    \n', '    \n', '    Significance level, also denoted as alpha or , is the probability of rejecting  the null hypothesis when it is true.\n', '    Probability of incorrectly rejecting a true null hypothesis\n', '\n', '    P=0.05  , At least 23% (and typically close to 50%)\n', '    P=0.01  , At least 7% (and typically close to 15%\n', '\n', '    (-2.9607012342275936,\n', '    0.038730981052330332, 0,\n', '    249,\n', ""    {'1%': -3.4568881317725864,\n"", ""       '10%': -2.5729936189738876,\n"", ""     '5%': -2.8732185133016057},\n"", '      601.96849256295991)\n', '        It can be seen that the calculated test statistic of -2.96 is smaller than the 5% critical value of -2.87, \n', ""        which means that we can reject the null hypothesis that  there isn't a cointegrating relationship at the 5% level.\n"", '  """"""\n']",['np.zeros'],1
utilmy/zarchive/portfolio.py:causality_y1_y2,causality_y1_y2,function,10,14,13,153,10.93,0,0,"['price2', 'price1', 'maxlag']","[None, None, None]","[None, None, None]",677,[],[],0
utilmy/zarchive/portfolio.py:reg_slope,reg_slope,function,16,24,24,261,10.88,1,0,"['close', 'dateref', 'tlag', 'type1']","[None, None, None, None]","[None, None, None, ""'elasticv'""]",685,[],"['np.ones', 'xrange', 'regression', 'np.arange']",4
utilmy/zarchive/portfolio.py:rolling_cointegration,rolling_cointegration,function,13,29,26,280,9.66,0,0,"['x', 'y']","[None, None]","[None, None]",700,[],"['rolling_coint', 'pd.expanding_apply']",2
utilmy/zarchive/portfolio.py:regression,regression,function,13,67,32,589,8.79,0,5,"['yreturn', 'xreturn', 'type1']","[None, None, None]","[None, None, '""elasticv""']",719,"["" '''Y = X* reg.coef_  +  reg.intercept_, r2 '''\n""]","['len', 'yreturn.ravel', 'xreturn.reshape', 'reg.fit', 'F', 'reg.score']",6
utilmy/zarchive/portfolio.py:regression_fixedsymbolstock,regression_fixedsymbolstock,function,30,59,54,591,10.02,1,1,"['sym', 'ret_close2', 'tsstart', 'tsample', 'ret_spy', 'spyclose', 'regonly']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, 'True']",756,"["" ''' Price, Weight, R2, Error  '''\n""]","['len', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max']",7
utilmy/zarchive/portfolio.py:regression_getpricefromww,regression_getpricefromww,function,20,38,30,298,7.84,3,0,"['spyclose', 'ww01', 'regasset01', 'ret_close2', 'tstart', 'tlag']","[None, None, None, None, None, None]","[None, None, None, None, None, '1']",779,[],"['np.copy', 'np.zeros', 'range', 'len']",4
utilmy/zarchive/portfolio.py:regression_allstocks_vs_riskfactors,regression_allstocks_vs_riskfactors,function,65,137,113,1351,9.86,2,1,"['symstock', 'pricestock', 'symriskfac', 'priceriskfac', 'nlaglist']","[None, None, None, None, None]","[None, None, None, None, None]",800,"["" '''Make Regression on all stocks ''' \n""]","['np.shape', 'print', 'np.arange', 'np.empty', 'len', 'enumerate', 'getlogret_fromquotes', 'range', 'np.reshape', 'regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",13
utilmy/zarchive/portfolio.py:getdiff_fromquotes,getdiff_fromquotes,function,4,6,6,73,12.17,0,0,"['close', 'timelag']","[None, None]","[None, None]",897,[],['np.shape'],1
utilmy/zarchive/portfolio.py:getret_fromquotes,getret_fromquotes,function,7,23,17,159,6.91,0,1,"['close', 'timelag']","[None, None]","[None, '1']",901,[],"['np.shape', 'len']",2
utilmy/zarchive/portfolio.py:getlogret_fromquotes,getlogret_fromquotes,function,4,7,7,81,11.57,0,0,"['close', 'timelag']","[None, None]","[None, '1']",912,[],"['np.shape', 'np.log']",2
utilmy/zarchive/portfolio.py:getprice_fromret,getprice_fromret,function,12,23,21,190,8.26,2,0,"['ret', 'normprice']","[None, None]","[None, '100']",917,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio.py:price_normalize100,price_normalize100,function,16,43,36,292,6.79,1,1,"['ret', 'normprice']","[None, None]","[None, '100']",929,[],"['np.shape', 'len', 'np.reshape', 'np.zeros', 'range', 'np.cumprod']",6
utilmy/zarchive/portfolio.py:price_normalize_1d,price_normalize_1d,function,8,22,19,147,6.68,0,0,"['ret', 'normprice', 'dtype1']","[None, None, None]","[None, '100', ' np.float32']",949,[],"['np.empty', 'np.cumprod']",2
utilmy/zarchive/portfolio.py:norm_fast,norm_fast,function,7,8,8,85,10.62,0,0,"['y', 'ny']","[None, None]","[None, None]",958,[],['ne.evaluate'],1
utilmy/zarchive/portfolio.py:correl_fast,correl_fast,function,8,13,13,116,8.92,0,0,"['xn', 'y', 'nx']","[None, None, None]","[None, None, None]",966,[],['ne.evaluate'],1
utilmy/zarchive/portfolio.py:volhisto_fromret,volhisto_fromret,function,2,14,11,168,12.0,0,1,"['retbsk', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",974,[],"['len', 'np.std']",2
utilmy/zarchive/portfolio.py:volhisto_fromprice,volhisto_fromprice,function,6,25,17,245,9.8,0,1,"['price', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",981,[],"['len', 'np.shape', 'np.std']",3
utilmy/zarchive/portfolio.py:volhistorolling_fromprice,volhistorolling_fromprice,function,16,42,30,318,7.57,2,1,"['price', 'volrange']","[None, None]","[None, None]",990,[],"['np.shape', 'len', 'np.zeros', 'xrange', 'volhisto_fromprice']",5
utilmy/zarchive/portfolio.py:rsk_calc_all_TA,rsk_calc_all_TA,function,51,223,105,1352,6.06,0,10,['df'],[None],"[""'panda_dataframe'""]",1009,"[""  '''Add All TA RMI, RSI To the '''\n""]","['ta.MA', 'ta.distance', 'ta.RET', 'ta.RMI', 'ta.STDDEV', 'ta.nbday_low', 'ta.nbday_high', 'ta.RSI', 'ta.qearning_dist', 'ta.optionexpiry_dist', 'linearreg2', 'np.array', 'np.sum', 'util.np_findlocalmin2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",18
utilmy/zarchive/portfolio.py:ta_highbandtrend1,ta_highbandtrend1,function,42,170,75,910,5.35,0,11,"['close2', 'type1']","[None, None]","[None, '0']",1091,[],"['linearreg', 'np.array', 'np.sum', 'util.np_findlocalmax2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",8
utilmy/zarchive/portfolio.py:pd_transform_asset,pd_transform_asset,function,11,35,27,409,11.69,0,1,"['q0', 'q1', 'type1']","[None, None, None]","[None, None, '""spread""']",1140,[],"['util.pd_date_intersection', 'util.pd_array_todataframe', 'util.pd_insertcol']",3
utilmy/zarchive/portfolio.py:calcbasket_table,calcbasket_table,function,25,59,53,477,8.08,1,2,"['wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps']","[None, None, None, None, None, None]","[None, None, '""table""', '""constant""', '1', ' 0.000']",1154,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.mod', 'np.sum']",6
utilmy/zarchive/portfolio.py:folio_createvolta_asset,folio_createvolta_asset,function,10,19,19,159,8.37,1,0,"['close', 'vol', 'volrange', 'lev']","[None, None, None, None]","[None, '0.12', '120', '1.0']",1181,[],"['np.zeros_like', 'np.shape', 'xrange', 'folio_volta']",4
utilmy/zarchive/portfolio.py:folio_lowcorrelation,folio_lowcorrelation,function,145,431,300,3894,9.03,8,7,"['sym01', 'nstock', 'periodlist', 'dateref', 'close1', 'kbenchmark', 'badlist', 'costbppa', 'showgraph']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, '0.02', 'True']",1189,[],"['ww_selection', 'np.corrcoef', 'np.nan_to_num', 'np.zeros', 'range', 'util.np_sortbycol', 'int', 'np.std', 'np.isnan', 'util.find', 'np.sum', 'stk_select.append', 'volhisto_fromret', 'sum', '1/len', 'getret_fromquotes', 'len', 'np.empty', 'np.ones', 'enumerate', 'calcbasket_table', 'price_normalize100', 'np.column_stack', 'np.zeros_like', 'np.array', 'np.concatenate', 'print', 'str', 'plot_price', 'sym01[int', 'volhisto_fromprice', 'xrange', 'folio_inverseetf']",33
utilmy/zarchive/portfolio.py:folio_leverageetf,folio_leverageetf,function,8,23,20,156,6.78,1,0,"['price', 'lev', 'costpa']","[None, None, None]","[None, '1.0', '0.0']",1327,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio.py:folio_inverseetf,folio_inverseetf,function,8,18,18,151,8.39,1,0,"['price', 'costpa']","[None, None]","[None, '0.0']",1336,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio.py:folio_longshort_unit,folio_longshort_unit,function,59,240,112,1594,6.64,2,7,"['long1', 'short1', 'ww', '-1]', 'costpa', 'tlag', 'istable', 'wwschedule']","[None, None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1', '[]']",1345,[],"['len', 'np.zeros', 'xrange', 'np.mod', 'folio_longshort_unitfixed']",5
utilmy/zarchive/portfolio.py:folio_longshort_unitfixed,folio_longshort_unitfixed,function,43,111,73,719,6.48,1,3,"['long1', 'short1', 'nn', '-1]', 'costpa', 'tlag', 'istable']","[None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1']",1386,[],"['len', 'np.zeros', 'xrange', 'np.mod']",4
utilmy/zarchive/portfolio.py:folio_longshort_pct,folio_longshort_pct,function,8,21,20,189,9.0,1,0,"['long1', 'short1', 'ww', '-1]', 'costpa']","[None, None, None, None, None]","[None, None, '[1', None, '0.0']",1424,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio.py:folio_histogram,folio_histogram,function,13,75,41,914,12.19,0,0,['close'],[None],[None],1432,[],"['getret_fromquotes', 'plt.subplots', 'np.ones_like', 'ax2.hist', 'ax2.set_title', 'ax2.set_xlabel', 'ax2.set_ylabel', 'ax2.axvline', 'plt.show', 'print']",10
utilmy/zarchive/portfolio.py:folio_voltarget,folio_voltarget,function,2,6,6,61,10.17,0,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1460,[],['folio_volta'],1
utilmy/zarchive/portfolio.py:folio_volta,folio_volta,function,54,197,112,1663,8.44,2,8,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1464,[],"['folio_volta', 'len', 'np.shape', 'np.zeros', 'range', 'np.std', 'util.findhigher', 'max', 'min', 'folio_volta2', 'np.abs']",11
utilmy/zarchive/portfolio.py:folio_volta2,folio_volta2,function,29,61,54,514,8.43,1,2,"['bsk', 'riskind', 'par', 'targetvol', 'volrange', 'cap', 'floor', 'costbp']","[None, None, None, None, None, None, None, None]","[None, None, None, '0.11', ' 90', '1.5', '0.0', '0.0005']",1503,[],"['np.shape', 'np.zeros', 'range', 'np.std', 'max', 'min', 'np.abs']",7
utilmy/zarchive/portfolio.py:folio_fixedunitprice,folio_fixedunitprice,function,13,36,33,221,6.14,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1528,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio.py:folio_fixedweightprice,folio_fixedweightprice,function,13,36,33,225,6.25,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1542,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio.py:folio_fixedweightret,folio_fixedweightret,function,13,31,28,193,6.23,2,0,"['ret', 'fixedww']","[None, None]","[None, None]",1554,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio.py:folio_cost_turnover,folio_cost_turnover,function,26,88,71,825,9.38,1,1,"['wwall', 'bsk', 'dateref', 'costbp']","[None, None, None, None]","[None, None, None, None]",1567,[],"['len', 'np.zeros', 'xrange', 'np.sum', 'plot_price', 'date1=dateint_tostring']",6
utilmy/zarchive/portfolio.py:folio_riskpa,folio_riskpa,function,20,52,40,422,8.12,2,0,"['ret', 'targetvol', 'volrange', 'cap']","[None, None, None, None]","[None, '0.1', '90', '1.0']",1597,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.sum', 'np.std', 'min', 'list']",8
utilmy/zarchive/portfolio.py:folio_perfreport_schedule,folio_perfreport_schedule,function,14,20,19,189,9.45,1,0,"['sym', 'dateref', 'close', 'wwind', 't0', 'scheduleperiod']","[None, None, None, None, None, None]","[None, None, None, None, None, '""1monthend""']",1911,[],"['np.shape', 'generate_schedule', 'np.zeros', 'enumerate']",4
utilmy/zarchive/portfolio.py:folio_concenfactor2,folio_concenfactor2,function,7,12,12,103,8.58,0,0,"['ww', 'masset']","[None, None]","[None, '12']",2211,[],"['getweight', 'np.sum', 'np.mean']",3
utilmy/zarchive/portfolio.py:calcbasket_objext,calcbasket_objext,function,50,203,96,1094,5.39,1,7,"['RETURN', 'TMAX', 'riskind_i', 'wwmat', 'wwasset0', 'ww0', 'nbrange', 'criteria']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",2229,[],"['xrange', 'np.sum', 'math.sqrt']",3
utilmy/zarchive/portfolio.py:calc_ranktable,calc_ranktable,function,20,44,41,351,7.98,1,0,"['close2', 'symjp1', 'nlag', 'refindex', 'funeval', 'funargs']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",3639,[],"['np.zeros', 'getlogret_fromquotes', 'enumerate', 'funeval', 'util.np_sortbycolumn']",5
utilmy/zarchive/portfolio.py:similarity_correl,similarity_correl,function,7,10,9,88,8.8,0,0,"['ret_close2', 'funargs']","[None, None]","[None, None]",3659,[],['correlation_mat'],1
utilmy/zarchive/portfolio.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3714,[],['np_distance_l1'],1
utilmy/zarchive/portfolio.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3720,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/portfolio.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3714,[],['np_distance_l1'],1
utilmy/zarchive/portfolio.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3720,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/portfolio.py:get,get,function,11,44,26,436,9.91,0,1,"['close', 'timelag']","[None, None]","[None, None]",4085,"['    """"""Return dataframe of requested dataset from Quandl.\n', '    :param dataset: str or list, depending on single dataset usage or multiset usage\n', '            Dataset codes are available on the Quandl website\n', '    :param str api_key: Downloads are limited to 50 unless api_key is specified\n', '    :param str start_date, end_date: Optional datefilers, otherwise entire dataset is returned\n', '    :param str collapse: Options are daily, weekly, monthly, quarterly, annual\n', '    :param str transform: options are diff, rdiff, cumul, and normalize\n', '    :param int rows: Number of rows which will be returned\n', '    :param str order: options are asc, desc. Default: `asc`\n', '    :param str returns: specify what format you wish your dataset returned as,\n', '        either `numpy` for a numpy ndarray or `pandas`. Default: `pandas`\n', '    :returns: :class:`pandas.DataFrame` or :class:`numpy.ndarray`\n', '    Any other `kwargs` passed to `get` are sent as field/value params to Quandl\n', '    with no interference.\n', '\n', ""'''\n"", '\n', '\n', '\n', '#--------------------Import data from Yahoo --------------------------------------------------\n', 'def imp_yahoo_getquotes(symbols, start=""20150101"", end=""20160101"", type1=1):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', '# symbols = np.array(symbol1)\n', ' quotes= []; errorlist=[]; correctlist=[]\n', ' for i, symbol in enumerate(symbols) :\n', '   # if np.mod(i,400) ==0 and i != 0 :\n', ""     # print('Waiting 30s'); time.sleep(30)\n"", '   try:   \n', '     array1= quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '     df= pd.DataFrame.from_records(array1)\n', '     quotes.append(df)\n', '     correctlist.append(symbol)\n', '   except :\n', '       errorlist.append(symbol)\n', ""       print('Err: '+symbol)\n"", ' #quotes = [quotes_historical_yahoo(symbol, d1, d2, asobject=True)  for symbol in symbols]\n', ' #print(errorlist) \n', ' if type1==1 :  return quotes, correctlist\n', ' else: return quotes, correctlist, errorlist  \n', '\n', '              \n', '#Find error in Ticker import\n', 'def imp_yahoo_geterrorticker(symbols, start=""20150101"", end=""20160101""):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', ' errorlist= []\n', ' for symbol in symbols :\n', '   try :  \n', '     quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '   except :\n', '     errorlist.append(symbol)\n', '     print(symbol)       \n', ' return errorlist\n', ' \n', ""'''\n"", ""symbols0= ['KHC', 'PYPL', 'HPE', 'BXLT', 'SYF', 'WLTW', 'CFG', 'BF-B', 'WRK']\n"", '\n', '#Show list of ticker in error\n', 'import_errorticker(symbols0,""20110101"",""20150601""  )\n', ""'''\n"", '\n', '\n', 'def imp_yahoo_financials_url(ticker_symbol, statement=""is"", quarterly=False):\n', '    if statement == ""is"" or statement == ""bs"" or statement == ""cf"":\n', '        url = ""https://finance.yahoo.com/q/"" + statement + ""?s="" + ticker_symbol\n', '        if not quarterly:\n', '            url += ""&annual""; return BeautifulSoup(requests.get(url).text, ""html.parser"")\n', '    return sys.exit(""Invalid financial statement code \'"" + statement + ""\' passed."")\n', '\n', 'def imp_yahoo_periodic_figure(soup, yahoo_figure):\n', '    values = []; pattern = re.compile(yahoo_figure)\n', '\n', '    title = soup.find(""strong"", text=pattern)    # works for the figures printed in bold\n', '    if title:  row = title.parent.parent\n', '    else:\n', '        title = soup.find(""td"", text=pattern)    # works for any other available figure\n', '        if title:  row = title.parent\n', '        else:      sys.exit(""Invalid figure \'"" + yahoo_figure + ""\' passed."")\n', '\n', '    cells = row.find_all(""td"")[1:]    # exclude the <td> with figure name\n', '    for cell in cells:\n', '        if cell.text.strip() != yahoo_figure:    # needed because some figures are indented\n', '            str_value = cell.text.strip().replace("","", """").replace(""("", ""-"").replace("")"", """")\n', '            if str_value == ""-"": str_value = 0\n', '            value = int(str_value) * 1000\n', '            values.append(value)\n', '\n', '    return values\n', '    \n', '# print(imp_yahoo_periodic(imp_yahoo_financials_url(""AAPL"", ""is""), ""Income Tax Expense""))\n', '\n', ' \n', '\n', '#--------------------Import Quotes Google  ------------------------------------------\n', 'import requests.packages.urllib3\n', 'requests.packages.urllib3.disable_warnings()\n', 'import urllib, os\n', '\n', ""dirstockcsv= 'E:\\_data\\stock\\csv'\n"", '\n', 'def imp_googleIntradayQuote(symbol, freqsec=300, nday=5):\n', ""    ''' Intraday quotes from google. Specify interval seconds and number of days\n"", '    http://www.google.com/finance/getprices?q=7261&i=300&p=3d&f=d,o,h,l,c,v\n', ""    '''\n"", '    url =""http://www.google.com/finance/getprices?q={0}"".format(symbol)\n', '    url +=""&i={0}&p={1}d&f=d,o,h,l,c,v"".format(freqsec, nday)\n', '    try :      \n', '       resp= requests.post(url)\n', '       csv= resp.text\n', '       csv= csv.splitlines()\n', '    except :\n', ""       print('Err Intaday '+symbol)\n"", '\n', '    if len(csv) < 9 :\n', ""      print 'Using Daily',\n"", '\n', ""      url='http://www.google.com/finance/historical?q='+symbol+'&i='+str(freqsec)+'&p=3d&f=d,o,h,l,c,v&output=csv'\n"", '      csv = urllib.urlopen(url).readlines()\n', '      csv.reverse()\n', '      q=[]\n', '      for bar in xrange(0,len(csv)-1):\n', ""        ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '        if isfloat(open_) and isfloat(high) :\n', '          open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""          dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '          q.append([dt,open_,high,low,close,volume])\n', ""      df= util.pd_array_todataframe(q, ['date','open','high','low','close','volume'])\n"", '      return df\n', '\n', '\n', '    # print(csv)\n', '    qq=[]\n', '    for bar in xrange(7,len(csv)):\n', ""      if csv[bar].count(',')!=5: continue\n"", ""      offset,close,high,low,open_,volume = csv[bar].split(',')\n"", '      \n', ""      if offset[0]=='a':\n"", '        day = float(offset[1:])\n', '        offset = 0\n', '      else:\n', '        offset = float(offset)\n', '      open_, high, low, close = [float(x) for x in [open_,high,low,close]]\n', '      dt = datetime.datetime.fromtimestamp(day + (freqsec * offset))\n', '      #print (dt,open_,high,low,close,volume)\n', '      qq.append([dt,open_,high,low,close,volume])\n', ""    df= util.pd_array_todataframe(qq, ['date','open','high','low','close','volume'])\n"", '    return df\n', '\n', ""def imp_googleIntradayQuoteSave(symbols=['NKE'], freqsec=300, nday=2000, dircsv='', dbname=''):\n"", "" ''' Save Under various format: csv / db / output in Dataframe '''\n"", ' if isinstance(symbols, str) : symbols= [symbols]\n', ' symout,qlist, sym_error= [], [], []\n', ' for sym in symbols:\n', '   try :\n', '    q = imp_googleIntradayQuote(sym, freqsec, nday)  #interval, timeframe\n', '    print sym,\n', ""    sym= sym.replace(':', '_')\n"", '\n', ""    if dircsv != '' :\n"", '      if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""      start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""      file1= dircsv+ '\\\\' + sym + '_' + str(start1) + '_' + str(freqsec) + '_' + str(nday) + '.csv'\n"", '\n', ""      q= util.pd_addcol(q, 'symbol'); q['symbol']= sym\n"", '      q.to_csv(file1, index=False)\n', '\n', ""    elif dbname != '' :\n"", '      import sqlalchemy as sql\n', '      dbcon= sql.create_engine(dbname)\n', '      if interv_sec== 300 : # 5mins\n', ""        q.to_sql('q5min', dbcon)\n"", '\n', '    else :\n', '      qlist.append(q);   symout.append(sym)\n', '   except:\n', ""      print('Error:'+sym, )\n"", '      sym_error.append(sym)\n', '\n', ' return qlist, symout, sym_error\n', '\n', ""def imp_googleQuote(symbol, start_date='20160101', end_date= '20160101') : # datetime.date.today().isoformat()):\n"", ""    ''' Daily quotes from google. Date format='yyyymmdd' '''\n"", '    symbol = symbol.upper()\n', '    start = datetime.date(int(start_date[0:4]),int(start_date[4:6]),int(start_date[6:8]))\n', '    end =   datetime.date(int(end_date[0:4]),int(end_date[4:6]),int(end_date[6:8]))\n', '    url =""http://www.google.com/finance/historical?q={0}"".format(symbol)\n', '    url +=""&startdate={0}&enddate={1}&output=csv"".format( start.strftime(\'%b %d, %Y\'),end.strftime(\'%b %d, %Y\'))\n', '    csv = urllib.urlopen(url).readlines()\n', '    csv.reverse()\n', '    # print(url)\n', '    q=[]\n', '    for bar in xrange(0,len(csv)-1):\n', ""      ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '      if isfloat(open_) and isfloat(high) :\n', '        open_,high,low,close = [float(x) for x in [open_, high, low, close]  ]\n', ""        dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '        q.append([dt,open_,high,low,close,volume])\n', '    return  pd.DataFrame(np.array(q), columns= [""date"",""open"",""high"",""low"",""Close"",""volume""])\n', '\n', '\n', 'def imp_googleQuoteSave(symbols, date1, date2, dircsv):\n', ' if isinstance(symbols, str) : symbols= [symbols]\n', ' for sym in symbols:\n', '   try :\n', '      q = imp_googleQuote(sym, date1, date2)   #interval, timeframe\n', ""   except: print('Error:'+symbol)\n"", '\n', ""   sym= sym.replace(':', '_')\n"", '\n', ""   if dircsv != '' :\n"", '     if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""     start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""     file1= dircsv+ '\\\\'+ name1+'_'+ start1 +'_'+ str(date2) +'.csv'\n"", '     q.to_csv(file1)\n', '\n', ""   if dbname != '' :\n"", '     import sqlalchemy as sql\n', '     dbcon= sql.create_engine(dbname)\n', '     if interv_sec== 300 : # 5mins\n', ""       q.to_sql('q5min', dbcon)\n"", '\n', '\n', '\n', ""def imp_csv_dbupdate(indir='E:/_data/stock/intraday/intraday_google_usetf2.h5',\n"", ""                     outdir='E:/_data/stock/intraday/q5min/us/etf/', filelist=[], intype='csv',\n"", ""                     refcols=['date', 'open', 'high', 'low', 'close', 'volume', 'symbol']) :\n"", '\n', '  for file1 in filelist :\n', ""    sym=  file1[:file1.find('_')]  #Clean Up name\n"", '    print sym,\n', ""    outfile= outdir+'/'+sym+'.csv'\n"", '    if os.path.isfile(outfile) :\n', ""      df0= imp_csv_toext(file1=outfile, fromzone='Japan', tozone='UTC', header=0, cols=refcols)\n"", '    else :\n', '      df0= None\n', '\n', ""    if intype== 'hdfs':\n"", '      df1= imp_hdfs_getquote(indir, sym)\n', '      if isinstance(df1, float) : df1= None\n', '\n', ""    if intype=='csv' :\n"", ""      infile= indir+'/'+ file1   #csv\n"", ""      df1= imp_csv_toext(file1=infile, header=0, cols=refcols, fromzone='Japan', tozone='UTC')\n"", '\n', '    if df1 is not None :\n', '       if df0 is not None  : df1= imp_pd_merge(df1[refcols], df0[refcols])\n', '       # return outfile, df1\n', '       df1[refcols].to_csv(outfile, index=False)\n', '\n', '\n', '#####################################################################################\n', 'def imp_numpy_close_fromdb(dbname=\'/aaserialize/store/yahoo.db\', table1=\'\', symlist=[], t0=20010101, t1=20010101, priceid=""close"", batchsize= 400, maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from DB SQL"")\n', ' import data.hist_data_storage as yhh\n', ' dstore= yhh.dailyDataStore(dbname)\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', '\n', "" dateref0= dstore.get_histo(['SPY'], table1='daily_us_etf', start1=str(t0), end1=str(t1),  split_df=0).date.values\n"", ' \n', ' k=0; symfull=[];   i=0\n', ' nsym= len(symlist); nbatch= int(nsym / batchsize)+1\n', ' for j in xrange(0, nbatch) : \n', '      qlist, sym= dstore.get_histo(symlist[i:min(nsym,i+batchsize)], table1=table1, start1=str(t0), end1=str(t1),  split_df=1)\n', '\n', '      #print(""batch: ""+str(j), len(qlist), len(qlist[0].index) )\n', '      #for k,q in enumerate(qlist) :print sym[k], len(q.index)\n', '      i= i + batchsize\n', '      symfull= np.concatenate((symfull,sym))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)\n', '      print(""batch: ""+str(j), len(sym),dateref[0],dateref[-1] )\n', '      qlist=None; sym=None\n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[k:k+masset,0:tmax] = close\n', '      k=k+ masset\n', '\n', ' maxasset= k\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', 'def imp_numpy_close_fromhdfs(dbfile, symlist=[], t0=20010101, t1=20010101, priceid=""close"", maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from Pandas"")\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', ' store = pd.HDFStore(dbfile)\n', ' \n', "" df= store.select('SPY')\n"", ' df= df[(df.date >= t0) & (df.date <= t1 )]\n', ' dateref0= df.date.values\n', ' \n', ' k=0; symfull=[]; qlist=[]; sym=[]; tmax= 2000\n', ' for j, symbol in enumerate(store.keys()):\n', '  symbol=  symbol[1:]\n', '\n', '  if len(symlist)==0  or  util.find(symbol,symlist) > -1 : \n', '   #print symbol, util.find(symbol,symlist) \n', '   df= store.select(symbol) \n', '   if t0 !=t1 :     df= df[(df.date >= t0) & (df.date <= t1 )]\n', '   \n', '   qlist.append(df);   sym.append(symbol)\n', '   if np.mod(j+1, 401) == 0 :\n', '      print(""batch: ""+str(j))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)   \n', '      print len(sym),dateref[0],dateref[-1] \n', '      symfull= symfull+sym\n', '      qlist=[]; sym=[]\n', ' \n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[(k):(k+masset),0:tmax] = close\n', '      k=k+ masset   \n', '     \n', ' if len(qlist) > 0:\n', '  # return qlist, qlist[0] ,  qlist[1] \n', '   close,dateref= date_align(qlist,type1=priceid)   \n', '   print len(sym),dateref[0],dateref[-1] \n', '   symfull= symfull+sym\n', '   masset,tmax= np.shape(close);\n', '   close2[(k):(k+masset),0:tmax] = close\n', ' \n', ' maxasset= k+masset\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', '\n', ""def imp_sql_getquotes(stocklist01, dbname='sqlite:///aaserialize/store/yahoo.db', start1=20150101, end1=20160616, table1='daily_us_stock'):\n"", '    import data.hist_data_storage as yhh\n', '    dstore = yhh.dailyDataStore(dbname)\n', '    qlist, sym= dstore.get_histo(stocklist01, table1=table1,  start1=start1, end1=end1, split_df=1)\n', '    return qlist, sym\n', '\n', ""def imp_txt_getquotes(stocklist01, filedir='E:/_data/stock/daily/20160610/jp', startdate=20150101, endate=20160616):\n"", ' liststockfile= util.listallfile(filedir, ""*.txt"", dirlevel=5)\n', ' #print liststockfile\n', ' if len(np.shape(liststockfile)) > 1 :\n', '  liststockname=[ x.split(""."")[0] for x in liststockfile[:,0] ]\n', '#  for k in range(0, np.shape(liststockfile)[0]):  liststockname.append( (liststockfile[k,0])[0:4])   \n', '   \n', ' else: \n', '  stk0= liststockfile[0]; #stk2= liststockfile[2]\n', '#  liststockname=[ x[0:4] for x in stk0 ]\n', '  liststockname=[ x for x in stk0 ]\n', '\n', '#  liststockname=[]\n', '#  for k in range(0, len(stk0)):  liststockname.append( (stk0[k])[0:4])\n', ' \n', ' quotes=[]\n', ' print liststockname\n', ' for sym in stocklist01:\n', '   kstock= util.np_findfirst(sym, liststockname)\n', '   if kstock == -1 :\n', ""     print('Not Found '+sym)\n"", '   else :\n', '     df= pd.read_csv(liststockfile[kstock][2])\n', ""     df.columns = ['date', 'open', 'high','low','close', 'volume', 'openint']  #Change Column Name\n"", '     df2= df[(df.date > startdate  )& ( df.date   < endate )] # Filter by date\n', '     quotes.append(df2)\n', '  \n', ' return quotes \n', '\n', '\n', 'def imp_csv_getname(name1, date1, inter, tframe):\n', "" file1= dirstockcsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", ' return file1\n', '\n', '\n', ""def imp_csv_toext(file1='SPY.csv', outputfile='.h5', fromzone='Japan', tozone='UTC', header=None,\n"", ""                  cols=['date', 'time','open','high','low','close','volume', 'symbol'], coldate=[0]):\n"", ""  ''' cols: column name,  coldate: position of date column   '''\n"", '  from dateutil import parser\n', '\n', '  if os.path.getsize(file1)> 500 :\n', ""   df = pd.read_csv(file1,sep=',',header=header)  # date_parser=dateparse)  # parse_dates={'date': [] },\n"", '   df.date= [ parser.parse(x) for x in  df.date]\n', '\n', ""   #if util.find('symbol', df.columns.values) < 0 :\n"", ""     #df= util.pd_addcol(df, 'symbol')\n"", ""     #df['symbol']= sym\n"", '\n', ""   type1= outputfile[outputfile.find('.'):]\n"", '\n', ""   if outputfile=='':\n"", '     # df.columns = [  x.lower() for x in df.columns.values ]\n', ""     # df.columns = ['date', 'symbol','open','high','low','close','volume']\n"", '     df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""     df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""     df.columns = ['date', 'open','high','low','close','volume', 'symbol']\n"", '     return df[cols]\n', '\n', ""   if type1=='csv' :\n"", ""     df[cols].to_csv(outputfile , index=False)  # , compression='gzip' )\n"", '\n', ""   if type1== 'h5' :\n"", ""      # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '      dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '      # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '      # df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '      # df.date= [x.to_datetime() for x in  df.date]\n', '\n', '      df.drop(df.columns[[0]], axis=1, inplace=True)\n', '      print filenameh5\n', ""      if util.find('symbol', df.columns.values) < 0 :\n"", ""         df= util.pd_addcol(df, 'symbol'); df['symbol']= dfname\n"", '      store = pd.HDFStore(outputfile); store.append(dfname, df);  store.close()\n', '\n', '\n', '\n', ""def imp_hdfs_db_updatefromcsv(dircsv, filepd=r'E:\\_data\\stock\\intraday_google.h5', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= filepd + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2, name1, fromtimezone, tozone)\n', '\n', ""def imp_hdfs_db_dumpinfo(dbfile='E:\\_data\\stock\\intraday_google.h5'):\n"", '  store = pd.HDFStore(dbfile)\n', '  extract=[]; errsym=[]\n', '  for symbol in store.keys():\n', '     try:\n', '       df= pd.read_hdf(dbfile, symbol)\n', ""       t0= df['date'].values[0]\n"", ""       t1= df['date'].values[-1]\n"", '\n', '       extract.append([symbol[1:], df.shape[1],   df.shape[0], t0, t1 ])\n', '\n', '     except: errsym.append(symbol)\n', '  return np.array(extract), errsym\n', '\n', 'def imp_hdfs_mergedb(filepdfrom, filepdto) :\n', '  store0 = pd.HDFStore(filepdfrom)\n', '  store1 = pd.HDFStore(filepdto)\n', '\n', '  for symbol in store0.keys():\n', '    qq= imp_hdfs_getquote(filepdfrom, symbol)\n', '    store1.append(symbol, qq)\n', '\n', '    qq= imp_hdfs_getquote(filepdto, symbol)\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    print(symbol)\n', '  store0.close(); store1.close()\n', '\n', ""def imp_hdfs_storecopy(hdfs1='F:/usstock8.h5', hdfs2='F:/usstock8.h5'):\n"", ' store = pd.HDFStore(hdfs1);  store2 = pd.HDFStore(hdfs2)\n', ' for symbol in store.keys() :\n', '   df= imp_hdfs_getquote(hdfs1, symbol)\n', '   symbol= symbol[1:].replace(""-"",""_"")\n', '   store2.append(symbol, df, data_columns=True)\n', ' store.close(); store2.close()\n', '\n', 'def imp_hdfs_getquote(filenameh5, dfname=""data""):\n', '  try: return  pd.read_hdf(filenameh5, dfname)\n', '  except: return -1.0;\n', '\n', ""def imp_hdfs_getListquote(symbols, close1='close', start='12/18/2015 00:00:00+00:00',\n"", ""                          end='3/1/2016 00:00:00+00:00', freq='0d0h10min', filepd= 'E:\\_data\\stock\\intraday_google.h5',\n"", ""                          tozone='Japan', fillna=True, interpo=True):\n"", '\n', ' datefilter= pd.date_range(start=start, end=end, freq= freq,tz=tozone).values\n', '\n', ' errorsym=[]; quotes=[]; correctsym=[]\n', ' for symbol in symbols:  # Issue Not same size\n', '   qq= imp_hdfs_getquote(filepd, symbol)\n', '\n', '   if type(qq)==np.float :  # Error qq=-1\n', '        errorsym.append(symbol)\n', '   else:\n', ""       qq.columns = ['date', 'symbol','open','high','low','close','volume']\n"", ""       qq= qq[qq['date'].isin(datefilter)]   #Only date in the range\n"", ""       #qq= qq.drop_duplicates(cols='date', take_last=True)\n"", ""       #  qq= qq.sort('date', asc=True)\n"", '\n', '       #print qq.date.values[0]\n', ""       if fillna : qq= qq.fillna(method='backfill')\n"", '       if interpo : qq= qq.interpolate()\n', '       quotes.append(qq)\n', '       correctsym.append(symbol)\n', '\n', ' datefilter= datenumpy_todatetime(datefilter)\n', ' return quotes,datefilter, correctsym,   errorsym\n', '\n', '\n', ""def imp_hdfs_removeDuplicate(filepd='E:\\_data\\stock\\intraday_google.h5') :\n"", '  #-------Clean by removing duplicate-------------------------------------------------\n', '  store = pd.HDFStore(filepd)\n', '  for symbol in store.keys():\n', '    #qq= imp_hdfs_getquote(filepd, symbol);\n', '    qq= store.select(symbol[1:])\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    qq.index = list(np.arange(0,len(qq.index)))\n', '\n', '    store.remove(symbol); store.append(symbol, qq);\n', '  store.close()\n', '\n', '\n', '\n', ""def imp_pd_tohdfs(sym, qqlist, filenameh5, fromzone='Japan', tozone='UTC') :\n"", ""  ''' df list to HDFS '''\n"", '  store = pd.HDFStore(filenameh5);\n', '  for k, df2 in enumerate(qqlist) :\n', '    df= copy.deepcopy(df2)\n', ""    df['date']= datetime_toint(df.date.values)\n"", '\n', ""    symbol= sym[k].replace('-','_')\n"", '    qq= imp_hdfs_getquote(filenameh5, symbol)\n', '    # print symbol, type(qq)\n', '    if type(qq) ==  float or  type(qq) ==  int  :\n', '      store.append(symbol, df)  # , data_columns=True\n', '      # print(symbol + str(df.date.values[-1]))\n', '    else :\n', '      qq= pd.concat([qq, df], ignore_index=True)\n', ""      qq= qq.drop_duplicates(subset='date', keep='last')\n"", ""      qq= qq.sort('date', ascending=1)\n"", '      store.append(symbol, qq)  #Too much space , data_columns=True\n', '      print(symbol + str(qq.date.values[-1]))\n', '\n', '  store.close()\n', '\n', 'def imp_pd_merge(df1, df2) :\n', '  df= pd.concat([df1, df2], axis=0)\n', ""  df= df.drop_duplicates(subset='date', keep='last')\n"", ""  df= df.sort_values(by=['date'], ascending=1)\n"", '  df.index = list(np.arange(0,len(df.index)))\n', '  return df\n', '\n', 'def imp_pd_checkquote(quotes) :\n', ""   for c in quotes: print np.shape(c), c['date'].values[0], c['date'].values[-1]\n"", '\n', 'def imp_pd_getclose(df, datefilter=None):\n', ' if datefilter is  not None :\n', ""    df= df[df['date'].isin(datefilter)]   #Only date in the range\n"", "" df= df.sort('date')\n"", "" close= df.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", ' \n', ' close= np.array(close.values[1:,1:]).astype(np.float)            #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close\n', '\n', 'def imp_pd_cashyield(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  100 * np.cumprod( (1 + np.ones(len(vv)) * 0.005/365.0 ))\n', '     qbond[id1]= pbond\n', '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_yield_tobond(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  1/ np.power(1+ vv*0.01,duration) *100\n', '     qbond[id1]= pbond\n', ""#     print 'ok'\n"", '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_errordate(quotes, dateref):\n', "" ''' Show Symbol in Error when importing '''\n"", ' for i, stock in enumerate(quotes) :\n', '   print(i, symbols1[i],  datetime_tostring(stock[0][0]))\n', ' print(""\\n\\n"")\n', '\n', ' for i, stock in enumerate(quotes) :\n', '   date1= datetime_toint(stock[0][0])\n', '   if date1 != dateref : print(i, symbols1[i],  str(date1))\n', '\n', 'def imp_pd_fxtoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', 'def imp_pd_fxinversetoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(1.0 / q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', ""def imp_pd_filterbydate(df, dtref=None, start='2016-06-06 00:00:00', end='2016-06-14 00:00:00', freq='0d0h05min', timezone='Japan'):\n"", "" ''' df: DateSeries or TimeSeries of Quotes   '''\n"", '\n', ' if type(df) in {pd.core.frame.DataFrame} :  #Data frame version\n', '   if type(dtref)== str:\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', ""   return df[df['date'].isin(dtref)]\n"", ' else :\n', '   if type(dtref)== str:  #Date version\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', '   return df[df.isin(dtref)].values\n', '\n', 'def imp_pd_cleanquote(q):\n', ' col= q.columns.values\n', "" if isinstance(q['date'].values[0] , str) :\n"", ""   q['date']= datetime_todate(datestring_todatetime(q['date'].values))\n"", '\n', ' for kid in col:\n', ""   if kid not in ['date', 'day','month','year'] :\n"", ""      q[kid]= pd.to_numeric(q[kid], errors='coerce').values  #Put NA on string\n"", '\n', "" q= q.fillna(method='pad')\n"", ' return q\n', '\n', 'def imp_pd_divide(q1, q2, funapply):\n', "" close, dateref= date_align([q1,q2], type1='close')\n"", ' m,tt= np.shape(close)\n', '\n', ' q3= util.pd_createdf( np.zeros((tt,len(q1.columns))) ,q1.columns, dateref)\n', "" q3['date']= dateref\n"", "" q3['close']= (close[0,:] / close[1,:])\n"", '\n', ' for kid in q1.columns :\n', ""   if kid not in ['close', 'volume','date','day','month', 'year'] :\n"", '     close, _= date_align([q1,q2], type1=kid)\n', '     q3[kid]= (close[0,:] / close[1,:])\n', ' return q3\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""def imp_quote_csvdir_tofile(dircsv='', outdir1='E:/_data/stock/', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= outdir + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2,  header=True, fromzone=fromtimezone, tozone=tozone)\n', ""'''\n"", '\n', '\n', ""'''\n"", ""close1='Close' ; start='12/18/2015 00:00:00';\n"", ""end='3/1/2016 00:00:00'; freq='1d0h00min';\n"", ""filepd= 'E:\\_data\\stock\\intraday_google.h5'\n"", '\n', 'datefilter= pd.date_range(start=start, end=end,   freq= freq).values\n', '\n', 'symbols, names = np.array(list(symbol_dict.items())).T\n', 'i=0; vv=[]\n', 'for symbol in symbols:  # Issue Not same size\n', '   qq= quote_frompanda(filepd, symbol); i+=1\n', '   if isfloat(qq) :  vv.append(symbol)\n', '   else:\n', ""     if i==1: close = qq[['Datetime']]  #new dataframe    \n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', '     if not tmp.isnull().values.all():\n', ""      close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""      close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', ""close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", ""close= close.sort('Datetime')\n"", ""close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", 'close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', 'close= close[(np.abs(stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', ""'''\n"", 'from datetime import datetime\n', 'from dateutil import tz\n', '\n', ""from_zone = tz.gettz('Japan'); to_zone = tz.gettz('UTC')\n"", '\n', ""date1 = datetime.strptime('2011-01-21 09:00:00', '%Y-%m-%d %H:%M:%S')\n"", 'date1 = date1.replace(tzinfo=from_zone)\n', 'dateutc = date1.astimezone(to_zone)\n', 'date1, dateutc\n', '\n', ""Suppose you have a column 'datetime' with your string, then:\n"", ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\n"", ' combine multiple columns into a single datetime column,\n', ""this merges a 'date' and a 'time' column into a single 'datetime' column:\n"", '\n', ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)\n"", ""'''\n"", '\n', '\n', '#date1 = ""20160302""; inter= 60; tframe=80; name1= ""spy""\n', '#googleIntradayQuoteSave(name1, inter, tframe)\n', '\n', '\n', '\n', 'def ta_mar(close,t,m):  return  100*( np.mean(close[(t-m):(t+1)], axis=0) / close[t] )\n', 'def ta_ma(close,t,m):  return   np.mean(close[(t-m):(t+1)], axis=0)\n', '\n', '\n', '############################################################################\n', '#---------------------Calculate the Statistics         --------------------  \n', 'def calc_statestock(close2, dateref, symfull):\n', ' def sort(x,col,asc): return   util.sortcol(x,col,asc)\n', ' def perf(close,t0,t1):  return  100*( close[:,t1] / close[:,t0] -1)\n', ' def and2(tuple1):  return np.logical_and.reduce(tuple1)\n', ' def mar(close,t,m):  return  100*( np.mean(close[:,(t-m):(t+1)], axis=1) / close[:,t] )\n', ' def ma(close,t,m):  return   np.mean(close[:,(t-m):(t+1)], axis=1)\n', '\n', '\n', ' # a= ma(close2, tmax, 5) / ma(close2, tmax, 50)  \n', '\n', '\n', ' def dd(t) :\n', '  x= util.find(t,dateref)  # 607\n', ""  if x==-1 : print 'Error date not found in dateref '+str(t) ; return np.nan\n"", '  else :  return x\n', '\n', ' def gap(close,t0,t1,lag):   \n', '  ret= getret_fromquotes(close[:,t0:t1],lag)\n', '  rmin= 100*np.amin(ret,axis=1)\n', '  return rmin\n', ' \n', ' #--------------------Size----------------------------------------- \n', ' masset= len(symfull)\n', ' ttmax= util.find(0,close2[0,:])\n', ' if ttmax==-1 : ttmax= np.shape(close2)[1]\n', ' close2= close2[0:masset,0:ttmax]\n', ' m, tmax= masset, ttmax-1\n', ' \n', ' #correl\n', ' #close3= np.array(close2[:,0:ttmax],dtype=np.float16)\n', ' #close2ret= getret_fromquotes(close3)\n', ' #close2ret= np.nan_to_num(close2ret)\n', ' #close2ret= util.np_cleanmatrix(close2ret);  del close3\n', '\n', '##################################################################################\n', '#1: 1d,2:5d,3:10d,4:15d,5:20d,11:50d,12:60d,13:90d,15:1y\n', '#16: YTD,17:From Feb,21: 2015Ret,45: Price,50,51: Min,52,53: Max\n', ' print(""Calcul the Stats "" + str(dateref[-1]))\n', ' stat= np.zeros((2600,200),dtype=np.float16)\n', '\n', ' k=0\n', ' stat[k:(k+m),0]= np.arange(k,k+m)\n', ' stat[k:(k+m),1]=  perf(close2,tmax-1,tmax)  \n', ' stat[k:(k+m),2]=  perf(close2,tmax-5,tmax)  \n', ' stat[k:(k+m),3]=  perf(close2,tmax-10,tmax)  \n', ' stat[k:(k+m),4]=  perf(close2,tmax-15,tmax)  \n', ' stat[k:(k+m),5]=  perf(close2,tmax-20,tmax)  \n', '# stat[k:(k+m),6]=  perf(close2,tmax-25,tmax)  \n', ' stat[k:(k+m),7]=  perf(close2,tmax-30,tmax)  \n', '# stat[k:(k+m),8]=  perf(close2,tmax-35,tmax)  \n', ' stat[k:(k+m),9]=  perf(close2,tmax-40,tmax)  \n', '# stat[k:(k+m),10]=  perf(close2,tmax-45,tmax)  \n', ' stat[k:(k+m),11]=  perf(close2,tmax-50,tmax)  \n', ' stat[k:(k+m),12]=  perf(close2,tmax-60,tmax)  \n', ' stat[k:(k+m),13]=  perf(close2,tmax-90,tmax)  \n', ' stat[k:(k+m),14]=  perf(close2,tmax-120,tmax)  \n', ' stat[k:(k+m),15]=  perf(close2,tmax-250,tmax)  \n', '\n', '\n', '# stat[k:(k+m),16]=  perf(close2, dd(20160105),tmax)   #1Jan 2016\n', '# stat[k:(k+m),17]=  perf(close2, dd(20160222),tmax)   # 22 Feb 2016\n', '# stat[k:(k+m),18]=  perf(close2,dd(20160105),dd(20160222))   # Crash DrawDown\n', ' # stat[k:(k+m),19]=  perf(close2,624,tmax)   #  24 June 2016\n', ' # stat[k:(k+m),20]=  perf(close2,623,625)   #  Crash 24 June 2016\n', ' # stat[k:(k+m),21]=  perf(close2,dd(20151230)-250,dd(20151230))    #2015 Return\n', '\n', ' stat[k:(k+m),22]= gap(close2,tmax-80,tmax,1) #Max 1 days Gap\n', ' stat[k:(k+m),23]= gap(close2,tmax-80,tmax,5) #Max 5 days Gap\n', ' stat[k:(k+m),24]= perf(close2,tmax-2,tmax)  \n', ' stat[k:(k+m),25]= perf(close2,tmax-3,tmax)  \n', ' stat[k:(k+m),26]= perf(close2,tmax-4,tmax)  \n', '\n', ' stat[k:(k+m),27]= perf(close2,tmax-2,tmax-1)   \n', ' stat[k:(k+m),28]= perf(close2,tmax-3,tmax-2)   \n', ' stat[k:(k+m),29]= perf(close2,tmax-4,tmax-3)   \n', ' stat[k:(k+m),30]= perf(close2,tmax-5,tmax-4)\n', ' \n', ' stat[k:(k+m),120]= mar(close2, tmax, 20) \n', ' stat[k:(k+m),121]= mar(close2, tmax, 50) \n', ' stat[k:(k+m),122]= 100*ma(close2, tmax, 5) / ma(close2, tmax, 50)  #OverSold /OverBought\n', ' stat[k:(k+m),123]= mar(close2, tmax, 100)  \n', ' stat[k:(k+m),124]= mar(close2, tmax, 10) \n', '# stat[k:(k+m),35]= 0 \n', '# stat[k:(k+m),36]= 0 \n', '# stat[k:(k+m),37]= 0 \n', '# stat[k:(k+m),38]= 0 \n', '# stat[k:(k+m),39]= 0 \n', '\n', ' # stat[k:(k+m),30]= volume / AvgVol3M\n', ' # stat[k:(k+m),30]= Nbday_to_Earnings\n', ' #Volume/3M AvgVolume\n', ' # stat[k:(k+m),26]=  volume(volume2,tmax-120,tmax)  \n', '\n', ' #==============================================================================\n', ' #-------------- Data Fundamental    -------------------------------------------\n', "" df= util.sql_query(sqlr='SELECT ticker,shortratio,sector1_id, sector2_id, marketcap   FROM stockfundamental ', dburl='/aaserialize/store/finviz.db')\n"", ' npdf= df.values; del df\n', ' npdf0= npdf[:,0]  \n', ' for i in range(0,m):  \n', '   try :\n', '     kid= util.find(symfull[i], npdf0)\n', '     if kid != -1 :\n', '      stat[i,150]=  float(npdf[kid, 1])   # short ratio\n', '      stat[i,151]=  float(npdf[kid, 2])   # sector 1      \n', '      stat[i,152]=  float(npdf[kid, 3])   # sector 2     \n', '      stat[i,153]=  float(npdf[kid, 4] / 100000000.0)   # market Cap    \n', '   except : pass\n', ' del npdf, npdf0\n', '\n', '\n', '#==============================================================================\n', ' ################ Volatility\n', ' stat[k:(k+m),40]= volhisto_fromprice(close2,tmax,20,axis=1)* 100\n', ' stat[k:(k+m),41]= volhisto_fromprice(close2,tmax,60,axis=1)* 100\n', ' stat[k:(k+m),42]= volhisto_fromprice(close2,tmax,252,axis=1)* 100\n', '# stat[k:(k+m),43]= stat[k:(k+m),12] / stat[k:(k+m),41] #Sharpe 3Month\n', '# stat[k:(k+m),44]= stat[k:(k+m),15] / stat[k:(k+m),42] #Sharpe 1Year\n', '\n', ' stat[k:(k+m),45]= close2[:,tmax] #Last Close\n', '\n', '# stat[k:(k+m),46]= 0 \n', '# stat[k:(k+m),47]= 0 \n', '# stat[k:(k+m),48]= 0 \n', '# stat[k:(k+m),49]= 0 \n', '\n', '\n', ' ###############  Technical Indicator\n', ' #Min of last 6 months, Max of last 6months\n', ' for i in range(0,m):\n', '  pp0= stat[i,45]\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-120):tmax])\n', '  stat[i,50]= kmin+(tmax-120);  stat[i,51]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-120):tmax])\n', '  stat[i,52]= kmax+(tmax-120);  stat[i,53]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-10):tmax])\n', '  stat[i,66]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-10):tmax])\n', '  stat[i,67]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-5):tmax])\n', '  stat[i,68]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-5):tmax])\n', '  stat[i,69]= 100*pp0 / pmax\n', '\n', ' del kmax,pmax,i,k  \n', '\n', '\n', ' #Regression from Min Price Time\n', ' for i in range(0,m):\n', '  t0= int(stat[i,50])\n', '  try :\n', '    res= regression(close2[i,t0:tmax ]  ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,54]=  res[2]  #R2\n', '    stat[i,55]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from Max Price Time\n', ' for i in range(0,m):  \n', '  t0= stat[i,52]\n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,56]=  res[2]  #R2\n', '    stat[i,57]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from 5 days ago\n', ' t0= tmax-5\n', ' for i in range(0,m): \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,58]=  res[2]  #R2\n', '    stat[i,59]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', '#Regression from 10 days ago\n', ' t0= tmax-10\n', ' for i in range(0,m):  \n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,60]=  res[2]  #R2\n', '    stat[i,61]=  res[0][0]  #Slope\n', '   except : pass\n', '\n', "" '''\n"", '#Regression from 1 month\n', ' t0= tmax-20   \n', ' for i in range(0,m):\n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,62]=  res[2]  #R2\n', '    stat[i,63]=  res[0][0]  #Slope\n', '   except : pass\n', "" '''\n"", '\n', "" '''\n"", '#Regression from 2 months ago\n', ' t0= tmax-40\n', ' for i in range(0,m):  \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,64]=  res[2]  #R2\n', '    stat[i,65]=  res[0][0]  #Slope\n', '  except : pass\n', "" '''\n"", '\n', '#Nb of Positive days last 5d\n', ' for i in range(0,m):  stat[i,66]=  np_countretsign(close2[i,(tmax-5):tmax])  \n', '\n', '#Nb of Positive days last 10d\n', ' for i in range(0,m):  stat[i,67]=  np_countretsign(close2[i,(tmax-10):tmax])  \n', '\n', '#Nb of Positive days last 20d\n', '# for i in range(0,m):  stat[i,68]=  np_countretsign(close2[i,(tmax-20):tmax])  \n', '\n', '\n', '#Regression from Max Values,200days\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,70]=  res[2]  #R2\n', '    stat[i,71]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmax\n', '\n', '\n', '#Regression from Min Values,200days \n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,72]=  res[2]  #R2\n', '    stat[i,73]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmin\n', '\n', '\n', '#Regression from Max Values,100days\n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,74]=  res[2]  #R2\n', '    stat[i,75]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmax\n', '\n', '\n', '#Regression from Min Values,100days \n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,76]=  res[2]  #R2\n', '    stat[i,77]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmin\n', '\n', '\n', '\n', '# Upside Trend with Higher Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '   vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '   vmax= util.sort(vmax,0,asc=0)\n', '   stat[i,80]=  -1\n', '   if len(vmax) > 1 :\n', '    ss=0\n', '    for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '    if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,80]=  ss  \n', '        stat[i,81]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Upside Trend with Higher High detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '    vmax= util.sort(vmax,0,asc=0)\n', '    stat[i,82]=  -1\n', '    if len(vmax) > 1 :\n', '      ss=0\n', '      for k in range(0,len(vmax)-1):\n', '        if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher high\n', '        else : break;\n', '      if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,82]=  ss  \n', '        stat[i,83]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Downside Trend with lower Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,84]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,84]=  ss  \n', '        stat[i,85]=  vmax[0,0] + t0\n', '\n', '\n', '# Downside Trend  with lower highs detection\n', ' t0= tmax-20*6\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,80]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,86]=  ss    #Nb  of lower high consecutive\n', '        stat[i,87]=  vmax[0,0] + t0\n', '\n', "" print('Higher/Lower Band Support')\n"", '#-----higher band Support / Lower Band Support 120days-------------------------------\n', ' t0= tmax-120\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,90]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,91]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,92]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '    # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1]) \n', '    # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 200days-------------------------------\n', ' t0= tmax-200\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,93]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,94]= 100.0 * stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,95]= 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 300days-------------------------------------\n', ' t0= tmax-300\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,96]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,97]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,98]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', ""  '''\n"", '  # -----higher band Support / Lower Band Support 60days-------------------------------\n', '  t0 = tmax - 60\n', '  for i in range(0, m):\n', '      try:\n', '          res1 = ta_highbandtrend1(close2[i, t0:tmax])\n', '          pmax = (res1.x[0] * (tmax - t0) + res1.x[1])\n', '          stat[i, 99] = 100.0 * stat[i, 45] / pmax  # Higher Band\n', '\n', '          res2 = ta_lowbandtrend1(close2[i, t0:tmax])\n', '          pmin = (res2.x[0] * (tmax - t0) + res2.x[1])\n', '          stat[i, 100] = 100.0 * stat[i, 45] / pmin  # LowerBand\n', '\n', '          stat[i, 101] = 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)  # Price inside Range\n', '\n', '          # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1])\n', '          # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '      except:\n', '          pass\n', ""  '''\n"", '\n', '  #-----Technical Indicator------------------------------------------------\n', '# for i in range(0,m): \n', '#  try :\n', '#   res2=0\n', '   # df= pd.read_hdf(dbfile, symfull[i])\n', '   # stat[i,110]= ta.RMI(close2[i,:])\n', '   # stat[i,111]= 100*close2[i,:] / ta.MA(close2[i,:],20)\n', '   # stat[i,112]= 100*close2[i,:] / ta.MA(close2[i,:],50)   \n', '#  except: pass\n', '\n', '\n', ' return np.array(stat, dtype=np.float16) \n', '\n', '\n', ""'''  \n"", 'i=1964  \n', 'stat= s1\n', 'stat[i, 91]  \n', '\n', 'tt= np.arange(t0, tmax)\n', 'plot_price(close2[i,t0:tmax], (res2.x[0] * (tt-t0) + res2.x[1]) )\n', ""'''\n"", '\n', '  \n', '#------------------- Stock Monitoring Tools ------------------------------------------------\n', ""def monitor_addrecommend(string1, dbname='stock_recommend') :\n"", ' ss= string1.replace(""("","" "").replace(\')\',\' \').replace(\':\',\' \')\n', "" ss= ss.replace('\\t', ' ').replace('\\n', ' ')\n"", ' sl1= ss.split("" "")\n', ' print sl1\n', ' aux= [datestring_toint(util.date_now())]\n', ' symfull= copy.deepcopy(a_us_all)\n', ' for x in sl1:\n', '   if len(x) < 5 :\n', '    if util.find(x,symfull) > 0 :   aux.append(x)\n', '\n', ' if len(aux) >  1 :\n', '  stock_recommend= util.load_obj(dbname)\n', '  stock_recommend.append(aux)\n', '  util.save_obj(stock_recommend,dbname)\n', '  print aux\n', ' return stock_recommend\n', '\n', '\n', '\n', '#################### Finviz  ###############################################################\n', 'from bs4 import BeautifulSoup\n', 'import csv,datetime, requests\n', 'def imp_finviz():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Overview Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=111&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(111) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 10].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 10\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockoverview.csv', 'wb') as csvfile:\n"", ""    overview = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    overview.writeheader()\n', '\n', '    for stock in alldata:\n', '        overview.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10] })\n', '\n', ' print ""Finviz Overview Completed""\n', ' return overview\n', ' \n', '\n', 'def imp_finviz_news():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Performance Start""\n', ' url = ""http://www.finviz.com/quote.ashx?t=intc""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', ' titleslist = soup.find_all(\'a\',{""class"" : ""tab-link-news""})\n', ' return titleslist\n', '\n', '\n', 'def imp_finviz_financials():\n', ' import datetime\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=161&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(161) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 17].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 16].text,stockdata[datalength - 15].text,stockdata[datalength - 14].text,stockdata[datalength - 13].text,stockdata[datalength - 12].text,stockdata[datalength - 11].text,stockdata[datalength - 10].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 17\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockfinancial.csv', 'wb') as csvfile:\n"", ""    financial = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    financial.writeheader()\n', '\n', '    for stock in alldata:\n', '        financial.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10],titlesarray[11] : stock[11],titlesarray[12] : stock[12],titlesarray[13] : stock[13],titlesarray[14] : stock[14],titlesarray[15] : stock[15],titlesarray[16] : stock[16],titlesarray[17] : stock[17] })\n', '\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Completed""\n', '\n', '\n', '\n', 'def get_price2book( symbol ):\n', '   from bs4 import BeautifulSoup as bs\n', '   import urllib as u\n', '   try:\n', ""    \turl = r'http://finviz.com/quote.ashx?t={}'.format(symbol.lower())\n"", '        html = u.request.urlopen(url).read()\n', ""        soup = bs(html, 'lxml')\n"", '        # Change the text below to get a diff metric\n', ""        pb =  soup.find(text = r'P/B')\n"", ""        pb_ = pb.find_next(class_='snapshot-td2').text\n"", ""        print( '{} price to book = {}'.format(symbol, pb_) )\n"", '        return pb_\n', '   except Exception as e:\n', '        print(e)\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ' try:\n', '   q = imp_googleQuote(name1, date1, date2)  #interval, timeframe\n', ""   name1= name1.replace(':','_')\n"", ""   file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(date2) +'.csv'\n"", '   q.write_csv(file1)\n', ' except: print\n', ""'''\n"", '\n', '\n', ""'''\n"", 'def imp_googleQuoteList(symbols, freqsec=300, nday=1, intraday1=True) :\n', ' qlist=[]; sym=[]\n', ' if intraday1:\n', '  for symbol in symbols:\n', '     #try :\n', '        q = imp_googleIntradayQuote(symbol, freqsec, nday)  #interval, timeframe\n', '        qlist.append(q)\n', '        sym.append(symbol)\n', ""     #except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       q = imp_googleQuote(name1, freqsec, num_days)  #interval, timeframe\n', '     except: print(symbol)\n', '\n', ' return qlist, sym\n', ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''        \n"", ""stock_list = ['XOM','AMZN','AAPL','SWKS']\n"", 'p2b_series = pd.Series( index=stock_list )\n', '\n', 'for sym in stock_list:\tp2b_series[sym] = get_price2book(sym)\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", "" # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", ' from dateutil.parser import parse\n', ' if os.path.getsize(file1)> 500 :\n', '  from_zone = tz.gettz(fromzone); tozone = tz.gettz(tozone)\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%m-%d-%Y %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', '  dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '\n', '  # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '  print file1\n', ""  #df = pd.read_csv(file1,sep=',',header=None, parse_dates={'date': [1]}, date_parser=dateparse)\n"", '\n', ""  df = pd.read_csv(file1,sep=',',header=0)\n"", '  #df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '  #df.date= [x.to_datetime() for x in  df.date]\n', '\n', '\n', '  df.drop(df.columns[[0]], axis=1, inplace=True)\n', ""  df= util.pd_addcol(df, 'symbol')\n"", ""  df['symbol']= dfname\n"", '\n', '  print filenameh5\n', ""  df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", ""  df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", '\n', '  # store = pd.HDFStore(filenameh5);\n', '  # store.append(dfname, df);  store.close()\n', ""'''\n"", '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dropcol=[], type1='csv', hasheader=True, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", ' if os.path.getsize(file1)> 500 :\n', '   header= 0 if hasheader else None\n', ""   df = pd.read_csv(file1, sep=',',header=0)\n"", '\n', '   df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""   df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""   df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", '\n', ""   if type1=='csv' :\n"", ""     df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""     if i==1: close = qq[['Datetime']]  #new dataframe\n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', ""     close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""     close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', "" close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", "" close= close.sort('Datetime')\n"", "" close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", '\n', ' close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", 'class Quote(object):\n', ""  DATE_FMT = '%Y-%m-%d';  TIME_FMT = '%H:%M:%S'\n"", '\n', '  def __init__(self):\n', ""    self.symbol = '';    self.exchn=''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', '\n', '  def append(self,dt,open_,high,low,close,volume):\n', '    self.date.append(dt.date())\n', '    self.time.append(dt.time())\n', '    self.open_.append(float(open_))\n', '    self.high.append(float(high))\n', '    self.low.append(float(low))\n', '    self.close.append(float(close))\n', '    self.volume.append(int(volume))\n', '\n', '  def to_csv(self):\n', '    return \'\'.join([""{0},{1},{2},{3:.2f},{4:.2f},{5:.2f},{6:.2f},{7}\\n"".format(self.symbol,\n', ""              self.date[bar].strftime('%Y-%m-%d'),self.time[bar].strftime('%H:%M:%S'),\n"", '              self.open_[bar],self.high[bar],self.low[bar],self.close[bar],self.volume[bar])\n', '              for bar in xrange(len(self.close))])\n', '\n', '  def write_csv(self,filename):\n', ""    with open(filename,'w') as f:\n"", '      txt= self.to_csv()\n', '      f.write(txt)\n', '\n', '  def read_csv(self,filename):\n', ""    self.symbol = ''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', ""    for line in open(filename,'r'):\n"", ""      symbol,ds,ts,open_,high,low,close,volume = line.rstrip().split(',')\n"", '      self.symbol = symbol\n', ""      dt = datetime.datetime.strptime(ds+' '+ts,self.DATE_FMT+' '+self.TIME_FMT)\n"", '      self.append(dt,open_,high,low,close,volume)\n', '    return True\n', '\n', '  def __repr__(self):\n', '    return self.to_csv()\n', ""'''\n"", '\n', ' \n', '\n', ""'''\n"", ""def imp_googleIntradayQuoteSave2(name1, date1, inter, tframe, dircsv='', dbname=''):\n"", ' q = imp_googleIntradayQuote(name1, inter, tframe)  #interval, timeframe\n', "" name1= name1.replace(':','_')\n"", '\n', "" if dircsv != '' :\n"", ""    file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", '    q.to_csv(file1)\n', '\n', "" if dbname != '' :\n"", '    import sqlalchemy as sql\n', '    dbcon= sql.create_engine(dbname)\n', '    if inter== 300 : # 5mins\n', ""      q.to_sql('q5min', dbcon)\n"", '\n', '\n', ""def imp_googleQuoteList_save(symbols, date1, date2, inter=23400, tframe=2000, dircsv='', intraday1=True) :\n"", ' if intraday1:\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleIntradayQuoteSave(symbol, date1, inter, tframe, dircsv)\n', ""     except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleQuoteSave(symbol, date1, date2, dircsv)\n', '     except: print(symbol)\n', ""'''\n"", '\n']","['np.shape', 'getret_fromquotes', 'len', 'getlogret_fromquotes', 'np.log', 'getprice_fromret']",6
utilmy/zarchive/portfolio.py:index,index,class,103,300,221,3009,10.03,1,3,[],[],[],1625,[],[],0
utilmy/zarchive/portfolio.py:folioCalc,folioCalc,class,125,509,332,4736,9.3,2,17,[],[],[],1924,[],[],0
utilmy/zarchive/portfolio.py:folioRiskIndicator,folioRiskIndicator,class,89,306,215,3180,10.39,1,9,[],[],[],2099,[],[],0
utilmy/zarchive/portfolio.py:folioOptimizationF,folioOptimizationF,class,280,1291,671,10994,8.52,6,39,[],[],[],2277,[],[],0
utilmy/zarchive/portfolio.py:searchSimilarity,searchSimilarity,class,173,497,328,4550,9.15,8,17,[],[],[],3724,[],[],0
utilmy/zarchive/portfolio.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1626,[],['date_generatedatetime'],1
utilmy/zarchive/portfolio.py:index:close,index:close,method,0,1,1,4,4.0,0,0,['self'],[None],[None],1631,[],[],0
utilmy/zarchive/portfolio.py:index:updatehisto,index:updatehisto,method,2,12,11,62,5.17,0,0,['self)'],['  #Download Quotespassself) :'],[None],1634,[],['print'],1
utilmy/zarchive/portfolio.py:index:help,index:help,method,2,12,11,62,5.17,0,0,['self'],[None],[None],1638,[],['print'],1
utilmy/zarchive/portfolio.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]",['date_generatedatetime'],1
utilmy/zarchive/portfolio.py:index:calc_baskettable_pct,index:calc_baskettable_pct,method,37,95,77,782,8.23,1,2,"['self', 'type1', 'showdetail']","[None, None, None]","[None, '""table""', '0']",1703,"[""      '''   Calc Basket Values from Input data '''\n""]","['np.zeros', 'np.sum', 'self._udpate_wwindpct', 'range', 'np.mod', 'self._wwpct_rebal']",6
utilmy/zarchive/portfolio.py:index:_wwpct_rebal,index:_wwpct_rebal,method,3,4,3,41,10.25,0,0,"['self', 'wwpct_actual', 't', 'trebal)', '']","[None, None, None, '  # BskUnit', ']np.abs(wwpct_actual/wwpct_th  -1 )) > self.rebal_trigger:']","[None, None, None, ' 1.0  !!!wwpct_th = self.wwasset[trebal', None]",1730,[],[],0
utilmy/zarchive/portfolio.py:index:_udpate_wwindpct,index:_udpate_wwindpct,method,11,25,17,224,8.96,0,0,"['self', 't', 'bskt', 'hedgecost', 'wwpct_actual', 'wwpct_th']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",1740,[],[],0
utilmy/zarchive/portfolio.py:index:calc_baskettable_unit,index:calc_baskettable_unit,method,0,0,0,0,0.0,0,0,[],[],[],1749,"[""    '''   t           --->  t+1                 ---->   t+2\n"", '            wwactual:    B[t]    -->   B[t+1]   using  w[t+1], B[t] /   S[t]\n', '            wwnew   :    B[t+1]  -->   B[t+2]   using  w[t+2], B[t+1] /   S[t+1]\n', ""    '''\n""]",[],0
utilmy/zarchive/portfolio.py:folioCalc:__init__,folioCalc:__init__,method,21,39,37,356,9.13,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1925,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioCalc:set_symclose,folioCalc:set_symclose,method,17,34,33,312,9.18,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1938,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioCalc:setcriteria,folioCalc:setcriteria,method,41,76,71,1046,13.76,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",1947,"[""        ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '            wwtype:     constant / regime /regimExtra\n', '            initperiod: NbOfDays_initial_Risk_Monitoring\n', '            riskid:     spprice/spperf/multi\n', ""        '''\n""]","['np.array', 'len']",2
utilmy/zarchive/portfolio.py:folioCalc:_weightcalc_generic,folioCalc:_weightcalc_generic,method,5,35,23,396,11.31,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",1997,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/portfolio.py:folioCalc:_weightcalc_regime,folioCalc:_weightcalc_regime,method,10,37,32,272,7.35,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2008,[],"['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/portfolio.py:folioCalc:_regimecalc,folioCalc:_regimecalc,method,3,7,6,83,11.86,0,0,"['self', 't', 'wwextra)', 't - 1]self.riskind[0', 't - 1] / self.riskind[0', 't - 1 - self.nbrange] - 1if self.riskid == ""multi""']","[None, None, '  # Risk Indicatorif self.riskid ', None, None, '']","[None, None, '= ""spprice"":   return self.riskind[0', None, None, '= ""multi"":']",2018,[],['self._mapping_calc_risk'],1
utilmy/zarchive/portfolio.py:folioCalc:_weightcalc_constant,folioCalc:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2027,[],['np.sum'],1
utilmy/zarchive/portfolio.py:folioCalc:getweight,folioCalc:getweight,method,5,12,9,126,10.5,0,0,['self'],[None],[None],2031,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/portfolio.py:folioCalc:calc_baskettable,folioCalc:calc_baskettable,method,33,111,83,811,7.31,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', '0.000', '0']",2038,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/portfolio.py:folioCalc:plot,folioCalc:plot,method,10,29,26,295,10.17,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2066,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/portfolio.py:folioCalc:multiperiod_ww,folioCalc:multiperiod_ww,method,15,36,29,240,6.67,1,1,"['self', 't']","[None, None]","[None, None]",2077,[],['xrange'],1
utilmy/zarchive/portfolio.py:folioCalc:help,folioCalc:help,method,1,2,2,13,6.5,0,0,['self'],[None],[None],2090,[],['print'],1
utilmy/zarchive/portfolio.py:folioRiskIndicator:__init__,folioRiskIndicator:__init__,method,23,40,38,356,8.9,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioRiskIndicator:set_symclose,folioRiskIndicator:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2114,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioRiskIndicator:setcriteria,folioRiskIndicator:setcriteria,method,34,81,70,1006,12.42,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2124,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'np.zeros']",3
utilmy/zarchive/portfolio.py:folioRiskIndicator:calcrisk,folioRiskIndicator:calcrisk,method,13,18,17,220,12.22,1,0,"['self', 'wwvec', 'initval']","[None, None, None]","[None, '[]', '1']",2172,[],"['xrange', 'self._weightcalc_generic', 'np.column_stack']",3
utilmy/zarchive/portfolio.py:folioRiskIndicator:_weightcalc_generic,folioRiskIndicator:_weightcalc_generic,method,4,34,24,327,9.62,0,3,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2184,[],"['self._weightcalc_regime', 'print']",2
utilmy/zarchive/portfolio.py:folioRiskIndicator:_weightcalc_regime,folioRiskIndicator:_weightcalc_regime,method,3,11,11,68,6.18,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2193,[],['self._regimecalc'],1
utilmy/zarchive/portfolio.py:folioRiskIndicator:_regimecalc,folioRiskIndicator:_regimecalc,method,7,18,17,216,12.0,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )self.riskind', 'wwextra', 't', 'self.riskind_out)self', 'maxiter', 'name1', 'isreset', 'popsize=15) ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, None, None, None, None, None, None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, None, None, None, None, '1', ""''"", '1', '15) :']",2198,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio.py:folioRiskIndicator:calc_optimal_weight,folioRiskIndicator:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2204,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:__init__,folioOptimizationF:__init__,method,23,39,37,340,8.72,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioOptimizationF:set_symclose,folioOptimizationF:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2114,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioOptimizationF:setcriteria,folioOptimizationF:setcriteria,method,44,128,103,1669,13.04,0,2,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2124,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'print', 'list']",4
utilmy/zarchive/portfolio.py:folioOptimizationF:calcbasket_obj2,folioOptimizationF:calcbasket_obj2,method,23,76,63,756,9.95,0,1,"['self', 'wwvec']","[None, None]","[None, None]",2362,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float']",6
utilmy/zarchive/portfolio.py:folioOptimizationF:calcbasket_obj,folioOptimizationF:calcbasket_obj,method,55,157,118,1494,9.52,1,4,"['self', 'wwvec']","[None, None]","[None, None]",2388,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float', 'calcbasket_obj', 'concenfactor=folio_concenfactor2', 'np.zeros', 'xrange', 'np.mod', 'self._weightcalc_generic', 'self._loss_obj', 'self._objective_criteria']",14
utilmy/zarchive/portfolio.py:folioOptimizationF:_loss_obj,folioOptimizationF:_loss_obj,method,4,6,6,68,11.33,0,0,"['self', 'ww2', 'wwpenalty']","[None, None, None]","[None, None, None]",2413,[],['np.sum'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:_weightcalc_generic,folioOptimizationF:_weightcalc_generic,method,5,40,26,394,9.85,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2184,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/portfolio.py:folioOptimizationF:_weightcalc_regime,folioOptimizationF:_weightcalc_regime,method,8,32,28,239,7.47,0,0,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2193,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']","['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/portfolio.py:folioOptimizationF:_regimecalc,folioOptimizationF:_regimecalc,method,4,7,7,83,11.86,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )if self.riskid== ""multi""   ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, '= ""multi""   :']",2198,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']",['self._mapping_calc_risk'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:_weightcalc_constant,folioOptimizationF:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2452,[],['np.sum'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:calc_optimal_weight,folioOptimizationF:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2204,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:getweight,folioOptimizationF:getweight,method,6,11,9,126,11.45,0,0,['self'],[None],[None],2461,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/portfolio.py:folioOptimizationF:calc_baskettable,folioOptimizationF:calc_baskettable,method,36,86,72,827,9.62,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', ' 0.000', '0']",2469,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/portfolio.py:folioOptimizationF:plot,folioOptimizationF:plot,method,11,31,30,294,9.48,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2498,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/portfolio.py:folioOptimizationF:_objective_criteria,folioOptimizationF:_objective_criteria,method,31,147,78,1105,7.52,2,7,"['self', 'bsk']","[None, None]","[None, None]",2510,[],"['np.std', 'np.sum', 'range', 'np.arange']",4
utilmy/zarchive/portfolio.py:folioOptimizationF:multiperiod_ww,folioOptimizationF:multiperiod_ww,method,18,29,27,238,8.21,1,1,"['self', 't']","[None, None]","[None, None]",2557,[],['xrange'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:help,folioOptimizationF:help,method,50,152,103,1472,9.68,1,6,['self'],[None],[None],2569,[],"['print', 'util.load_obj', 'int', 'copy.deepcopy', 'xrange', 'next', 'util.save_obj', 'np.mod', 'np.abs', 'np.reshape', 'np.sum']",11
utilmy/zarchive/portfolio.py:folioOptimizationF:mapping_risk_ww,folioOptimizationF:mapping_risk_ww,method,12,56,29,245,4.38,0,1,"['self', 'risk', 'wwmat', 'ww2']","[None, None, None, None]","[None, None, None, 'self.wwasset0']",2628,[],"['np.sum', 'np.array']",2
utilmy/zarchive/portfolio.py:folioOptimizationF:_mapping_calc_risk,folioOptimizationF:_mapping_calc_risk,method,27,201,76,831,4.13,0,3,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",2640,[],[],0
utilmy/zarchive/portfolio.py:searchSimilarity:__init__,searchSimilarity:__init__,method,15,18,17,193,10.72,0,0,"['self', ""filejpstock=r'E"", 'sym01', 'symname', 'startdate', 'enddate', 'pricetype']","[None, '', None, None, None, None, None]","[None, ""r'E:/_data/stock/daily/20160616/jp'"", ""['7203']"", ""['Toyota']"", ' 20150101', '20160601', '""close""']",3725,[],[],0
utilmy/zarchive/portfolio.py:searchSimilarity:load_quotes_fromdb,searchSimilarity:load_quotes_fromdb,method,15,35,33,355,10.14,0,1,"['self', 'picklefile']","[None, None]","[None, ""''""]",3730,[],"['util.load_obj', 'imp_txt_getquotes', 'date_align', 'util.a_cleanmemory']",4
utilmy/zarchive/portfolio.py:searchSimilarity:__generate_return__,searchSimilarity:__generate_return__,method,4,4,4,64,16.0,0,0,"['self', 'nlag']","[None, None]","[None, None]",3741,[],['getret_fromquotes'],1
utilmy/zarchive/portfolio.py:searchSimilarity:__overweight__,searchSimilarity:__overweight__,method,17,62,41,412,6.65,2,4,"['self', 'px']","[None, None]","[None, None]",3745,[],"['len', 'np.ones', 'util.np_findlocalmax', 'type', 'np.abs', 'wwerr[max', 'util.np_findlocalmin']",7
utilmy/zarchive/portfolio.py:searchSimilarity:set_searchcriteria,searchSimilarity:set_searchcriteria,method,34,79,63,793,10.04,0,5,"['self', 'name1', 'date1', 'date2', 'nlag', 'searchperiodstart', 'typesearch', '']","[None, None, None, None, None, None, None, None]","[None, ""'7203'"", '20160301', '20160601', '1', '20120101', '""pattern2""', None]",3765,[],"['getret_fromquotes', 'date_finddateid', 'max', 'util.np_findfirst', 'print', 'price_normalize_1d', 'len', 'self.__overweight__']",8
utilmy/zarchive/portfolio.py:searchSimilarity:launch_search,searchSimilarity:launch_search,method,53,107,81,908,8.49,3,3,['self'],[None],[None],3794,[],"['len', 'np.zeros', 'range', 'price_normalize_1d', 'np_similarity', 'util.np_sortbycolumn', 'enumerate']",7
utilmy/zarchive/portfolio.py:searchSimilarity:show_comparison_graph,searchSimilarity:show_comparison_graph,method,33,72,63,682,9.47,1,3,"['self', 'maxresult', 'show_only_different_time', 'fromid', 'fromend', 'filenameout']","[None, None, None, None, None, None]","[None, '20', 'True', '0', ' 0', ""''""]",3828,[],"['np.shape', 'range', 'int', 'print', 'price_normalize_1d', 'str', 'plot_price']",7
utilmy/zarchive/portfolio.py:searchSimilarity:staticmethod,searchSimilarity:staticmethod,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",3857,[],[],0
utilmy/zarchive/portfolio.py:searchSimilarity:get_rankresult,searchSimilarity:get_rankresult,method,24,63,53,496,7.87,2,1,"['self', 'filetosave']","[None, None]","[None, ""''""]",3861,[],"['len', 'np.savetxt', 'np.shape', 'np.array', 'np.empty', 'range', 'int', 'str']",8
utilmy/zarchive/portfolio.py:searchSimilarity:export_results,searchSimilarity:export_results,method,0,0,0,0,0.0,0,0,[],[],[],3883,"[""'''\n"", '#####################################################################################\n', '#---------Run over all the indexes, with time lag -----------------------------------\n', 'def np_similarity(x,y, wwerr=[], type1=0):\n', '  if type1==2 : return np_distance_l1(x,y, wwerr)\n', '  if type1==1: return sci.spatial.distance.correlation(x, y)  \n', '  if type1==0 : return 1-np.corrcoef(x,y)[0,1]\n', '\n', 'def np_distance_l1(x,y, wwerr) :\n', ' return np.sum(wwerr * np.abs(x-y))  \n', '  \n', '#---------------------  Universe Load         ---------------------------------------\n', ""filejpstock= r'E:/_data/stock/daily/20160616/jp'\n"", 'sym01= nk400list\n', '\n', 'quotes= imp_txt_getquotes(sym01, filejpstock, startdate=20090101, endate=20160616)\n', 'open1, dateref= date_align(quotes, type1=""close"")    #Get the data and align dates\n', 'del quotes; util.a_cleanmemory()\n', '\n', ""#util.save_obj(open1, 'close_nk400_2009_2016')\n"", ""#util.save_obj(dateref, 'dateref_nk400_2009_2016')\n"", '\n', ""open1= util.load_obj('close_nk400_2009_2016')\n"", ""dateref= util.load_obj( 'dateref_nk400_2009_2016')\n"", '\n', 'nlag=1\n', 'ret_open1 =  getdailyret_fromquotes(open1,nlag)\n', 'del open1\n', '\n', '#--------------------  Search Asset Input     ---------------------------------------\n', ""name1= '7203' \n"", 'date1= 20160328\n', 'date2= 20160531\n', 'twindow= util.np_findfirst(date2, dateref) - util.np_findfirst(date1, dateref) \n', '\n', '\n', 'tstartx= util.np_findfirst(date1, dateref)          # Date Index\n', 'stockx= util.np_findfirst(name1, sym01)\n', 'retx= ret_open1[stockx, tstartx:(tstartx+twindow-1)]    # Recent Period\n', 'px= price_normalize_1d(retx)\n', 'nx= len(px)\n', '\n', '\n', '#----OverWeight for Local Min, Local Max         -----------------------------------\n', 'wwerr= np.ones(nx, dtype=np.float16)\n', 'vvmax= util.np_findlocalmax(px); xprev=0\n', 'for x in vvmax:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', 'vvmin= util.np_findlocalmin(px); xprev=0\n', 'for x in vvmin:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', '\n', '#--------------------  Search the Pattern       -------------------------------------\n', 'tmaxx= len(dateref)-1\n', 'similar_list= np.zeros((nstock*(tmaxx-twindow)+1, 3), np.float16)\n', 'i=0\n', 'for iy in range(0, nstock) :\n', ' for t in range(0, tmaxx-twindow):\n', '   if iy == stockx and t > tstartx : \n', '     pass\n', '   else :\n', '    rety= ret_open1[iy, t:(t+twindow-1)]\n', '    py=   price_normalize_1d(rety)\n', '    ss= np_similarity(px, py, wwerr=wwerr, type1=2)\n', '    i+=1\n', '    similar_list[i,0]= iy\n', '    similar_list[i,1]= t\n', '    similar_list[i,2]= ss\n', '\n', '\n', ' #-------------------Clean the table -------------------------------------------------\n', 'rank= util.np_sortbycolumn(similar_list,2, asc=True)\n', 'for i,x in enumerate(rank) :\n', '  if rank[i,2]==0.0 : rank[i,2]= 1000         # Empty cell\n', '  if rank[i,1]> tstartx-3 : rank[i,2]= 100    # Start Element\n', 'rank= util.np_sortbycolumn(rank,2, asc=True)  \n', '\n', '\n', ' #----- Show Similar Stocks ---------------------------------------------------------\n', 'show_only_different_time= True\n', '\n', 'for i in range(0,10) :\n', ' tstarti= rank[i,1]\n', ' stocki= int(rank[i,0])\n', ' \n', ' if show_only_different_time and tstarti < tstartx-1  :\n', '   py= price_normalize100(ret_open1[stocki, tstarti:(tstarti+twindow-1)]) \n', '\n', '   namei= sym01[stocki]\n', '   namefulli= nk400name[util.np_findfirst(namei, nk400list)]\n', '\n', '   tit= namei+ "" "" +namefulli+ "" "" + str(dateref[tstarti])          \n', ""   plot_price(px-100, py-100, label=('Similar '+tit, 'Time','% Var') )\n"", '\n', '\n', 'kix= util.np_findfirst(name1, statsjp[:,0, ilag])\n', 'stocklist01[390]\n', '\n', '\n', 'stocklist01[157] , nk400name[157] ,  dateref1adj[86]     \n', 'plot_price(price_normalize100(ret_open1[157, 86:86+twindow-1])-100,px-100   )\n', ""'''    \n""]",[],0
utilmy/zarchive/portfolio_withdate.py:data_jpsector,data_jpsector,function,3,4,4,47,11.75,0,0,[],[],[],30,[],['util.load_obj'],1
utilmy/zarchive/portfolio_withdate.py:date_earningquater,date_earningquater,function,9,103,42,604,5.86,0,5,['t1'],[None],[None],40,[],['datetime.datetime'],1
utilmy/zarchive/portfolio_withdate.py:date_is_3rdfriday,date_is_3rdfriday,function,4,14,13,67,4.79,0,0,['s'],[None],[None],59,[],"['datetime.strptime', 'd.weekday']",2
utilmy/zarchive/portfolio_withdate.py:date_option_expiry,date_option_expiry,function,10,50,33,354,7.08,0,2,['date'],[None],[None],64,[],['datetime.datetime'],1
utilmy/zarchive/portfolio_withdate.py:date_find_kday_fromintradaydate,date_find_kday_fromintradaydate,function,2,3,3,68,22.67,0,0,"['kintraday', 'intradaydate', 'dailydate']","[None, None, None]","[None, None, None]",81,[],['util.np_find'],1
utilmy/zarchive/portfolio_withdate.py:date_find_kintraday_fromdate,date_find_kintraday_fromdate,function,4,10,10,88,8.8,0,0,"['d1', 'intradaydate1', 'h1', 'm1']","[None, None, None, None]","[None, None, '9', '30']",85,[],"['datetime.datetime', 'util.np_find']",2
utilmy/zarchive/portfolio_withdate.py:date_find_intradateid,date_find_intradateid,function,8,13,13,96,7.38,1,0,"['datetimelist', 'stringdate']","[None, None]","[None, ""['20160420223000']""]",92,[],"['datestring_todatetime', 'util.np_find', 'str']",3
utilmy/zarchive/portfolio_withdate.py:datetime_convertzone1_tozone2,datetime_convertzone1_tozone2,function,16,29,25,343,11.83,1,1,"['tt', 'fromzone', 'tozone']","[None, None, None]","[None, ""'Japan'"", ""'US/Eastern'""]",103,[],"['pytz.timezone', 'type', 'tz.localize', 't2.append']",4
utilmy/zarchive/portfolio_withdate.py:date_extract_dailyopenclosetime,date_extract_dailyopenclosetime,function,23,51,35,431,8.45,2,3,"['spdateref1', 'market']","[None, None]","[None, ""'us'""]",120,[],"['enumerate', 'spdailyopendate.append', 'np.array', 'spdailyclosedate.append']",4
utilmy/zarchive/portfolio_withdate.py:datetime_tostring,datetime_tostring,function,6,34,22,269,7.91,1,3,['tt'],[None],[None],138,[],"['isinstance', 'tt.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/portfolio_withdate.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",149,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/portfolio_withdate.py:datetime_todate,datetime_todate,function,6,40,25,319,7.97,1,3,['tt'],[None],[None],158,[],"['isinstance', 'datetime.date', 'pd.to_datetime', 'date2.append']",4
utilmy/zarchive/portfolio_withdate.py:datetime_toint,datetime_toint,function,12,37,28,424,11.46,2,2,['datelist1'],[None],[None],169,[],"['isinstance', 'int', 'date2.append', 'datetime_tointhour', 'yy2.append', 'np.array']",6
utilmy/zarchive/portfolio_withdate.py:datetime_tointhour,datetime_tointhour,function,7,20,19,234,11.7,1,1,['datelist1'],[None],[None],177,[],"['isinstance', 'int', 'yy2.append', 'np.array']",4
utilmy/zarchive/portfolio_withdate.py:dateint_tostring,dateint_tostring,function,7,15,14,183,12.2,1,1,"['datelist1', 'format1']","[None, None]","[None, ""'%b-%y'""]",185,[],"['isinstance', 'dateint_todatetime', 'date2.append', 'np.array']",4
utilmy/zarchive/portfolio_withdate.py:dateint_todatetime,dateint_todatetime,function,6,14,12,126,9.0,1,1,['datelist1'],[None],[None],207,[],"['isint', 'parser.parse', 'date2.append']",3
utilmy/zarchive/portfolio_withdate.py:datenumpy_todatetime,datenumpy_todatetime,function,9,48,26,381,7.94,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",218,[],['type'],1
utilmy/zarchive/portfolio_withdate.py:datetime_tonumpypdate,datetime_tonumpypdate,function,2,2,2,22,11.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",232,[],['np.datetime64'],1
utilmy/zarchive/portfolio_withdate.py:date_diffindays,date_diffindays,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",237,[],['dateint_todatetime'],1
utilmy/zarchive/portfolio_withdate.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",242,[],['util.np_findfirst'],1
utilmy/zarchive/portfolio_withdate.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],256,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/portfolio_withdate.py:date_as_float,date_as_float,function,12,32,26,311,9.72,0,2,['dt'],[None],[None],263,[],"['isint', 'dateint_todatetime', 'datetime.datetime', 'isleap', 'timedelta']",5
utilmy/zarchive/portfolio_withdate.py:date_todatetime,date_todatetime,function,1,9,9,58,6.44,0,0,['tlist'],[None],[None],277,[],[],0
utilmy/zarchive/portfolio_withdate.py:date_removetimezone,date_removetimezone,function,1,6,6,63,10.5,0,0,['datelist'],[None],[None],281,[],[],0
utilmy/zarchive/portfolio_withdate.py:datediff_inyear,datediff_inyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",285,[],['date_as_float'],1
utilmy/zarchive/portfolio_withdate.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",289,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/portfolio_withdate.py:date_add_bdays,date_add_bdays,function,12,37,30,369,9.97,1,2,"['from_date', 'add_days']","[None, None]","[None, None]",298,[],"['type', 'dateint_todatetime', 'datestring_todatetime', 'datetime.timedelta', 'current_date.weekday']",5
utilmy/zarchive/portfolio_withdate.py:date_getspecificdate,date_getspecificdate,function,21,203,58,1312,6.46,8,19,"['datelist', 'datetype1', 'outputype1', 'includelastdate', 'includefirstdate', '']","[None, None, None, None, None, None]","[None, '""yearend""', '""intdate""', 'True', 'False', None]",312,[],"['isint', 'dateint_todatetime', 'enumerate', 'vec2.append', 'np.mod', 'np.array']",6
utilmy/zarchive/portfolio_withdate.py:date_alignfromdateref,date_alignfromdateref,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",373,[],"['range', 'np.float', 'len']",3
utilmy/zarchive/portfolio_withdate.py:_date_align,_date_align,function,16,42,33,256,6.1,2,2,"['dateref', 'datei', 'tmax', 'closei']","[None, None, None, None]","[None, None, None, None]",398,[],"['np.zeros', 'range', 'len']",3
utilmy/zarchive/portfolio_withdate.py:date_align,date_align,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",412,"["" ''' #Aligne the price with the same dates date\tyear\tmonth\tday\td\topen\tclose\thigh\tlow\tvolume\taclose '''\n""]","['range', 'np.float', 'len']",3
utilmy/zarchive/portfolio_withdate.py:min_withposition,min_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],459,[],['min'],1
utilmy/zarchive/portfolio_withdate.py:max_withposition,max_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],463,[],['max'],1
utilmy/zarchive/portfolio_withdate.py:_reshape,_reshape,function,2,14,12,68,4.86,0,1,['x'],[None],[None],469,[],"['len', 'np.reshape', 'np.size']",3
utilmy/zarchive/portfolio_withdate.py:_notnone,_notnone,function,39,211,114,1769,8.38,1,11,"['x)', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5)', 'label', ""'Time'"", ""'Y')"", 'legendloc', 'dpi', 'isband=0) ']","['  return not x is Noneasset', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None, ""('title'"", None, None, '""upper left""', '150', '0) :']",473,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend']",23
utilmy/zarchive/portfolio_withdate.py:plot_price,plot_price,function,69,272,170,2746,10.1,2,11,"['asset', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None]",477,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend', 'plot_priceintraday', 'np.loadtxt', 'np.unique', 'xdays.append', 'np.hstack', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick']",35
utilmy/zarchive/portfolio_withdate.py:plot_priceintraday,plot_priceintraday,function,32,59,57,947,16.05,1,0,['data'],[None],[None],556,[],"['np.loadtxt', 'np.unique', 'np.arange', 'xdays.append', 'np.hstack', 'plt.figure', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plt.show']",14
utilmy/zarchive/portfolio_withdate.py:plot_check,plot_check,function,8,19,19,257,13.53,0,0,"['close', 'tt0i', 'tt1i', 'dateref', 'sym', 'tickperday']","[None, None, None, None, None, None]","[None, '20140102', '20160815', '[]', '[]', '120']",598,[],"['util.find', 'getret_fromquotes', 'price_normalize100', 'plot_price']",4
utilmy/zarchive/portfolio_withdate.py:plot_pricedate,plot_pricedate,function,18,61,49,534,8.75,1,4,"['date1', 'sym1', 'asset1', 'sym2', 'bsk1', 'verticaldate', 'savename1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None', ""''"", '(10', None]",608,[],"['type', 'datestring_todatetime', 'np.row_stack', 'np.concatenate', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'np.arange', 'int', 'len', 'ax.savefig']",11
utilmy/zarchive/portfolio_withdate.py:generate_sepvertical,generate_sepvertical,function,9,13,12,149,11.46,0,1,"['asset1', 'tt', 'tmax', 'start', 'datebar']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",690,[],"['np.zeros', 'datestring_todatetime']",2
utilmy/zarchive/portfolio_withdate.py:save_asset_tofile,save_asset_tofile,function,31,129,87,978,7.58,5,9,"['file1', 'asset1', 'asset2', 'asset3', 'date1', 'title1']","[None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None']",705,[],"['np.shape', 'len', 'np.reshape', 'print', 'np.zeros', 'range', 'int', 'np.row_stack', 'np.savetxt']",9
utilmy/zarchive/portfolio_withdate.py:load_asset_fromfile,load_asset_fromfile,function,1,4,4,51,12.75,0,0,['file1'],[None],[None],744,[],[],0
utilmy/zarchive/portfolio_withdate.py:array_todataframe,array_todataframe,function,11,41,27,259,6.32,0,2,"['price', 'symbols', 'date1']","[None, None, None]","[None, 'None', 'None']",748,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/portfolio_withdate.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],759,[],[],0
utilmy/zarchive/portfolio_withdate.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],768,[],['float'],1
utilmy/zarchive/portfolio_withdate.py:isint,isint,function,32,105,61,1036,9.87,0,8,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) )Xmat', 'type1', 'type2=""correl"") ']","[' return isinstance(x', None, None, None, None, None, None, '']","[None, None, None, None, None, None, '""robust""', '""correl"") :']",776,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/portfolio_withdate.py:correlation_mat,correlation_mat,function,32,105,61,1036,9.87,0,8,"['Xmat', 'type1', 'type2']","[None, None, None]","[None, '""robust""', '""correl""']",783,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/portfolio_withdate.py:correl_reducebytrigger,correl_reducebytrigger,function,9,22,18,128,5.82,2,1,"['correl2', 'trigger']","[None, None]","[None, None]",831,"[""  ''' Put Zero below trigger  '''\n""]","['correl2.copy', 'range', 'abs']",3
utilmy/zarchive/portfolio_withdate.py:sk_cov_fromcorrel,sk_cov_fromcorrel,function,8,14,13,115,8.21,0,0,"['correl', 'ret_close1']","[None, None]","[None, None]",843,[],"['volhisto_fromret', 'np.diag', 'np.dot']",3
utilmy/zarchive/portfolio_withdate.py:cointegration,cointegration,function,18,47,37,385,8.19,0,0,"['x', 'y']","[None, None]","[None, None]",849,"['  """""" Output :\n', '    coint_t :t-statistic of unit-root test on residuals\n', ""    pvalue :   MacKinnon's approximate p-value based on MacKinnon (1994)\n"", '    crit_value : Critical values for the test statistic at the 1 %, 5 %, and 10 %  Signifiance levels.\n', '\n', '    The Null hypothesis is that there is no cointegration, the alt hypothesis is that there is cointegrating relationship. \n', '    If the pvalue is small, below a critical size:  Reject Null Hypothesis -->  Cointegration\n', '           pvalue is high --> No Cointegration    \n', '    \n', '    Significance level, also denoted as alpha or , is the probability of rejecting  the null hypothesis when it is true.\n', '    Probability of incorrectly rejecting a true null hypothesis\n', '\n', '    P=0.05  , At least 23% (and typically close to 50%)\n', '    P=0.01  , At least 7% (and typically close to 15%\n', '\n', '    (-2.9607012342275936,\n', '    0.038730981052330332, 0,\n', '    249,\n', ""    {'1%': -3.4568881317725864,\n"", ""       '10%': -2.5729936189738876,\n"", ""     '5%': -2.8732185133016057},\n"", '      601.96849256295991)\n', '        It can be seen that the calculated test statistic of -2.96 is smaller than the 5% critical value of -2.87, \n', ""        which means that we can reject the null hypothesis that  there isn't a cointegrating relationship at the 5% level.\n"", '  """"""\n']",['np.zeros'],1
utilmy/zarchive/portfolio_withdate.py:causality_y1_y2,causality_y1_y2,function,10,14,13,153,10.93,0,0,"['price2', 'price1', 'maxlag']","[None, None, None]","[None, None, None]",887,[],[],0
utilmy/zarchive/portfolio_withdate.py:reg_slope,reg_slope,function,16,24,24,261,10.88,1,0,"['close', 'dateref', 'tlag', 'type1']","[None, None, None, None]","[None, None, None, ""'elasticv'""]",895,[],"['np.ones', 'xrange', 'regression', 'np.arange']",4
utilmy/zarchive/portfolio_withdate.py:rolling_cointegration,rolling_cointegration,function,13,29,26,280,9.66,0,0,"['x', 'y']","[None, None]","[None, None]",910,[],"['rolling_coint', 'pd.expanding_apply']",2
utilmy/zarchive/portfolio_withdate.py:regression,regression,function,13,67,32,589,8.79,0,5,"['yreturn', 'xreturn', 'type1']","[None, None, None]","[None, None, '""elasticv""']",929,"["" '''Y = X* reg.coef_  +  reg.intercept_, r2 '''\n""]","['len', 'yreturn.ravel', 'xreturn.reshape', 'reg.fit', 'F', 'reg.score']",6
utilmy/zarchive/portfolio_withdate.py:regression_fixedsymbolstock,regression_fixedsymbolstock,function,30,59,54,591,10.02,1,1,"['sym', 'ret_close2', 'tsstart', 'tsample', 'ret_spy', 'spyclose', 'regonly']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, 'True']",966,"["" ''' Price, Weight, R2, Error  '''\n""]","['len', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max']",7
utilmy/zarchive/portfolio_withdate.py:regression_getpricefromww,regression_getpricefromww,function,20,38,30,298,7.84,3,0,"['spyclose', 'ww01', 'regasset01', 'ret_close2', 'tstart', 'tlag']","[None, None, None, None, None, None]","[None, None, None, None, None, '1']",989,[],"['np.copy', 'np.zeros', 'range', 'len']",4
utilmy/zarchive/portfolio_withdate.py:regression_allstocks_vs_riskfactors,regression_allstocks_vs_riskfactors,function,65,137,113,1351,9.86,2,1,"['symstock', 'pricestock', 'symriskfac', 'priceriskfac', 'nlaglist']","[None, None, None, None, None]","[None, None, None, None, None]",1010,"["" '''Make Regression on all stocks ''' \n""]","['np.shape', 'print', 'np.arange', 'np.empty', 'len', 'enumerate', 'getlogret_fromquotes', 'range', 'np.reshape', 'regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",13
utilmy/zarchive/portfolio_withdate.py:getdiff_fromquotes,getdiff_fromquotes,function,4,6,6,73,12.17,0,0,"['close', 'timelag']","[None, None]","[None, None]",1107,[],['np.shape'],1
utilmy/zarchive/portfolio_withdate.py:getret_fromquotes,getret_fromquotes,function,7,23,17,159,6.91,0,1,"['close', 'timelag']","[None, None]","[None, '1']",1111,[],"['np.shape', 'len']",2
utilmy/zarchive/portfolio_withdate.py:getlogret_fromquotes,getlogret_fromquotes,function,4,7,7,81,11.57,0,0,"['close', 'timelag']","[None, None]","[None, '1']",1122,[],"['np.shape', 'np.log']",2
utilmy/zarchive/portfolio_withdate.py:getprice_fromret,getprice_fromret,function,12,23,21,190,8.26,2,0,"['ret', 'normprice']","[None, None]","[None, '100']",1127,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio_withdate.py:price_normalize100,price_normalize100,function,16,43,36,292,6.79,1,1,"['ret', 'normprice']","[None, None]","[None, '100']",1139,[],"['np.shape', 'len', 'np.reshape', 'np.zeros', 'range', 'np.cumprod']",6
utilmy/zarchive/portfolio_withdate.py:price_normalize_1d,price_normalize_1d,function,8,22,19,147,6.68,0,0,"['ret', 'normprice', 'dtype1']","[None, None, None]","[None, '100', ' np.float32']",1159,[],"['np.empty', 'np.cumprod']",2
utilmy/zarchive/portfolio_withdate.py:norm_fast,norm_fast,function,7,8,8,85,10.62,0,0,"['y', 'ny']","[None, None]","[None, None]",1168,[],['ne.evaluate'],1
utilmy/zarchive/portfolio_withdate.py:correl_fast,correl_fast,function,8,13,13,116,8.92,0,0,"['xn', 'y', 'nx']","[None, None, None]","[None, None, None]",1176,[],['ne.evaluate'],1
utilmy/zarchive/portfolio_withdate.py:volhisto_fromret,volhisto_fromret,function,2,14,11,168,12.0,0,1,"['retbsk', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1184,[],"['len', 'np.std']",2
utilmy/zarchive/portfolio_withdate.py:volhisto_fromprice,volhisto_fromprice,function,6,25,17,245,9.8,0,1,"['price', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1191,[],"['len', 'np.shape', 'np.std']",3
utilmy/zarchive/portfolio_withdate.py:volhistorolling_fromprice,volhistorolling_fromprice,function,16,42,30,318,7.57,2,1,"['price', 'volrange']","[None, None]","[None, None]",1200,[],"['np.shape', 'len', 'np.zeros', 'xrange', 'volhisto_fromprice']",5
utilmy/zarchive/portfolio_withdate.py:rsk_calc_all_TA,rsk_calc_all_TA,function,51,223,105,1352,6.06,0,10,['df'],[None],"[""'panda_dataframe'""]",1219,"[""  '''Add All TA RMI, RSI To the '''\n""]","['ta.MA', 'ta.distance', 'ta.RET', 'ta.RMI', 'ta.STDDEV', 'ta.nbday_low', 'ta.nbday_high', 'ta.RSI', 'ta.qearning_dist', 'ta.optionexpiry_dist', 'linearreg2', 'np.array', 'np.sum', 'util.np_findlocalmin2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",18
utilmy/zarchive/portfolio_withdate.py:ta_highbandtrend1,ta_highbandtrend1,function,42,170,75,910,5.35,0,11,"['close2', 'type1']","[None, None]","[None, '0']",1301,[],"['linearreg', 'np.array', 'np.sum', 'util.np_findlocalmax2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",8
utilmy/zarchive/portfolio_withdate.py:pd_transform_asset,pd_transform_asset,function,11,35,27,409,11.69,0,1,"['q0', 'q1', 'type1']","[None, None, None]","[None, None, '""spread""']",1350,[],"['util.pd_date_intersection', 'util.pd_array_todataframe', 'util.pd_insertcol']",3
utilmy/zarchive/portfolio_withdate.py:calcbasket_table,calcbasket_table,function,25,59,53,477,8.08,1,2,"['wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps']","[None, None, None, None, None, None]","[None, None, '""table""', '""constant""', '1', ' 0.000']",1364,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.mod', 'np.sum']",6
utilmy/zarchive/portfolio_withdate.py:folio_createvolta_asset,folio_createvolta_asset,function,10,19,19,159,8.37,1,0,"['close', 'vol', 'volrange', 'lev']","[None, None, None, None]","[None, '0.12', '120', '1.0']",1391,[],"['np.zeros_like', 'np.shape', 'xrange', 'folio_volta']",4
utilmy/zarchive/portfolio_withdate.py:folio_lowcorrelation,folio_lowcorrelation,function,145,431,300,3894,9.03,8,7,"['sym01', 'nstock', 'periodlist', 'dateref', 'close1', 'kbenchmark', 'badlist', 'costbppa', 'showgraph']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, '0.02', 'True']",1399,[],"['ww_selection', 'np.corrcoef', 'np.nan_to_num', 'np.zeros', 'range', 'util.np_sortbycol', 'int', 'np.std', 'np.isnan', 'util.find', 'np.sum', 'stk_select.append', 'volhisto_fromret', 'sum', '1/len', 'getret_fromquotes', 'len', 'np.empty', 'np.ones', 'enumerate', 'calcbasket_table', 'price_normalize100', 'np.column_stack', 'np.zeros_like', 'np.array', 'np.concatenate', 'print', 'str', 'plot_price', 'sym01[int', 'volhisto_fromprice', 'xrange', 'folio_inverseetf']",33
utilmy/zarchive/portfolio_withdate.py:folio_leverageetf,folio_leverageetf,function,8,23,20,156,6.78,1,0,"['price', 'lev', 'costpa']","[None, None, None]","[None, '1.0', '0.0']",1537,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio_withdate.py:folio_inverseetf,folio_inverseetf,function,8,18,18,151,8.39,1,0,"['price', 'costpa']","[None, None]","[None, '0.0']",1546,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio_withdate.py:folio_longshort_unit,folio_longshort_unit,function,59,240,112,1594,6.64,2,7,"['long1', 'short1', 'ww', '-1]', 'costpa', 'tlag', 'istable', 'wwschedule']","[None, None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1', '[]']",1555,[],"['len', 'np.zeros', 'xrange', 'np.mod', 'folio_longshort_unitfixed']",5
utilmy/zarchive/portfolio_withdate.py:folio_longshort_unitfixed,folio_longshort_unitfixed,function,43,111,73,719,6.48,1,3,"['long1', 'short1', 'nn', '-1]', 'costpa', 'tlag', 'istable']","[None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1']",1596,[],"['len', 'np.zeros', 'xrange', 'np.mod']",4
utilmy/zarchive/portfolio_withdate.py:folio_longshort_pct,folio_longshort_pct,function,8,21,20,189,9.0,1,0,"['long1', 'short1', 'ww', '-1]', 'costpa']","[None, None, None, None, None]","[None, None, '[1', None, '0.0']",1634,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio_withdate.py:folio_histogram,folio_histogram,function,13,75,41,914,12.19,0,0,['close'],[None],[None],1642,[],"['getret_fromquotes', 'plt.subplots', 'np.ones_like', 'ax2.hist', 'ax2.set_title', 'ax2.set_xlabel', 'ax2.set_ylabel', 'ax2.axvline', 'plt.show', 'print']",10
utilmy/zarchive/portfolio_withdate.py:folio_voltarget,folio_voltarget,function,2,6,6,61,10.17,0,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1670,[],['folio_volta'],1
utilmy/zarchive/portfolio_withdate.py:folio_volta,folio_volta,function,54,197,112,1663,8.44,2,8,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1674,[],"['folio_volta', 'len', 'np.shape', 'np.zeros', 'range', 'np.std', 'util.findhigher', 'max', 'min', 'folio_volta2', 'np.abs']",11
utilmy/zarchive/portfolio_withdate.py:folio_volta2,folio_volta2,function,29,61,54,514,8.43,1,2,"['bsk', 'riskind', 'par', 'targetvol', 'volrange', 'cap', 'floor', 'costbp']","[None, None, None, None, None, None, None, None]","[None, None, None, '0.11', ' 90', '1.5', '0.0', '0.0005']",1713,[],"['np.shape', 'np.zeros', 'range', 'np.std', 'max', 'min', 'np.abs']",7
utilmy/zarchive/portfolio_withdate.py:folio_fixedunitprice,folio_fixedunitprice,function,13,36,33,221,6.14,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1738,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio_withdate.py:folio_fixedweightprice,folio_fixedweightprice,function,13,36,33,225,6.25,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1752,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio_withdate.py:folio_fixedweightret,folio_fixedweightret,function,13,31,28,193,6.23,2,0,"['ret', 'fixedww']","[None, None]","[None, None]",1764,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio_withdate.py:folio_cost_turnover,folio_cost_turnover,function,26,88,71,825,9.38,1,1,"['wwall', 'bsk', 'dateref', 'costbp']","[None, None, None, None]","[None, None, None, None]",1777,[],"['len', 'np.zeros', 'xrange', 'np.sum', 'plot_price', 'date1=dateint_tostring']",6
utilmy/zarchive/portfolio_withdate.py:folio_riskpa,folio_riskpa,function,20,52,40,422,8.12,2,0,"['ret', 'targetvol', 'volrange', 'cap']","[None, None, None, None]","[None, '0.1', '90', '1.0']",1807,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.sum', 'np.std', 'min', 'list']",8
utilmy/zarchive/portfolio_withdate.py:folio_perfreport_schedule,folio_perfreport_schedule,function,14,20,19,189,9.45,1,0,"['sym', 'dateref', 'close', 'wwind', 't0', 'scheduleperiod']","[None, None, None, None, None, None]","[None, None, None, None, None, '""1monthend""']",2121,[],"['np.shape', 'generate_schedule', 'np.zeros', 'enumerate']",4
utilmy/zarchive/portfolio_withdate.py:folio_concenfactor2,folio_concenfactor2,function,7,12,12,103,8.58,0,0,"['ww', 'masset']","[None, None]","[None, '12']",2421,[],"['getweight', 'np.sum', 'np.mean']",3
utilmy/zarchive/portfolio_withdate.py:calcbasket_objext,calcbasket_objext,function,50,203,96,1094,5.39,1,7,"['RETURN', 'TMAX', 'riskind_i', 'wwmat', 'wwasset0', 'ww0', 'nbrange', 'criteria']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",2439,[],"['xrange', 'np.sum', 'math.sqrt']",3
utilmy/zarchive/portfolio_withdate.py:calc_ranktable,calc_ranktable,function,20,44,41,351,7.98,1,0,"['close2', 'symjp1', 'nlag', 'refindex', 'funeval', 'funargs']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",3849,[],"['np.zeros', 'getlogret_fromquotes', 'enumerate', 'funeval', 'util.np_sortbycolumn']",5
utilmy/zarchive/portfolio_withdate.py:similarity_correl,similarity_correl,function,7,10,9,88,8.8,0,0,"['ret_close2', 'funargs']","[None, None]","[None, None]",3869,[],['correlation_mat'],1
utilmy/zarchive/portfolio_withdate.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3924,[],['np_distance_l1'],1
utilmy/zarchive/portfolio_withdate.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3930,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/portfolio_withdate.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3924,[],['np_distance_l1'],1
utilmy/zarchive/portfolio_withdate.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3930,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/portfolio_withdate.py:get,get,function,11,44,26,436,9.91,0,1,"['close', 'timelag']","[None, None]","[None, None]",4293,"['    """"""Return dataframe of requested dataset from Quandl.\n', '    :param dataset: str or list, depending on single dataset usage or multiset usage\n', '            Dataset codes are available on the Quandl website\n', '    :param str api_key: Downloads are limited to 50 unless api_key is specified\n', '    :param str start_date, end_date: Optional datefilers, otherwise entire dataset is returned\n', '    :param str collapse: Options are daily, weekly, monthly, quarterly, annual\n', '    :param str transform: options are diff, rdiff, cumul, and normalize\n', '    :param int rows: Number of rows which will be returned\n', '    :param str order: options are asc, desc. Default: `asc`\n', '    :param str returns: specify what format you wish your dataset returned as,\n', '        either `numpy` for a numpy ndarray or `pandas`. Default: `pandas`\n', '    :returns: :class:`pandas.DataFrame` or :class:`numpy.ndarray`\n', '    Any other `kwargs` passed to `get` are sent as field/value params to Quandl\n', '    with no interference.\n', '\n', ""'''\n"", '\n', '\n', '\n', '#--------------------Import data from Yahoo --------------------------------------------------\n', 'def imp_yahoo_getquotes(symbols, start=""20150101"", end=""20160101"", type1=1):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', '# symbols = np.array(symbol1)\n', ' quotes= []; errorlist=[]; correctlist=[]\n', ' for i, symbol in enumerate(symbols) :\n', '   # if np.mod(i,400) ==0 and i != 0 :\n', ""     # print('Waiting 30s'); time.sleep(30)\n"", '   try:   \n', '     array1= quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '     df= pd.DataFrame.from_records(array1)\n', '     quotes.append(df)\n', '     correctlist.append(symbol)\n', '   except :\n', '       errorlist.append(symbol)\n', ""       print('Err: '+symbol)\n"", ' #quotes = [quotes_historical_yahoo(symbol, d1, d2, asobject=True)  for symbol in symbols]\n', ' #print(errorlist) \n', ' if type1==1 :  return quotes, correctlist\n', ' else: return quotes, correctlist, errorlist  \n', '\n', '              \n', '#Find error in Ticker import\n', 'def imp_yahoo_geterrorticker(symbols, start=""20150101"", end=""20160101""):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', ' errorlist= []\n', ' for symbol in symbols :\n', '   try :  \n', '     quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '   except :\n', '     errorlist.append(symbol)\n', '     print(symbol)       \n', ' return errorlist\n', ' \n', ""'''\n"", ""symbols0= ['KHC', 'PYPL', 'HPE', 'BXLT', 'SYF', 'WLTW', 'CFG', 'BF-B', 'WRK']\n"", '\n', '#Show list of ticker in error\n', 'import_errorticker(symbols0,""20110101"",""20150601""  )\n', ""'''\n"", '\n', '\n', 'def imp_yahoo_financials_url(ticker_symbol, statement=""is"", quarterly=False):\n', '    if statement == ""is"" or statement == ""bs"" or statement == ""cf"":\n', '        url = ""https://finance.yahoo.com/q/"" + statement + ""?s="" + ticker_symbol\n', '        if not quarterly:\n', '            url += ""&annual""; return BeautifulSoup(requests.get(url).text, ""html.parser"")\n', '    return sys.exit(""Invalid financial statement code \'"" + statement + ""\' passed."")\n', '\n', 'def imp_yahoo_periodic_figure(soup, yahoo_figure):\n', '    values = []; pattern = re.compile(yahoo_figure)\n', '\n', '    title = soup.find(""strong"", text=pattern)    # works for the figures printed in bold\n', '    if title:  row = title.parent.parent\n', '    else:\n', '        title = soup.find(""td"", text=pattern)    # works for any other available figure\n', '        if title:  row = title.parent\n', '        else:      sys.exit(""Invalid figure \'"" + yahoo_figure + ""\' passed."")\n', '\n', '    cells = row.find_all(""td"")[1:]    # exclude the <td> with figure name\n', '    for cell in cells:\n', '        if cell.text.strip() != yahoo_figure:    # needed because some figures are indented\n', '            str_value = cell.text.strip().replace("","", """").replace(""("", ""-"").replace("")"", """")\n', '            if str_value == ""-"": str_value = 0\n', '            value = int(str_value) * 1000\n', '            values.append(value)\n', '\n', '    return values\n', '    \n', '# print(imp_yahoo_periodic(imp_yahoo_financials_url(""AAPL"", ""is""), ""Income Tax Expense""))\n', '\n', ' \n', '\n', '#--------------------Import Quotes Google  ------------------------------------------\n', 'import requests.packages.urllib3\n', 'requests.packages.urllib3.disable_warnings()\n', 'import urllib, os\n', '\n', ""dirstockcsv= 'E:\\_data\\stock\\csv'\n"", '\n', 'def imp_googleIntradayQuote(symbol, freqsec=300, nday=5):\n', ""    ''' Intraday quotes from google. Specify interval seconds and number of days\n"", '    http://www.google.com/finance/getprices?q=7261&i=300&p=3d&f=d,o,h,l,c,v\n', ""    '''\n"", '    url =""http://www.google.com/finance/getprices?q={0}"".format(symbol)\n', '    url +=""&i={0}&p={1}d&f=d,o,h,l,c,v"".format(freqsec, nday)\n', '    try :      \n', '       resp= requests.post(url)\n', '       csv= resp.text\n', '       csv= csv.splitlines()\n', '    except :\n', ""       print('Err Intaday '+symbol)\n"", '\n', '    if len(csv) < 9 :\n', ""      print 'Using Daily',\n"", '\n', ""      url='http://www.google.com/finance/historical?q='+symbol+'&i='+str(freqsec)+'&p=3d&f=d,o,h,l,c,v&output=csv'\n"", '      csv = urllib.urlopen(url).readlines()\n', '      csv.reverse()\n', '      q=[]\n', '      for bar in xrange(0,len(csv)-1):\n', ""        ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '        if isfloat(open_) and isfloat(high) :\n', '          open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""          dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '          q.append([dt,open_,high,low,close,volume])\n', ""      df= util.pd_array_todataframe(q, ['date','open','high','low','close','volume'])\n"", '      return df\n', '\n', '\n', '    # print(csv)\n', '    qq=[]\n', '    for bar in xrange(7,len(csv)):\n', ""      if csv[bar].count(',')!=5: continue\n"", ""      offset,close,high,low,open_,volume = csv[bar].split(',')\n"", '      \n', ""      if offset[0]=='a':\n"", '        day = float(offset[1:])\n', '        offset = 0\n', '      else:\n', '        offset = float(offset)\n', '      open_, high, low, close = [float(x) for x in [open_,high,low,close]]\n', '      dt = datetime.datetime.fromtimestamp(day + (freqsec * offset))\n', '      #print (dt,open_,high,low,close,volume)\n', '      qq.append([dt,open_,high,low,close,volume])\n', ""    df= util.pd_array_todataframe(qq, ['date','open','high','low','close','volume'])\n"", '    return df\n', '\n', ""def imp_googleIntradayQuoteSave(symbols=['NKE'], freqsec=300, nday=2000, dircsv='', dbname=''):\n"", "" ''' Save Under various format: csv / db / output in Dataframe '''\n"", ' if isinstance(symbols, str) : symbols= [symbols]\n', ' symout,qlist, sym_error= [], [], []\n', ' for sym in symbols:\n', '   try :\n', '    q = imp_googleIntradayQuote(sym, freqsec, nday)  #interval, timeframe\n', '    print sym,\n', ""    sym= sym.replace(':', '_')\n"", '\n', ""    if dircsv != '' :\n"", '      if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""      start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""      file1= dircsv+ '\\\\' + sym + '_' + str(start1) + '_' + str(freqsec) + '_' + str(nday) + '.csv'\n"", '\n', ""      q= util.pd_addcol(q, 'symbol'); q['symbol']= sym\n"", '      q.to_csv(file1, index=False)\n', '\n', ""    elif dbname != '' :\n"", '      import sqlalchemy as sql\n', '      dbcon= sql.create_engine(dbname)\n', '      if interv_sec== 300 : # 5mins\n', ""        q.to_sql('q5min', dbcon)\n"", '\n', '    else :\n', '      qlist.append(q);   symout.append(sym)\n', '   except:\n', ""      print('Error:'+sym, )\n"", '      sym_error.append(sym)\n', '\n', ' return qlist, symout, sym_error\n', '\n', ""def imp_googleQuote(symbol, start_date='20160101', end_date= '20160101') : # datetime.date.today().isoformat()):\n"", ""    ''' Daily quotes from google. Date format='yyyymmdd' '''\n"", '    symbol = symbol.upper()\n', '    start = datetime.date(int(start_date[0:4]),int(start_date[4:6]),int(start_date[6:8]))\n', '    end =   datetime.date(int(end_date[0:4]),int(end_date[4:6]),int(end_date[6:8]))\n', '    url =""http://www.google.com/finance/historical?q={0}"".format(self.symbol)\n', '    url +=""&startdate={0}&enddate={1}&output=csv"".format( start.strftime(\'%b %d, %Y\'),end.strftime(\'%b %d, %Y\'))\n', '    csv = urllib.urlopen(url).readlines()\n', '    csv.reverse()\n', '    # print(url)\n', '    q=[]\n', '    for bar in xrange(0,len(csv)-1):\n', ""      ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '      if isfloat(open_) and isfloat(high) :\n', '        open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""        dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '        q.append([dt,open_,high,low,close,volume])\n', '    return q\n', '\n', 'def imp_googleQuoteSave(symbols, date1, date2, dircsv):\n', ' if isinstance(symbols, str) : symbols= [symbols]\n', ' for sym in symbols:\n', '   try :\n', '      q = imp_googleQuote(sym, date1, date2)   #interval, timeframe\n', ""   except: print('Error:'+symbol)\n"", '\n', ""   sym= sym.replace(':', '_')\n"", '\n', ""   if dircsv != '' :\n"", '     if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""     start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""     file1= dircsv+ '\\\\'+ name1+'_'+ start1 +'_'+ str(date2) +'.csv'\n"", '     q.to_csv(file1)\n', '\n', ""   if dbname != '' :\n"", '     import sqlalchemy as sql\n', '     dbcon= sql.create_engine(dbname)\n', '     if interv_sec== 300 : # 5mins\n', ""       q.to_sql('q5min', dbcon)\n"", '\n', '\n', '\n', ""def imp_csv_dbupdate(indir='E:/_data/stock/intraday/intraday_google_usetf2.h5',\n"", ""                     outdir='E:/_data/stock/intraday/q5min/us/etf/', filelist=[], intype='csv',\n"", ""                     refcols=['date', 'open', 'high', 'low', 'close', 'volume', 'symbol']) :\n"", '\n', '  for file1 in filelist :\n', ""    sym=  file1[:file1.find('_')]  #Clean Up name\n"", '    print sym,\n', ""    outfile= outdir+'/'+sym+'.csv'\n"", '    if os.path.isfile(outfile) :\n', ""      df0= imp_csv_toext(file1=outfile, fromzone='Japan', tozone='UTC', header=0, cols=refcols)\n"", '    else :\n', '      df0= None\n', '\n', ""    if intype== 'hdfs':\n"", '      df1= imp_hdfs_getquote(indir, sym)\n', '      if isinstance(df1, float) : df1= None\n', '\n', ""    if intype=='csv' :\n"", ""      infile= indir+'/'+ file1   #csv\n"", ""      df1= imp_csv_toext(file1=infile, header=0, cols=refcols, fromzone='Japan', tozone='UTC')\n"", '\n', '    if df1 is not None :\n', '       if df0 is not None  : df1= imp_pd_merge(df1[refcols], df0[refcols])\n', '       # return outfile, df1\n', '       df1[refcols].to_csv(outfile, index=False)\n', '\n', '\n', '#####################################################################################\n', 'def imp_numpy_close_fromdb(dbname=\'/aaserialize/store/yahoo.db\', table1=\'\', symlist=[], t0=20010101, t1=20010101, priceid=""close"", batchsize= 400, maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from DB SQL"")\n', ' import data.hist_data_storage as yhh\n', ' dstore= yhh.dailyDataStore(dbname)\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', '\n', "" dateref0= dstore.get_histo(['SPY'], table1='daily_us_etf', start1=str(t0), end1=str(t1),  split_df=0).date.values\n"", ' \n', ' k=0; symfull=[];   i=0\n', ' nsym= len(symlist); nbatch= int(nsym / batchsize)+1\n', ' for j in xrange(0, nbatch) : \n', '      qlist, sym= dstore.get_histo(symlist[i:min(nsym,i+batchsize)], table1=table1, start1=str(t0), end1=str(t1),  split_df=1)\n', '\n', '      #print(""batch: ""+str(j), len(qlist), len(qlist[0].index) )\n', '      #for k,q in enumerate(qlist) :print sym[k], len(q.index)\n', '      i= i + batchsize\n', '      symfull= np.concatenate((symfull,sym))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)\n', '      print(""batch: ""+str(j), len(sym),dateref[0],dateref[-1] )\n', '      qlist=None; sym=None\n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[k:k+masset,0:tmax] = close\n', '      k=k+ masset\n', '\n', ' maxasset= k\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', 'def imp_numpy_close_fromhdfs(dbfile, symlist=[], t0=20010101, t1=20010101, priceid=""close"", maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from Pandas"")\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', ' store = pd.HDFStore(dbfile)\n', ' \n', "" df= store.select('SPY')\n"", ' df= df[(df.date >= t0) & (df.date <= t1 )]\n', ' dateref0= df.date.values\n', ' \n', ' k=0; symfull=[]; qlist=[]; sym=[]; tmax= 2000\n', ' for j, symbol in enumerate(store.keys()):\n', '  symbol=  symbol[1:]\n', '\n', '  if len(symlist)==0  or  util.find(symbol,symlist) > -1 : \n', '   #print symbol, util.find(symbol,symlist) \n', '   df= store.select(symbol) \n', '   if t0 !=t1 :     df= df[(df.date >= t0) & (df.date <= t1 )]\n', '   \n', '   qlist.append(df);   sym.append(symbol)\n', '   if np.mod(j+1, 401) == 0 :\n', '      print(""batch: ""+str(j))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)   \n', '      print len(sym),dateref[0],dateref[-1] \n', '      symfull= symfull+sym\n', '      qlist=[]; sym=[]\n', ' \n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[(k):(k+masset),0:tmax] = close\n', '      k=k+ masset   \n', '     \n', ' if len(qlist) > 0:\n', '  # return qlist, qlist[0] ,  qlist[1] \n', '   close,dateref= date_align(qlist,type1=priceid)   \n', '   print len(sym),dateref[0],dateref[-1] \n', '   symfull= symfull+sym\n', '   masset,tmax= np.shape(close);\n', '   close2[(k):(k+masset),0:tmax] = close\n', ' \n', ' maxasset= k+masset\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', '\n', ""def imp_sql_getquotes(stocklist01, dbname='sqlite:///aaserialize/store/yahoo.db', start1=20150101, end1=20160616, table1='daily_us_stock'):\n"", '    import data.hist_data_storage as yhh\n', '    dstore = yhh.dailyDataStore(dbname)\n', '    qlist, sym= dstore.get_histo(stocklist01, table1=table1,  start1=start1, end1=end1, split_df=1)\n', '    return qlist, sym\n', '\n', ""def imp_txt_getquotes(stocklist01, filedir='E:/_data/stock/daily/20160610/jp', startdate=20150101, endate=20160616):\n"", ' liststockfile= util.listallfile(filedir, ""*.txt"", dirlevel=5)\n', ' #print liststockfile\n', ' if len(np.shape(liststockfile)) > 1 :\n', '  liststockname=[ x.split(""."")[0] for x in liststockfile[:,0] ]\n', '#  for k in range(0, np.shape(liststockfile)[0]):  liststockname.append( (liststockfile[k,0])[0:4])   \n', '   \n', ' else: \n', '  stk0= liststockfile[0]; #stk2= liststockfile[2]\n', '#  liststockname=[ x[0:4] for x in stk0 ]\n', '  liststockname=[ x for x in stk0 ]\n', '\n', '#  liststockname=[]\n', '#  for k in range(0, len(stk0)):  liststockname.append( (stk0[k])[0:4])\n', ' \n', ' quotes=[]\n', ' print liststockname\n', ' for sym in stocklist01:\n', '   kstock= util.np_findfirst(sym, liststockname)\n', '   if kstock == -1 :\n', ""     print('Not Found '+sym)\n"", '   else :\n', '     df= pd.read_csv(liststockfile[kstock][2])\n', ""     df.columns = ['date', 'open', 'high','low','close', 'volume', 'openint']  #Change Column Name\n"", '     df2= df[(df.date > startdate  )& ( df.date   < endate )] # Filter by date\n', '     quotes.append(df2)\n', '  \n', ' return quotes \n', '\n', '\n', 'def imp_csv_getname(name1, date1, inter, tframe):\n', "" file1= dirstockcsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", ' return file1\n', '\n', '\n', 'from dateutil import tz\n', ""def imp_csv_toext(file1='SPY.csv', outputfile='.h5', fromzone='Japan', tozone='UTC', header=None,\n"", ""                  cols=['date', 'time','open','high','low','close','volume', 'symbol'], coldate=[0]):\n"", ""  ''' cols: column name,  coldate: position of date column   '''\n"", '  from dateutil import parser\n', '\n', '  if os.path.getsize(file1)> 500 :\n', ""   df = pd.read_csv(file1,sep=',',header=header)  # date_parser=dateparse)  # parse_dates={'date': [] },\n"", '   df.date= [ parser.parse(x) for x in  df.date]\n', '\n', ""   #if util.find('symbol', df.columns.values) < 0 :\n"", ""     #df= util.pd_addcol(df, 'symbol')\n"", ""     #df['symbol']= sym\n"", '\n', ""   type1= outputfile[outputfile.find('.'):]\n"", '\n', ""   if outputfile=='':\n"", '     # df.columns = [  x.lower() for x in df.columns.values ]\n', ""     # df.columns = ['date', 'symbol','open','high','low','close','volume']\n"", '     df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""     df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""     df.columns = ['date', 'open','high','low','close','volume', 'symbol']\n"", '     return df[cols]\n', '\n', ""   if type1=='csv' :\n"", ""     df[cols].to_csv(outputfile , index=False)  # , compression='gzip' )\n"", '\n', ""   if type1== 'h5' :\n"", ""      # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '      dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '      # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '      # df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '      # df.date= [x.to_datetime() for x in  df.date]\n', '\n', '      df.drop(df.columns[[0]], axis=1, inplace=True)\n', '      print filenameh5\n', ""      if util.find('symbol', df.columns.values) < 0 :\n"", ""         df= util.pd_addcol(df, 'symbol'); df['symbol']= dfname\n"", '      store = pd.HDFStore(outputfile); store.append(dfname, df);  store.close()\n', '\n', '\n', '\n', ""def imp_hdfs_db_updatefromcsv(dircsv, filepd=r'E:\\_data\\stock\\intraday_google.h5', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= filepd + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2, name1, fromtimezone, tozone)\n', '\n', ""def imp_hdfs_db_dumpinfo(dbfile='E:\\_data\\stock\\intraday_google.h5'):\n"", '  store = pd.HDFStore(dbfile)\n', '  extract=[]; errsym=[]\n', '  for symbol in store.keys():\n', '     try:\n', '       df= pd.read_hdf(dbfile, symbol)\n', ""       t0= df['date'].values[0]\n"", ""       t1= df['date'].values[-1]\n"", '\n', '       extract.append([symbol[1:], df.shape[1],   df.shape[0], t0, t1 ])\n', '\n', '     except: errsym.append(symbol)\n', '  return np.array(extract), errsym\n', '\n', 'def imp_hdfs_mergedb(filepdfrom, filepdto) :\n', '  store0 = pd.HDFStore(filepdfrom)\n', '  store1 = pd.HDFStore(filepdto)\n', '\n', '  for symbol in store0.keys():\n', '    qq= imp_hdfs_getquote(filepdfrom, symbol)\n', '    store1.append(symbol, qq)\n', '\n', '    qq= imp_hdfs_getquote(filepdto, symbol)\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    print(symbol)\n', '  store0.close(); store1.close()\n', '\n', ""def imp_hdfs_storecopy(hdfs1='F:/usstock8.h5', hdfs2='F:/usstock8.h5'):\n"", ' store = pd.HDFStore(hdfs1);  store2 = pd.HDFStore(hdfs2)\n', ' for symbol in store.keys() :\n', '   df= imp_hdfs_getquote(hdfs1, symbol)\n', '   symbol= symbol[1:].replace(""-"",""_"")\n', '   store2.append(symbol, df, data_columns=True)\n', ' store.close(); store2.close()\n', '\n', 'def imp_hdfs_getquote(filenameh5, dfname=""data""):\n', '  try: return  pd.read_hdf(filenameh5, dfname)\n', '  except: return -1.0;\n', '\n', ""def imp_hdfs_getListquote(symbols, close1='close', start='12/18/2015 00:00:00+00:00',\n"", ""                          end='3/1/2016 00:00:00+00:00', freq='0d0h10min', filepd= 'E:\\_data\\stock\\intraday_google.h5',\n"", ""                          tozone='Japan', fillna=True, interpo=True):\n"", '\n', ' datefilter= pd.date_range(start=start, end=end, freq= freq,tz=tozone).values\n', '\n', ' errorsym=[]; quotes=[]; correctsym=[]\n', ' for symbol in symbols:  # Issue Not same size\n', '   qq= imp_hdfs_getquote(filepd, symbol)\n', '\n', '   if type(qq)==np.float :  # Error qq=-1\n', '        errorsym.append(symbol)\n', '   else:\n', ""       qq.columns = ['date', 'symbol','open','high','low','close','volume']\n"", ""       qq= qq[qq['date'].isin(datefilter)]   #Only date in the range\n"", ""       #qq= qq.drop_duplicates(cols='date', take_last=True)\n"", ""       #  qq= qq.sort('date', asc=True)\n"", '\n', '       #print qq.date.values[0]\n', ""       if fillna : qq= qq.fillna(method='backfill')\n"", '       if interpo : qq= qq.interpolate()\n', '       quotes.append(qq)\n', '       correctsym.append(symbol)\n', '\n', ' datefilter= datenumpy_todatetime(datefilter)\n', ' return quotes,datefilter, correctsym,   errorsym\n', '\n', '\n', ""def imp_hdfs_removeDuplicate(filepd='E:\\_data\\stock\\intraday_google.h5') :\n"", '  #-------Clean by removing duplicate-------------------------------------------------\n', '  store = pd.HDFStore(filepd)\n', '  for symbol in store.keys():\n', '    #qq= imp_hdfs_getquote(filepd, symbol);\n', '    qq= store.select(symbol[1:])\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    qq.index = list(np.arange(0,len(qq.index)))\n', '\n', '    store.remove(symbol); store.append(symbol, qq);\n', '  store.close()\n', '\n', '\n', '\n', ""def imp_pd_tohdfs(sym, qqlist, filenameh5, fromzone='Japan', tozone='UTC') :\n"", ""  ''' df list to HDFS '''\n"", '  store = pd.HDFStore(filenameh5);\n', '  for k, df2 in enumerate(qqlist) :\n', '    df= copy.deepcopy(df2)\n', ""    df['date']= datetime_toint(df.date.values)\n"", '\n', ""    symbol= sym[k].replace('-','_')\n"", '    qq= imp_hdfs_getquote(filenameh5, symbol)\n', '    # print symbol, type(qq)\n', '    if type(qq) ==  float or  type(qq) ==  int  :\n', '      store.append(symbol, df)  # , data_columns=True\n', '      # print(symbol + str(df.date.values[-1]))\n', '    else :\n', '      qq= pd.concat([qq, df], ignore_index=True)\n', ""      qq= qq.drop_duplicates(subset='date', keep='last')\n"", ""      qq= qq.sort('date', ascending=1)\n"", '      store.append(symbol, qq)  #Too much space , data_columns=True\n', '      print(symbol + str(qq.date.values[-1]))\n', '\n', '  store.close()\n', '\n', 'def imp_pd_merge(df1, df2) :\n', '  df= pd.concat([df1, df2], axis=0)\n', ""  df= df.drop_duplicates(subset='date', keep='last')\n"", ""  df= df.sort_values(by=['date'], ascending=1)\n"", '  df.index = list(np.arange(0,len(df.index)))\n', '  return df\n', '\n', 'def imp_pd_checkquote(quotes) :\n', ""   for c in quotes: print np.shape(c), c['date'].values[0], c['date'].values[-1]\n"", '\n', 'def imp_pd_getclose(df, datefilter=None):\n', ' if datefilter is  not None :\n', ""    df= df[df['date'].isin(datefilter)]   #Only date in the range\n"", "" df= df.sort('date')\n"", "" close= df.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", ' \n', ' close= np.array(close.values[1:,1:]).astype(np.float)            #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close\n', '\n', 'def imp_pd_cashyield(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  100 * np.cumprod( (1 + np.ones(len(vv)) * 0.005/365.0 ))\n', '     qbond[id1]= pbond\n', '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_yield_tobond(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  1/ np.power(1+ vv*0.01,duration) *100\n', '     qbond[id1]= pbond\n', ""#     print 'ok'\n"", '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_errordate(quotes, dateref):\n', "" ''' Show Symbol in Error when importing '''\n"", ' for i, stock in enumerate(quotes) :\n', '   print(i, symbols1[i],  datetime_tostring(stock[0][0]))\n', ' print(""\\n\\n"")\n', '\n', ' for i, stock in enumerate(quotes) :\n', '   date1= datetime_toint(stock[0][0])\n', '   if date1 != dateref : print(i, symbols1[i],  str(date1))\n', '\n', 'def imp_pd_fxtoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', 'def imp_pd_fxinversetoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(1.0 / q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', ""def imp_pd_filterbydate(df, dtref=None, start='2016-06-06 00:00:00', end='2016-06-14 00:00:00', freq='0d0h05min', timezone='Japan'):\n"", "" ''' df: DateSeries or TimeSeries of Quotes   '''\n"", '\n', ' if type(df) in {pd.core.frame.DataFrame} :  #Data frame version\n', '   if type(dtref)== str:\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', ""   return df[df['date'].isin(dtref)]\n"", ' else :\n', '   if type(dtref)== str:  #Date version\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', '   return df[df.isin(dtref)].values\n', '\n', 'def imp_pd_cleanquote(q):\n', ' col= q.columns.values\n', "" if isinstance(q['date'].values[0] , str) :\n"", ""   q['date']= datetime_todate(datestring_todatetime(q['date'].values))\n"", '\n', ' for kid in col:\n', ""   if kid not in ['date', 'day','month','year'] :\n"", ""      q[kid]= pd.to_numeric(q[kid], errors='coerce').values  #Put NA on string\n"", '\n', "" q= q.fillna(method='pad')\n"", ' return q\n', '\n', 'def imp_pd_divide(q1, q2, funapply):\n', "" close, dateref= date_align([q1,q2], type1='close')\n"", ' m,tt= np.shape(close)\n', '\n', ' q3= util.pd_createdf( np.zeros((tt,len(q1.columns))) ,q1.columns, dateref)\n', "" q3['date']= dateref\n"", "" q3['close']= (close[0,:] / close[1,:])\n"", '\n', ' for kid in q1.columns :\n', ""   if kid not in ['close', 'volume','date','day','month', 'year'] :\n"", '     close, _= date_align([q1,q2], type1=kid)\n', '     q3[kid]= (close[0,:] / close[1,:])\n', ' return q3\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""def imp_quote_csvdir_tofile(dircsv='', outdir1='E:/_data/stock/', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= outdir + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2,  header=True, fromzone=fromtimezone, tozone=tozone)\n', ""'''\n"", '\n', '\n', ""'''\n"", ""close1='Close' ; start='12/18/2015 00:00:00';\n"", ""end='3/1/2016 00:00:00'; freq='1d0h00min';\n"", ""filepd= 'E:\\_data\\stock\\intraday_google.h5'\n"", '\n', 'datefilter= pd.date_range(start=start, end=end,   freq= freq).values\n', '\n', 'symbols, names = np.array(list(symbol_dict.items())).T\n', 'i=0; vv=[]\n', 'for symbol in symbols:  # Issue Not same size\n', '   qq= quote_frompanda(filepd, symbol); i+=1\n', '   if isfloat(qq) :  vv.append(symbol)\n', '   else:\n', ""     if i==1: close = qq[['Datetime']]  #new dataframe    \n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', '     if not tmp.isnull().values.all():\n', ""      close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""      close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', ""close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", ""close= close.sort('Datetime')\n"", ""close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", 'close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', 'close= close[(np.abs(stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', ""'''\n"", 'from datetime import datetime\n', 'from dateutil import tz\n', '\n', ""from_zone = tz.gettz('Japan'); to_zone = tz.gettz('UTC')\n"", '\n', ""date1 = datetime.strptime('2011-01-21 09:00:00', '%Y-%m-%d %H:%M:%S')\n"", 'date1 = date1.replace(tzinfo=from_zone)\n', 'dateutc = date1.astimezone(to_zone)\n', 'date1, dateutc\n', '\n', ""Suppose you have a column 'datetime' with your string, then:\n"", ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\n"", ' combine multiple columns into a single datetime column,\n', ""this merges a 'date' and a 'time' column into a single 'datetime' column:\n"", '\n', ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)\n"", ""'''\n"", '\n', '\n', '#date1 = ""20160302""; inter= 60; tframe=80; name1= ""spy""\n', '#googleIntradayQuoteSave(name1, inter, tframe)\n', '\n', '\n', '\n', 'def ta_mar(close,t,m):  return  100*( np.mean(close[(t-m):(t+1)], axis=0) / close[t] )\n', 'def ta_ma(close,t,m):  return   np.mean(close[(t-m):(t+1)], axis=0)\n', '\n', '\n', '############################################################################\n', '#---------------------Calculate the Statistics         --------------------  \n', 'def calc_statestock(close2, dateref, symfull):\n', ' def sort(x,col,asc): return   util.sortcol(x,col,asc)\n', ' def perf(close,t0,t1):  return  100*( close[:,t1] / close[:,t0] -1)\n', ' def and2(tuple1):  return np.logical_and.reduce(tuple1)\n', ' def mar(close,t,m):  return  100*( np.mean(close[:,(t-m):(t+1)], axis=1) / close[:,t] )\n', ' def ma(close,t,m):  return   np.mean(close[:,(t-m):(t+1)], axis=1)\n', '\n', '\n', ' # a= ma(close2, tmax, 5) / ma(close2, tmax, 50)  \n', '\n', '\n', ' def dd(t) :\n', '  x= util.find(t,dateref)  # 607\n', ""  if x==-1 : print 'Error date not found in dateref '+str(t) ; return np.nan\n"", '  else :  return x\n', '\n', ' def gap(close,t0,t1,lag):   \n', '  ret= getret_fromquotes(close[:,t0:t1],lag)\n', '  rmin= 100*np.amin(ret,axis=1)\n', '  return rmin\n', ' \n', ' #--------------------Size----------------------------------------- \n', ' masset= len(symfull)\n', ' ttmax= util.find(0,close2[0,:])\n', ' if ttmax==-1 : ttmax= np.shape(close2)[1]\n', ' close2= close2[0:masset,0:ttmax]\n', ' m, tmax= masset, ttmax-1\n', ' \n', ' #correl\n', ' #close3= np.array(close2[:,0:ttmax],dtype=np.float16)\n', ' #close2ret= getret_fromquotes(close3)\n', ' #close2ret= np.nan_to_num(close2ret)\n', ' #close2ret= util.np_cleanmatrix(close2ret);  del close3\n', '\n', '##################################################################################\n', '#1: 1d,2:5d,3:10d,4:15d,5:20d,11:50d,12:60d,13:90d,15:1y\n', '#16: YTD,17:From Feb,21: 2015Ret,45: Price,50,51: Min,52,53: Max\n', ' print(""Calcul the Stats "" + str(dateref[-1]))\n', ' stat= np.zeros((2600,200),dtype=np.float16)\n', '\n', ' k=0\n', ' stat[k:(k+m),0]= np.arange(k,k+m)\n', ' stat[k:(k+m),1]=  perf(close2,tmax-1,tmax)  \n', ' stat[k:(k+m),2]=  perf(close2,tmax-5,tmax)  \n', ' stat[k:(k+m),3]=  perf(close2,tmax-10,tmax)  \n', ' stat[k:(k+m),4]=  perf(close2,tmax-15,tmax)  \n', ' stat[k:(k+m),5]=  perf(close2,tmax-20,tmax)  \n', '# stat[k:(k+m),6]=  perf(close2,tmax-25,tmax)  \n', ' stat[k:(k+m),7]=  perf(close2,tmax-30,tmax)  \n', '# stat[k:(k+m),8]=  perf(close2,tmax-35,tmax)  \n', ' stat[k:(k+m),9]=  perf(close2,tmax-40,tmax)  \n', '# stat[k:(k+m),10]=  perf(close2,tmax-45,tmax)  \n', ' stat[k:(k+m),11]=  perf(close2,tmax-50,tmax)  \n', ' stat[k:(k+m),12]=  perf(close2,tmax-60,tmax)  \n', ' stat[k:(k+m),13]=  perf(close2,tmax-90,tmax)  \n', ' stat[k:(k+m),14]=  perf(close2,tmax-120,tmax)  \n', ' stat[k:(k+m),15]=  perf(close2,tmax-250,tmax)  \n', '\n', '\n', '# stat[k:(k+m),16]=  perf(close2, dd(20160105),tmax)   #1Jan 2016\n', '# stat[k:(k+m),17]=  perf(close2, dd(20160222),tmax)   # 22 Feb 2016\n', '# stat[k:(k+m),18]=  perf(close2,dd(20160105),dd(20160222))   # Crash DrawDown\n', ' # stat[k:(k+m),19]=  perf(close2,624,tmax)   #  24 June 2016\n', ' # stat[k:(k+m),20]=  perf(close2,623,625)   #  Crash 24 June 2016\n', ' # stat[k:(k+m),21]=  perf(close2,dd(20151230)-250,dd(20151230))    #2015 Return\n', '\n', ' stat[k:(k+m),22]= gap(close2,tmax-80,tmax,1) #Max 1 days Gap\n', ' stat[k:(k+m),23]= gap(close2,tmax-80,tmax,5) #Max 5 days Gap\n', ' stat[k:(k+m),24]= perf(close2,tmax-2,tmax)  \n', ' stat[k:(k+m),25]= perf(close2,tmax-3,tmax)  \n', ' stat[k:(k+m),26]= perf(close2,tmax-4,tmax)  \n', '\n', ' stat[k:(k+m),27]= perf(close2,tmax-2,tmax-1)   \n', ' stat[k:(k+m),28]= perf(close2,tmax-3,tmax-2)   \n', ' stat[k:(k+m),29]= perf(close2,tmax-4,tmax-3)   \n', ' stat[k:(k+m),30]= perf(close2,tmax-5,tmax-4)\n', ' \n', ' stat[k:(k+m),120]= mar(close2, tmax, 20) \n', ' stat[k:(k+m),121]= mar(close2, tmax, 50) \n', ' stat[k:(k+m),122]= 100*ma(close2, tmax, 5) / ma(close2, tmax, 50)  #OverSold /OverBought\n', ' stat[k:(k+m),123]= mar(close2, tmax, 100)  \n', ' stat[k:(k+m),124]= mar(close2, tmax, 10) \n', '# stat[k:(k+m),35]= 0 \n', '# stat[k:(k+m),36]= 0 \n', '# stat[k:(k+m),37]= 0 \n', '# stat[k:(k+m),38]= 0 \n', '# stat[k:(k+m),39]= 0 \n', '\n', ' # stat[k:(k+m),30]= volume / AvgVol3M\n', ' # stat[k:(k+m),30]= Nbday_to_Earnings\n', ' #Volume/3M AvgVolume\n', ' # stat[k:(k+m),26]=  volume(volume2,tmax-120,tmax)  \n', '\n', ' #==============================================================================\n', ' #-------------- Data Fundamental    -------------------------------------------\n', "" df= util.sql_query(sqlr='SELECT ticker,shortratio,sector1_id, sector2_id, marketcap   FROM stockfundamental ', dburl='/aaserialize/store/finviz.db')\n"", ' npdf= df.values; del df\n', ' npdf0= npdf[:,0]  \n', ' for i in range(0,m):  \n', '   try :\n', '     kid= util.find(symfull[i], npdf0)\n', '     if kid != -1 :\n', '      stat[i,150]=  float(npdf[kid, 1])   # short ratio\n', '      stat[i,151]=  float(npdf[kid, 2])   # sector 1      \n', '      stat[i,152]=  float(npdf[kid, 3])   # sector 2     \n', '      stat[i,153]=  float(npdf[kid, 4] / 100000000.0)   # market Cap    \n', '   except : pass\n', ' del npdf, npdf0\n', '\n', '\n', '#==============================================================================\n', ' ################ Volatility\n', ' stat[k:(k+m),40]= volhisto_fromprice(close2,tmax,20,axis=1)* 100\n', ' stat[k:(k+m),41]= volhisto_fromprice(close2,tmax,60,axis=1)* 100\n', ' stat[k:(k+m),42]= volhisto_fromprice(close2,tmax,252,axis=1)* 100\n', '# stat[k:(k+m),43]= stat[k:(k+m),12] / stat[k:(k+m),41] #Sharpe 3Month\n', '# stat[k:(k+m),44]= stat[k:(k+m),15] / stat[k:(k+m),42] #Sharpe 1Year\n', '\n', ' stat[k:(k+m),45]= close2[:,tmax] #Last Close\n', '\n', '# stat[k:(k+m),46]= 0 \n', '# stat[k:(k+m),47]= 0 \n', '# stat[k:(k+m),48]= 0 \n', '# stat[k:(k+m),49]= 0 \n', '\n', '\n', ' ###############  Technical Indicator\n', ' #Min of last 6 months, Max of last 6months\n', ' for i in range(0,m):\n', '  pp0= stat[i,45]\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-120):tmax])\n', '  stat[i,50]= kmin+(tmax-120);  stat[i,51]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-120):tmax])\n', '  stat[i,52]= kmax+(tmax-120);  stat[i,53]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-10):tmax])\n', '  stat[i,66]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-10):tmax])\n', '  stat[i,67]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-5):tmax])\n', '  stat[i,68]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-5):tmax])\n', '  stat[i,69]= 100*pp0 / pmax\n', '\n', ' del kmax,pmax,i,k  \n', '\n', '\n', ' #Regression from Min Price Time\n', ' for i in range(0,m):\n', '  t0= int(stat[i,50])\n', '  try :\n', '    res= regression(close2[i,t0:tmax ]  ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,54]=  res[2]  #R2\n', '    stat[i,55]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from Max Price Time\n', ' for i in range(0,m):  \n', '  t0= stat[i,52]\n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,56]=  res[2]  #R2\n', '    stat[i,57]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from 5 days ago\n', ' t0= tmax-5\n', ' for i in range(0,m): \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,58]=  res[2]  #R2\n', '    stat[i,59]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', '#Regression from 10 days ago\n', ' t0= tmax-10\n', ' for i in range(0,m):  \n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,60]=  res[2]  #R2\n', '    stat[i,61]=  res[0][0]  #Slope\n', '   except : pass\n', '\n', "" '''\n"", '#Regression from 1 month\n', ' t0= tmax-20   \n', ' for i in range(0,m):\n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,62]=  res[2]  #R2\n', '    stat[i,63]=  res[0][0]  #Slope\n', '   except : pass\n', "" '''\n"", '\n', "" '''\n"", '#Regression from 2 months ago\n', ' t0= tmax-40\n', ' for i in range(0,m):  \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,64]=  res[2]  #R2\n', '    stat[i,65]=  res[0][0]  #Slope\n', '  except : pass\n', "" '''\n"", '\n', '#Nb of Positive days last 5d\n', ' for i in range(0,m):  stat[i,66]=  np_countretsign(close2[i,(tmax-5):tmax])  \n', '\n', '#Nb of Positive days last 10d\n', ' for i in range(0,m):  stat[i,67]=  np_countretsign(close2[i,(tmax-10):tmax])  \n', '\n', '#Nb of Positive days last 20d\n', '# for i in range(0,m):  stat[i,68]=  np_countretsign(close2[i,(tmax-20):tmax])  \n', '\n', '\n', '#Regression from Max Values,200days\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,70]=  res[2]  #R2\n', '    stat[i,71]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmax\n', '\n', '\n', '#Regression from Min Values,200days \n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,72]=  res[2]  #R2\n', '    stat[i,73]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmin\n', '\n', '\n', '#Regression from Max Values,100days\n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,74]=  res[2]  #R2\n', '    stat[i,75]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmax\n', '\n', '\n', '#Regression from Min Values,100days \n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,76]=  res[2]  #R2\n', '    stat[i,77]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmin\n', '\n', '\n', '\n', '# Upside Trend with Higher Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '   vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '   vmax= util.sort(vmax,0,asc=0)\n', '   stat[i,80]=  -1\n', '   if len(vmax) > 1 :\n', '    ss=0\n', '    for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '    if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,80]=  ss  \n', '        stat[i,81]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Upside Trend with Higher High detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '    vmax= util.sort(vmax,0,asc=0)\n', '    stat[i,82]=  -1\n', '    if len(vmax) > 1 :\n', '      ss=0\n', '      for k in range(0,len(vmax)-1):\n', '        if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher high\n', '        else : break;\n', '      if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,82]=  ss  \n', '        stat[i,83]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Downside Trend with lower Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,84]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,84]=  ss  \n', '        stat[i,85]=  vmax[0,0] + t0\n', '\n', '\n', '# Downside Trend  with lower highs detection\n', ' t0= tmax-20*6\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,80]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,86]=  ss    #Nb  of lower high consecutive\n', '        stat[i,87]=  vmax[0,0] + t0\n', '\n', "" print('Higher/Lower Band Support')\n"", '#-----higher band Support / Lower Band Support 120days-------------------------------\n', ' t0= tmax-120\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,90]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,91]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,92]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '    # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1]) \n', '    # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 200days-------------------------------\n', ' t0= tmax-200\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,93]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,94]= 100.0 * stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,95]= 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 300days-------------------------------------\n', ' t0= tmax-300\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,96]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,97]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,98]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', ""  '''\n"", '  # -----higher band Support / Lower Band Support 60days-------------------------------\n', '  t0 = tmax - 60\n', '  for i in range(0, m):\n', '      try:\n', '          res1 = ta_highbandtrend1(close2[i, t0:tmax])\n', '          pmax = (res1.x[0] * (tmax - t0) + res1.x[1])\n', '          stat[i, 99] = 100.0 * stat[i, 45] / pmax  # Higher Band\n', '\n', '          res2 = ta_lowbandtrend1(close2[i, t0:tmax])\n', '          pmin = (res2.x[0] * (tmax - t0) + res2.x[1])\n', '          stat[i, 100] = 100.0 * stat[i, 45] / pmin  # LowerBand\n', '\n', '          stat[i, 101] = 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)  # Price inside Range\n', '\n', '          # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1])\n', '          # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '      except:\n', '          pass\n', ""  '''\n"", '\n', '  #-----Technical Indicator------------------------------------------------\n', '# for i in range(0,m): \n', '#  try :\n', '#   res2=0\n', '   # df= pd.read_hdf(dbfile, symfull[i])\n', '   # stat[i,110]= ta.RMI(close2[i,:])\n', '   # stat[i,111]= 100*close2[i,:] / ta.MA(close2[i,:],20)\n', '   # stat[i,112]= 100*close2[i,:] / ta.MA(close2[i,:],50)   \n', '#  except: pass\n', '\n', '\n', ' return np.array(stat, dtype=np.float16) \n', '\n', '\n', ""'''  \n"", 'i=1964  \n', 'stat= s1\n', 'stat[i, 91]  \n', '\n', 'tt= np.arange(t0, tmax)\n', 'plot_price(close2[i,t0:tmax], (res2.x[0] * (tt-t0) + res2.x[1]) )\n', ""'''\n"", '\n', '  \n', '#------------------- Stock Monitoring Tools ------------------------------------------------\n', ""def monitor_addrecommend(string1, dbname='stock_recommend') :\n"", ' ss= string1.replace(""("","" "").replace(\')\',\' \').replace(\':\',\' \')\n', "" ss= ss.replace('\\t', ' ').replace('\\n', ' ')\n"", ' sl1= ss.split("" "")\n', ' print sl1\n', ' aux= [datestring_toint(util.date_now())]\n', ' symfull= copy.deepcopy(a_us_all)\n', ' for x in sl1:\n', '   if len(x) < 5 :\n', '    if util.find(x,symfull) > 0 :   aux.append(x)\n', '\n', ' if len(aux) >  1 :\n', '  stock_recommend= util.load_obj(dbname)\n', '  stock_recommend.append(aux)\n', '  util.save_obj(stock_recommend,dbname)\n', '  print aux\n', ' return stock_recommend\n', '\n', '\n', '\n', '#################### Finviz  ###############################################################\n', 'from bs4 import BeautifulSoup\n', 'import csv,datetime, requests\n', 'def imp_finviz():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Overview Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=111&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(111) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 10].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 10\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockoverview.csv', 'wb') as csvfile:\n"", ""    overview = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    overview.writeheader()\n', '\n', '    for stock in alldata:\n', '        overview.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10] })\n', '\n', ' print ""Finviz Overview Completed""\n', ' return overview\n', ' \n', '\n', 'def imp_finviz_news():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Performance Start""\n', ' url = ""http://www.finviz.com/quote.ashx?t=intc""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', ' titleslist = soup.find_all(\'a\',{""class"" : ""tab-link-news""})\n', ' return titleslist\n', '\n', '\n', 'def imp_finviz_financials():\n', ' import datetime\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=161&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(161) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 17].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 16].text,stockdata[datalength - 15].text,stockdata[datalength - 14].text,stockdata[datalength - 13].text,stockdata[datalength - 12].text,stockdata[datalength - 11].text,stockdata[datalength - 10].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 17\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockfinancial.csv', 'wb') as csvfile:\n"", ""    financial = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    financial.writeheader()\n', '\n', '    for stock in alldata:\n', '        financial.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10],titlesarray[11] : stock[11],titlesarray[12] : stock[12],titlesarray[13] : stock[13],titlesarray[14] : stock[14],titlesarray[15] : stock[15],titlesarray[16] : stock[16],titlesarray[17] : stock[17] })\n', '\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Completed""\n', '\n', '\n', '\n', 'def get_price2book( symbol ):\n', '   from bs4 import BeautifulSoup as bs\n', '   import urllib as u\n', '   try:\n', ""    \turl = r'http://finviz.com/quote.ashx?t={}'.format(symbol.lower())\n"", '        html = u.request.urlopen(url).read()\n', ""        soup = bs(html, 'lxml')\n"", '        # Change the text below to get a diff metric\n', ""        pb =  soup.find(text = r'P/B')\n"", ""        pb_ = pb.find_next(class_='snapshot-td2').text\n"", ""        print( '{} price to book = {}'.format(symbol, pb_) )\n"", '        return pb_\n', '   except Exception as e:\n', '        print(e)\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ' try:\n', '   q = imp_googleQuote(name1, date1, date2)  #interval, timeframe\n', ""   name1= name1.replace(':','_')\n"", ""   file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(date2) +'.csv'\n"", '   q.write_csv(file1)\n', ' except: print\n', ""'''\n"", '\n', '\n', ""'''\n"", 'def imp_googleQuoteList(symbols, freqsec=300, nday=1, intraday1=True) :\n', ' qlist=[]; sym=[]\n', ' if intraday1:\n', '  for symbol in symbols:\n', '     #try :\n', '        q = imp_googleIntradayQuote(symbol, freqsec, nday)  #interval, timeframe\n', '        qlist.append(q)\n', '        sym.append(symbol)\n', ""     #except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       q = imp_googleQuote(name1, freqsec, num_days)  #interval, timeframe\n', '     except: print(symbol)\n', '\n', ' return qlist, sym\n', ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''        \n"", ""stock_list = ['XOM','AMZN','AAPL','SWKS']\n"", 'p2b_series = pd.Series( index=stock_list )\n', '\n', 'for sym in stock_list:\tp2b_series[sym] = get_price2book(sym)\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", "" # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", ' from dateutil.parser import parse\n', ' if os.path.getsize(file1)> 500 :\n', '  from_zone = tz.gettz(fromzone); tozone = tz.gettz(tozone)\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%m-%d-%Y %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', '  dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '\n', '  # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '  print file1\n', ""  #df = pd.read_csv(file1,sep=',',header=None, parse_dates={'date': [1]}, date_parser=dateparse)\n"", '\n', ""  df = pd.read_csv(file1,sep=',',header=0)\n"", '  #df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '  #df.date= [x.to_datetime() for x in  df.date]\n', '\n', '\n', '  df.drop(df.columns[[0]], axis=1, inplace=True)\n', ""  df= util.pd_addcol(df, 'symbol')\n"", ""  df['symbol']= dfname\n"", '\n', '  print filenameh5\n', ""  df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", ""  df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", '\n', '  # store = pd.HDFStore(filenameh5);\n', '  # store.append(dfname, df);  store.close()\n', ""'''\n"", '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dropcol=[], type1='csv', hasheader=True, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", ' if os.path.getsize(file1)> 500 :\n', '   header= 0 if hasheader else None\n', ""   df = pd.read_csv(file1, sep=',',header=0)\n"", '\n', '   df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""   df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""   df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", '\n', ""   if type1=='csv' :\n"", ""     df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""     if i==1: close = qq[['Datetime']]  #new dataframe\n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', ""     close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""     close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', "" close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", "" close= close.sort('Datetime')\n"", "" close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", '\n', ' close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", 'class Quote(object):\n', ""  DATE_FMT = '%Y-%m-%d';  TIME_FMT = '%H:%M:%S'\n"", '\n', '  def __init__(self):\n', ""    self.symbol = '';    self.exchn=''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', '\n', '  def append(self,dt,open_,high,low,close,volume):\n', '    self.date.append(dt.date())\n', '    self.time.append(dt.time())\n', '    self.open_.append(float(open_))\n', '    self.high.append(float(high))\n', '    self.low.append(float(low))\n', '    self.close.append(float(close))\n', '    self.volume.append(int(volume))\n', '\n', '  def to_csv(self):\n', '    return \'\'.join([""{0},{1},{2},{3:.2f},{4:.2f},{5:.2f},{6:.2f},{7}\\n"".format(self.symbol,\n', ""              self.date[bar].strftime('%Y-%m-%d'),self.time[bar].strftime('%H:%M:%S'),\n"", '              self.open_[bar],self.high[bar],self.low[bar],self.close[bar],self.volume[bar])\n', '              for bar in xrange(len(self.close))])\n', '\n', '  def write_csv(self,filename):\n', ""    with open(filename,'w') as f:\n"", '      txt= self.to_csv()\n', '      f.write(txt)\n', '\n', '  def read_csv(self,filename):\n', ""    self.symbol = ''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', ""    for line in open(filename,'r'):\n"", ""      symbol,ds,ts,open_,high,low,close,volume = line.rstrip().split(',')\n"", '      self.symbol = symbol\n', ""      dt = datetime.datetime.strptime(ds+' '+ts,self.DATE_FMT+' '+self.TIME_FMT)\n"", '      self.append(dt,open_,high,low,close,volume)\n', '    return True\n', '\n', '  def __repr__(self):\n', '    return self.to_csv()\n', ""'''\n"", '\n', ' \n', '\n', ""'''\n"", ""def imp_googleIntradayQuoteSave2(name1, date1, inter, tframe, dircsv='', dbname=''):\n"", ' q = imp_googleIntradayQuote(name1, inter, tframe)  #interval, timeframe\n', "" name1= name1.replace(':','_')\n"", '\n', "" if dircsv != '' :\n"", ""    file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", '    q.to_csv(file1)\n', '\n', "" if dbname != '' :\n"", '    import sqlalchemy as sql\n', '    dbcon= sql.create_engine(dbname)\n', '    if inter== 300 : # 5mins\n', ""      q.to_sql('q5min', dbcon)\n"", '\n', '\n', ""def imp_googleQuoteList_save(symbols, date1, date2, inter=23400, tframe=2000, dircsv='', intraday1=True) :\n"", ' if intraday1:\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleIntradayQuoteSave(symbol, date1, inter, tframe, dircsv)\n', ""     except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleQuoteSave(symbol, date1, date2, dircsv)\n', '     except: print(symbol)\n', ""'''\n"", '\n']","['np.shape', 'getret_fromquotes', 'len', 'getlogret_fromquotes', 'np.log', 'getprice_fromret']",6
utilmy/zarchive/portfolio_withdate.py:index,index,class,103,300,221,3009,10.03,1,3,[],[],[],1835,[],[],0
utilmy/zarchive/portfolio_withdate.py:folioCalc,folioCalc,class,125,509,332,4736,9.3,2,17,[],[],[],2134,[],[],0
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator,folioRiskIndicator,class,89,306,215,3180,10.39,1,9,[],[],[],2309,[],[],0
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF,folioOptimizationF,class,280,1291,671,10994,8.52,6,39,[],[],[],2487,[],[],0
utilmy/zarchive/portfolio_withdate.py:searchSimilarity,searchSimilarity,class,173,497,328,4550,9.15,8,17,[],[],[],3934,[],[],0
utilmy/zarchive/portfolio_withdate.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1836,[],['date_generatedatetime'],1
utilmy/zarchive/portfolio_withdate.py:index:close,index:close,method,0,1,1,4,4.0,0,0,['self'],[None],[None],1841,[],[],0
utilmy/zarchive/portfolio_withdate.py:index:updatehisto,index:updatehisto,method,2,12,11,62,5.17,0,0,['self)'],['  #Download Quotespassself) :'],[None],1844,[],['print'],1
utilmy/zarchive/portfolio_withdate.py:index:help,index:help,method,2,12,11,62,5.17,0,0,['self'],[None],[None],1848,[],['print'],1
utilmy/zarchive/portfolio_withdate.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]",['date_generatedatetime'],1
utilmy/zarchive/portfolio_withdate.py:index:calc_baskettable_pct,index:calc_baskettable_pct,method,37,95,77,782,8.23,1,2,"['self', 'type1', 'showdetail']","[None, None, None]","[None, '""table""', '0']",1913,"[""      '''   Calc Basket Values from Input data '''\n""]","['np.zeros', 'np.sum', 'self._udpate_wwindpct', 'range', 'np.mod', 'self._wwpct_rebal']",6
utilmy/zarchive/portfolio_withdate.py:index:_wwpct_rebal,index:_wwpct_rebal,method,3,4,3,41,10.25,0,0,"['self', 'wwpct_actual', 't', 'trebal)', '']","[None, None, None, '  # BskUnit', ']np.abs(wwpct_actual/wwpct_th  -1 )) > self.rebal_trigger:']","[None, None, None, ' 1.0  !!!wwpct_th = self.wwasset[trebal', None]",1940,[],[],0
utilmy/zarchive/portfolio_withdate.py:index:_udpate_wwindpct,index:_udpate_wwindpct,method,11,25,17,224,8.96,0,0,"['self', 't', 'bskt', 'hedgecost', 'wwpct_actual', 'wwpct_th']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",1950,[],[],0
utilmy/zarchive/portfolio_withdate.py:index:calc_baskettable_unit,index:calc_baskettable_unit,method,0,0,0,0,0.0,0,0,[],[],[],1959,"[""    '''   t           --->  t+1                 ---->   t+2\n"", '            wwactual:    B[t]    -->   B[t+1]   using  w[t+1], B[t] /   S[t]\n', '            wwnew   :    B[t+1]  -->   B[t+2]   using  w[t+2], B[t+1] /   S[t+1]\n', ""    '''\n""]",[],0
utilmy/zarchive/portfolio_withdate.py:folioCalc:__init__,folioCalc:__init__,method,21,39,37,356,9.13,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2135,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioCalc:set_symclose,folioCalc:set_symclose,method,17,34,33,312,9.18,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2148,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioCalc:setcriteria,folioCalc:setcriteria,method,41,76,71,1046,13.76,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2157,"[""        ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '            wwtype:     constant / regime /regimExtra\n', '            initperiod: NbOfDays_initial_Risk_Monitoring\n', '            riskid:     spprice/spperf/multi\n', ""        '''\n""]","['np.array', 'len']",2
utilmy/zarchive/portfolio_withdate.py:folioCalc:_weightcalc_generic,folioCalc:_weightcalc_generic,method,5,35,23,396,11.31,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2207,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/portfolio_withdate.py:folioCalc:_weightcalc_regime,folioCalc:_weightcalc_regime,method,10,37,32,272,7.35,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2218,[],"['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/portfolio_withdate.py:folioCalc:_regimecalc,folioCalc:_regimecalc,method,3,7,6,83,11.86,0,0,"['self', 't', 'wwextra)', 't - 1]self.riskind[0', 't - 1] / self.riskind[0', 't - 1 - self.nbrange] - 1if self.riskid == ""multi""']","[None, None, '  # Risk Indicatorif self.riskid ', None, None, '']","[None, None, '= ""spprice"":   return self.riskind[0', None, None, '= ""multi"":']",2228,[],['self._mapping_calc_risk'],1
utilmy/zarchive/portfolio_withdate.py:folioCalc:_weightcalc_constant,folioCalc:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2237,[],['np.sum'],1
utilmy/zarchive/portfolio_withdate.py:folioCalc:getweight,folioCalc:getweight,method,5,12,9,126,10.5,0,0,['self'],[None],[None],2241,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/portfolio_withdate.py:folioCalc:calc_baskettable,folioCalc:calc_baskettable,method,33,111,83,811,7.31,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', '0.000', '0']",2248,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/portfolio_withdate.py:folioCalc:plot,folioCalc:plot,method,10,29,26,295,10.17,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2276,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/portfolio_withdate.py:folioCalc:multiperiod_ww,folioCalc:multiperiod_ww,method,15,36,29,240,6.67,1,1,"['self', 't']","[None, None]","[None, None]",2287,[],['xrange'],1
utilmy/zarchive/portfolio_withdate.py:folioCalc:help,folioCalc:help,method,1,2,2,13,6.5,0,0,['self'],[None],[None],2300,[],['print'],1
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:__init__,folioRiskIndicator:__init__,method,23,40,38,356,8.9,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:set_symclose,folioRiskIndicator:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2324,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:setcriteria,folioRiskIndicator:setcriteria,method,34,81,70,1006,12.42,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2334,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'np.zeros']",3
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:calcrisk,folioRiskIndicator:calcrisk,method,13,18,17,220,12.22,1,0,"['self', 'wwvec', 'initval']","[None, None, None]","[None, '[]', '1']",2382,[],"['xrange', 'self._weightcalc_generic', 'np.column_stack']",3
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:_weightcalc_generic,folioRiskIndicator:_weightcalc_generic,method,4,34,24,327,9.62,0,3,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2394,[],"['self._weightcalc_regime', 'print']",2
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:_weightcalc_regime,folioRiskIndicator:_weightcalc_regime,method,3,11,11,68,6.18,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2403,[],['self._regimecalc'],1
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:_regimecalc,folioRiskIndicator:_regimecalc,method,7,18,17,216,12.0,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )self.riskind', 'wwextra', 't', 'self.riskind_out)self', 'maxiter', 'name1', 'isreset', 'popsize=15) ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, None, None, None, None, None, None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, None, None, None, None, '1', ""''"", '1', '15) :']",2408,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:calc_optimal_weight,folioRiskIndicator:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2414,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:__init__,folioOptimizationF:__init__,method,23,39,37,340,8.72,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:set_symclose,folioOptimizationF:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2324,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:setcriteria,folioOptimizationF:setcriteria,method,44,128,103,1669,13.04,0,2,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2334,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'print', 'list']",4
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:calcbasket_obj2,folioOptimizationF:calcbasket_obj2,method,23,76,63,756,9.95,0,1,"['self', 'wwvec']","[None, None]","[None, None]",2572,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float']",6
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:calcbasket_obj,folioOptimizationF:calcbasket_obj,method,55,157,118,1494,9.52,1,4,"['self', 'wwvec']","[None, None]","[None, None]",2598,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float', 'calcbasket_obj', 'concenfactor=folio_concenfactor2', 'np.zeros', 'xrange', 'np.mod', 'self._weightcalc_generic', 'self._loss_obj', 'self._objective_criteria']",14
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_loss_obj,folioOptimizationF:_loss_obj,method,4,6,6,68,11.33,0,0,"['self', 'ww2', 'wwpenalty']","[None, None, None]","[None, None, None]",2623,[],['np.sum'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_weightcalc_generic,folioOptimizationF:_weightcalc_generic,method,5,40,26,394,9.85,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2394,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_weightcalc_regime,folioOptimizationF:_weightcalc_regime,method,8,32,28,239,7.47,0,0,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2403,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']","['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_regimecalc,folioOptimizationF:_regimecalc,method,4,7,7,83,11.86,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )if self.riskid== ""multi""   ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, '= ""multi""   :']",2408,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']",['self._mapping_calc_risk'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_weightcalc_constant,folioOptimizationF:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2662,[],['np.sum'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:calc_optimal_weight,folioOptimizationF:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2414,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:getweight,folioOptimizationF:getweight,method,6,11,9,126,11.45,0,0,['self'],[None],[None],2671,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:calc_baskettable,folioOptimizationF:calc_baskettable,method,36,86,72,827,9.62,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', ' 0.000', '0']",2679,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:plot,folioOptimizationF:plot,method,11,31,30,294,9.48,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2708,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_objective_criteria,folioOptimizationF:_objective_criteria,method,31,147,78,1105,7.52,2,7,"['self', 'bsk']","[None, None]","[None, None]",2720,[],"['np.std', 'np.sum', 'range', 'np.arange']",4
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:multiperiod_ww,folioOptimizationF:multiperiod_ww,method,18,29,27,238,8.21,1,1,"['self', 't']","[None, None]","[None, None]",2767,[],['xrange'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:help,folioOptimizationF:help,method,50,152,103,1472,9.68,1,6,['self'],[None],[None],2779,[],"['print', 'util.load_obj', 'int', 'copy.deepcopy', 'xrange', 'next', 'util.save_obj', 'np.mod', 'np.abs', 'np.reshape', 'np.sum']",11
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:mapping_risk_ww,folioOptimizationF:mapping_risk_ww,method,12,56,29,245,4.38,0,1,"['self', 'risk', 'wwmat', 'ww2']","[None, None, None, None]","[None, None, None, 'self.wwasset0']",2838,[],"['np.sum', 'np.array']",2
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_mapping_calc_risk,folioOptimizationF:_mapping_calc_risk,method,27,201,76,831,4.13,0,3,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",2850,[],[],0
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:__init__,searchSimilarity:__init__,method,15,18,17,193,10.72,0,0,"['self', ""filejpstock=r'E"", 'sym01', 'symname', 'startdate', 'enddate', 'pricetype']","[None, '', None, None, None, None, None]","[None, ""r'E:/_data/stock/daily/20160616/jp'"", ""['7203']"", ""['Toyota']"", ' 20150101', '20160601', '""close""']",3935,[],[],0
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:load_quotes_fromdb,searchSimilarity:load_quotes_fromdb,method,15,35,33,355,10.14,0,1,"['self', 'picklefile']","[None, None]","[None, ""''""]",3940,[],"['util.load_obj', 'imp_txt_getquotes', 'date_align', 'util.a_cleanmemory']",4
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:__generate_return__,searchSimilarity:__generate_return__,method,4,4,4,64,16.0,0,0,"['self', 'nlag']","[None, None]","[None, None]",3951,[],['getret_fromquotes'],1
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:__overweight__,searchSimilarity:__overweight__,method,17,62,41,412,6.65,2,4,"['self', 'px']","[None, None]","[None, None]",3955,[],"['len', 'np.ones', 'util.np_findlocalmax', 'type', 'np.abs', 'wwerr[max', 'util.np_findlocalmin']",7
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:set_searchcriteria,searchSimilarity:set_searchcriteria,method,34,79,63,793,10.04,0,5,"['self', 'name1', 'date1', 'date2', 'nlag', 'searchperiodstart', 'typesearch', '']","[None, None, None, None, None, None, None, None]","[None, ""'7203'"", '20160301', '20160601', '1', '20120101', '""pattern2""', None]",3975,[],"['getret_fromquotes', 'date_finddateid', 'max', 'util.np_findfirst', 'print', 'price_normalize_1d', 'len', 'self.__overweight__']",8
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:launch_search,searchSimilarity:launch_search,method,53,107,81,908,8.49,3,3,['self'],[None],[None],4004,[],"['len', 'np.zeros', 'range', 'price_normalize_1d', 'np_similarity', 'util.np_sortbycolumn', 'enumerate']",7
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:show_comparison_graph,searchSimilarity:show_comparison_graph,method,33,72,63,682,9.47,1,3,"['self', 'maxresult', 'show_only_different_time', 'fromid', 'fromend', 'filenameout']","[None, None, None, None, None, None]","[None, '20', 'True', '0', ' 0', ""''""]",4038,[],"['np.shape', 'range', 'int', 'print', 'price_normalize_1d', 'str', 'plot_price']",7
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:staticmethod,searchSimilarity:staticmethod,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",4067,[],[],0
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:get_rankresult,searchSimilarity:get_rankresult,method,24,63,53,496,7.87,2,1,"['self', 'filetosave']","[None, None]","[None, ""''""]",4071,[],"['len', 'np.savetxt', 'np.shape', 'np.array', 'np.empty', 'range', 'int', 'str']",8
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:export_results,searchSimilarity:export_results,method,0,0,0,0,0.0,0,0,[],[],[],4093,"[""'''\n"", '#####################################################################################\n', '#---------Run over all the indexes, with time lag -----------------------------------\n', 'def np_similarity(x,y, wwerr=[], type1=0):\n', '  if type1==2 : return np_distance_l1(x,y, wwerr)\n', '  if type1==1: return sci.spatial.distance.correlation(x, y)  \n', '  if type1==0 : return 1-np.corrcoef(x,y)[0,1]\n', '\n', 'def np_distance_l1(x,y, wwerr) :\n', ' return np.sum(wwerr * np.abs(x-y))  \n', '  \n', '#---------------------  Universe Load         ---------------------------------------\n', ""filejpstock= r'E:/_data/stock/daily/20160616/jp'\n"", 'sym01= nk400list\n', '\n', 'quotes= imp_txt_getquotes(sym01, filejpstock, startdate=20090101, endate=20160616)\n', 'open1, dateref= date_align(quotes, type1=""close"")    #Get the data and align dates\n', 'del quotes; util.a_cleanmemory()\n', '\n', ""#util.save_obj(open1, 'close_nk400_2009_2016')\n"", ""#util.save_obj(dateref, 'dateref_nk400_2009_2016')\n"", '\n', ""open1= util.load_obj('close_nk400_2009_2016')\n"", ""dateref= util.load_obj( 'dateref_nk400_2009_2016')\n"", '\n', 'nlag=1\n', 'ret_open1 =  getdailyret_fromquotes(open1,nlag)\n', 'del open1\n', '\n', '#--------------------  Search Asset Input     ---------------------------------------\n', ""name1= '7203' \n"", 'date1= 20160328\n', 'date2= 20160531\n', 'twindow= util.np_findfirst(date2, dateref) - util.np_findfirst(date1, dateref) \n', '\n', '\n', 'tstartx= util.np_findfirst(date1, dateref)          # Date Index\n', 'stockx= util.np_findfirst(name1, sym01)\n', 'retx= ret_open1[stockx, tstartx:(tstartx+twindow-1)]    # Recent Period\n', 'px= price_normalize_1d(retx)\n', 'nx= len(px)\n', '\n', '\n', '#----OverWeight for Local Min, Local Max         -----------------------------------\n', 'wwerr= np.ones(nx, dtype=np.float16)\n', 'vvmax= util.np_findlocalmax(px); xprev=0\n', 'for x in vvmax:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', 'vvmin= util.np_findlocalmin(px); xprev=0\n', 'for x in vvmin:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', '\n', '#--------------------  Search the Pattern       -------------------------------------\n', 'tmaxx= len(dateref)-1\n', 'similar_list= np.zeros((nstock*(tmaxx-twindow)+1, 3), np.float16)\n', 'i=0\n', 'for iy in range(0, nstock) :\n', ' for t in range(0, tmaxx-twindow):\n', '   if iy == stockx and t > tstartx : \n', '     pass\n', '   else :\n', '    rety= ret_open1[iy, t:(t+twindow-1)]\n', '    py=   price_normalize_1d(rety)\n', '    ss= np_similarity(px, py, wwerr=wwerr, type1=2)\n', '    i+=1\n', '    similar_list[i,0]= iy\n', '    similar_list[i,1]= t\n', '    similar_list[i,2]= ss\n', '\n', '\n', ' #-------------------Clean the table -------------------------------------------------\n', 'rank= util.np_sortbycolumn(similar_list,2, asc=True)\n', 'for i,x in enumerate(rank) :\n', '  if rank[i,2]==0.0 : rank[i,2]= 1000         # Empty cell\n', '  if rank[i,1]> tstartx-3 : rank[i,2]= 100    # Start Element\n', 'rank= util.np_sortbycolumn(rank,2, asc=True)  \n', '\n', '\n', ' #----- Show Similar Stocks ---------------------------------------------------------\n', 'show_only_different_time= True\n', '\n', 'for i in range(0,10) :\n', ' tstarti= rank[i,1]\n', ' stocki= int(rank[i,0])\n', ' \n', ' if show_only_different_time and tstarti < tstartx-1  :\n', '   py= price_normalize100(ret_open1[stocki, tstarti:(tstarti+twindow-1)]) \n', '\n', '   namei= sym01[stocki]\n', '   namefulli= nk400name[util.np_findfirst(namei, nk400list)]\n', '\n', '   tit= namei+ "" "" +namefulli+ "" "" + str(dateref[tstarti])          \n', ""   plot_price(px-100, py-100, label=('Similar '+tit, 'Time','% Var') )\n"", '\n', '\n', 'kix= util.np_findfirst(name1, statsjp[:,0, ilag])\n', 'stocklist01[390]\n', '\n', '\n', 'stocklist01[157] , nk400name[157] ,  dateref1adj[86]     \n', 'plot_price(price_normalize100(ret_open1[157, 86:86+twindow-1])-100,px-100   )\n', ""'''    \n""]",[],0
utilmy/zarchive/report.py:map_show,map_show,function,0,1,1,4,4.0,0,0,[],[],[],36,[],[],0
utilmy/zarchive/report.py:xl_create_pivot,xl_create_pivot,function,4,9,9,134,14.89,0,0,"['infile', 'index_list', '""Rep""', '""Product""]', 'value_list', '""Quantity""]']","[None, None, None, None, None, None]","[None, '[""Manager""', None, None, '[""Price""', None]",65,"[""   ''' Read in the Excel file, create a pivot table and return it as a DataFrame '''\n""]",[],0
utilmy/zarchive/report.py:xl_save_report,xl_save_report,function,6,10,10,167,16.7,1,0,"['report', 'outfile']","[None, None]","[None, None]",72,"[""   '''  Take a report and save it to a single Excel file\n"", '       sales_report = create_pivot(args.infile.name)\n', '       save_report(sales_report, args.outfile.name)\n', ""   '''\n""]","['temp_df.to_excel', 'writer.save']",2
utilmy/zarchive/report.py:xl_create_pdf,xl_create_pdf,function,23,44,39,743,16.89,1,0,[],[],[],97,[],"['sales_report=create_pivot', 'manager_df.append', 'sales_report.xs', 'env=Environment', 'get_summary_stats', 'sales_report.to_html', 'HTML']",7
utilmy/zarchive/rstatpy.py:stl,stl,function,32,165,104,1260,7.64,0,11,"['data', 'ns', 'np', 'nt', 'nl', 'isdeg', 'itdeg', 'ildeg', 'nsjump', 'ntjump', 'nljump', 'ni', 'no', 'fulloutput']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', '0', '1', '1', 'None', 'None', 'None', '2', '0', 'False']",9,"['    """"""\n', '    Seasonal-Trend decomposition procedure based on LOESS\n', '    data : pandas.Series\n', '    ns : int\n', '        Length of the seasonal smoother.\n', '        The value of  ns should be an odd integer greater than or equal to 3.\n', '        A value ns>6 is recommended. As ns  increases  the  values  of  the\n', '        seasonal component at a given point in the seasonal cycle (e.g., January\n', '        values of a monthly series with  a  yearly cycle) become smoother.\n', '    np : int\n', '        Period of the seasonal component.\n', '        For example, if  the  time series is monthly with a yearly cycle, then\n', '        np=12.\n', '        If no value is given, then the period will be determined from the\n', '        ``data`` timeseries.\n', '    nt : int\n', '        Length of the trend smoother.\n', '        The  value  of  nt should be an odd integer greater than or equal to 3.\n', '        A value of nt between 1.5*np and 2*np is  recommended. As nt increases,\n', '        the values of the trend component become  smoother.\n', '        If nt is None, it is estimated as the smallest odd integer greater\n', '        or equal to ``(1.5*np)/[1-(1.5/ns)]``\n', '    nl : int\n', '        Length of the low-pass filter.\n', '        The value of nl should  be an odd integer greater than or equal to 3.\n', '        The smallest odd integer greater than or equal to np is used by default.\n', '    isdeg : int\n', '        Degree of locally-fitted polynomial in seasonal smoothing.\n', '        The value is 0 or 1.\n', '    itdeg : int\n', '        Degree of locally-fitted polynomial in trend smoothing.\n', '        The value is 0 or 1.\n', '    ildeg : int\n', '        Degree of locally-fitted polynomial in low-pass smoothing.\n', '        The value is 0 or 1.\n', '    nsjump : int\n', '        Skipping value for seasonal smoothing.\n', '        The seasonal smoother skips ahead nsjump points and then linearly\n', '        interpolates in between.  The value  of nsjump should be a positive\n', '        integer; if nsjump=1, a seasonal smooth is calculated at all n points.\n', '        To make the procedure run faster, a reasonable choice for nsjump is\n', '        10%-20% of ns. By default, nsjump= 0.1*ns.\n', '    ntjump : int\n', '        Skipping value for trend smoothing. If None, ntjump= 0.1*nt\n', '    nljump : int\n', '        Skipping value for low-pass smoothing. If None, nljump= 0.1*nl\n', '    ni :int\n', '        Number of loops for updating the seasonal and trend  components.\n', '        The value of ni should be a positive integer.\n', '        See the next argument for advice on the  choice of ni.\n', '        If ni is None, ni is set to 2 for robust fitting, to 5 otherwise.\n', '    no : int\n', '        Number of iterations of robust fitting. The value of no should\n', '        be a nonnegative integer. If the data are well behaved without\n', '        outliers, then robustness iterations are not needed. In this case\n', '        set no=0, and set ni=2 to 5 depending on how much security\n', '        you want that  the seasonal-trend looping converges.\n', '        If outliers are present then no=3 is a very secure value unless\n', '        the outliers are radical, in which case no=5 or even 10 might\n', '        be better.  If no>0 then set ni to 1 or 2.\n', '        If None, then no is set to 15 for robust fitting, to 0 otherwise.\n', '    fulloutput : bool\n', '        If True, a dictionary holding the full output of the original R routine\n', '        will be returned.\n', '    returns\n', '    data : pandas.DataFrame\n', '        The seasonal, trend, and remainder components\n', '    """"""\n']","['data.copy', '_data.dropna', 'pandas.DateRange', 'pandas.Series', 'ceil', 'robjects.IntVector', 'ts_', 'stl_', 'asarray', 'pandas.DataFrame']",10
utilmy/zarchive/util.py:session_save,session_save,function,39,72,64,1009,14.01,0,2,"['filename', 'globals1']","[None, None]","['""/folder1/name1""', 'None']",278,"[""    '''Need to pass globals() Cannot Get Save data to .spydata file\n"", '\n', '   BIG issue with Import, Impor FULL MODULE ----> BIG ISSUE\n', '     BIG ISSUE with DICT, USE LIST INSTEAD\n', '        If you try to put this code in a module and import the function then you will have to pass globals() to the function explicitly as the globals() in the function is not the IPython global namespace. However, you can put the above code inside your ~/.ipython/profile_PROFILE/startup/startup.ipy file and it will work as expected.\n', '       PROFILE is the name of the profile that you plan to start IPython with.\n', ""    '''\n""]","['print', 'spyutil.globalsfilter', 'filters=tuple', 'filename.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'iofunc.save_dictionary', 'os.chdir']",8
utilmy/zarchive/util.py:aa_unicode_ascii_utf8_issue,aa_unicode_ascii_utf8_issue,function,0,0,0,0,0.0,0,0,[],[],[],356,"[""   '''Take All csv in a folder and provide Table, Column Schema, type\n"", '\n', ' METHOD FOR Unicode / ASCII issue\n', '1. Decode early\n', ""Decode to <type 'unicode'> ASAP\n"", ""df['PREF_NAME']=       df['PREF_NAME'].apply(to_unicode)\n"", '\n', '2. Unicode everywhere\n', '\n', '\n', '3. Encode late\n', "">>> f = open('/tmp/ivan_out.txt','w')\n"", "">>> f.write(ivan_uni.encode('utf-8'))\n"", '\n', 'Important methods\n', ""s.decode(encoding)  <type 'str'> to <type 'unicode'>\n"", ""u.encode(encoding)  <type 'unicode'> to <type 'str'>\n"", '\n', 'http://farmdev.com/talks/unicode/\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/util.py:isexist,isexist,function,3,9,8,46,5.11,0,0,['a'],[None],[None],380,[],[],0
utilmy/zarchive/util.py:isfloat,isfloat,function,5,16,14,67,4.19,0,1,['x'],[None],[None],386,[],['float'],1
utilmy/zarchive/util.py:isint,isint,function,6,15,14,80,5.33,0,1,"['x)', '( int', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, '']","[None, None, None, None, None]",393,[],['txt.find'],1
utilmy/zarchive/util.py:a_isanaconda,a_isanaconda,function,6,15,14,80,5.33,0,1,[],[],[],395,[],['txt.find'],1
utilmy/zarchive/util.py:a_run_ipython,a_run_ipython,function,1,1,1,33,33.0,0,0,['cmd1'],[None],[None],405,"["" ''' Execute Ipython Command in python code\n"", '     run -i :  run including current interprete variable\n', "" '''\n""]",['IPython.get_ipython'],1
utilmy/zarchive/util.py:a_autoreload,a_autoreload,function,1,4,4,64,16.0,0,0,[],[],[],411,[],['a_run_ipython'],1
utilmy/zarchive/util.py:a_start_log,a_start_log,function,1,14,12,98,7.0,0,0,"['id1', 'folder']","[None, None]","[""''"", ""'aaserialize/log/'""]",414,[],"['a_run_ipython', 'str', 'a_get_platform', 'date_now']",4
utilmy/zarchive/util.py:a_cleanmemory,a_cleanmemory,function,3,3,3,21,7.0,0,0,[],[],[],417,[],['gc.collect'],1
utilmy/zarchive/util.py:a_module_codesample,a_module_codesample,function,6,9,9,130,14.44,0,0,['module_str'],[None],"[""'pandas'""]",420,[],"['os_file_read', 'os_gui_popup_show']",2
utilmy/zarchive/util.py:a_module_doc,a_module_doc,function,6,9,9,123,13.67,0,0,['module_str'],[None],"[""'pandas'""]",426,[],"['os_file_read', 'os_gui_popup_show']",2
utilmy/zarchive/util.py:a_module_generatedoc,a_module_generatedoc,function,8,16,16,180,11.25,0,1,"['module_str', 'fileout']","[None, None]","['""pandas""', ""''""]",432,"['  \'\'\' #  getmodule_doc(""jedi"", r""D:\\_devs\\Python01\\aapackage\\doc.txt"")\'\'\'\n']","['os.makedirs', 'ca.getmodule_doc']",2
utilmy/zarchive/util.py:a_info_conda_jupyter,a_info_conda_jupyter,function,61,133,110,1071,8.05,1,3,[],[],[],440,[],"['printProgress', 'shutil.make_archive', 'os_zipfolder', 'dir_tozip.split', 'os_zip_checkintegrity', 'print']",6
utilmy/zarchive/util.py:os_zipextractall,os_zipextractall,function,23,59,48,538,9.12,1,3,"['filezip_or_dir', 'tofolderextract', 'isprint']","[None, None, None]","['""folder1/*.zip""', ""'zdisk/test'"", '1']",711,"[""   '''os_zipextractall( 'aapackage.zip','zdisk/test/'      )  '''\n""]","['filezip_or_dir.find', 'os_file_listall', 'os_file_getname', 'zipfile.ZipFile', 'zip_ref.extractall', 'zip_ref.close', 'print']",7
utilmy/zarchive/util.py:os_folder_copy,os_folder_copy,function,17,36,35,345,9.58,0,1,"['src', 'dst', 'symlinks', 'pattern1', 'fun_file_toignore']","[None, None, None, None, None]","[None, None, 'False', '""*.py""', 'None']",741,"[""   '''\n"", '       callable(src, names) -> ignored_names\n', ""       'src' parameter, which is the directory being visited by copytree(), and\n"", ""       'names' which is the list of `src` contents, as returned by os.listdir():\n"", '\n', '    Since copytree() is called recursively, the callable will be called once for each directory that is copied.\n', '    It returns a  list of names relative to the `src` directory that should not be copied.\n', '   :param fun_ignore:\n', ""   '''\n""]","['fun_file_toignore', 'fnmatch.filter', 'shutil.copytree', 'shutil.copy']",4
utilmy/zarchive/util.py:os_folder_create,os_folder_create,function,4,7,7,85,12.14,0,1,['directory'],[None],[None],764,[],"['os.getcwd', 'os.makedirs', 'os.chdir']",3
utilmy/zarchive/util.py:os_folder_robocopy,os_folder_robocopy,function,3,15,15,163,10.87,0,1,"['from_folder', 'to_folder', ""my_log='H""]","[None, None, '']","[""''"", ""''"", ""'H:/robocopy_log.txt'""]",769,"['    """"""\n', '    Copy files to working directory\n', '    robocopy <Source> <Destination> [<File>[ ...]] [<Options>]\n', '    We want to copy the files to a fast SSD drive\n', '    """"""\n']","['subprocess.call', 'print']",2
utilmy/zarchive/util.py:os_file_replace,os_file_replace,function,26,69,57,697,10.1,2,0,"['source_file_path', 'pattern', 'substring']","[None, None, None]","[None, None, None]",784,[],"['mkstemp', 'open', 'target_file.write', 'remove', 'move', 'os_file_replacestring1', 'fileinput.FileInput', 'line.replace', 'file1.close', 'print', 'os_file_replacestring2']",11
utilmy/zarchive/util.py:os_file_replacestring1,os_file_replacestring1,function,11,26,25,240,9.23,1,0,"['findStr', 'repStr', 'filePath']","[None, None, None]","[None, None, None]",798,[],"['fileinput.FileInput', 'line.replace', 'file1.close', 'print']",4
utilmy/zarchive/util.py:os_file_replacestring2,os_file_replacestring2,function,6,14,13,161,11.5,1,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",809,"['  \'\'\' #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",    pattern=""*.html"", dirlevel=5  )\n', ""  '''\n""]","['os_file_listall', 'os_file_replacestring1']",2
utilmy/zarchive/util.py:os_file_getname,os_file_getname,function,8,9,8,75,8.33,0,0,['path'],[None],[None],817,[],"['ntpath.split', 'ntpath.basename']",2
utilmy/zarchive/util.py:os_file_getpath,os_file_getpath,function,7,7,7,52,7.43,0,0,['path'],[None],[None],822,[],['ntpath.split'],1
utilmy/zarchive/util.py:os_file_gettext,os_file_gettext,function,4,8,8,56,7.0,0,0,['file1'],[None],[None],827,[],"['open', 'f.read']",2
utilmy/zarchive/util.py:os_file_listall,os_file_listall,function,28,82,46,904,11.02,4,3,"['dir1', 'pattern', 'dirlevel', 'onlyfolder']","[None, None, None, None]","[None, '""*.*""', '1', '0']",833,"[""  '''\n"", '   # DIRCWD=r""D:\\_devs\\Python01\\project""\n', '   # aa= listallfile(DIRCWD, ""*.*"", 2)\n', '   # aa[0][30];   aa[2][30]\n', '\n', '   :param dir1:\n', '   :param pattern:\n', '   :param dirlevel:\n', '   :param onlyfolder:\n', '   :return:\n', ""  '''\n""]","['dir1.rstrip', 'dir1.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 'np.array']",7
utilmy/zarchive/util.py:os_file_rename,os_file_rename,function,32,60,48,643,10.72,2,1,"['some_dir', 'pattern', 'pattern2', 'dirlevel']","[None, None, None, None]","[None, '""*.*""', '""""', '1']",870,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 're.sub', 'os.rename', 'np.array']",9
utilmy/zarchive/util.py:os_gui_popup_show,os_gui_popup_show,function,25,38,37,361,9.5,0,0,['txt'],[None],[None],891,[],"['os_gui_popup_show2', 'Tk', 'Scrollbar', 'Text', 'S.pack', 'T.pack', 'S.config', 'T.config', 'T.insert', 'root.attributes', 'mainloop']",11
utilmy/zarchive/util.py:os_print_tofile,os_print_tofile,function,8,21,19,174,8.29,0,1,"['vv', 'file1', ""mode1='a')"", 'mode1) as text_file']","[None, None, '', '  text_file.write(str(vv))pth): #Normalize path for Python directory)']","[None, None, ""'a'):  # print into a file='afile1"", '=2:']",908,"[""    '''\n"", '    Here is a list of the different modes of opening a file:\n', 'r\n', 'Opens a file for reading only. The file pointer is placed at the beginning of the file. This is the default mode.\n', '\n', 'rb\n', '\n', 'Opens a file for reading only in binary format. The file pointer is placed at the beginning of the file. This is the default mode.\n', 'r+\n', '\n', 'Opens a file for both reading and writing. The file pointer will be at the beginning of the file.\n', 'rb+\n', '\n', 'Opens a file for both reading and writing in binary format. The file pointer will be at the beginning of the file.\n', 'w\n', '\n', 'Opens a file for writing only. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'wb\n', '\n', 'Opens a file for writing only in binary format. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'w+\n', '\n', 'Opens a file for both writing and reading. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'wb+\n', '\n', 'Opens a file for both writing and reading in binary format. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'a\n', '\n', 'Opens a file for appending. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'ab\n', '\n', 'Opens a file for appending in binary format. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'a+\n', '\n', 'Opens a file for both appending and reading. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'ab+\n', '\n', 'Opens a file for both appending and reading in binary format. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'To open a text file, use:\n', 'fh = open(""hello.txt"", ""r"")\n', '\n', 'To read a text file, use:\n', 'print fh.read()\n', '\n', 'To read one line at a time, use:\n', 'print fh.readline()\n', '\n', 'To read a list of lines use:\n', 'print fh.readlines()\n', '\n', 'To write to a file, use:\n', 'fh = open(""hello.txt"", ""w"")\n', 'lines_of_text = [""a line of text"", ""another line of text"", ""a third line""]\n', 'fh.writelines(lines_of_text)\n', 'fh.close()\n', '\n', 'To append to file, use:\n', 'fh = open(""Hello.txt"", ""a"")\n', 'fh.close()\n', '\n', ""    '''\n""]","['pth.find', 'b.lstrip']",2
utilmy/zarchive/util.py:os_path_norm,os_path_norm,function,8,21,19,174,8.29,0,1,['pth)'],[' #Normalize path for Python directory)'],['=2:'],972,"['    \'\'\' #r""D:\\_devs\\Python01\\project\\03-Connect_Java_CPP_Excel\\PyBindGen\\examples"" \'\'\'\n']","['pth.find', 'b.lstrip']",2
utilmy/zarchive/util.py:os_path_change,os_path_change,function,4,4,4,34,8.5,0,0,['path1)'],[' path1'],[' normpath(path1); os.chdir(path1)    #Change Working directory path): return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],984,[],"['open', 'fh.read']",2
utilmy/zarchive/util.py:os_path_current,os_path_current,function,4,4,4,34,8.5,0,0,[')'],[' return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],986,[],"['open', 'fh.read']",2
utilmy/zarchive/util.py:os_file_exist,os_file_exist,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],988,[],"['open', 'fh.read']",2
utilmy/zarchive/util.py:os_file_size,os_file_size,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.getsize(file1)file1):'],[None],990,[],"['open', 'fh.read']",2
utilmy/zarchive/util.py:os_file_read,os_file_read,function,4,4,4,34,8.5,0,0,['file1'],[None],[None],992,[],"['open', 'fh.read']",2
utilmy/zarchive/util.py:os_file_isame,os_file_isame,function,4,7,7,44,6.29,0,0,"['file1', 'file2']","[None, None]","[None, None]",997,[],['filecmp.cmp'],1
utilmy/zarchive/util.py:os_file_get_file_extension,os_file_get_file_extension,function,5,12,10,98,8.17,0,2,['file_path'],[None],[None],1004,"['    """"""\n', '    >>> get_file_extension(""/a/b/c"")\n', ""    ''\n"", '    >>> get_file_extension(""/a/b/c.tar.xz"")\n', ""    'xz'\n"", '    """"""\n']",['_ext.startswith'],1
utilmy/zarchive/util.py:os_file_normpath,os_file_normpath,function,2,8,8,67,8.38,0,0,['path'],[None],[None],1021,"['    """"""Normalize path.\n', '    - eliminating double slashes, etc. (os.path.normpath)\n', '    - ensure paths contain ~[user]/ expanded.\n', '\n', '    :param path: Path string :: str\n', '    """"""\n']",[],0
utilmy/zarchive/util.py:os_folder_is_path,os_folder_is_path,function,2,3,3,36,12.0,0,0,['path_or_stream'],[None],[None],1031,"['    """"""\n', '    Is given object `path_or_stream` a file path?\n', '    :param path_or_stream: file path or stream, file/file-like object\n', '    :return: True if `path_or_stream` is a file path\n', '    """"""\n']",['isinstance'],1
utilmy/zarchive/util.py:os_file_get_path_from_stream,os_file_get_path_from_stream,function,7,20,15,187,9.35,0,2,['maybe_stream'],[None],[None],1040,"['    """"""\n', '    Try to get file path from given stream `stream`.\n', '\n', '    :param maybe_stream: A file or file-like object\n', '    :return: Path of given file or file-like object or None\n', '\n', '    >>> __file__ == get_path_from_stream(__file__)\n', '    True\n', ""    >>> __file__ == get_path_from_stream(open(__file__, 'r'))\n"", '    True\n', '    >>> strm = anyconfig.compat.StringIO()\n', '    >>> get_path_from_stream(strm) is None\n', '    True\n', '    """"""\n']","['os_folder_is_path', 'getattr']",2
utilmy/zarchive/util.py:os_file_try_to_get_extension,os_file_try_to_get_extension,function,4,12,10,117,9.75,0,1,['path_or_strm'],[None],[None],1065,"['    """"""\n', '    Try to get file extension from given path or file object.\n', '    :return: File extension or None\n', '    """"""\n']","['os_file_get_path_from_stream', 'os_file_get_file_extension']",2
utilmy/zarchive/util.py:os_file_are_same_file_types,os_file_are_same_file_types,function,5,20,14,152,7.6,0,2,['paths'],[None],[None],1077,"['    """"""\n', '    Are given (maybe) file paths same type (extension) ?\n', '    :param paths: A list of file path or file(-like) objects\n', '\n', '    >>> are_same_file_types([])\n', '    False\n', '    >>> are_same_file_types([""a.conf""])\n', '    True\n', '    >>> are_same_file_types([""a.yml"", ""b.json""])\n', '    False\n', '    >>> strm = anyconfig.compat.StringIO()\n', '    >>> are_same_file_types([""a.yml"", ""b.yml"", strm])\n', '    False\n', '    """"""\n']","['os_file_try_to_get_extension', 'all']",2
utilmy/zarchive/util.py:os_file_norm_paths,os_file_norm_paths,function,18,55,36,393,7.15,2,3,"['paths', 'marker']","[None, None]","[None, ""'*'""]",1099,"['    """"""\n', '    :param paths:\n', '        A glob path pattern string, or a list consists of path strings or glob\n', '        path pattern strings or file objects\n', ""    :param marker: Glob marker character or string, e.g. '*'\n"", '    :return: List of path strings\n', '    >>> norm_paths([])\n', '    []\n', '    >>> norm_paths(""/usr/lib/a/b.conf /etc/a/b.conf /run/a/b.conf"".split())\n', ""    ['/usr/lib/a/b.conf', '/etc/a/b.conf', '/run/a/b.conf']\n"", '    >>> paths_s = os.path.join(os.path.dirname(__file__), ""u*.py"")\n', '    >>> ref = sglob(paths_s)\n', '    >>> ref = [""/etc/a.conf""] + ref\n', '    >>> assert norm_paths([""/etc/a.conf"", paths_s]) == ref\n', '    >>> strm = anyconfig.compat.StringIO()\n', '    >>> assert norm_paths([""/etc/a.conf"", strm]) == [""/etc/a.conf"", strm]\n', '    """"""\n']","['sglob', 'sorted', '_norm_paths_itr', 'os_folder_is_path', 'list']",5
utilmy/zarchive/util.py:os_file_mergeall,os_file_mergeall,function,10,20,20,185,9.25,1,0,"['nfile', 'dir1', 'pattern1', 'deepness']","[None, None, None, None]","[None, None, None, '2']",1144,[],"['os_file_listall', 'open', 'os_file_gettext', 'nfile1.write', 'nfile1.close']",5
utilmy/zarchive/util.py:os_file_extracttext,os_file_extracttext,function,14,31,29,286,9.23,1,0,"['output_file', 'dir1', 'pattern1', 'htmltag', 'deepness']","[None, None, None, None, None]","[None, None, '""*.html""', ""'p'"", '2']",1154,"["" ''' Extract text from html '''\n""]","['os_file_listall', 'open', 'os_file_gettext', 'BeautifulSoup', 'soup.find_all', 'txt2.strip', 'output_file1.write']",7
utilmy/zarchive/util.py:os_path_append,os_path_append,function,4,19,11,121,6.37,0,3,"['p1', 'p2', 'p3', 'p4']","[None, None, None, None]","[None, 'None', 'None', 'None']",1169,[],[],0
utilmy/zarchive/util.py:os_wait_cpu,os_wait_cpu,function,12,31,27,286,9.23,1,0,"['priority', 'cpu_min']","[None, None]","['300', '50']",1178,[],"['psutil.cpu_percent', 'print', 'arrow.utcnow', 'sleep']",4
utilmy/zarchive/util.py:os_split_dir_file,os_split_dir_file,function,6,15,15,112,7.47,0,1,['dirfile'],[None],[None],1187,[],"['dirfile.split', 'len']",2
utilmy/zarchive/util.py:os_process_run,os_process_run,function,13,31,31,321,10.35,0,1,"['cmd_list', ""'arg1'"", ""'arg2']"", 'capture_output']","[None, None, None, None]","[""['program'"", None, None, 'False']",1193,[],"['subprocess.Popen', 'proc.communicate', 'print', 'str']",4
utilmy/zarchive/util.py:os_process_2,os_process_2,function,0,1,1,4,4.0,0,0,[],[],[],1209,[],[],0
utilmy/zarchive/util.py:py_importfromfile,py_importfromfile,function,12,21,19,251,11.95,0,1,"['modulename', 'dir1']","[None, None]","[None, None]",1246,[],"['a_get_pythonversion', 'SourceFileLoader', 'foo.MyClass', 'imp.load_source']",4
utilmy/zarchive/util.py:py_memorysize,py_memorysize,function,16,56,38,312,5.57,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",1258,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'o.items']",7
utilmy/zarchive/util.py:save,save,function,2,4,4,64,16.0,0,0,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",1286,[],['py_save_obj'],1
utilmy/zarchive/util.py:load,load,function,2,3,3,60,20.0,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",1289,[],['py_load_obj'],1
utilmy/zarchive/util.py:save_test,save_test,function,6,11,11,126,11.45,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",1292,[],"['py_load_obj', 'print', 'str', 'gc.collect']",4
utilmy/zarchive/util.py:py_save_obj,py_save_obj,function,17,36,35,308,8.56,0,1,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",1298,[],"['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.dump']",5
utilmy/zarchive/util.py:py_load_obj,py_load_obj,function,16,30,28,265,8.83,0,1,"['folder', 'isabsolutpath', 'encoding1']","[None, None, None]","[""'/folder1/keyname'"", '0', ""'utf-8'""]",1311,"[""    '''def load_obj(name, encoding1='utf-8' ):\n"", ""         with open('D:/_devs/Python01/aaserialize/' + name + '.pkl', 'rb') as f:\n"", '            return pickle.load(f, encoding=encoding1)\n', ""    '''\n""]","['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.load']",5
utilmy/zarchive/util.py:z_key_splitinto_dir_name,z_key_splitinto_dir_name,function,6,15,15,112,7.47,0,1,['keyname'],[None],[None],1327,[],"['keyname.split', 'len']",2
utilmy/zarchive/util.py:sql_getdate,sql_getdate,function,0,1,1,4,4.0,0,0,[],[],[],1337,[],[],0
utilmy/zarchive/util.py:obj_getclass_of_method,obj_getclass_of_method,function,7,15,13,114,7.6,1,1,['meth'],[None],[None],1409,[],['inspect.getmro'],1
utilmy/zarchive/util.py:obj_getclass_property,obj_getclass_property,function,4,9,9,63,7.0,1,0,['pfi'],[None],[None],1417,[],"['vars', 'print']",2
utilmy/zarchive/util.py:print_topdf,print_topdf,function,27,114,95,912,8.0,0,0,[],[],[],1434,[],"['PdfPages', 'plt.figure', 'plt.plot', 'plt.title', 'pdf.savefig', 'plt.close', 'plt.rc', 'np.arange', 'np.sin', 'pdf.infodict', 'datetime.datetime']",11
utilmy/zarchive/util.py:os_config_setfile,os_config_setfile,function,9,39,26,229,5.87,1,1,"['dict_params', 'outfile', 'mode1']","[None, None, None]","[None, None, ""'w+'""]",1481,[],"['open', 'dict_params.items', 'isinstance', 'f1.write', 'str', 'f1.close', 'print']",7
utilmy/zarchive/util.py:os_config_getfile,os_config_getfile,function,7,16,15,73,4.56,1,0,['file1'],[None],[None],1493,[],"['open', 'f1.readlines', 'print']",3
utilmy/zarchive/util.py:os_csv_process,os_csv_process,function,1,2,2,9,4.5,0,0,['file1'],[None],[None],1501,[],['print'],1
utilmy/zarchive/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1527,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1527,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1527,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/util.py:str_match_fuzzy,str_match_fuzzy,function,4,12,11,64,5.33,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1687,"["" ''' if any of list_strinf elt matches partially xstring '''\n""]",['xstring.find'],1
utilmy/zarchive/util.py:str_parse_stringcalendar,str_parse_stringcalendar,function,14,39,29,278,7.13,3,1,['cal'],[None],[None],1694,"[""    '''----------Parse Calendar  --------'''\n""]","['cal.split', 'x.find', 'cal4.append', 'np.array', 'print']",5
utilmy/zarchive/util.py:str_make_unicode,str_make_unicode,function,7,16,13,102,6.38,0,1,"['input', 'errors']","[None, None]","[None, ""'replace'""]",1708,[],"['type', 'input.decode']",2
utilmy/zarchive/util.py:str_empty_string_array,str_empty_string_array,function,9,30,23,184,6.13,2,1,"['x', 'y']","[None, None]","[None, '1']",1714,[],"['range', 'str_empty_string_array_numpy', 'np.empty']",3
utilmy/zarchive/util.py:str_empty_string_array_numpy,str_empty_string_array_numpy,function,4,9,8,56,6.22,0,0,"['nx', 'ny']","[None, None]","[None, '1']",1718,[],['np.empty'],1
utilmy/zarchive/util.py:str_isfloat,str_isfloat,function,1,8,7,46,5.75,0,0,['value'],[None],[None],1723,[],['float'],1
utilmy/zarchive/util.py:str_is_azchar,str_is_azchar,function,1,8,7,42,5.25,0,0,['x'],[None],[None],1727,[],['float'],1
utilmy/zarchive/util.py:str_is_az09char,str_is_az09char,function,1,8,7,42,5.25,0,0,['x'],[None],[None],1731,[],['float'],1
utilmy/zarchive/util.py:str_reindent,str_reindent,function,1,3,3,28,9.33,0,0,"['s', 'numSpaces)', ""'\\n')numSpaces * ' ') + string.lstrip(line) for line in s]s"", ""'\\n')return sdelimiters"", 'string', 'maxsplit=0)', 'delimiters))regexPattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, ' #change indentation of multine strings', None, None, None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, None, None, None, '0):  #Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1735,"[""    '''\n"", '   if args:\n', ""       aux= name1+'.'+obj.__name__ +'('+ str(args) +')  \\n' + str(inspect.getdoc(obj))\n"", ""       aux= aux.replace('\\n', '\\n       ')\n"", '       aux= aux.rstrip()\n', ""       aux= aux + ' \\n'\n"", '       wi( aux)\n', ""    '''\n""]",['x.decode'],1
utilmy/zarchive/util.py:str_split2,str_split2,function,1,3,3,28,9.33,0,0,"['delimiters', 'string', 'maxsplit=0)', 'delimiters))regexPattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, '0):  #Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1749,[],['x.decode'],1
utilmy/zarchive/util.py:str_split_pattern,str_split_pattern,function,1,3,3,28,9.33,0,0,"['sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1754,[],['x.decode'],1
utilmy/zarchive/util.py:pd_str_isascii,pd_str_isascii,function,1,3,3,28,9.33,0,0,['x'],[None],[None],1762,[],['x.decode'],1
utilmy/zarchive/util.py:str_to_utf8,str_to_utf8,function,2,2,2,23,11.5,0,0,['x'],[None],[None],1768,"['  """""" Do it before saving/output to external printer """"""\n']",['x.encode'],1
utilmy/zarchive/util.py:str_to_unicode,str_to_unicode,function,3,14,11,78,5.57,0,2,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",1773,"[""  ''' Do it First after Loading some text '''\n""]","['isinstance', 'str']",2
utilmy/zarchive/util.py:np_minimize,np_minimize,function,12,41,37,379,9.24,1,0,"['fun_obj', 'x0', 'argext', '0']","[None, None, None, None]","[None, '[0.0]', '(0', None]",1846,[],"['penalty', 'enumerate', 'max', 'loss', 'fun_obj', 'np_minimizeDE']",6
utilmy/zarchive/util.py:np_minimizeDE,np_minimizeDE,function,16,51,41,418,8.2,1,2,"['fun_obj', 'bounds', 'name1', 'maxiter', 'popsize', 'solver']","[None, None, None, None, None, None]","[None, None, None, '10', '5', 'None']",1859,[],"['range', 'next', 'print', 'save', 'name1+date_now', 'np.mod', 'np.abs']",7
utilmy/zarchive/util.py:np_remove_NA_INF_2d,np_remove_NA_INF_2d,function,9,22,19,116,5.27,2,1,['X'],[None],[None],1876,[],"['np.shape', 'range', 'np.isnan', 'np.isinf']",4
utilmy/zarchive/util.py:np_addcolumn,np_addcolumn,function,8,11,11,86,7.82,0,0,"['arr', 'nbcol']","[None, None]","[None, None]",1883,[],"['np.shape', 'np.zeros', 'np.column_stack']",3
utilmy/zarchive/util.py:np_addrow,np_addrow,function,9,20,19,139,6.95,0,1,"['arr', 'nbrow']","[None, None]","[None, None]",1889,[],"['np.shape', 'len', 'np.zeros', 'np.row_stack', 'np.append']",5
utilmy/zarchive/util.py:np_int_tostr,np_int_tostr,function,3,17,12,69,4.06,0,1,['i'],[None],[None],1898,[],['str'],1
utilmy/zarchive/util.py:np_dictordered_create,np_dictordered_create,function,5,6,6,52,8.67,0,0,[],[],[],1904,[],['OrderedDict'],1
utilmy/zarchive/util.py:np_list_unique,np_list_unique,function,5,8,8,46,5.75,0,0,['seq'],[None],[None],1908,[],"['Set', 'list']",2
utilmy/zarchive/util.py:np_list_tofreqdict,np_list_tofreqdict,function,10,39,23,162,4.15,2,1,"['l1', 'wweight']","[None, None]","[None, '[]']",1914,[],"['dict', 'len', 'enumerate']",3
utilmy/zarchive/util.py:np_list_flatten,np_list_flatten,function,11,25,19,114,4.56,2,1,['seq'],[None],[None],1931,[],"['type', 'flatten', 'l.append']",3
utilmy/zarchive/util.py:np_dict_tolist,np_dict_tolist,function,5,22,15,100,4.55,2,1,"['dd', 'withkey']","[None, None]","[None, '0']",1942,[],['list'],1
utilmy/zarchive/util.py:np_dict_tostr_val,np_dict_tostr_val,function,1,9,9,52,5.78,0,0,['dd'],[None],[None],1948,[],"['str', 'list']",2
utilmy/zarchive/util.py:np_dict_tostr_key,np_dict_tostr_key,function,1,8,8,52,6.5,0,0,['dd'],[None],[None],1951,[],"['str', 'list']",2
utilmy/zarchive/util.py:np_removelist,np_removelist,function,6,15,15,71,4.73,1,1,"['x0', 'xremove']","[None, None]","[None, '[]']",1956,[],"['np_findfirst', 'xnew.append']",2
utilmy/zarchive/util.py:np_transform2d_int_1d,np_transform2d_int_1d,function,19,31,28,227,7.32,2,0,"['m2d', 'onlyhalf']","[None, None]","[None, 'False']",1962,[],"['np.shape', 'np.zeros', 'range', 'np.abs', 'np_sortbycol']",5
utilmy/zarchive/util.py:np_mergelist,np_mergelist,function,5,10,10,55,5.5,1,0,"['x0', 'x1']","[None, None]","[None, None]",1974,[],"['list', 'xnew.append']",2
utilmy/zarchive/util.py:np_enumerate2,np_enumerate2,function,6,14,14,83,5.93,1,0,['vec_1d'],[None],[None],1980,[],"['np.empty', 'enumerate']",2
utilmy/zarchive/util.py:np_pivottable_count,np_pivottable_count,function,12,24,23,170,7.08,1,0,['mylist'],[None],[None],1986,[],"['np_dict_tolist', 'sorted', 'int']",3
utilmy/zarchive/util.py:np_nan_helper,np_nan_helper,function,2,5,5,40,8.0,0,0,['y'],[None],[None],1994,"['    """""" Input:  - y, 1d numpy array with possible NaNs\n', '        Output - nans, logical indices of NaNs - index, a function, with signature indices= index(logical_indices),\n', ""              to convert logical indices of NaNs to 'equivalent' indices\n"", '    """"""\n']","['np.isnan', 'z.nonzero']",2
utilmy/zarchive/util.py:np_interpolate_nan,np_interpolate_nan,function,7,9,9,76,8.44,0,0,['y'],[None],[None],2001,[],"['np_nan_helper', 'np.interp', 'x']",3
utilmy/zarchive/util.py:np_and1,np_and1,function,8,55,22,356,6.47,0,6,"['x', 'y', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']","[None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None', 'None', 'None']",2006,[],[],0
utilmy/zarchive/util.py:np_sortcol,np_sortcol,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2014,"[' """""" df.sort([\'A\', \'B\'], ascending=[1, 0])  """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/util.py:np_sort,np_sort,function,7,19,12,184,9.68,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2020,[],"['pd.DataFrame', 'df.sort_values', 'np_sort']",3
utilmy/zarchive/util.py:np_ma,np_ma,function,2,3,3,45,15.0,0,0,"['vv', 'n']","[None, None]","[None, None]",2026,"[""  '''Moving average '''\n""]","['np.convolve', 'np.ones']",2
utilmy/zarchive/util.py:np_cleanmatrix,np_cleanmatrix,function,11,22,20,124,5.64,2,1,['m'],[None],[None],2032,[],"['np.nan_to_num', 'np.shape', 'range', 'abs']",4
utilmy/zarchive/util.py:np_torecarray,np_torecarray,function,2,6,6,105,17.5,0,0,"['arr', 'colname']","[None, None]","[None, None]",2040,[],['np.shape'],1
utilmy/zarchive/util.py:np_sortbycolumn,np_sortbycolumn,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",2043,[],"['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/util.py:np_sortbycol,np_sortbycol,function,8,30,20,257,8.57,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",2048,[],"['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/util.py:min_kpos,min_kpos,function,2,3,3,36,12.0,0,0,"['arr', 'kth']","[None, None]","[None, None]",2059,"[""   ''' return kth mininimun '''\n""]",['np.partition'],1
utilmy/zarchive/util.py:max_kpos,max_kpos,function,3,5,5,53,10.6,0,0,"['arr', 'kth']","[None, None]","[None, None]",2063,"[""   ''' return kth mininimun '''\n""]","['len', 'np.partition']",2
utilmy/zarchive/util.py:np_findfirst,np_findfirst,function,5,11,10,54,4.91,1,1,"['item', 'vec']","[None, None]","[None, None]",2070,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/util.py:np_find,np_find,function,5,11,10,54,4.91,1,1,"['item', 'vec']","[None, None]","[None, None]",2077,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/util.py:find,find,function,14,54,32,291,5.39,2,4,"['item', 'vec']","[None, None]","[None, None]",2084,"['    """"""return the index of the first occurence of item in vec""""""\n']","['range', 'findnone', 'findx', 'type', 'vec.index', 'len', 'finds']",7
utilmy/zarchive/util.py:findnone,findnone,function,4,11,10,54,4.91,1,1,['vec'],[None],[None],2090,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/util.py:findx,findx,function,6,27,18,119,4.41,0,2,"['item', 'vec']","[None, None]","[None, None]",2096,"['    """"""return the index of the first occurence of item in vec""""""\n']","['type', 'vec.index', 'len']",3
utilmy/zarchive/util.py:finds,finds,function,12,34,23,155,4.56,2,3,"['itemlist', 'vec']","[None, None]","[None, None]",2107,"['  """"""return the index of the first occurence of item in vec""""""\n']","['range', 'idlist.append']",2
utilmy/zarchive/util.py:findhigher,findhigher,function,5,13,12,50,3.85,1,1,"['x', 'vec']","[None, None]","[None, None]",2118,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/util.py:findlower,findlower,function,5,12,11,50,4.17,1,1,"['x', 'vec']","[None, None]","[None, None]",2124,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/util.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],2132,[],['min'],1
utilmy/zarchive/util.py:np_find_maxpos,np_find_maxpos,function,17,45,34,266,5.91,1,3,['values'],[None],[None],2136,[],"['max', 'np_find_maxpos_2nd', 'float', 'enumerate']",4
utilmy/zarchive/util.py:np_find_maxpos_2nd,np_find_maxpos_2nd,function,13,37,28,138,3.73,1,3,['numbers'],[None],[None],2140,[],"['float', 'enumerate']",2
utilmy/zarchive/util.py:np_findlocalmax2,np_findlocalmax2,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",2152,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/util.py:np_findlocalmin2,np_findlocalmin2,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",2186,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/util.py:np_findlocalmax,np_findlocalmax,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",2220,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/util.py:np_findlocalmin,np_findlocalmin,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",2234,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/util.py:np_stack,np_stack,function,12,53,25,323,6.09,0,7,"['v1', 'v2', 'v3', 'v4', 'v5']","[None, None, None, None, None]","[None, 'None', 'None', 'None', 'None']",2250,[],"['np.shape', 'np.row_stack', 'np.column_stack']",3
utilmy/zarchive/util.py:np_uniquerows,np_uniquerows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],2265,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/util.py:np_remove_zeros,np_remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",2270,[],[],0
utilmy/zarchive/util.py:np_sort,np_sort,function,7,19,12,184,9.68,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2273,"['    """"""\n', '    Creates a cross-tab or pivot table from a normalised input table. Use this\n', ""    function to 'denormalize' a table of normalized records.\n"", '\n', '    * The table argument can be a list of dictionaries or a Table object.\n', '    (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/334621)\n', '    * The left argument is a tuple of headings which are displayed down the\n', '    left side of the new table.\n', '    * The top argument is a tuple of headings which are displayed across the\n', '    top of the new table.\n', '    Tuples are used so that multiple element headings and columns can be used.\n', '\n', '    E.g. To transform the list (listOfDicts):\n', '\n', '    Name,   Year,  Value\n', '    -----------------------\n', ""    'Simon', 2004, 32\n"", ""    'Simon', 2005, 128\n"", ""    'Russel', 2004, 64\n"", ""    'Eric', 2004, 52\n"", ""    'Russel', 2005, 32\n"", '\n', '    into the new list:\n', '\n', ""    'Name',   2004, 2005\n"", '    ------------------------\n', ""    'Simon',  32,     128\n"", ""    'Russel',  64,     32\n"", ""    'Eric',   52,     NA\n"", '\n', '    you would call pivot with the arguments:\n', '\n', ""    newList = pivot(listOfDicts, ('Name',), ('Year',), 'Value')\n"", '\n', '    """"""\n']","['pd.DataFrame', 'df.sort_values', 'np_sort']",3
utilmy/zarchive/util.py:np_memory_array_adress,np_memory_array_adress,function,2,2,2,38,19.0,0,0,['x'],[None],[None],2276,[],[],0
utilmy/zarchive/util.py:np_pivotable_create,np_pivotable_create,function,28,99,61,699,7.06,4,5,"['table', 'left', 'top', 'value']","[None, None, None, None]","[None, None, None, None]",2283,"['    """"""\n', '    Creates a cross-tab or pivot table from a normalised input table. Use this\n', ""    function to 'denormalize' a table of normalized records.\n"", '\n', '    * The table argument can be a list of dictionaries or a Table object.\n', '    (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/334621)\n', '    * The left argument is a tuple of headings which are displayed down the\n', '    left side of the new table.\n', '    * The top argument is a tuple of headings which are displayed across the\n', '    top of the new table.\n', '    Tuples are used so that multiple element headings and columns can be used.\n', '\n', '    E.g. To transform the list (listOfDicts):\n', '\n', '    Name,   Year,  Value\n', '    -----------------------\n', ""    'Simon', 2004, 32\n"", ""    'Simon', 2005, 128\n"", ""    'Russel', 2004, 64\n"", ""    'Eric', 2004, 52\n"", ""    'Russel', 2005, 32\n"", '\n', '    into the new list:\n', '\n', ""    'Name',   2004, 2005\n"", '    ------------------------\n', ""    'Simon',  32,     128\n"", ""    'Russel',  64,     32\n"", ""    'Eric',   52,     NA\n"", '\n', '    you would call pivot with the arguments:\n', '\n', ""    newList = pivot(listOfDicts, ('Name',), ('Year',), 'Value')\n"", '\n', '    """"""\n']","['tuple', 'ysort.append', 'xsort.append', 'len', 'list', 'xsort.sort', 'headings.extend', 'sortedkeys.sort', 'row.extend', 't.append']",10
utilmy/zarchive/util.py:pd_info,pd_info,function,13,25,24,255,10.2,1,2,"['df', 'doreturn']","[None, None]","[None, '1']",2368,[],"['df.info', 'print', 'type', 'pd_info_memsize', 'pd_info', 'df.memory_usage']",6
utilmy/zarchive/util.py:pd_info_memsize,pd_info_memsize,function,5,6,6,84,14.0,0,1,"['df', 'memusage']","[None, None]","[None, '0']",2375,[],"['df.info', 'pd_info', 'df.memory_usage']",3
utilmy/zarchive/util.py:pd_row_findlast,pd_row_findlast,function,7,13,13,57,4.38,1,1,"['df', 'colid', 'emptyrowid']","[None, None, None]","[None, '0', 'None']",2382,[],['df.iterrows'],1
utilmy/zarchive/util.py:pd_row_select,pd_row_select,function,11,100,54,863,8.63,1,3,"['df', '**conditions']","[None, None]","[None, None]",2388,"[""    '''Select rows from a df according to conditions\n"", '    pdselect(data, a=2, b__lt=3) __gt __ge __lte  __in  __not_in\n', ""    will select all rows where 'a' is 2 and 'b' is less than 3\n"", ""    '''\n""]","['type', 'pd.DataFrame', 'list', 'c.endswith', 'np.in1d', 'ValueError']",6
utilmy/zarchive/util.py:pd_csv_randomread,pd_csv_randomread,function,11,41,37,266,6.49,0,1,"['filename', 'nsample', 'filemaxline', 'dtype']","[None, None, None, None]","[None, '10000', '-1', 'None']",2432,[],"['sum', 'open', 'np.sort', 'pd.read_csv']",4
utilmy/zarchive/util.py:pd_array_todataframe,pd_array_todataframe,function,14,46,33,313,6.8,0,2,"['array', 'colname', 'index1', 'dotranspose']","[None, None, None, None]","[None, 'None', 'None', 'False']",2442,[],"['np.shape', 'len', 'pd.DataFrame', 'np.array']",4
utilmy/zarchive/util.py:pd_dataframe_toarray,pd_dataframe_toarray,function,10,10,10,103,10.3,0,0,['df'],[None],[None],2452,[],['df.reset_index'],1
utilmy/zarchive/util.py:pd_createdf,pd_createdf,function,2,4,4,55,13.75,0,0,"['array1', 'col1', 'idx1']","[None, None, None]","[None, 'None', 'None']",2458,[],['pd.DataFrame'],1
utilmy/zarchive/util.py:pd_create_colmapdict_nametoint,pd_create_colmapdict_nametoint,function,9,12,12,77,6.42,1,0,['df'],[None],[None],2461,"[""  ''' 'close' ---> 5    '''\n""]",['enumerate'],1
utilmy/zarchive/util.py:pd_extract_col_idx_val,pd_extract_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],2471,[],[],0
utilmy/zarchive/util.py:pd_extract_col_uniquevalue_tocsv,pd_extract_col_uniquevalue_tocsv,function,5,10,9,101,10.1,0,0,"['df', 'colname', 'csvfile']","[None, None, None]","[None, ""''"", ""''""]",2475,"["" ''' Write one column into a file   '''\n""]","['np.array', 'pd.DataFrame', 'print']",3
utilmy/zarchive/util.py:pd_split_col_idx_val,pd_split_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],2484,[],[],0
utilmy/zarchive/util.py:pd_splitdf_inlist,pd_splitdf_inlist,function,15,34,26,254,7.47,3,2,"['df', 'colid', 'type1']","[None, None, None]","[None, None, '""dict""']",2487,"[""    ''' Split df into dictionnary of dict/list '''\n""]","['list', 'l1.append']",2
utilmy/zarchive/util.py:pd_find,pd_find,function,38,140,82,994,7.1,5,8,"['df', 'regex_pattern', 'col_restrict', 'isnumeric', 'doreturnposition']","[None, None, None, None, None]","[None, ""'*'"", '[]', 'False', 'False']",2502,"["" ''' Find string / numeric values inside df columns, return position where found\n"", ""     col_restrict : restrict to these columns '''\n""]","['str', 'print', 'enumerate', 'np.column_stack', 'len', 'gc.collect', 'np_dictordered_create', 'range', 'np.array']",9
utilmy/zarchive/util.py:pd_dtypes_totype2,pd_dtypes_totype2,function,6,9,9,58,6.44,1,0,"['df', 'columns', 'targetype']","[None, None, None]","[None, '[]', ""'category'""]",2548,[],[],0
utilmy/zarchive/util.py:pd_dtypes,pd_dtypes,function,7,12,11,91,7.58,1,0,"['df', 'columns', 'targetype']","[None, None, None]","[None, '[]', ""'category'""]",2553,[],['pd_dtypes'],1
utilmy/zarchive/util.py:pd_df_todict2,pd_df_todict2,function,16,31,27,247,7.97,1,2,"['df1', 'colkey', 'excludekey', 'onlyfirstelt']","[None, None, None, None]","[None, ""'table'"", ""['']"", ' True']",2568,[],"['df.drop_duplicates', 'range', 'len', 'dict0.setdefault']",4
utilmy/zarchive/util.py:pd_df_todict,pd_df_todict,function,17,35,31,306,8.74,1,2,"['df1', 'colkey', 'excludekey', 'onlyfirstelt']","[None, None, None, None]","[None, ""'table'"", ""['']"", ' True']",2581,[],"['df.drop_duplicates', 'range', 'len', 'dict0.setdefault', 'pd_df_todict']",5
utilmy/zarchive/util.py:pd_col_addfrom_dfmap,pd_col_addfrom_dfmap,function,12,44,34,229,5.2,0,1,"['df', 'dfmap', 'colkey', 'colval', 'df_colused', 'df_colnew', 'exceptval', 'inplace']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, '-1', ' True']",2594,"[""  ''' Add new columns based on df_map:  In Place Modification of df\n"", '    df:     Dataframe of transactions.\n', '    dfmap:  FSMaster Dataframe\n', '      colkey: colum used for dict key.  machine_code\n', '      colval: colum used for dict val.  adress\n', '      \n', '    df_colused  :     ""machine_code""\n', ""    exception val:  -1 or ''\n"", ""  '''\n""]","['pd_df_todict', 'map_dict_fun', 'df.apply']",3
utilmy/zarchive/util.py:pd_applyfun_col,pd_applyfun_col,function,5,11,9,107,9.73,0,1,"['df', 'newcol', 'ff', 'use_colname']","[None, None, None, None]","[None, None, None, '""all/[colname]""']",2652,"[""   ''' use all Columns to compute values '''\n""]",['ff'],1
utilmy/zarchive/util.py:pd_date_intersection,pd_date_intersection,function,7,18,15,157,8.72,1,0,['qlist'],[None],[None],2669,[],"['set', 'set.intersection', 'list', 'sorted']",4
utilmy/zarchive/util.py:pd_is_categorical,pd_is_categorical,function,2,12,10,108,9.0,0,1,['z'],[None],[None],2677,[],['isinstance'],1
utilmy/zarchive/util.py:pd_str_encoding_change,pd_str_encoding_change,function,6,8,8,76,9.5,1,0,"['df', 'cols', 'fromenc', 'toenc']","[None, None, None, None]","[None, None, ""'iso-8859-1'"", ""'utf-8'""]",2684,[],[],0
utilmy/zarchive/util.py:pd_str_unicode_tostr,pd_str_unicode_tostr,function,2,4,4,60,15.0,0,0,"['df', 'targetype']","[None, None]","[None, 'str']",2690,"["" '''\n"", ' https://www.azavea.com/blog/2014/03/24/solving-unicode-problems-in-python-2-7/\n', ' Nearly every Unicode problem can be solved by the proper application of these tools;\n', ' they will help you build an airlock to keep the inside of your code nice and clean:\n', '\n', 'encode(): Gets you from Unicode -> bytes\n', 'decode(): Gets you from bytes -> Unicode\n', 'codecs.open(encoding=utf-8): Read and write files directly to/from Unicode (you can use any encoding,\n', ' not just utf-8, but utf-8 is most common).\n', 'u: Makes your string literals into Unicode objects rather than byte sequences.\n', 'Warning: Dont use encode() on bytes or decode() on Unicode objects\n', '\n', '>>> uni_greeting % utf8_name\n', 'Traceback (most recent call last):\n', ' File ""<stdin>"", line 1, in <module>\n', ""UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 3: ordinal not in range(128)\n"", '# Solution:\n', "">>> uni_greeting % utf8_name.decode('utf-8')\n"", ""u'Hi, my name is Josxe9.'\n"", '\n', "" '''\n""]",['pd_dtypes_type1_totype2'],1
utilmy/zarchive/util.py:pd_dtypes_type1_totype2,pd_dtypes_type1_totype2,function,7,13,12,100,7.69,1,1,"['df', 'fromtype', 'targetype']","[None, None, None]","[None, 'str', 'str']",2714,[],['isinstance'],1
utilmy/zarchive/util.py:pd_resetindex,pd_resetindex,function,3,4,4,50,12.5,0,0,['df'],[None],[None],2723,[],['list'],1
utilmy/zarchive/util.py:pd_insertdatecol,pd_insertdatecol,function,8,11,11,192,17.45,0,0,"['df_insider', 'format1=""%Y-%m-%d %H']","[None, '']","[None, '""%Y-%m-%d %H:%M:%S:%f""']",2727,[],"['pd_addcol', 'date_nowtime']",2
utilmy/zarchive/util.py:pd_replacevalues,pd_replacevalues,function,11,14,14,101,7.21,1,0,"['df', 'matrix']","[None, None]","[None, None]",2733,"["" ''' Matrix replaces df.values  '''\n""]",['np.shape'],1
utilmy/zarchive/util.py:pd_removerow,pd_removerow,function,2,2,2,29,14.5,0,0,"['df', 'row_list_index', '45]']","[None, None, None]","[None, '[23', None]",2742,[],['df.drop'],1
utilmy/zarchive/util.py:pd_removecol,pd_removecol,function,2,3,3,28,9.33,0,0,"['df1', 'name1']","[None, None]","[None, None]",2745,[],['df1.drop'],1
utilmy/zarchive/util.py:pd_insertrow,pd_insertrow,function,6,10,10,102,10.2,0,0,"['df', 'rowval', 'index1', 'isreset']","[None, None, None, None]","[None, None, 'None', '1']",2749,[],"['pd_array_todataframe', 'df.append']",2
utilmy/zarchive/util.py:pd_h5_cleanbeforesave,pd_h5_cleanbeforesave,function,5,12,11,91,7.58,0,0,['df'],[None],[None],2757,"[""   '''Clean Column type before Saving in HDFS: Unicode, Datetime  '''\n""]","['pd_resetindex', 'pd_str_unicode_tostr']",2
utilmy/zarchive/util.py:pd_h5_addtable,pd_h5_addtable,function,5,18,17,148,8.22,0,1,"['df', 'tablename', ""dbfile='F""]","[None, None, '']","[None, None, ""'F:\\temp_pandas.h5'""]",2773,[],"['pd.HDFStore', 'find', 'list', 'print', 'store.append', 'store.close']",6
utilmy/zarchive/util.py:pd_h5_tableinfo,pd_h5_tableinfo,function,4,4,4,65,16.25,0,0,"['filenameh5', 'table']","[None, None]","[None, None]",2782,[],"['pd.HDFStore', 'store.get_storer']",2
utilmy/zarchive/util.py:pd_h5_dumpinfo,pd_h5_dumpinfo,function,12,23,23,304,13.22,1,0,"[""dbfile='E""]",[''],"[""'E:\\_data\\stock\\intraday_google.h5'""]",2787,[],"['pd.HDFStore', 'list', 'pd.read_hdf', 'extract.append', 'datetime_tostring', 'errsym.append', 'np.array']",7
utilmy/zarchive/util.py:pd_h5_save,pd_h5_save,function,3,6,6,64,10.67,0,0,"['df', ""filenameh5='E"", 'key']","[None, '', None]","[None, ""'E:/_data/_data_outlier.h5'"", ""'data'""]",2800,"["" ''' File is release after saving it'''\n""]","['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zarchive/util.py:pd_h5_load,pd_h5_load,function,4,22,16,185,8.41,0,2,"[""filenameh5='E"", 'table_id', 'exportype', 'rowstart', 'rowend', 'cols']","['', None, None, None, None, None]","[""'E:/_data/_data_outlier.h5'"", ""'data'"", '""pandas""', '-1', '-1', '[]']",2805,[],['pd.read_hdf'],1
utilmy/zarchive/util.py:pd_h5_fromcsv_tohdfs,pd_h5_fromcsv_tohdfs,function,30,78,65,670,8.59,3,2,"['dircsv', 'filepattern', 'tofilehdfs', 'tablename', 'col_category', 'dtype0', 'encoding', 'chunksize', 'mode', 'format', 'complib']","[None, None, None, None, None, None, None, None, None, None, None]","[""'dir1/dir2/'"", ""'*.csv'"", ""'file1.h5'"", ""'df'"", '[]', 'None', ""'utf-8'"", ' 2000000', ""'a'"", ""'table'"", 'None']",2811,[],"['os_file_listall', 'pd.HDFStore', 'enumerate', 'pd.read_csv', 'print', 'store.append', 'store.close', 'os_file_exist']",8
utilmy/zarchive/util.py:pd_np_toh5file,pd_np_toh5file,function,2,8,8,76,9.5,0,0,"['numpyarr', 'fileout', 'table1']","[None, None, None]","[None, '""file.h5""', ""'data'""]",2848,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zarchive/util.py:date_allinfo,date_allinfo,function,0,0,0,0,0.0,0,0,[],[],[],2856,"[""   '''\n"", '\n', '   https://aboutsimon.com/blog/2016/08/04/datetime-vs-Arrow-vs-Pendulum-vs-Delorean-vs-udatetime.html\n', '\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/util.py:date_convert,date_convert,function,14,53,37,303,5.72,1,1,"['t1', 'fromtype', 'totype']","[None, None, None]","[None, None, None]",2865,[],"['len', 'isinstance', '_dateconvert_from', 'tlist.append']",4
utilmy/zarchive/util.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],2889,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/util.py:date_remove_bdays,date_remove_bdays,function,16,41,28,351,8.56,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2899,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/util.py:date_add_bdays,date_add_bdays,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2913,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/util.py:datenumpy_todatetime,datenumpy_todatetime,function,11,36,22,384,10.67,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",2927,[],['type'],1
utilmy/zarchive/util.py:datetime_tonumpydate,datetime_tonumpydate,function,2,2,2,22,11.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",2943,[],['np.datetime64'],1
utilmy/zarchive/util.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",2947,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/util.py:datetime_toint,datetime_toint,function,6,15,13,155,10.33,1,1,['datelist1'],[None],[None],2955,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/util.py:date_holiday,date_holiday,function,0,0,0,0,0.0,0,0,[],[],[],2962,"[""   '''\n"", '   https://jakevdp.github.io/blog/2015/07/23/learning-seattles-work-habits-from-bicycle-counts/\n', '\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'cal = USFederalHolidayCalendar()\n', ""holidays = cal.holidays('2012', '2016', return_name=True)\n"", 'holidays.head()\n', '\n', 'holidays_all = pd.concat([holidays, ""Day Before "" + holidays.shift(-1, \'D\'),  ""Day After "" + holidays.shift(1, \'D\')])\n', 'holidays_all = holidays_all.sort_index()\n', 'holidays_all.head()\n', '\n', 'from pandas.tseries.offsets import CustomBusinessDay\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'bday_us = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n', 'dateref[-1] - bday_us- bday_us\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/util.py:date_add_bday,date_add_bday,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2982,"["" ''' str / stamp /  '''\n""]","['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/util.py:dateint_todatetime,dateint_todatetime,function,6,15,13,135,9.0,1,1,['datelist1'],[None],[None],2995,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/util.py:date_diffinday,date_diffinday,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",3003,[],['dateint_todatetime'],1
utilmy/zarchive/util.py:date_diffinyear,date_diffinyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",3007,[],['date_as_float'],1
utilmy/zarchive/util.py:date_diffinbday,date_diffinbday,function,7,11,9,112,10.18,0,0,"['intd2', 'intd1']","[None, None]","[None, None]",3010,[],"['dateint_todatetime', 'd1.date', 'd2.date', 'np.busday_count']",4
utilmy/zarchive/util.py:date_gencalendar,date_gencalendar,function,9,13,11,233,17.92,0,0,"['start', 'end', 'country']","[None, None, None]","[""'2010-01-01'"", ""'2010-01-15'"", ""'us'""]",3018,[],"['CustomBusinessDay', 'np.arrray']",2
utilmy/zarchive/util.py:date_finddateid,date_finddateid,function,5,75,20,437,5.83,0,10,"['date1', 'dateref']","[None, None]","[None, None]",3024,[],['np_findfirst'],1
utilmy/zarchive/util.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],3038,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/util.py:date_now,date_now,function,15,45,31,396,8.8,0,2,['i'],[None],['0'],3044,[],"['datetime.now', 'date_add_bdays', 'date_remove_bdays', 'str', 'date_nowtime', 'datetime.today', 'd.strftime']",7
utilmy/zarchive/util.py:date_nowtime,date_nowtime,function,8,23,18,205,8.91,0,1,"['type1', 'format1= ""%Y-%m-%d %H']","[None, '']","[""'str'"", ' ""%Y-%m-%d %H:%M:%S:%f""']",3051,"["" ''' str / stamp /  '''\n""]","['datetime.today', 'd.strftime']",2
utilmy/zarchive/util.py:date_tofloat,date_tofloat,function,11,28,23,273,9.75,0,1,['dt'],[None],[None],3060,[],"['datetime.datetime', 'isleap', 'timedelta']",3
utilmy/zarchive/util.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",3068,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/util.py:np_numexpr_vec_calc,np_numexpr_vec_calc,function,13,28,22,214,7.64,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",3081,"["" ''' New= xx*xx  over very large series\n"", ' #numexpr_vect_calc(filename, 0, imax=16384*4096, ""xx*xx"", \'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5\'  ):\n', ""'''\n""]","['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/util.py:np_numexpr_tohdfs,np_numexpr_tohdfs,function,10,28,22,248,8.86,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",3095,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/util.py:np_comoment,np_comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",3111,[],['ne.evaluate'],1
utilmy/zarchive/util.py:np_acf,np_acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],3117,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/util.py:plot_XY,plot_XY,function,25,83,60,688,8.29,0,3,"['xx', 'yy', 'zcolor', 'tsize', 'title1', 'xlabel', 'ylabel', 'figsize', '6']","[None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', ""''"", ""''"", ""''"", '(8', None]",3133,[],"['isinstance', 'np.array', 'np.abs', 'plt.get_cmap', 'np.min', 'plt.subplots', 'fig.set_size_inches', 'fig.set_dpi', 'fig.tight_layout', 'ax1.scatter', 'ax1.set_xlabel', 'ax1.set_ylabel', 'ax1.set_title', 'ax1.grid', 'plt.savefig', 'plt.clf', 'plt.show']",17
utilmy/zarchive/util.py:plot_heatmap,plot_heatmap,function,15,26,25,364,14.0,0,1,"['frame', 'ax', 'cmap', 'vmin', 'vmax', 'interpolation']","[None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', ""'nearest'""]",3173,[],"['plt.gca', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_yticks', 'ax.set_yticklabels', 'ax.grid', 'ax.set_aspect', 'ax.imshow']",8
utilmy/zarchive/util.py:np_map_dict_to_bq_schema,np_map_dict_to_bq_schema,function,13,59,31,720,12.2,3,3,"['source_dict', 'schema', 'dest_dict']","[None, None, None]","[None, None, None]",3190,"[""    '''\n"", '     new_dict = {}\n', '     map_dict_to_bq_schema (my_dict, schema, new_dict)\n', '\n', '     new_dict = {}\n', '     map_dict_to_bq_schema (my_dict, schema, new_dict)\n', '\n', '    :param source_dict:\n', '    :param schema:\n', '    :param dest_dict:\n', '    :return:\n', ""    '''\n""]","['np_map_dict_to_bq_schema', 'format_value_bq']",2
utilmy/zarchive/util.py:googledrive_get,googledrive_get,function,0,1,1,4,4.0,0,0,[],[],[],3235,"[""   '''\n"", '   https://github.com/ctberthiaume/gdcp\n', '   ... I am using this now to transfer thousands of mp3 files from a ubuntu vps to google drive.\n', '\n', '\n', 'http://olivermarshall.net/how-to-upload-a-file-to-google-drive-from-the-command-line/\n', 'https://github.com/prasmussen/gdrive  : Super Complete\n', '\n', 'gdrive [global] upload [options] <path>\n', '\n', 'global:\n', '  -c, --config <configDir>         Application path, default: /Users/<user>/.gdrive\n', '  --refresh-token <refreshToken>   Oauth refresh token used to get access token (for advanced users)\n', '  --access-token <accessToken>     Oauth access token, only recommended for short-lived requests because of short lifetime (for advanced users)\n', '\n', 'options:\n', '  -r, --recursive           Upload directory recursively\n', '  -p, --parent <parent>     Parent id, used to upload file to a specific directory, can be specified multiple times to give many parents\n', '  --name <name>             Filename\n', '  --no-progress             Hide progress\n', '  --mime <mime>             Force mime type\n', '  --share                   Share file\n', '  --delete                  Delete local file when upload is successful\n', '  --chunksize <chunksize>   Set chunk size in bytes, default: 8388608\n', '\n', '   :return:\n', ""   '''\n""]",[],0
utilmy/zarchive/util.py:googledrive_put,googledrive_put,function,0,1,1,4,4.0,0,0,[],[],[],3265,"[""  '''\n"", '  100 GB: 2USD,  1TB: 10USD\n', '  https://gsuite.google.com/intl/en/pricing.html\n', '\n', '  :return:\n', ""  '''\n""]",[],0
utilmy/zarchive/util.py:googledrive_list,googledrive_list,function,0,1,1,4,4.0,0,0,[],[],[],3275,[],[],0
utilmy/zarchive/util.py:os_processify_fun,os_processify_fun,function,32,78,63,713,9.14,0,1,['func'],[None],[None],3280,"[""    '''Decorator to run a function as a process.\n"", '    Be sure that every argument and the return value is *pickable*.\n', '    The created process is joined, so the code does not  run in parallel.\n', '    @processify\n', '\n', '    def test():\n', '      return os.getpid()\n', '\n', '    @processify\n', '    def test_deadlock():\n', '      return range(30000)\n', '\n', '   @processify\n', '   def test_exception():\n', ""     raise RuntimeError('xyz')\n"", '\n', '   def test():\n', '     print os.getpid()\n', '     print test_function()\n', '     print len(test_deadlock())\n', '     test_exception()\n', '\n', ""   if __name__ == '__main__':\n"", '     test()\n', '\n', ""    '''\n""]","['process_func', 'func', 'sys.exc_info', 'q.put', 'setattr', 'wrapper', 'Queue', 'Process', 'list', 'p.start', 'q.get', 'ex_type']",12
utilmy/zarchive/util.py:ztest_processify,ztest_processify,function,2,2,2,17,8.5,0,0,[],[],[],3347,[],['os.getpid'],1
utilmy/zarchive/util.py:date_getspecificdate,date_getspecificdate,function,21,194,56,1312,6.76,8,19,"['datelist', 'datetype1', 'outputype1', 'includelastdate', 'includefirstdate', '']","[None, None, None, None, None, None]","[None, '""yearend""', '""intdate""', 'True', 'False', None]",3353,[],"['isint', 'dateint_todatetime', 'enumerate', 'vec2.append', 'np.mod', 'np.array']",6
utilmy/zarchive/util.py:py_exception_print,py_exception_print,function,16,27,26,281,10.41,0,0,[],[],[],3413,[],"['sys.exc_info', 'linecache.checkcache', 'linecache.getline', 'print', 'line.strip']",5
utilmy/zarchive/util.py:py_log_write,py_log_write,function,13,29,26,365,12.59,0,0,"['LOGFILE', 'prefix']","[None, None]","[None, None]",3424,[],"['print', 'arrow.utcnow', 'str', 'open']",4
utilmy/zarchive/util.py:testclass,testclass,class,21,51,42,434,8.51,0,3,[],[],[],148,[],[],0
utilmy/zarchive/util.py:FundingRecord,FundingRecord,class,14,59,48,394,6.68,0,0,[],[],[],1582,[],[],0
utilmy/zarchive/util.py:testclass:__init__,testclass:__init__,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",149,[],[],0
utilmy/zarchive/util.py:testclass:z_autotest,testclass:z_autotest,method,19,44,38,387,8.8,0,3,['self'],[None],[None],152,[],"['io.StringIO', 'f', 'self.redirect_internalshell_stdio', 'getopenfilename', '_', 'getcwd', 'self.close']",7
utilmy/zarchive/util.py:FundingRecord:parse,FundingRecord:parse,method,7,35,26,223,6.37,0,0,"['klass', 'row']","[None, None]","[None, None]",1585,[],"['list', 'int', 'datetime.strptime', 'klass']",4
utilmy/zarchive/util.py:FundingRecord:__str__,FundingRecord:__str__,method,6,18,18,118,6.56,0,0,['self'],[None],[None],1592,[],[],0
utilmy/zarchive/utilgeo.py:df_to_geojson,df_to_geojson,function,10,24,21,329,13.71,2,0,"['df', 'col_properties', 'lat', 'lon']","[None, None, None, None]","[None, None, ""'latitude'"", ""'longitude'""]",24,[],['df.iterrows'],1
utilmy/zarchive/util_aws.py:aws_credentials,aws_credentials,function,3,7,7,126,18.0,0,0,['account'],[None],['None'],41,"['    """"""\n', '    Return a tuple of AWS credentials (access key id and secret access key) for\n', '    the given account.\n', '    """"""\n']",['INIConfig'],1
utilmy/zarchive/util_aws.py:aws_ec2_get_instanceid,aws_ec2_get_instanceid,function,4,7,6,110,15.71,0,1,"['con', 'ip_address']","[None, None]","[None, None]",283,[],['con.get_all_instances'],1
utilmy/zarchive/util_aws.py:aws_ec2_allocate_elastic_ip,aws_ec2_allocate_elastic_ip,function,7,31,23,358,11.55,0,1,"['con', 'instance_id', 'elastic_ip', 'region']","[None, None, None, None]","[None, '""""', ""''"", '""ap-northeast-2""']",288,[],"['con.allocate_address', 'con.associate_address']",2
utilmy/zarchive/util_aws.py:aws_ec2_printinfo,aws_ec2_printinfo,function,5,17,12,93,5.47,0,3,"['instance', 'ipadress', 'instance_id']","[None, None, None]","['None', '""""', '""""']",300,"[""   '''   Idenfiy instnance of\n"", '   :param instance: \n', '     ipadress\n', '   :param instance_id: \n', '   :return: return info on the instance : ip, ip_adress,  \n', ""   '''\n""]","['print', 'pprint']",2
utilmy/zarchive/util_aws.py:aws_ec2_spot_start,aws_ec2_spot_start,function,26,96,89,1014,10.56,1,1,"['con', 'region', 'key_name', 'inst_type', 'ami_id', 'pricemax', 'elastic_ip', 'pars= {""security_group""', '""disk_size""', '""disk_type""', '""volume_type""']","[None, None, None, None, None, None, None, '', ' 25', ' ""ssd""', ' ""gp2""}']","[None, None, '""ecsInstanceRole""', '""cx2.2""', '""""', '0.15', ""''"", ' {""security_group"": [""""]', None, None, None]",320,"[""    '''\n"", '   :param con:   Connector to Boto\n', '   :param region: AWS region (us-east-1,..) \n', '   :param key_name: AWS  SSH Key Name  (in EC2 webspage )\n', '   :param security_group: AWS security group id\n', '   :param inst_type:  AWS EC2 instance type (t1.micro, m1.small ...)\n', '   :param ami_id:  AWS AMI ID\n', '   :param pars: Disk Size, Volume type (General Purpose SSD - gp2, Magnetic etc)\n', '   :param pricemax: minmum spot instance bid price\n', ""    '''\n""]","['dict2', 'BlockDeviceMapping', 'EBSBlockDeviceType', 'int', 'print', 'con.request_spot_instances', 'con.get_all_spot_instance_requests', 'con.get_all_instances', 'aws_ec2_allocate_elastic_ip', 'aws_ec2_printinfo', 'sleep']",11
utilmy/zarchive/util_aws.py:aws_ec2_get_id,aws_ec2_get_id,function,4,11,9,69,6.27,0,2,"['ipadress', 'instance_id']","[None, None]","[""''"", ""''""]",368,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_spot_stop,aws_ec2_spot_stop,function,5,39,33,281,7.21,0,1,"['con', 'ipadress', 'instance_id']","[None, None, None]","[None, '""""', '""""']",379,"[""   '''\n"", '   :param con: connector \n', '   :param ipadress:   of the instance  to Identify the instance.\n', '   :param instance_id:  OR use instance ID....\n', '   :return: \n', ""   '''\n""]","['aws_ec2_get_instanceid', 'str', 'con.terminate_instances']",3
utilmy/zarchive/util_aws.py:aws_ec2_res_start,aws_ec2_res_start,function,26,97,90,972,10.02,1,1,"['con', 'region', 'key_name', 'ami_id', 'inst_type', 'min_count ', 'max_count ', 'pars= {""security_group""', '""disk_size""', '""disk_type""', '""volume_type""']","[None, None, None, None, None, None, None, '', ' 25', ' ""ssd""', ' ""gp2""}']","[None, None, None, None, '""cx2.2""', '1', '1', ' {""security_group"": [""""]', None, None, None]",405,"[""    '''  \n"", '        normal instance start\n', '        :param con:   Connector to Boto\n', '        :param region: AWS region (us-east-1,..) \n', '        :param key_name: AWS  SSH Key Name\n', '        :param security_group: AWS security group id\n', '        :param inst_type:  AWS EC2 instance type (t1.micro, m1.small ...)\n', '        :param ami_id:  AWS AMI ID\n', '        :param min_count: Minumum number of instances\n', '        :param max_count : Maximum number of instances\n', '        :param pars: Disk Size, Volume type (General Purpose SSD - gp2, Magnetic etc)\n', '        :return \n', ""    '''\n""]","['dict2', 'BlockDeviceMapping', 'EBSBlockDeviceType', 'int', 'print', 'con.run_instances', 'con.get_all_instances', 'aws_ec2_printinfo', 'sleep']",9
utilmy/zarchive/util_aws.py:aws_ec2_res_stop,aws_ec2_res_stop,function,7,44,37,309,7.02,0,1,"['con', 'ipadress', 'instance_id']","[None, None, None]","[None, '""""', '""""']",450,"[""   '''\n"", '   :param con: connector \n', '   :param ipadress:     Of the instance  to Identify the instance.\n', '   :param instance_id:  OR use instance ID....\n', '   :return: \n', ""   '''\n""]","['aws_ec2_get_instanceid', 'con.stop_instances', 'str']",3
utilmy/zarchive/util_aws.py:aws_accesskey_get,aws_accesskey_get,function,6,19,16,193,10.16,0,1,"['access', 'key']","[None, None]","[""''"", ""''""]",483,[],['print'],1
utilmy/zarchive/util_aws.py:aws_conn_do,aws_conn_do,function,2,3,3,39,13.0,0,0,"['action', 'region']","[None, None]","[""''"", '""ap-northeast-2""']",492,[],['aws_conn_create'],1
utilmy/zarchive/util_aws.py:aws_conn_getallregions,aws_conn_getallregions,function,2,2,2,28,14.0,0,0,['conn'],[None],['None'],497,[],['conn.get_all_regions'],1
utilmy/zarchive/util_aws.py:aws_conn_create,aws_conn_create,function,21,36,34,282,7.83,1,2,"['region', 'access', 'key']","[None, None, None]","['""ap-northeast-2""', ""''"", ""''""]",500,[],"['aws_accesskey_get', 'EC2Connection', 'aws_conn_getallregions', 'conn=EC2Connection', 'print']",5
utilmy/zarchive/util_aws.py:aws_conn_getinfo,aws_conn_getinfo,function,1,2,2,23,11.5,0,0,['conn'],[None],[None],513,[],['print'],1
utilmy/zarchive/util_aws.py:aws_s3_url_split,aws_s3_url_split,function,4,5,5,52,10.4,0,0,['url'],[None],[None],543,"[""  '''Split into Bucket, url '''\n""]",['url.split'],1
utilmy/zarchive/util_aws.py:aws_s3_getbucketconn,aws_s3_getbucketconn,function,13,17,16,221,13.0,0,0,['s3dir'],[None],[None],548,[],"['aws_s3_url_split', 'aws_accesskey_get', 'boto.connect_s3', 'conn.get_bucket']",4
utilmy/zarchive/util_aws.py:aws_s3_puto_s3,aws_s3_puto_s3,function,35,114,102,1162,10.19,3,2,"['fromdir_file', 'todir']","[None, None]","[""'dir/file.zip'"", ""'bucket/folder1/folder2'""]",556,"["" ''' Copy File or Folder to S3 '''\n""]","['aws_s3_getbucketconn', 'aws_s3_url_split', 'fromdir_file.find', 'util.os_file_getname', 'os.walk', 'uploadFileNames.extend', 'percent_cb', 'print', 'bucket.initiate_multipart_upload', 'open', 'mp.upload_part_from_file', 'mp.complete_upload', 'k.set_contents_from_filename']",13
utilmy/zarchive/util_aws.py:aws_s3_getfrom_s3,aws_s3_getfrom_s3,function,21,44,44,435,9.89,1,1,"['froms3dir', 'todir', 'bucket_name']","[None, None, None]","[""'task01/'"", ""''"", ""'zdisk'""]",600,"["" ''' Get from S3 file/folder  '''\n""]","['aws_s3_url_split', 'aws_s3_getbucketconn', 'bucket.list', 'str', 'util.os_file_getname', 'util.os_file_getpath', 'os.makedirs', 'l.get_contents_to_filename']",8
utilmy/zarchive/util_aws.py:aws_s3_folder_printtall,aws_s3_folder_printtall,function,12,19,18,234,12.32,1,0,['bucket_name'],[None],"[""'zdisk'""]",620,[],"['aws_accesskey_get', 'boto.connect_s3', 'conn.create_bucket', 'bucket.list']",4
utilmy/zarchive/util_aws.py:aws_s3_file_read,aws_s3_file_read,function,10,14,13,186,13.29,0,0,"['bucket1', 'filepath', 'isbinary']","[None, None, None]","[None, None, '1']",630,"[""  ''' s3_client = boto3.client('s3')\n"", '    #Download private key file from secure S3 bucket\n', ""  s3_client.download_file('s3-key-bucket','keys/keyname.pem', '/tmp/keyname.pem')\n"", ""  '''\n""]","['S3Connection', 'conn.get_object']",2
utilmy/zarchive/util_aws.py:aws_ec2_cmd_ssh,aws_ec2_cmd_ssh,function,23,82,72,560,6.83,1,4,"['cmdlist', 'host', 'doreturn', 'ssh', 'username', 'keyfilepath']","[None, None, None, None, None, None]","['  [""ls "" ]', ""'ip'"", '0', 'None', ""'ubuntu'"", ""''""]",642,"[""    ''' SSH Linux terminal Command\n"", '     https://www.siteground.com/tutorials/ssh/ssh_deleting.htm\n', '\n', '     rm -rf foldername/\n', '\n', '\n', '    fuser 8888/tcp     Check if Jupyter is running\n', '    ps -ef | grep python     :List of  PID Python process\n', '    kill -9 PID_number     (i.e. the pid returned)\n', '    top     : CPU usage\n', '\n', '      Run nohup python bgservice.py & to get the script to ignore the hangup signal and keep running.\n', '      Output will be put in nohup.out.\n', '        ""aws s3 cp s3://s3-bucket/scripts/HelloWorld.sh /home/ec2-user/HelloWorld.sh"",\n', '        ""chmod 700 /home/ec2-user/HelloWorld.sh"",\n', '        ""/home/ec2-user/HelloWorld.sh""\n', '\n', '    https://aws.amazon.com/blogs/compute/scheduling-ssh-jobs-using-aws-lambda/\n', ""   '''\n""]","['len', 'aws_ec2_create_con', 'print', 'isinstance', 'ssh.exec_command', 'stdout.read', 'stderr.read', 'readall.append', 'ssh.close']",9
utilmy/zarchive/util_aws.py:aws_ec2_python_script,aws_ec2_python_script,function,5,20,18,195,9.75,0,0,"['script_path', 'args1', 'host']","[None, None, None]","[None, None, None]",682,[],['aws_ec2_cmd_ssh'],1
utilmy/zarchive/util_aws.py:aws_ec2_create_con,aws_ec2_create_con,function,36,121,93,1016,8.4,1,9,"['contype', 'host', 'port', 'username', 'keyfilepath', 'password', 'keyfiletype', 'isprint']","[None, None, None, None, None, None, None, None]","[""'sftp/ssh'"", ""'ip'"", '22', ""'ubuntu'"", ""''"", ""''"", ""'RSA'"", '1']",687,"['    """""" Transfert File  host = \'52.79.79.1\'\n', ""        keyfilepath = 'D:/_devs/aws/keypairs/ec2_instanc'\n"", '\n', '# List files in the default directory on the remote computer.\n', ""dirlist = sftp.listdir('.')\n"", ""sftp.get('remote_file.txt', 'downloaded_file.txt')\n"", ""sftp.put('testfile.txt', 'remote_testfile.txt')\n"", '\n', 'http://docs.paramiko.org/en/2.1/api/sftp.html\n', '    """"""\n']","['paramiko.Transport', 'transport.add_server_key', 'transport.connect', 'print', 'sftp.listdir', 'paramiko.SSHClient', 'ssh.set_missing_host_key_policy', 'ssh.connect', 'ssh.exec_command', 'stdin.flush', 'stdout.read', 'sftp.close', 'transport.close', 'ssh.close']",14
utilmy/zarchive/util_aws.py:ztest_01,ztest_01,function,0,1,1,4,4.0,0,0,[],[],[],1069,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh,aws_ec2_ssh,class,132,332,236,4141,12.47,9,10,[],[],[],54,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh:__init__,aws_ec2_ssh:__init__,method,24,61,49,779,12.77,0,4,"['self', 'hostname', 'username', 'key_file', 'password']","[None, None, None, None, None]","[None, None, ""'ubuntu'"", 'None', 'None']",70,[],"['socket.socket', 'paramiko.Transport', 'isinstance', 'key_file=open', 'key_file.seek', 'Exception', 'print']",7
utilmy/zarchive/util_aws.py:aws_ec2_ssh:command,aws_ec2_ssh:command,method,12,19,17,242,12.74,1,0,"['self', 'cmd']","[None, None]","[None, None]",111,[],"['chan.get_pty', 'chan.invoke_shell', 'chan.settimeout', 'chan.send', 'cmd.split']",5
utilmy/zarchive/util_aws.py:aws_ec2_ssh:put,aws_ec2_ssh:put,method,17,33,29,648,19.64,2,2,"['self', 'localfile', 'remotefile']","[None, None, None]","[None, None, None]",131,[],"['put_all', 'os.chdir', 'os.walk', 'print', 'self.put']",5
utilmy/zarchive/util_aws.py:aws_ec2_ssh:put_all,aws_ec2_ssh:put_all,method,15,30,26,573,19.1,2,2,"['self', 'localpath', 'remotepath']","[None, None, None]","[None, None, None]",135,[],"['os.chdir', 'os.walk', 'print', 'self.put']",4
utilmy/zarchive/util_aws.py:aws_ec2_ssh:get,aws_ec2_ssh:get,method,1,1,1,35,35.0,0,0,"['self', 'remotefile', 'localfile']","[None, None, None]","[None, None, None]",151,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh:sftp_walk,aws_ec2_ssh:sftp_walk,method,18,31,25,347,11.19,3,1,"['self', 'remotepath']","[None, None]","[None, None]",155,[],"['S_ISDIR', 'folders.append', 'files.append', 'self.sftp_walk']",4
utilmy/zarchive/util_aws.py:aws_ec2_ssh:get_all,aws_ec2_ssh:get_all,method,15,38,30,599,15.76,2,2,"['self', 'remotepath', 'localpath']","[None, None, None]","[None, None, None]",175,[],"['os.mkdir', 'self.sftp_walk', 'print', 'self.get']",4
utilmy/zarchive/util_aws.py:aws_ec2_ssh:write_command,aws_ec2_ssh:write_command,method,2,2,2,74,37.0,0,0,"['self', 'text', 'remotefile']","[None, None, None]","[None, None, None]",199,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh:python_script,aws_ec2_ssh:python_script,method,5,12,10,119,9.92,0,0,"['self', 'script_path', 'args1']","[None, None, None]","[None, None, None]",206,[],['self.cmd2'],1
utilmy/zarchive/util_aws.py:aws_ec2_ssh:command_list,aws_ec2_ssh:command_list,method,5,13,13,119,9.15,1,0,"['self', 'cmdlist']","[None, None]","[None, None]",212,[],"['print', 'self.command']",2
utilmy/zarchive/util_aws.py:aws_ec2_ssh:listdir,aws_ec2_ssh:listdir,method,2,2,2,34,17.0,0,0,"['self', 'remotedir']","[None, None]","[None, None]",219,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh:jupyter_kill,aws_ec2_ssh:jupyter_kill,method,3,10,10,136,13.6,0,0,['self'],[None],[None],222,[],['aws_ec2_cmd_ssh'],1
utilmy/zarchive/util_aws.py:aws_ec2_ssh:jupyter_start,aws_ec2_ssh:jupyter_start,method,0,1,1,4,4.0,0,0,['self'],[None],[None],226,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh:cmd2,aws_ec2_ssh:cmd2,method,2,5,5,63,12.6,0,0,"['self', 'cmd1']","[None, None]","[None, None]",229,[],['aws_ec2_cmd_ssh'],1
utilmy/zarchive/util_aws.py:aws_ec2_ssh:_help_ssh,aws_ec2_ssh:_help_ssh,method,18,29,29,132,4.55,0,1,['self'],[None],[None],232,[],[],0
utilmy/zarchive/util_min.py:os_wait_cpu,os_wait_cpu,function,12,31,27,286,9.23,1,0,"['priority', 'cpu_min']","[None, None]","['300', '50']",23,[],"['psutil.cpu_percent', 'print', 'arrow.utcnow', 'sleep']",4
utilmy/zarchive/util_min.py:isexist,isexist,function,3,11,10,58,5.27,0,0,['a'],[None],[None],48,[],['print'],1
utilmy/zarchive/util_min.py:isfloat,isfloat,function,5,15,13,67,4.47,0,1,['x'],[None],[None],54,[],['float'],1
utilmy/zarchive/util_min.py:isint,isint,function,6,14,13,80,5.71,0,1,"['x)', '( int', 'np.int8', 'np.int16', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, None, None, '']","[None, None, None, None, None, None, None]",61,[],['txt.find'],1
utilmy/zarchive/util_min.py:a_isanaconda,a_isanaconda,function,6,14,13,80,5.71,0,1,[],[],[],63,[],['txt.find'],1
utilmy/zarchive/util_min.py:os_zip_checkintegrity,os_zip_checkintegrity,function,9,33,31,185,5.61,0,1,['filezip1'],[None],[None],72,[],"['zipfile.ZipFile', 'zip_file.testzip', 'print']",3
utilmy/zarchive/util_min.py:os_zipfile,os_zipfile,function,23,43,37,397,9.23,2,2,"['folderin', 'folderzipname', 'iscompress']","[None, None, None]","[None, None, 'True']",83,[],"['zipfile.ZipFile', 'os.walk', 'zf.write', 'zf.close', 'os_zip_checkintegrity', 'print']",6
utilmy/zarchive/util_min.py:os_zipfolder,os_zipfolder,function,15,35,29,346,9.89,0,3,"['dir_tozip', 'zipname', 'dir_prefix', 'iscompress']","[None, None, None, None]","[""'/zdisks3/output'"", ""'/zdisk3/output.zip'"", 'None', 'True']",99,"["" '''\n"", "" shutil.make_archive('/zdisks3/results/output', 'zip',\n"", ""                     root_dir=/zdisks3/results/',\n"", ""                     base_dir='output')\n"", '\n', "" os_zipfolder('zdisk/test/aapackage', 'zdisk/test/aapackage.zip', 'zdisk/test')'''\n""]","['dir_tozip.split', 'shutil.make_archive', 'os_zip_checkintegrity', 'print']",4
utilmy/zarchive/util_min.py:os_zipextractall,os_zipextractall,function,23,59,48,538,9.12,1,3,"['filezip_or_dir', 'tofolderextract', 'isprint']","[None, None, None]","['""folder1/*.zip""', ""'zdisk/test'"", '1']",148,"[""   '''os_zipextractall( 'aapackage.zip','zdisk/test/'      )  '''\n""]","['filezip_or_dir.find', 'os_file_listall', 'os_file_getname', 'zipfile.ZipFile', 'zip_ref.extractall', 'zip_ref.close', 'print']",7
utilmy/zarchive/util_min.py:os_folder_copy,os_folder_copy,function,17,36,35,345,9.58,0,1,"['src', 'dst', 'symlinks', 'pattern1', 'fun_file_toignore']","[None, None, None, None, None]","[None, None, 'False', '""*.py""', 'None']",178,"[""   '''\n"", '       callable(src, names) -> ignored_names\n', ""       'src' parameter, which is the directory being visited by copytree(), and\n"", ""       'names' which is the list of `src` contents, as returned by os.listdir():\n"", '\n', '    Since copytree() is called recursively, the callable will be called once for each directory that is copied.\n', '    It returns a  list of names relative to the `src` directory that should not be copied.\n', ""   '''\n""]","['fun_file_toignore', 'fnmatch.filter', 'shutil.copytree', 'shutil.copy']",4
utilmy/zarchive/util_min.py:os_folder_create,os_folder_create,function,4,7,7,85,12.14,0,1,['directory'],[None],[None],200,[],"['os.getcwd', 'os.makedirs', 'os.chdir']",3
utilmy/zarchive/util_min.py:os_folder_robocopy,os_folder_robocopy,function,3,15,15,166,11.07,0,1,"['from_folder', 'to_folder', ""my_log='H""]","[None, None, '']","[""''"", ""''"", ""'H:/robocopy_log.txt'""]",205,"['    """"""\n', '    Copy files to working directory\n', '    robocopy <Source> <Destination> [<File>[ ...]] [<Options>]\n', '    We want to copy the files to a fast SSD drive\n', '    """"""\n']",['print'],1
utilmy/zarchive/util_min.py:os_file_replacestring1,os_file_replacestring1,function,11,25,24,238,9.52,1,0,"['findStr', 'repStr', 'filePath']","[None, None, None]","[None, None, None]",216,[],"['fileinput.FileInput', 'line.replace', 'file1.close', 'print']",4
utilmy/zarchive/util_min.py:os_file_replacestring2,os_file_replacestring2,function,6,14,13,161,11.5,1,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",227,"['  \'\'\' #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",    pattern=""*.html"", dirlevel=5  )\n', ""  '''\n""]","['os_file_listall', 'os_file_replacestring1']",2
utilmy/zarchive/util_min.py:os_file_getname,os_file_getname,function,8,9,8,75,8.33,0,0,['path'],[None],[None],234,[],"['ntpath.split', 'ntpath.basename']",2
utilmy/zarchive/util_min.py:os_file_getpath,os_file_getpath,function,7,7,7,52,7.43,0,0,['path'],[None],[None],239,[],['ntpath.split'],1
utilmy/zarchive/util_min.py:os_file_gettext,os_file_gettext,function,4,7,7,56,8.0,0,0,['file1'],[None],[None],244,[],"['open', 'f.read']",2
utilmy/zarchive/util_min.py:os_file_listall,os_file_listall,function,28,79,46,902,11.42,4,3,"['dir1', 'pattern', 'dirlevel', 'onlyfolder']","[None, None, None, None]","[None, '""*.*""', '1', '0']",250,"[""  '''\n"", '   # DIRCWD=r""D:\\_devs\\Python01\\project""\n', '   # aa= listallfile(DIRCWD, ""*.*"", 2)\n', '   # aa[0][30];   aa[2][30]\n', '\n', '   :param dir1:\n', '   :param pattern:\n', '   :param dirlevel:\n', '   :param onlyfolder:\n', '   :return:\n', ""  '''\n""]","['dir1.rstrip', 'dir1.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 'np.array']",7
utilmy/zarchive/util_min.py:os_file_rename,os_file_rename,function,32,56,48,642,11.46,2,1,"['some_dir', 'pattern', 'pattern2', 'dirlevel']","[None, None, None, None]","[None, '""*.*""', '""""', '1']",287,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 're.sub', 'os.rename', 'np.array']",9
utilmy/zarchive/util_min.py:os_print_tofile,os_print_tofile,function,1,2,2,7,3.5,0,0,"['vv', 'file1', ""mode1='a')"", 'mode1) as text_file']","[None, None, '', '  text_file.write(str(vv))) :']","[None, None, ""'a'):  # print into a file='afile1"", None]",309,"[""    '''\n"", '    Here is a list of the different modes of opening a file:\n', 'r\n', 'Opens a file for reading only. The file pointer is placed at the beginning of the file. This is the default mode.\n', '\n', 'rb\n', '\n', 'Opens a file for reading only in binary format. The file pointer is placed at the beginning of the file. This is the default mode.\n', 'r+\n', '\n', 'Opens a file for both reading and writing. The file pointer will be at the beginning of the file.\n', 'rb+\n', '\n', 'Opens a file for both reading and writing in binary format. The file pointer will be at the beginning of the file.\n', 'w\n', '\n', 'Opens a file for writing only. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'wb\n', '\n', 'Opens a file for writing only in binary format. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'w+\n', '\n', 'Opens a file for both writing and reading. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'wb+\n', '\n', 'Opens a file for both writing and reading in binary format. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'a\n', '\n', 'Opens a file for appending. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'ab\n', '\n', 'Opens a file for appending in binary format. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'a+\n', '\n', 'Opens a file for both appending and reading. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'ab+\n', '\n', 'Opens a file for both appending and reading in binary format. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'To open a text file, use:\n', 'fh = open(""hello.txt"", ""r"")\n', '\n', 'To read a text file, use:\n', 'print fh.read()\n', '\n', 'To read one line at a time, use:\n', 'print fh.readline()\n', '\n', 'To read a list of lines use:\n', 'print fh.readlines()\n', '\n', 'To write to a file, use:\n', 'fh = open(""hello.txt"", ""w"")\n', 'lines_of_text = [""a line of text"", ""another line of text"", ""a third line""]\n', 'fh.writelines(lines_of_text)\n', 'fh.close()\n', '\n', 'To append to file, use:\n', 'fh = open(""Hello.txt"", ""a"")\n', 'fh.close()\n', '\n', ""    '''\n""]",[],0
utilmy/zarchive/util_min.py:a_get_pythonversion,a_get_pythonversion,function,1,2,2,7,3.5,0,0,[],[],[],374,[],[],0
utilmy/zarchive/util_min.py:os_path_norm,os_path_norm,function,8,20,18,174,8.7,0,1,['pth)'],[' #Normalize path for Python directory)'],['=2:'],377,"['    \'\'\' #r""D:\\_devs\\Python01\\project\\03-Connect_Java_CPP_Excel\\PyBindGen\\examples"" \'\'\'\n']","['pth.find', 'b.lstrip']",2
utilmy/zarchive/util_min.py:os_path_change,os_path_change,function,4,4,4,34,8.5,0,0,['path1)'],[' path1'],[' os_path_norm(path1); os.chdir(path1)    #Change Working directory path): return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],389,[],"['open', 'fh.read']",2
utilmy/zarchive/util_min.py:os_path_current,os_path_current,function,4,4,4,34,8.5,0,0,[')'],[' return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],391,[],"['open', 'fh.read']",2
utilmy/zarchive/util_min.py:os_file_exist,os_file_exist,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],393,[],"['open', 'fh.read']",2
utilmy/zarchive/util_min.py:os_file_size,os_file_size,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.getsize(file1)file1):'],[None],395,[],"['open', 'fh.read']",2
utilmy/zarchive/util_min.py:os_file_read,os_file_read,function,4,4,4,34,8.5,0,0,['file1'],[None],[None],397,[],"['open', 'fh.read']",2
utilmy/zarchive/util_min.py:os_file_mergeall,os_file_mergeall,function,10,20,20,185,9.25,1,0,"['nfile', 'dir1', 'pattern1', 'deepness']","[None, None, None, None]","[None, None, None, '2']",401,[],"['os_file_listall', 'open', 'os_file_gettext', 'nfile1.write', 'nfile1.close']",5
utilmy/zarchive/util_min.py:os_path_append,os_path_append,function,4,19,11,121,6.37,0,3,"['p1', 'p2', 'p3', 'p4']","[None, None, None, None]","[None, 'None', 'None', 'None']",412,[],[],0
utilmy/zarchive/util_min.py:os_split_dir_file,os_split_dir_file,function,6,15,15,112,7.47,0,1,['dirfile'],[None],[None],421,[],"['dirfile.split', 'len']",2
utilmy/zarchive/util_min.py:py_importfromfile,py_importfromfile,function,12,21,19,251,11.95,0,1,"['modulename', 'dir1']","[None, None]","[None, None]",430,[],"['a_get_pythonversion', 'SourceFileLoader', 'foo.MyClass', 'imp.load_source']",4
utilmy/zarchive/util_min.py:py_memorysize,py_memorysize,function,16,56,38,320,5.71,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",442,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'o.iteritems']",7
utilmy/zarchive/util_min.py:save,save,function,2,4,4,64,16.0,0,0,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",470,[],['py_save_obj'],1
utilmy/zarchive/util_min.py:load,load,function,2,3,3,60,20.0,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",473,[],['py_load_obj'],1
utilmy/zarchive/util_min.py:save_test,save_test,function,6,11,11,124,11.27,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",476,[],"['py_load_obj', 'print', 'str', 'gc.collect']",4
utilmy/zarchive/util_min.py:py_save_obj,py_save_obj,function,17,36,35,308,8.56,0,1,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",482,[],"['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.dump']",5
utilmy/zarchive/util_min.py:py_load_obj,py_load_obj,function,16,30,28,265,8.83,0,1,"['folder', 'isabsolutpath', 'encoding1']","[None, None, None]","[""'/folder1/keyname'"", '0', ""'utf-8'""]",495,"[""    '''def load_obj(name, encoding1='utf-8' ):\n"", ""         with open('D:/_devs/Python01/aaserialize/' + name + '.pkl', 'rb') as f:\n"", '            return pickle.load(f, encoding=encoding1)\n', ""    '''\n""]","['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.load']",5
utilmy/zarchive/util_min.py:z_key_splitinto_dir_name,z_key_splitinto_dir_name,function,6,15,15,112,7.47,0,1,['keyname'],[None],[None],511,[],"['keyname.split', 'len']",2
utilmy/zarchive/util_ml.py:create_weight_variable,create_weight_variable,function,5,7,6,129,18.43,0,0,"['name', 'shape']","[None, None]","[None, None]",27,[],['tf.Variable'],1
utilmy/zarchive/util_ml.py:create_bias_variable,create_bias_variable,function,4,6,6,112,18.67,0,0,"['name', 'shape']","[None, None]","[None, None]",33,[],"['tf.constant_initializer', 'tf.Variable']",2
utilmy/zarchive/util_ml.py:create_adam_optimizer,create_adam_optimizer,function,2,3,3,70,23.33,0,0,"['learning_rate', 'momentum']","[None, None]","[None, None]",38,[],[],0
utilmy/zarchive/util_ml.py:tf_check,tf_check,function,32,91,51,915,10.05,0,0,[],[],[],44,[],"['print', 'tf.constant', 'tf.matmul', 'tf.Session', 'sess.run']",5
utilmy/zarchive/util_ml.py:parse_args,parse_args,function,11,26,24,196,7.54,1,1,"['ppa', 'args']","[None, None]","['None', ' {}']",75,[],"['argparse.ArgumentParser', 'args.items', 'ppa.add_argument', 'type=type', 'ppa.parse_args', 'parse_args2']",6
utilmy/zarchive/util_ml.py:parse_args2,parse_args2,function,5,133,98,1435,10.79,0,1,['ppa'],[None],['None'],86,[],"['argparse.ArgumentParser', 'e:print', 'ppa.add_argument']",3
utilmy/zarchive/util_ml.py:tf_global_variables_initializer,tf_global_variables_initializer,function,27,65,46,866,13.32,3,1,['sess'],[None],['None'],124,"['    """"""Initializes all uninitialized variables in correct order. Initializers\n', ""    are only run for uninitialized variables, so it's safe to run this multiple times.\n"", '    Args:   sess: session to use. Use default session if None.\n', '    """"""\n']","['make_initializer', 'f', 'tf.assign', 'make_noop', 'tf.no_op', 'make_safe_initializer', 'tf.cond', 'tf.get_default_session', 'tf.get_default_graph', 'tf.global_variables', 'g.get_operation_by_name', 'sess.run']",12
utilmy/zarchive/util_ml.py:visualize_result,visualize_result,function,21,142,111,1132,7.97,2,0,[],[],[],234,[],"['range', 'enumerate', 'pd.read_csv', 'plt.plot', 'train_loss.tolist', 'plt.legend', 'plt.xlabel', 'plt.ylabel', 'plt.show']",9
utilmy/zarchive/util_ml.py:TextLoader,TextLoader,class,65,159,120,2143,13.48,0,1,[],[],[],167,[],[],0
utilmy/zarchive/util_ml.py:TextLoader:__init__,TextLoader:__init__,method,15,34,31,491,14.44,0,1,"['self', 'data_dir', 'batch_size', 'seq_length']","[None, None, None, None]","[None, None, None, None]",168,[],"['print', 'self.preprocess', 'self.load_preprocessed', 'self.create_batches', 'self.reset_batch_pointer']",5
utilmy/zarchive/util_ml.py:TextLoader:preprocess,TextLoader:preprocess,method,17,34,31,404,11.88,0,0,"['self', 'input_file', 'vocab_file', 'tensor_file']","[None, None, None, None]","[None, None, None, None]",186,[],"['codecs.open', 'f.read', 'collections.Counter', 'sorted', 'list', 'len', 'dict', 'range', 'open', 'pickle.dump', 'np.array', 'np.save']",12
utilmy/zarchive/util_ml.py:TextLoader:load_preprocessed,TextLoader:load_preprocessed,method,10,19,19,245,12.89,0,0,"['self', 'vocab_file', 'tensor_file']","[None, None, None]","[None, None, None]",199,[],"['open', 'pickle.load', 'len', 'dict', 'range', 'np.load']",6
utilmy/zarchive/util_ml.py:TextLoader:create_batches,TextLoader:create_batches,method,20,40,33,665,16.62,0,0,['self'],[None],[None],207,[],"['np.copy', 'np.split', 'int', 'zip']",4
utilmy/zarchive/util_ml.py:TextLoader:next_batch,TextLoader:next_batch,method,6,10,8,87,8.7,0,0,['self'],[None],[None],223,[],[],0
utilmy/zarchive/util_ml.py:TextLoader:reset_batch_pointer,TextLoader:reset_batch_pointer,method,1,2,2,14,7.0,0,0,['self'],[None],[None],228,[],[],0
utilmy/zarchive/util_sql.py:sql_create_dbengine,sql_create_dbengine,function,4,45,26,358,7.96,0,1,"['type1', 'dbname', 'login', 'password', 'url', 'port']","[None, None, None, None, None, None]","[""''"", ""''"", ""''"", ""''"", ""'localhost'"", '5432']",43,"[""   ''' Return SQL Alchemy Connector\n"", '\n', '# psycopg2\n', ""engine = create_engine('postgresql+psycopg2://scott:tiger@localhost/mydatabase')\n"", '\n', '# MySQL-connector-python  Official one\n', ""engine = create_engine('mysql+mysqlconnector://scott:tiger@localhost/foo')\n"", 'conda install -c anaconda mysql-connector-python=2.0.4\n', ""engine = create_engine('postgresql://%s:%s@localhost:5432/%s' %(myusername, mypassword, mydatabase))\n"", '\n', ""engine = create_engine('sqlite:///  folder/foo.db')\n"", '\n', ""   '''\n""]","['sql.create_engine', 'str']",2
utilmy/zarchive/util_sql.py:sql_query,sql_query,function,6,22,18,155,7.05,0,2,"['sqlr', 'dbengine', 'output', ""dburl='sqlite""]","[None, None, None, '']","[""'SELECT ticker,shortratio,sector1_id, FROM stockfundamental'"", 'None', ""'df'"", ""'sqlite:///aaserialize/store/finviz.db'""]",69,"["" '''\n"", "" :param sqlr:       'SELECT ticker,shortratio,sector1_id, FROM stockfundamental'\n"", ' :param output:     df   /   file1.csv\n', "" :param dburl:      'sqlite:///aaserialize/store/finviz.db'\n"", "" :param dbengine:   dbengine = sql.create_engine('postgresql+psycopg2://postgres:postgres@localhost/coke')\n"", ' :return:\n', "" '''\n""]","['sql.create_engine', 'pd.read_sql_query', 'output.find', 'df.to_csv']",4
utilmy/zarchive/util_sql.py:sql_get_dbschema,sql_get_dbschema,function,16,37,32,318,8.59,2,2,"[""dburl='sqlite"", 'dbengine', 'isprint']","['', None, None]","[""'sqlite:///aapackage/store/yahoo.db'"", 'None', '0']",83,[],"['sql.create_engine', 'sql.inspect', 'inspector.get_table_names', 'inspector.get_columns', 'l1.append', 'print', 'np.array']",7
utilmy/zarchive/util_sql.py:sql_delete_table,sql_delete_table,function,1,8,8,89,11.12,0,0,"['name', 'dbengine']","[None, None]","[None, None]",96,[],[],0
utilmy/zarchive/util_sql.py:sql_insert_excel,sql_insert_excel,function,50,131,97,992,7.57,5,2,"['file1', 'dbengine', 'dbtype']","[None, None, None]","[""'.xls'"", 'None', ""''""]",103,"["" ''' http://flask-excel.readthedocs.io/en/latest/\n"", ' https://pythonhosted.org/pyexcel/tutorial_data_conversion.html#import-excel-sheet-into-a-database-table\n', ' from sqlalchemy import create_engine\n', 'from sqlalchemy.ext.declarative import declarative_base\n', 'from sqlalchemy import Column , Integer, String, Float, Date\n', 'from sqlalchemy.orm import sessionmaker\n', 'engine = create_engine(""sqlite:///birth.db"")\n', 'Base = declarative_base()\n', 'Session = sessionmaker(bind=engine)\n', '\n', 'class BirthRegister(Base):\n', ""...     __tablename__='birth'\n"", '...     id=Column(Integer, primary_key=True)\n', '...     name=Column(String)\n', '...     weight=Column(Float)\n', '...     birth=Column(Date)\n', '\n', 'Base.metadata.create_all(engine)\n', '\n', 'https://www.digitalocean.com/community/tutorials/how-to-use-celery-with-rabbitmq-to-queue-tasks-on-an-ubuntu-vps\n', 'import os\n', 'import pyexcel\n', 'import datetime\n', '\n', 'from sqlalchemy import create_engine\n', 'from sqlalchemy.ext.declarative import declarative_base\n', 'from sqlalchemy import Column, Integer, String, Float, Date\n', 'from sqlalchemy.orm import sessionmaker\n', '\n', '\n', 'engine = create_engine(""sqlite:///birth.db"")\n', 'Base = declarative_base()\n', 'Session = sessionmaker(bind=engine)\n', '\n', '\n', '# here is the destination table\n', 'class BirthRegister(Base):\n', ""    __tablename__ = 'birth'\n"", '    id = Column(Integer, primary_key=True)\n', '    name = Column(String)\n', '    weight = Column(Float)\n', '    birth = Column(Date)\n', '\n', '\n', 'Base.metadata.create_all(engine)\n', '\n', '\n', '# create fixture\n', 'data = [\n', '    [""name"", ""weight"", ""birth""],\n', '    [""Adam"", 3.4, datetime.date(2015, 2, 3)],\n', '    [""Smith"", 4.2, datetime.date(2014, 11, 12)]\n', ']\n', 'pyexcel.save_as(array=data,\n', '                dest_file_name=""birth.xls"")\n', '\n', '# import the xls file\n', 'session = Session()  # obtain a sql session\n', 'pyexcel.save_as(file_name=""birth.xls"",\n', '                name_columns_by_row=0,\n', '                dest_session=session,\n', '                dest_table=BirthRegister)\n', '\n', '# verify results\n', 'sheet = pyexcel.get_sheet(session=session, table=BirthRegister)\n', 'print(sheet)\n', '\n', 'session.close()\n', ""os.unlink('birth.db')\n"", 'os.unlink(""birth.xls"")\n', '\n', ' This code uses the openpyxl package for playing around with excel using Python code\n', ' to convert complete excel workbook (all sheets) to an SQLite database\n', ' The code assumes that the first row of every sheet is the column name\n', ' Every sheet is stored in a separate table\n', ' The sheet name is assigned as the table name for every sheet\n', "" '''\n""]","['slugify', 'text.strip', 're.sub', 'load_workbook', 'wb.get_sheet_names', 'str', 'columns.append', 'dbengine.execute', 'enumerate', 'tuprow.append', 'tup.append', 'VALUES', 'dbengine.executemany', 'dbengine.commit', 'dbengine.close']",15
utilmy/zarchive/util_sql.py:sql_insert_df,sql_insert_df,function,22,59,51,481,8.15,1,2,"['df', 'dbtable', 'dbengine', 'col_drop', 'verbose']","[None, None, None, None, None]","[None, None, None, ""['id']"", '1']",226,[],"['df.drop', 'df.to_dict', 'print', 'sql.Table', 'Session', 'dbengine.execute', 'session.commit', 'session.close']",8
utilmy/zarchive/util_sql.py:sql_insert_csv,sql_insert_csv,function,35,159,130,1364,8.58,3,3,"['csvfile', 'dbtable', 'dbengine', 'col_drop']","[None, None, None, None]","[None, None, None, '[]']",256,[],"['datetime.now', 'pd.read_csv', 'df.rename', 'c.replace', 'df.drop', 'df.to_dict', 'sql.Table', 'Session', 'dbengine.execute', 'session.commit', 'session.close', 'print', 'sql_insert_csv2', 'os.listdir', 'i.endswith', 'i.startswith', 'df.to_sql']",17
utilmy/zarchive/util_sql.py:sql_insert_csv2,sql_insert_csv2,function,11,58,54,469,8.09,1,2,"['csvfile', 'dbtable', 'columns', 'dbengine', 'nrows']","[None, None, None, None, None]","[""''"", ""''"", '[]', 'None', ' 10000']",328,"['    """"""\n', '    Upload data to a temporary table first using PANDAs to identify optimal data-types for columns\n', '    PANDAS is not speed-efficient as it uses INSERT commands rather than COPY e.g. it took COPY 16mins average\n', '    to get a 15GB CSV into the database (door-to-door) whereas pandas.to_sql took 50mins\n', '    """"""\n']","['os.listdir', 'i.endswith', 'i.startswith', 'print', 'pd.read_csv', 'df.to_sql']",6
utilmy/zarchive/util_sql.py:sql_postgres_create_table,sql_postgres_create_table,function,20,108,73,890,8.24,0,3,"['mytable', 'database', 'username', 'password']","[None, None, None, None]","[""''"", ""''"", ""''"", ""''""]",361,"['    """""" Create table copying the structure of the temp table created using pandas  Timer to benchmark """"""\n']","['psycopg2.connect', 'con.cursor', 'print', 'sys.exit', 'cur.execute', 'open', 'cur.copy_expert', 'con.close']",8
utilmy/zarchive/util_sql.py:sql_postgres_pivot,sql_postgres_pivot,function,0,1,1,4,4.0,0,0,[],[],[],447,"[""   '''\n"", 'Enabling the Crosstab Function\n', 'As we previously mentioned, the crosstab function is part of a PostgreSQL extension called tablefunc. To call the crosstab function,\n', 'you must first enable the tablefunc extension by executing the following SQL command:\n', 'CREATE extension tablefunc;\n', '\n', 'SELECT *\n', ""FROM crosstab( 'select student, subject, evaluation_result from evaluations order by 1,2')\n"", 'AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '\n', '##### Correct Even iF there are missing values :\n', 'http://www.vertabelo.com/blog/technical-articles/creating-pivot-tables-in-postgresql-using-the-crosstab-function\n', '\n', 'SELECT *\n', ""FROM crosstab( 'select student, subject, evaluation_result from evaluations\n"", ""                where extract (month from evaluation_day) = 7 order by 1,2',\n"", ""                'select name from subject order by 1')\n"", '     AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/util_sql.py:sql_mysql_insert_excel,sql_mysql_insert_excel,function,30,73,69,712,9.75,1,0,[],[],[],473,[],"['xlrd.open_workbook', 'list.sheet_by_index', 'database.cursor', 'range', 'sheet.cell', 'cursor.execute', 'cursor.close', 'database.commit', 'database.close', 'print', 'str', 'rows=str']",12
utilmy/zarchive/util_sql.py:sql_pivotable,sql_pivotable,function,1,3,3,10,3.33,0,0,"['dbcon', 'ss']","[None, None]","[None, ""'select  '""]",506,"[""  '''\n"", '\n', ' 1) get the category\n', '\n', ' 2) Build the Pivot From category\n', '  SELECT *\n', ""  FROM crosstab( 'select student, subject, evaluation_result from evaluations\n"", ""                where extract (month from evaluation_day) = 7 order by 1,2',\n"", ""                'select name from subject order by 1')\n"", '   AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '  https://www.amazon.com/PostgreSQL-High-Performance-Gregory-Smith/dp/184951030X/ref=as_li_ss_tl?s=books&ie=UTF8&qid=1458352081&sr=1-6&keywords=postgres&linkCode=sl1&tag=postgres-bottom-20&linkId=c981783121cbd5542dc2b44a2297df57\n', '\n', '\n', 'http://blog.brakmic.com/data-science-for-losers-part-2/\n', '\n', 'Here we instruct Pandas to merge two tables by using certain primary keys from both when combining their rows into a new table. The parameter how instructs Pandas to use the inner-join which means it will only combine such rows which belong to both of the tables. Therefore well not receive any NaN-rows. But in some cases this could be desirable. Then use the alternative options like left, right or outer.\n', '\n', 'Pivots with Tables from SQLAlchemy\n', '\n', 'And of course its possible to generate the same pivot tables with data that came from SQLAlchemy.\n', 'Theyre nothing else but DataFrames all the way down. OK, not absolutely all the way down,\n', 'because there are also Series and NumPy arrays etc.,\n', 'but this is a little bit too much of knowledge for Losers like us. Maybe in some later articles.\n', '\n', '\n', ' :return:\n', ""  '''\n""]",[],0
utilmy/zarchive/util_web.py:web_restapi_toresp,web_restapi_toresp,function,12,19,18,168,8.84,0,1,['apiurl1'],[None],[None],59,[],"['requests.get', 'ApiError']",2
utilmy/zarchive/util_web.py:web_getrawhtml,web_getrawhtml,function,13,20,20,176,8.8,0,1,['url1'],[None],[None],66,[],"['requests.get', 'ApiError']",2
utilmy/zarchive/util_web.py:web_importio_todataframe,web_importio_todataframe,function,41,77,59,641,8.32,4,4,"['apiurl1', 'isurl']","[None, None]","[None, '1']",74,[],"['requests.get', 'ApiError', 'resp.json', 'list', 'colname.append', 'str', 'np.array', 'colmax=len', 'np.empty', 'pd_createdf', 'np.arange', 'len']",12
utilmy/zarchive/util_web.py:web_getjson_fromurl,web_getjson_fromurl,function,10,11,10,138,12.55,0,0,['url'],[None],[None],101,[],"['urllib3.connection_from_url', 'http.urlopen', 'print', 'json.loads']",4
utilmy/zarchive/util_web.py:web_gettext_fromurl,web_gettext_fromurl,function,9,18,17,203,11.28,0,0,"['url', 'htmltag']","[None, None]","[None, ""'p'""]",116,[],"['urllib3.connection_from_url', 'http.urlopen', 'BeautifulSoup', 'soup.find_all']",4
utilmy/zarchive/util_web.py:web_gettext_fromhtml,web_gettext_fromhtml,function,8,20,19,176,8.8,0,0,"['file1', 'htmltag']","[None, None]","[None, ""'p'""]",124,[],"['open', 'BeautifulSoup', 'soup.find_all']",3
utilmy/zarchive/util_web.py:web_getlink_fromurl,web_getlink_fromurl,function,14,20,20,248,12.4,1,0,['url'],[None],[None],183,[],"['urllib3.connection_from_url', 'http.urlopen', 'BeautifulSoup', 'soup.prettify', 'soup.findAll', 'links.append', 'set']",7
utilmy/zarchive/util_web.py:web_send_email,web_send_email,function,33,126,77,1266,10.05,0,0,"['FROM', 'recipient', 'subject', 'body', 'login1', 'pss1', 'server1', 'port1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, '""mizenjapan@gmail.com""', '""sophieelise237""', '""smtp.gmail.com""', '465']",195,"['    \'\'\'  # send_email(""Kevin"", ""brookm291@gmail.com"", ""JapaneseText:"" , ""txt"") \'\'\'\n']","['MIMEMultipart', 'msg.set_charset', 'MIMEText', 'msg.attach', 'smtplib.SMTP_SSL', 'server_ssl.ehlo', 'login', 'server_ssl.login', 'server_ssl.sendmail', 'msg.as_string', 'server_ssl.close', 'print', 'web_send_email_tls', 'smtplib.SMTP', 'mailserver.ehlo', 'mailserver.starttls', 'mailserver.login', 'mailserver.sendmail', 'mailserver.quit']",19
utilmy/zarchive/util_web.py:web_send_email_tls,web_send_email_tls,function,25,56,51,568,10.14,0,0,"['FROM', 'recipient', 'subject', 'body', 'login1', 'pss1', 'server1', 'port1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, '""mizenjapan@gmail.com""', '""sophieelise237""', '""smtp.gmail.com""', '465']",220,[],"['MIMEMultipart', 'msg.set_charset', 'MIMEText', 'msg.attach', 'smtplib.SMTP', 'mailserver.ehlo', 'mailserver.starttls', 'mailserver.login', 'mailserver.sendmail', 'msg.as_string', 'mailserver.quit', 'print']",12
utilmy/zarchive/util_web.py:web_sendurl,web_sendurl,function,3,10,10,95,9.5,0,0,['url1'],[None],[None],256,[],"['web_gettext_fromurl', 'send_email']",2
utilmy/zarchive/_HELP.py:os_compileVSsolution,os_compileVSsolution,function,6,32,21,239,7.47,0,4,"['dir1', 'flags1', 'type1', 'compilerdir']","[None, None, None, None]","[None, '""""', '""devenv""', '""""']",744,[],['os.system'],1
utilmy/zarchive/_HELP.py:os_VS_build,os_VS_build,function,16,62,54,614,9.9,1,2,"['self', 'lib_to_build']","[None, None]","[None, None]",773,[],"['print', 'subprocess.Popen', 'process.poll', 'process.communicate']",4
utilmy/zarchive/_HELP.py:set_rc_version,set_rc_version,function,12,37,34,502,13.57,0,0,"['rcfile', 'target_version']","[None, None]","[None, None]",810,[],"['open', 'f.seek', 'f.write', 'f.truncate']",4
utilmy/zarchive/_HELP.py:os_VS_start,os_VS_start,function,18,56,52,881,15.73,0,2,"['self', 'version']","[None, None]","[None, None]",847,[],"['os.getenv', 'Exception', 'default.append', 'libs.append']",4
utilmy/zarchive/_HELP.py:fun_cython,fun_cython,function,5,10,9,34,3.4,1,0,['a'],[None],[None],890,[],['xrange'],1
utilmy/zarchive/_HELP.py:fun_python,fun_python,function,5,10,9,34,3.4,1,0,['a'],[None],[None],897,[],['xrange'],1
utilmy/zarchive/_HELP.py:LookupTable,LookupTable,class,4,7,7,94,13.43,0,0,[],[],[],207,[],[],0
utilmy/zarchive/py2to3/allmodule.py:pprint,pprint,function,10,32,23,378,11.81,0,1,"['table1', 'tablefmt']","[None, None]","[None, '""simple""']",34,"[' """"""To print nice column headers, supply the second argument (`headers`):\n', '      - `headers` can be an explicit list of column headers\n', '      - if `headers=""firstrow""`, then the first row of data is used\n', '      - if `headers=""keys""`, then dictionary keys or column indices are used\n', '    print(tabulate([[1, 2.34], [-56, ""8.999""], [""2"", ""10001""]]))\n', '  """"""\n']","['isinstance', 'tabulate', 'pprint2', 'pprint.PrettyPrinter', 'pp.pprint']",5
utilmy/zarchive/py2to3/allmodule.py:pprint2,pprint2,function,5,5,5,59,11.8,0,0,['x'],[None],[None],51,"[""  '''import pprint\n"", ""     stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']\n"", 'stuff.insert(0, stuff[:])\n', 'pp = pprint.PrettyPrinter(indent=4)\n', 'pp.pprint(ALLDB)\n', ""  '''\n""]","['pprint.PrettyPrinter', 'pp.pprint']",2
utilmy/zarchive/py2to3/allmodule.py:str_convert_beforeprint,str_convert_beforeprint,function,2,2,2,23,11.5,0,0,['x'],[None],[None],64,"[""  ''' #Before writing/output to printer put in utf-8 '''\n""]",['x.encode'],1
utilmy/zarchive/py2to3/allmodule.py:str_to_utf8,str_to_utf8,function,2,2,2,23,11.5,0,0,['x'],[None],[None],69,"[""  ''' #Before writing/output to printer put in utf-8 '''\n""]",['x.encode'],1
utilmy/zarchive/py2to3/allmodule.py:str_to_unicode,str_to_unicode,function,4,16,12,98,6.12,0,2,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",74,"[""  ''' #After Loading Text from CSV ---> Immediately in unicode '''\n""]","['isinstance', 'unicode']",2
utilmy/zarchive/py2to3/coke_functions.py:date_diffsecond,date_diffsecond,function,4,8,7,71,8.88,0,0,"['str_t1', 'str_t0', ""fmt='YYYY-MM-DD HH""]","[None, None, '']","[None, None, ""'YYYY-MM-DD HH:mm:SS'""]",8,[],"['arrow.get', 'dd.total_seconds']",2
utilmy/zarchive/py2to3/coke_functions.py:date_diffstart,date_diffstart,function,4,9,8,31,3.44,1,0,"['t) ', 'str_t0=t0)t) ', 'str_t0=t)dd) ']","[' return date_diffsecond(str_t1', '', '']","['t', 't0)t) :   return date_diffsecond(str_t1=t1', 't)dd) :']",13,[],['dd.items'],1
utilmy/zarchive/py2to3/coke_functions.py:date_diffend,date_diffend,function,4,9,8,31,3.44,1,0,"['t) ', 'str_t0=t)dd) ']","['   return date_diffsecond(str_t1', '']","['t1', 't)dd) :']",14,[],['dd.items'],1
utilmy/zarchive/py2to3/coke_functions.py:np_dict_tolist,np_dict_tolist,function,4,9,8,31,3.44,1,0,['dd'],[None],[None],17,[],['dd.items'],1
utilmy/zarchive/py2to3/coke_functions.py:np_dict_tostr_val,np_dict_tostr_val,function,1,9,9,46,5.11,0,0,['dd'],[None],[None],20,[],"['str', 'dd.items']",2
utilmy/zarchive/py2to3/coke_functions.py:np_dict_tostr_key,np_dict_tostr_key,function,1,8,8,46,5.75,0,0,['dd'],[None],[None],23,[],"['str', 'dd.items']",2
utilmy/zarchive/py2to3/coke_functions.py:day,day,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['    return int(s[8:10])s):  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",31,[],['arrow.get'],1
utilmy/zarchive/py2to3/coke_functions.py:month,month,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",32,[],['arrow.get'],1
utilmy/zarchive/py2to3/coke_functions.py:year,year,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",33,[],['arrow.get'],1
utilmy/zarchive/py2to3/coke_functions.py:hour,hour,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",34,[],['arrow.get'],1
utilmy/zarchive/py2to3/coke_functions.py:weekday,weekday,function,9,16,15,117,7.31,0,0,"['s', 'fmt', 'i0', 'i1']","[None, None, None, None]","[None, ""'YYYY-MM-DD'"", '0', '10']",38,[],['arrow.get'],1
utilmy/zarchive/py2to3/coke_functions.py:season,season,function,4,15,13,47,3.13,0,1,['d'],[None],[None],48,[],['int'],1
utilmy/zarchive/py2to3/coke_functions.py:daytime,daytime,function,7,42,23,123,2.93,0,1,['d'],[None],[None],53,[],['int'],1
utilmy/zarchive/py2to3/coke_functions.py:pd_date_splitall,pd_date_splitall,function,11,22,17,255,11.59,0,0,"['df', 'coldate']","[None, None]","[None, ""'purchased_at'""]",62,[],['copy.deepcopy'],1
utilmy/zarchive/py2to3/datanalysis.py:pd_filter_column,pd_filter_column,function,12,25,22,218,8.72,1,2,"['df_client_product', 'filter_val', 'iscol']","[None, None, None]","[None, '[]', '1']",52,"[""   '''\n"", '   # Remove Columns where Index Value is not in the filter_value\n', ""   # filter1= X_client['client_id'].values\n"", '   :param df_client_product:\n', '   :param filter_val:\n', '   :param iscol:\n', '   :return:\n', ""   '''\n""]",['col_delete1.append'],1
utilmy/zarchive/py2to3/datanalysis.py:pd_missing_show,pd_missing_show,function,0,1,1,4,4.0,0,0,[],[],[],69,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:pd_validation_struct,pd_validation_struct,function,0,1,1,4,4.0,0,0,[],[],[],98,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:pd_checkpoint,pd_checkpoint,function,0,1,1,4,4.0,0,0,[],[],[],108,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:xl_setstyle,xl_setstyle,function,32,63,47,610,9.68,2,0,['file1'],[None],[None],167,"["" '''\n"", '   http://openpyxl.readthedocs.io/en/default/styles.html#cell-styles-and-named-styles\n', '  import openpyxl.styles.builtins  as bi\n', '  import openpyxl.styles.builtins\n', '\n', ""  col = ws.column_dimensions['A']\n"", '  col.font = Font(bold=True)\n', '\n', ""  for cell in ws['A'] + ws[1]:\n"", ""    cell.style = 'data01'\n"", '\n', '  bd = Side(style=\'thick\', color=""000000"")\n', '  highlight.border = BORDER_NONE\n', '  from openpyxl.styles import\n', "" '''\n""]","['load_workbook', 'print', 'named_styles.NamedStyle', 'Font', 'wb.get_sheet_names', 'wb.get_sheet_by_name', 'xrange', 'wb.save']",8
utilmy/zarchive/py2to3/datanalysis.py:xl_val,xl_val,function,7,14,13,107,7.64,0,0,"['ws', 'colj', 'rowi']","[None, None, None]","[None, None, None]",207,[],"['ws[gcol', 'str']",2
utilmy/zarchive/py2to3/datanalysis.py:isnull,isnull,function,3,5,5,20,4.0,0,0,['x'],[None],[None],214,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:xl_get_rowcol,xl_get_rowcol,function,8,44,37,222,5.05,1,1,"['ws', 'i0', 'j0', 'imax', 'jmax']","[None, None, None, None, None]","[None, None, None, None, None]",217,[],"['xrange', 'isnull', 'rmat.append']",3
utilmy/zarchive/py2to3/datanalysis.py:pd_stack_dflist,pd_stack_dflist,function,8,29,24,155,5.34,1,1,['df_list'],[None],[None],227,[],"['enumerate', 'df0.append', 'print']",3
utilmy/zarchive/py2to3/datanalysis.py:xl_getschema,xl_getschema,function,73,258,174,1953,7.57,4,8,"['dirxl', 'filepattern', 'dirlevel', 'outfile']","[None, None, None, None]","['""""', ""'*.xlsx'"", '1', ""'.xlsx'""]",237,"["" '''Take All excel in a folder and provide Table, Column Schema, type into master file\n"", "" '''\n""]","['xl_is_data_block_start', 'isnull', 'xl_find_start_block', 'xrange', '_xl_getschema', 'util.os_file_getname', 'load_workbook', 'print', 'wb.get_sheet_names', 'wb.get_sheet_by_name', 'gcol', 'str', 'np.array', 'unicode', 'np.column_stack', 'df_list.append', 'pd_stack_dflist', 'util.os_file_listall', 'enumerate', 'df0.append', 'util.pd_toexcel']",21
utilmy/zarchive/py2to3/datanalysis.py:str_to_unicode,str_to_unicode,function,4,16,12,99,6.19,0,2,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",318,[],"['isinstance', 'unicode']",2
utilmy/zarchive/py2to3/datanalysis.py:csv_dtypes_getdict,csv_dtypes_getdict,function,6,20,16,122,6.1,0,1,"['df', 'csvfile']","[None, None]","['None', 'None']",327,[],['pd.read_csv'],1
utilmy/zarchive/py2to3/datanalysis.py:csv_fast_processing,csv_fast_processing,function,0,0,0,0,0.0,0,0,[],[],[],334,"[""   '''\n"", '   http://word.bitly.com/post/74069870671/optimizing-text-processing\n', '\n', 'import sys\n', 'from collections import defaultdict\n', 'OUT_FILES = defaultdict(dict)\n', '\n', 'open_outfiles()  # open all files I could possibly need\n', '\n', 'for line in sys.stdin:\n', '    # 1. parse line for account_id and metric_type\n', ""    key = line.split(',')\n"", '    account_id = key[ACCOUNT_ID_INDEX][1:] # strip leading quote\n', '\n', '    # 2. write to appropriate file for account_id and metric_type\n', '    OUT_FILES[account_id][key[METRIC_TYPE_INDEX]].write(line)\n', '\n', '   close_outfiles()  # close all the files we opened\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/py2to3/datanalysis.py:csv_col_schema_toexcel,csv_col_schema_toexcel,function,87,292,206,2613,8.95,3,8,"['dircsv', 'filepattern', 'outfile', 'returntable', 'maxrow', 'maxcol_pertable', 'maxstrlen']","[None, None, None, None, None, None, None]","['""""', ""'*.csv'"", ""'.xlsx'"", '1', '5000000', '90', ""'U80'""]",356,"["" '''Take All csv in a folder and provide Table, Column Schema, type\n"", ' str(df[col].dtype)  USE str always, otherwise BIG Issue\n', '\n', 'METHOD FOR Unicode / ASCII issue\n', ""1. Decode early:  Decode to <type 'unicode'> ASAP\n"", ""    df['PREF_NAME']=       df['PREF_NAME'].apply(to_unicode)\n"", '2. Unicode everywhere\n', ""3. Encode late :f = open('/tmp/ivan_out.txt','w')\n"", ""                f.write(ivan_uni.encode('utf-8'))\n"", "" '''\n""]","['util.os_file_listall', 'len', 'np.array', 'enumerate', 'pd.read_csv', 'str', 'util.pd_toexcel', 'df.apply', 'np.zeros', 'xrange', 'float', 'gc.collect', 'pd.DataFrame', 'util.save', 'outfile.replace', 'print']",16
utilmy/zarchive/py2to3/datanalysis.py:csv_col_get_dict_categoryfreq,csv_col_get_dict_categoryfreq,function,39,81,63,551,6.8,4,4,"['dircsv', 'filepattern', 'category_cols', 'maxline', 'fileencoding']","[None, None, None, None, None]","[None, '""*.csv""', '[]', '-1', '""utf-8""']",447,"[""  ''' Find Category Freq in large CSV Transaction Column   '''\n""]","['datetime.now', 'defaultdict', 'util.os_file_listall', 'enumerate', 'line.split']",5
utilmy/zarchive/py2to3/datanalysis.py:csv_row_reduce_line,csv_row_reduce_line,function,23,82,62,474,5.78,1,5,"['fromfile', 'tofile', 'condfilter', 'catval_tokeep', 'maxline']","[None, None, None, None, None]","[None, None, None, None, '-1']",472,"[""  ''' Reduce Data Row by filtering on some Category\n"", '    file_category=  in1+ ""offers.csv""\n', '    ncol= 8\n', '    catval_tokeep=[ {} for i in xrange(0, ncol)]\n', '    for i, line in enumerate(open(file_category)):\n', '      ll=  line.split("","")\n', '      catval_tokeep[3][  ll[1] ]  = 1  # Offer_file_col1 --> Transact_file_col_4\n', '      catval_tokeep[4][  ll[3] ] =  1  # Offer_file_col3 --> Transact_file_col_4\n', '\n', '  def condfilter(colk, catval_tokeep) :\n', '    if colk[3] in catval_tokeep[3] or colk[4] in catval_tokeep[4]: return True\n', '    else: return False\n', ""  '''\n""]","['datetime.now', 'open', 'f.next', 'outfile.write', 'enumerate', 'line.split', 'condfilter']",7
utilmy/zarchive/py2to3/datanalysis.py:csv_analysis,csv_analysis,function,0,0,0,0,0.0,0,0,[],[],[],511,"[""   '''\n"", '   https://csvkit.readthedocs.io/en/540/tutorial/1_getting_started.html\n', '\n', '   sudo pip install csvkit\n', '\n', '   :return:\n', ""   '''\n""]",[],0
utilmy/zarchive/py2to3/datanalysis.py:csv_row_reduce_line_manual,csv_row_reduce_line_manual,function,26,79,53,495,6.27,2,4,"['file_category', 'file_transact', 'file_reduced']","[None, None, None]","[None, None, None]",520,"[""  ''' Reduce Data by filtering on some Category '''\n""]","['datetime.now', 'enumerate', 'line.split', 'open', 'outfile.write']",5
utilmy/zarchive/py2to3/datanalysis.py:csv_row_mapreduce,csv_row_mapreduce,function,19,29,26,278,9.59,2,0,"['dircsv', 'outfile', 'type_mapreduce', 'chunk']","[None, None, None, None]","['""""', '""""', ""'sum'"", ' 5000000']",549,"["" '''Take All csv in a folder and provide Table, Column Schema'''\n""]","['util.os_file_listall', 'pd.DataFrame', 'enumerate', 'xrange', 'pd.read_csv']",5
utilmy/zarchive/py2to3/datanalysis.py:csv_pivotable,csv_pivotable,function,13,57,38,576,10.11,1,4,"['dircsv', 'filepattern', 'fileh5', 'leftX', 'topY', 'centerZ', 'mapreduce', 'chunksize', 'tablename']","[None, None, None, None, None, None, None, None, None]","['""""', ""'*.csv'"", ""'.h5'"", ""'col0'"", ""'col2'"", ""'coli'"", ""'sum'"", ' 500000', ""'df'""]",565,"["" ''' return df Pivot Table from series of csv file (transfer to d5 temporary)\n"", '\n', 'Edit: you can groupby/sum from the store iteratively since this ""map-reduces"" over the chunks:\n', '\n', 'reduce(lambda x, y: x.add(y, fill_value=0),\n', ""       (df.groupby().sum() for df in store.select('df', chunksize=50000)))\n"", '\n', "" '''\n""]","['util.pd_h5_fromcsv_tohdfs', 'pd.HDFStore', 'store.select', 'pd.concat']",4
utilmy/zarchive/py2to3/datanalysis.py:csv_bigcompute,csv_bigcompute,function,0,1,1,4,4.0,0,0,[],[],[],594,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:db_getdata,db_getdata,function,0,1,1,4,4.0,0,0,[],[],[],601,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:db_sql,db_sql,function,0,1,1,4,4.0,0,0,[],[],[],604,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:db_meta_add,db_meta_add,function,26,85,61,762,8.96,1,4,"['metadb', 'dbname', 'new_table', '[]']","[None, None, None, None]","[None, None, ""(''"", None]",607,"[""   ''' Create Meta database to store infos on the tables : csv, zip, HFS, Postgres\n"", ""ALL_DB['japancoupon']= {}\n"", ""ALL_DB['japancoupon']['schema']=    df_schema\n"", ""ALL_DB['japancoupon']['df_table_uri']= df_schema_dictionnary\n"", ""ALL_DB['japancoupon']['df_table_columns']= df_schema_dict\n"", '        DBname, db_schema, db_table_uri, db_table_columns(dict_table->colum_list),\n', ""   '''\n""]","['pd_df_todict', 'df.drop_duplicates', 'xrange', 'dict0.setdefault']",4
utilmy/zarchive/py2to3/datanalysis.py:db_meta_find,db_meta_find,function,24,86,67,605,7.03,3,4,"['ALLDB', 'query', 'filter_db', 'filter_table', 'filter_column']","[None, None, None, None, None]","[None, ""''"", '[]', '[]', '[]']",644,"[""  ''' Find string in all the meta table name, column\n"", ""  db_meta_find(ALLDB, query='bottler', filter_db=['cokeon'],   filter_table=['table'], filter_column=['table'] )\n"", '  dbname: should be exact name\n', '  fitler_table: partial match is ok\n', '  fitler_column : partial name is ok\n', '  return   (dbname, meta_table_name,  meta_table_filtered_by_row_containing query)\n', ""  '''\n""]","['ALLDB.items', 'len', 'dbi.items', 'isinstance', 'util.str_match_fuzzy', 'list', 'util.find_fuzzy', 'util.pd_find', 'rs.append']",9
utilmy/zarchive/py2to3/datanalysis.py:col_study_getcategorydict_freq,col_study_getcategorydict_freq,function,17,26,25,402,15.46,1,0,['catedict'],[None],[None],675,"[""  ''' Generate Frequency of category : Id, Freq, Freqin%, CumSum%, ZScore\n"", '      given a dictionnary of category parsed previously\n', ""  '''\n""]","['catedict.items', 'util.pd_array_todataframe', 'df.sort_values', 'np.arange', 'catlist.append']",5
utilmy/zarchive/py2to3/datanalysis.py:col_feature_importance,col_feature_importance,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",690,"[""   ''' random forest for column importance '''\n""]",[],0
utilmy/zarchive/py2to3/datanalysis.py:col_study_distribution_show,col_study_distribution_show,function,22,96,71,982,10.23,3,3,"['df', 'col_include', 'col_exclude', ""pars={'binsize'""]","[None, None, None, '']","[None, 'None', 'None', ""{'binsize':20}""]",694,"["" '''  Perfom Full Study of the pandas columns'''\n""]","['np.count_nonzero', 'sorted', 'print', 'len', 'np.max', 'np.min', 'np.median', 'np.mean', 'np.std', 'plot_Y', 'plt.title', 'plt.plot', 'plt.hist', 'plt.show', 'plt.figure', 'np.percentile', 'range']",17
utilmy/zarchive/py2to3/datanalysis.py:col_study_summary,col_study_summary,function,18,57,53,604,10.6,1,3,"['Xmat', '0.0]', 'Xcolname', ""'col2']"", 'Xcolselect', '9]', 'isprint']","[None, None, None, None, None, None, None]","['[0.0', None, ""['col1'"", None, '[9', None, '0']",724,[],"['np.arange', 'len', 'print', 'np.min', 'np.max', 'np.median', 'np.mean', 'np.std', 'colanalysis.append', 'pd.DataFrame', 'np.shape']",11
utilmy/zarchive/py2to3/datanalysis.py:col_pair_plot,col_pair_plot,function,14,34,32,261,7.68,1,1,"['dfX', 'Xcolname_selectlist', 'dfY', 'Ycolname']","[None, None, None, None]","[None, 'None', 'None', 'None']",741,[],"['str', 'plt.scatter', 'plt.autoscale', 'plt.title', 'plt.show']",5
utilmy/zarchive/py2to3/datanalysis.py:col_pair_correl,col_pair_correl,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",755,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:col_pair_interaction,col_pair_interaction,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",758,"[""   ''' random forest for pairwise interaction '''\n""]",[],0
utilmy/zarchive/py2to3/datanalysis.py:plot_col_pair,plot_col_pair,function,1,4,4,66,16.5,0,0,"['dfX', 'Xcolname_selectlist', 'dfY', 'Ycolname']","[None, None, None, None]","[None, 'None', 'None', 'None']",762,[],['col_pair_plot'],1
utilmy/zarchive/py2to3/datanalysis.py:tf_transform_catlabel_toint,tf_transform_catlabel_toint,function,13,18,18,219,12.17,1,0,['Xmat'],[None],[None],768,"[""   '''\n"", '     # [""paris"", ""paris"", ""tokyo"", ""amsterdam""]  --> 2 ,5,6\n', '     # np.array(le.inverse_transform([2, 2, 1]))\n', '     le = preprocessing.LabelEncoder()\n', '     le.fit([""paris"", ""paris"", ""tokyo"", ""amsterdam""])\n', 'LabelEncoder()\n', 'list(le.classes_)\n', ""['amsterdam', 'paris', 'tokyo']\n"", 'le.transform([""tokyo"", ""tokyo"", ""paris""])\n', 'array([2, 2, 1]...)\n', 'list(le.inverse_transform([2, 2, 1]))\n', ""['tokyo', 'tokyo', 'paris']\n"", ""   '''\n""]","['xrange', 'le.get_params']",2
utilmy/zarchive/py2to3/datanalysis.py:tf_transform_pca,tf_transform_pca,function,3,4,4,78,19.5,0,0,"['Xmat', 'dimpca', 'whiten']","[None, None, None]","[None, '2', 'True']",793,"[""   '''Project ndim data into dimpca sub-space  '''\n""]","['pca=PCA', 'pca.transform']",2
utilmy/zarchive/py2to3/datanalysis.py:plot_distance_heatmap,plot_distance_heatmap,function,19,30,29,363,12.1,0,0,"['Xmat_dist', 'Xcolname']","[None, None]","[None, None]",802,[],"['pd.DataFrame', 'plt.figure', 'fig.add_subplot', 'ax.imshow', 'pyplot.get_cmap', 'ax.set_xlabel', 'ax.set_ylabel', 'ax.set_title', 'plt.colorbar']",9
utilmy/zarchive/py2to3/datanalysis.py:plot_cluster_2D,plot_cluster_2D,function,10,20,20,238,11.9,1,0,"['X_2dim', 'target_class', 'target_names']","[None, None, None]","[None, None, None]",817,"[""   ''' Plot 2d of Clustering Class,\n"", '       X2d: Nbsample x 2 dim  (projection on 2D sub-space)\n', ""   '''\n""]","['target_ids=xrange', 'len', 'pl.figure', 'zip', 'pl.scatter', 'pl.legend', 'pl.show']",7
utilmy/zarchive/py2to3/datanalysis.py:plot_cluster_tsne,plot_cluster_tsne,function,23,53,46,590,11.13,0,3,"['Xmat', 'Xcluster_label', 'metric', 'perplexity', 'ncomponent', 'savefile', 'isprecompute', 'returnval']","[None, None, None, None, None, None, None, None]","[None, 'None', ""'euclidean'"", '50', '2', ""''"", 'False', 'True']",829,"["" '''Plot High dimemnsionnal State using TSNE method\n"", ""   'euclidean, 'minkowski', 'cityblock', 'seuclidean', 'sqeuclidean, 'cosine, 'correlation, 'hamming, 'jaccard, 'chebyshev,\n"", ""   'canberra, 'braycurtis, 'mahalanobis', VI=None) 'yule, 'matching, 'dice, 'kulsinski, 'rogerstanimoto, 'russellrao, 'sokalmichener, 'sokalsneath,\n"", '\n', '   Xtsne= da.plot_cluster_tsne(Xtrain_dist, Xcluster_label=None, perplexity=40, ncomponent=2, isprecompute=True)\n', '\n', '   Xtrain_dist= sci.spatial.distance.squareform(sci.spatial.distance.pdist(Xtrain_d,\n', ""               metric='cityblock', p=2, w=None, V=None, VI=None))\n"", ""   '''\n""]","['np.set_printoptions', 'model.fit_transform', 'np.arange', 'plot_XY']",4
utilmy/zarchive/py2to3/datanalysis.py:plot_cluster_pca,plot_cluster_pca,function,22,51,44,480,9.41,0,3,"['Xmat', 'Xcluster_label', 'metric', 'dimpca', 'whiten', 'isprecompute', 'savefile', 'doreturn']","[None, None, None, None, None, None, None, None]","[None, 'None', ""'euclidean'"", '2', 'True', 'False', ""''"", '1']",857,[],"['PCA', 'model.fit_transform', 'np.zeros', 'plot_XY']",4
utilmy/zarchive/py2to3/datanalysis.py:plot_cluster_hiearchy,plot_cluster_hiearchy,function,29,84,76,941,11.2,1,3,"['Xmat_dist', 'p', 'truncate_mode', 'color_threshold', 'get_leaves', 'orientation', 'labels', 'count_sort', 'distance_sort', 'show_leaf_counts', 'no_plot', 'no_labels', 'leaf_font_size', 'leaf_rotation', 'leaf_label_func', 'show_contracted', 'link_color_func', 'ax', 'above_threshold_color']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]","[None, '30', 'None', 'None', 'True', ""'top'"", 'None', 'False', 'False', 'True', 'False', 'False', 'None', 'None', 'None', 'False', 'None', 'None', ""'b'""]",874,[],"['dendrogram', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'zip', 'sum', 'plt.plot', 'plt.annotate', 'plt.axhline']",9
utilmy/zarchive/py2to3/datanalysis.py:plot_distribution_density,plot_distribution_density,function,28,58,52,631,10.88,0,0,"['Xsample', 'kernel', 'N', 'bandwith']","[None, None, None, None]","[None, ""'gaussian'"", '10', '1 / 10.0']",902,[],"['plt.subplots', 'len', 'np.min', 'np.max', 'np.linspace', 'np.ones_like', 'np.ones', 'ax.hist', 'kde.score_samples', 'np.log', 'ax.plot', 'np.exp', 'ax.set_xlim', 'plt.show']",14
utilmy/zarchive/py2to3/datanalysis.py:plot_Y,plot_Y,function,4,7,7,88,12.57,0,0,"['Yval', 'typeplot', 'tsize', 'labels', 'title', 'xlabel', 'ylabel', 'zcolor_label', 'figsize', '6']","[None, None, None, None, None, None, None, None, None, None]","[None, ""'.b'"", 'None', 'None', ""''"", ""''"", ""''"", ""''"", '(8', None]",944,[],"['plt.figure', 'plt.title', 'plt.plot', 'plt.show']",4
utilmy/zarchive/py2to3/datanalysis.py:plot_XY,plot_XY,function,72,197,147,1805,9.16,0,7,"['xx', 'yy', 'zcolor', 'tsize', 'labels', 'title', 'xlabel', 'ylabel', 'zcolor_label', 'figsize', '6']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', ""''"", ""''"", ""''"", ""''"", '(8', None]",950,"[""  '''\n"", '      labels= numpy array, ---> Generate HTML File with the labels interactives\n', '      Color: Plasma\n', ""  '''\n""]","['isinstance', 'np.array', 'np.abs', 'plt.get_cmap', 'np.min', 'plt.subplots', 'fig.set_size_inches', 'fig.set_dpi', 'fig.tight_layout', 'ax1.scatter', 'ax1.set_xlabel', 'ax1.set_ylabel', 'ax1.set_title', 'ax1.grid', 'np.max', 'scatter.set_clim', 'fig.colorbar', 'cb.set_label', 'list', 'mpld3.save_html', 'plt.show', 'util.os_folder_create', 'plt.savefig', 'plot_XY_plotly', 'go.Scatter', 'py.iplot', 'py.plot', 'plot_XY_seaborn', 'sns.set_context', 'sns.set_color_codes', 'sns.color_palette', 'np.unique', 'plt.scatter', 'plt.gca', 'plt.title']",35
utilmy/zarchive/py2to3/datanalysis.py:plot_XY_plotly,plot_XY_plotly,function,15,31,26,261,8.42,0,1,"['xx', 'yy', 'towhere']","[None, None, None]","[None, None, ""'url'""]",1016,"[""  ''' Create Interactive Plotly   '''\n""]","['go.Scatter', 'py.iplot', 'py.plot']",3
utilmy/zarchive/py2to3/datanalysis.py:plot_XY_seaborn,plot_XY_seaborn,function,14,44,42,400,9.09,0,1,"['X', 'Y', 'Zcolor']","[None, None, None]","[None, None, 'None']",1038,[],"['sns.set_context', 'sns.set_color_codes', 'sns.color_palette', 'np.unique', 'plt.scatter', 'plt.gca', 'plt.title']",7
utilmy/zarchive/py2to3/datanalysis.py:optim_is_pareto_efficient,optim_is_pareto_efficient,function,15,35,31,304,8.69,1,2,"['Xmat_cost', 'epsilon', 'ret_boolean']","[None, None, None]","[None, ' 0.01', '1']",1080,"['    """""" Calculate Pareto Frontier of Multi-criteria Optimization program\n', '    c1, c2  has to be minimized : -Sharpe, -Perf, +Drawdown\n', '    :param Xmat_cost: An (n_points, k_costs) array\n', '    :return: A (n_points, ) boolean array, indicating whether each point is Pareto efficient\n', '    """"""\n']","['np.ones', 'enumerate', 'np.any']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_model_auto_tpot,sk_model_auto_tpot,function,21,41,36,560,13.66,0,1,"['Xmat', 'y', 'outfolder', 'model_type', 'train_size', 'generation', 'population_size', 'verbosity']","[None, None, None, None, None, None, None, None]","[None, None, ""'aaserialize/'"", ""'regressor/classifier'"", '0.5', '1', '5', '2']",1098,"[""  ''' Automatic training of Xmat--->Y, Generate SKlearn code in outfile\n"", '      Very Slow Process, use lower number of Sample\n', '  :param Xmat:\n', '  :param y:\n', '  :param outfolder:\n', '  :param model_type:\n', '  :param train_size:\n', '  :param generation: \n', '  :param population_size:\n', '  :param verbosity:\n', '  :return:\n', ""  '''\n""]","['train_test_split', 'TPOTRegressor', 'TPOTClassifier', 'tpot.fit', 'print', 'str', 'tpot.export']",7
utilmy/zarchive/py2to3/datanalysis.py:sk_params_search_best,sk_params_search_best,function,30,61,51,826,13.54,0,3,"['Xmat', 'Ytarget', 'model1', ""param_grid={'alpha'"", '1', '5) }', 'method', ""param_search= {'scoretype'"", ""'cv'"", ""'population_size'"", ""'generations_number'""]","[None, None, None, '', None, None, None, '', '5', '5', '3 }']","[None, None, None, ""{'alpha':  np.linspace(0"", None, None, ""'gridsearch'"", "" {'scoretype':'r2'"", None, None, None]",1126,"[""  '''\n"", '   genetic: population_size=5, ngene_mutation_prob=0.10,,gene_crossover_prob=0.5, tournament_size=3,  generations_number=3\n', '\n', '  :param Xmat:\n', '  :param Ytarget:\n', '  :param model1:\n', '  :param param_grid:\n', '  :param method:\n', '  :param param_search:\n', '  :return:\n', ""  '''\n""]","['make_scorer', 'GridSearchCV', 'grid.fit', 'EvolutionaryAlgorithmSearchCV', 'cv=StratifiedKFold', 'cv.fit']",6
utilmy/zarchive/py2to3/datanalysis.py:sk_distribution_kernel_bestbandwidth,sk_distribution_kernel_bestbandwidth,function,8,17,17,176,10.35,0,0,['kde'],[None],[None],1193,"["" '''Find best Bandwidht for a  given kernel\n"", '  :param kde:\n', '  :return:\n', "" '''\n""]","['GridSearchCV', 'np.linspace', 'grid.fit']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_distribution_kernel_sample,sk_distribution_kernel_sample,function,15,31,29,212,6.84,1,0,"['kde', 'n']","[None, None]","['None', '1']",1204,"["" ''' \n"", '  kde = sm.nonparametric.KDEUnivariate(np.array(Y[Y_cluster==0],dtype=np.float64))\n', '  kde = sm.nonparametric.KDEMultivariate()  # ... you already did this\n', "" '''\n""]","['np.zeros', 'func', 'kde.cdf', 'xrange', 'brentq']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_correl_rank,sk_correl_rank,function,16,38,31,291,7.66,2,0,"['correl', '0]', '[0', '1]]']","[None, None, None, None]","['[[1', None, None, None]",1222,"[' """""" Correl Ranking:  Col i, Col j, Correl_i_j, Abs_Correl_i_j    """"""\n']","['np.shape', 'np.zeros', 'xrange', 'abs', 'util.sortcol']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_error_r2,sk_error_r2,function,8,19,16,175,9.21,0,1,"['Ypred', 'y_true', 'sample_weight', 'multioutput']","[None, None, None, None]","[None, None, 'None', 'None']",1237,[],"['r2_score', 'np.sign']",2
utilmy/zarchive/py2to3/datanalysis.py:sk_error_rmse,sk_error_rmse,function,6,10,10,100,10.0,0,0,"['Ypred', 'Ytrue']","[None, None]","[None, None]",1244,[],"['np.sqrt', 'len', 'np.std']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_cluster_distance_pair,sk_cluster_distance_pair,function,5,16,14,195,12.19,0,2,"['Xmat', 'metric']","[None, None]","[None, ""'jaccard'""]",1248,"[""   '''\n"", ""    'euclidean, 'minkowski', 'cityblock', 'seuclidean', 'sqeuclidean, 'cosine, 'correlation, 'hamming, 'jaccard, 'chebyshev, 'canberra, 'braycurtis, 'mahalanobis', VI=None) 'yule, 'matching, 'dice, 'kulsinski, 'rogerstanimoto, 'russellrao, 'sokalmichener, 'sokalsneath,\n"", '\n', ""    'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance,\n"", "" 'canberra': hdbscan.dist_metrics.CanberraDistance,\n"", "" 'chebyshev': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'cityblock': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'dice': hdbscan.dist_metrics.DiceDistance,\n"", "" 'euclidean': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'hamming': hdbscan.dist_metrics.HammingDistance,\n"", "" 'haversine': hdbscan.dist_metrics.HaversineDistance,\n"", "" 'infinity': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'jaccard': hdbscan.dist_metrics.JaccardDistance,\n"", "" 'kulsinski': hdbscan.dist_metrics.KulsinskiDistance,\n"", "" 'l1': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'l2': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance,\n"", "" 'manhattan': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'matching': hdbscan.dist_metrics.MatchingDistance,\n"", "" 'minkowski': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'p': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'pyfunc': hdbscan.dist_metrics.PyFuncDistance,\n"", "" 'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance,\n"", "" 'russellrao': hdbscan.dist_metrics.RussellRaoDistance,\n"", "" 'seuclidean': hdbscan.dist_metrics.SEuclideanDistance,\n"", "" 'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance,\n"", "" 'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance,\n"", "" 'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance}\n"", '   #Visualize discretization scheme\n', '\n', '   Xtrain_dist= sci.spatial.distance.squareform(sci.spatial.distance.pdist(Xtrain_d,\n', ""             metric='cityblock', p=2, w=None, V=None, VI=None))\n"", '\n', ""   Xtsne= da.plot_cluster_tsne(Xtrain_dist, metric='', perplexity=40, ncomponent=2, isprecompute=True)\n"", '\n', ""   '''\n""]",['fast.distance_jaccard_X'],1
utilmy/zarchive/py2to3/datanalysis.py:sk_cluster,sk_cluster,function,52,174,123,1637,9.41,2,11,"['Xmat', 'metric']","[None, None]","[None, ""'jaccard'""]",1290,[],"['fast.distance_jaccard_X', 'sk_cluster', 'hdbscan.HDBSCAN', 'print', 'len', 'np.std', 'np.mean', 'Xmat.reshape', 'k_means', 'KMeans', 'kmeans.fit', 'range', 'plt.plot', 'plt.show', 'sk_cluster_algo_custom', 'algorithm']",16
utilmy/zarchive/py2to3/datanalysis.py:sk_cluster_algo_custom,sk_cluster_algo_custom,function,9,17,15,172,10.12,0,1,"['Xmat', 'algorithm', 'args', 'kwds', 'returnval']","[None, None, None, None, None]","[None, None, None, None, '1']",1353,"[""    ''' Plot the cLuster using specific Algo\n"", '    distance_matrix = pairwise_distances(blobs)\n', ""    clusterer = hdbscan.HDBSCAN(metric='precomputed')\n"", '    clusterer.fit(distance_matrix)\n', '    clusterer.labels_\n', '\n', ""    {'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance,\n"", "" 'canberra': hdbscan.dist_metrics.CanberraDistance,\n"", "" 'chebyshev': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'cityblock': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'dice': hdbscan.dist_metrics.DiceDistance,\n"", "" 'euclidean': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'hamming': hdbscan.dist_metrics.HammingDistance,\n"", "" 'haversine': hdbscan.dist_metrics.HaversineDistance,\n"", "" 'infinity': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'jaccard': hdbscan.dist_metrics.JaccardDistance,\n"", "" 'kulsinski': hdbscan.dist_metrics.KulsinskiDistance,\n"", "" 'l1': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'l2': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance,\n"", "" 'manhattan': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'matching': hdbscan.dist_metrics.MatchingDistance,\n"", "" 'minkowski': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'p': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'pyfunc': hdbscan.dist_metrics.PyFuncDistance,\n"", "" 'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance,\n"", "" 'russellrao': hdbscan.dist_metrics.RussellRaoDistance,\n"", "" 'seuclidean': hdbscan.dist_metrics.SEuclideanDistance,\n"", "" 'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance,\n"", "" 'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance,\n"", "" 'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance}\n"", '\n', ""    '''\n""]","['algorithm', 'print', 'len']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_optim_de,sk_optim_de,function,37,127,96,1179,9.28,1,4,"['obj_fun', 'bounds', 'maxiter', 'name1', 'solver1', 'isreset', 'popsize']","[None, None, None, None, None, None, None]","[None, None, '1', ""''"", 'None', '1', '15']",1426,"[""    ''' Optimization and Save Data into file'''\n""]","['print', 'load_obj', 'int', 'copy.deepcopy', 'xrange', 'next', 'util.save_obj', 'util.date_now', 'util.np_int_tostr', 'np.mod', 'np.abs']",11
utilmy/zarchive/py2to3/datanalysis.py:sk_feature_importance,sk_feature_importance,function,9,20,20,228,11.4,1,1,"['clfrf', 'feature_name']","[None, None]","[None, None]",1529,[],"['np.argsort', 'range', 'len', 'str']",4
utilmy/zarchive/py2to3/datanalysis.py:sk_showconfusion,sk_showconfusion,function,11,22,21,244,11.09,0,1,"['clfrf', 'X_train', 'Y_train', 'isprint']","[None, None, None, None]","[None, None, None, 'True']",1537,[],"['clfrf.predict', 'cm.astype', 'cm.sum', 'print']",4
utilmy/zarchive/py2to3/datanalysis.py:sk_tree,sk_tree,function,13,33,32,445,13.48,0,1,"['Xtrain', 'Ytrain', 'nbtree', 'maxdepth', 'isprint1', 'njobs']","[None, None, None, None, None, None]","[None, None, None, None, '1', '1']",1546,[],"['clfrf.fit', 'clfrf.predict', 'cm.astype', 'cm.sum', 'print']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_gen_ensemble_weight,sk_gen_ensemble_weight,function,14,29,27,213,7.34,1,0,"['vv', 'acclevel', 'maxlevel']","[None, None, None]","[None, None, '0.88']",1558,[],"['min', 'np.empty', 'range', 'estww.append', 'np.log', 'np.array']",6
utilmy/zarchive/py2to3/datanalysis.py:sk_votingpredict,sk_votingpredict,function,19,33,28,267,8.09,2,1,"['estimators', 'voting', 'ww', 'X_test']","[None, None, None, None]","[None, None, None, None]",1572,[],"['np.zeros', 'enumerate', 'clf.predict_proba', 'range', 'len']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_tree_get_ifthen,sk_tree_get_ifthen,function,26,91,64,774,8.51,2,3,"['tree', 'feature_names', 'target_names', 'spacer_base']","[None, None, None, None]","[None, None, None, '"" ""']",1587,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['recurse', 'print', 'str', 'zip', 'int']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_model_template1,sk_model_template1,class,39,143,86,1191,8.33,0,3,[],[],[],1473,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:sk_stateRule,sk_stateRule,class,38,138,104,1118,8.1,0,5,[],[],[],1658,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:sk_model_template1:__init__,sk_model_template1:__init__,method,10,13,13,166,12.77,0,0,"['self', 'alpha', 'low_y_cut', 'high_y_cut', 'ww0']","[None, None, None, None, None]","[None, '0.5', '-0.09', '0.09', '0.95']",1474,[],['Ridge'],1
utilmy/zarchive/py2to3/datanalysis.py:sk_model_template1:fit,sk_model_template1:fit,method,17,46,40,465,10.11,0,1,"['self', 'X', 'Y']","[None, None, None]","[None, None, 'None']",1480,[],"['len', 'print', 'np.median']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_model_template1:predict,sk_model_template1:predict,method,10,27,21,166,6.15,0,1,"['self', 'X', 'y', 'ymedian']","[None, None, None, None]","[None, None, 'None', 'None']",1498,[],['Y.clip'],1
utilmy/zarchive/py2to3/datanalysis.py:sk_model_template1:score,sk_model_template1:score,method,14,32,27,216,6.75,0,1,"['self', 'X', 'Ytrue', 'ymedian']","[None, None, None, None]","[None, None, 'None', 'None']",1509,[],"['Y.clip', 'r2_score']",2
utilmy/zarchive/py2to3/datanalysis.py:sk_stateRule:__init__,sk_stateRule:__init__,method,8,44,37,371,8.43,0,1,"['self', 'state', 'trigger', 'colname']","[None, None, None, None]","[None, None, None, '[]']",1661,[],"['np.empty', 'np.shape', 'len', 'xrange', 'util.np_torecarray']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_stateRule:addrule,sk_stateRule:addrule,method,20,47,42,381,8.11,0,2,"['self', 'rulefun', 'name', 'desc']","[None, None, None, None]","[None, None, ""''"", ""''""]",1673,[],"['util.findnone', 'util.find', 'print', 'util.np_addcolumn', 'rulefun', 'copy.deepcopy']",6
utilmy/zarchive/py2to3/datanalysis.py:sk_stateRule:eval,sk_stateRule:eval,method,9,29,24,231,7.97,0,2,"['self', 'idrule', 't', 'ktrig']","[None, None, None, None]","[None, None, None, '0']",1691,[],"['isinstance', 'util.find', 'print']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_stateRule:help,sk_stateRule:help,method,0,0,0,0,0.0,0,0,[],[],[],1699,"[""    '''\n"", 's1= np.arange(5000).reshape((1000, 5))\n', 'trig1= np.ones((1,5))\n', ""state1= sk_stateRule(aa, trig1, ['drawdown','ma100d','ret10d','state_1','state_2'] )\n"", '\n', 'def fun1(s, tr,t):\n', '  return  s.drawdown[t] < tr.drawdown[0] and  s.drawdown[t] < tr.drawdown[0]\n', '\n', 'def fun2(s, tr,t):\n', ' return  s.drawdown[t] > tr.drawdown[0] and  s.drawdown[t] < tr.drawdown[0]\n', '\n', ""state1.addrule(fun1, 'rule6')\n"", ""state1.addrule(fun2, 'rule5')\n"", '\n', 'state1.eval(idrule=0,t=5)\n', '\n', 'state1.eval(idrule=1,t=5)\n', '\n', ""state1.eval(idrule='rule5',t=6)\n"", '\n', ""util.save_obj(state1, 'state1')\n"", '\n', 'np.shape(aa2)\n', '\n', ""aa2= util.np_torecarray(aa,  ['drawdown','a2','a3','a4','a5'])\n"", '\n', 'util.find(5.0, aa2[0])\n', '\n', 'recordarr = np.rec.array([(1,2.,7),(2,3.,5)],\n', ""                   dtype=[('col1', 'f8'),('col2', 'f8'), ('col3', 'f8')])\n"", 'recordarr.col3[0]\n', '\n', 'state1= stateRule(np.ones((100,10)), np.ones((1,10)))\n', '\n', 'col= aa2.a2\n', '\n', ""'''\n""]",[],0
utilmy/zarchive/py2to3/excel.py:get_workbook_name,get_workbook_name,function,3,5,5,48,9.6,0,0,[],[],[],9,"['    """"""Writes the name of the Workbook into Range(""D3"") of Sheet 1""""""\n']","['Workbook.caller', 'Range']",2
utilmy/zarchive/py2to3/excel.py:double_sum,double_sum,function,1,4,4,13,3.25,0,0,"['x', 'y']","[None, None]","[None, None]",16,"['    """"""Returns twice the sum of the two arguments""""""\n']",[],0
utilmy/zarchive/py2to3/excel.py:add_one,add_one,function,5,11,9,40,3.64,2,0,['data'],[None],[None],23,"['    """"""Adds 1 to every cell in Range""""""\n']",[],0
utilmy/zarchive/py2to3/excel.py:matrix_mult,matrix_mult,function,2,2,2,14,7.0,0,0,"['x', 'y']","[None, None]","[None, None]",31,"['    """"""Alternative implementation of Excel\'s MMULT, requires NumPy""""""\n']",['x.dot'],1
utilmy/zarchive/py2to3/excel.py:npdot,npdot,function,0,0,0,0,0.0,0,0,[],[],[],43,[],[],0
utilmy/zarchive/py2to3/fast.py:day,day,function,9,15,14,125,8.33,0,0,['s)'],['    return int(s[8:10])s):  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],130,[],['arrow.get'],1
utilmy/zarchive/py2to3/fast.py:month,month,function,9,15,14,125,8.33,0,0,['s)'],['  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],131,[],['arrow.get'],1
utilmy/zarchive/py2to3/fast.py:year,year,function,9,15,14,125,8.33,0,0,['s)'],['   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],132,[],['arrow.get'],1
utilmy/zarchive/py2to3/fast.py:hour,hour,function,9,15,14,125,8.33,0,0,['s)'],['   return int(s[11:13])cache_weekday'],[' {}s):'],133,[],['arrow.get'],1
utilmy/zarchive/py2to3/fast.py:weekday,weekday,function,9,15,14,125,8.33,0,0,['s'],[None],[None],139,[],['arrow.get'],1
utilmy/zarchive/py2to3/fast.py:season,season,function,4,15,13,47,3.13,0,1,['d'],[None],[None],148,[],['int'],1
utilmy/zarchive/py2to3/fast.py:daytime,daytime,function,5,40,23,123,3.08,0,1,['d'],[None],[None],154,[],['int'],1
utilmy/zarchive/py2to3/fast.py:fastStrptime,fastStrptime,function,8,46,35,288,6.26,0,2,"['val', 'format']","[None, None]","[None, None]",164,[],"['len', 'int', 'datetime.datetime']",3
utilmy/zarchive/py2to3/fast.py:drawdown_calc_fast,drawdown_calc_fast,function,36,80,63,618,7.72,1,3,['price'],[None],[None],190,[],"['len', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/fast.py:std,std,function,6,12,12,61,5.08,0,0,['x'],[None],[None],225,"['    """"""Std Deviation 1D array""""""\n']","['x.sum', 'sqrt']",2
utilmy/zarchive/py2to3/fast.py:mean,mean,function,2,3,3,24,8.0,0,0,['x'],[None],[None],236,"['    """"""Mean  """"""\n']",['x.sum'],1
utilmy/zarchive/py2to3/fast.py:_compute_overlaps,_compute_overlaps,function,13,27,20,108,4.0,1,0,"['u', 'v']","[None, None]","[None, None]",249,[],['xrange'],1
utilmy/zarchive/py2to3/fast.py:distance_jaccard2,distance_jaccard2,function,5,11,11,55,5.0,0,0,"['u', 'v']","[None, None]","[None, None]",260,[],"['_compute_overlaps', 'float']",2
utilmy/zarchive/py2to3/fast.py:distance_jaccard,distance_jaccard,function,5,11,11,55,5.0,0,0,"['u', 'v']","[None, None]","[None, None]",266,[],"['_compute_overlaps', 'float']",2
utilmy/zarchive/py2to3/fast.py:distance_jaccard_X,distance_jaccard_X,function,13,21,19,163,7.76,2,0,['X'],[None],[None],277,[],"['np.zeros', 'xrange', 'distance_jaccard']",3
utilmy/zarchive/py2to3/fast.py:cosine,cosine,function,11,43,26,262,6.09,0,2,"['u', 'v']","[None, None]","[None, None]",292,[],['np.sqrt'],1
utilmy/zarchive/py2to3/fast.py:rmse,rmse,function,1,7,6,31,4.43,0,0,"['y', 'yhat']","[None, None]","[None, None]",321,"['    """""" Calculate and return Root Mean Squared Error (RMSE)\n', '    Returns: float: Root Mean Squared Error\n', '    """"""\n']",[],0
utilmy/zarchive/py2to3/fast.py:cross,cross,function,17,31,25,211,6.81,0,0,"['vec1', 'vec2']","[None, None]","[None, None]",329,"['    """""" Calculate the dot product of two 3d vectors. """"""\n']","['double', 'np.zeros']",2
utilmy/zarchive/py2to3/fast.py:norm,norm,function,4,8,8,61,7.62,1,0,['vec'],[None],[None],341,"['    """""" Calculate the norm of a 3d vector. """"""\n']","['sqrt', 'range']",2
utilmy/zarchive/py2to3/fast.py:log_exp_sum2,log_exp_sum2,function,0,1,1,5,5.0,0,0,"['a', 'b']","[None, None]","[None, None]",242,[],[],0
utilmy/zarchive/py2to3/fast_parallel.py:task_summary,task_summary,function,4,17,17,142,8.35,1,0,['tasks'],[None],[None],76,[],"['print', 'enumerate', 't.get']",3
utilmy/zarchive/py2to3/fast_parallel.py:task_progress,task_progress,function,8,26,23,161,6.19,1,1,['tasks'],[None],[None],83,"[""  ''' Monitor progress '''\n""]","['np.mean', 'print']",2
utilmy/zarchive/py2to3/fast_parallel.py:task_find_best,task_find_best,function,3,11,11,80,7.27,0,0,"['tasks', 'n_top']","[None, None]","[None, '5']",94,"['    """"""Compute the best score of tasks_folder""""""\n']","['t.ready', 'sorted']",2
utilmy/zarchive/py2to3/fast_parallel.py:task_parallel_job_01,task_parallel_job_01,function,19,33,32,336,10.18,0,0,"['name', 'param', 'datadict']","[None, None, None]","[None, None, None]",101,"[""   ''' Sample task run in Parallel '''\n""]","['os.chdir', 'util.a_run_ipython', 'str']",3
utilmy/zarchive/py2to3/filelock.py:FileLock,FileLock,class,41,133,94,1246,9.37,2,6,[],[],[],36,[],[],0
utilmy/zarchive/py2to3/filelock.py:FileLock:__init__,FileLock:__init__,method,11,27,23,279,10.33,1,1,"['self', 'protected_file_path', 'timeout', 'delay', 'lock_file_contents']","[None, None, None, None, None]","[None, None, 'None', '1', 'None']",53,"['        """""" Prepare the file locker. Specify the file to lock and optionally\n', '            the maximum timeout and the delay between each attempt to lock.\n', '        """"""\n']",[],0
utilmy/zarchive/py2to3/filelock.py:FileLock:locked,FileLock:locked,method,2,2,2,20,10.0,0,0,['self'],[None],[None],67,"['        """"""\n', '        Returns True iff the file is owned by THIS FileLock instance.\n', '        (Even if this returns false, the file could be owned by another FileLock instance, possibly in a different thread or process).\n', '        """"""\n']",[],0
utilmy/zarchive/py2to3/filelock.py:FileLock:available,FileLock:available,method,2,3,3,38,12.67,0,0,['self'],[None],[None],74,"['        """"""\n', '        Returns True iff the file is currently available to be locked.\n', '        """"""\n']",[],0
utilmy/zarchive/py2to3/filelock.py:FileLock:acquire,FileLock:acquire,method,18,55,48,410,7.45,1,3,"['self', 'blocking']","[None, None]","[None, 'True']",80,"['        """""" Acquire the lock, if possible. If the lock is in use, and `blocking` is False, return False.\n', '            Otherwise, check again every `self.delay` seconds until it either gets the lock or\n', '            exceeds `timeout` number of seconds, in which case it raises an exception.\n', '        """"""\n']","['time.time', 'os.open', 'os.fdopen', 'f.write', 'FileLock.FileLockException', 'time.sleep']",6
utilmy/zarchive/py2to3/filelock.py:FileLock:release,FileLock:release,method,2,3,3,45,15.0,0,0,['self'],[None],[None],106,"['        """""" Get rid of the lock by deleting the lockfile.\n', '            When working in a `with` statement, this gets automatically\n', '            called at the end.\n', '        """"""\n']",['os.unlink'],1
utilmy/zarchive/py2to3/filelock.py:FileLock:__enter__,FileLock:__enter__,method,2,3,3,25,8.33,0,0,['self'],[None],[None],115,"['        """""" Activated when used in the with statement.\n', '            Should automatically acquire a lock to be used in the with block.\n', '        """"""\n']",['self.acquire'],1
utilmy/zarchive/py2to3/filelock.py:FileLock:__exit__,FileLock:__exit__,method,1,1,1,14,14.0,0,0,"['self', 'type', 'value', 'traceback']","[None, None, None, None]","[None, None, None, None]",123,"['        """""" Activated at the end of the with statement.\n', ""            It automatically releases the lock if it isn't locked.\n"", '        """"""\n']",['self.release'],1
utilmy/zarchive/py2to3/filelock.py:FileLock:__del__,FileLock:__del__,method,2,3,3,32,10.67,0,1,['self'],[None],[None],130,"['        """""" Make sure this ``FileLock`` instance doesn\'t leave a .lock file\n', '            lying around.\n', '        """"""\n']",['self.release'],1
utilmy/zarchive/py2to3/filelock.py:FileLock:purge,FileLock:purge,method,3,7,6,70,10.0,0,1,['self'],[None],[None],137,"['        """"""\n', '        For debug purposes only.  Removes the lock file from the hard disk.\n', '        """"""\n']",['self.release'],1
utilmy/zarchive/py2to3/function_custom.py:mapping_calc_risk_elvis_v03,mapping_calc_risk_elvis_v03,function,4,9,9,63,7.0,0,0,"['ss', 'tr', 't', 'riskout']","[None, None, None, None]","[None, None, None, None]",18,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",['mapping_calc_risk_v01'],1
utilmy/zarchive/py2to3/function_custom.py:mapping_calc_risk_v02,mapping_calc_risk_v02,function,18,190,75,704,3.71,0,2,"['ss', 'tr', 't', 'risk0']","[None, None, None, None]","[None, None, None, None]",31,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",[],0
utilmy/zarchive/py2to3/function_custom.py:mapping_calc_risk_v01,mapping_calc_risk_v01,function,19,130,56,532,4.09,0,2,"['ss', 'tr', 't', 'risk0']","[None, None, None, None]","[None, None, None, None]",72,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",[],0
utilmy/zarchive/py2to3/function_custom.py:mapping_risk_ww_v01,mapping_risk_ww_v01,function,12,56,29,245,4.38,0,1,"['risk', 'wwmat', 'ww2']","[None, None, None]","[None, None, None]",98,[],"['np.sum', 'np.array']",2
utilmy/zarchive/py2to3/function_custom.py:mapping_calc_risk_v00,mapping_calc_risk_v00,function,16,68,45,286,4.21,0,1,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",107,[],[],0
utilmy/zarchive/py2to3/function_custom.py:getweight,getweight,function,7,13,12,70,5.38,0,1,"['ww', 'size', '3']","[None, None, None]","[None, '(9', None]",133,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/py2to3/function_custom.py:fun_obj,fun_obj,function,6,11,11,120,10.91,0,0,"['vv', 'ext']","[None, None]","[None, None]",139,[],"['pf.folio_volta', 'int', 'pf.volhisto_fromprice', 'len']",4
utilmy/zarchive/py2to3/geospatial.py:coordinates_box,coordinates_box,class,1,2,2,16,8.0,0,0,[],[],[],33,[],[],0
utilmy/zarchive/py2to3/kagglegym.py:r_score,r_score,function,4,15,12,146,9.73,0,1,"['y_true', 'y_pred', 'sample_weight', 'multioutput']","[None, None, None, None]","[None, None, 'None', 'None']",77,[],['r2_score'],1
utilmy/zarchive/py2to3/kagglegym.py:make,make,function,2,2,2,19,9.5,0,0,[],[],[],175,[],['Environment'],1
utilmy/zarchive/py2to3/kagglegym.py:Observation,Observation,class,7,11,11,99,9.0,0,0,[],[],[],86,[],[],0
utilmy/zarchive/py2to3/kagglegym.py:Environment,Environment,class,49,148,101,1719,11.61,0,1,[],[],[],93,[],[],0
utilmy/zarchive/py2to3/kagglegym.py:Observation:__init__,Observation:__init__,method,6,6,6,58,9.67,0,0,"['self', 'train', 'target', 'features']","[None, None, None, None]","[None, None, None, None]",87,[],[],0
utilmy/zarchive/py2to3/kagglegym.py:Environment:__init__,Environment:__init__,method,21,37,35,452,12.22,0,0,['self'],[None],[None],94,[],"['pd.HDFStore', 'hfdata.get', 'len', 'int']",4
utilmy/zarchive/py2to3/kagglegym.py:Environment:reset,Environment:reset,method,16,36,34,403,11.19,0,0,['self'],[None],[None],115,[],"['int', 'Observation']",2
utilmy/zarchive/py2to3/kagglegym.py:Environment:step,Environment:step,method,29,64,52,765,11.95,0,1,"['self', 'target']","[None, None]","[None, None]",135,[],"['r_score', 'Observation']",2
utilmy/zarchive/py2to3/kagglegym.py:Environment:__str__,Environment:__str__,method,1,2,2,21,10.5,0,0,['self'],[None],[None],171,[],[],0
utilmy/zarchive/py2to3/linux.py:load_session,load_session,function,4,7,7,86,12.29,0,0,['name'],[None],"[""'test_20160815'""]",100,[],['dill.load_session'],1
utilmy/zarchive/py2to3/linux.py:save_session,save_session,function,6,9,9,107,11.89,0,0,['name'],[None],"[""''""]",106,[],"['date_now', 'dill.dump_session']",2
utilmy/zarchive/py2to3/linux.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],121,[],['float'],1
utilmy/zarchive/py2to3/linux.py:isint,isint,function,6,15,14,80,5.33,0,1,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, None, '']","[None, None, None, None, None, None]",129,[],['txt.find'],1
utilmy/zarchive/py2to3/linux.py:aa_isanaconda,aa_isanaconda,function,6,15,14,80,5.33,0,1,[],[],[],132,[],['txt.find'],1
utilmy/zarchive/py2to3/linux.py:aa_cleanmemory,aa_cleanmemory,function,3,3,3,21,7.0,0,0,[],[],[],147,[],['gc.collect'],1
utilmy/zarchive/py2to3/linux.py:aa_getmodule_doc,aa_getmodule_doc,function,8,13,13,110,8.46,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",150,[],"['ca.getmodule_doc', 'np.isnan', 'z.nonzero']",3
utilmy/zarchive/py2to3/linux.py:np_interpolate_nan,np_interpolate_nan,function,7,9,9,78,8.67,0,0,['y'],[None],[None],1176,[],"['__np_nan_helper', 'np.interp', 'x']",3
utilmy/zarchive/py2to3/linux.py:and1,and1,function,8,55,22,356,6.47,0,6,"['x', 'y', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']","[None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None', 'None', 'None']",1182,[],[],0
utilmy/zarchive/py2to3/linux.py:sortcol,sortcol,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",1192,"[' """""" df.sort([\'A\', \'B\'], ascending=[1, 0])  """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/py2to3/linux.py:sort,sort,function,7,20,12,181,9.05,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",1198,[],"['pd.DataFrame', 'df.sort_values', 'sort']",3
utilmy/zarchive/py2to3/linux.py:np_ma,np_ma,function,2,3,3,45,15.0,0,0,"['vv', 'n']","[None, None]","[None, None]",1205,"[""  '''Moving average '''\n""]","['np.convolve', 'np.ones']",2
utilmy/zarchive/py2to3/linux.py:np_cleanmatrix,np_cleanmatrix,function,11,22,20,124,5.64,2,1,['m'],[None],[None],1211,[],"['np.nan_to_num', 'np.shape', 'range', 'abs']",4
utilmy/zarchive/py2to3/linux.py:np_sortbycolumn,np_sortbycolumn,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1222,[],"['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/py2to3/linux.py:np_sortbycol,np_sortbycol,function,8,30,20,257,8.57,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1227,[],"['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/py2to3/linux.py:np_findfirst,np_findfirst,function,5,11,10,55,5.0,1,1,"['item', 'vec']","[None, None]","[None, None]",1238,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/py2to3/linux.py:np_find,np_find,function,6,24,13,133,5.54,2,2,"['item', 'vec']","[None, None]","[None, None]",1244,[],"['xrange', 'np_find']",2
utilmy/zarchive/py2to3/linux.py:find,find,function,12,42,30,219,5.21,1,3,"['item', 'vec']","[None, None]","[None, None]",1250,"['    """"""return the index of the first occurence of item in vec""""""\n']","['xrange', 'findx', 'type', 'vec.index', 'len', 'finds']",6
utilmy/zarchive/py2to3/linux.py:findx,findx,function,6,27,18,119,4.41,0,2,"['item', 'vec']","[None, None]","[None, None]",1257,"['    """"""return the index of the first occurence of item in vec""""""\n']","['type', 'vec.index', 'len']",3
utilmy/zarchive/py2to3/linux.py:finds,finds,function,12,34,23,156,4.59,2,3,"['itemlist', 'vec']","[None, None]","[None, None]",1268,"['  """"""return the index of the first occurence of item in vec""""""\n']","['xrange', 'idlist.append']",2
utilmy/zarchive/py2to3/linux.py:findhigher,findhigher,function,5,13,12,51,3.92,1,1,"['x', 'vec']","[None, None]","[None, None]",1280,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/py2to3/linux.py:findlower,findlower,function,5,12,11,51,4.25,1,1,"['x', 'vec']","[None, None]","[None, None]",1287,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/py2to3/linux.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],1297,[],['min'],1
utilmy/zarchive/py2to3/linux.py:np_find_maxpos,np_find_maxpos,function,17,45,34,266,5.91,1,3,['values'],[None],[None],1301,[],"['max', 'np_find_maxpos_2nd', 'float', 'enumerate']",4
utilmy/zarchive/py2to3/linux.py:np_find_maxpos_2nd,np_find_maxpos_2nd,function,13,37,28,138,3.73,1,3,['numbers'],[None],[None],1306,[],"['float', 'enumerate']",2
utilmy/zarchive/py2to3/linux.py:np_findlocalmax2,np_findlocalmax2,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",1320,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/py2to3/linux.py:np_findlocalmin2,np_findlocalmin2,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",1355,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/py2to3/linux.py:np_findlocalmax,np_findlocalmax,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",1392,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/py2to3/linux.py:np_findlocalmin,np_findlocalmin,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",1407,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/py2to3/linux.py:np_stack,np_stack,function,12,53,25,323,6.09,0,7,"['v1', 'v2', 'v3', 'v4', 'v5']","[None, None, None, None, None]","[None, 'None', 'None', 'None', 'None']",1428,[],"['np.shape', 'np.row_stack', 'np.column_stack']",3
utilmy/zarchive/py2to3/linux.py:np_uniquerows,np_uniquerows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],1443,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/py2to3/linux.py:np_remove_zeros,np_remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",1448,[],[],0
utilmy/zarchive/py2to3/linux.py:np_sort,np_sort,function,8,30,20,257,8.57,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1451,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/py2to3/linux.py:np_memory_array_adress,np_memory_array_adress,function,2,2,2,38,19.0,0,0,['x'],[None],[None],1454,[],[],0
utilmy/zarchive/py2to3/linux.py:sk_featureimportance,sk_featureimportance,function,9,21,21,228,10.86,1,1,"['clfrf', 'feature_name']","[None, None]","[None, None]",1463,[],"['np.argsort', 'range', 'len', 'str']",4
utilmy/zarchive/py2to3/linux.py:sk_showconfusion,sk_showconfusion,function,11,22,21,244,11.09,0,1,"['clfrf', 'X_train', 'Y_train', 'isprint']","[None, None, None, None]","[None, None, None, 'True']",1471,[],"['clfrf.predict', 'cm.astype', 'cm.sum', 'print']",4
utilmy/zarchive/py2to3/linux.py:sk_tree,sk_tree,function,13,34,32,430,12.65,0,1,"['Xtrain', 'Ytrain', 'nbtree', 'maxdepth', 'print1']","[None, None, None, None, None]","[None, None, None, None, None]",1479,[],"['clfrf.fit', 'clfrf.predict', 'cm.astype', 'cm.sum', 'print']",5
utilmy/zarchive/py2to3/linux.py:sk_gen_ensemble_weight,sk_gen_ensemble_weight,function,14,30,28,213,7.1,1,0,"['vv', 'acclevel', 'maxlevel']","[None, None, None]","[None, None, '0.88']",1492,[],"['min', 'np.empty', 'range', 'estww.append', 'np.log', 'np.array']",6
utilmy/zarchive/py2to3/linux.py:sk_votingpredict,sk_votingpredict,function,19,33,28,267,8.09,2,1,"['estimators', 'voting', 'ww', 'X_test']","[None, None, None, None]","[None, None, None, None]",1506,[],"['np.zeros', 'enumerate', 'clf.predict_proba', 'range', 'len']",5
utilmy/zarchive/py2to3/linux.py:sk_tree_get_ifthen,sk_tree_get_ifthen,function,26,89,62,768,8.63,2,3,"['tree', 'feature_names', 'target_names', 'spacer_base']","[None, None, None, None]","[None, None, None, '"" ""']",1524,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['recurse', 'print', 'str', 'zip', 'int']",5
utilmy/zarchive/py2to3/linux.py:pd_array_todataframe,pd_array_todataframe,function,13,45,29,277,6.16,0,2,"['price', 'symbols', 'date1', 'dotranspose']","[None, None, None, None]","[None, 'None', 'None', 'False']",1562,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/py2to3/linux.py:pd_date_intersection,pd_date_intersection,function,7,18,15,157,8.72,1,0,['qlist'],[None],[None],1574,[],"['set', 'set.intersection', 'list', 'sorted']",4
utilmy/zarchive/py2to3/linux.py:pd_resetindex,pd_resetindex,function,3,4,4,50,12.5,0,0,['df'],[None],[None],1585,[],['list'],1
utilmy/zarchive/py2to3/linux.py:pd_create_colmap_nametoid,pd_create_colmap_nametoid,function,9,12,12,77,6.42,1,0,['df'],[None],[None],1591,"[""  ''' 'close' ---> 5    '''\n""]",['enumerate'],1
utilmy/zarchive/py2to3/linux.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],1599,[],[],0
utilmy/zarchive/py2to3/linux.py:pd_changeencoding,pd_changeencoding,function,6,8,8,89,11.12,1,0,"['data', 'cols']","[None, None]","[None, None]",1606,[],[],0
utilmy/zarchive/py2to3/linux.py:pd_createdf,pd_createdf,function,2,4,4,53,13.25,0,0,"['val1', 'col1', 'idx1']","[None, None, None]","[None, 'None', 'None']",1613,[],['pd.DataFrame'],1
utilmy/zarchive/py2to3/linux.py:pd_insertcolumn,pd_insertcolumn,function,12,29,27,179,6.17,1,1,"['df', 'colname', 'vec']","[None, None, None]","[None, None, None]",1618,"["" ''' Vec and Colname must be aligned '''\n""]","['len', 'np.shape', 'range', 'df.insert']",4
utilmy/zarchive/py2to3/linux.py:pd_insertrows,pd_insertrows,function,17,31,30,237,7.65,1,1,"['df', 'rowval', 'index1']","[None, None, None]","[None, None, 'None']",1632,[],"['np.shape', 'np.arange', 'pd.DataFrame', 'range', 'df.append']",5
utilmy/zarchive/py2to3/linux.py:pd_replacevalues,pd_replacevalues,function,11,14,14,101,7.21,1,0,"['df', 'matrix']","[None, None]","[None, None]",1645,"["" ''' Matrix replaces df.values  '''\n""]",['np.shape'],1
utilmy/zarchive/py2to3/linux.py:pd_storeadddf,pd_storeadddf,function,6,15,15,113,7.53,0,1,"['df', 'dfname', ""dbfile='F""]","[None, None, '']","[None, None, ""'F:\\temp_pandas.h5'""]",1655,[],"['pd.HDFStore', 'find', 'store.keys', 'store.append', 'store.close']",5
utilmy/zarchive/py2to3/linux.py:pd_storedumpinfo,pd_storedumpinfo,function,13,29,24,298,10.28,1,0,"[""dbfile='E""]",[''],"[""'E:\\_data\\stock\\intraday_google.h5'""]",1663,[],"['pd.HDFStore', 'store.keys', 'pd.read_hdf', 'extract.append', 'datetime_tostring', 'errsym.append', 'np.array']",7
utilmy/zarchive/py2to3/linux.py:pd_remove_row,pd_remove_row,function,2,2,2,29,14.5,0,0,"['df', 'row_list_index', '45]']","[None, None, None]","[None, '[23', None]",1677,[],['df.drop'],1
utilmy/zarchive/py2to3/linux.py:pd_extract_col_idx_val,pd_extract_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],1680,[],[],0
utilmy/zarchive/py2to3/linux.py:pd_split_col_idx_val,pd_split_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],1684,[],[],0
utilmy/zarchive/py2to3/linux.py:pd_addcolumn,pd_addcolumn,function,10,23,19,190,8.26,1,1,"['df1', 'name1']","[None, None]","[None, ""'new'""]",1688,[],"['len', 'type', 'pd.Series']",3
utilmy/zarchive/py2to3/linux.py:pd_removecolumn,pd_removecolumn,function,2,3,3,23,7.67,0,0,"['df1', 'name1']","[None, None]","[None, None]",1697,[],['df1.drop'],1
utilmy/zarchive/py2to3/linux.py:pd_save_vectopanda,pd_save_vectopanda,function,9,22,19,182,8.27,1,0,"['vv', 'filenameh5)', 'pdf); store.close()filenameh5', ""store_id='data')"", 'store_id)    #from filereturn pdf.values   #to numpy vectorfilein1', 'filename', ""tablen='data')""]","[None, ""  # 'E:\\_data\\_data_outlier.h5'filenameh5)vv); store.append('data'"", None, '', None, None, '']","[None, None, None, ""'data'):  # 'E:\\_data\\_data_outlier.h5'filenameh5"", None, None, ""'data'):""]",1701,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/py2to3/linux.py:pd_load_panda2vec,pd_load_panda2vec,function,9,22,19,182,8.27,1,0,"['filenameh5', ""store_id='data')"", 'store_id)    #from filereturn pdf.values   #to numpy vectorfilein1', 'filename', ""tablen='data')""]","[None, '', None, None, '']","[None, ""'data'):  # 'E:\\_data\\_data_outlier.h5'filenameh5"", None, None, ""'data'):""]",1706,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/py2to3/linux.py:pd_csv_topanda,pd_csv_topanda,function,9,22,19,182,8.27,1,0,"['filein1', 'filename', 'tablen']","[None, None, None]","[None, None, ""'data'""]",1711,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/py2to3/linux.py:pd_getpanda_tonumpy,pd_getpanda_tonumpy,function,6,10,10,92,9.2,0,0,"['filename', 'nsize', 'tablen']","[None, None, None]","[None, None, ""'data'""]",1723,[],['pd.read_hdf'],1
utilmy/zarchive/py2to3/linux.py:pd_getrandom_tonumpy,pd_getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample', 'tablen']","[None, None, None, None]","[None, None, None, ""'data'""]",1728,[],['pd.read_hdf'],1
utilmy/zarchive/py2to3/linux.py:sk_cluster_kmeans,sk_cluster_kmeans,function,21,38,37,375,9.87,1,1,"['x', 'nbcluster', 'isplot']","[None, None, None]","[None, '5', 'True']",1861,[],"['np.std', 'kmeans.fit', 'range', 'plt.plot', 'plt.show']",5
utilmy/zarchive/py2to3/linux.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],1885,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/py2to3/linux.py:date_remove_bdays,date_remove_bdays,function,16,41,28,351,8.56,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",1896,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/py2to3/linux.py:date_add_bdays,date_add_bdays,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",1914,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/py2to3/linux.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",1929,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:datetime_toint,datetime_toint,function,6,15,13,155,10.33,1,1,['datelist1'],[None],[None],1938,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:dateint_todatetime,dateint_todatetime,function,6,15,13,135,9.0,1,1,['datelist1'],[None],[None],1946,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:date_diffindays,date_diffindays,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",1955,[],['dateint_todatetime'],1
utilmy/zarchive/py2to3/linux.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",1960,[],['util.np_findfirst'],1
utilmy/zarchive/py2to3/linux.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],1974,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:date_now,date_now,function,10,18,16,130,7.22,0,1,['i'],[None],['0'],1981,[],"['datetime.now', 'date_add_bdays', 'date_remove_bdays', 'str']",4
utilmy/zarchive/py2to3/linux.py:date_as_float,date_as_float,function,11,28,23,273,9.75,0,1,['dt'],[None],[None],1989,[],"['datetime.datetime', 'isleap', 'timedelta']",3
utilmy/zarchive/py2to3/linux.py:datediff_inyear,datediff_inyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",2001,[],['date_as_float'],1
utilmy/zarchive/py2to3/linux.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",2005,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/py2to3/linux.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],1885,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/py2to3/linux.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",1929,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],1974,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",2048,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/py2to3/linux.py:numexpr_topanda,numexpr_topanda,function,10,28,22,248,8.86,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",2060,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/py2to3/linux.py:textvect_topanda,textvect_topanda,function,2,8,8,70,8.75,0,0,"['vv', 'fileout']","[None, None]","[None, '""""']",2070,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zarchive/py2to3/linux.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",2093,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/linux.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],2101,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/py2to3/linux.py:plotsave,plotsave,function,7,16,16,199,12.44,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",2124,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/py2to3/linux.py:plotshow,plotshow,function,4,9,9,101,11.22,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",2135,[],"['plt.scatter', 'plt.autoscale', 'plt.title', 'plt.show']",4
utilmy/zarchive/py2to3/linux.py:compileVSsolution,compileVSsolution,function,5,33,19,239,7.24,0,4,"['dir1', 'flags1', 'type1', 'compilerdir']","[None, None, None, None]","[None, '""""', '""devenv""', '""""']",2568,[],['os.system'],1
utilmy/zarchive/py2to3/linux.py:VS_start,VS_start,function,18,56,52,881,15.73,0,2,"['self', 'version']","[None, None]","[None, None]",2597,[],"['os.getenv', 'Exception', 'default.append', 'libs.append']",4
utilmy/zarchive/py2to3/linux.py:VS_build,VS_build,function,16,62,54,614,9.9,1,2,"['self', 'lib_to_build']","[None, None]","[None, None]",2632,[],"['print', 'subprocess.Popen', 'process.poll', 'process.communicate']",4
utilmy/zarchive/py2to3/linux.py:set_rc_version,set_rc_version,function,12,43,39,500,11.63,0,0,"['rcfile', 'target_version']","[None, None]","[None, None]",2666,[],"['open', 'f.read', 're.compile', 're.sub', 'f.seek', 'f.write', 'f.truncate']",7
utilmy/zarchive/py2to3/multiprocessfunc.py:multigbm_paralell_func,multigbm_paralell_func,function,34,117,81,913,7.8,1,4,"['nbsimul', 'ww', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price', 'type1', 'strike', 'cp']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, '0', '0', '1']",20,[],"['np.zeros', 'range', 'np.dot', 'np.multiply', 'np.exp', 'np.cumprod', 'np.maximum', 'sum', 'sum1/float']",9
utilmy/zarchive/py2to3/multiprocessfunc.py:func,func,function,6,10,10,56,5.6,1,0,"['val', 'lock']","[None, None]","[None, None]",73,[],"['range', 'time.sleep']",2
utilmy/zarchive/py2to3/multiprocessfunc.py:multigbm_processfast7,multigbm_processfast7,function,24,48,44,419,8.73,3,0,"['nbsimul', 's0', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",150,[],"['range', 'np.dot', 'bm_generator', 'np.exp', 'sum', 'sum1/float']",6
utilmy/zarchive/py2to3/multiprocessfunc.py:bm_generator,bm_generator,function,5,9,8,43,4.78,0,1,"['bm', 'dt', 'n', 'type1']","[None, None, None, None]","[None, None, None, None]",177,[],[],0
utilmy/zarchive/py2to3/multiprocessfunc.py:merge,merge,function,6,20,17,106,5.3,1,1,['d2'],[None],[None],211,[],"['time.sleep', 'd2.keys']",2
utilmy/zarchive/py2to3/multiprocessfunc.py:integratenp2,integratenp2,function,10,29,25,184,6.34,1,0,"['its', 'nchunk']","[None, None]","[None, None]",222,[],"['range', 'ne.evaluate']",2
utilmy/zarchive/py2to3/multiprocessfunc.py:integratenp,integratenp,function,27,77,47,454,5.9,2,0,"['its', 'nchunk']","[None, None]","[None, None]",234,[],"['range', 'ne.evaluate', 'integratenp', 'np.sum', 'float']",5
utilmy/zarchive/py2to3/multiprocessfunc.py:integratene,integratene,function,12,44,38,275,6.25,1,0,['its'],[None],[None],247,[],"['range', 'ne.evaluate', 'float']",3
utilmy/zarchive/py2to3/multiprocessfunc.py:parzen_estimation,parzen_estimation,function,7,30,26,185,6.17,2,1,"['x_samples', 'point_x', 'h']","[None, None, None]","[None, None, None]",268,[],"['np.abs', 'len']",2
utilmy/zarchive/py2to3/multiprocessfunc.py:init2,init2,function,2,4,4,13,3.25,0,0,['d'],[None],[None],282,[],[],0
utilmy/zarchive/py2to3/multiprocessfunc.py:init_global1,init_global1,function,2,2,2,37,18.5,0,0,"['l', 'r']","[None, None]","[None, None]",286,[],[],0
utilmy/zarchive/py2to3/multiprocessfunc.py:np_sin,np_sin,function,2,2,2,19,9.5,0,0,['value'],[None],[None],291,[],['np.sin'],1
utilmy/zarchive/py2to3/multiprocessfunc.py:ne_sin,ne_sin,function,2,2,2,27,13.5,0,0,['x'],[None],[None],294,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/multiprocessfunc.py:res_shared2,res_shared2,function,4,16,14,94,5.88,0,0,[],[],[],297,[],['float'],1
utilmy/zarchive/py2to3/multiprocessfunc.py:list_append,list_append,function,3,4,4,54,13.5,1,0,"['count', 'id', 'out_list']","[None, None, None]","[None, None, None]",261,"['\t""""""Creates an empty list and then appends a random number to the list \'count\' number of times. A CPU-heavy operation!""""""\n']",['range'],1
utilmy/zarchive/py2to3/portfolio.py:data_jpsector,data_jpsector,function,3,4,4,47,11.75,0,0,[],[],[],37,[],['util.load_obj'],1
utilmy/zarchive/py2to3/portfolio.py:date_earningquater,date_earningquater,function,9,103,42,604,5.86,0,5,['t1'],[None],[None],47,[],['datetime.datetime'],1
utilmy/zarchive/py2to3/portfolio.py:date_is_3rdfriday,date_is_3rdfriday,function,4,14,13,67,4.79,0,0,['s'],[None],[None],66,[],"['datetime.strptime', 'd.weekday']",2
utilmy/zarchive/py2to3/portfolio.py:date_option_expiry,date_option_expiry,function,10,50,33,354,7.08,0,2,['date'],[None],[None],71,[],['datetime.datetime'],1
utilmy/zarchive/py2to3/portfolio.py:date_find_kday_fromintradaydate,date_find_kday_fromintradaydate,function,2,3,3,68,22.67,0,0,"['kintraday', 'intradaydate', 'dailydate']","[None, None, None]","[None, None, None]",88,[],['util.np_find'],1
utilmy/zarchive/py2to3/portfolio.py:date_find_kintraday_fromdate,date_find_kintraday_fromdate,function,4,10,10,88,8.8,0,0,"['d1', 'intradaydate1', 'h1', 'm1']","[None, None, None, None]","[None, None, '9', '30']",92,[],"['datetime.datetime', 'util.np_find']",2
utilmy/zarchive/py2to3/portfolio.py:date_find_intradateid,date_find_intradateid,function,8,13,13,96,7.38,1,0,"['datetimelist', 'stringdate']","[None, None]","[None, ""['20160420223000']""]",99,[],"['datestring_todatetime', 'util.np_find', 'str']",3
utilmy/zarchive/py2to3/portfolio.py:datetime_convertzone1_tozone2,datetime_convertzone1_tozone2,function,16,29,25,343,11.83,1,1,"['tt', 'fromzone', 'tozone']","[None, None, None]","[None, ""'Japan'"", ""'US/Eastern'""]",110,[],"['pytz.timezone', 'type', 'tz.localize', 't2.append']",4
utilmy/zarchive/py2to3/portfolio.py:date_extract_dailyopenclosetime,date_extract_dailyopenclosetime,function,23,51,35,431,8.45,2,3,"['spdateref1', 'market']","[None, None]","[None, ""'us'""]",127,[],"['enumerate', 'spdailyopendate.append', 'np.array', 'spdailyclosedate.append']",4
utilmy/zarchive/py2to3/portfolio.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",147,[],['util.np_findfirst'],1
utilmy/zarchive/py2to3/portfolio.py:date_alignfromdateref,date_alignfromdateref,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",162,[],"['range', 'np.float', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:_date_align,_date_align,function,16,42,33,256,6.1,2,2,"['dateref', 'datei', 'tmax', 'closei']","[None, None, None, None]","[None, None, None, None]",187,[],"['np.zeros', 'range', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:date_align,date_align,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",201,"["" ''' #Aligne the price with the same dates date\tyear\tmonth\tday\td\topen\tclose\thigh\tlow\tvolume\taclose '''\n""]","['range', 'np.float', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:min_withposition,min_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],249,[],['min'],1
utilmy/zarchive/py2to3/portfolio.py:max_withposition,max_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],253,[],['max'],1
utilmy/zarchive/py2to3/portfolio.py:_reshape,_reshape,function,2,14,12,68,4.86,0,1,['x'],[None],[None],259,[],"['len', 'np.reshape', 'np.size']",3
utilmy/zarchive/py2to3/portfolio.py:_notnone,_notnone,function,39,211,114,1769,8.38,1,11,"['x)', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5)', 'label', ""'Time'"", ""'Y')"", 'legendloc', 'dpi', 'isband=0) ']","['  return not x is Noneasset', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None, ""('title'"", None, None, '""upper left""', '150', '0) :']",263,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend']",23
utilmy/zarchive/py2to3/portfolio.py:plot_price,plot_price,function,69,272,170,2746,10.1,2,11,"['asset', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None]",267,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend', 'plot_priceintraday', 'np.loadtxt', 'np.unique', 'xdays.append', 'np.hstack', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick']",35
utilmy/zarchive/py2to3/portfolio.py:plot_priceintraday,plot_priceintraday,function,32,59,57,947,16.05,1,0,['data'],[None],[None],346,[],"['np.loadtxt', 'np.unique', 'np.arange', 'xdays.append', 'np.hstack', 'plt.figure', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plt.show']",14
utilmy/zarchive/py2to3/portfolio.py:plot_check,plot_check,function,8,19,19,257,13.53,0,0,"['close', 'tt0i', 'tt1i', 'dateref', 'sym', 'tickperday']","[None, None, None, None, None, None]","[None, '20140102', '20160815', '[]', '[]', '120']",388,[],"['util.find', 'getret_fromquotes', 'price_normalize100', 'plot_price']",4
utilmy/zarchive/py2to3/portfolio.py:plot_pricedate,plot_pricedate,function,18,61,49,534,8.75,1,4,"['date1', 'sym1', 'asset1', 'sym2', 'bsk1', 'verticaldate', 'savename1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None', ""''"", '(10', None]",398,[],"['type', 'datestring_todatetime', 'np.row_stack', 'np.concatenate', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'np.arange', 'int', 'len', 'ax.savefig']",11
utilmy/zarchive/py2to3/portfolio.py:generate_sepvertical,generate_sepvertical,function,9,13,12,149,11.46,0,1,"['asset1', 'tt', 'tmax', 'start', 'datebar']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",480,[],"['np.zeros', 'datestring_todatetime']",2
utilmy/zarchive/py2to3/portfolio.py:save_asset_tofile,save_asset_tofile,function,31,129,87,978,7.58,5,9,"['file1', 'asset1', 'asset2', 'asset3', 'date1', 'title1']","[None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None']",495,[],"['np.shape', 'len', 'np.reshape', 'print', 'np.zeros', 'range', 'int', 'np.row_stack', 'np.savetxt']",9
utilmy/zarchive/py2to3/portfolio.py:load_asset_fromfile,load_asset_fromfile,function,1,4,4,51,12.75,0,0,['file1'],[None],[None],534,[],[],0
utilmy/zarchive/py2to3/portfolio.py:array_todataframe,array_todataframe,function,11,41,27,259,6.32,0,2,"['price', 'symbols', 'date1']","[None, None, None]","[None, 'None', 'None']",538,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/py2to3/portfolio.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],549,[],[],0
utilmy/zarchive/py2to3/portfolio.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],558,[],['float'],1
utilmy/zarchive/py2to3/portfolio.py:isint,isint,function,32,105,61,1036,9.87,0,8,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) )Xmat', 'type1', 'type2=""correl"") ']","[' return isinstance(x', None, None, None, None, None, None, '']","[None, None, None, None, None, None, '""robust""', '""correl"") :']",566,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/py2to3/portfolio.py:correlation_mat,correlation_mat,function,32,105,61,1036,9.87,0,8,"['Xmat', 'type1', 'type2']","[None, None, None]","[None, '""robust""', '""correl""']",573,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/py2to3/portfolio.py:correl_reducebytrigger,correl_reducebytrigger,function,9,22,18,128,5.82,2,1,"['correl2', 'trigger']","[None, None]","[None, None]",621,"[""  ''' Put Zero below trigger  '''\n""]","['correl2.copy', 'range', 'abs']",3
utilmy/zarchive/py2to3/portfolio.py:sk_cov_fromcorrel,sk_cov_fromcorrel,function,8,14,13,115,8.21,0,0,"['correl', 'ret_close1']","[None, None]","[None, None]",633,[],"['volhisto_fromret', 'np.diag', 'np.dot']",3
utilmy/zarchive/py2to3/portfolio.py:cointegration,cointegration,function,18,47,37,385,8.19,0,0,"['x', 'y']","[None, None]","[None, None]",639,"['  """""" Output :\n', '    coint_t :t-statistic of unit-root test on residuals\n', ""    pvalue :   MacKinnon's approximate p-value based on MacKinnon (1994)\n"", '    crit_value : Critical values for the test statistic at the 1 %, 5 %, and 10 %  Signifiance levels.\n', '\n', '    The Null hypothesis is that there is no cointegration, the alt hypothesis is that there is cointegrating relationship. \n', '    If the pvalue is small, below a critical size:  Reject Null Hypothesis -->  Cointegration\n', '           pvalue is high --> No Cointegration    \n', '    \n', '    Significance level, also denoted as alpha or , is the probability of rejecting  the null hypothesis when it is true.\n', '    Probability of incorrectly rejecting a true null hypothesis\n', '\n', '    P=0.05  , At least 23% (and typically close to 50%)\n', '    P=0.01  , At least 7% (and typically close to 15%\n', '\n', '    (-2.9607012342275936,\n', '    0.038730981052330332, 0,\n', '    249,\n', ""    {'1%': -3.4568881317725864,\n"", ""       '10%': -2.5729936189738876,\n"", ""     '5%': -2.8732185133016057},\n"", '      601.96849256295991)\n', '        It can be seen that the calculated test statistic of -2.96 is smaller than the 5% critical value of -2.87, \n', ""        which means that we can reject the null hypothesis that  there isn't a cointegrating relationship at the 5% level.\n"", '  """"""\n']",['np.zeros'],1
utilmy/zarchive/py2to3/portfolio.py:causality_y1_y2,causality_y1_y2,function,10,14,13,153,10.93,0,0,"['price2', 'price1', 'maxlag']","[None, None, None]","[None, None, None]",677,[],[],0
utilmy/zarchive/py2to3/portfolio.py:reg_slope,reg_slope,function,16,24,24,261,10.88,1,0,"['close', 'dateref', 'tlag', 'type1']","[None, None, None, None]","[None, None, None, ""'elasticv'""]",685,[],"['np.ones', 'xrange', 'regression', 'np.arange']",4
utilmy/zarchive/py2to3/portfolio.py:rolling_cointegration,rolling_cointegration,function,13,29,26,280,9.66,0,0,"['x', 'y']","[None, None]","[None, None]",700,[],"['rolling_coint', 'pd.expanding_apply']",2
utilmy/zarchive/py2to3/portfolio.py:regression,regression,function,13,67,32,589,8.79,0,5,"['yreturn', 'xreturn', 'type1']","[None, None, None]","[None, None, '""elasticv""']",719,"["" '''Y = X* reg.coef_  +  reg.intercept_, r2 '''\n""]","['len', 'yreturn.ravel', 'xreturn.reshape', 'reg.fit', 'F', 'reg.score']",6
utilmy/zarchive/py2to3/portfolio.py:regression_fixedsymbolstock,regression_fixedsymbolstock,function,30,59,54,591,10.02,1,1,"['sym', 'ret_close2', 'tsstart', 'tsample', 'ret_spy', 'spyclose', 'regonly']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, 'True']",756,"["" ''' Price, Weight, R2, Error  '''\n""]","['len', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max']",7
utilmy/zarchive/py2to3/portfolio.py:regression_getpricefromww,regression_getpricefromww,function,20,38,30,298,7.84,3,0,"['spyclose', 'ww01', 'regasset01', 'ret_close2', 'tstart', 'tlag']","[None, None, None, None, None, None]","[None, None, None, None, None, '1']",779,[],"['np.copy', 'np.zeros', 'range', 'len']",4
utilmy/zarchive/py2to3/portfolio.py:regression_allstocks_vs_riskfactors,regression_allstocks_vs_riskfactors,function,65,137,113,1351,9.86,2,1,"['symstock', 'pricestock', 'symriskfac', 'priceriskfac', 'nlaglist']","[None, None, None, None, None]","[None, None, None, None, None]",800,"["" '''Make Regression on all stocks ''' \n""]","['np.shape', 'print', 'np.arange', 'np.empty', 'len', 'enumerate', 'getlogret_fromquotes', 'range', 'np.reshape', 'regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",13
utilmy/zarchive/py2to3/portfolio.py:getdiff_fromquotes,getdiff_fromquotes,function,4,6,6,73,12.17,0,0,"['close', 'timelag']","[None, None]","[None, None]",897,[],['np.shape'],1
utilmy/zarchive/py2to3/portfolio.py:getret_fromquotes,getret_fromquotes,function,7,23,17,159,6.91,0,1,"['close', 'timelag']","[None, None]","[None, '1']",901,[],"['np.shape', 'len']",2
utilmy/zarchive/py2to3/portfolio.py:getlogret_fromquotes,getlogret_fromquotes,function,4,7,7,81,11.57,0,0,"['close', 'timelag']","[None, None]","[None, '1']",912,[],"['np.shape', 'np.log']",2
utilmy/zarchive/py2to3/portfolio.py:getprice_fromret,getprice_fromret,function,12,23,21,190,8.26,2,0,"['ret', 'normprice']","[None, None]","[None, '100']",917,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio.py:price_normalize100,price_normalize100,function,16,43,36,292,6.79,1,1,"['ret', 'normprice']","[None, None]","[None, '100']",929,[],"['np.shape', 'len', 'np.reshape', 'np.zeros', 'range', 'np.cumprod']",6
utilmy/zarchive/py2to3/portfolio.py:price_normalize_1d,price_normalize_1d,function,8,22,19,147,6.68,0,0,"['ret', 'normprice', 'dtype1']","[None, None, None]","[None, '100', ' np.float32']",949,[],"['np.empty', 'np.cumprod']",2
utilmy/zarchive/py2to3/portfolio.py:norm_fast,norm_fast,function,7,8,8,85,10.62,0,0,"['y', 'ny']","[None, None]","[None, None]",958,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/portfolio.py:correl_fast,correl_fast,function,8,13,13,116,8.92,0,0,"['xn', 'y', 'nx']","[None, None, None]","[None, None, None]",966,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/portfolio.py:volhisto_fromret,volhisto_fromret,function,2,14,11,168,12.0,0,1,"['retbsk', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",974,[],"['len', 'np.std']",2
utilmy/zarchive/py2to3/portfolio.py:volhisto_fromprice,volhisto_fromprice,function,6,25,17,245,9.8,0,1,"['price', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",981,[],"['len', 'np.shape', 'np.std']",3
utilmy/zarchive/py2to3/portfolio.py:volhistorolling_fromprice,volhistorolling_fromprice,function,16,42,30,318,7.57,2,1,"['price', 'volrange']","[None, None]","[None, None]",990,[],"['np.shape', 'len', 'np.zeros', 'xrange', 'volhisto_fromprice']",5
utilmy/zarchive/py2to3/portfolio.py:rsk_calc_all_TA,rsk_calc_all_TA,function,51,223,105,1352,6.06,0,10,['df'],[None],"[""'panda_dataframe'""]",1009,"[""  '''Add All TA RMI, RSI To the '''\n""]","['ta.MA', 'ta.distance', 'ta.RET', 'ta.RMI', 'ta.STDDEV', 'ta.nbday_low', 'ta.nbday_high', 'ta.RSI', 'ta.qearning_dist', 'ta.optionexpiry_dist', 'linearreg2', 'np.array', 'np.sum', 'util.np_findlocalmin2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",18
utilmy/zarchive/py2to3/portfolio.py:ta_highbandtrend1,ta_highbandtrend1,function,42,170,75,910,5.35,0,11,"['close2', 'type1']","[None, None]","[None, '0']",1091,[],"['linearreg', 'np.array', 'np.sum', 'util.np_findlocalmax2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",8
utilmy/zarchive/py2to3/portfolio.py:pd_transform_asset,pd_transform_asset,function,11,35,27,409,11.69,0,1,"['q0', 'q1', 'type1']","[None, None, None]","[None, None, '""spread""']",1140,[],"['util.pd_date_intersection', 'util.pd_array_todataframe', 'util.pd_insertcol']",3
utilmy/zarchive/py2to3/portfolio.py:calcbasket_table,calcbasket_table,function,25,59,53,477,8.08,1,2,"['wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps']","[None, None, None, None, None, None]","[None, None, '""table""', '""constant""', '1', ' 0.000']",1154,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.mod', 'np.sum']",6
utilmy/zarchive/py2to3/portfolio.py:folio_createvolta_asset,folio_createvolta_asset,function,10,19,19,159,8.37,1,0,"['close', 'vol', 'volrange', 'lev']","[None, None, None, None]","[None, '0.12', '120', '1.0']",1181,[],"['np.zeros_like', 'np.shape', 'xrange', 'folio_volta']",4
utilmy/zarchive/py2to3/portfolio.py:folio_lowcorrelation,folio_lowcorrelation,function,145,431,300,3894,9.03,8,7,"['sym01', 'nstock', 'periodlist', 'dateref', 'close1', 'kbenchmark', 'badlist', 'costbppa', 'showgraph']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, '0.02', 'True']",1189,[],"['ww_selection', 'np.corrcoef', 'np.nan_to_num', 'np.zeros', 'range', 'util.np_sortbycol', 'int', 'np.std', 'np.isnan', 'util.find', 'np.sum', 'stk_select.append', 'volhisto_fromret', 'sum', '1/len', 'getret_fromquotes', 'len', 'np.empty', 'np.ones', 'enumerate', 'calcbasket_table', 'price_normalize100', 'np.column_stack', 'np.zeros_like', 'np.array', 'np.concatenate', 'print', 'str', 'plot_price', 'sym01[int', 'volhisto_fromprice', 'xrange', 'folio_inverseetf']",33
utilmy/zarchive/py2to3/portfolio.py:folio_leverageetf,folio_leverageetf,function,8,23,20,156,6.78,1,0,"['price', 'lev', 'costpa']","[None, None, None]","[None, '1.0', '0.0']",1327,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:folio_inverseetf,folio_inverseetf,function,8,18,18,151,8.39,1,0,"['price', 'costpa']","[None, None]","[None, '0.0']",1336,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:folio_longshort_unit,folio_longshort_unit,function,59,240,112,1594,6.64,2,7,"['long1', 'short1', 'ww', '-1]', 'costpa', 'tlag', 'istable', 'wwschedule']","[None, None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1', '[]']",1345,[],"['len', 'np.zeros', 'xrange', 'np.mod', 'folio_longshort_unitfixed']",5
utilmy/zarchive/py2to3/portfolio.py:folio_longshort_unitfixed,folio_longshort_unitfixed,function,43,111,73,719,6.48,1,3,"['long1', 'short1', 'nn', '-1]', 'costpa', 'tlag', 'istable']","[None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1']",1386,[],"['len', 'np.zeros', 'xrange', 'np.mod']",4
utilmy/zarchive/py2to3/portfolio.py:folio_longshort_pct,folio_longshort_pct,function,8,21,20,189,9.0,1,0,"['long1', 'short1', 'ww', '-1]', 'costpa']","[None, None, None, None, None]","[None, None, '[1', None, '0.0']",1424,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:folio_histogram,folio_histogram,function,13,75,41,914,12.19,0,0,['close'],[None],[None],1432,[],"['getret_fromquotes', 'plt.subplots', 'np.ones_like', 'ax2.hist', 'ax2.set_title', 'ax2.set_xlabel', 'ax2.set_ylabel', 'ax2.axvline', 'plt.show', 'print']",10
utilmy/zarchive/py2to3/portfolio.py:folio_voltarget,folio_voltarget,function,2,6,6,61,10.17,0,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1460,[],['folio_volta'],1
utilmy/zarchive/py2to3/portfolio.py:folio_volta,folio_volta,function,54,197,112,1663,8.44,2,8,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1464,[],"['folio_volta', 'len', 'np.shape', 'np.zeros', 'range', 'np.std', 'util.findhigher', 'max', 'min', 'folio_volta2', 'np.abs']",11
utilmy/zarchive/py2to3/portfolio.py:folio_volta2,folio_volta2,function,29,61,54,514,8.43,1,2,"['bsk', 'riskind', 'par', 'targetvol', 'volrange', 'cap', 'floor', 'costbp']","[None, None, None, None, None, None, None, None]","[None, None, None, '0.11', ' 90', '1.5', '0.0', '0.0005']",1503,[],"['np.shape', 'np.zeros', 'range', 'np.std', 'max', 'min', 'np.abs']",7
utilmy/zarchive/py2to3/portfolio.py:folio_fixedunitprice,folio_fixedunitprice,function,13,36,33,221,6.14,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1528,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio.py:folio_fixedweightprice,folio_fixedweightprice,function,13,36,33,225,6.25,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1542,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio.py:folio_fixedweightret,folio_fixedweightret,function,13,31,28,193,6.23,2,0,"['ret', 'fixedww']","[None, None]","[None, None]",1554,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio.py:folio_cost_turnover,folio_cost_turnover,function,26,88,71,825,9.38,1,1,"['wwall', 'bsk', 'dateref', 'costbp']","[None, None, None, None]","[None, None, None, None]",1567,[],"['len', 'np.zeros', 'xrange', 'np.sum', 'plot_price', 'date1=dateint_tostring']",6
utilmy/zarchive/py2to3/portfolio.py:folio_riskpa,folio_riskpa,function,20,52,40,422,8.12,2,0,"['ret', 'targetvol', 'volrange', 'cap']","[None, None, None, None]","[None, '0.1', '90', '1.0']",1597,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.sum', 'np.std', 'min', 'list']",8
utilmy/zarchive/py2to3/portfolio.py:folio_perfreport_schedule,folio_perfreport_schedule,function,14,20,19,189,9.45,1,0,"['sym', 'dateref', 'close', 'wwind', 't0', 'scheduleperiod']","[None, None, None, None, None, None]","[None, None, None, None, None, '""1monthend""']",1911,[],"['np.shape', 'generate_schedule', 'np.zeros', 'enumerate']",4
utilmy/zarchive/py2to3/portfolio.py:folio_concenfactor2,folio_concenfactor2,function,7,12,12,103,8.58,0,0,"['ww', 'masset']","[None, None]","[None, '12']",2211,[],"['getweight', 'np.sum', 'np.mean']",3
utilmy/zarchive/py2to3/portfolio.py:calcbasket_objext,calcbasket_objext,function,50,203,96,1094,5.39,1,7,"['RETURN', 'TMAX', 'riskind_i', 'wwmat', 'wwasset0', 'ww0', 'nbrange', 'criteria']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",2229,[],"['xrange', 'np.sum', 'math.sqrt']",3
utilmy/zarchive/py2to3/portfolio.py:calc_ranktable,calc_ranktable,function,20,44,41,351,7.98,1,0,"['close2', 'symjp1', 'nlag', 'refindex', 'funeval', 'funargs']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",3639,[],"['np.zeros', 'getlogret_fromquotes', 'enumerate', 'funeval', 'util.np_sortbycolumn']",5
utilmy/zarchive/py2to3/portfolio.py:similarity_correl,similarity_correl,function,7,10,9,88,8.8,0,0,"['ret_close2', 'funargs']","[None, None]","[None, None]",3659,[],['correlation_mat'],1
utilmy/zarchive/py2to3/portfolio.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3714,[],['np_distance_l1'],1
utilmy/zarchive/py2to3/portfolio.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3720,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/py2to3/portfolio.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3714,[],['np_distance_l1'],1
utilmy/zarchive/py2to3/portfolio.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3720,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/py2to3/portfolio.py:get,get,function,11,44,26,436,9.91,0,1,"['close', 'timelag']","[None, None]","[None, None]",4085,"['    """"""Return dataframe of requested dataset from Quandl.\n', '    :param dataset: str or list, depending on single dataset usage or multiset usage\n', '            Dataset codes are available on the Quandl website\n', '    :param str api_key: Downloads are limited to 50 unless api_key is specified\n', '    :param str start_date, end_date: Optional datefilers, otherwise entire dataset is returned\n', '    :param str collapse: Options are daily, weekly, monthly, quarterly, annual\n', '    :param str transform: options are diff, rdiff, cumul, and normalize\n', '    :param int rows: Number of rows which will be returned\n', '    :param str order: options are asc, desc. Default: `asc`\n', '    :param str returns: specify what format you wish your dataset returned as,\n', '        either `numpy` for a numpy ndarray or `pandas`. Default: `pandas`\n', '    :returns: :class:`pandas.DataFrame` or :class:`numpy.ndarray`\n', '    Any other `kwargs` passed to `get` are sent as field/value params to Quandl\n', '    with no interference.\n', '\n', ""'''\n"", '\n', '\n', '\n', '#--------------------Import data from Yahoo --------------------------------------------------\n', 'def imp_yahoo_getquotes(symbols, start=""20150101"", end=""20160101"", type1=1):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', '# symbols = np.array(symbol1)\n', ' quotes= []; errorlist=[]; correctlist=[]\n', ' for i, symbol in enumerate(symbols) :\n', '   # if np.mod(i,400) ==0 and i != 0 :\n', ""     # print('Waiting 30s'); time.sleep(30)\n"", '   try:   \n', '     array1= quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '     df= pd.DataFrame.from_records(array1)\n', '     quotes.append(df)\n', '     correctlist.append(symbol)\n', '   except :\n', '       errorlist.append(symbol)\n', ""       print('Err: '+symbol)\n"", ' #quotes = [quotes_historical_yahoo(symbol, d1, d2, asobject=True)  for symbol in symbols]\n', ' #print(errorlist) \n', ' if type1==1 :  return quotes, correctlist\n', ' else: return quotes, correctlist, errorlist  \n', '\n', '              \n', '#Find error in Ticker import\n', 'def imp_yahoo_geterrorticker(symbols, start=""20150101"", end=""20160101""):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', ' errorlist= []\n', ' for symbol in symbols :\n', '   try :  \n', '     quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '   except :\n', '     errorlist.append(symbol)\n', '     print(symbol)       \n', ' return errorlist\n', ' \n', ""'''\n"", ""symbols0= ['KHC', 'PYPL', 'HPE', 'BXLT', 'SYF', 'WLTW', 'CFG', 'BF-B', 'WRK']\n"", '\n', '#Show list of ticker in error\n', 'import_errorticker(symbols0,""20110101"",""20150601""  )\n', ""'''\n"", '\n', '\n', 'def imp_yahoo_financials_url(ticker_symbol, statement=""is"", quarterly=False):\n', '    if statement == ""is"" or statement == ""bs"" or statement == ""cf"":\n', '        url = ""https://finance.yahoo.com/q/"" + statement + ""?s="" + ticker_symbol\n', '        if not quarterly:\n', '            url += ""&annual""; return BeautifulSoup(requests.get(url).text, ""html.parser"")\n', '    return sys.exit(""Invalid financial statement code \'"" + statement + ""\' passed."")\n', '\n', 'def imp_yahoo_periodic_figure(soup, yahoo_figure):\n', '    values = []; pattern = re.compile(yahoo_figure)\n', '\n', '    title = soup.find(""strong"", text=pattern)    # works for the figures printed in bold\n', '    if title:  row = title.parent.parent\n', '    else:\n', '        title = soup.find(""td"", text=pattern)    # works for any other available figure\n', '        if title:  row = title.parent\n', '        else:      sys.exit(""Invalid figure \'"" + yahoo_figure + ""\' passed."")\n', '\n', '    cells = row.find_all(""td"")[1:]    # exclude the <td> with figure name\n', '    for cell in cells:\n', '        if cell.text.strip() != yahoo_figure:    # needed because some figures are indented\n', '            str_value = cell.text.strip().replace("","", """").replace(""("", ""-"").replace("")"", """")\n', '            if str_value == ""-"": str_value = 0\n', '            value = int(str_value) * 1000\n', '            values.append(value)\n', '\n', '    return values\n', '    \n', '# print(imp_yahoo_periodic(imp_yahoo_financials_url(""AAPL"", ""is""), ""Income Tax Expense""))\n', '\n', ' \n', '\n', '#--------------------Import Quotes Google  ------------------------------------------\n', 'import requests.packages.urllib3\n', 'requests.packages.urllib3.disable_warnings()\n', 'import urllib, os\n', '\n', ""dirstockcsv= 'E:\\_data\\stock\\csv'\n"", '\n', 'def imp_googleIntradayQuote(symbol, freqsec=300, nday=5):\n', ""    ''' Intraday quotes from google. Specify interval seconds and number of days\n"", '    http://www.google.com/finance/getprices?q=7261&i=300&p=3d&f=d,o,h,l,c,v\n', ""    '''\n"", '    url =""http://www.google.com/finance/getprices?q={0}"".format(symbol)\n', '    url +=""&i={0}&p={1}d&f=d,o,h,l,c,v"".format(freqsec, nday)\n', '    try :      \n', '       resp= requests.post(url)\n', '       csv= resp.text\n', '       csv= csv.splitlines()\n', '    except :\n', ""       print('Err Intaday '+symbol)\n"", '\n', '    if len(csv) < 9 :\n', ""      print 'Using Daily',\n"", '\n', ""      url='http://www.google.com/finance/historical?q='+symbol+'&i='+str(freqsec)+'&p=3d&f=d,o,h,l,c,v&output=csv'\n"", '      csv = urllib.urlopen(url).readlines()\n', '      csv.reverse()\n', '      q=[]\n', '      for bar in xrange(0,len(csv)-1):\n', ""        ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '        if isfloat(open_) and isfloat(high) :\n', '          open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""          dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '          q.append([dt,open_,high,low,close,volume])\n', ""      df= util.pd_array_todataframe(q, ['date','open','high','low','close','volume'])\n"", '      return df\n', '\n', '\n', '    # print(csv)\n', '    qq=[]\n', '    for bar in xrange(7,len(csv)):\n', ""      if csv[bar].count(',')!=5: continue\n"", ""      offset,close,high,low,open_,volume = csv[bar].split(',')\n"", '      \n', ""      if offset[0]=='a':\n"", '        day = float(offset[1:])\n', '        offset = 0\n', '      else:\n', '        offset = float(offset)\n', '      open_, high, low, close = [float(x) for x in [open_,high,low,close]]\n', '      dt = datetime.datetime.fromtimestamp(day + (freqsec * offset))\n', '      #print (dt,open_,high,low,close,volume)\n', '      qq.append([dt,open_,high,low,close,volume])\n', ""    df= util.pd_array_todataframe(qq, ['date','open','high','low','close','volume'])\n"", '    return df\n', '\n', ""def imp_googleIntradayQuoteSave(symbols=['NKE'], freqsec=300, nday=2000, dircsv='', dbname=''):\n"", "" ''' Save Under various format: csv / db / output in Dataframe '''\n"", ' if isinstance(symbols, str) : symbols= [symbols]\n', ' symout,qlist, sym_error= [], [], []\n', ' for sym in symbols:\n', '   try :\n', '    q = imp_googleIntradayQuote(sym, freqsec, nday)  #interval, timeframe\n', '    print sym,\n', ""    sym= sym.replace(':', '_')\n"", '\n', ""    if dircsv != '' :\n"", '      if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""      start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""      file1= dircsv+ '\\\\' + sym + '_' + str(start1) + '_' + str(freqsec) + '_' + str(nday) + '.csv'\n"", '\n', ""      q= util.pd_addcol(q, 'symbol'); q['symbol']= sym\n"", '      q.to_csv(file1, index=False)\n', '\n', ""    elif dbname != '' :\n"", '      import sqlalchemy as sql\n', '      dbcon= sql.create_engine(dbname)\n', '      if interv_sec== 300 : # 5mins\n', ""        q.to_sql('q5min', dbcon)\n"", '\n', '    else :\n', '      qlist.append(q);   symout.append(sym)\n', '   except:\n', ""      print('Error:'+sym, )\n"", '      sym_error.append(sym)\n', '\n', ' return qlist, symout, sym_error\n', '\n', ""def imp_googleQuote(symbol, start_date='20160101', end_date= '20160101') : # datetime.date.today().isoformat()):\n"", ""    ''' Daily quotes from google. Date format='yyyymmdd' '''\n"", '    symbol = symbol.upper()\n', '    start = datetime.date(int(start_date[0:4]),int(start_date[4:6]),int(start_date[6:8]))\n', '    end =   datetime.date(int(end_date[0:4]),int(end_date[4:6]),int(end_date[6:8]))\n', '    url =""http://www.google.com/finance/historical?q={0}"".format(symbol)\n', '    url +=""&startdate={0}&enddate={1}&output=csv"".format( start.strftime(\'%b %d, %Y\'),end.strftime(\'%b %d, %Y\'))\n', '    csv = urllib.urlopen(url).readlines()\n', '    csv.reverse()\n', '    # print(url)\n', '    q=[]\n', '    for bar in xrange(0,len(csv)-1):\n', ""      ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '      if isfloat(open_) and isfloat(high) :\n', '        open_,high,low,close = [float(x) for x in [open_, high, low, close]  ]\n', ""        dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '        q.append([dt,open_,high,low,close,volume])\n', '    return  pd.DataFrame(np.array(q), columns= [""date"",""open"",""high"",""low"",""Close"",""volume""])\n', '\n', '\n', 'def imp_googleQuoteSave(symbols, date1, date2, dircsv):\n', ' if isinstance(symbols, str) : symbols= [symbols]\n', ' for sym in symbols:\n', '   try :\n', '      q = imp_googleQuote(sym, date1, date2)   #interval, timeframe\n', ""   except: print('Error:'+symbol)\n"", '\n', ""   sym= sym.replace(':', '_')\n"", '\n', ""   if dircsv != '' :\n"", '     if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""     start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""     file1= dircsv+ '\\\\'+ name1+'_'+ start1 +'_'+ str(date2) +'.csv'\n"", '     q.to_csv(file1)\n', '\n', ""   if dbname != '' :\n"", '     import sqlalchemy as sql\n', '     dbcon= sql.create_engine(dbname)\n', '     if interv_sec== 300 : # 5mins\n', ""       q.to_sql('q5min', dbcon)\n"", '\n', '\n', '\n', ""def imp_csv_dbupdate(indir='E:/_data/stock/intraday/intraday_google_usetf2.h5',\n"", ""                     outdir='E:/_data/stock/intraday/q5min/us/etf/', filelist=[], intype='csv',\n"", ""                     refcols=['date', 'open', 'high', 'low', 'close', 'volume', 'symbol']) :\n"", '\n', '  for file1 in filelist :\n', ""    sym=  file1[:file1.find('_')]  #Clean Up name\n"", '    print sym,\n', ""    outfile= outdir+'/'+sym+'.csv'\n"", '    if os.path.isfile(outfile) :\n', ""      df0= imp_csv_toext(file1=outfile, fromzone='Japan', tozone='UTC', header=0, cols=refcols)\n"", '    else :\n', '      df0= None\n', '\n', ""    if intype== 'hdfs':\n"", '      df1= imp_hdfs_getquote(indir, sym)\n', '      if isinstance(df1, float) : df1= None\n', '\n', ""    if intype=='csv' :\n"", ""      infile= indir+'/'+ file1   #csv\n"", ""      df1= imp_csv_toext(file1=infile, header=0, cols=refcols, fromzone='Japan', tozone='UTC')\n"", '\n', '    if df1 is not None :\n', '       if df0 is not None  : df1= imp_pd_merge(df1[refcols], df0[refcols])\n', '       # return outfile, df1\n', '       df1[refcols].to_csv(outfile, index=False)\n', '\n', '\n', '#####################################################################################\n', 'def imp_numpy_close_fromdb(dbname=\'/aaserialize/store/yahoo.db\', table1=\'\', symlist=[], t0=20010101, t1=20010101, priceid=""close"", batchsize= 400, maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from DB SQL"")\n', ' import data.hist_data_storage as yhh\n', ' dstore= yhh.dailyDataStore(dbname)\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', '\n', "" dateref0= dstore.get_histo(['SPY'], table1='daily_us_etf', start1=str(t0), end1=str(t1),  split_df=0).date.values\n"", ' \n', ' k=0; symfull=[];   i=0\n', ' nsym= len(symlist); nbatch= int(nsym / batchsize)+1\n', ' for j in xrange(0, nbatch) : \n', '      qlist, sym= dstore.get_histo(symlist[i:min(nsym,i+batchsize)], table1=table1, start1=str(t0), end1=str(t1),  split_df=1)\n', '\n', '      #print(""batch: ""+str(j), len(qlist), len(qlist[0].index) )\n', '      #for k,q in enumerate(qlist) :print sym[k], len(q.index)\n', '      i= i + batchsize\n', '      symfull= np.concatenate((symfull,sym))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)\n', '      print(""batch: ""+str(j), len(sym),dateref[0],dateref[-1] )\n', '      qlist=None; sym=None\n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[k:k+masset,0:tmax] = close\n', '      k=k+ masset\n', '\n', ' maxasset= k\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', 'def imp_numpy_close_fromhdfs(dbfile, symlist=[], t0=20010101, t1=20010101, priceid=""close"", maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from Pandas"")\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', ' store = pd.HDFStore(dbfile)\n', ' \n', "" df= store.select('SPY')\n"", ' df= df[(df.date >= t0) & (df.date <= t1 )]\n', ' dateref0= df.date.values\n', ' \n', ' k=0; symfull=[]; qlist=[]; sym=[]; tmax= 2000\n', ' for j, symbol in enumerate(store.keys()):\n', '  symbol=  symbol[1:]\n', '\n', '  if len(symlist)==0  or  util.find(symbol,symlist) > -1 : \n', '   #print symbol, util.find(symbol,symlist) \n', '   df= store.select(symbol) \n', '   if t0 !=t1 :     df= df[(df.date >= t0) & (df.date <= t1 )]\n', '   \n', '   qlist.append(df);   sym.append(symbol)\n', '   if np.mod(j+1, 401) == 0 :\n', '      print(""batch: ""+str(j))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)   \n', '      print len(sym),dateref[0],dateref[-1] \n', '      symfull= symfull+sym\n', '      qlist=[]; sym=[]\n', ' \n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[(k):(k+masset),0:tmax] = close\n', '      k=k+ masset   \n', '     \n', ' if len(qlist) > 0:\n', '  # return qlist, qlist[0] ,  qlist[1] \n', '   close,dateref= date_align(qlist,type1=priceid)   \n', '   print len(sym),dateref[0],dateref[-1] \n', '   symfull= symfull+sym\n', '   masset,tmax= np.shape(close);\n', '   close2[(k):(k+masset),0:tmax] = close\n', ' \n', ' maxasset= k+masset\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', '\n', ""def imp_sql_getquotes(stocklist01, dbname='sqlite:///aaserialize/store/yahoo.db', start1=20150101, end1=20160616, table1='daily_us_stock'):\n"", '    import data.hist_data_storage as yhh\n', '    dstore = yhh.dailyDataStore(dbname)\n', '    qlist, sym= dstore.get_histo(stocklist01, table1=table1,  start1=start1, end1=end1, split_df=1)\n', '    return qlist, sym\n', '\n', ""def imp_txt_getquotes(stocklist01, filedir='E:/_data/stock/daily/20160610/jp', startdate=20150101, endate=20160616):\n"", ' liststockfile= util.listallfile(filedir, ""*.txt"", dirlevel=5)\n', ' #print liststockfile\n', ' if len(np.shape(liststockfile)) > 1 :\n', '  liststockname=[ x.split(""."")[0] for x in liststockfile[:,0] ]\n', '#  for k in range(0, np.shape(liststockfile)[0]):  liststockname.append( (liststockfile[k,0])[0:4])   \n', '   \n', ' else: \n', '  stk0= liststockfile[0]; #stk2= liststockfile[2]\n', '#  liststockname=[ x[0:4] for x in stk0 ]\n', '  liststockname=[ x for x in stk0 ]\n', '\n', '#  liststockname=[]\n', '#  for k in range(0, len(stk0)):  liststockname.append( (stk0[k])[0:4])\n', ' \n', ' quotes=[]\n', ' print liststockname\n', ' for sym in stocklist01:\n', '   kstock= util.np_findfirst(sym, liststockname)\n', '   if kstock == -1 :\n', ""     print('Not Found '+sym)\n"", '   else :\n', '     df= pd.read_csv(liststockfile[kstock][2])\n', ""     df.columns = ['date', 'open', 'high','low','close', 'volume', 'openint']  #Change Column Name\n"", '     df2= df[(df.date > startdate  )& ( df.date   < endate )] # Filter by date\n', '     quotes.append(df2)\n', '  \n', ' return quotes \n', '\n', '\n', 'def imp_csv_getname(name1, date1, inter, tframe):\n', "" file1= dirstockcsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", ' return file1\n', '\n', '\n', ""def imp_csv_toext(file1='SPY.csv', outputfile='.h5', fromzone='Japan', tozone='UTC', header=None,\n"", ""                  cols=['date', 'time','open','high','low','close','volume', 'symbol'], coldate=[0]):\n"", ""  ''' cols: column name,  coldate: position of date column   '''\n"", '  from dateutil import parser\n', '\n', '  if os.path.getsize(file1)> 500 :\n', ""   df = pd.read_csv(file1,sep=',',header=header)  # date_parser=dateparse)  # parse_dates={'date': [] },\n"", '   df.date= [ parser.parse(x) for x in  df.date]\n', '\n', ""   #if util.find('symbol', df.columns.values) < 0 :\n"", ""     #df= util.pd_addcol(df, 'symbol')\n"", ""     #df['symbol']= sym\n"", '\n', ""   type1= outputfile[outputfile.find('.'):]\n"", '\n', ""   if outputfile=='':\n"", '     # df.columns = [  x.lower() for x in df.columns.values ]\n', ""     # df.columns = ['date', 'symbol','open','high','low','close','volume']\n"", '     df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""     df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""     df.columns = ['date', 'open','high','low','close','volume', 'symbol']\n"", '     return df[cols]\n', '\n', ""   if type1=='csv' :\n"", ""     df[cols].to_csv(outputfile , index=False)  # , compression='gzip' )\n"", '\n', ""   if type1== 'h5' :\n"", ""      # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '      dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '      # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '      # df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '      # df.date= [x.to_datetime() for x in  df.date]\n', '\n', '      df.drop(df.columns[[0]], axis=1, inplace=True)\n', '      print filenameh5\n', ""      if util.find('symbol', df.columns.values) < 0 :\n"", ""         df= util.pd_addcol(df, 'symbol'); df['symbol']= dfname\n"", '      store = pd.HDFStore(outputfile); store.append(dfname, df);  store.close()\n', '\n', '\n', '\n', ""def imp_hdfs_db_updatefromcsv(dircsv, filepd=r'E:\\_data\\stock\\intraday_google.h5', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= filepd + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2, name1, fromtimezone, tozone)\n', '\n', ""def imp_hdfs_db_dumpinfo(dbfile='E:\\_data\\stock\\intraday_google.h5'):\n"", '  store = pd.HDFStore(dbfile)\n', '  extract=[]; errsym=[]\n', '  for symbol in store.keys():\n', '     try:\n', '       df= pd.read_hdf(dbfile, symbol)\n', ""       t0= df['date'].values[0]\n"", ""       t1= df['date'].values[-1]\n"", '\n', '       extract.append([symbol[1:], df.shape[1],   df.shape[0], t0, t1 ])\n', '\n', '     except: errsym.append(symbol)\n', '  return np.array(extract), errsym\n', '\n', 'def imp_hdfs_mergedb(filepdfrom, filepdto) :\n', '  store0 = pd.HDFStore(filepdfrom)\n', '  store1 = pd.HDFStore(filepdto)\n', '\n', '  for symbol in store0.keys():\n', '    qq= imp_hdfs_getquote(filepdfrom, symbol)\n', '    store1.append(symbol, qq)\n', '\n', '    qq= imp_hdfs_getquote(filepdto, symbol)\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    print(symbol)\n', '  store0.close(); store1.close()\n', '\n', ""def imp_hdfs_storecopy(hdfs1='F:/usstock8.h5', hdfs2='F:/usstock8.h5'):\n"", ' store = pd.HDFStore(hdfs1);  store2 = pd.HDFStore(hdfs2)\n', ' for symbol in store.keys() :\n', '   df= imp_hdfs_getquote(hdfs1, symbol)\n', '   symbol= symbol[1:].replace(""-"",""_"")\n', '   store2.append(symbol, df, data_columns=True)\n', ' store.close(); store2.close()\n', '\n', 'def imp_hdfs_getquote(filenameh5, dfname=""data""):\n', '  try: return  pd.read_hdf(filenameh5, dfname)\n', '  except: return -1.0;\n', '\n', ""def imp_hdfs_getListquote(symbols, close1='close', start='12/18/2015 00:00:00+00:00',\n"", ""                          end='3/1/2016 00:00:00+00:00', freq='0d0h10min', filepd= 'E:\\_data\\stock\\intraday_google.h5',\n"", ""                          tozone='Japan', fillna=True, interpo=True):\n"", '\n', ' datefilter= pd.date_range(start=start, end=end, freq= freq,tz=tozone).values\n', '\n', ' errorsym=[]; quotes=[]; correctsym=[]\n', ' for symbol in symbols:  # Issue Not same size\n', '   qq= imp_hdfs_getquote(filepd, symbol)\n', '\n', '   if type(qq)==np.float :  # Error qq=-1\n', '        errorsym.append(symbol)\n', '   else:\n', ""       qq.columns = ['date', 'symbol','open','high','low','close','volume']\n"", ""       qq= qq[qq['date'].isin(datefilter)]   #Only date in the range\n"", ""       #qq= qq.drop_duplicates(cols='date', take_last=True)\n"", ""       #  qq= qq.sort('date', asc=True)\n"", '\n', '       #print qq.date.values[0]\n', ""       if fillna : qq= qq.fillna(method='backfill')\n"", '       if interpo : qq= qq.interpolate()\n', '       quotes.append(qq)\n', '       correctsym.append(symbol)\n', '\n', ' datefilter= datenumpy_todatetime(datefilter)\n', ' return quotes,datefilter, correctsym,   errorsym\n', '\n', '\n', ""def imp_hdfs_removeDuplicate(filepd='E:\\_data\\stock\\intraday_google.h5') :\n"", '  #-------Clean by removing duplicate-------------------------------------------------\n', '  store = pd.HDFStore(filepd)\n', '  for symbol in store.keys():\n', '    #qq= imp_hdfs_getquote(filepd, symbol);\n', '    qq= store.select(symbol[1:])\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    qq.index = list(np.arange(0,len(qq.index)))\n', '\n', '    store.remove(symbol); store.append(symbol, qq);\n', '  store.close()\n', '\n', '\n', '\n', ""def imp_pd_tohdfs(sym, qqlist, filenameh5, fromzone='Japan', tozone='UTC') :\n"", ""  ''' df list to HDFS '''\n"", '  store = pd.HDFStore(filenameh5);\n', '  for k, df2 in enumerate(qqlist) :\n', '    df= copy.deepcopy(df2)\n', ""    df['date']= datetime_toint(df.date.values)\n"", '\n', ""    symbol= sym[k].replace('-','_')\n"", '    qq= imp_hdfs_getquote(filenameh5, symbol)\n', '    # print symbol, type(qq)\n', '    if type(qq) ==  float or  type(qq) ==  int  :\n', '      store.append(symbol, df)  # , data_columns=True\n', '      # print(symbol + str(df.date.values[-1]))\n', '    else :\n', '      qq= pd.concat([qq, df], ignore_index=True)\n', ""      qq= qq.drop_duplicates(subset='date', keep='last')\n"", ""      qq= qq.sort('date', ascending=1)\n"", '      store.append(symbol, qq)  #Too much space , data_columns=True\n', '      print(symbol + str(qq.date.values[-1]))\n', '\n', '  store.close()\n', '\n', 'def imp_pd_merge(df1, df2) :\n', '  df= pd.concat([df1, df2], axis=0)\n', ""  df= df.drop_duplicates(subset='date', keep='last')\n"", ""  df= df.sort_values(by=['date'], ascending=1)\n"", '  df.index = list(np.arange(0,len(df.index)))\n', '  return df\n', '\n', 'def imp_pd_checkquote(quotes) :\n', ""   for c in quotes: print np.shape(c), c['date'].values[0], c['date'].values[-1]\n"", '\n', 'def imp_pd_getclose(df, datefilter=None):\n', ' if datefilter is  not None :\n', ""    df= df[df['date'].isin(datefilter)]   #Only date in the range\n"", "" df= df.sort('date')\n"", "" close= df.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", ' \n', ' close= np.array(close.values[1:,1:]).astype(np.float)            #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close\n', '\n', 'def imp_pd_cashyield(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  100 * np.cumprod( (1 + np.ones(len(vv)) * 0.005/365.0 ))\n', '     qbond[id1]= pbond\n', '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_yield_tobond(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  1/ np.power(1+ vv*0.01,duration) *100\n', '     qbond[id1]= pbond\n', ""#     print 'ok'\n"", '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_errordate(quotes, dateref):\n', "" ''' Show Symbol in Error when importing '''\n"", ' for i, stock in enumerate(quotes) :\n', '   print(i, symbols1[i],  datetime_tostring(stock[0][0]))\n', ' print(""\\n\\n"")\n', '\n', ' for i, stock in enumerate(quotes) :\n', '   date1= datetime_toint(stock[0][0])\n', '   if date1 != dateref : print(i, symbols1[i],  str(date1))\n', '\n', 'def imp_pd_fxtoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', 'def imp_pd_fxinversetoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(1.0 / q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', ""def imp_pd_filterbydate(df, dtref=None, start='2016-06-06 00:00:00', end='2016-06-14 00:00:00', freq='0d0h05min', timezone='Japan'):\n"", "" ''' df: DateSeries or TimeSeries of Quotes   '''\n"", '\n', ' if type(df) in {pd.core.frame.DataFrame} :  #Data frame version\n', '   if type(dtref)== str:\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', ""   return df[df['date'].isin(dtref)]\n"", ' else :\n', '   if type(dtref)== str:  #Date version\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', '   return df[df.isin(dtref)].values\n', '\n', 'def imp_pd_cleanquote(q):\n', ' col= q.columns.values\n', "" if isinstance(q['date'].values[0] , str) :\n"", ""   q['date']= datetime_todate(datestring_todatetime(q['date'].values))\n"", '\n', ' for kid in col:\n', ""   if kid not in ['date', 'day','month','year'] :\n"", ""      q[kid]= pd.to_numeric(q[kid], errors='coerce').values  #Put NA on string\n"", '\n', "" q= q.fillna(method='pad')\n"", ' return q\n', '\n', 'def imp_pd_divide(q1, q2, funapply):\n', "" close, dateref= date_align([q1,q2], type1='close')\n"", ' m,tt= np.shape(close)\n', '\n', ' q3= util.pd_createdf( np.zeros((tt,len(q1.columns))) ,q1.columns, dateref)\n', "" q3['date']= dateref\n"", "" q3['close']= (close[0,:] / close[1,:])\n"", '\n', ' for kid in q1.columns :\n', ""   if kid not in ['close', 'volume','date','day','month', 'year'] :\n"", '     close, _= date_align([q1,q2], type1=kid)\n', '     q3[kid]= (close[0,:] / close[1,:])\n', ' return q3\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""def imp_quote_csvdir_tofile(dircsv='', outdir1='E:/_data/stock/', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= outdir + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2,  header=True, fromzone=fromtimezone, tozone=tozone)\n', ""'''\n"", '\n', '\n', ""'''\n"", ""close1='Close' ; start='12/18/2015 00:00:00';\n"", ""end='3/1/2016 00:00:00'; freq='1d0h00min';\n"", ""filepd= 'E:\\_data\\stock\\intraday_google.h5'\n"", '\n', 'datefilter= pd.date_range(start=start, end=end,   freq= freq).values\n', '\n', 'symbols, names = np.array(list(symbol_dict.items())).T\n', 'i=0; vv=[]\n', 'for symbol in symbols:  # Issue Not same size\n', '   qq= quote_frompanda(filepd, symbol); i+=1\n', '   if isfloat(qq) :  vv.append(symbol)\n', '   else:\n', ""     if i==1: close = qq[['Datetime']]  #new dataframe    \n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', '     if not tmp.isnull().values.all():\n', ""      close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""      close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', ""close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", ""close= close.sort('Datetime')\n"", ""close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", 'close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', 'close= close[(np.abs(stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', ""'''\n"", 'from datetime import datetime\n', 'from dateutil import tz\n', '\n', ""from_zone = tz.gettz('Japan'); to_zone = tz.gettz('UTC')\n"", '\n', ""date1 = datetime.strptime('2011-01-21 09:00:00', '%Y-%m-%d %H:%M:%S')\n"", 'date1 = date1.replace(tzinfo=from_zone)\n', 'dateutc = date1.astimezone(to_zone)\n', 'date1, dateutc\n', '\n', ""Suppose you have a column 'datetime' with your string, then:\n"", ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\n"", ' combine multiple columns into a single datetime column,\n', ""this merges a 'date' and a 'time' column into a single 'datetime' column:\n"", '\n', ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)\n"", ""'''\n"", '\n', '\n', '#date1 = ""20160302""; inter= 60; tframe=80; name1= ""spy""\n', '#googleIntradayQuoteSave(name1, inter, tframe)\n', '\n', '\n', '\n', 'def ta_mar(close,t,m):  return  100*( np.mean(close[(t-m):(t+1)], axis=0) / close[t] )\n', 'def ta_ma(close,t,m):  return   np.mean(close[(t-m):(t+1)], axis=0)\n', '\n', '\n', '############################################################################\n', '#---------------------Calculate the Statistics         --------------------  \n', 'def calc_statestock(close2, dateref, symfull):\n', ' def sort(x,col,asc): return   util.sortcol(x,col,asc)\n', ' def perf(close,t0,t1):  return  100*( close[:,t1] / close[:,t0] -1)\n', ' def and2(tuple1):  return np.logical_and.reduce(tuple1)\n', ' def mar(close,t,m):  return  100*( np.mean(close[:,(t-m):(t+1)], axis=1) / close[:,t] )\n', ' def ma(close,t,m):  return   np.mean(close[:,(t-m):(t+1)], axis=1)\n', '\n', '\n', ' # a= ma(close2, tmax, 5) / ma(close2, tmax, 50)  \n', '\n', '\n', ' def dd(t) :\n', '  x= util.find(t,dateref)  # 607\n', ""  if x==-1 : print 'Error date not found in dateref '+str(t) ; return np.nan\n"", '  else :  return x\n', '\n', ' def gap(close,t0,t1,lag):   \n', '  ret= getret_fromquotes(close[:,t0:t1],lag)\n', '  rmin= 100*np.amin(ret,axis=1)\n', '  return rmin\n', ' \n', ' #--------------------Size----------------------------------------- \n', ' masset= len(symfull)\n', ' ttmax= util.find(0,close2[0,:])\n', ' if ttmax==-1 : ttmax= np.shape(close2)[1]\n', ' close2= close2[0:masset,0:ttmax]\n', ' m, tmax= masset, ttmax-1\n', ' \n', ' #correl\n', ' #close3= np.array(close2[:,0:ttmax],dtype=np.float16)\n', ' #close2ret= getret_fromquotes(close3)\n', ' #close2ret= np.nan_to_num(close2ret)\n', ' #close2ret= util.np_cleanmatrix(close2ret);  del close3\n', '\n', '##################################################################################\n', '#1: 1d,2:5d,3:10d,4:15d,5:20d,11:50d,12:60d,13:90d,15:1y\n', '#16: YTD,17:From Feb,21: 2015Ret,45: Price,50,51: Min,52,53: Max\n', ' print(""Calcul the Stats "" + str(dateref[-1]))\n', ' stat= np.zeros((2600,200),dtype=np.float16)\n', '\n', ' k=0\n', ' stat[k:(k+m),0]= np.arange(k,k+m)\n', ' stat[k:(k+m),1]=  perf(close2,tmax-1,tmax)  \n', ' stat[k:(k+m),2]=  perf(close2,tmax-5,tmax)  \n', ' stat[k:(k+m),3]=  perf(close2,tmax-10,tmax)  \n', ' stat[k:(k+m),4]=  perf(close2,tmax-15,tmax)  \n', ' stat[k:(k+m),5]=  perf(close2,tmax-20,tmax)  \n', '# stat[k:(k+m),6]=  perf(close2,tmax-25,tmax)  \n', ' stat[k:(k+m),7]=  perf(close2,tmax-30,tmax)  \n', '# stat[k:(k+m),8]=  perf(close2,tmax-35,tmax)  \n', ' stat[k:(k+m),9]=  perf(close2,tmax-40,tmax)  \n', '# stat[k:(k+m),10]=  perf(close2,tmax-45,tmax)  \n', ' stat[k:(k+m),11]=  perf(close2,tmax-50,tmax)  \n', ' stat[k:(k+m),12]=  perf(close2,tmax-60,tmax)  \n', ' stat[k:(k+m),13]=  perf(close2,tmax-90,tmax)  \n', ' stat[k:(k+m),14]=  perf(close2,tmax-120,tmax)  \n', ' stat[k:(k+m),15]=  perf(close2,tmax-250,tmax)  \n', '\n', '\n', '# stat[k:(k+m),16]=  perf(close2, dd(20160105),tmax)   #1Jan 2016\n', '# stat[k:(k+m),17]=  perf(close2, dd(20160222),tmax)   # 22 Feb 2016\n', '# stat[k:(k+m),18]=  perf(close2,dd(20160105),dd(20160222))   # Crash DrawDown\n', ' # stat[k:(k+m),19]=  perf(close2,624,tmax)   #  24 June 2016\n', ' # stat[k:(k+m),20]=  perf(close2,623,625)   #  Crash 24 June 2016\n', ' # stat[k:(k+m),21]=  perf(close2,dd(20151230)-250,dd(20151230))    #2015 Return\n', '\n', ' stat[k:(k+m),22]= gap(close2,tmax-80,tmax,1) #Max 1 days Gap\n', ' stat[k:(k+m),23]= gap(close2,tmax-80,tmax,5) #Max 5 days Gap\n', ' stat[k:(k+m),24]= perf(close2,tmax-2,tmax)  \n', ' stat[k:(k+m),25]= perf(close2,tmax-3,tmax)  \n', ' stat[k:(k+m),26]= perf(close2,tmax-4,tmax)  \n', '\n', ' stat[k:(k+m),27]= perf(close2,tmax-2,tmax-1)   \n', ' stat[k:(k+m),28]= perf(close2,tmax-3,tmax-2)   \n', ' stat[k:(k+m),29]= perf(close2,tmax-4,tmax-3)   \n', ' stat[k:(k+m),30]= perf(close2,tmax-5,tmax-4)\n', ' \n', ' stat[k:(k+m),120]= mar(close2, tmax, 20) \n', ' stat[k:(k+m),121]= mar(close2, tmax, 50) \n', ' stat[k:(k+m),122]= 100*ma(close2, tmax, 5) / ma(close2, tmax, 50)  #OverSold /OverBought\n', ' stat[k:(k+m),123]= mar(close2, tmax, 100)  \n', ' stat[k:(k+m),124]= mar(close2, tmax, 10) \n', '# stat[k:(k+m),35]= 0 \n', '# stat[k:(k+m),36]= 0 \n', '# stat[k:(k+m),37]= 0 \n', '# stat[k:(k+m),38]= 0 \n', '# stat[k:(k+m),39]= 0 \n', '\n', ' # stat[k:(k+m),30]= volume / AvgVol3M\n', ' # stat[k:(k+m),30]= Nbday_to_Earnings\n', ' #Volume/3M AvgVolume\n', ' # stat[k:(k+m),26]=  volume(volume2,tmax-120,tmax)  \n', '\n', ' #==============================================================================\n', ' #-------------- Data Fundamental    -------------------------------------------\n', "" df= util.sql_query(sqlr='SELECT ticker,shortratio,sector1_id, sector2_id, marketcap   FROM stockfundamental ', dburl='/aaserialize/store/finviz.db')\n"", ' npdf= df.values; del df\n', ' npdf0= npdf[:,0]  \n', ' for i in range(0,m):  \n', '   try :\n', '     kid= util.find(symfull[i], npdf0)\n', '     if kid != -1 :\n', '      stat[i,150]=  float(npdf[kid, 1])   # short ratio\n', '      stat[i,151]=  float(npdf[kid, 2])   # sector 1      \n', '      stat[i,152]=  float(npdf[kid, 3])   # sector 2     \n', '      stat[i,153]=  float(npdf[kid, 4] / 100000000.0)   # market Cap    \n', '   except : pass\n', ' del npdf, npdf0\n', '\n', '\n', '#==============================================================================\n', ' ################ Volatility\n', ' stat[k:(k+m),40]= volhisto_fromprice(close2,tmax,20,axis=1)* 100\n', ' stat[k:(k+m),41]= volhisto_fromprice(close2,tmax,60,axis=1)* 100\n', ' stat[k:(k+m),42]= volhisto_fromprice(close2,tmax,252,axis=1)* 100\n', '# stat[k:(k+m),43]= stat[k:(k+m),12] / stat[k:(k+m),41] #Sharpe 3Month\n', '# stat[k:(k+m),44]= stat[k:(k+m),15] / stat[k:(k+m),42] #Sharpe 1Year\n', '\n', ' stat[k:(k+m),45]= close2[:,tmax] #Last Close\n', '\n', '# stat[k:(k+m),46]= 0 \n', '# stat[k:(k+m),47]= 0 \n', '# stat[k:(k+m),48]= 0 \n', '# stat[k:(k+m),49]= 0 \n', '\n', '\n', ' ###############  Technical Indicator\n', ' #Min of last 6 months, Max of last 6months\n', ' for i in range(0,m):\n', '  pp0= stat[i,45]\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-120):tmax])\n', '  stat[i,50]= kmin+(tmax-120);  stat[i,51]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-120):tmax])\n', '  stat[i,52]= kmax+(tmax-120);  stat[i,53]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-10):tmax])\n', '  stat[i,66]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-10):tmax])\n', '  stat[i,67]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-5):tmax])\n', '  stat[i,68]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-5):tmax])\n', '  stat[i,69]= 100*pp0 / pmax\n', '\n', ' del kmax,pmax,i,k  \n', '\n', '\n', ' #Regression from Min Price Time\n', ' for i in range(0,m):\n', '  t0= int(stat[i,50])\n', '  try :\n', '    res= regression(close2[i,t0:tmax ]  ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,54]=  res[2]  #R2\n', '    stat[i,55]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from Max Price Time\n', ' for i in range(0,m):  \n', '  t0= stat[i,52]\n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,56]=  res[2]  #R2\n', '    stat[i,57]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from 5 days ago\n', ' t0= tmax-5\n', ' for i in range(0,m): \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,58]=  res[2]  #R2\n', '    stat[i,59]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', '#Regression from 10 days ago\n', ' t0= tmax-10\n', ' for i in range(0,m):  \n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,60]=  res[2]  #R2\n', '    stat[i,61]=  res[0][0]  #Slope\n', '   except : pass\n', '\n', "" '''\n"", '#Regression from 1 month\n', ' t0= tmax-20   \n', ' for i in range(0,m):\n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,62]=  res[2]  #R2\n', '    stat[i,63]=  res[0][0]  #Slope\n', '   except : pass\n', "" '''\n"", '\n', "" '''\n"", '#Regression from 2 months ago\n', ' t0= tmax-40\n', ' for i in range(0,m):  \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,64]=  res[2]  #R2\n', '    stat[i,65]=  res[0][0]  #Slope\n', '  except : pass\n', "" '''\n"", '\n', '#Nb of Positive days last 5d\n', ' for i in range(0,m):  stat[i,66]=  np_countretsign(close2[i,(tmax-5):tmax])  \n', '\n', '#Nb of Positive days last 10d\n', ' for i in range(0,m):  stat[i,67]=  np_countretsign(close2[i,(tmax-10):tmax])  \n', '\n', '#Nb of Positive days last 20d\n', '# for i in range(0,m):  stat[i,68]=  np_countretsign(close2[i,(tmax-20):tmax])  \n', '\n', '\n', '#Regression from Max Values,200days\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,70]=  res[2]  #R2\n', '    stat[i,71]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmax\n', '\n', '\n', '#Regression from Min Values,200days \n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,72]=  res[2]  #R2\n', '    stat[i,73]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmin\n', '\n', '\n', '#Regression from Max Values,100days\n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,74]=  res[2]  #R2\n', '    stat[i,75]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmax\n', '\n', '\n', '#Regression from Min Values,100days \n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,76]=  res[2]  #R2\n', '    stat[i,77]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmin\n', '\n', '\n', '\n', '# Upside Trend with Higher Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '   vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '   vmax= util.sort(vmax,0,asc=0)\n', '   stat[i,80]=  -1\n', '   if len(vmax) > 1 :\n', '    ss=0\n', '    for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '    if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,80]=  ss  \n', '        stat[i,81]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Upside Trend with Higher High detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '    vmax= util.sort(vmax,0,asc=0)\n', '    stat[i,82]=  -1\n', '    if len(vmax) > 1 :\n', '      ss=0\n', '      for k in range(0,len(vmax)-1):\n', '        if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher high\n', '        else : break;\n', '      if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,82]=  ss  \n', '        stat[i,83]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Downside Trend with lower Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,84]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,84]=  ss  \n', '        stat[i,85]=  vmax[0,0] + t0\n', '\n', '\n', '# Downside Trend  with lower highs detection\n', ' t0= tmax-20*6\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,80]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,86]=  ss    #Nb  of lower high consecutive\n', '        stat[i,87]=  vmax[0,0] + t0\n', '\n', "" print('Higher/Lower Band Support')\n"", '#-----higher band Support / Lower Band Support 120days-------------------------------\n', ' t0= tmax-120\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,90]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,91]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,92]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '    # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1]) \n', '    # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 200days-------------------------------\n', ' t0= tmax-200\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,93]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,94]= 100.0 * stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,95]= 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 300days-------------------------------------\n', ' t0= tmax-300\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,96]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,97]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,98]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', ""  '''\n"", '  # -----higher band Support / Lower Band Support 60days-------------------------------\n', '  t0 = tmax - 60\n', '  for i in range(0, m):\n', '      try:\n', '          res1 = ta_highbandtrend1(close2[i, t0:tmax])\n', '          pmax = (res1.x[0] * (tmax - t0) + res1.x[1])\n', '          stat[i, 99] = 100.0 * stat[i, 45] / pmax  # Higher Band\n', '\n', '          res2 = ta_lowbandtrend1(close2[i, t0:tmax])\n', '          pmin = (res2.x[0] * (tmax - t0) + res2.x[1])\n', '          stat[i, 100] = 100.0 * stat[i, 45] / pmin  # LowerBand\n', '\n', '          stat[i, 101] = 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)  # Price inside Range\n', '\n', '          # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1])\n', '          # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '      except:\n', '          pass\n', ""  '''\n"", '\n', '  #-----Technical Indicator------------------------------------------------\n', '# for i in range(0,m): \n', '#  try :\n', '#   res2=0\n', '   # df= pd.read_hdf(dbfile, symfull[i])\n', '   # stat[i,110]= ta.RMI(close2[i,:])\n', '   # stat[i,111]= 100*close2[i,:] / ta.MA(close2[i,:],20)\n', '   # stat[i,112]= 100*close2[i,:] / ta.MA(close2[i,:],50)   \n', '#  except: pass\n', '\n', '\n', ' return np.array(stat, dtype=np.float16) \n', '\n', '\n', ""'''  \n"", 'i=1964  \n', 'stat= s1\n', 'stat[i, 91]  \n', '\n', 'tt= np.arange(t0, tmax)\n', 'plot_price(close2[i,t0:tmax], (res2.x[0] * (tt-t0) + res2.x[1]) )\n', ""'''\n"", '\n', '  \n', '#------------------- Stock Monitoring Tools ------------------------------------------------\n', ""def monitor_addrecommend(string1, dbname='stock_recommend') :\n"", ' ss= string1.replace(""("","" "").replace(\')\',\' \').replace(\':\',\' \')\n', "" ss= ss.replace('\\t', ' ').replace('\\n', ' ')\n"", ' sl1= ss.split("" "")\n', ' print sl1\n', ' aux= [datestring_toint(util.date_now())]\n', ' symfull= copy.deepcopy(a_us_all)\n', ' for x in sl1:\n', '   if len(x) < 5 :\n', '    if util.find(x,symfull) > 0 :   aux.append(x)\n', '\n', ' if len(aux) >  1 :\n', '  stock_recommend= util.load_obj(dbname)\n', '  stock_recommend.append(aux)\n', '  util.save_obj(stock_recommend,dbname)\n', '  print aux\n', ' return stock_recommend\n', '\n', '\n', '\n', '#################### Finviz  ###############################################################\n', 'from bs4 import BeautifulSoup\n', 'import csv,datetime, requests\n', 'def imp_finviz():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Overview Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=111&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(111) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 10].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 10\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockoverview.csv', 'wb') as csvfile:\n"", ""    overview = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    overview.writeheader()\n', '\n', '    for stock in alldata:\n', '        overview.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10] })\n', '\n', ' print ""Finviz Overview Completed""\n', ' return overview\n', ' \n', '\n', 'def imp_finviz_news():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Performance Start""\n', ' url = ""http://www.finviz.com/quote.ashx?t=intc""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', ' titleslist = soup.find_all(\'a\',{""class"" : ""tab-link-news""})\n', ' return titleslist\n', '\n', '\n', 'def imp_finviz_financials():\n', ' import datetime\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=161&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(161) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 17].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 16].text,stockdata[datalength - 15].text,stockdata[datalength - 14].text,stockdata[datalength - 13].text,stockdata[datalength - 12].text,stockdata[datalength - 11].text,stockdata[datalength - 10].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 17\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockfinancial.csv', 'wb') as csvfile:\n"", ""    financial = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    financial.writeheader()\n', '\n', '    for stock in alldata:\n', '        financial.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10],titlesarray[11] : stock[11],titlesarray[12] : stock[12],titlesarray[13] : stock[13],titlesarray[14] : stock[14],titlesarray[15] : stock[15],titlesarray[16] : stock[16],titlesarray[17] : stock[17] })\n', '\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Completed""\n', '\n', '\n', '\n', 'def get_price2book( symbol ):\n', '   from bs4 import BeautifulSoup as bs\n', '   import urllib as u\n', '   try:\n', ""    \turl = r'http://finviz.com/quote.ashx?t={}'.format(symbol.lower())\n"", '        html = u.request.urlopen(url).read()\n', ""        soup = bs(html, 'lxml')\n"", '        # Change the text below to get a diff metric\n', ""        pb =  soup.find(text = r'P/B')\n"", ""        pb_ = pb.find_next(class_='snapshot-td2').text\n"", ""        print( '{} price to book = {}'.format(symbol, pb_) )\n"", '        return pb_\n', '   except Exception as e:\n', '        print(e)\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ' try:\n', '   q = imp_googleQuote(name1, date1, date2)  #interval, timeframe\n', ""   name1= name1.replace(':','_')\n"", ""   file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(date2) +'.csv'\n"", '   q.write_csv(file1)\n', ' except: print\n', ""'''\n"", '\n', '\n', ""'''\n"", 'def imp_googleQuoteList(symbols, freqsec=300, nday=1, intraday1=True) :\n', ' qlist=[]; sym=[]\n', ' if intraday1:\n', '  for symbol in symbols:\n', '     #try :\n', '        q = imp_googleIntradayQuote(symbol, freqsec, nday)  #interval, timeframe\n', '        qlist.append(q)\n', '        sym.append(symbol)\n', ""     #except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       q = imp_googleQuote(name1, freqsec, num_days)  #interval, timeframe\n', '     except: print(symbol)\n', '\n', ' return qlist, sym\n', ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''        \n"", ""stock_list = ['XOM','AMZN','AAPL','SWKS']\n"", 'p2b_series = pd.Series( index=stock_list )\n', '\n', 'for sym in stock_list:\tp2b_series[sym] = get_price2book(sym)\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", "" # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", ' from dateutil.parser import parse\n', ' if os.path.getsize(file1)> 500 :\n', '  from_zone = tz.gettz(fromzone); tozone = tz.gettz(tozone)\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%m-%d-%Y %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', '  dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '\n', '  # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '  print file1\n', ""  #df = pd.read_csv(file1,sep=',',header=None, parse_dates={'date': [1]}, date_parser=dateparse)\n"", '\n', ""  df = pd.read_csv(file1,sep=',',header=0)\n"", '  #df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '  #df.date= [x.to_datetime() for x in  df.date]\n', '\n', '\n', '  df.drop(df.columns[[0]], axis=1, inplace=True)\n', ""  df= util.pd_addcol(df, 'symbol')\n"", ""  df['symbol']= dfname\n"", '\n', '  print filenameh5\n', ""  df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", ""  df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", '\n', '  # store = pd.HDFStore(filenameh5);\n', '  # store.append(dfname, df);  store.close()\n', ""'''\n"", '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dropcol=[], type1='csv', hasheader=True, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", ' if os.path.getsize(file1)> 500 :\n', '   header= 0 if hasheader else None\n', ""   df = pd.read_csv(file1, sep=',',header=0)\n"", '\n', '   df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""   df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""   df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", '\n', ""   if type1=='csv' :\n"", ""     df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""     if i==1: close = qq[['Datetime']]  #new dataframe\n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', ""     close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""     close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', "" close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", "" close= close.sort('Datetime')\n"", "" close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", '\n', ' close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", 'class Quote(object):\n', ""  DATE_FMT = '%Y-%m-%d';  TIME_FMT = '%H:%M:%S'\n"", '\n', '  def __init__(self):\n', ""    self.symbol = '';    self.exchn=''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', '\n', '  def append(self,dt,open_,high,low,close,volume):\n', '    self.date.append(dt.date())\n', '    self.time.append(dt.time())\n', '    self.open_.append(float(open_))\n', '    self.high.append(float(high))\n', '    self.low.append(float(low))\n', '    self.close.append(float(close))\n', '    self.volume.append(int(volume))\n', '\n', '  def to_csv(self):\n', '    return \'\'.join([""{0},{1},{2},{3:.2f},{4:.2f},{5:.2f},{6:.2f},{7}\\n"".format(self.symbol,\n', ""              self.date[bar].strftime('%Y-%m-%d'),self.time[bar].strftime('%H:%M:%S'),\n"", '              self.open_[bar],self.high[bar],self.low[bar],self.close[bar],self.volume[bar])\n', '              for bar in xrange(len(self.close))])\n', '\n', '  def write_csv(self,filename):\n', ""    with open(filename,'w') as f:\n"", '      txt= self.to_csv()\n', '      f.write(txt)\n', '\n', '  def read_csv(self,filename):\n', ""    self.symbol = ''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', ""    for line in open(filename,'r'):\n"", ""      symbol,ds,ts,open_,high,low,close,volume = line.rstrip().split(',')\n"", '      self.symbol = symbol\n', ""      dt = datetime.datetime.strptime(ds+' '+ts,self.DATE_FMT+' '+self.TIME_FMT)\n"", '      self.append(dt,open_,high,low,close,volume)\n', '    return True\n', '\n', '  def __repr__(self):\n', '    return self.to_csv()\n', ""'''\n"", '\n', ' \n', '\n', ""'''\n"", ""def imp_googleIntradayQuoteSave2(name1, date1, inter, tframe, dircsv='', dbname=''):\n"", ' q = imp_googleIntradayQuote(name1, inter, tframe)  #interval, timeframe\n', "" name1= name1.replace(':','_')\n"", '\n', "" if dircsv != '' :\n"", ""    file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", '    q.to_csv(file1)\n', '\n', "" if dbname != '' :\n"", '    import sqlalchemy as sql\n', '    dbcon= sql.create_engine(dbname)\n', '    if inter== 300 : # 5mins\n', ""      q.to_sql('q5min', dbcon)\n"", '\n', '\n', ""def imp_googleQuoteList_save(symbols, date1, date2, inter=23400, tframe=2000, dircsv='', intraday1=True) :\n"", ' if intraday1:\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleIntradayQuoteSave(symbol, date1, inter, tframe, dircsv)\n', ""     except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleQuoteSave(symbol, date1, date2, dircsv)\n', '     except: print(symbol)\n', ""'''\n"", '\n']","['np.shape', 'getret_fromquotes', 'len', 'getlogret_fromquotes', 'np.log', 'getprice_fromret']",6
utilmy/zarchive/py2to3/portfolio.py:index,index,class,103,300,221,3009,10.03,1,3,[],[],[],1625,[],[],0
utilmy/zarchive/py2to3/portfolio.py:folioCalc,folioCalc,class,125,509,332,4736,9.3,2,17,[],[],[],1924,[],[],0
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator,folioRiskIndicator,class,89,306,215,3180,10.39,1,9,[],[],[],2099,[],[],0
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF,folioOptimizationF,class,280,1291,671,10994,8.52,6,39,[],[],[],2277,[],[],0
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity,searchSimilarity,class,173,497,328,4550,9.15,8,17,[],[],[],3724,[],[],0
utilmy/zarchive/py2to3/portfolio.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1626,[],['date_generatedatetime'],1
utilmy/zarchive/py2to3/portfolio.py:index:close,index:close,method,0,1,1,4,4.0,0,0,['self'],[None],[None],1631,[],[],0
utilmy/zarchive/py2to3/portfolio.py:index:updatehisto,index:updatehisto,method,2,12,11,62,5.17,0,0,['self)'],['  #Download Quotespassself) :'],[None],1634,[],['print'],1
utilmy/zarchive/py2to3/portfolio.py:index:help,index:help,method,2,12,11,62,5.17,0,0,['self'],[None],[None],1638,[],['print'],1
utilmy/zarchive/py2to3/portfolio.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]",['date_generatedatetime'],1
utilmy/zarchive/py2to3/portfolio.py:index:calc_baskettable_pct,index:calc_baskettable_pct,method,37,95,77,782,8.23,1,2,"['self', 'type1', 'showdetail']","[None, None, None]","[None, '""table""', '0']",1703,"[""      '''   Calc Basket Values from Input data '''\n""]","['np.zeros', 'np.sum', 'self._udpate_wwindpct', 'range', 'np.mod', 'self._wwpct_rebal']",6
utilmy/zarchive/py2to3/portfolio.py:index:_wwpct_rebal,index:_wwpct_rebal,method,3,4,3,41,10.25,0,0,"['self', 'wwpct_actual', 't', 'trebal)', '']","[None, None, None, '  # BskUnit', ']np.abs(wwpct_actual/wwpct_th  -1 )) > self.rebal_trigger:']","[None, None, None, ' 1.0  !!!wwpct_th = self.wwasset[trebal', None]",1730,[],[],0
utilmy/zarchive/py2to3/portfolio.py:index:_udpate_wwindpct,index:_udpate_wwindpct,method,11,25,17,224,8.96,0,0,"['self', 't', 'bskt', 'hedgecost', 'wwpct_actual', 'wwpct_th']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",1740,[],[],0
utilmy/zarchive/py2to3/portfolio.py:index:calc_baskettable_unit,index:calc_baskettable_unit,method,0,0,0,0,0.0,0,0,[],[],[],1749,"[""    '''   t           --->  t+1                 ---->   t+2\n"", '            wwactual:    B[t]    -->   B[t+1]   using  w[t+1], B[t] /   S[t]\n', '            wwnew   :    B[t+1]  -->   B[t+2]   using  w[t+2], B[t+1] /   S[t+1]\n', ""    '''\n""]",[],0
utilmy/zarchive/py2to3/portfolio.py:folioCalc:__init__,folioCalc:__init__,method,21,39,37,356,9.13,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1925,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioCalc:set_symclose,folioCalc:set_symclose,method,17,34,33,312,9.18,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1938,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioCalc:setcriteria,folioCalc:setcriteria,method,41,76,71,1046,13.76,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",1947,"[""        ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '            wwtype:     constant / regime /regimExtra\n', '            initperiod: NbOfDays_initial_Risk_Monitoring\n', '            riskid:     spprice/spperf/multi\n', ""        '''\n""]","['np.array', 'len']",2
utilmy/zarchive/py2to3/portfolio.py:folioCalc:_weightcalc_generic,folioCalc:_weightcalc_generic,method,5,35,23,396,11.31,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",1997,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/py2to3/portfolio.py:folioCalc:_weightcalc_regime,folioCalc:_weightcalc_regime,method,10,37,32,272,7.35,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2008,[],"['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/py2to3/portfolio.py:folioCalc:_regimecalc,folioCalc:_regimecalc,method,3,7,6,83,11.86,0,0,"['self', 't', 'wwextra)', 't - 1]self.riskind[0', 't - 1] / self.riskind[0', 't - 1 - self.nbrange] - 1if self.riskid == ""multi""']","[None, None, '  # Risk Indicatorif self.riskid ', None, None, '']","[None, None, '= ""spprice"":   return self.riskind[0', None, None, '= ""multi"":']",2018,[],['self._mapping_calc_risk'],1
utilmy/zarchive/py2to3/portfolio.py:folioCalc:_weightcalc_constant,folioCalc:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2027,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio.py:folioCalc:getweight,folioCalc:getweight,method,5,12,9,126,10.5,0,0,['self'],[None],[None],2031,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/py2to3/portfolio.py:folioCalc:calc_baskettable,folioCalc:calc_baskettable,method,33,111,83,811,7.31,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', '0.000', '0']",2038,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/py2to3/portfolio.py:folioCalc:plot,folioCalc:plot,method,10,29,26,295,10.17,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2066,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/py2to3/portfolio.py:folioCalc:multiperiod_ww,folioCalc:multiperiod_ww,method,15,36,29,240,6.67,1,1,"['self', 't']","[None, None]","[None, None]",2077,[],['xrange'],1
utilmy/zarchive/py2to3/portfolio.py:folioCalc:help,folioCalc:help,method,1,2,2,13,6.5,0,0,['self'],[None],[None],2090,[],['print'],1
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:__init__,folioRiskIndicator:__init__,method,23,40,38,356,8.9,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:set_symclose,folioRiskIndicator:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2114,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:setcriteria,folioRiskIndicator:setcriteria,method,34,81,70,1006,12.42,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2124,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'np.zeros']",3
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:calcrisk,folioRiskIndicator:calcrisk,method,13,18,17,220,12.22,1,0,"['self', 'wwvec', 'initval']","[None, None, None]","[None, '[]', '1']",2172,[],"['xrange', 'self._weightcalc_generic', 'np.column_stack']",3
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:_weightcalc_generic,folioRiskIndicator:_weightcalc_generic,method,4,34,24,327,9.62,0,3,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2184,[],"['self._weightcalc_regime', 'print']",2
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:_weightcalc_regime,folioRiskIndicator:_weightcalc_regime,method,3,11,11,68,6.18,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2193,[],['self._regimecalc'],1
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:_regimecalc,folioRiskIndicator:_regimecalc,method,7,18,17,216,12.0,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )self.riskind', 'wwextra', 't', 'self.riskind_out)self', 'maxiter', 'name1', 'isreset', 'popsize=15) ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, None, None, None, None, None, None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, None, None, None, None, '1', ""''"", '1', '15) :']",2198,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:calc_optimal_weight,folioRiskIndicator:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2204,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:__init__,folioOptimizationF:__init__,method,23,39,37,340,8.72,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:set_symclose,folioOptimizationF:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2114,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:setcriteria,folioOptimizationF:setcriteria,method,44,128,103,1669,13.04,0,2,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2124,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'print', 'list']",4
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:calcbasket_obj2,folioOptimizationF:calcbasket_obj2,method,23,76,63,756,9.95,0,1,"['self', 'wwvec']","[None, None]","[None, None]",2362,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float']",6
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:calcbasket_obj,folioOptimizationF:calcbasket_obj,method,55,157,118,1494,9.52,1,4,"['self', 'wwvec']","[None, None]","[None, None]",2388,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float', 'calcbasket_obj', 'concenfactor=folio_concenfactor2', 'np.zeros', 'xrange', 'np.mod', 'self._weightcalc_generic', 'self._loss_obj', 'self._objective_criteria']",14
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_loss_obj,folioOptimizationF:_loss_obj,method,4,6,6,68,11.33,0,0,"['self', 'ww2', 'wwpenalty']","[None, None, None]","[None, None, None]",2413,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_weightcalc_generic,folioOptimizationF:_weightcalc_generic,method,5,40,26,394,9.85,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2184,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_weightcalc_regime,folioOptimizationF:_weightcalc_regime,method,8,32,28,239,7.47,0,0,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2193,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']","['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_regimecalc,folioOptimizationF:_regimecalc,method,4,7,7,83,11.86,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )if self.riskid== ""multi""   ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, '= ""multi""   :']",2198,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']",['self._mapping_calc_risk'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_weightcalc_constant,folioOptimizationF:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2452,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:calc_optimal_weight,folioOptimizationF:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2204,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:getweight,folioOptimizationF:getweight,method,6,11,9,126,11.45,0,0,['self'],[None],[None],2461,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:calc_baskettable,folioOptimizationF:calc_baskettable,method,36,86,72,827,9.62,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', ' 0.000', '0']",2469,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:plot,folioOptimizationF:plot,method,11,31,30,294,9.48,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2498,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_objective_criteria,folioOptimizationF:_objective_criteria,method,31,147,78,1105,7.52,2,7,"['self', 'bsk']","[None, None]","[None, None]",2510,[],"['np.std', 'np.sum', 'range', 'np.arange']",4
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:multiperiod_ww,folioOptimizationF:multiperiod_ww,method,18,29,27,238,8.21,1,1,"['self', 't']","[None, None]","[None, None]",2557,[],['xrange'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:help,folioOptimizationF:help,method,50,152,103,1472,9.68,1,6,['self'],[None],[None],2569,[],"['print', 'util.load_obj', 'int', 'copy.deepcopy', 'xrange', 'next', 'util.save_obj', 'np.mod', 'np.abs', 'np.reshape', 'np.sum']",11
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:mapping_risk_ww,folioOptimizationF:mapping_risk_ww,method,12,56,29,245,4.38,0,1,"['self', 'risk', 'wwmat', 'ww2']","[None, None, None, None]","[None, None, None, 'self.wwasset0']",2628,[],"['np.sum', 'np.array']",2
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_mapping_calc_risk,folioOptimizationF:_mapping_calc_risk,method,27,201,76,831,4.13,0,3,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",2640,[],[],0
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:__init__,searchSimilarity:__init__,method,15,18,17,193,10.72,0,0,"['self', ""filejpstock=r'E"", 'sym01', 'symname', 'startdate', 'enddate', 'pricetype']","[None, '', None, None, None, None, None]","[None, ""r'E:/_data/stock/daily/20160616/jp'"", ""['7203']"", ""['Toyota']"", ' 20150101', '20160601', '""close""']",3725,[],[],0
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:load_quotes_fromdb,searchSimilarity:load_quotes_fromdb,method,15,35,33,355,10.14,0,1,"['self', 'picklefile']","[None, None]","[None, ""''""]",3730,[],"['util.load_obj', 'imp_txt_getquotes', 'date_align', 'util.a_cleanmemory']",4
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:__generate_return__,searchSimilarity:__generate_return__,method,4,4,4,64,16.0,0,0,"['self', 'nlag']","[None, None]","[None, None]",3741,[],['getret_fromquotes'],1
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:__overweight__,searchSimilarity:__overweight__,method,17,62,41,412,6.65,2,4,"['self', 'px']","[None, None]","[None, None]",3745,[],"['len', 'np.ones', 'util.np_findlocalmax', 'type', 'np.abs', 'wwerr[max', 'util.np_findlocalmin']",7
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:set_searchcriteria,searchSimilarity:set_searchcriteria,method,34,79,63,793,10.04,0,5,"['self', 'name1', 'date1', 'date2', 'nlag', 'searchperiodstart', 'typesearch', '']","[None, None, None, None, None, None, None, None]","[None, ""'7203'"", '20160301', '20160601', '1', '20120101', '""pattern2""', None]",3765,[],"['getret_fromquotes', 'date_finddateid', 'max', 'util.np_findfirst', 'print', 'price_normalize_1d', 'len', 'self.__overweight__']",8
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:launch_search,searchSimilarity:launch_search,method,53,107,81,908,8.49,3,3,['self'],[None],[None],3794,[],"['len', 'np.zeros', 'range', 'price_normalize_1d', 'np_similarity', 'util.np_sortbycolumn', 'enumerate']",7
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:show_comparison_graph,searchSimilarity:show_comparison_graph,method,33,72,63,682,9.47,1,3,"['self', 'maxresult', 'show_only_different_time', 'fromid', 'fromend', 'filenameout']","[None, None, None, None, None, None]","[None, '20', 'True', '0', ' 0', ""''""]",3828,[],"['np.shape', 'range', 'int', 'print', 'price_normalize_1d', 'str', 'plot_price']",7
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:staticmethod,searchSimilarity:staticmethod,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",3857,[],[],0
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:get_rankresult,searchSimilarity:get_rankresult,method,24,63,53,496,7.87,2,1,"['self', 'filetosave']","[None, None]","[None, ""''""]",3861,[],"['len', 'np.savetxt', 'np.shape', 'np.array', 'np.empty', 'range', 'int', 'str']",8
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:export_results,searchSimilarity:export_results,method,0,0,0,0,0.0,0,0,[],[],[],3883,"[""'''\n"", '#####################################################################################\n', '#---------Run over all the indexes, with time lag -----------------------------------\n', 'def np_similarity(x,y, wwerr=[], type1=0):\n', '  if type1==2 : return np_distance_l1(x,y, wwerr)\n', '  if type1==1: return sci.spatial.distance.correlation(x, y)  \n', '  if type1==0 : return 1-np.corrcoef(x,y)[0,1]\n', '\n', 'def np_distance_l1(x,y, wwerr) :\n', ' return np.sum(wwerr * np.abs(x-y))  \n', '  \n', '#---------------------  Universe Load         ---------------------------------------\n', ""filejpstock= r'E:/_data/stock/daily/20160616/jp'\n"", 'sym01= nk400list\n', '\n', 'quotes= imp_txt_getquotes(sym01, filejpstock, startdate=20090101, endate=20160616)\n', 'open1, dateref= date_align(quotes, type1=""close"")    #Get the data and align dates\n', 'del quotes; util.a_cleanmemory()\n', '\n', ""#util.save_obj(open1, 'close_nk400_2009_2016')\n"", ""#util.save_obj(dateref, 'dateref_nk400_2009_2016')\n"", '\n', ""open1= util.load_obj('close_nk400_2009_2016')\n"", ""dateref= util.load_obj( 'dateref_nk400_2009_2016')\n"", '\n', 'nlag=1\n', 'ret_open1 =  getdailyret_fromquotes(open1,nlag)\n', 'del open1\n', '\n', '#--------------------  Search Asset Input     ---------------------------------------\n', ""name1= '7203' \n"", 'date1= 20160328\n', 'date2= 20160531\n', 'twindow= util.np_findfirst(date2, dateref) - util.np_findfirst(date1, dateref) \n', '\n', '\n', 'tstartx= util.np_findfirst(date1, dateref)          # Date Index\n', 'stockx= util.np_findfirst(name1, sym01)\n', 'retx= ret_open1[stockx, tstartx:(tstartx+twindow-1)]    # Recent Period\n', 'px= price_normalize_1d(retx)\n', 'nx= len(px)\n', '\n', '\n', '#----OverWeight for Local Min, Local Max         -----------------------------------\n', 'wwerr= np.ones(nx, dtype=np.float16)\n', 'vvmax= util.np_findlocalmax(px); xprev=0\n', 'for x in vvmax:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', 'vvmin= util.np_findlocalmin(px); xprev=0\n', 'for x in vvmin:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', '\n', '#--------------------  Search the Pattern       -------------------------------------\n', 'tmaxx= len(dateref)-1\n', 'similar_list= np.zeros((nstock*(tmaxx-twindow)+1, 3), np.float16)\n', 'i=0\n', 'for iy in range(0, nstock) :\n', ' for t in range(0, tmaxx-twindow):\n', '   if iy == stockx and t > tstartx : \n', '     pass\n', '   else :\n', '    rety= ret_open1[iy, t:(t+twindow-1)]\n', '    py=   price_normalize_1d(rety)\n', '    ss= np_similarity(px, py, wwerr=wwerr, type1=2)\n', '    i+=1\n', '    similar_list[i,0]= iy\n', '    similar_list[i,1]= t\n', '    similar_list[i,2]= ss\n', '\n', '\n', ' #-------------------Clean the table -------------------------------------------------\n', 'rank= util.np_sortbycolumn(similar_list,2, asc=True)\n', 'for i,x in enumerate(rank) :\n', '  if rank[i,2]==0.0 : rank[i,2]= 1000         # Empty cell\n', '  if rank[i,1]> tstartx-3 : rank[i,2]= 100    # Start Element\n', 'rank= util.np_sortbycolumn(rank,2, asc=True)  \n', '\n', '\n', ' #----- Show Similar Stocks ---------------------------------------------------------\n', 'show_only_different_time= True\n', '\n', 'for i in range(0,10) :\n', ' tstarti= rank[i,1]\n', ' stocki= int(rank[i,0])\n', ' \n', ' if show_only_different_time and tstarti < tstartx-1  :\n', '   py= price_normalize100(ret_open1[stocki, tstarti:(tstarti+twindow-1)]) \n', '\n', '   namei= sym01[stocki]\n', '   namefulli= nk400name[util.np_findfirst(namei, nk400list)]\n', '\n', '   tit= namei+ "" "" +namefulli+ "" "" + str(dateref[tstarti])          \n', ""   plot_price(px-100, py-100, label=('Similar '+tit, 'Time','% Var') )\n"", '\n', '\n', 'kix= util.np_findfirst(name1, statsjp[:,0, ilag])\n', 'stocklist01[390]\n', '\n', '\n', 'stocklist01[157] , nk400name[157] ,  dateref1adj[86]     \n', 'plot_price(price_normalize100(ret_open1[157, 86:86+twindow-1])-100,px-100   )\n', ""'''    \n""]",[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:data_jpsector,data_jpsector,function,3,4,4,47,11.75,0,0,[],[],[],30,[],['util.load_obj'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_earningquater,date_earningquater,function,9,103,42,604,5.86,0,5,['t1'],[None],[None],40,[],['datetime.datetime'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_is_3rdfriday,date_is_3rdfriday,function,4,14,13,67,4.79,0,0,['s'],[None],[None],59,[],"['datetime.strptime', 'd.weekday']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:date_option_expiry,date_option_expiry,function,10,50,33,354,7.08,0,2,['date'],[None],[None],64,[],['datetime.datetime'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_find_kday_fromintradaydate,date_find_kday_fromintradaydate,function,2,3,3,68,22.67,0,0,"['kintraday', 'intradaydate', 'dailydate']","[None, None, None]","[None, None, None]",81,[],['util.np_find'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_find_kintraday_fromdate,date_find_kintraday_fromdate,function,4,10,10,88,8.8,0,0,"['d1', 'intradaydate1', 'h1', 'm1']","[None, None, None, None]","[None, None, '9', '30']",85,[],"['datetime.datetime', 'util.np_find']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:date_find_intradateid,date_find_intradateid,function,8,13,13,96,7.38,1,0,"['datetimelist', 'stringdate']","[None, None]","[None, ""['20160420223000']""]",92,[],"['datestring_todatetime', 'util.np_find', 'str']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_convertzone1_tozone2,datetime_convertzone1_tozone2,function,16,29,25,343,11.83,1,1,"['tt', 'fromzone', 'tozone']","[None, None, None]","[None, ""'Japan'"", ""'US/Eastern'""]",103,[],"['pytz.timezone', 'type', 'tz.localize', 't2.append']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:date_extract_dailyopenclosetime,date_extract_dailyopenclosetime,function,23,51,35,431,8.45,2,3,"['spdateref1', 'market']","[None, None]","[None, ""'us'""]",120,[],"['enumerate', 'spdailyopendate.append', 'np.array', 'spdailyclosedate.append']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_tostring,datetime_tostring,function,6,34,22,269,7.91,1,3,['tt'],[None],[None],138,[],"['isinstance', 'tt.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",149,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_todate,datetime_todate,function,6,40,25,319,7.97,1,3,['tt'],[None],[None],158,[],"['isinstance', 'datetime.date', 'pd.to_datetime', 'date2.append']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_toint,datetime_toint,function,12,37,28,424,11.46,2,2,['datelist1'],[None],[None],169,[],"['isinstance', 'int', 'date2.append', 'datetime_tointhour', 'yy2.append', 'np.array']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_tointhour,datetime_tointhour,function,7,20,19,234,11.7,1,1,['datelist1'],[None],[None],177,[],"['isinstance', 'int', 'yy2.append', 'np.array']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:dateint_tostring,dateint_tostring,function,7,15,14,183,12.2,1,1,"['datelist1', 'format1']","[None, None]","[None, ""'%b-%y'""]",185,[],"['isinstance', 'dateint_todatetime', 'date2.append', 'np.array']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:dateint_todatetime,dateint_todatetime,function,6,14,12,126,9.0,1,1,['datelist1'],[None],[None],207,[],"['isint', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:datenumpy_todatetime,datenumpy_todatetime,function,9,48,26,381,7.94,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",218,[],['type'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_tonumpypdate,datetime_tonumpypdate,function,2,2,2,22,11.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",232,[],['np.datetime64'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_diffindays,date_diffindays,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",237,[],['dateint_todatetime'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",242,[],['util.np_findfirst'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],256,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:date_as_float,date_as_float,function,12,32,26,311,9.72,0,2,['dt'],[None],[None],263,[],"['isint', 'dateint_todatetime', 'datetime.datetime', 'isleap', 'timedelta']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:date_todatetime,date_todatetime,function,1,9,9,58,6.44,0,0,['tlist'],[None],[None],277,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:date_removetimezone,date_removetimezone,function,1,6,6,63,10.5,0,0,['datelist'],[None],[None],281,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:datediff_inyear,datediff_inyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",285,[],['date_as_float'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",289,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:date_add_bdays,date_add_bdays,function,12,37,30,369,9.97,1,2,"['from_date', 'add_days']","[None, None]","[None, None]",298,[],"['type', 'dateint_todatetime', 'datestring_todatetime', 'datetime.timedelta', 'current_date.weekday']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:date_getspecificdate,date_getspecificdate,function,21,203,58,1312,6.46,8,19,"['datelist', 'datetype1', 'outputype1', 'includelastdate', 'includefirstdate', '']","[None, None, None, None, None, None]","[None, '""yearend""', '""intdate""', 'True', 'False', None]",312,[],"['isint', 'dateint_todatetime', 'enumerate', 'vec2.append', 'np.mod', 'np.array']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:date_alignfromdateref,date_alignfromdateref,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",373,[],"['range', 'np.float', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:_date_align,_date_align,function,16,42,33,256,6.1,2,2,"['dateref', 'datei', 'tmax', 'closei']","[None, None, None, None]","[None, None, None, None]",398,[],"['np.zeros', 'range', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:date_align,date_align,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",412,"["" ''' #Aligne the price with the same dates date\tyear\tmonth\tday\td\topen\tclose\thigh\tlow\tvolume\taclose '''\n""]","['range', 'np.float', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:min_withposition,min_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],459,[],['min'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:max_withposition,max_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],463,[],['max'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:_reshape,_reshape,function,2,14,12,68,4.86,0,1,['x'],[None],[None],469,[],"['len', 'np.reshape', 'np.size']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:_notnone,_notnone,function,39,211,114,1769,8.38,1,11,"['x)', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5)', 'label', ""'Time'"", ""'Y')"", 'legendloc', 'dpi', 'isband=0) ']","['  return not x is Noneasset', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None, ""('title'"", None, None, '""upper left""', '150', '0) :']",473,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend']",23
utilmy/zarchive/py2to3/portfolio_withdate.py:plot_price,plot_price,function,69,272,170,2746,10.1,2,11,"['asset', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None]",477,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend', 'plot_priceintraday', 'np.loadtxt', 'np.unique', 'xdays.append', 'np.hstack', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick']",35
utilmy/zarchive/py2to3/portfolio_withdate.py:plot_priceintraday,plot_priceintraday,function,32,59,57,947,16.05,1,0,['data'],[None],[None],556,[],"['np.loadtxt', 'np.unique', 'np.arange', 'xdays.append', 'np.hstack', 'plt.figure', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plt.show']",14
utilmy/zarchive/py2to3/portfolio_withdate.py:plot_check,plot_check,function,8,19,19,257,13.53,0,0,"['close', 'tt0i', 'tt1i', 'dateref', 'sym', 'tickperday']","[None, None, None, None, None, None]","[None, '20140102', '20160815', '[]', '[]', '120']",598,[],"['util.find', 'getret_fromquotes', 'price_normalize100', 'plot_price']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:plot_pricedate,plot_pricedate,function,18,61,49,534,8.75,1,4,"['date1', 'sym1', 'asset1', 'sym2', 'bsk1', 'verticaldate', 'savename1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None', ""''"", '(10', None]",608,[],"['type', 'datestring_todatetime', 'np.row_stack', 'np.concatenate', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'np.arange', 'int', 'len', 'ax.savefig']",11
utilmy/zarchive/py2to3/portfolio_withdate.py:generate_sepvertical,generate_sepvertical,function,9,13,12,149,11.46,0,1,"['asset1', 'tt', 'tmax', 'start', 'datebar']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",690,[],"['np.zeros', 'datestring_todatetime']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:save_asset_tofile,save_asset_tofile,function,31,129,87,978,7.58,5,9,"['file1', 'asset1', 'asset2', 'asset3', 'date1', 'title1']","[None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None']",705,[],"['np.shape', 'len', 'np.reshape', 'print', 'np.zeros', 'range', 'int', 'np.row_stack', 'np.savetxt']",9
utilmy/zarchive/py2to3/portfolio_withdate.py:load_asset_fromfile,load_asset_fromfile,function,1,4,4,51,12.75,0,0,['file1'],[None],[None],744,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:array_todataframe,array_todataframe,function,11,41,27,259,6.32,0,2,"['price', 'symbols', 'date1']","[None, None, None]","[None, 'None', 'None']",748,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],759,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],768,[],['float'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:isint,isint,function,32,105,61,1036,9.87,0,8,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) )Xmat', 'type1', 'type2=""correl"") ']","[' return isinstance(x', None, None, None, None, None, None, '']","[None, None, None, None, None, None, '""robust""', '""correl"") :']",776,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:correlation_mat,correlation_mat,function,32,105,61,1036,9.87,0,8,"['Xmat', 'type1', 'type2']","[None, None, None]","[None, '""robust""', '""correl""']",783,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:correl_reducebytrigger,correl_reducebytrigger,function,9,22,18,128,5.82,2,1,"['correl2', 'trigger']","[None, None]","[None, None]",831,"[""  ''' Put Zero below trigger  '''\n""]","['correl2.copy', 'range', 'abs']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:sk_cov_fromcorrel,sk_cov_fromcorrel,function,8,14,13,115,8.21,0,0,"['correl', 'ret_close1']","[None, None]","[None, None]",843,[],"['volhisto_fromret', 'np.diag', 'np.dot']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:cointegration,cointegration,function,18,47,37,385,8.19,0,0,"['x', 'y']","[None, None]","[None, None]",849,"['  """""" Output :\n', '    coint_t :t-statistic of unit-root test on residuals\n', ""    pvalue :   MacKinnon's approximate p-value based on MacKinnon (1994)\n"", '    crit_value : Critical values for the test statistic at the 1 %, 5 %, and 10 %  Signifiance levels.\n', '\n', '    The Null hypothesis is that there is no cointegration, the alt hypothesis is that there is cointegrating relationship. \n', '    If the pvalue is small, below a critical size:  Reject Null Hypothesis -->  Cointegration\n', '           pvalue is high --> No Cointegration    \n', '    \n', '    Significance level, also denoted as alpha or , is the probability of rejecting  the null hypothesis when it is true.\n', '    Probability of incorrectly rejecting a true null hypothesis\n', '\n', '    P=0.05  , At least 23% (and typically close to 50%)\n', '    P=0.01  , At least 7% (and typically close to 15%\n', '\n', '    (-2.9607012342275936,\n', '    0.038730981052330332, 0,\n', '    249,\n', ""    {'1%': -3.4568881317725864,\n"", ""       '10%': -2.5729936189738876,\n"", ""     '5%': -2.8732185133016057},\n"", '      601.96849256295991)\n', '        It can be seen that the calculated test statistic of -2.96 is smaller than the 5% critical value of -2.87, \n', ""        which means that we can reject the null hypothesis that  there isn't a cointegrating relationship at the 5% level.\n"", '  """"""\n']",['np.zeros'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:causality_y1_y2,causality_y1_y2,function,10,14,13,153,10.93,0,0,"['price2', 'price1', 'maxlag']","[None, None, None]","[None, None, None]",887,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:reg_slope,reg_slope,function,16,24,24,261,10.88,1,0,"['close', 'dateref', 'tlag', 'type1']","[None, None, None, None]","[None, None, None, ""'elasticv'""]",895,[],"['np.ones', 'xrange', 'regression', 'np.arange']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:rolling_cointegration,rolling_cointegration,function,13,29,26,280,9.66,0,0,"['x', 'y']","[None, None]","[None, None]",910,[],"['rolling_coint', 'pd.expanding_apply']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:regression,regression,function,13,67,32,589,8.79,0,5,"['yreturn', 'xreturn', 'type1']","[None, None, None]","[None, None, '""elasticv""']",929,"["" '''Y = X* reg.coef_  +  reg.intercept_, r2 '''\n""]","['len', 'yreturn.ravel', 'xreturn.reshape', 'reg.fit', 'F', 'reg.score']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:regression_fixedsymbolstock,regression_fixedsymbolstock,function,30,59,54,591,10.02,1,1,"['sym', 'ret_close2', 'tsstart', 'tsample', 'ret_spy', 'spyclose', 'regonly']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, 'True']",966,"["" ''' Price, Weight, R2, Error  '''\n""]","['len', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:regression_getpricefromww,regression_getpricefromww,function,20,38,30,298,7.84,3,0,"['spyclose', 'ww01', 'regasset01', 'ret_close2', 'tstart', 'tlag']","[None, None, None, None, None, None]","[None, None, None, None, None, '1']",989,[],"['np.copy', 'np.zeros', 'range', 'len']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:regression_allstocks_vs_riskfactors,regression_allstocks_vs_riskfactors,function,65,137,113,1351,9.86,2,1,"['symstock', 'pricestock', 'symriskfac', 'priceriskfac', 'nlaglist']","[None, None, None, None, None]","[None, None, None, None, None]",1010,"["" '''Make Regression on all stocks ''' \n""]","['np.shape', 'print', 'np.arange', 'np.empty', 'len', 'enumerate', 'getlogret_fromquotes', 'range', 'np.reshape', 'regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",13
utilmy/zarchive/py2to3/portfolio_withdate.py:getdiff_fromquotes,getdiff_fromquotes,function,4,6,6,73,12.17,0,0,"['close', 'timelag']","[None, None]","[None, None]",1107,[],['np.shape'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:getret_fromquotes,getret_fromquotes,function,7,23,17,159,6.91,0,1,"['close', 'timelag']","[None, None]","[None, '1']",1111,[],"['np.shape', 'len']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:getlogret_fromquotes,getlogret_fromquotes,function,4,7,7,81,11.57,0,0,"['close', 'timelag']","[None, None]","[None, '1']",1122,[],"['np.shape', 'np.log']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:getprice_fromret,getprice_fromret,function,12,23,21,190,8.26,2,0,"['ret', 'normprice']","[None, None]","[None, '100']",1127,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:price_normalize100,price_normalize100,function,16,43,36,292,6.79,1,1,"['ret', 'normprice']","[None, None]","[None, '100']",1139,[],"['np.shape', 'len', 'np.reshape', 'np.zeros', 'range', 'np.cumprod']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:price_normalize_1d,price_normalize_1d,function,8,22,19,147,6.68,0,0,"['ret', 'normprice', 'dtype1']","[None, None, None]","[None, '100', ' np.float32']",1159,[],"['np.empty', 'np.cumprod']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:norm_fast,norm_fast,function,7,8,8,85,10.62,0,0,"['y', 'ny']","[None, None]","[None, None]",1168,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:correl_fast,correl_fast,function,8,13,13,116,8.92,0,0,"['xn', 'y', 'nx']","[None, None, None]","[None, None, None]",1176,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:volhisto_fromret,volhisto_fromret,function,2,14,11,168,12.0,0,1,"['retbsk', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1184,[],"['len', 'np.std']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:volhisto_fromprice,volhisto_fromprice,function,6,25,17,245,9.8,0,1,"['price', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1191,[],"['len', 'np.shape', 'np.std']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:volhistorolling_fromprice,volhistorolling_fromprice,function,16,42,30,318,7.57,2,1,"['price', 'volrange']","[None, None]","[None, None]",1200,[],"['np.shape', 'len', 'np.zeros', 'xrange', 'volhisto_fromprice']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:rsk_calc_all_TA,rsk_calc_all_TA,function,51,223,105,1352,6.06,0,10,['df'],[None],"[""'panda_dataframe'""]",1219,"[""  '''Add All TA RMI, RSI To the '''\n""]","['ta.MA', 'ta.distance', 'ta.RET', 'ta.RMI', 'ta.STDDEV', 'ta.nbday_low', 'ta.nbday_high', 'ta.RSI', 'ta.qearning_dist', 'ta.optionexpiry_dist', 'linearreg2', 'np.array', 'np.sum', 'util.np_findlocalmin2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",18
utilmy/zarchive/py2to3/portfolio_withdate.py:ta_highbandtrend1,ta_highbandtrend1,function,42,170,75,910,5.35,0,11,"['close2', 'type1']","[None, None]","[None, '0']",1301,[],"['linearreg', 'np.array', 'np.sum', 'util.np_findlocalmax2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:pd_transform_asset,pd_transform_asset,function,11,35,27,409,11.69,0,1,"['q0', 'q1', 'type1']","[None, None, None]","[None, None, '""spread""']",1350,[],"['util.pd_date_intersection', 'util.pd_array_todataframe', 'util.pd_insertcol']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:calcbasket_table,calcbasket_table,function,25,59,53,477,8.08,1,2,"['wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps']","[None, None, None, None, None, None]","[None, None, '""table""', '""constant""', '1', ' 0.000']",1364,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.mod', 'np.sum']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_createvolta_asset,folio_createvolta_asset,function,10,19,19,159,8.37,1,0,"['close', 'vol', 'volrange', 'lev']","[None, None, None, None]","[None, '0.12', '120', '1.0']",1391,[],"['np.zeros_like', 'np.shape', 'xrange', 'folio_volta']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_lowcorrelation,folio_lowcorrelation,function,145,431,300,3894,9.03,8,7,"['sym01', 'nstock', 'periodlist', 'dateref', 'close1', 'kbenchmark', 'badlist', 'costbppa', 'showgraph']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, '0.02', 'True']",1399,[],"['ww_selection', 'np.corrcoef', 'np.nan_to_num', 'np.zeros', 'range', 'util.np_sortbycol', 'int', 'np.std', 'np.isnan', 'util.find', 'np.sum', 'stk_select.append', 'volhisto_fromret', 'sum', '1/len', 'getret_fromquotes', 'len', 'np.empty', 'np.ones', 'enumerate', 'calcbasket_table', 'price_normalize100', 'np.column_stack', 'np.zeros_like', 'np.array', 'np.concatenate', 'print', 'str', 'plot_price', 'sym01[int', 'volhisto_fromprice', 'xrange', 'folio_inverseetf']",33
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_leverageetf,folio_leverageetf,function,8,23,20,156,6.78,1,0,"['price', 'lev', 'costpa']","[None, None, None]","[None, '1.0', '0.0']",1537,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_inverseetf,folio_inverseetf,function,8,18,18,151,8.39,1,0,"['price', 'costpa']","[None, None]","[None, '0.0']",1546,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_longshort_unit,folio_longshort_unit,function,59,240,112,1594,6.64,2,7,"['long1', 'short1', 'ww', '-1]', 'costpa', 'tlag', 'istable', 'wwschedule']","[None, None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1', '[]']",1555,[],"['len', 'np.zeros', 'xrange', 'np.mod', 'folio_longshort_unitfixed']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_longshort_unitfixed,folio_longshort_unitfixed,function,43,111,73,719,6.48,1,3,"['long1', 'short1', 'nn', '-1]', 'costpa', 'tlag', 'istable']","[None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1']",1596,[],"['len', 'np.zeros', 'xrange', 'np.mod']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_longshort_pct,folio_longshort_pct,function,8,21,20,189,9.0,1,0,"['long1', 'short1', 'ww', '-1]', 'costpa']","[None, None, None, None, None]","[None, None, '[1', None, '0.0']",1634,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_histogram,folio_histogram,function,13,75,41,914,12.19,0,0,['close'],[None],[None],1642,[],"['getret_fromquotes', 'plt.subplots', 'np.ones_like', 'ax2.hist', 'ax2.set_title', 'ax2.set_xlabel', 'ax2.set_ylabel', 'ax2.axvline', 'plt.show', 'print']",10
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_voltarget,folio_voltarget,function,2,6,6,61,10.17,0,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1670,[],['folio_volta'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_volta,folio_volta,function,54,197,112,1663,8.44,2,8,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1674,[],"['folio_volta', 'len', 'np.shape', 'np.zeros', 'range', 'np.std', 'util.findhigher', 'max', 'min', 'folio_volta2', 'np.abs']",11
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_volta2,folio_volta2,function,29,61,54,514,8.43,1,2,"['bsk', 'riskind', 'par', 'targetvol', 'volrange', 'cap', 'floor', 'costbp']","[None, None, None, None, None, None, None, None]","[None, None, None, '0.11', ' 90', '1.5', '0.0', '0.0005']",1713,[],"['np.shape', 'np.zeros', 'range', 'np.std', 'max', 'min', 'np.abs']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_fixedunitprice,folio_fixedunitprice,function,13,36,33,221,6.14,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1738,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_fixedweightprice,folio_fixedweightprice,function,13,36,33,225,6.25,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1752,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_fixedweightret,folio_fixedweightret,function,13,31,28,193,6.23,2,0,"['ret', 'fixedww']","[None, None]","[None, None]",1764,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_cost_turnover,folio_cost_turnover,function,26,88,71,825,9.38,1,1,"['wwall', 'bsk', 'dateref', 'costbp']","[None, None, None, None]","[None, None, None, None]",1777,[],"['len', 'np.zeros', 'xrange', 'np.sum', 'plot_price', 'date1=dateint_tostring']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_riskpa,folio_riskpa,function,20,52,40,422,8.12,2,0,"['ret', 'targetvol', 'volrange', 'cap']","[None, None, None, None]","[None, '0.1', '90', '1.0']",1807,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.sum', 'np.std', 'min', 'list']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_perfreport_schedule,folio_perfreport_schedule,function,14,20,19,189,9.45,1,0,"['sym', 'dateref', 'close', 'wwind', 't0', 'scheduleperiod']","[None, None, None, None, None, None]","[None, None, None, None, None, '""1monthend""']",2121,[],"['np.shape', 'generate_schedule', 'np.zeros', 'enumerate']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_concenfactor2,folio_concenfactor2,function,7,12,12,103,8.58,0,0,"['ww', 'masset']","[None, None]","[None, '12']",2421,[],"['getweight', 'np.sum', 'np.mean']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:calcbasket_objext,calcbasket_objext,function,50,203,96,1094,5.39,1,7,"['RETURN', 'TMAX', 'riskind_i', 'wwmat', 'wwasset0', 'ww0', 'nbrange', 'criteria']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",2439,[],"['xrange', 'np.sum', 'math.sqrt']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:calc_ranktable,calc_ranktable,function,20,44,41,351,7.98,1,0,"['close2', 'symjp1', 'nlag', 'refindex', 'funeval', 'funargs']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",3849,[],"['np.zeros', 'getlogret_fromquotes', 'enumerate', 'funeval', 'util.np_sortbycolumn']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:similarity_correl,similarity_correl,function,7,10,9,88,8.8,0,0,"['ret_close2', 'funargs']","[None, None]","[None, None]",3869,[],['correlation_mat'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3924,[],['np_distance_l1'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3930,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3924,[],['np_distance_l1'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3930,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:get,get,function,11,44,26,436,9.91,0,1,"['close', 'timelag']","[None, None]","[None, None]",4293,"['    """"""Return dataframe of requested dataset from Quandl.\n', '    :param dataset: str or list, depending on single dataset usage or multiset usage\n', '            Dataset codes are available on the Quandl website\n', '    :param str api_key: Downloads are limited to 50 unless api_key is specified\n', '    :param str start_date, end_date: Optional datefilers, otherwise entire dataset is returned\n', '    :param str collapse: Options are daily, weekly, monthly, quarterly, annual\n', '    :param str transform: options are diff, rdiff, cumul, and normalize\n', '    :param int rows: Number of rows which will be returned\n', '    :param str order: options are asc, desc. Default: `asc`\n', '    :param str returns: specify what format you wish your dataset returned as,\n', '        either `numpy` for a numpy ndarray or `pandas`. Default: `pandas`\n', '    :returns: :class:`pandas.DataFrame` or :class:`numpy.ndarray`\n', '    Any other `kwargs` passed to `get` are sent as field/value params to Quandl\n', '    with no interference.\n', '\n', ""'''\n"", '\n', '\n', '\n', '#--------------------Import data from Yahoo --------------------------------------------------\n', 'def imp_yahoo_getquotes(symbols, start=""20150101"", end=""20160101"", type1=1):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', '# symbols = np.array(symbol1)\n', ' quotes= []; errorlist=[]; correctlist=[]\n', ' for i, symbol in enumerate(symbols) :\n', '   # if np.mod(i,400) ==0 and i != 0 :\n', ""     # print('Waiting 30s'); time.sleep(30)\n"", '   try:   \n', '     array1= quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '     df= pd.DataFrame.from_records(array1)\n', '     quotes.append(df)\n', '     correctlist.append(symbol)\n', '   except :\n', '       errorlist.append(symbol)\n', ""       print('Err: '+symbol)\n"", ' #quotes = [quotes_historical_yahoo(symbol, d1, d2, asobject=True)  for symbol in symbols]\n', ' #print(errorlist) \n', ' if type1==1 :  return quotes, correctlist\n', ' else: return quotes, correctlist, errorlist  \n', '\n', '              \n', '#Find error in Ticker import\n', 'def imp_yahoo_geterrorticker(symbols, start=""20150101"", end=""20160101""):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', ' errorlist= []\n', ' for symbol in symbols :\n', '   try :  \n', '     quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '   except :\n', '     errorlist.append(symbol)\n', '     print(symbol)       \n', ' return errorlist\n', ' \n', ""'''\n"", ""symbols0= ['KHC', 'PYPL', 'HPE', 'BXLT', 'SYF', 'WLTW', 'CFG', 'BF-B', 'WRK']\n"", '\n', '#Show list of ticker in error\n', 'import_errorticker(symbols0,""20110101"",""20150601""  )\n', ""'''\n"", '\n', '\n', 'def imp_yahoo_financials_url(ticker_symbol, statement=""is"", quarterly=False):\n', '    if statement == ""is"" or statement == ""bs"" or statement == ""cf"":\n', '        url = ""https://finance.yahoo.com/q/"" + statement + ""?s="" + ticker_symbol\n', '        if not quarterly:\n', '            url += ""&annual""; return BeautifulSoup(requests.get(url).text, ""html.parser"")\n', '    return sys.exit(""Invalid financial statement code \'"" + statement + ""\' passed."")\n', '\n', 'def imp_yahoo_periodic_figure(soup, yahoo_figure):\n', '    values = []; pattern = re.compile(yahoo_figure)\n', '\n', '    title = soup.find(""strong"", text=pattern)    # works for the figures printed in bold\n', '    if title:  row = title.parent.parent\n', '    else:\n', '        title = soup.find(""td"", text=pattern)    # works for any other available figure\n', '        if title:  row = title.parent\n', '        else:      sys.exit(""Invalid figure \'"" + yahoo_figure + ""\' passed."")\n', '\n', '    cells = row.find_all(""td"")[1:]    # exclude the <td> with figure name\n', '    for cell in cells:\n', '        if cell.text.strip() != yahoo_figure:    # needed because some figures are indented\n', '            str_value = cell.text.strip().replace("","", """").replace(""("", ""-"").replace("")"", """")\n', '            if str_value == ""-"": str_value = 0\n', '            value = int(str_value) * 1000\n', '            values.append(value)\n', '\n', '    return values\n', '    \n', '# print(imp_yahoo_periodic(imp_yahoo_financials_url(""AAPL"", ""is""), ""Income Tax Expense""))\n', '\n', ' \n', '\n', '#--------------------Import Quotes Google  ------------------------------------------\n', 'import requests.packages.urllib3\n', 'requests.packages.urllib3.disable_warnings()\n', 'import urllib, os\n', '\n', ""dirstockcsv= 'E:\\_data\\stock\\csv'\n"", '\n', 'def imp_googleIntradayQuote(symbol, freqsec=300, nday=5):\n', ""    ''' Intraday quotes from google. Specify interval seconds and number of days\n"", '    http://www.google.com/finance/getprices?q=7261&i=300&p=3d&f=d,o,h,l,c,v\n', ""    '''\n"", '    url =""http://www.google.com/finance/getprices?q={0}"".format(symbol)\n', '    url +=""&i={0}&p={1}d&f=d,o,h,l,c,v"".format(freqsec, nday)\n', '    try :      \n', '       resp= requests.post(url)\n', '       csv= resp.text\n', '       csv= csv.splitlines()\n', '    except :\n', ""       print('Err Intaday '+symbol)\n"", '\n', '    if len(csv) < 9 :\n', ""      print 'Using Daily',\n"", '\n', ""      url='http://www.google.com/finance/historical?q='+symbol+'&i='+str(freqsec)+'&p=3d&f=d,o,h,l,c,v&output=csv'\n"", '      csv = urllib.urlopen(url).readlines()\n', '      csv.reverse()\n', '      q=[]\n', '      for bar in xrange(0,len(csv)-1):\n', ""        ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '        if isfloat(open_) and isfloat(high) :\n', '          open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""          dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '          q.append([dt,open_,high,low,close,volume])\n', ""      df= util.pd_array_todataframe(q, ['date','open','high','low','close','volume'])\n"", '      return df\n', '\n', '\n', '    # print(csv)\n', '    qq=[]\n', '    for bar in xrange(7,len(csv)):\n', ""      if csv[bar].count(',')!=5: continue\n"", ""      offset,close,high,low,open_,volume = csv[bar].split(',')\n"", '      \n', ""      if offset[0]=='a':\n"", '        day = float(offset[1:])\n', '        offset = 0\n', '      else:\n', '        offset = float(offset)\n', '      open_, high, low, close = [float(x) for x in [open_,high,low,close]]\n', '      dt = datetime.datetime.fromtimestamp(day + (freqsec * offset))\n', '      #print (dt,open_,high,low,close,volume)\n', '      qq.append([dt,open_,high,low,close,volume])\n', ""    df= util.pd_array_todataframe(qq, ['date','open','high','low','close','volume'])\n"", '    return df\n', '\n', ""def imp_googleIntradayQuoteSave(symbols=['NKE'], freqsec=300, nday=2000, dircsv='', dbname=''):\n"", "" ''' Save Under various format: csv / db / output in Dataframe '''\n"", ' if isinstance(symbols, str) : symbols= [symbols]\n', ' symout,qlist, sym_error= [], [], []\n', ' for sym in symbols:\n', '   try :\n', '    q = imp_googleIntradayQuote(sym, freqsec, nday)  #interval, timeframe\n', '    print sym,\n', ""    sym= sym.replace(':', '_')\n"", '\n', ""    if dircsv != '' :\n"", '      if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""      start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""      file1= dircsv+ '\\\\' + sym + '_' + str(start1) + '_' + str(freqsec) + '_' + str(nday) + '.csv'\n"", '\n', ""      q= util.pd_addcol(q, 'symbol'); q['symbol']= sym\n"", '      q.to_csv(file1, index=False)\n', '\n', ""    elif dbname != '' :\n"", '      import sqlalchemy as sql\n', '      dbcon= sql.create_engine(dbname)\n', '      if interv_sec== 300 : # 5mins\n', ""        q.to_sql('q5min', dbcon)\n"", '\n', '    else :\n', '      qlist.append(q);   symout.append(sym)\n', '   except:\n', ""      print('Error:'+sym, )\n"", '      sym_error.append(sym)\n', '\n', ' return qlist, symout, sym_error\n', '\n', ""def imp_googleQuote(symbol, start_date='20160101', end_date= '20160101') : # datetime.date.today().isoformat()):\n"", ""    ''' Daily quotes from google. Date format='yyyymmdd' '''\n"", '    symbol = symbol.upper()\n', '    start = datetime.date(int(start_date[0:4]),int(start_date[4:6]),int(start_date[6:8]))\n', '    end =   datetime.date(int(end_date[0:4]),int(end_date[4:6]),int(end_date[6:8]))\n', '    url =""http://www.google.com/finance/historical?q={0}"".format(self.symbol)\n', '    url +=""&startdate={0}&enddate={1}&output=csv"".format( start.strftime(\'%b %d, %Y\'),end.strftime(\'%b %d, %Y\'))\n', '    csv = urllib.urlopen(url).readlines()\n', '    csv.reverse()\n', '    # print(url)\n', '    q=[]\n', '    for bar in xrange(0,len(csv)-1):\n', ""      ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '      if isfloat(open_) and isfloat(high) :\n', '        open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""        dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '        q.append([dt,open_,high,low,close,volume])\n', '    return q\n', '\n', 'def imp_googleQuoteSave(symbols, date1, date2, dircsv):\n', ' if isinstance(symbols, str) : symbols= [symbols]\n', ' for sym in symbols:\n', '   try :\n', '      q = imp_googleQuote(sym, date1, date2)   #interval, timeframe\n', ""   except: print('Error:'+symbol)\n"", '\n', ""   sym= sym.replace(':', '_')\n"", '\n', ""   if dircsv != '' :\n"", '     if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""     start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""     file1= dircsv+ '\\\\'+ name1+'_'+ start1 +'_'+ str(date2) +'.csv'\n"", '     q.to_csv(file1)\n', '\n', ""   if dbname != '' :\n"", '     import sqlalchemy as sql\n', '     dbcon= sql.create_engine(dbname)\n', '     if interv_sec== 300 : # 5mins\n', ""       q.to_sql('q5min', dbcon)\n"", '\n', '\n', '\n', ""def imp_csv_dbupdate(indir='E:/_data/stock/intraday/intraday_google_usetf2.h5',\n"", ""                     outdir='E:/_data/stock/intraday/q5min/us/etf/', filelist=[], intype='csv',\n"", ""                     refcols=['date', 'open', 'high', 'low', 'close', 'volume', 'symbol']) :\n"", '\n', '  for file1 in filelist :\n', ""    sym=  file1[:file1.find('_')]  #Clean Up name\n"", '    print sym,\n', ""    outfile= outdir+'/'+sym+'.csv'\n"", '    if os.path.isfile(outfile) :\n', ""      df0= imp_csv_toext(file1=outfile, fromzone='Japan', tozone='UTC', header=0, cols=refcols)\n"", '    else :\n', '      df0= None\n', '\n', ""    if intype== 'hdfs':\n"", '      df1= imp_hdfs_getquote(indir, sym)\n', '      if isinstance(df1, float) : df1= None\n', '\n', ""    if intype=='csv' :\n"", ""      infile= indir+'/'+ file1   #csv\n"", ""      df1= imp_csv_toext(file1=infile, header=0, cols=refcols, fromzone='Japan', tozone='UTC')\n"", '\n', '    if df1 is not None :\n', '       if df0 is not None  : df1= imp_pd_merge(df1[refcols], df0[refcols])\n', '       # return outfile, df1\n', '       df1[refcols].to_csv(outfile, index=False)\n', '\n', '\n', '#####################################################################################\n', 'def imp_numpy_close_fromdb(dbname=\'/aaserialize/store/yahoo.db\', table1=\'\', symlist=[], t0=20010101, t1=20010101, priceid=""close"", batchsize= 400, maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from DB SQL"")\n', ' import data.hist_data_storage as yhh\n', ' dstore= yhh.dailyDataStore(dbname)\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', '\n', "" dateref0= dstore.get_histo(['SPY'], table1='daily_us_etf', start1=str(t0), end1=str(t1),  split_df=0).date.values\n"", ' \n', ' k=0; symfull=[];   i=0\n', ' nsym= len(symlist); nbatch= int(nsym / batchsize)+1\n', ' for j in xrange(0, nbatch) : \n', '      qlist, sym= dstore.get_histo(symlist[i:min(nsym,i+batchsize)], table1=table1, start1=str(t0), end1=str(t1),  split_df=1)\n', '\n', '      #print(""batch: ""+str(j), len(qlist), len(qlist[0].index) )\n', '      #for k,q in enumerate(qlist) :print sym[k], len(q.index)\n', '      i= i + batchsize\n', '      symfull= np.concatenate((symfull,sym))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)\n', '      print(""batch: ""+str(j), len(sym),dateref[0],dateref[-1] )\n', '      qlist=None; sym=None\n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[k:k+masset,0:tmax] = close\n', '      k=k+ masset\n', '\n', ' maxasset= k\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', 'def imp_numpy_close_fromhdfs(dbfile, symlist=[], t0=20010101, t1=20010101, priceid=""close"", maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from Pandas"")\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', ' store = pd.HDFStore(dbfile)\n', ' \n', "" df= store.select('SPY')\n"", ' df= df[(df.date >= t0) & (df.date <= t1 )]\n', ' dateref0= df.date.values\n', ' \n', ' k=0; symfull=[]; qlist=[]; sym=[]; tmax= 2000\n', ' for j, symbol in enumerate(store.keys()):\n', '  symbol=  symbol[1:]\n', '\n', '  if len(symlist)==0  or  util.find(symbol,symlist) > -1 : \n', '   #print symbol, util.find(symbol,symlist) \n', '   df= store.select(symbol) \n', '   if t0 !=t1 :     df= df[(df.date >= t0) & (df.date <= t1 )]\n', '   \n', '   qlist.append(df);   sym.append(symbol)\n', '   if np.mod(j+1, 401) == 0 :\n', '      print(""batch: ""+str(j))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)   \n', '      print len(sym),dateref[0],dateref[-1] \n', '      symfull= symfull+sym\n', '      qlist=[]; sym=[]\n', ' \n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[(k):(k+masset),0:tmax] = close\n', '      k=k+ masset   \n', '     \n', ' if len(qlist) > 0:\n', '  # return qlist, qlist[0] ,  qlist[1] \n', '   close,dateref= date_align(qlist,type1=priceid)   \n', '   print len(sym),dateref[0],dateref[-1] \n', '   symfull= symfull+sym\n', '   masset,tmax= np.shape(close);\n', '   close2[(k):(k+masset),0:tmax] = close\n', ' \n', ' maxasset= k+masset\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', '\n', ""def imp_sql_getquotes(stocklist01, dbname='sqlite:///aaserialize/store/yahoo.db', start1=20150101, end1=20160616, table1='daily_us_stock'):\n"", '    import data.hist_data_storage as yhh\n', '    dstore = yhh.dailyDataStore(dbname)\n', '    qlist, sym= dstore.get_histo(stocklist01, table1=table1,  start1=start1, end1=end1, split_df=1)\n', '    return qlist, sym\n', '\n', ""def imp_txt_getquotes(stocklist01, filedir='E:/_data/stock/daily/20160610/jp', startdate=20150101, endate=20160616):\n"", ' liststockfile= util.listallfile(filedir, ""*.txt"", dirlevel=5)\n', ' #print liststockfile\n', ' if len(np.shape(liststockfile)) > 1 :\n', '  liststockname=[ x.split(""."")[0] for x in liststockfile[:,0] ]\n', '#  for k in range(0, np.shape(liststockfile)[0]):  liststockname.append( (liststockfile[k,0])[0:4])   \n', '   \n', ' else: \n', '  stk0= liststockfile[0]; #stk2= liststockfile[2]\n', '#  liststockname=[ x[0:4] for x in stk0 ]\n', '  liststockname=[ x for x in stk0 ]\n', '\n', '#  liststockname=[]\n', '#  for k in range(0, len(stk0)):  liststockname.append( (stk0[k])[0:4])\n', ' \n', ' quotes=[]\n', ' print liststockname\n', ' for sym in stocklist01:\n', '   kstock= util.np_findfirst(sym, liststockname)\n', '   if kstock == -1 :\n', ""     print('Not Found '+sym)\n"", '   else :\n', '     df= pd.read_csv(liststockfile[kstock][2])\n', ""     df.columns = ['date', 'open', 'high','low','close', 'volume', 'openint']  #Change Column Name\n"", '     df2= df[(df.date > startdate  )& ( df.date   < endate )] # Filter by date\n', '     quotes.append(df2)\n', '  \n', ' return quotes \n', '\n', '\n', 'def imp_csv_getname(name1, date1, inter, tframe):\n', "" file1= dirstockcsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", ' return file1\n', '\n', '\n', 'from dateutil import tz\n', ""def imp_csv_toext(file1='SPY.csv', outputfile='.h5', fromzone='Japan', tozone='UTC', header=None,\n"", ""                  cols=['date', 'time','open','high','low','close','volume', 'symbol'], coldate=[0]):\n"", ""  ''' cols: column name,  coldate: position of date column   '''\n"", '  from dateutil import parser\n', '\n', '  if os.path.getsize(file1)> 500 :\n', ""   df = pd.read_csv(file1,sep=',',header=header)  # date_parser=dateparse)  # parse_dates={'date': [] },\n"", '   df.date= [ parser.parse(x) for x in  df.date]\n', '\n', ""   #if util.find('symbol', df.columns.values) < 0 :\n"", ""     #df= util.pd_addcol(df, 'symbol')\n"", ""     #df['symbol']= sym\n"", '\n', ""   type1= outputfile[outputfile.find('.'):]\n"", '\n', ""   if outputfile=='':\n"", '     # df.columns = [  x.lower() for x in df.columns.values ]\n', ""     # df.columns = ['date', 'symbol','open','high','low','close','volume']\n"", '     df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""     df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""     df.columns = ['date', 'open','high','low','close','volume', 'symbol']\n"", '     return df[cols]\n', '\n', ""   if type1=='csv' :\n"", ""     df[cols].to_csv(outputfile , index=False)  # , compression='gzip' )\n"", '\n', ""   if type1== 'h5' :\n"", ""      # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '      dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '      # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '      # df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '      # df.date= [x.to_datetime() for x in  df.date]\n', '\n', '      df.drop(df.columns[[0]], axis=1, inplace=True)\n', '      print filenameh5\n', ""      if util.find('symbol', df.columns.values) < 0 :\n"", ""         df= util.pd_addcol(df, 'symbol'); df['symbol']= dfname\n"", '      store = pd.HDFStore(outputfile); store.append(dfname, df);  store.close()\n', '\n', '\n', '\n', ""def imp_hdfs_db_updatefromcsv(dircsv, filepd=r'E:\\_data\\stock\\intraday_google.h5', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= filepd + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2, name1, fromtimezone, tozone)\n', '\n', ""def imp_hdfs_db_dumpinfo(dbfile='E:\\_data\\stock\\intraday_google.h5'):\n"", '  store = pd.HDFStore(dbfile)\n', '  extract=[]; errsym=[]\n', '  for symbol in store.keys():\n', '     try:\n', '       df= pd.read_hdf(dbfile, symbol)\n', ""       t0= df['date'].values[0]\n"", ""       t1= df['date'].values[-1]\n"", '\n', '       extract.append([symbol[1:], df.shape[1],   df.shape[0], t0, t1 ])\n', '\n', '     except: errsym.append(symbol)\n', '  return np.array(extract), errsym\n', '\n', 'def imp_hdfs_mergedb(filepdfrom, filepdto) :\n', '  store0 = pd.HDFStore(filepdfrom)\n', '  store1 = pd.HDFStore(filepdto)\n', '\n', '  for symbol in store0.keys():\n', '    qq= imp_hdfs_getquote(filepdfrom, symbol)\n', '    store1.append(symbol, qq)\n', '\n', '    qq= imp_hdfs_getquote(filepdto, symbol)\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    print(symbol)\n', '  store0.close(); store1.close()\n', '\n', ""def imp_hdfs_storecopy(hdfs1='F:/usstock8.h5', hdfs2='F:/usstock8.h5'):\n"", ' store = pd.HDFStore(hdfs1);  store2 = pd.HDFStore(hdfs2)\n', ' for symbol in store.keys() :\n', '   df= imp_hdfs_getquote(hdfs1, symbol)\n', '   symbol= symbol[1:].replace(""-"",""_"")\n', '   store2.append(symbol, df, data_columns=True)\n', ' store.close(); store2.close()\n', '\n', 'def imp_hdfs_getquote(filenameh5, dfname=""data""):\n', '  try: return  pd.read_hdf(filenameh5, dfname)\n', '  except: return -1.0;\n', '\n', ""def imp_hdfs_getListquote(symbols, close1='close', start='12/18/2015 00:00:00+00:00',\n"", ""                          end='3/1/2016 00:00:00+00:00', freq='0d0h10min', filepd= 'E:\\_data\\stock\\intraday_google.h5',\n"", ""                          tozone='Japan', fillna=True, interpo=True):\n"", '\n', ' datefilter= pd.date_range(start=start, end=end, freq= freq,tz=tozone).values\n', '\n', ' errorsym=[]; quotes=[]; correctsym=[]\n', ' for symbol in symbols:  # Issue Not same size\n', '   qq= imp_hdfs_getquote(filepd, symbol)\n', '\n', '   if type(qq)==np.float :  # Error qq=-1\n', '        errorsym.append(symbol)\n', '   else:\n', ""       qq.columns = ['date', 'symbol','open','high','low','close','volume']\n"", ""       qq= qq[qq['date'].isin(datefilter)]   #Only date in the range\n"", ""       #qq= qq.drop_duplicates(cols='date', take_last=True)\n"", ""       #  qq= qq.sort('date', asc=True)\n"", '\n', '       #print qq.date.values[0]\n', ""       if fillna : qq= qq.fillna(method='backfill')\n"", '       if interpo : qq= qq.interpolate()\n', '       quotes.append(qq)\n', '       correctsym.append(symbol)\n', '\n', ' datefilter= datenumpy_todatetime(datefilter)\n', ' return quotes,datefilter, correctsym,   errorsym\n', '\n', '\n', ""def imp_hdfs_removeDuplicate(filepd='E:\\_data\\stock\\intraday_google.h5') :\n"", '  #-------Clean by removing duplicate-------------------------------------------------\n', '  store = pd.HDFStore(filepd)\n', '  for symbol in store.keys():\n', '    #qq= imp_hdfs_getquote(filepd, symbol);\n', '    qq= store.select(symbol[1:])\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    qq.index = list(np.arange(0,len(qq.index)))\n', '\n', '    store.remove(symbol); store.append(symbol, qq);\n', '  store.close()\n', '\n', '\n', '\n', ""def imp_pd_tohdfs(sym, qqlist, filenameh5, fromzone='Japan', tozone='UTC') :\n"", ""  ''' df list to HDFS '''\n"", '  store = pd.HDFStore(filenameh5);\n', '  for k, df2 in enumerate(qqlist) :\n', '    df= copy.deepcopy(df2)\n', ""    df['date']= datetime_toint(df.date.values)\n"", '\n', ""    symbol= sym[k].replace('-','_')\n"", '    qq= imp_hdfs_getquote(filenameh5, symbol)\n', '    # print symbol, type(qq)\n', '    if type(qq) ==  float or  type(qq) ==  int  :\n', '      store.append(symbol, df)  # , data_columns=True\n', '      # print(symbol + str(df.date.values[-1]))\n', '    else :\n', '      qq= pd.concat([qq, df], ignore_index=True)\n', ""      qq= qq.drop_duplicates(subset='date', keep='last')\n"", ""      qq= qq.sort('date', ascending=1)\n"", '      store.append(symbol, qq)  #Too much space , data_columns=True\n', '      print(symbol + str(qq.date.values[-1]))\n', '\n', '  store.close()\n', '\n', 'def imp_pd_merge(df1, df2) :\n', '  df= pd.concat([df1, df2], axis=0)\n', ""  df= df.drop_duplicates(subset='date', keep='last')\n"", ""  df= df.sort_values(by=['date'], ascending=1)\n"", '  df.index = list(np.arange(0,len(df.index)))\n', '  return df\n', '\n', 'def imp_pd_checkquote(quotes) :\n', ""   for c in quotes: print np.shape(c), c['date'].values[0], c['date'].values[-1]\n"", '\n', 'def imp_pd_getclose(df, datefilter=None):\n', ' if datefilter is  not None :\n', ""    df= df[df['date'].isin(datefilter)]   #Only date in the range\n"", "" df= df.sort('date')\n"", "" close= df.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", ' \n', ' close= np.array(close.values[1:,1:]).astype(np.float)            #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close\n', '\n', 'def imp_pd_cashyield(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  100 * np.cumprod( (1 + np.ones(len(vv)) * 0.005/365.0 ))\n', '     qbond[id1]= pbond\n', '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_yield_tobond(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  1/ np.power(1+ vv*0.01,duration) *100\n', '     qbond[id1]= pbond\n', ""#     print 'ok'\n"", '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_errordate(quotes, dateref):\n', "" ''' Show Symbol in Error when importing '''\n"", ' for i, stock in enumerate(quotes) :\n', '   print(i, symbols1[i],  datetime_tostring(stock[0][0]))\n', ' print(""\\n\\n"")\n', '\n', ' for i, stock in enumerate(quotes) :\n', '   date1= datetime_toint(stock[0][0])\n', '   if date1 != dateref : print(i, symbols1[i],  str(date1))\n', '\n', 'def imp_pd_fxtoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', 'def imp_pd_fxinversetoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(1.0 / q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', ""def imp_pd_filterbydate(df, dtref=None, start='2016-06-06 00:00:00', end='2016-06-14 00:00:00', freq='0d0h05min', timezone='Japan'):\n"", "" ''' df: DateSeries or TimeSeries of Quotes   '''\n"", '\n', ' if type(df) in {pd.core.frame.DataFrame} :  #Data frame version\n', '   if type(dtref)== str:\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', ""   return df[df['date'].isin(dtref)]\n"", ' else :\n', '   if type(dtref)== str:  #Date version\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', '   return df[df.isin(dtref)].values\n', '\n', 'def imp_pd_cleanquote(q):\n', ' col= q.columns.values\n', "" if isinstance(q['date'].values[0] , str) :\n"", ""   q['date']= datetime_todate(datestring_todatetime(q['date'].values))\n"", '\n', ' for kid in col:\n', ""   if kid not in ['date', 'day','month','year'] :\n"", ""      q[kid]= pd.to_numeric(q[kid], errors='coerce').values  #Put NA on string\n"", '\n', "" q= q.fillna(method='pad')\n"", ' return q\n', '\n', 'def imp_pd_divide(q1, q2, funapply):\n', "" close, dateref= date_align([q1,q2], type1='close')\n"", ' m,tt= np.shape(close)\n', '\n', ' q3= util.pd_createdf( np.zeros((tt,len(q1.columns))) ,q1.columns, dateref)\n', "" q3['date']= dateref\n"", "" q3['close']= (close[0,:] / close[1,:])\n"", '\n', ' for kid in q1.columns :\n', ""   if kid not in ['close', 'volume','date','day','month', 'year'] :\n"", '     close, _= date_align([q1,q2], type1=kid)\n', '     q3[kid]= (close[0,:] / close[1,:])\n', ' return q3\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""def imp_quote_csvdir_tofile(dircsv='', outdir1='E:/_data/stock/', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= outdir + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2,  header=True, fromzone=fromtimezone, tozone=tozone)\n', ""'''\n"", '\n', '\n', ""'''\n"", ""close1='Close' ; start='12/18/2015 00:00:00';\n"", ""end='3/1/2016 00:00:00'; freq='1d0h00min';\n"", ""filepd= 'E:\\_data\\stock\\intraday_google.h5'\n"", '\n', 'datefilter= pd.date_range(start=start, end=end,   freq= freq).values\n', '\n', 'symbols, names = np.array(list(symbol_dict.items())).T\n', 'i=0; vv=[]\n', 'for symbol in symbols:  # Issue Not same size\n', '   qq= quote_frompanda(filepd, symbol); i+=1\n', '   if isfloat(qq) :  vv.append(symbol)\n', '   else:\n', ""     if i==1: close = qq[['Datetime']]  #new dataframe    \n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', '     if not tmp.isnull().values.all():\n', ""      close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""      close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', ""close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", ""close= close.sort('Datetime')\n"", ""close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", 'close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', 'close= close[(np.abs(stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', ""'''\n"", 'from datetime import datetime\n', 'from dateutil import tz\n', '\n', ""from_zone = tz.gettz('Japan'); to_zone = tz.gettz('UTC')\n"", '\n', ""date1 = datetime.strptime('2011-01-21 09:00:00', '%Y-%m-%d %H:%M:%S')\n"", 'date1 = date1.replace(tzinfo=from_zone)\n', 'dateutc = date1.astimezone(to_zone)\n', 'date1, dateutc\n', '\n', ""Suppose you have a column 'datetime' with your string, then:\n"", ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\n"", ' combine multiple columns into a single datetime column,\n', ""this merges a 'date' and a 'time' column into a single 'datetime' column:\n"", '\n', ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)\n"", ""'''\n"", '\n', '\n', '#date1 = ""20160302""; inter= 60; tframe=80; name1= ""spy""\n', '#googleIntradayQuoteSave(name1, inter, tframe)\n', '\n', '\n', '\n', 'def ta_mar(close,t,m):  return  100*( np.mean(close[(t-m):(t+1)], axis=0) / close[t] )\n', 'def ta_ma(close,t,m):  return   np.mean(close[(t-m):(t+1)], axis=0)\n', '\n', '\n', '############################################################################\n', '#---------------------Calculate the Statistics         --------------------  \n', 'def calc_statestock(close2, dateref, symfull):\n', ' def sort(x,col,asc): return   util.sortcol(x,col,asc)\n', ' def perf(close,t0,t1):  return  100*( close[:,t1] / close[:,t0] -1)\n', ' def and2(tuple1):  return np.logical_and.reduce(tuple1)\n', ' def mar(close,t,m):  return  100*( np.mean(close[:,(t-m):(t+1)], axis=1) / close[:,t] )\n', ' def ma(close,t,m):  return   np.mean(close[:,(t-m):(t+1)], axis=1)\n', '\n', '\n', ' # a= ma(close2, tmax, 5) / ma(close2, tmax, 50)  \n', '\n', '\n', ' def dd(t) :\n', '  x= util.find(t,dateref)  # 607\n', ""  if x==-1 : print 'Error date not found in dateref '+str(t) ; return np.nan\n"", '  else :  return x\n', '\n', ' def gap(close,t0,t1,lag):   \n', '  ret= getret_fromquotes(close[:,t0:t1],lag)\n', '  rmin= 100*np.amin(ret,axis=1)\n', '  return rmin\n', ' \n', ' #--------------------Size----------------------------------------- \n', ' masset= len(symfull)\n', ' ttmax= util.find(0,close2[0,:])\n', ' if ttmax==-1 : ttmax= np.shape(close2)[1]\n', ' close2= close2[0:masset,0:ttmax]\n', ' m, tmax= masset, ttmax-1\n', ' \n', ' #correl\n', ' #close3= np.array(close2[:,0:ttmax],dtype=np.float16)\n', ' #close2ret= getret_fromquotes(close3)\n', ' #close2ret= np.nan_to_num(close2ret)\n', ' #close2ret= util.np_cleanmatrix(close2ret);  del close3\n', '\n', '##################################################################################\n', '#1: 1d,2:5d,3:10d,4:15d,5:20d,11:50d,12:60d,13:90d,15:1y\n', '#16: YTD,17:From Feb,21: 2015Ret,45: Price,50,51: Min,52,53: Max\n', ' print(""Calcul the Stats "" + str(dateref[-1]))\n', ' stat= np.zeros((2600,200),dtype=np.float16)\n', '\n', ' k=0\n', ' stat[k:(k+m),0]= np.arange(k,k+m)\n', ' stat[k:(k+m),1]=  perf(close2,tmax-1,tmax)  \n', ' stat[k:(k+m),2]=  perf(close2,tmax-5,tmax)  \n', ' stat[k:(k+m),3]=  perf(close2,tmax-10,tmax)  \n', ' stat[k:(k+m),4]=  perf(close2,tmax-15,tmax)  \n', ' stat[k:(k+m),5]=  perf(close2,tmax-20,tmax)  \n', '# stat[k:(k+m),6]=  perf(close2,tmax-25,tmax)  \n', ' stat[k:(k+m),7]=  perf(close2,tmax-30,tmax)  \n', '# stat[k:(k+m),8]=  perf(close2,tmax-35,tmax)  \n', ' stat[k:(k+m),9]=  perf(close2,tmax-40,tmax)  \n', '# stat[k:(k+m),10]=  perf(close2,tmax-45,tmax)  \n', ' stat[k:(k+m),11]=  perf(close2,tmax-50,tmax)  \n', ' stat[k:(k+m),12]=  perf(close2,tmax-60,tmax)  \n', ' stat[k:(k+m),13]=  perf(close2,tmax-90,tmax)  \n', ' stat[k:(k+m),14]=  perf(close2,tmax-120,tmax)  \n', ' stat[k:(k+m),15]=  perf(close2,tmax-250,tmax)  \n', '\n', '\n', '# stat[k:(k+m),16]=  perf(close2, dd(20160105),tmax)   #1Jan 2016\n', '# stat[k:(k+m),17]=  perf(close2, dd(20160222),tmax)   # 22 Feb 2016\n', '# stat[k:(k+m),18]=  perf(close2,dd(20160105),dd(20160222))   # Crash DrawDown\n', ' # stat[k:(k+m),19]=  perf(close2,624,tmax)   #  24 June 2016\n', ' # stat[k:(k+m),20]=  perf(close2,623,625)   #  Crash 24 June 2016\n', ' # stat[k:(k+m),21]=  perf(close2,dd(20151230)-250,dd(20151230))    #2015 Return\n', '\n', ' stat[k:(k+m),22]= gap(close2,tmax-80,tmax,1) #Max 1 days Gap\n', ' stat[k:(k+m),23]= gap(close2,tmax-80,tmax,5) #Max 5 days Gap\n', ' stat[k:(k+m),24]= perf(close2,tmax-2,tmax)  \n', ' stat[k:(k+m),25]= perf(close2,tmax-3,tmax)  \n', ' stat[k:(k+m),26]= perf(close2,tmax-4,tmax)  \n', '\n', ' stat[k:(k+m),27]= perf(close2,tmax-2,tmax-1)   \n', ' stat[k:(k+m),28]= perf(close2,tmax-3,tmax-2)   \n', ' stat[k:(k+m),29]= perf(close2,tmax-4,tmax-3)   \n', ' stat[k:(k+m),30]= perf(close2,tmax-5,tmax-4)\n', ' \n', ' stat[k:(k+m),120]= mar(close2, tmax, 20) \n', ' stat[k:(k+m),121]= mar(close2, tmax, 50) \n', ' stat[k:(k+m),122]= 100*ma(close2, tmax, 5) / ma(close2, tmax, 50)  #OverSold /OverBought\n', ' stat[k:(k+m),123]= mar(close2, tmax, 100)  \n', ' stat[k:(k+m),124]= mar(close2, tmax, 10) \n', '# stat[k:(k+m),35]= 0 \n', '# stat[k:(k+m),36]= 0 \n', '# stat[k:(k+m),37]= 0 \n', '# stat[k:(k+m),38]= 0 \n', '# stat[k:(k+m),39]= 0 \n', '\n', ' # stat[k:(k+m),30]= volume / AvgVol3M\n', ' # stat[k:(k+m),30]= Nbday_to_Earnings\n', ' #Volume/3M AvgVolume\n', ' # stat[k:(k+m),26]=  volume(volume2,tmax-120,tmax)  \n', '\n', ' #==============================================================================\n', ' #-------------- Data Fundamental    -------------------------------------------\n', "" df= util.sql_query(sqlr='SELECT ticker,shortratio,sector1_id, sector2_id, marketcap   FROM stockfundamental ', dburl='/aaserialize/store/finviz.db')\n"", ' npdf= df.values; del df\n', ' npdf0= npdf[:,0]  \n', ' for i in range(0,m):  \n', '   try :\n', '     kid= util.find(symfull[i], npdf0)\n', '     if kid != -1 :\n', '      stat[i,150]=  float(npdf[kid, 1])   # short ratio\n', '      stat[i,151]=  float(npdf[kid, 2])   # sector 1      \n', '      stat[i,152]=  float(npdf[kid, 3])   # sector 2     \n', '      stat[i,153]=  float(npdf[kid, 4] / 100000000.0)   # market Cap    \n', '   except : pass\n', ' del npdf, npdf0\n', '\n', '\n', '#==============================================================================\n', ' ################ Volatility\n', ' stat[k:(k+m),40]= volhisto_fromprice(close2,tmax,20,axis=1)* 100\n', ' stat[k:(k+m),41]= volhisto_fromprice(close2,tmax,60,axis=1)* 100\n', ' stat[k:(k+m),42]= volhisto_fromprice(close2,tmax,252,axis=1)* 100\n', '# stat[k:(k+m),43]= stat[k:(k+m),12] / stat[k:(k+m),41] #Sharpe 3Month\n', '# stat[k:(k+m),44]= stat[k:(k+m),15] / stat[k:(k+m),42] #Sharpe 1Year\n', '\n', ' stat[k:(k+m),45]= close2[:,tmax] #Last Close\n', '\n', '# stat[k:(k+m),46]= 0 \n', '# stat[k:(k+m),47]= 0 \n', '# stat[k:(k+m),48]= 0 \n', '# stat[k:(k+m),49]= 0 \n', '\n', '\n', ' ###############  Technical Indicator\n', ' #Min of last 6 months, Max of last 6months\n', ' for i in range(0,m):\n', '  pp0= stat[i,45]\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-120):tmax])\n', '  stat[i,50]= kmin+(tmax-120);  stat[i,51]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-120):tmax])\n', '  stat[i,52]= kmax+(tmax-120);  stat[i,53]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-10):tmax])\n', '  stat[i,66]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-10):tmax])\n', '  stat[i,67]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-5):tmax])\n', '  stat[i,68]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-5):tmax])\n', '  stat[i,69]= 100*pp0 / pmax\n', '\n', ' del kmax,pmax,i,k  \n', '\n', '\n', ' #Regression from Min Price Time\n', ' for i in range(0,m):\n', '  t0= int(stat[i,50])\n', '  try :\n', '    res= regression(close2[i,t0:tmax ]  ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,54]=  res[2]  #R2\n', '    stat[i,55]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from Max Price Time\n', ' for i in range(0,m):  \n', '  t0= stat[i,52]\n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,56]=  res[2]  #R2\n', '    stat[i,57]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from 5 days ago\n', ' t0= tmax-5\n', ' for i in range(0,m): \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,58]=  res[2]  #R2\n', '    stat[i,59]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', '#Regression from 10 days ago\n', ' t0= tmax-10\n', ' for i in range(0,m):  \n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,60]=  res[2]  #R2\n', '    stat[i,61]=  res[0][0]  #Slope\n', '   except : pass\n', '\n', "" '''\n"", '#Regression from 1 month\n', ' t0= tmax-20   \n', ' for i in range(0,m):\n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,62]=  res[2]  #R2\n', '    stat[i,63]=  res[0][0]  #Slope\n', '   except : pass\n', "" '''\n"", '\n', "" '''\n"", '#Regression from 2 months ago\n', ' t0= tmax-40\n', ' for i in range(0,m):  \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,64]=  res[2]  #R2\n', '    stat[i,65]=  res[0][0]  #Slope\n', '  except : pass\n', "" '''\n"", '\n', '#Nb of Positive days last 5d\n', ' for i in range(0,m):  stat[i,66]=  np_countretsign(close2[i,(tmax-5):tmax])  \n', '\n', '#Nb of Positive days last 10d\n', ' for i in range(0,m):  stat[i,67]=  np_countretsign(close2[i,(tmax-10):tmax])  \n', '\n', '#Nb of Positive days last 20d\n', '# for i in range(0,m):  stat[i,68]=  np_countretsign(close2[i,(tmax-20):tmax])  \n', '\n', '\n', '#Regression from Max Values,200days\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,70]=  res[2]  #R2\n', '    stat[i,71]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmax\n', '\n', '\n', '#Regression from Min Values,200days \n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,72]=  res[2]  #R2\n', '    stat[i,73]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmin\n', '\n', '\n', '#Regression from Max Values,100days\n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,74]=  res[2]  #R2\n', '    stat[i,75]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmax\n', '\n', '\n', '#Regression from Min Values,100days \n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,76]=  res[2]  #R2\n', '    stat[i,77]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmin\n', '\n', '\n', '\n', '# Upside Trend with Higher Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '   vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '   vmax= util.sort(vmax,0,asc=0)\n', '   stat[i,80]=  -1\n', '   if len(vmax) > 1 :\n', '    ss=0\n', '    for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '    if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,80]=  ss  \n', '        stat[i,81]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Upside Trend with Higher High detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '    vmax= util.sort(vmax,0,asc=0)\n', '    stat[i,82]=  -1\n', '    if len(vmax) > 1 :\n', '      ss=0\n', '      for k in range(0,len(vmax)-1):\n', '        if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher high\n', '        else : break;\n', '      if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,82]=  ss  \n', '        stat[i,83]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Downside Trend with lower Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,84]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,84]=  ss  \n', '        stat[i,85]=  vmax[0,0] + t0\n', '\n', '\n', '# Downside Trend  with lower highs detection\n', ' t0= tmax-20*6\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,80]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,86]=  ss    #Nb  of lower high consecutive\n', '        stat[i,87]=  vmax[0,0] + t0\n', '\n', "" print('Higher/Lower Band Support')\n"", '#-----higher band Support / Lower Band Support 120days-------------------------------\n', ' t0= tmax-120\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,90]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,91]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,92]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '    # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1]) \n', '    # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 200days-------------------------------\n', ' t0= tmax-200\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,93]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,94]= 100.0 * stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,95]= 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 300days-------------------------------------\n', ' t0= tmax-300\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,96]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,97]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,98]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', ""  '''\n"", '  # -----higher band Support / Lower Band Support 60days-------------------------------\n', '  t0 = tmax - 60\n', '  for i in range(0, m):\n', '      try:\n', '          res1 = ta_highbandtrend1(close2[i, t0:tmax])\n', '          pmax = (res1.x[0] * (tmax - t0) + res1.x[1])\n', '          stat[i, 99] = 100.0 * stat[i, 45] / pmax  # Higher Band\n', '\n', '          res2 = ta_lowbandtrend1(close2[i, t0:tmax])\n', '          pmin = (res2.x[0] * (tmax - t0) + res2.x[1])\n', '          stat[i, 100] = 100.0 * stat[i, 45] / pmin  # LowerBand\n', '\n', '          stat[i, 101] = 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)  # Price inside Range\n', '\n', '          # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1])\n', '          # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '      except:\n', '          pass\n', ""  '''\n"", '\n', '  #-----Technical Indicator------------------------------------------------\n', '# for i in range(0,m): \n', '#  try :\n', '#   res2=0\n', '   # df= pd.read_hdf(dbfile, symfull[i])\n', '   # stat[i,110]= ta.RMI(close2[i,:])\n', '   # stat[i,111]= 100*close2[i,:] / ta.MA(close2[i,:],20)\n', '   # stat[i,112]= 100*close2[i,:] / ta.MA(close2[i,:],50)   \n', '#  except: pass\n', '\n', '\n', ' return np.array(stat, dtype=np.float16) \n', '\n', '\n', ""'''  \n"", 'i=1964  \n', 'stat= s1\n', 'stat[i, 91]  \n', '\n', 'tt= np.arange(t0, tmax)\n', 'plot_price(close2[i,t0:tmax], (res2.x[0] * (tt-t0) + res2.x[1]) )\n', ""'''\n"", '\n', '  \n', '#------------------- Stock Monitoring Tools ------------------------------------------------\n', ""def monitor_addrecommend(string1, dbname='stock_recommend') :\n"", ' ss= string1.replace(""("","" "").replace(\')\',\' \').replace(\':\',\' \')\n', "" ss= ss.replace('\\t', ' ').replace('\\n', ' ')\n"", ' sl1= ss.split("" "")\n', ' print sl1\n', ' aux= [datestring_toint(util.date_now())]\n', ' symfull= copy.deepcopy(a_us_all)\n', ' for x in sl1:\n', '   if len(x) < 5 :\n', '    if util.find(x,symfull) > 0 :   aux.append(x)\n', '\n', ' if len(aux) >  1 :\n', '  stock_recommend= util.load_obj(dbname)\n', '  stock_recommend.append(aux)\n', '  util.save_obj(stock_recommend,dbname)\n', '  print aux\n', ' return stock_recommend\n', '\n', '\n', '\n', '#################### Finviz  ###############################################################\n', 'from bs4 import BeautifulSoup\n', 'import csv,datetime, requests\n', 'def imp_finviz():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Overview Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=111&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(111) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 10].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 10\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockoverview.csv', 'wb') as csvfile:\n"", ""    overview = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    overview.writeheader()\n', '\n', '    for stock in alldata:\n', '        overview.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10] })\n', '\n', ' print ""Finviz Overview Completed""\n', ' return overview\n', ' \n', '\n', 'def imp_finviz_news():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Performance Start""\n', ' url = ""http://www.finviz.com/quote.ashx?t=intc""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', ' titleslist = soup.find_all(\'a\',{""class"" : ""tab-link-news""})\n', ' return titleslist\n', '\n', '\n', 'def imp_finviz_financials():\n', ' import datetime\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=161&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(161) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 17].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 16].text,stockdata[datalength - 15].text,stockdata[datalength - 14].text,stockdata[datalength - 13].text,stockdata[datalength - 12].text,stockdata[datalength - 11].text,stockdata[datalength - 10].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 17\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockfinancial.csv', 'wb') as csvfile:\n"", ""    financial = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    financial.writeheader()\n', '\n', '    for stock in alldata:\n', '        financial.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10],titlesarray[11] : stock[11],titlesarray[12] : stock[12],titlesarray[13] : stock[13],titlesarray[14] : stock[14],titlesarray[15] : stock[15],titlesarray[16] : stock[16],titlesarray[17] : stock[17] })\n', '\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Completed""\n', '\n', '\n', '\n', 'def get_price2book( symbol ):\n', '   from bs4 import BeautifulSoup as bs\n', '   import urllib as u\n', '   try:\n', ""    \turl = r'http://finviz.com/quote.ashx?t={}'.format(symbol.lower())\n"", '        html = u.request.urlopen(url).read()\n', ""        soup = bs(html, 'lxml')\n"", '        # Change the text below to get a diff metric\n', ""        pb =  soup.find(text = r'P/B')\n"", ""        pb_ = pb.find_next(class_='snapshot-td2').text\n"", ""        print( '{} price to book = {}'.format(symbol, pb_) )\n"", '        return pb_\n', '   except Exception as e:\n', '        print(e)\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ' try:\n', '   q = imp_googleQuote(name1, date1, date2)  #interval, timeframe\n', ""   name1= name1.replace(':','_')\n"", ""   file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(date2) +'.csv'\n"", '   q.write_csv(file1)\n', ' except: print\n', ""'''\n"", '\n', '\n', ""'''\n"", 'def imp_googleQuoteList(symbols, freqsec=300, nday=1, intraday1=True) :\n', ' qlist=[]; sym=[]\n', ' if intraday1:\n', '  for symbol in symbols:\n', '     #try :\n', '        q = imp_googleIntradayQuote(symbol, freqsec, nday)  #interval, timeframe\n', '        qlist.append(q)\n', '        sym.append(symbol)\n', ""     #except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       q = imp_googleQuote(name1, freqsec, num_days)  #interval, timeframe\n', '     except: print(symbol)\n', '\n', ' return qlist, sym\n', ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''        \n"", ""stock_list = ['XOM','AMZN','AAPL','SWKS']\n"", 'p2b_series = pd.Series( index=stock_list )\n', '\n', 'for sym in stock_list:\tp2b_series[sym] = get_price2book(sym)\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", "" # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", ' from dateutil.parser import parse\n', ' if os.path.getsize(file1)> 500 :\n', '  from_zone = tz.gettz(fromzone); tozone = tz.gettz(tozone)\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%m-%d-%Y %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', '  dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '\n', '  # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '  print file1\n', ""  #df = pd.read_csv(file1,sep=',',header=None, parse_dates={'date': [1]}, date_parser=dateparse)\n"", '\n', ""  df = pd.read_csv(file1,sep=',',header=0)\n"", '  #df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '  #df.date= [x.to_datetime() for x in  df.date]\n', '\n', '\n', '  df.drop(df.columns[[0]], axis=1, inplace=True)\n', ""  df= util.pd_addcol(df, 'symbol')\n"", ""  df['symbol']= dfname\n"", '\n', '  print filenameh5\n', ""  df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", ""  df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", '\n', '  # store = pd.HDFStore(filenameh5);\n', '  # store.append(dfname, df);  store.close()\n', ""'''\n"", '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dropcol=[], type1='csv', hasheader=True, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", ' if os.path.getsize(file1)> 500 :\n', '   header= 0 if hasheader else None\n', ""   df = pd.read_csv(file1, sep=',',header=0)\n"", '\n', '   df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""   df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""   df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", '\n', ""   if type1=='csv' :\n"", ""     df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""     if i==1: close = qq[['Datetime']]  #new dataframe\n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', ""     close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""     close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', "" close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", "" close= close.sort('Datetime')\n"", "" close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", '\n', ' close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", 'class Quote(object):\n', ""  DATE_FMT = '%Y-%m-%d';  TIME_FMT = '%H:%M:%S'\n"", '\n', '  def __init__(self):\n', ""    self.symbol = '';    self.exchn=''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', '\n', '  def append(self,dt,open_,high,low,close,volume):\n', '    self.date.append(dt.date())\n', '    self.time.append(dt.time())\n', '    self.open_.append(float(open_))\n', '    self.high.append(float(high))\n', '    self.low.append(float(low))\n', '    self.close.append(float(close))\n', '    self.volume.append(int(volume))\n', '\n', '  def to_csv(self):\n', '    return \'\'.join([""{0},{1},{2},{3:.2f},{4:.2f},{5:.2f},{6:.2f},{7}\\n"".format(self.symbol,\n', ""              self.date[bar].strftime('%Y-%m-%d'),self.time[bar].strftime('%H:%M:%S'),\n"", '              self.open_[bar],self.high[bar],self.low[bar],self.close[bar],self.volume[bar])\n', '              for bar in xrange(len(self.close))])\n', '\n', '  def write_csv(self,filename):\n', ""    with open(filename,'w') as f:\n"", '      txt= self.to_csv()\n', '      f.write(txt)\n', '\n', '  def read_csv(self,filename):\n', ""    self.symbol = ''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', ""    for line in open(filename,'r'):\n"", ""      symbol,ds,ts,open_,high,low,close,volume = line.rstrip().split(',')\n"", '      self.symbol = symbol\n', ""      dt = datetime.datetime.strptime(ds+' '+ts,self.DATE_FMT+' '+self.TIME_FMT)\n"", '      self.append(dt,open_,high,low,close,volume)\n', '    return True\n', '\n', '  def __repr__(self):\n', '    return self.to_csv()\n', ""'''\n"", '\n', ' \n', '\n', ""'''\n"", ""def imp_googleIntradayQuoteSave2(name1, date1, inter, tframe, dircsv='', dbname=''):\n"", ' q = imp_googleIntradayQuote(name1, inter, tframe)  #interval, timeframe\n', "" name1= name1.replace(':','_')\n"", '\n', "" if dircsv != '' :\n"", ""    file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", '    q.to_csv(file1)\n', '\n', "" if dbname != '' :\n"", '    import sqlalchemy as sql\n', '    dbcon= sql.create_engine(dbname)\n', '    if inter== 300 : # 5mins\n', ""      q.to_sql('q5min', dbcon)\n"", '\n', '\n', ""def imp_googleQuoteList_save(symbols, date1, date2, inter=23400, tframe=2000, dircsv='', intraday1=True) :\n"", ' if intraday1:\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleIntradayQuoteSave(symbol, date1, inter, tframe, dircsv)\n', ""     except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleQuoteSave(symbol, date1, date2, dircsv)\n', '     except: print(symbol)\n', ""'''\n"", '\n']","['np.shape', 'getret_fromquotes', 'len', 'getlogret_fromquotes', 'np.log', 'getprice_fromret']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:index,index,class,103,300,221,3009,10.03,1,3,[],[],[],1835,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc,folioCalc,class,125,509,332,4736,9.3,2,17,[],[],[],2134,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator,folioRiskIndicator,class,89,306,215,3180,10.39,1,9,[],[],[],2309,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF,folioOptimizationF,class,280,1291,671,10994,8.52,6,39,[],[],[],2487,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity,searchSimilarity,class,173,497,328,4550,9.15,8,17,[],[],[],3934,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1836,[],['date_generatedatetime'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:index:close,index:close,method,0,1,1,4,4.0,0,0,['self'],[None],[None],1841,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:index:updatehisto,index:updatehisto,method,2,12,11,62,5.17,0,0,['self)'],['  #Download Quotespassself) :'],[None],1844,[],['print'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:index:help,index:help,method,2,12,11,62,5.17,0,0,['self'],[None],[None],1848,[],['print'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]",['date_generatedatetime'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:index:calc_baskettable_pct,index:calc_baskettable_pct,method,37,95,77,782,8.23,1,2,"['self', 'type1', 'showdetail']","[None, None, None]","[None, '""table""', '0']",1913,"[""      '''   Calc Basket Values from Input data '''\n""]","['np.zeros', 'np.sum', 'self._udpate_wwindpct', 'range', 'np.mod', 'self._wwpct_rebal']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:index:_wwpct_rebal,index:_wwpct_rebal,method,3,4,3,41,10.25,0,0,"['self', 'wwpct_actual', 't', 'trebal)', '']","[None, None, None, '  # BskUnit', ']np.abs(wwpct_actual/wwpct_th  -1 )) > self.rebal_trigger:']","[None, None, None, ' 1.0  !!!wwpct_th = self.wwasset[trebal', None]",1940,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:index:_udpate_wwindpct,index:_udpate_wwindpct,method,11,25,17,224,8.96,0,0,"['self', 't', 'bskt', 'hedgecost', 'wwpct_actual', 'wwpct_th']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",1950,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:index:calc_baskettable_unit,index:calc_baskettable_unit,method,0,0,0,0,0.0,0,0,[],[],[],1959,"[""    '''   t           --->  t+1                 ---->   t+2\n"", '            wwactual:    B[t]    -->   B[t+1]   using  w[t+1], B[t] /   S[t]\n', '            wwnew   :    B[t+1]  -->   B[t+2]   using  w[t+2], B[t+1] /   S[t+1]\n', ""    '''\n""]",[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:__init__,folioCalc:__init__,method,21,39,37,356,9.13,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2135,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:set_symclose,folioCalc:set_symclose,method,17,34,33,312,9.18,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2148,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:setcriteria,folioCalc:setcriteria,method,41,76,71,1046,13.76,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2157,"[""        ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '            wwtype:     constant / regime /regimExtra\n', '            initperiod: NbOfDays_initial_Risk_Monitoring\n', '            riskid:     spprice/spperf/multi\n', ""        '''\n""]","['np.array', 'len']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:_weightcalc_generic,folioCalc:_weightcalc_generic,method,5,35,23,396,11.31,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2207,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:_weightcalc_regime,folioCalc:_weightcalc_regime,method,10,37,32,272,7.35,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2218,[],"['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:_regimecalc,folioCalc:_regimecalc,method,3,7,6,83,11.86,0,0,"['self', 't', 'wwextra)', 't - 1]self.riskind[0', 't - 1] / self.riskind[0', 't - 1 - self.nbrange] - 1if self.riskid == ""multi""']","[None, None, '  # Risk Indicatorif self.riskid ', None, None, '']","[None, None, '= ""spprice"":   return self.riskind[0', None, None, '= ""multi"":']",2228,[],['self._mapping_calc_risk'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:_weightcalc_constant,folioCalc:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2237,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:getweight,folioCalc:getweight,method,5,12,9,126,10.5,0,0,['self'],[None],[None],2241,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:calc_baskettable,folioCalc:calc_baskettable,method,33,111,83,811,7.31,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', '0.000', '0']",2248,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:plot,folioCalc:plot,method,10,29,26,295,10.17,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2276,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:multiperiod_ww,folioCalc:multiperiod_ww,method,15,36,29,240,6.67,1,1,"['self', 't']","[None, None]","[None, None]",2287,[],['xrange'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:help,folioCalc:help,method,1,2,2,13,6.5,0,0,['self'],[None],[None],2300,[],['print'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:__init__,folioRiskIndicator:__init__,method,23,40,38,356,8.9,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:set_symclose,folioRiskIndicator:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2324,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:setcriteria,folioRiskIndicator:setcriteria,method,34,81,70,1006,12.42,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2334,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'np.zeros']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:calcrisk,folioRiskIndicator:calcrisk,method,13,18,17,220,12.22,1,0,"['self', 'wwvec', 'initval']","[None, None, None]","[None, '[]', '1']",2382,[],"['xrange', 'self._weightcalc_generic', 'np.column_stack']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:_weightcalc_generic,folioRiskIndicator:_weightcalc_generic,method,4,34,24,327,9.62,0,3,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2394,[],"['self._weightcalc_regime', 'print']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:_weightcalc_regime,folioRiskIndicator:_weightcalc_regime,method,3,11,11,68,6.18,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2403,[],['self._regimecalc'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:_regimecalc,folioRiskIndicator:_regimecalc,method,7,18,17,216,12.0,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )self.riskind', 'wwextra', 't', 'self.riskind_out)self', 'maxiter', 'name1', 'isreset', 'popsize=15) ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, None, None, None, None, None, None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, None, None, None, None, '1', ""''"", '1', '15) :']",2408,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:calc_optimal_weight,folioRiskIndicator:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2414,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:__init__,folioOptimizationF:__init__,method,23,39,37,340,8.72,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:set_symclose,folioOptimizationF:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2324,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:setcriteria,folioOptimizationF:setcriteria,method,44,128,103,1669,13.04,0,2,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2334,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'print', 'list']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:calcbasket_obj2,folioOptimizationF:calcbasket_obj2,method,23,76,63,756,9.95,0,1,"['self', 'wwvec']","[None, None]","[None, None]",2572,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:calcbasket_obj,folioOptimizationF:calcbasket_obj,method,55,157,118,1494,9.52,1,4,"['self', 'wwvec']","[None, None]","[None, None]",2598,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float', 'calcbasket_obj', 'concenfactor=folio_concenfactor2', 'np.zeros', 'xrange', 'np.mod', 'self._weightcalc_generic', 'self._loss_obj', 'self._objective_criteria']",14
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_loss_obj,folioOptimizationF:_loss_obj,method,4,6,6,68,11.33,0,0,"['self', 'ww2', 'wwpenalty']","[None, None, None]","[None, None, None]",2623,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_weightcalc_generic,folioOptimizationF:_weightcalc_generic,method,5,40,26,394,9.85,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2394,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_weightcalc_regime,folioOptimizationF:_weightcalc_regime,method,8,32,28,239,7.47,0,0,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2403,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']","['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_regimecalc,folioOptimizationF:_regimecalc,method,4,7,7,83,11.86,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )if self.riskid== ""multi""   ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, '= ""multi""   :']",2408,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']",['self._mapping_calc_risk'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_weightcalc_constant,folioOptimizationF:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2662,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:calc_optimal_weight,folioOptimizationF:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2414,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:getweight,folioOptimizationF:getweight,method,6,11,9,126,11.45,0,0,['self'],[None],[None],2671,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:calc_baskettable,folioOptimizationF:calc_baskettable,method,36,86,72,827,9.62,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', ' 0.000', '0']",2679,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:plot,folioOptimizationF:plot,method,11,31,30,294,9.48,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2708,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_objective_criteria,folioOptimizationF:_objective_criteria,method,31,147,78,1105,7.52,2,7,"['self', 'bsk']","[None, None]","[None, None]",2720,[],"['np.std', 'np.sum', 'range', 'np.arange']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:multiperiod_ww,folioOptimizationF:multiperiod_ww,method,18,29,27,238,8.21,1,1,"['self', 't']","[None, None]","[None, None]",2767,[],['xrange'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:help,folioOptimizationF:help,method,50,152,103,1472,9.68,1,6,['self'],[None],[None],2779,[],"['print', 'util.load_obj', 'int', 'copy.deepcopy', 'xrange', 'next', 'util.save_obj', 'np.mod', 'np.abs', 'np.reshape', 'np.sum']",11
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:mapping_risk_ww,folioOptimizationF:mapping_risk_ww,method,12,56,29,245,4.38,0,1,"['self', 'risk', 'wwmat', 'ww2']","[None, None, None, None]","[None, None, None, 'self.wwasset0']",2838,[],"['np.sum', 'np.array']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_mapping_calc_risk,folioOptimizationF:_mapping_calc_risk,method,27,201,76,831,4.13,0,3,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",2850,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:__init__,searchSimilarity:__init__,method,15,18,17,193,10.72,0,0,"['self', ""filejpstock=r'E"", 'sym01', 'symname', 'startdate', 'enddate', 'pricetype']","[None, '', None, None, None, None, None]","[None, ""r'E:/_data/stock/daily/20160616/jp'"", ""['7203']"", ""['Toyota']"", ' 20150101', '20160601', '""close""']",3935,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:load_quotes_fromdb,searchSimilarity:load_quotes_fromdb,method,15,35,33,355,10.14,0,1,"['self', 'picklefile']","[None, None]","[None, ""''""]",3940,[],"['util.load_obj', 'imp_txt_getquotes', 'date_align', 'util.a_cleanmemory']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:__generate_return__,searchSimilarity:__generate_return__,method,4,4,4,64,16.0,0,0,"['self', 'nlag']","[None, None]","[None, None]",3951,[],['getret_fromquotes'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:__overweight__,searchSimilarity:__overweight__,method,17,62,41,412,6.65,2,4,"['self', 'px']","[None, None]","[None, None]",3955,[],"['len', 'np.ones', 'util.np_findlocalmax', 'type', 'np.abs', 'wwerr[max', 'util.np_findlocalmin']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:set_searchcriteria,searchSimilarity:set_searchcriteria,method,34,79,63,793,10.04,0,5,"['self', 'name1', 'date1', 'date2', 'nlag', 'searchperiodstart', 'typesearch', '']","[None, None, None, None, None, None, None, None]","[None, ""'7203'"", '20160301', '20160601', '1', '20120101', '""pattern2""', None]",3975,[],"['getret_fromquotes', 'date_finddateid', 'max', 'util.np_findfirst', 'print', 'price_normalize_1d', 'len', 'self.__overweight__']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:launch_search,searchSimilarity:launch_search,method,53,107,81,908,8.49,3,3,['self'],[None],[None],4004,[],"['len', 'np.zeros', 'range', 'price_normalize_1d', 'np_similarity', 'util.np_sortbycolumn', 'enumerate']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:show_comparison_graph,searchSimilarity:show_comparison_graph,method,33,72,63,682,9.47,1,3,"['self', 'maxresult', 'show_only_different_time', 'fromid', 'fromend', 'filenameout']","[None, None, None, None, None, None]","[None, '20', 'True', '0', ' 0', ""''""]",4038,[],"['np.shape', 'range', 'int', 'print', 'price_normalize_1d', 'str', 'plot_price']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:staticmethod,searchSimilarity:staticmethod,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",4067,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:get_rankresult,searchSimilarity:get_rankresult,method,24,63,53,496,7.87,2,1,"['self', 'filetosave']","[None, None]","[None, ""''""]",4071,[],"['len', 'np.savetxt', 'np.shape', 'np.array', 'np.empty', 'range', 'int', 'str']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:export_results,searchSimilarity:export_results,method,0,0,0,0,0.0,0,0,[],[],[],4093,"[""'''\n"", '#####################################################################################\n', '#---------Run over all the indexes, with time lag -----------------------------------\n', 'def np_similarity(x,y, wwerr=[], type1=0):\n', '  if type1==2 : return np_distance_l1(x,y, wwerr)\n', '  if type1==1: return sci.spatial.distance.correlation(x, y)  \n', '  if type1==0 : return 1-np.corrcoef(x,y)[0,1]\n', '\n', 'def np_distance_l1(x,y, wwerr) :\n', ' return np.sum(wwerr * np.abs(x-y))  \n', '  \n', '#---------------------  Universe Load         ---------------------------------------\n', ""filejpstock= r'E:/_data/stock/daily/20160616/jp'\n"", 'sym01= nk400list\n', '\n', 'quotes= imp_txt_getquotes(sym01, filejpstock, startdate=20090101, endate=20160616)\n', 'open1, dateref= date_align(quotes, type1=""close"")    #Get the data and align dates\n', 'del quotes; util.a_cleanmemory()\n', '\n', ""#util.save_obj(open1, 'close_nk400_2009_2016')\n"", ""#util.save_obj(dateref, 'dateref_nk400_2009_2016')\n"", '\n', ""open1= util.load_obj('close_nk400_2009_2016')\n"", ""dateref= util.load_obj( 'dateref_nk400_2009_2016')\n"", '\n', 'nlag=1\n', 'ret_open1 =  getdailyret_fromquotes(open1,nlag)\n', 'del open1\n', '\n', '#--------------------  Search Asset Input     ---------------------------------------\n', ""name1= '7203' \n"", 'date1= 20160328\n', 'date2= 20160531\n', 'twindow= util.np_findfirst(date2, dateref) - util.np_findfirst(date1, dateref) \n', '\n', '\n', 'tstartx= util.np_findfirst(date1, dateref)          # Date Index\n', 'stockx= util.np_findfirst(name1, sym01)\n', 'retx= ret_open1[stockx, tstartx:(tstartx+twindow-1)]    # Recent Period\n', 'px= price_normalize_1d(retx)\n', 'nx= len(px)\n', '\n', '\n', '#----OverWeight for Local Min, Local Max         -----------------------------------\n', 'wwerr= np.ones(nx, dtype=np.float16)\n', 'vvmax= util.np_findlocalmax(px); xprev=0\n', 'for x in vvmax:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', 'vvmin= util.np_findlocalmin(px); xprev=0\n', 'for x in vvmin:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', '\n', '#--------------------  Search the Pattern       -------------------------------------\n', 'tmaxx= len(dateref)-1\n', 'similar_list= np.zeros((nstock*(tmaxx-twindow)+1, 3), np.float16)\n', 'i=0\n', 'for iy in range(0, nstock) :\n', ' for t in range(0, tmaxx-twindow):\n', '   if iy == stockx and t > tstartx : \n', '     pass\n', '   else :\n', '    rety= ret_open1[iy, t:(t+twindow-1)]\n', '    py=   price_normalize_1d(rety)\n', '    ss= np_similarity(px, py, wwerr=wwerr, type1=2)\n', '    i+=1\n', '    similar_list[i,0]= iy\n', '    similar_list[i,1]= t\n', '    similar_list[i,2]= ss\n', '\n', '\n', ' #-------------------Clean the table -------------------------------------------------\n', 'rank= util.np_sortbycolumn(similar_list,2, asc=True)\n', 'for i,x in enumerate(rank) :\n', '  if rank[i,2]==0.0 : rank[i,2]= 1000         # Empty cell\n', '  if rank[i,1]> tstartx-3 : rank[i,2]= 100    # Start Element\n', 'rank= util.np_sortbycolumn(rank,2, asc=True)  \n', '\n', '\n', ' #----- Show Similar Stocks ---------------------------------------------------------\n', 'show_only_different_time= True\n', '\n', 'for i in range(0,10) :\n', ' tstarti= rank[i,1]\n', ' stocki= int(rank[i,0])\n', ' \n', ' if show_only_different_time and tstarti < tstartx-1  :\n', '   py= price_normalize100(ret_open1[stocki, tstarti:(tstarti+twindow-1)]) \n', '\n', '   namei= sym01[stocki]\n', '   namefulli= nk400name[util.np_findfirst(namei, nk400list)]\n', '\n', '   tit= namei+ "" "" +namefulli+ "" "" + str(dateref[tstarti])          \n', ""   plot_price(px-100, py-100, label=('Similar '+tit, 'Time','% Var') )\n"", '\n', '\n', 'kix= util.np_findfirst(name1, statsjp[:,0, ilag])\n', 'stocklist01[390]\n', '\n', '\n', 'stocklist01[157] , nk400name[157] ,  dateref1adj[86]     \n', 'plot_price(price_normalize100(ret_open1[157, 86:86+twindow-1])-100,px-100   )\n', ""'''    \n""]",[],0
utilmy/zarchive/py2to3/report.py:map_show,map_show,function,0,1,1,4,4.0,0,0,[],[],[],36,[],[],0
utilmy/zarchive/py2to3/report.py:xl_create_pivot,xl_create_pivot,function,4,9,9,134,14.89,0,0,"['infile', 'index_list', '""Rep""', '""Product""]', 'value_list', '""Quantity""]']","[None, None, None, None, None, None]","[None, '[""Manager""', None, None, '[""Price""', None]",65,"[""   ''' Read in the Excel file, create a pivot table and return it as a DataFrame '''\n""]",[],0
utilmy/zarchive/py2to3/report.py:xl_save_report,xl_save_report,function,6,10,10,167,16.7,1,0,"['report', 'outfile']","[None, None]","[None, None]",72,"[""   '''  Take a report and save it to a single Excel file\n"", '       sales_report = create_pivot(args.infile.name)\n', '       save_report(sales_report, args.outfile.name)\n', ""   '''\n""]","['temp_df.to_excel', 'writer.save']",2
utilmy/zarchive/py2to3/report.py:xl_create_pdf,xl_create_pdf,function,23,44,39,743,16.89,1,0,[],[],[],97,[],"['sales_report=create_pivot', 'manager_df.append', 'sales_report.xs', 'env=Environment', 'get_summary_stats', 'sales_report.to_html', 'HTML']",7
utilmy/zarchive/py2to3/rstatpy.py:stl,stl,function,32,165,104,1260,7.64,0,11,"['data', 'ns', 'np', 'nt', 'nl', 'isdeg', 'itdeg', 'ildeg', 'nsjump', 'ntjump', 'nljump', 'ni', 'no', 'fulloutput']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', '0', '1', '1', 'None', 'None', 'None', '2', '0', 'False']",9,"['    """"""\n', '    Seasonal-Trend decomposition procedure based on LOESS\n', '    data : pandas.Series\n', '    ns : int\n', '        Length of the seasonal smoother.\n', '        The value of  ns should be an odd integer greater than or equal to 3.\n', '        A value ns>6 is recommended. As ns  increases  the  values  of  the\n', '        seasonal component at a given point in the seasonal cycle (e.g., January\n', '        values of a monthly series with  a  yearly cycle) become smoother.\n', '    np : int\n', '        Period of the seasonal component.\n', '        For example, if  the  time series is monthly with a yearly cycle, then\n', '        np=12.\n', '        If no value is given, then the period will be determined from the\n', '        ``data`` timeseries.\n', '    nt : int\n', '        Length of the trend smoother.\n', '        The  value  of  nt should be an odd integer greater than or equal to 3.\n', '        A value of nt between 1.5*np and 2*np is  recommended. As nt increases,\n', '        the values of the trend component become  smoother.\n', '        If nt is None, it is estimated as the smallest odd integer greater\n', '        or equal to ``(1.5*np)/[1-(1.5/ns)]``\n', '    nl : int\n', '        Length of the low-pass filter.\n', '        The value of nl should  be an odd integer greater than or equal to 3.\n', '        The smallest odd integer greater than or equal to np is used by default.\n', '    isdeg : int\n', '        Degree of locally-fitted polynomial in seasonal smoothing.\n', '        The value is 0 or 1.\n', '    itdeg : int\n', '        Degree of locally-fitted polynomial in trend smoothing.\n', '        The value is 0 or 1.\n', '    ildeg : int\n', '        Degree of locally-fitted polynomial in low-pass smoothing.\n', '        The value is 0 or 1.\n', '    nsjump : int\n', '        Skipping value for seasonal smoothing.\n', '        The seasonal smoother skips ahead nsjump points and then linearly\n', '        interpolates in between.  The value  of nsjump should be a positive\n', '        integer; if nsjump=1, a seasonal smooth is calculated at all n points.\n', '        To make the procedure run faster, a reasonable choice for nsjump is\n', '        10%-20% of ns. By default, nsjump= 0.1*ns.\n', '    ntjump : int\n', '        Skipping value for trend smoothing. If None, ntjump= 0.1*nt\n', '    nljump : int\n', '        Skipping value for low-pass smoothing. If None, nljump= 0.1*nl\n', '    ni :int\n', '        Number of loops for updating the seasonal and trend  components.\n', '        The value of ni should be a positive integer.\n', '        See the next argument for advice on the  choice of ni.\n', '        If ni is None, ni is set to 2 for robust fitting, to 5 otherwise.\n', '    no : int\n', '        Number of iterations of robust fitting. The value of no should\n', '        be a nonnegative integer. If the data are well behaved without\n', '        outliers, then robustness iterations are not needed. In this case\n', '        set no=0, and set ni=2 to 5 depending on how much security\n', '        you want that  the seasonal-trend looping converges.\n', '        If outliers are present then no=3 is a very secure value unless\n', '        the outliers are radical, in which case no=5 or even 10 might\n', '        be better.  If no>0 then set ni to 1 or 2.\n', '        If None, then no is set to 15 for robust fitting, to 0 otherwise.\n', '    fulloutput : bool\n', '        If True, a dictionary holding the full output of the original R routine\n', '        will be returned.\n', '    returns\n', '    data : pandas.DataFrame\n', '        The seasonal, trend, and remainder components\n', '    """"""\n']","['data.copy', '_data.dropna', 'pandas.DateRange', 'pandas.Series', 'ceil', 'robjects.IntVector', 'ts_', 'stl_', 'asarray', 'pandas.DataFrame']",10
utilmy/zarchive/py2to3/utilgeo.py:df_to_geojson,df_to_geojson,function,10,24,21,329,13.71,2,0,"['df', 'col_properties', 'lat', 'lon']","[None, None, None, None]","[None, None, ""'latitude'"", ""'longitude'""]",24,[],['df.iterrows'],1
utilmy/zarchive/py2to3/util_min.py:os_wait_cpu,os_wait_cpu,function,12,31,27,286,9.23,1,0,"['priority', 'cpu_min']","[None, None]","['300', '50']",23,[],"['psutil.cpu_percent', 'print', 'arrow.utcnow', 'sleep']",4
utilmy/zarchive/py2to3/util_min.py:isexist,isexist,function,3,11,10,58,5.27,0,0,['a'],[None],[None],48,[],['print'],1
utilmy/zarchive/py2to3/util_min.py:isfloat,isfloat,function,5,15,13,67,4.47,0,1,['x'],[None],[None],54,[],['float'],1
utilmy/zarchive/py2to3/util_min.py:isint,isint,function,6,14,13,80,5.71,0,1,"['x)', '( int', 'np.int8', 'np.int16', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, None, None, '']","[None, None, None, None, None, None, None]",61,[],['txt.find'],1
utilmy/zarchive/py2to3/util_min.py:a_isanaconda,a_isanaconda,function,6,14,13,80,5.71,0,1,[],[],[],63,[],['txt.find'],1
utilmy/zarchive/py2to3/util_min.py:os_zip_checkintegrity,os_zip_checkintegrity,function,9,33,31,185,5.61,0,1,['filezip1'],[None],[None],72,[],"['zipfile.ZipFile', 'zip_file.testzip', 'print']",3
utilmy/zarchive/py2to3/util_min.py:os_zipfile,os_zipfile,function,23,43,37,397,9.23,2,2,"['folderin', 'folderzipname', 'iscompress']","[None, None, None]","[None, None, 'True']",83,[],"['zipfile.ZipFile', 'os.walk', 'zf.write', 'zf.close', 'os_zip_checkintegrity', 'print']",6
utilmy/zarchive/py2to3/util_min.py:os_zipfolder,os_zipfolder,function,15,35,29,346,9.89,0,3,"['dir_tozip', 'zipname', 'dir_prefix', 'iscompress']","[None, None, None, None]","[""'/zdisks3/output'"", ""'/zdisk3/output.zip'"", 'None', 'True']",99,"["" '''\n"", "" shutil.make_archive('/zdisks3/results/output', 'zip',\n"", ""                     root_dir=/zdisks3/results/',\n"", ""                     base_dir='output')\n"", '\n', "" os_zipfolder('zdisk/test/aapackage', 'zdisk/test/aapackage.zip', 'zdisk/test')'''\n""]","['dir_tozip.split', 'shutil.make_archive', 'os_zip_checkintegrity', 'print']",4
utilmy/zarchive/py2to3/util_min.py:os_zipextractall,os_zipextractall,function,23,59,48,538,9.12,1,3,"['filezip_or_dir', 'tofolderextract', 'isprint']","[None, None, None]","['""folder1/*.zip""', ""'zdisk/test'"", '1']",148,"[""   '''os_zipextractall( 'aapackage.zip','zdisk/test/'      )  '''\n""]","['filezip_or_dir.find', 'os_file_listall', 'os_file_getname', 'zipfile.ZipFile', 'zip_ref.extractall', 'zip_ref.close', 'print']",7
utilmy/zarchive/py2to3/util_min.py:os_folder_copy,os_folder_copy,function,17,36,35,345,9.58,0,1,"['src', 'dst', 'symlinks', 'pattern1', 'fun_file_toignore']","[None, None, None, None, None]","[None, None, 'False', '""*.py""', 'None']",178,"[""   '''\n"", '       callable(src, names) -> ignored_names\n', ""       'src' parameter, which is the directory being visited by copytree(), and\n"", ""       'names' which is the list of `src` contents, as returned by os.listdir():\n"", '\n', '    Since copytree() is called recursively, the callable will be called once for each directory that is copied.\n', '    It returns a  list of names relative to the `src` directory that should not be copied.\n', ""   '''\n""]","['fun_file_toignore', 'fnmatch.filter', 'shutil.copytree', 'shutil.copy']",4
utilmy/zarchive/py2to3/util_min.py:os_folder_create,os_folder_create,function,4,7,7,85,12.14,0,1,['directory'],[None],[None],200,[],"['os.getcwd', 'os.makedirs', 'os.chdir']",3
utilmy/zarchive/py2to3/util_min.py:os_folder_robocopy,os_folder_robocopy,function,3,15,15,166,11.07,0,1,"['from_folder', 'to_folder', ""my_log='H""]","[None, None, '']","[""''"", ""''"", ""'H:/robocopy_log.txt'""]",205,"['    """"""\n', '    Copy files to working directory\n', '    robocopy <Source> <Destination> [<File>[ ...]] [<Options>]\n', '    We want to copy the files to a fast SSD drive\n', '    """"""\n']",['print'],1
utilmy/zarchive/py2to3/util_min.py:os_file_replacestring1,os_file_replacestring1,function,11,25,24,238,9.52,1,0,"['findStr', 'repStr', 'filePath']","[None, None, None]","[None, None, None]",216,[],"['fileinput.FileInput', 'line.replace', 'file1.close', 'print']",4
utilmy/zarchive/py2to3/util_min.py:os_file_replacestring2,os_file_replacestring2,function,6,14,13,161,11.5,1,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",227,"['  \'\'\' #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",    pattern=""*.html"", dirlevel=5  )\n', ""  '''\n""]","['os_file_listall', 'os_file_replacestring1']",2
utilmy/zarchive/py2to3/util_min.py:os_file_getname,os_file_getname,function,8,9,8,75,8.33,0,0,['path'],[None],[None],234,[],"['ntpath.split', 'ntpath.basename']",2
utilmy/zarchive/py2to3/util_min.py:os_file_getpath,os_file_getpath,function,7,7,7,52,7.43,0,0,['path'],[None],[None],239,[],['ntpath.split'],1
utilmy/zarchive/py2to3/util_min.py:os_file_gettext,os_file_gettext,function,4,7,7,56,8.0,0,0,['file1'],[None],[None],244,[],"['open', 'f.read']",2
utilmy/zarchive/py2to3/util_min.py:os_file_listall,os_file_listall,function,28,79,46,902,11.42,4,3,"['dir1', 'pattern', 'dirlevel', 'onlyfolder']","[None, None, None, None]","[None, '""*.*""', '1', '0']",250,"[""  '''\n"", '   # DIRCWD=r""D:\\_devs\\Python01\\project""\n', '   # aa= listallfile(DIRCWD, ""*.*"", 2)\n', '   # aa[0][30];   aa[2][30]\n', '\n', '   :param dir1:\n', '   :param pattern:\n', '   :param dirlevel:\n', '   :param onlyfolder:\n', '   :return:\n', ""  '''\n""]","['dir1.rstrip', 'dir1.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 'np.array']",7
utilmy/zarchive/py2to3/util_min.py:os_file_rename,os_file_rename,function,32,56,48,642,11.46,2,1,"['some_dir', 'pattern', 'pattern2', 'dirlevel']","[None, None, None, None]","[None, '""*.*""', '""""', '1']",287,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 're.sub', 'os.rename', 'np.array']",9
utilmy/zarchive/py2to3/util_min.py:os_print_tofile,os_print_tofile,function,1,2,2,7,3.5,0,0,"['vv', 'file1', ""mode1='a')"", 'mode1) as text_file']","[None, None, '', '  text_file.write(str(vv))) :']","[None, None, ""'a'):  # print into a file='afile1"", None]",309,"[""    '''\n"", '    Here is a list of the different modes of opening a file:\n', 'r\n', 'Opens a file for reading only. The file pointer is placed at the beginning of the file. This is the default mode.\n', '\n', 'rb\n', '\n', 'Opens a file for reading only in binary format. The file pointer is placed at the beginning of the file. This is the default mode.\n', 'r+\n', '\n', 'Opens a file for both reading and writing. The file pointer will be at the beginning of the file.\n', 'rb+\n', '\n', 'Opens a file for both reading and writing in binary format. The file pointer will be at the beginning of the file.\n', 'w\n', '\n', 'Opens a file for writing only. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'wb\n', '\n', 'Opens a file for writing only in binary format. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'w+\n', '\n', 'Opens a file for both writing and reading. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'wb+\n', '\n', 'Opens a file for both writing and reading in binary format. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'a\n', '\n', 'Opens a file for appending. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'ab\n', '\n', 'Opens a file for appending in binary format. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'a+\n', '\n', 'Opens a file for both appending and reading. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'ab+\n', '\n', 'Opens a file for both appending and reading in binary format. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'To open a text file, use:\n', 'fh = open(""hello.txt"", ""r"")\n', '\n', 'To read a text file, use:\n', 'print fh.read()\n', '\n', 'To read one line at a time, use:\n', 'print fh.readline()\n', '\n', 'To read a list of lines use:\n', 'print fh.readlines()\n', '\n', 'To write to a file, use:\n', 'fh = open(""hello.txt"", ""w"")\n', 'lines_of_text = [""a line of text"", ""another line of text"", ""a third line""]\n', 'fh.writelines(lines_of_text)\n', 'fh.close()\n', '\n', 'To append to file, use:\n', 'fh = open(""Hello.txt"", ""a"")\n', 'fh.close()\n', '\n', ""    '''\n""]",[],0
utilmy/zarchive/py2to3/util_min.py:a_get_pythonversion,a_get_pythonversion,function,1,2,2,7,3.5,0,0,[],[],[],374,[],[],0
utilmy/zarchive/py2to3/util_min.py:os_path_norm,os_path_norm,function,8,20,18,174,8.7,0,1,['pth)'],[' #Normalize path for Python directory)'],['=2:'],377,"['    \'\'\' #r""D:\\_devs\\Python01\\project\\03-Connect_Java_CPP_Excel\\PyBindGen\\examples"" \'\'\'\n']","['pth.find', 'b.lstrip']",2
utilmy/zarchive/py2to3/util_min.py:os_path_change,os_path_change,function,4,4,4,34,8.5,0,0,['path1)'],[' path1'],[' os_path_norm(path1); os.chdir(path1)    #Change Working directory path): return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],389,[],"['open', 'fh.read']",2
utilmy/zarchive/py2to3/util_min.py:os_path_current,os_path_current,function,4,4,4,34,8.5,0,0,[')'],[' return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],391,[],"['open', 'fh.read']",2
utilmy/zarchive/py2to3/util_min.py:os_file_exist,os_file_exist,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],393,[],"['open', 'fh.read']",2
utilmy/zarchive/py2to3/util_min.py:os_file_size,os_file_size,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.getsize(file1)file1):'],[None],395,[],"['open', 'fh.read']",2
utilmy/zarchive/py2to3/util_min.py:os_file_read,os_file_read,function,4,4,4,34,8.5,0,0,['file1'],[None],[None],397,[],"['open', 'fh.read']",2
utilmy/zarchive/py2to3/util_min.py:os_file_mergeall,os_file_mergeall,function,10,20,20,185,9.25,1,0,"['nfile', 'dir1', 'pattern1', 'deepness']","[None, None, None, None]","[None, None, None, '2']",401,[],"['os_file_listall', 'open', 'os_file_gettext', 'nfile1.write', 'nfile1.close']",5
utilmy/zarchive/py2to3/util_min.py:os_path_append,os_path_append,function,4,19,11,121,6.37,0,3,"['p1', 'p2', 'p3', 'p4']","[None, None, None, None]","[None, 'None', 'None', 'None']",412,[],[],0
utilmy/zarchive/py2to3/util_min.py:os_split_dir_file,os_split_dir_file,function,6,15,15,112,7.47,0,1,['dirfile'],[None],[None],421,[],"['dirfile.split', 'len']",2
utilmy/zarchive/py2to3/util_min.py:py_importfromfile,py_importfromfile,function,12,21,19,251,11.95,0,1,"['modulename', 'dir1']","[None, None]","[None, None]",430,[],"['a_get_pythonversion', 'SourceFileLoader', 'foo.MyClass', 'imp.load_source']",4
utilmy/zarchive/py2to3/util_min.py:py_memorysize,py_memorysize,function,16,56,38,320,5.71,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",442,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'o.iteritems']",7
utilmy/zarchive/py2to3/util_min.py:save,save,function,2,4,4,64,16.0,0,0,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",470,[],['py_save_obj'],1
utilmy/zarchive/py2to3/util_min.py:load,load,function,2,3,3,60,20.0,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",473,[],['py_load_obj'],1
utilmy/zarchive/py2to3/util_min.py:save_test,save_test,function,6,11,11,124,11.27,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",476,[],"['py_load_obj', 'print', 'str', 'gc.collect']",4
utilmy/zarchive/py2to3/util_min.py:py_save_obj,py_save_obj,function,17,36,35,308,8.56,0,1,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",482,[],"['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.dump']",5
utilmy/zarchive/py2to3/util_min.py:py_load_obj,py_load_obj,function,16,30,28,265,8.83,0,1,"['folder', 'isabsolutpath', 'encoding1']","[None, None, None]","[""'/folder1/keyname'"", '0', ""'utf-8'""]",495,"[""    '''def load_obj(name, encoding1='utf-8' ):\n"", ""         with open('D:/_devs/Python01/aaserialize/' + name + '.pkl', 'rb') as f:\n"", '            return pickle.load(f, encoding=encoding1)\n', ""    '''\n""]","['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.load']",5
utilmy/zarchive/py2to3/util_min.py:z_key_splitinto_dir_name,z_key_splitinto_dir_name,function,6,15,15,112,7.47,0,1,['keyname'],[None],[None],511,[],"['keyname.split', 'len']",2
utilmy/zarchive/py2to3/util_ml.py:create_weight_variable,create_weight_variable,function,5,7,6,129,18.43,0,0,"['name', 'shape']","[None, None]","[None, None]",11,[],['tf.Variable'],1
utilmy/zarchive/py2to3/util_ml.py:create_bias_variable,create_bias_variable,function,4,6,6,112,18.67,0,0,"['name', 'shape']","[None, None]","[None, None]",17,[],"['tf.constant_initializer', 'tf.Variable']",2
utilmy/zarchive/py2to3/util_ml.py:create_adam_optimizer,create_adam_optimizer,function,2,3,3,70,23.33,0,0,"['learning_rate', 'momentum']","[None, None]","[None, None]",22,[],[],0
utilmy/zarchive/py2to3/util_ml.py:tf_check,tf_check,function,32,91,51,915,10.05,0,0,[],[],[],28,[],"['print', 'tf.constant', 'tf.matmul', 'tf.Session', 'sess.run']",5
utilmy/zarchive/py2to3/util_ml.py:parse_args,parse_args,function,11,26,24,196,7.54,1,1,"['ppa', 'args']","[None, None]","['None', ' {}']",59,[],"['argparse.ArgumentParser', 'args.items', 'ppa.add_argument', 'type=type', 'ppa.parse_args', 'parse_args2']",6
utilmy/zarchive/py2to3/util_ml.py:parse_args2,parse_args2,function,5,133,98,1435,10.79,0,1,['ppa'],[None],['None'],70,[],"['argparse.ArgumentParser', 'e:print', 'ppa.add_argument']",3
utilmy/zarchive/py2to3/util_ml.py:tf_global_variables_initializer,tf_global_variables_initializer,function,27,65,46,866,13.32,3,1,['sess'],[None],['None'],108,"['    """"""Initializes all uninitialized variables in correct order. Initializers\n', ""    are only run for uninitialized variables, so it's safe to run this multiple times.\n"", '    Args:   sess: session to use. Use default session if None.\n', '    """"""\n']","['make_initializer', 'f', 'tf.assign', 'make_noop', 'tf.no_op', 'make_safe_initializer', 'tf.cond', 'tf.get_default_session', 'tf.get_default_graph', 'tf.global_variables', 'g.get_operation_by_name', 'sess.run']",12
utilmy/zarchive/py2to3/util_ml.py:visualize_result,visualize_result,function,21,142,111,1132,7.97,2,0,[],[],[],218,[],"['range', 'enumerate', 'pd.read_csv', 'plt.plot', 'train_loss.tolist', 'plt.legend', 'plt.xlabel', 'plt.ylabel', 'plt.show']",9
utilmy/zarchive/py2to3/util_ml.py:TextLoader,TextLoader,class,65,159,120,2143,13.48,0,1,[],[],[],151,[],[],0
utilmy/zarchive/py2to3/util_ml.py:TextLoader:__init__,TextLoader:__init__,method,15,34,31,491,14.44,0,1,"['self', 'data_dir', 'batch_size', 'seq_length']","[None, None, None, None]","[None, None, None, None]",152,[],"['print', 'self.preprocess', 'self.load_preprocessed', 'self.create_batches', 'self.reset_batch_pointer']",5
utilmy/zarchive/py2to3/util_ml.py:TextLoader:preprocess,TextLoader:preprocess,method,17,34,31,404,11.88,0,0,"['self', 'input_file', 'vocab_file', 'tensor_file']","[None, None, None, None]","[None, None, None, None]",170,[],"['codecs.open', 'f.read', 'collections.Counter', 'sorted', 'list', 'len', 'dict', 'range', 'open', 'pickle.dump', 'np.array', 'np.save']",12
utilmy/zarchive/py2to3/util_ml.py:TextLoader:load_preprocessed,TextLoader:load_preprocessed,method,10,19,19,245,12.89,0,0,"['self', 'vocab_file', 'tensor_file']","[None, None, None]","[None, None, None]",183,[],"['open', 'pickle.load', 'len', 'dict', 'range', 'np.load']",6
utilmy/zarchive/py2to3/util_ml.py:TextLoader:create_batches,TextLoader:create_batches,method,20,40,33,665,16.62,0,0,['self'],[None],[None],191,[],"['np.copy', 'np.split', 'int', 'zip']",4
utilmy/zarchive/py2to3/util_ml.py:TextLoader:next_batch,TextLoader:next_batch,method,6,10,8,87,8.7,0,0,['self'],[None],[None],207,[],[],0
utilmy/zarchive/py2to3/util_ml.py:TextLoader:reset_batch_pointer,TextLoader:reset_batch_pointer,method,1,2,2,14,7.0,0,0,['self'],[None],[None],212,[],[],0
utilmy/zarchive/py2to3/_HELP.py:os_compileVSsolution,os_compileVSsolution,function,6,32,21,239,7.47,0,4,"['dir1', 'flags1', 'type1', 'compilerdir']","[None, None, None, None]","[None, '""""', '""devenv""', '""""']",744,[],['os.system'],1
utilmy/zarchive/py2to3/_HELP.py:os_VS_build,os_VS_build,function,16,62,54,614,9.9,1,2,"['self', 'lib_to_build']","[None, None]","[None, None]",773,[],"['print', 'subprocess.Popen', 'process.poll', 'process.communicate']",4
utilmy/zarchive/py2to3/_HELP.py:set_rc_version,set_rc_version,function,12,37,34,502,13.57,0,0,"['rcfile', 'target_version']","[None, None]","[None, None]",810,[],"['open', 'f.seek', 'f.write', 'f.truncate']",4
utilmy/zarchive/py2to3/_HELP.py:os_VS_start,os_VS_start,function,18,56,52,881,15.73,0,2,"['self', 'version']","[None, None]","[None, None]",847,[],"['os.getenv', 'Exception', 'default.append', 'libs.append']",4
utilmy/zarchive/py2to3/_HELP.py:fun_cython,fun_cython,function,5,10,9,34,3.4,1,0,['a'],[None],[None],890,[],['xrange'],1
utilmy/zarchive/py2to3/_HELP.py:fun_python,fun_python,function,5,10,9,34,3.4,1,0,['a'],[None],[None],897,[],['xrange'],1
utilmy/zarchive/py2to3/_HELP.py:LookupTable,LookupTable,class,4,7,7,94,13.43,0,0,[],[],[],207,[],[],0
utilmy/zarchive/py3/util.py:session_save,session_save,function,39,72,64,1007,13.99,0,2,"['filename', 'globals1']","[None, None]","['""/folder1/name1""', 'None']",260,"[""    '''Need to pass globals() Cannot Get Save data to .spydata file\n"", '\n', '   BIG issue with Import, Impor FULL MODULE ----> BIG ISSUE\n', '     BIG ISSUE with DICT, USE LIST INSTEAD\n', '        If you try to put this code in a module and import the function then you will have to pass globals() to the function explicitly as the globals() in the function is not the IPython global namespace. However, you can put the above code inside your ~/.ipython/profile_PROFILE/startup/startup.ipy file and it will work as expected.\n', '       PROFILE is the name of the profile that you plan to start IPython with.\n', ""    '''\n""]","['print', 'spyutil.globalsfilter', 'filters=tuple', 'filename.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'iofunc.save_dictionary', 'os.chdir']",8
utilmy/zarchive/py3/util.py:aa_unicode_ascii_utf8_issue,aa_unicode_ascii_utf8_issue,function,0,0,0,0,0.0,0,0,[],[],[],338,"[""   '''Take All csv in a folder and provide Table, Column Schema, type\n"", '\n', ' METHOD FOR Unicode / ASCII issue\n', '1. Decode early\n', ""Decode to <type 'unicode'> ASAP\n"", ""df['PREF_NAME']=       df['PREF_NAME'].apply(to_unicode)\n"", '\n', '2. Unicode everywhere\n', '\n', '\n', '3. Encode late\n', "">>> f = open('/tmp/ivan_out.txt','w')\n"", "">>> f.write(ivan_uni.encode('utf-8'))\n"", '\n', 'Important methods\n', ""s.decode(encoding)  <type 'str'> to <type 'unicode'>\n"", ""u.encode(encoding)  <type 'unicode'> to <type 'str'>\n"", '\n', 'http://farmdev.com/talks/unicode/\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/py3/util.py:isexist,isexist,function,3,9,8,46,5.11,0,0,['a'],[None],[None],362,[],[],0
utilmy/zarchive/py3/util.py:isfloat,isfloat,function,5,16,14,67,4.19,0,1,['x'],[None],[None],368,[],['float'],1
utilmy/zarchive/py3/util.py:isint,isint,function,6,15,14,80,5.33,0,1,"['x)', '( int', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, '']","[None, None, None, None, None]",375,[],['txt.find'],1
utilmy/zarchive/py3/util.py:a_isanaconda,a_isanaconda,function,6,15,14,80,5.33,0,1,[],[],[],377,[],['txt.find'],1
utilmy/zarchive/py3/util.py:a_run_ipython,a_run_ipython,function,1,1,1,33,33.0,0,0,['cmd1'],[None],[None],387,"["" ''' Execute Ipython Command in python code\n"", '     run -i :  run including current interprete variable\n', "" '''\n""]",['IPython.get_ipython'],1
utilmy/zarchive/py3/util.py:a_autoreload,a_autoreload,function,1,4,4,64,16.0,0,0,[],[],[],393,[],['a_run_ipython'],1
utilmy/zarchive/py3/util.py:a_get_platform,a_get_platform,function,1,2,2,13,6.5,0,0,[],[],[],396,[],[],0
utilmy/zarchive/py3/util.py:a_start_log,a_start_log,function,1,14,12,98,7.0,0,0,"['id1', 'folder']","[None, None]","[""''"", ""'aaserialize/log/'""]",400,[],"['a_run_ipython', 'str', 'a_get_platform', 'date_now']",4
utilmy/zarchive/py3/util.py:a_cleanmemory,a_cleanmemory,function,3,3,3,21,7.0,0,0,[],[],[],403,[],['gc.collect'],1
utilmy/zarchive/py3/util.py:a_module_codesample,a_module_codesample,function,6,9,9,130,14.44,0,0,['module_str'],[None],"[""'pandas'""]",406,[],"['os_file_read', 'os_gui_popup_show']",2
utilmy/zarchive/py3/util.py:a_module_doc,a_module_doc,function,6,9,9,123,13.67,0,0,['module_str'],[None],"[""'pandas'""]",412,[],"['os_file_read', 'os_gui_popup_show']",2
utilmy/zarchive/py3/util.py:a_module_generatedoc,a_module_generatedoc,function,9,16,16,179,11.19,0,1,"['module_str', 'fileout']","[None, None]","['""pandas""', ""''""]",418,"['  \'\'\' #  getmodule_doc(""jedi"", r""D:\\_devs\\Python01\\aapackage\\doc.txt"")\'\'\'\n']","['os.makedirs', 'ca.getmodule_doc']",2
utilmy/zarchive/py3/util.py:a_info_conda_jupyter,a_info_conda_jupyter,function,61,131,110,1065,8.13,1,3,[],[],[],426,[],"['printProgress', 'shutil.make_archive', 'os_zipfolder', 'dir_tozip.split', 'os_zip_checkintegrity', 'print']",6
utilmy/zarchive/py3/util.py:os_zipextractall,os_zipextractall,function,23,59,48,538,9.12,1,3,"['filezip_or_dir', 'tofolderextract', 'isprint']","[None, None, None]","['""folder1/*.zip""', ""'zdisk/test'"", '1']",697,"[""   '''os_zipextractall( 'aapackage.zip','zdisk/test/'      )  '''\n""]","['filezip_or_dir.find', 'os_file_listall', 'os_file_getname', 'zipfile.ZipFile', 'zip_ref.extractall', 'zip_ref.close', 'print']",7
utilmy/zarchive/py3/util.py:os_folder_copy,os_folder_copy,function,17,35,34,340,9.71,0,1,"['src', 'dst', 'symlinks', 'pattern1', 'fun_file_toignore']","[None, None, None, None, None]","[None, None, 'False', '""*.py""', 'None']",727,"[""   '''\n"", '       callable(src, names) -> ignored_names\n', ""       'src' parameter, which is the directory being visited by copytree(), and\n"", ""       'names' which is the list of `src` contents, as returned by os.listdir():\n"", '\n', '    Since copytree() is called recursively, the callable will be called once for each directory that is copied.\n', '    It returns a  list of names relative to the `src` directory that should not be copied.\n', '   :param fun_ignore:\n', ""   '''\n""]","['fun_file_toignore', 'fnmatch.filter', 'shutil.copytree', 'shutil.copy']",4
utilmy/zarchive/py3/util.py:os_folder_create,os_folder_create,function,4,7,7,85,12.14,0,1,['directory'],[None],[None],750,[],"['os.getcwd', 'os.makedirs', 'os.chdir']",3
utilmy/zarchive/py3/util.py:os_folder_robocopy,os_folder_robocopy,function,3,14,14,157,11.21,0,1,"['from_folder', 'to_folder', ""my_log='H""]","[None, None, '']","[""''"", ""''"", ""'H:/robocopy_log.txt'""]",755,"['    """"""\n', '    Copy files to working directory\n', '    robocopy <Source> <Destination> [<File>[ ...]] [<Options>]\n', '    We want to copy the files to a fast SSD drive\n', '    """"""\n']","['subprocess.call', 'print']",2
utilmy/zarchive/py3/util.py:os_file_replacestring1,os_file_replacestring1,function,11,26,25,238,9.15,1,0,"['findStr', 'repStr', 'filePath']","[None, None, None]","[None, None, None]",766,[],"['fileinput.FileInput', 'line.replace', 'file1.close', 'print']",4
utilmy/zarchive/py3/util.py:os_file_replacestring2,os_file_replacestring2,function,6,14,13,160,11.43,1,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",777,"['  \'\'\' #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",    pattern=""*.html"", dirlevel=5  )\n', ""  '''\n""]","['listallfile', 'fil_replacestring_onefile']",2
utilmy/zarchive/py3/util.py:os_file_getname,os_file_getname,function,8,9,8,75,8.33,0,0,['path'],[None],[None],784,[],"['ntpath.split', 'ntpath.basename']",2
utilmy/zarchive/py3/util.py:os_file_getpath,os_file_getpath,function,7,7,7,52,7.43,0,0,['path'],[None],[None],789,[],['ntpath.split'],1
utilmy/zarchive/py3/util.py:os_file_gettext,os_file_gettext,function,4,8,8,56,7.0,0,0,['file1'],[None],[None],794,[],"['open', 'f.read']",2
utilmy/zarchive/py3/util.py:os_file_listall,os_file_listall,function,28,82,46,904,11.02,4,3,"['dir1', 'pattern', 'dirlevel', 'onlyfolder']","[None, None, None, None]","[None, '""*.*""', '1', '0']",800,"[""  '''\n"", '   # DIRCWD=r""D:\\_devs\\Python01\\project""\n', '   # aa= listallfile(DIRCWD, ""*.*"", 2)\n', '   # aa[0][30];   aa[2][30]\n', '\n', '   :param dir1:\n', '   :param pattern:\n', '   :param dirlevel:\n', '   :param onlyfolder:\n', '   :return:\n', ""  '''\n""]","['dir1.rstrip', 'dir1.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 'np.array']",7
utilmy/zarchive/py3/util.py:os_file_rename,os_file_rename,function,32,60,48,643,10.72,2,1,"['some_dir', 'pattern', 'pattern2', 'dirlevel']","[None, None, None, None]","[None, '""*.*""', '""""', '1']",837,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 're.sub', 'os.rename', 'np.array']",9
utilmy/zarchive/py3/util.py:os_gui_popup_show,os_gui_popup_show,function,25,38,37,361,9.5,0,0,['txt'],[None],[None],858,[],"['os_gui_popup_show2', 'Tk', 'Scrollbar', 'Text', 'S.pack', 'T.pack', 'S.config', 'T.config', 'T.insert', 'root.attributes', 'mainloop']",11
utilmy/zarchive/py3/util.py:os_print_tofile,os_print_tofile,function,8,21,19,174,8.29,0,1,"['vv', 'file1', ""mode1='a')"", 'mode1) as text_file']","[None, None, '', '  text_file.write(str(vv))pth): #Normalize path for Python directory)']","[None, None, ""'a'):  # print into a file='afile1"", '=2:']",875,"[""    '''\n"", '    Here is a list of the different modes of opening a file:\n', 'r\n', 'Opens a file for reading only. The file pointer is placed at the beginning of the file. This is the default mode.\n', '\n', 'rb\n', '\n', 'Opens a file for reading only in binary format. The file pointer is placed at the beginning of the file. This is the default mode.\n', 'r+\n', '\n', 'Opens a file for both reading and writing. The file pointer will be at the beginning of the file.\n', 'rb+\n', '\n', 'Opens a file for both reading and writing in binary format. The file pointer will be at the beginning of the file.\n', 'w\n', '\n', 'Opens a file for writing only. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'wb\n', '\n', 'Opens a file for writing only in binary format. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'w+\n', '\n', 'Opens a file for both writing and reading. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'wb+\n', '\n', 'Opens a file for both writing and reading in binary format. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'a\n', '\n', 'Opens a file for appending. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'ab\n', '\n', 'Opens a file for appending in binary format. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'a+\n', '\n', 'Opens a file for both appending and reading. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'ab+\n', '\n', 'Opens a file for both appending and reading in binary format. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'To open a text file, use:\n', 'fh = open(""hello.txt"", ""r"")\n', '\n', 'To read a text file, use:\n', 'print fh.read()\n', '\n', 'To read one line at a time, use:\n', 'print fh.readline()\n', '\n', 'To read a list of lines use:\n', 'print fh.readlines()\n', '\n', 'To write to a file, use:\n', 'fh = open(""hello.txt"", ""w"")\n', 'lines_of_text = [""a line of text"", ""another line of text"", ""a third line""]\n', 'fh.writelines(lines_of_text)\n', 'fh.close()\n', '\n', 'To append to file, use:\n', 'fh = open(""Hello.txt"", ""a"")\n', 'fh.close()\n', '\n', ""    '''\n""]","['pth.find', 'b.lstrip']",2
utilmy/zarchive/py3/util.py:os_path_norm,os_path_norm,function,8,21,19,174,8.29,0,1,['pth)'],[' #Normalize path for Python directory)'],['=2:'],939,"['    \'\'\' #r""D:\\_devs\\Python01\\project\\03-Connect_Java_CPP_Excel\\PyBindGen\\examples"" \'\'\'\n']","['pth.find', 'b.lstrip']",2
utilmy/zarchive/py3/util.py:os_path_change,os_path_change,function,4,4,4,34,8.5,0,0,['path1)'],[' path1'],[' normpath(path1); os.chdir(path1)    #Change Working directory path): return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],951,[],"['open', 'fh.read']",2
utilmy/zarchive/py3/util.py:os_path_current,os_path_current,function,4,4,4,34,8.5,0,0,[')'],[' return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],953,[],"['open', 'fh.read']",2
utilmy/zarchive/py3/util.py:os_file_exist,os_file_exist,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],955,[],"['open', 'fh.read']",2
utilmy/zarchive/py3/util.py:os_file_size,os_file_size,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.getsize(file1)file1):'],[None],957,[],"['open', 'fh.read']",2
utilmy/zarchive/py3/util.py:os_file_read,os_file_read,function,4,4,4,34,8.5,0,0,['file1'],[None],[None],959,[],"['open', 'fh.read']",2
utilmy/zarchive/py3/util.py:os_file_mergeall,os_file_mergeall,function,10,20,20,182,9.1,1,0,"['nfile', 'dir1', 'pattern1', 'deepness']","[None, None, None, None]","[None, None, None, '2']",963,[],"['listallfile', 'open', 'gettext_fromfile', 'nfile1.write', 'nfile1.close']",5
utilmy/zarchive/py3/util.py:os_extracttext_allfile,os_extracttext_allfile,function,15,33,31,282,8.55,1,0,"['nfile', 'dir1', 'pattern1', 'htmltag', 'deepness']","[None, None, None, None, None]","[None, None, '""*.html""', ""'p'"", '2']",972,"["" ''' Extract text from html '''\n""]","['listallfile', 'open', 'gettext_fromfile', 'BeautifulSoup', 'soup.find_all', 'txt2.strip', 'newfile1.write', 'nfile1.close']",8
utilmy/zarchive/py3/util.py:os_path_append,os_path_append,function,4,19,11,121,6.37,0,3,"['p1', 'p2', 'p3', 'p4']","[None, None, None, None]","[None, 'None', 'None', 'None']",986,[],[],0
utilmy/zarchive/py3/util.py:os_split_dir_file,os_split_dir_file,function,6,15,15,112,7.47,0,1,['dirfile'],[None],[None],996,[],"['dirfile.split', 'len']",2
utilmy/zarchive/py3/util.py:os_process_run,os_process_run,function,13,31,31,317,10.23,0,1,"['cmd_list', ""'arg1'"", ""'arg2']"", 'capture_output']","[None, None, None, None]","[""['program'"", None, None, 'False']",1002,[],"['subprocess.Popen', 'proc.communicate', 'print', 'str']",4
utilmy/zarchive/py3/util.py:os_process_2,os_process_2,function,0,1,1,4,4.0,0,0,[],[],[],1018,[],[],0
utilmy/zarchive/py3/util.py:py_importfromfile,py_importfromfile,function,12,21,19,251,11.95,0,1,"['modulename', 'dir1']","[None, None]","[None, None]",1055,[],"['a_get_pythonversion', 'SourceFileLoader', 'foo.MyClass', 'imp.load_source']",4
utilmy/zarchive/py3/util.py:py_memorysize,py_memorysize,function,16,56,38,318,5.68,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",1067,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'list']",7
utilmy/zarchive/py3/util.py:save,save,function,2,4,4,64,16.0,0,0,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",1095,[],['py_save_obj'],1
utilmy/zarchive/py3/util.py:load,load,function,2,3,3,60,20.0,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",1098,[],['py_load_obj'],1
utilmy/zarchive/py3/util.py:save_test,save_test,function,6,11,11,124,11.27,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",1101,[],"['py_load_obj', 'print', 'str', 'gc.collect']",4
utilmy/zarchive/py3/util.py:py_save_obj,py_save_obj,function,17,36,35,308,8.56,0,1,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",1107,[],"['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.dump']",5
utilmy/zarchive/py3/util.py:py_load_obj,py_load_obj,function,16,30,28,265,8.83,0,1,"['folder', 'isabsolutpath', 'encoding1']","[None, None, None]","[""'/folder1/keyname'"", '0', ""'utf-8'""]",1120,"[""    '''def load_obj(name, encoding1='utf-8' ):\n"", ""         with open('D:/_devs/Python01/aaserialize/' + name + '.pkl', 'rb') as f:\n"", '            return pickle.load(f, encoding=encoding1)\n', ""    '''\n""]","['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.load']",5
utilmy/zarchive/py3/util.py:z_key_splitinto_dir_name,z_key_splitinto_dir_name,function,6,15,15,112,7.47,0,1,['keyname'],[None],[None],1136,[],"['keyname.split', 'len']",2
utilmy/zarchive/py3/util.py:sql_getdate,sql_getdate,function,0,1,1,4,4.0,0,0,[],[],[],1146,[],[],0
utilmy/zarchive/py3/util.py:obj_getclass_of_method,obj_getclass_of_method,function,7,15,13,114,7.6,1,1,['meth'],[None],[None],1218,[],['inspect.getmro'],1
utilmy/zarchive/py3/util.py:obj_getclass_property,obj_getclass_property,function,3,9,9,69,7.67,1,0,['pfi'],[None],[None],1226,[],"['list', 'print']",2
utilmy/zarchive/py3/util.py:print_topdf,print_topdf,function,27,114,95,913,8.01,0,0,[],[],[],1243,[],"['PdfPages', 'plt.figure', 'plt.plot', 'plt.title', 'pdf.savefig', 'plt.close', 'plt.rc', 'np.arange', 'np.sin', 'pdf.infodict', 'datetime.datetime']",11
utilmy/zarchive/py3/util.py:os_config_setfile,os_config_setfile,function,8,39,26,235,6.03,1,1,"['dict_params', 'outfile', 'mode1']","[None, None, None]","[None, None, ""'w+'""]",1290,[],"['open', 'list', 'isinstance', 'f1.write', 'str', 'f1.close', 'print']",7
utilmy/zarchive/py3/util.py:os_config_getfile,os_config_getfile,function,7,16,15,73,4.56,1,0,['file1'],[None],[None],1302,[],"['open', 'f1.readlines', 'print']",3
utilmy/zarchive/py3/util.py:os_csv_process,os_csv_process,function,1,2,2,9,4.5,0,0,['file1'],[None],[None],1310,[],['print'],1
utilmy/zarchive/py3/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1336,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/py3/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1336,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/py3/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1336,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/py3/util.py:find_fuzzy,find_fuzzy,function,4,12,11,49,4.08,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1504,"["" ''' if xstring matches partially, add to the list   '''\n""]",['xi.find'],1
utilmy/zarchive/py3/util.py:str_match_fuzzy,str_match_fuzzy,function,4,12,11,64,5.33,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1509,"["" ''' if any of list_strinf elt matches partially xstring '''\n""]",['xstring.find'],1
utilmy/zarchive/py3/util.py:str_parse_stringcalendar,str_parse_stringcalendar,function,14,39,29,278,7.13,3,1,['cal'],[None],[None],1516,"[""    '''----------Parse Calendar  --------'''\n""]","['cal.split', 'x.find', 'cal4.append', 'np.array', 'print']",5
utilmy/zarchive/py3/util.py:str_make_unicode,str_make_unicode,function,7,16,13,102,6.38,0,1,"['input', 'errors']","[None, None]","[None, ""'replace'""]",1530,[],"['type', 'input.decode']",2
utilmy/zarchive/py3/util.py:str_empty_string_array,str_empty_string_array,function,9,30,23,184,6.13,2,1,"['x', 'y']","[None, None]","[None, '1']",1536,[],"['range', 'str_empty_string_array_numpy', 'np.empty']",3
utilmy/zarchive/py3/util.py:str_empty_string_array_numpy,str_empty_string_array_numpy,function,4,9,8,56,6.22,0,0,"['nx', 'ny']","[None, None]","[None, '1']",1540,[],['np.empty'],1
utilmy/zarchive/py3/util.py:str_isfloat,str_isfloat,function,1,8,7,46,5.75,0,0,['value'],[None],[None],1545,[],['float'],1
utilmy/zarchive/py3/util.py:str_is_azchar,str_is_azchar,function,1,8,7,42,5.25,0,0,['x'],[None],[None],1549,[],['float'],1
utilmy/zarchive/py3/util.py:str_is_az09char,str_is_az09char,function,1,8,7,42,5.25,0,0,['x'],[None],[None],1553,[],['float'],1
utilmy/zarchive/py3/util.py:str_reindent,str_reindent,function,3,8,7,52,6.5,0,0,"['s', 'numSpaces)', ""'\\n')numSpaces * ' ') + string.lstrip(line) for line in s]s"", ""'\\n')return sdelimiters"", 'string', 'maxsplit=0)', 'delimiters))regexPattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, ' #change indentation of multine strings', None, None, None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, None, None, None, '0):  #Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1557,"[""    '''\n"", '   if args:\n', ""       aux= name1+'.'+obj.__name__ +'('+ str(args) +')  \\n' + str(inspect.getdoc(obj))\n"", ""       aux= aux.replace('\\n', '\\n       ')\n"", '       aux= aux.rstrip()\n', ""       aux= aux + ' \\n'\n"", '       wi( aux)\n', ""    '''\n""]",['x.decode'],1
utilmy/zarchive/py3/util.py:str_split2,str_split2,function,3,8,7,52,6.5,0,0,"['delimiters', 'string', 'maxsplit=0)', 'delimiters))regexPattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, '0):  #Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1571,[],['x.decode'],1
utilmy/zarchive/py3/util.py:str_split_pattern,str_split_pattern,function,3,8,7,52,6.5,0,0,"['sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1576,[],['x.decode'],1
utilmy/zarchive/py3/util.py:pd_str_isascii,pd_str_isascii,function,3,8,7,52,6.5,0,0,['x'],[None],[None],1584,[],['x.decode'],1
utilmy/zarchive/py3/util.py:str_to_utf8,str_to_utf8,function,2,2,2,23,11.5,0,0,['x'],[None],[None],1590,"['  """""" Do it before saving/output to external printer """"""\n']",['x.encode'],1
utilmy/zarchive/py3/util.py:str_to_unicode,str_to_unicode,function,3,14,11,85,6.07,0,2,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",1595,"[""  ''' Do it First after Loading some text '''\n""]","['isinstance', 'str']",2
utilmy/zarchive/py3/util.py:web_restapi_toresp,web_restapi_toresp,function,12,19,18,168,8.84,0,1,['apiurl1'],[None],[None],1696,[],"['requests.get', 'ApiError']",2
utilmy/zarchive/py3/util.py:web_getrawhtml,web_getrawhtml,function,13,20,20,176,8.8,0,1,['url1'],[None],[None],1703,[],"['requests.get', 'ApiError']",2
utilmy/zarchive/py3/util.py:web_importio_todataframe,web_importio_todataframe,function,41,78,61,641,8.22,4,4,"['apiurl1', 'isurl']","[None, None]","[None, '1']",1711,[],"['requests.get', 'ApiError', 'resp.json', 'list', 'colname.append', 'str', 'np.array', 'colmax=len', 'np.empty', 'pd_createdf', 'np.arange', 'len']",12
utilmy/zarchive/py3/util.py:web_getjson_fromurl,web_getjson_fromurl,function,10,12,11,138,11.5,0,0,['url'],[None],[None],1738,[],"['urllib3.connection_from_url', 'http.urlopen', 'print', 'json.loads']",4
utilmy/zarchive/py3/util.py:web_gettext_fromurl,web_gettext_fromurl,function,9,19,18,203,10.68,0,0,"['url', 'htmltag']","[None, None]","[None, ""'p'""]",1753,[],"['urllib3.connection_from_url', 'http.urlopen', 'BeautifulSoup', 'soup.find_all']",4
utilmy/zarchive/py3/util.py:web_gettext_fromhtml,web_gettext_fromhtml,function,8,21,20,176,8.38,0,0,"['file1', 'htmltag']","[None, None]","[None, ""'p'""]",1761,[],"['open', 'BeautifulSoup', 'soup.find_all']",3
utilmy/zarchive/py3/util.py:web_getlink_fromurl,web_getlink_fromurl,function,14,22,21,248,11.27,1,0,['url'],[None],[None],1820,[],"['urllib3.connection_from_url', 'http.urlopen', 'BeautifulSoup', 'soup.prettify', 'soup.findAll', 'links.append', 'set']",7
utilmy/zarchive/py3/util.py:web_send_email,web_send_email,function,33,127,78,1266,9.97,0,0,"['FROM', 'recipient', 'subject', 'body', 'login1', 'pss1', 'server1', 'port1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, '""mizenjapan@gmail.com""', '""sophieelise237""', '""smtp.gmail.com""', '465']",1832,"['    \'\'\'  # send_email(""Kevin"", ""brookm291@gmail.com"", ""JapaneseText:"" , ""txt"") \'\'\'\n']","['MIMEMultipart', 'msg.set_charset', 'MIMEText', 'msg.attach', 'smtplib.SMTP_SSL', 'server_ssl.ehlo', 'login', 'server_ssl.login', 'server_ssl.sendmail', 'msg.as_string', 'server_ssl.close', 'print', 'web_send_email_tls', 'smtplib.SMTP', 'mailserver.ehlo', 'mailserver.starttls', 'mailserver.login', 'mailserver.sendmail', 'mailserver.quit']",19
utilmy/zarchive/py3/util.py:web_send_email_tls,web_send_email_tls,function,25,56,51,568,10.14,0,0,"['FROM', 'recipient', 'subject', 'body', 'login1', 'pss1', 'server1', 'port1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, '""mizenjapan@gmail.com""', '""sophieelise237""', '""smtp.gmail.com""', '465']",1857,[],"['MIMEMultipart', 'msg.set_charset', 'MIMEText', 'msg.attach', 'smtplib.SMTP', 'mailserver.ehlo', 'mailserver.starttls', 'mailserver.login', 'mailserver.sendmail', 'msg.as_string', 'mailserver.quit', 'print']",12
utilmy/zarchive/py3/util.py:web_sendurl,web_sendurl,function,3,11,11,95,8.64,0,0,['url1'],[None],[None],1893,[],"['web_gettext_fromurl', 'send_email']",2
utilmy/zarchive/py3/util.py:np_minimize,np_minimize,function,12,39,35,358,9.18,1,0,"['fun_obj', 'x0', 'argext', '0']","[None, None, None, None]","[None, '[0.0]', '(0', None]",1901,[],"['penalty', 'enumerate', 'max', 'loss', 'fun_obj', 'np_minimizeDE']",6
utilmy/zarchive/py3/util.py:np_minimizeDE,np_minimizeDE,function,16,51,41,422,8.27,1,2,"['fun_obj', 'bounds', 'name1', 'solver']","[None, None, None, None]","[None, None, None, 'None']",1914,[],"['range', 'next', 'print', 'save_obj', 'name1+date_now', 'np.mod', 'np.abs']",7
utilmy/zarchive/py3/util.py:np_remove_NA_INF_2d,np_remove_NA_INF_2d,function,9,22,19,116,5.27,2,1,['X'],[None],[None],1931,[],"['np.shape', 'range', 'np.isnan', 'np.isinf']",4
utilmy/zarchive/py3/util.py:np_addcolumn,np_addcolumn,function,8,11,11,86,7.82,0,0,"['arr', 'nbcol']","[None, None]","[None, None]",1938,[],"['np.shape', 'np.zeros', 'np.column_stack']",3
utilmy/zarchive/py3/util.py:np_addrow,np_addrow,function,9,20,19,139,6.95,0,1,"['arr', 'nbrow']","[None, None]","[None, None]",1944,[],"['np.shape', 'len', 'np.zeros', 'np.row_stack', 'np.append']",5
utilmy/zarchive/py3/util.py:np_int_tostr,np_int_tostr,function,3,17,12,69,4.06,0,1,['i'],[None],[None],1953,[],['str'],1
utilmy/zarchive/py3/util.py:np_dictordered_create,np_dictordered_create,function,5,6,6,52,8.67,0,0,[],[],[],1959,[],['OrderedDict'],1
utilmy/zarchive/py3/util.py:np_list_unique,np_list_unique,function,5,8,8,46,5.75,0,0,['seq'],[None],[None],1963,[],"['Set', 'list']",2
utilmy/zarchive/py3/util.py:np_list_tofreqdict,np_list_tofreqdict,function,10,39,23,162,4.15,2,1,"['l1', 'wweight']","[None, None]","[None, '[]']",1969,[],"['dict', 'len', 'enumerate']",3
utilmy/zarchive/py3/util.py:np_list_flatten,np_list_flatten,function,11,25,19,114,4.56,2,1,['seq'],[None],[None],1986,[],"['type', 'flatten', 'l.append']",3
utilmy/zarchive/py3/util.py:np_dict_tolist,np_dict_tolist,function,5,22,15,100,4.55,2,1,"['dd', 'withkey']","[None, None]","[None, '0']",1997,[],['list'],1
utilmy/zarchive/py3/util.py:np_dict_tostr_val,np_dict_tostr_val,function,1,9,9,52,5.78,0,0,['dd'],[None],[None],2003,[],"['str', 'list']",2
utilmy/zarchive/py3/util.py:np_dict_tostr_key,np_dict_tostr_key,function,1,8,8,52,6.5,0,0,['dd'],[None],[None],2006,[],"['str', 'list']",2
utilmy/zarchive/py3/util.py:np_removelist,np_removelist,function,6,15,15,71,4.73,1,1,"['x0', 'xremove']","[None, None]","[None, '[]']",2011,[],"['np_findfirst', 'xnew.append']",2
utilmy/zarchive/py3/util.py:np_transform2d_int_1d,np_transform2d_int_1d,function,19,31,28,227,7.32,2,0,"['m2d', 'onlyhalf']","[None, None]","[None, 'False']",2017,[],"['np.shape', 'np.zeros', 'range', 'np.abs', 'np_sortbycol']",5
utilmy/zarchive/py3/util.py:np_mergelist,np_mergelist,function,5,10,10,55,5.5,1,0,"['x0', 'x1']","[None, None]","[None, None]",2029,[],"['list', 'xnew.append']",2
utilmy/zarchive/py3/util.py:np_enumerate2,np_enumerate2,function,6,14,14,83,5.93,1,0,['vec_1d'],[None],[None],2035,[],"['np.empty', 'enumerate']",2
utilmy/zarchive/py3/util.py:np_pivottable_count,np_pivottable_count,function,12,24,23,170,7.08,1,0,['mylist'],[None],[None],2041,[],"['np_dict_tolist', 'sorted', 'int']",3
utilmy/zarchive/py3/util.py:np_nan_helper,np_nan_helper,function,2,5,5,40,8.0,0,0,['y'],[None],[None],2049,"['    """""" Input:  - y, 1d numpy array with possible NaNs\n', '        Output - nans, logical indices of NaNs - index, a function, with signature indices= index(logical_indices),\n', ""              to convert logical indices of NaNs to 'equivalent' indices\n"", '    """"""\n']","['np.isnan', 'z.nonzero']",2
utilmy/zarchive/py3/util.py:np_interpolate_nan,np_interpolate_nan,function,7,9,9,76,8.44,0,0,['y'],[None],[None],2056,[],"['np_nan_helper', 'np.interp', 'x']",3
utilmy/zarchive/py3/util.py:np_and1,np_and1,function,8,55,22,356,6.47,0,6,"['x', 'y', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']","[None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None', 'None', 'None']",2061,[],[],0
utilmy/zarchive/py3/util.py:np_sortcol,np_sortcol,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2069,"[' """""" df.sort([\'A\', \'B\'], ascending=[1, 0])  """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/py3/util.py:np_sort,np_sort,function,7,19,12,184,9.68,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2075,[],"['pd.DataFrame', 'df.sort_values', 'np_sort']",3
utilmy/zarchive/py3/util.py:np_ma,np_ma,function,2,3,3,54,18.0,0,0,"['vv', 'n']","[None, None]","[None, None]",2081,"[""  '''Moving average '''\n""]","['np.convolve', 'old_div']",2
utilmy/zarchive/py3/util.py:np_cleanmatrix,np_cleanmatrix,function,11,22,20,124,5.64,2,1,['m'],[None],[None],2087,[],"['np.nan_to_num', 'np.shape', 'range', 'abs']",4
utilmy/zarchive/py3/util.py:np_torecarray,np_torecarray,function,2,6,6,105,17.5,0,0,"['arr', 'colname']","[None, None]","[None, None]",2095,[],['np.shape'],1
utilmy/zarchive/py3/util.py:np_sortbycolumn,np_sortbycolumn,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",2098,[],"['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/py3/util.py:np_sortbycol,np_sortbycol,function,8,28,19,251,8.96,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",2103,[],"['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/py3/util.py:min_kpos,min_kpos,function,2,3,3,36,12.0,0,0,"['arr', 'kth']","[None, None]","[None, None]",2114,"[""   ''' return kth mininimun '''\n""]",['np.partition'],1
utilmy/zarchive/py3/util.py:max_kpos,max_kpos,function,3,5,5,53,10.6,0,0,"['arr', 'kth']","[None, None]","[None, None]",2118,"[""   ''' return kth mininimun '''\n""]","['len', 'np.partition']",2
utilmy/zarchive/py3/util.py:np_findfirst,np_findfirst,function,5,11,10,54,4.91,1,1,"['item', 'vec']","[None, None]","[None, None]",2125,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/py3/util.py:np_find,np_find,function,5,11,10,54,4.91,1,1,"['item', 'vec']","[None, None]","[None, None]",2132,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/py3/util.py:find,find,function,4,12,11,49,4.08,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",2139,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xi.find'],1
utilmy/zarchive/py3/util.py:findnone,findnone,function,4,11,10,54,4.91,1,1,['vec'],[None],[None],2145,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/py3/util.py:findx,findx,function,6,27,18,119,4.41,0,2,"['item', 'vec']","[None, None]","[None, None]",2151,"['    """"""return the index of the first occurence of item in vec""""""\n']","['type', 'vec.index', 'len']",3
utilmy/zarchive/py3/util.py:finds,finds,function,12,34,23,155,4.56,2,3,"['itemlist', 'vec']","[None, None]","[None, None]",2162,"['  """"""return the index of the first occurence of item in vec""""""\n']","['range', 'idlist.append']",2
utilmy/zarchive/py3/util.py:findhigher,findhigher,function,5,13,12,50,3.85,1,1,"['x', 'vec']","[None, None]","[None, None]",2173,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/py3/util.py:findlower,findlower,function,5,12,11,50,4.17,1,1,"['x', 'vec']","[None, None]","[None, None]",2179,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/py3/util.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],2187,[],['min'],1
utilmy/zarchive/py3/util.py:np_find_maxpos,np_find_maxpos,function,17,44,33,260,5.91,1,3,['values'],[None],[None],2191,[],"['max', 'np_find_maxpos_2nd', 'float', 'enumerate']",4
utilmy/zarchive/py3/util.py:np_find_maxpos_2nd,np_find_maxpos_2nd,function,13,36,27,132,3.67,1,3,['numbers'],[None],[None],2195,[],"['float', 'enumerate']",2
utilmy/zarchive/py3/util.py:np_findlocalmax2,np_findlocalmax2,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",2207,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/py3/util.py:np_findlocalmin2,np_findlocalmin2,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",2241,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/py3/util.py:np_findlocalmax,np_findlocalmax,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",2275,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/py3/util.py:np_findlocalmin,np_findlocalmin,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",2289,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/py3/util.py:np_stack,np_stack,function,12,53,25,323,6.09,0,7,"['v1', 'v2', 'v3', 'v4', 'v5']","[None, None, None, None, None]","[None, 'None', 'None', 'None', 'None']",2305,[],"['np.shape', 'np.row_stack', 'np.column_stack']",3
utilmy/zarchive/py3/util.py:np_uniquerows,np_uniquerows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],2320,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/py3/util.py:np_remove_zeros,np_remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",2325,[],[],0
utilmy/zarchive/py3/util.py:np_sort,np_sort,function,7,19,12,184,9.68,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2328,"[""'''\n"", 'from sqlalchemy import create_engine\n', 'engine = create_engine(""postgresql://u:p@host/database"")\n', ""'''\n""]","['pd.DataFrame', 'df.sort_values', 'np_sort']",3
utilmy/zarchive/py3/util.py:np_memory_array_adress,np_memory_array_adress,function,2,2,2,38,19.0,0,0,['x'],[None],[None],2331,[],[],0
utilmy/zarchive/py3/util.py:sql_create_dbengine,sql_create_dbengine,function,4,45,26,358,7.96,0,1,"['type1', 'dbname', 'login', 'password', 'url', 'port']","[None, None, None, None, None, None]","[""''"", ""''"", ""''"", ""''"", ""'localhost'"", '5432']",2345,"[""   ''' Return SQL Alchemy Connector\n"", '\n', ""sql_create_dbengine(type1='mysql',  dbname='', login='', password='', url='localhost', port=5432)\n"", '\n', '# psycopg2\n', ""engine = create_engine('postgresql+psycopg2://scott:tiger@localhost/mydatabase')\n"", '\n', '\n', '# MySQL-connector-python  Official one\n', ""engine = create_engine('mysql+mysqlconnector://scott:tiger@localhost/foo')\n"", 'conda install -c anaconda mysql-connector-python=2.0.4\n', ""engine = create_engine('postgresql://%s:%s@localhost:5432/%s' %(myusername, mypassword, mydatabase))\n"", '\n', ""engine = create_engine('sqlite:///  folder/foo.db')\n"", '\n', ""   '''\n""]","['sql.create_engine', 'str']",2
utilmy/zarchive/py3/util.py:sql_query,sql_query,function,6,22,18,155,7.05,0,2,"['sqlr', 'dbengine', 'output', ""dburl='sqlite""]","[None, None, None, '']","[""'SELECT ticker,shortratio,sector1_id, FROM stockfundamental'"", 'None', ""'df'"", ""'sqlite:///aaserialize/store/finviz.db'""]",2377,"["" '''\n"", "" :param sqlr:       'SELECT ticker,shortratio,sector1_id, FROM stockfundamental'\n"", ' :param output:     df   /   file1.csv\n', "" :param dburl:      'sqlite:///aaserialize/store/finviz.db'\n"", "" :param dbengine:   dbengine = sql.create_engine('postgresql+psycopg2://postgres:postgres@localhost/coke')\n"", ' :return:\n', "" '''\n""]","['sql.create_engine', 'pd.read_sql_query', 'output.find', 'df.to_csv']",4
utilmy/zarchive/py3/util.py:sql_get_dbschema,sql_get_dbschema,function,16,37,32,316,8.54,2,2,"[""dburl='sqlite"", 'dbengine', 'isprint']","['', None, None]","[""'sqlite:///aapackage/store/yahoo.db'"", 'None', '0']",2391,[],"['sql.create_engine', 'sql.inspect', 'inspector.get_table_names', 'inspector.get_columns', 'l1.append', 'print', 'np.array']",7
utilmy/zarchive/py3/util.py:sql_delete_table,sql_delete_table,function,1,8,8,89,11.12,0,0,"['name', 'dbengine']","[None, None]","[None, None]",2404,[],[],0
utilmy/zarchive/py3/util.py:sql_insert_excel,sql_insert_excel,function,50,131,97,992,7.57,5,2,"['file1', 'dbengine', 'dbtype']","[None, None, None]","[""'.xls'"", 'None', ""''""]",2411,"["" ''' http://flask-excel.readthedocs.io/en/latest/\n"", ' https://pythonhosted.org/pyexcel/tutorial_data_conversion.html#import-excel-sheet-into-a-database-table\n', ' from sqlalchemy import create_engine\n', 'from sqlalchemy.ext.declarative import declarative_base\n', 'from sqlalchemy import Column , Integer, String, Float, Date\n', 'from sqlalchemy.orm import sessionmaker\n', 'engine = create_engine(""sqlite:///birth.db"")\n', 'Base = declarative_base()\n', 'Session = sessionmaker(bind=engine)\n', '\n', 'class BirthRegister(Base):\n', ""...     __tablename__='birth'\n"", '...     id=Column(Integer, primary_key=True)\n', '...     name=Column(String)\n', '...     weight=Column(Float)\n', '...     birth=Column(Date)\n', '\n', 'Base.metadata.create_all(engine)\n', '\n', 'https://www.digitalocean.com/community/tutorials/how-to-use-celery-with-rabbitmq-to-queue-tasks-on-an-ubuntu-vps\n', 'import os\n', 'import pyexcel\n', 'import datetime\n', '\n', 'from sqlalchemy import create_engine\n', 'from sqlalchemy.ext.declarative import declarative_base\n', 'from sqlalchemy import Column, Integer, String, Float, Date\n', 'from sqlalchemy.orm import sessionmaker\n', '\n', '\n', 'engine = create_engine(""sqlite:///birth.db"")\n', 'Base = declarative_base()\n', 'Session = sessionmaker(bind=engine)\n', '\n', '\n', '# here is the destination table\n', 'class BirthRegister(Base):\n', ""    __tablename__ = 'birth'\n"", '    id = Column(Integer, primary_key=True)\n', '    name = Column(String)\n', '    weight = Column(Float)\n', '    birth = Column(Date)\n', '\n', '\n', 'Base.metadata.create_all(engine)\n', '\n', '\n', '# create fixture\n', 'data = [\n', '    [""name"", ""weight"", ""birth""],\n', '    [""Adam"", 3.4, datetime.date(2015, 2, 3)],\n', '    [""Smith"", 4.2, datetime.date(2014, 11, 12)]\n', ']\n', 'pyexcel.save_as(array=data,\n', '                dest_file_name=""birth.xls"")\n', '\n', '# import the xls file\n', 'session = Session()  # obtain a sql session\n', 'pyexcel.save_as(file_name=""birth.xls"",\n', '                name_columns_by_row=0,\n', '                dest_session=session,\n', '                dest_table=BirthRegister)\n', '\n', '# verify results\n', 'sheet = pyexcel.get_sheet(session=session, table=BirthRegister)\n', 'print(sheet)\n', '\n', 'session.close()\n', ""os.unlink('birth.db')\n"", 'os.unlink(""birth.xls"")\n', '\n', ' This code uses the openpyxl package for playing around with excel using Python code\n', ' to convert complete excel workbook (all sheets) to an SQLite database\n', ' The code assumes that the first row of every sheet is the column name\n', ' Every sheet is stored in a separate table\n', ' The sheet name is assigned as the table name for every sheet\n', "" '''\n""]","['slugify', 'text.strip', 're.sub', 'load_workbook', 'wb.get_sheet_names', 'str', 'columns.append', 'dbengine.execute', 'enumerate', 'tuprow.append', 'tup.append', 'VALUES', 'dbengine.executemany', 'dbengine.commit', 'dbengine.close']",15
utilmy/zarchive/py3/util.py:sql_insert_df,sql_insert_df,function,22,60,52,481,8.02,1,2,"['df', 'dbtable', 'dbengine', 'col_drop', 'verbose']","[None, None, None, None, None]","[None, None, None, ""['id']"", '1']",2534,[],"['df.drop', 'df.to_dict', 'print', 'sql.Table', 'Session', 'dbengine.execute', 'session.commit', 'session.close']",8
utilmy/zarchive/py3/util.py:sql_insert_csv,sql_insert_csv,function,35,159,130,1358,8.54,3,3,"['csvfile', 'dbtable', 'dbengine', 'col_drop']","[None, None, None, None]","[None, None, None, '[]']",2564,[],"['datetime.now', 'pd.read_csv', 'df.rename', 'c.replace', 'df.drop', 'df.to_dict', 'sql.Table', 'Session', 'dbengine.execute', 'session.commit', 'session.close', 'print', 'sql_insert_csv2', 'os.listdir', 'i.endswith', 'i.startswith', 'df.to_sql']",17
utilmy/zarchive/py3/util.py:sql_insert_csv2,sql_insert_csv2,function,11,58,54,463,7.98,1,2,"['csvfile', 'dbtable', 'columns', 'dbengine', 'nrows']","[None, None, None, None, None]","[""''"", ""''"", '[]', 'None', ' 10000']",2636,"['    """"""\n', '    Upload data to a temporary table first using PANDAs to identify optimal data-types for columns\n', '    PANDAS is not speed-efficient as it uses INSERT commands rather than COPY e.g. it took COPY 16mins average\n', '    to get a 15GB CSV into the database (door-to-door) whereas pandas.to_sql took 50mins\n', '    """"""\n']","['os.listdir', 'i.endswith', 'i.startswith', 'print', 'pd.read_csv', 'df.to_sql']",6
utilmy/zarchive/py3/util.py:sql_postgres_create_table,sql_postgres_create_table,function,20,109,73,888,8.15,0,3,"['mytable', 'database', 'username', 'password']","[None, None, None, None]","[""''"", ""''"", ""''"", ""''""]",2669,"['    """""" Create table copying the structure of the temp table created using pandas  Timer to benchmark """"""\n']","['psycopg2.connect', 'con.cursor', 'print', 'sys.exit', 'cur.execute', 'open', 'cur.copy_expert', 'con.close']",8
utilmy/zarchive/py3/util.py:sql_postgres_pivot,sql_postgres_pivot,function,0,1,1,4,4.0,0,0,[],[],[],2755,"[""   '''\n"", 'Enabling the Crosstab Function\n', 'As we previously mentioned, the crosstab function is part of a PostgreSQL extension called tablefunc. To call the crosstab function,\n', 'you must first enable the tablefunc extension by executing the following SQL command:\n', 'CREATE extension tablefunc;\n', '\n', 'SELECT *\n', ""FROM crosstab( 'select student, subject, evaluation_result from evaluations order by 1,2')\n"", 'AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '\n', '##### Correct Even iF there are missing values :\n', 'http://www.vertabelo.com/blog/technical-articles/creating-pivot-tables-in-postgresql-using-the-crosstab-function\n', '\n', 'SELECT *\n', ""FROM crosstab( 'select student, subject, evaluation_result from evaluations\n"", ""                where extract (month from evaluation_day) = 7 order by 1,2',\n"", ""                'select name from subject order by 1')\n"", '     AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/py3/util.py:sql_mysql_insert_excel,sql_mysql_insert_excel,function,30,73,69,712,9.75,1,0,[],[],[],2781,[],"['xlrd.open_workbook', 'list.sheet_by_index', 'database.cursor', 'range', 'sheet.cell', 'cursor.execute', 'cursor.close', 'database.commit', 'database.close', 'print', 'str', 'rows=str']",12
utilmy/zarchive/py3/util.py:sql_pivotable,sql_pivotable,function,1,3,3,10,3.33,0,0,"['dbcon', 'ss']","[None, None]","[None, ""'select  '""]",2814,"[""  '''\n"", '\n', ' 1) get the category\n', '\n', ' 2) Build the Pivot From category\n', '  SELECT *\n', ""  FROM crosstab( 'select student, subject, evaluation_result from evaluations\n"", ""                where extract (month from evaluation_day) = 7 order by 1,2',\n"", ""                'select name from subject order by 1')\n"", '   AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '  https://www.amazon.com/PostgreSQL-High-Performance-Gregory-Smith/dp/184951030X/ref=as_li_ss_tl?s=books&ie=UTF8&qid=1458352081&sr=1-6&keywords=postgres&linkCode=sl1&tag=postgres-bottom-20&linkId=c981783121cbd5542dc2b44a2297df57\n', '\n', '\n', 'http://blog.brakmic.com/data-science-for-losers-part-2/\n', '\n', 'Here we instruct Pandas to merge two tables by using certain primary keys from both when combining their rows into a new table. The parameter how instructs Pandas to use the inner-join which means it will only combine such rows which belong to both of the tables. Therefore well not receive any NaN-rows. But in some cases this could be desirable. Then use the alternative options like left, right or outer.\n', '\n', 'Pivots with Tables from SQLAlchemy\n', '\n', 'And of course its possible to generate the same pivot tables with data that came from SQLAlchemy.\n', 'Theyre nothing else but DataFrames all the way down. OK, not absolutely all the way down,\n', 'because there are also Series and NumPy arrays etc.,\n', 'but this is a little bit too much of knowledge for Losers like us. Maybe in some later articles.\n', '\n', '\n', ' :return:\n', ""  '''\n""]",[],0
utilmy/zarchive/py3/util.py:np_pivotable_create,np_pivotable_create,function,28,99,61,699,7.06,4,5,"['table', 'left', 'top', 'value']","[None, None, None, None]","[None, None, None, None]",2847,"['    """"""\n', '    Creates a cross-tab or pivot table from a normalised input table. Use this\n', ""    function to 'denormalize' a table of normalized records.\n"", '\n', '    * The table argument can be a list of dictionaries or a Table object.\n', '    (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/334621)\n', '    * The left argument is a tuple of headings which are displayed down the\n', '    left side of the new table.\n', '    * The top argument is a tuple of headings which are displayed across the\n', '    top of the new table.\n', '    Tuples are used so that multiple element headings and columns can be used.\n', '\n', '    E.g. To transform the list (listOfDicts):\n', '\n', '    Name,   Year,  Value\n', '    -----------------------\n', ""    'Simon', 2004, 32\n"", ""    'Simon', 2005, 128\n"", ""    'Russel', 2004, 64\n"", ""    'Eric', 2004, 52\n"", ""    'Russel', 2005, 32\n"", '\n', '    into the new list:\n', '\n', ""    'Name',   2004, 2005\n"", '    ------------------------\n', ""    'Simon',  32,     128\n"", ""    'Russel',  64,     32\n"", ""    'Eric',   52,     NA\n"", '\n', '    you would call pivot with the arguments:\n', '\n', ""    newList = pivot(listOfDicts, ('Name',), ('Year',), 'Value')\n"", '\n', '    """"""\n']","['tuple', 'ysort.append', 'xsort.append', 'len', 'list', 'xsort.sort', 'headings.extend', 'sortedkeys.sort', 'row.extend', 't.append']",10
utilmy/zarchive/py3/util.py:pd_info,pd_info,function,13,25,24,255,10.2,1,2,"['df', 'doreturn']","[None, None]","[None, '1']",2932,[],"['df.info', 'print', 'type', 'pd_info_memsize', 'pd_info', 'df.memory_usage']",6
utilmy/zarchive/py3/util.py:pd_info_memsize,pd_info_memsize,function,5,6,6,84,14.0,0,1,"['df', 'memusage']","[None, None]","[None, '0']",2939,[],"['df.info', 'pd_info', 'df.memory_usage']",3
utilmy/zarchive/py3/util.py:pd_selectrow,pd_selectrow,function,11,99,53,857,8.66,1,3,"['df', '**conditions']","[None, None]","[None, None]",2947,"[""    '''Select rows from a df according to conditions\n"", '    pdselect(data, a=2, b__lt=3) __gt __ge __lte  __in  __not_in\n', ""    will select all rows where 'a' is 2 and 'b' is less than 3\n"", ""    '''\n""]","['type', 'pd.DataFrame', 'list', 'c.endswith', 'np.in1d', 'ValueError']",6
utilmy/zarchive/py3/util.py:pd_csv_randomread,pd_csv_randomread,function,11,41,37,266,6.49,0,1,"['filename', 'nsample', 'filemaxline', 'dtype']","[None, None, None, None]","[None, '10000', '-1', 'None']",2991,[],"['sum', 'open', 'np.sort', 'pd.read_csv']",4
utilmy/zarchive/py3/util.py:pd_array_todataframe,pd_array_todataframe,function,14,46,33,313,6.8,0,2,"['array', 'colname', 'index1', 'dotranspose']","[None, None, None, None]","[None, 'None', 'None', 'False']",3001,[],"['np.shape', 'len', 'pd.DataFrame', 'np.array']",4
utilmy/zarchive/py3/util.py:pd_dataframe_toarray,pd_dataframe_toarray,function,10,10,10,103,10.3,0,0,['df'],[None],[None],3011,[],['df.reset_index'],1
utilmy/zarchive/py3/util.py:pd_createdf,pd_createdf,function,2,4,4,55,13.75,0,0,"['array1', 'col1', 'idx1']","[None, None, None]","[None, 'None', 'None']",3017,[],['pd.DataFrame'],1
utilmy/zarchive/py3/util.py:pd_create_colmapdict_nametoint,pd_create_colmapdict_nametoint,function,9,12,12,77,6.42,1,0,['df'],[None],[None],3020,"[""  ''' 'close' ---> 5    '''\n""]",['enumerate'],1
utilmy/zarchive/py3/util.py:pd_extract_col_idx_val,pd_extract_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],3030,[],[],0
utilmy/zarchive/py3/util.py:pd_extract_col_uniquevalue_tocsv,pd_extract_col_uniquevalue_tocsv,function,5,10,9,101,10.1,0,0,"['df', 'colname', 'csvfile']","[None, None, None]","[None, ""''"", ""''""]",3034,"["" ''' Write one column into a file   '''\n""]","['np.array', 'pd.DataFrame', 'print']",3
utilmy/zarchive/py3/util.py:pd_split_col_idx_val,pd_split_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],3043,[],[],0
utilmy/zarchive/py3/util.py:pd_splitdf_inlist,pd_splitdf_inlist,function,15,34,26,254,7.47,3,2,"['df', 'colid', 'type1']","[None, None, None]","[None, None, '""dict""']",3046,"[""    ''' Split df into dictionnary of dict/list '''\n""]","['list', 'l1.append']",2
utilmy/zarchive/py3/util.py:pd_find,pd_find,function,38,140,82,990,7.07,5,8,"['df', 'regex_pattern', 'col_restrict', 'isnumeric', 'doreturnposition']","[None, None, None, None, None]","[None, ""'*'"", '[]', 'False', 'False']",3061,"["" ''' Find string / numeric values inside df columns, return position where found\n"", ""     col_restrict : restrict to these columns '''\n""]","['str', 'print', 'enumerate', 'np.column_stack', 'len', 'gc.collect', 'np_dictordered_create', 'range', 'np.array']",9
utilmy/zarchive/py3/util.py:pd_dtypes_totype2,pd_dtypes_totype2,function,6,9,9,58,6.44,1,0,"['df', 'columns', 'targetype']","[None, None, None]","[None, '[]', ""'category'""]",3107,[],[],0
utilmy/zarchive/py3/util.py:pd_dtypes,pd_dtypes,function,7,12,11,91,7.58,1,0,"['df', 'columns', 'targetype']","[None, None, None]","[None, '[]', ""'category'""]",3112,[],['pd_dtypes'],1
utilmy/zarchive/py3/util.py:pd_df_todict,pd_df_todict,function,16,30,26,246,8.2,1,2,"['df', 'colkey', 'excludekey', 'onlyfirstelt']","[None, None, None, None]","[None, ""'table'"", ""['']"", ' True']",3127,[],"['df.drop_duplicates', 'range', 'dict0.setdefault']",3
utilmy/zarchive/py3/util.py:pd_applyfun_col,pd_applyfun_col,function,5,11,9,107,9.73,0,1,"['df', 'newcol', 'ff', 'use_colname']","[None, None, None, None]","[None, None, None, '""all/[colname]""']",3174,"[""   ''' use all Columns to compute values '''\n""]",['ff'],1
utilmy/zarchive/py3/util.py:pd_cleanquote,pd_cleanquote,function,10,25,23,173,6.92,1,1,['q'],[None],[None],3180,[],"['pd.to_numeric', 'q.fillna']",2
utilmy/zarchive/py3/util.py:pd_date_intersection,pd_date_intersection,function,7,18,15,157,8.72,1,0,['qlist'],[None],[None],3189,[],"['set', 'set.intersection', 'list', 'sorted']",4
utilmy/zarchive/py3/util.py:pd_is_categorical,pd_is_categorical,function,2,12,10,108,9.0,0,1,['z'],[None],[None],3197,[],['isinstance'],1
utilmy/zarchive/py3/util.py:pd_str_encoding_change,pd_str_encoding_change,function,6,8,8,76,9.5,1,0,"['df', 'cols', 'fromenc', 'toenc']","[None, None, None, None]","[None, None, ""'iso-8859-1'"", ""'utf-8'""]",3204,[],[],0
utilmy/zarchive/py3/util.py:pd_str_unicode_tostr,pd_str_unicode_tostr,function,2,4,4,60,15.0,0,0,"['df', 'targetype']","[None, None]","[None, 'str']",3210,"["" '''\n"", ' https://www.azavea.com/blog/2014/03/24/solving-unicode-problems-in-python-2-7/\n', ' Nearly every Unicode problem can be solved by the proper application of these tools;\n', ' they will help you build an airlock to keep the inside of your code nice and clean:\n', '\n', 'encode(): Gets you from Unicode -> bytes\n', 'decode(): Gets you from bytes -> Unicode\n', 'codecs.open(encoding=utf-8): Read and write files directly to/from Unicode (you can use any encoding,\n', ' not just utf-8, but utf-8 is most common).\n', 'u: Makes your string literals into Unicode objects rather than byte sequences.\n', 'Warning: Dont use encode() on bytes or decode() on Unicode objects\n', '\n', '>>> uni_greeting % utf8_name\n', 'Traceback (most recent call last):\n', ' File ""<stdin>"", line 1, in <module>\n', ""UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 3: ordinal not in range(128)\n"", '# Solution:\n', "">>> uni_greeting % utf8_name.decode('utf-8')\n"", ""u'Hi, my name is Josxe9.'\n"", '\n', "" '''\n""]",['pd_dtypes_type1_totype2'],1
utilmy/zarchive/py3/util.py:pd_dtypes_type1_totype2,pd_dtypes_type1_totype2,function,7,13,12,100,7.69,1,1,"['df', 'fromtype', 'targetype']","[None, None, None]","[None, 'str', 'str']",3234,[],['isinstance'],1
utilmy/zarchive/py3/util.py:pd_resetindex,pd_resetindex,function,3,4,4,50,12.5,0,0,['df'],[None],[None],3243,[],['list'],1
utilmy/zarchive/py3/util.py:pd_insertdatecol,pd_insertdatecol,function,8,11,11,192,17.45,0,0,"['df_insider', 'format1=""%Y-%m-%d %H']","[None, '']","[None, '""%Y-%m-%d %H:%M:%S:%f""']",3247,[],"['pd_addcol', 'date_nowtime']",2
utilmy/zarchive/py3/util.py:pd_replacevalues,pd_replacevalues,function,11,14,14,101,7.21,1,0,"['df', 'matrix']","[None, None]","[None, None]",3253,"["" ''' Matrix replaces df.values  '''\n""]",['np.shape'],1
utilmy/zarchive/py3/util.py:pd_removerow,pd_removerow,function,2,2,2,29,14.5,0,0,"['df', 'row_list_index', '45]']","[None, None, None]","[None, '[23', None]",3262,[],['df.drop'],1
utilmy/zarchive/py3/util.py:pd_removecol,pd_removecol,function,2,3,3,28,9.33,0,0,"['df1', 'name1']","[None, None]","[None, None]",3265,[],['df1.drop'],1
utilmy/zarchive/py3/util.py:pd_addcol,pd_addcol,function,3,6,6,30,5.0,0,0,"['df1', 'name1']","[None, None]","[None, ""'new'""]",3268,[],[],0
utilmy/zarchive/py3/util.py:pd_insertcol,pd_insertcol,function,4,6,6,30,5.0,0,0,"['df', 'colname', 'vec']","[None, None, None]","[None, None, None]",3280,"["" ''' Vec and Colname must be aligned '''\n""]",[],0
utilmy/zarchive/py3/util.py:pd_insertrow,pd_insertrow,function,6,10,10,102,10.2,0,0,"['df', 'rowval', 'index1', 'isreset']","[None, None, None, None]","[None, None, 'None', '1']",3296,[],"['pd_array_todataframe', 'df.append']",2
utilmy/zarchive/py3/util.py:pd_h5_cleanbeforesave,pd_h5_cleanbeforesave,function,5,12,11,91,7.58,0,0,['df'],[None],[None],3304,"[""   '''Clean Column type before Saving in HDFS: Unicode, Datetime  '''\n""]","['pd_resetindex', 'pd_str_unicode_tostr']",2
utilmy/zarchive/py3/util.py:pd_h5_addtable,pd_h5_addtable,function,5,18,17,148,8.22,0,1,"['df', 'tablename', ""dbfile='F""]","[None, None, '']","[None, None, ""'F:\\temp_pandas.h5'""]",3320,[],"['pd.HDFStore', 'find', 'list', 'print', 'store.append', 'store.close']",6
utilmy/zarchive/py3/util.py:pd_h5_tableinfo,pd_h5_tableinfo,function,4,4,4,65,16.25,0,0,"['filenameh5', 'table']","[None, None]","[None, None]",3329,[],"['pd.HDFStore', 'store.get_storer']",2
utilmy/zarchive/py3/util.py:pd_h5_dumpinfo,pd_h5_dumpinfo,function,12,23,23,304,13.22,1,0,"[""dbfile='E""]",[''],"[""'E:\\_data\\stock\\intraday_google.h5'""]",3334,[],"['pd.HDFStore', 'list', 'pd.read_hdf', 'extract.append', 'datetime_tostring', 'errsym.append', 'np.array']",7
utilmy/zarchive/py3/util.py:pd_h5_save,pd_h5_save,function,3,6,6,64,10.67,0,0,"['df', ""filenameh5='E"", 'key']","[None, '', None]","[None, ""'E:/_data/_data_outlier.h5'"", ""'data'""]",3347,"["" ''' File is release after saving it'''\n""]","['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zarchive/py3/util.py:pd_h5_load,pd_h5_load,function,4,22,16,185,8.41,0,2,"[""filenameh5='E"", 'table_id', 'exportype', 'rowstart', 'rowend', 'cols']","['', None, None, None, None, None]","[""'E:/_data/_data_outlier.h5'"", ""'data'"", '""pandas""', '-1', '-1', '[]']",3352,[],['pd.read_hdf'],1
utilmy/zarchive/py3/util.py:pd_h5_fromcsv_tohdfs,pd_h5_fromcsv_tohdfs,function,30,78,65,670,8.59,3,2,"['dircsv', 'filepattern', 'tofilehdfs', 'tablename', 'col_category', 'dtype0', 'encoding', 'chunksize', 'mode', 'format', 'complib']","[None, None, None, None, None, None, None, None, None, None, None]","[""'dir1/dir2/'"", ""'*.csv'"", ""'file1.h5'"", ""'df'"", '[]', 'None', ""'utf-8'"", ' 2000000', ""'a'"", ""'table'"", 'None']",3358,[],"['os_file_listall', 'pd.HDFStore', 'enumerate', 'pd.read_csv', 'print', 'store.append', 'store.close', 'os_file_exist']",8
utilmy/zarchive/py3/util.py:pd_np_toh5file,pd_np_toh5file,function,2,8,8,76,9.5,0,0,"['numpyarr', 'fileout', 'table1']","[None, None, None]","[None, '""file.h5""', ""'data'""]",3395,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zarchive/py3/util.py:date_allinfo,date_allinfo,function,0,0,0,0,0.0,0,0,[],[],[],3403,"[""   '''\n"", '\n', '   https://aboutsimon.com/blog/2016/08/04/datetime-vs-Arrow-vs-Pendulum-vs-Delorean-vs-udatetime.html\n', '\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/py3/util.py:date_convert,date_convert,function,14,52,37,298,5.73,1,1,"['t1', 'fromtype', 'totype']","[None, None, None]","[None, None, None]",3412,[],"['len', 'isinstance', '_dateconvert_from', 'tlist.append']",4
utilmy/zarchive/py3/util.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],3436,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/py3/util.py:date_remove_bdays,date_remove_bdays,function,16,41,28,351,8.56,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",3446,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/py3/util.py:date_add_bdays,date_add_bdays,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",3460,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/py3/util.py:datenumpy_todatetime,datenumpy_todatetime,function,11,36,22,420,11.67,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",3474,[],['type'],1
utilmy/zarchive/py3/util.py:datetime_tonumpydate,datetime_tonumpydate,function,2,2,2,22,11.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",3490,[],['np.datetime64'],1
utilmy/zarchive/py3/util.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",3494,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py3/util.py:datetime_toint,datetime_toint,function,6,15,13,155,10.33,1,1,['datelist1'],[None],[None],3502,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py3/util.py:date_holiday,date_holiday,function,0,0,0,0,0.0,0,0,[],[],[],3509,"[""   '''\n"", '   https://jakevdp.github.io/blog/2015/07/23/learning-seattles-work-habits-from-bicycle-counts/\n', '\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'cal = USFederalHolidayCalendar()\n', ""holidays = cal.holidays('2012', '2016', return_name=True)\n"", 'holidays.head()\n', '\n', 'holidays_all = pd.concat([holidays, ""Day Before "" + holidays.shift(-1, \'D\'),  ""Day After "" + holidays.shift(1, \'D\')])\n', 'holidays_all = holidays_all.sort_index()\n', 'holidays_all.head()\n', '\n', 'from pandas.tseries.offsets import CustomBusinessDay\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'bday_us = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n', 'dateref[-1] - bday_us- bday_us\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/py3/util.py:date_add_bday,date_add_bday,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",3529,"["" ''' str / stamp /  '''\n""]","['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/py3/util.py:dateint_todatetime,dateint_todatetime,function,6,15,13,135,9.0,1,1,['datelist1'],[None],[None],3542,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py3/util.py:date_diffinday,date_diffinday,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",3550,[],['dateint_todatetime'],1
utilmy/zarchive/py3/util.py:date_diffinyear,date_diffinyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",3554,[],['date_as_float'],1
utilmy/zarchive/py3/util.py:date_diffinbday,date_diffinbday,function,7,11,9,112,10.18,0,0,"['intd2', 'intd1']","[None, None]","[None, None]",3557,[],"['dateint_todatetime', 'd1.date', 'd2.date', 'np.busday_count']",4
utilmy/zarchive/py3/util.py:date_gencalendar,date_gencalendar,function,9,13,11,233,17.92,0,0,"['start', 'end', 'country']","[None, None, None]","[""'2010-01-01'"", ""'2010-01-15'"", ""'us'""]",3565,[],"['CustomBusinessDay', 'np.arrray']",2
utilmy/zarchive/py3/util.py:date_finddateid,date_finddateid,function,5,75,20,437,5.83,0,10,"['date1', 'dateref']","[None, None]","[None, None]",3571,[],['np_findfirst'],1
utilmy/zarchive/py3/util.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],3585,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py3/util.py:date_now,date_now,function,15,45,31,396,8.8,0,2,['i'],[None],['0'],3591,[],"['datetime.now', 'date_add_bdays', 'date_remove_bdays', 'str', 'date_nowtime', 'datetime.today', 'd.strftime']",7
utilmy/zarchive/py3/util.py:date_nowtime,date_nowtime,function,8,23,18,205,8.91,0,1,"['type1', 'format1= ""%Y-%m-%d %H']","[None, '']","[""'str'"", ' ""%Y-%m-%d %H:%M:%S:%f""']",3598,"["" ''' str / stamp /  '''\n""]","['datetime.today', 'd.strftime']",2
utilmy/zarchive/py3/util.py:date_tofloat,date_tofloat,function,12,28,24,291,10.39,0,1,['dt'],[None],[None],3607,[],"['old_div', 'datetime.datetime', 'isleap', 'timedelta']",4
utilmy/zarchive/py3/util.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",3615,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/py3/util.py:np_numexpr_vec_calc,np_numexpr_vec_calc,function,13,28,22,214,7.64,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",3628,"["" ''' New= xx*xx  over very large series\n"", ' #numexpr_vect_calc(filename, 0, imax=16384*4096, ""xx*xx"", \'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5\'  ):\n', ""'''\n""]","['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/py3/util.py:np_numexpr_tohdfs,np_numexpr_tohdfs,function,10,28,22,248,8.86,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",3642,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/py3/util.py:np_comoment,np_comoment,function,4,6,6,70,11.67,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",3658,[],['old_div'],1
utilmy/zarchive/py3/util.py:np_acf,np_acf,function,12,34,31,253,7.44,0,0,['data'],[None],[None],3664,[],"['len', 'np.mean', 'old_div', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/py3/util.py:plot_XY,plot_XY,function,25,83,60,688,8.29,0,3,"['xx', 'yy', 'zcolor', 'tsize', 'title1', 'xlabel', 'ylabel', 'figsize', '6']","[None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', ""''"", ""''"", ""''"", '(8', None]",3680,[],"['isinstance', 'np.array', 'np.abs', 'plt.get_cmap', 'np.min', 'plt.subplots', 'fig.set_size_inches', 'fig.set_dpi', 'fig.tight_layout', 'ax1.scatter', 'ax1.set_xlabel', 'ax1.set_ylabel', 'ax1.set_title', 'ax1.grid', 'plt.savefig', 'plt.clf', 'plt.show']",17
utilmy/zarchive/py3/util.py:plot_heatmap,plot_heatmap,function,15,26,25,364,14.0,0,1,"['frame', 'ax', 'cmap', 'vmin', 'vmax', 'interpolation']","[None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', ""'nearest'""]",3720,[],"['plt.gca', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_yticks', 'ax.set_yticklabels', 'ax.grid', 'ax.set_aspect', 'ax.imshow']",8
utilmy/zarchive/py3/util.py:gc_map_dict_to_bq_schema,gc_map_dict_to_bq_schema,function,13,59,31,714,12.1,3,3,"['source_dict', 'schema', 'dest_dict']","[None, None, None]","[None, None, None]",3737,"[""    '''\n"", '     new_dict = {}\n', '     map_dict_to_bq_schema (my_dict, schema, new_dict)\n', '\n', '     new_dict = {}\n', '     map_dict_to_bq_schema (my_dict, schema, new_dict)\n', '\n', '    :param source_dict:\n', '    :param schema:\n', '    :param dest_dict:\n', '    :return:\n', ""    '''\n""]","['map_dict_to_bq_schema', 'format_value_bq']",2
utilmy/zarchive/py3/util.py:aws_accesskey_get,aws_accesskey_get,function,7,17,13,107,6.29,0,1,"['access', 'key']","[None, None]","[""''"", ""''""]",3782,[],[],0
utilmy/zarchive/py3/util.py:aws_conn_do,aws_conn_do,function,2,3,3,39,13.0,0,0,"['action', 'region']","[None, None]","[""''"", '""ap-northeast-2""']",3790,[],['aws_conn_create'],1
utilmy/zarchive/py3/util.py:aws_conn_getallregions,aws_conn_getallregions,function,2,2,2,28,14.0,0,0,['conn'],[None],['None'],3794,[],['conn.get_all_regions'],1
utilmy/zarchive/py3/util.py:aws_conn_create,aws_conn_create,function,21,36,34,282,7.83,1,2,"['region', 'access', 'key']","[None, None, None]","['""ap-northeast-2""', ""''"", ""''""]",3797,[],"['aws_accesskey_get', 'EC2Connection', 'aws_conn_getallregions', 'conn=EC2Connection', 'print']",5
utilmy/zarchive/py3/util.py:aws_conn_getinfo,aws_conn_getinfo,function,1,2,2,28,14.0,0,0,['conn'],[None],[None],3810,[],['print'],1
utilmy/zarchive/py3/util.py:aws_s3_url_split,aws_s3_url_split,function,4,5,5,52,10.4,0,0,['url'],[None],[None],3850,"[""  '''Split into Bucket, url '''\n""]",['url.split'],1
utilmy/zarchive/py3/util.py:aws_s3_getbucketconn,aws_s3_getbucketconn,function,13,17,16,221,13.0,0,0,['s3dir'],[None],[None],3855,[],"['aws_s3_url_split', 'aws_accesskey_get', 'boto.connect_s3', 'conn.get_bucket']",4
utilmy/zarchive/py3/util.py:aws_s3_puto_s3,aws_s3_puto_s3,function,36,114,102,1158,10.16,3,2,"['fromdir_file', 'todir']","[None, None]","[""'dir/file.zip'"", ""'bucket/folder1/folder2'""]",3863,"["" ''' Copy File or Folder to S3 '''\n""]","['aws_s3_getbucketconn', 'aws_s3_url_split', 'fromdir_file.find', 'os_file_getname', 'fromdir_file=os_file_getpath', 'os.walk', 'uploadFileNames.extend', 'percent_cb', 'print', 'bucket.initiate_multipart_upload', 'open', 'mp.upload_part_from_file', 'mp.complete_upload', 'k.set_contents_from_filename']",14
utilmy/zarchive/py3/util.py:aws_s3_getfrom_s3,aws_s3_getfrom_s3,function,21,45,45,430,9.56,1,1,"['froms3dir', 'todir', 'bucket_name']","[None, None, None]","[""'task01/'"", ""''"", ""'zdisk'""]",3907,"["" ''' Get from S3 file/folder  '''\n""]","['aws_s3_url_split', 'aws_s3_getbucketconn', 'bucket.list', 'str', 'os_file_getname', 'os_file_getpath', 'os.makedirs', 'l.get_contents_to_filename']",8
utilmy/zarchive/py3/util.py:aws_s3_folder_printtall,aws_s3_folder_printtall,function,12,18,17,234,13.0,1,0,['bucket_name'],[None],"[""'zdisk'""]",3926,[],"['aws_accesskey_get', 'boto.connect_s3', 'conn.create_bucket', 'bucket.list', 'print']",5
utilmy/zarchive/py3/util.py:aws_s3_file_read,aws_s3_file_read,function,10,14,13,187,13.36,0,0,"['filepath', 'isbinary']","[None, None]","[None, '1']",3935,"[""  ''' s3_client = boto3.client('s3')\n"", '    #Download private key file from secure S3 bucket\n', ""  s3_client.download_file('s3-key-bucket','keys/keyname.pem', '/tmp/keyname.pem')\n"", ""  '''\n""]","['S3Connection', 'conn.get_object']",2
utilmy/zarchive/py3/util.py:aws_ec2_python_script,aws_ec2_python_script,function,5,20,18,195,9.75,0,0,"['script_path', 'args1', 'host']","[None, None, None]","[None, None, None]",4179,[],['aws_ec2_cmd_ssh'],1
utilmy/zarchive/py3/util.py:aws_ec2_create_con,aws_ec2_create_con,function,35,116,89,1002,8.64,1,9,"['contype', 'host', 'port', 'username', 'keyfilepath', 'password', 'keyfiletype', 'isprint']","[None, None, None, None, None, None, None, None]","[""'sftp/ssh'"", ""'ip'"", '22', ""'ubuntu'"", ""''"", ""''"", ""'RSA'"", '1']",4184,"['    """""" Transfert File  host = \'52.79.79.1\'\n', ""        keyfilepath = 'D:/_devs/aws/keypairs/ec2_instanc'\n"", '\n', '# List files in the default directory on the remote computer.\n', ""dirlist = sftp.listdir('.')\n"", ""sftp.get('remote_file.txt', 'downloaded_file.txt')\n"", ""sftp.put('testfile.txt', 'remote_testfile.txt')\n"", '\n', 'http://docs.paramiko.org/en/2.1/api/sftp.html\n', '    """"""\n']","['paramiko.Transport', 'transport.add_server_key', 'transport.connect', 'print', 'sftp.listdir', 'paramiko.SSHClient', 'ssh.set_missing_host_key_policy', 'ssh.connect', 'ssh.exec_command', 'stdin.flush', 'stdout.read', 'sftp.close', 'transport.close', 'ssh.close']",14
utilmy/zarchive/py3/util.py:aws_ec2_allocate_elastic_ip,aws_ec2_allocate_elastic_ip,function,7,16,16,233,14.56,0,0,"['instance_id', 'region']","[None, None]","[None, '""ap-northeast-2""']",4233,[],"['aws_conn_create', 'con.associate_address', 'print']",3
utilmy/zarchive/py3/util.py:googledrive_get,googledrive_get,function,0,1,1,4,4.0,0,0,[],[],[],4388,"[""   '''\n"", '   https://github.com/ctberthiaume/gdcp\n', '   ... I am using this now to transfer thousands of mp3 files from a ubuntu vps to google drive.\n', '\n', '\n', 'http://olivermarshall.net/how-to-upload-a-file-to-google-drive-from-the-command-line/\n', 'https://github.com/prasmussen/gdrive  : Super Complete\n', '\n', 'gdrive [global] upload [options] <path>\n', '\n', 'global:\n', '  -c, --config <configDir>         Application path, default: /Users/<user>/.gdrive\n', '  --refresh-token <refreshToken>   Oauth refresh token used to get access token (for advanced users)\n', '  --access-token <accessToken>     Oauth access token, only recommended for short-lived requests because of short lifetime (for advanced users)\n', '\n', 'options:\n', '  -r, --recursive           Upload directory recursively\n', '  -p, --parent <parent>     Parent id, used to upload file to a specific directory, can be specified multiple times to give many parents\n', '  --name <name>             Filename\n', '  --no-progress             Hide progress\n', '  --mime <mime>             Force mime type\n', '  --share                   Share file\n', '  --delete                  Delete local file when upload is successful\n', '  --chunksize <chunksize>   Set chunk size in bytes, default: 8388608\n', '\n', '   :return:\n', ""   '''\n""]",[],0
utilmy/zarchive/py3/util.py:googledrive_put,googledrive_put,function,0,1,1,4,4.0,0,0,[],[],[],4418,"[""  '''\n"", '  100 GB: 2USD,  1TB: 10USD\n', '  https://gsuite.google.com/intl/en/pricing.html\n', '\n', '  :return:\n', ""  '''\n""]",[],0
utilmy/zarchive/py3/util.py:googledrive_list,googledrive_list,function,0,1,1,4,4.0,0,0,[],[],[],4428,[],[],0
utilmy/zarchive/py3/util.py:os_processify_fun,os_processify_fun,function,32,78,63,713,9.14,0,1,['func'],[None],[None],4433,"[""    '''Decorator to run a function as a process.\n"", '    Be sure that every argument and the return value is *pickable*.\n', '    The created process is joined, so the code does not  run in parallel.\n', '    @processify\n', '\n', '    def test():\n', '      return os.getpid()\n', '\n', '    @processify\n', '    def test_deadlock():\n', '      return range(30000)\n', '\n', '   @processify\n', '   def test_exception():\n', ""     raise RuntimeError('xyz')\n"", '\n', '   def test():\n', '     print os.getpid()\n', '     print test_function()\n', '     print len(test_deadlock())\n', '     test_exception()\n', '\n', ""   if __name__ == '__main__':\n"", '     test()\n', '\n', ""    '''\n""]","['process_func', 'func', 'sys.exc_info', 'q.put', 'setattr', 'wrapper', 'Queue', 'Process', 'list', 'p.start', 'q.get', 'ex_type']",12
utilmy/zarchive/py3/util.py:ztest_processify,ztest_processify,function,2,2,2,17,8.5,0,0,[],[],[],4500,[],['os.getpid'],1
utilmy/zarchive/py3/util.py:date_getspecificdate,date_getspecificdate,function,21,194,56,1312,6.76,8,19,"['datelist', 'datetype1', 'outputype1', 'includelastdate', 'includefirstdate', '']","[None, None, None, None, None, None]","[None, '""yearend""', '""intdate""', 'True', 'False', None]",4520,[],"['isint', 'dateint_todatetime', 'enumerate', 'vec2.append', 'np.mod', 'np.array']",6
utilmy/zarchive/py3/util.py:testclass,testclass,class,21,51,42,434,8.51,0,3,[],[],[],127,[],[],0
utilmy/zarchive/py3/util.py:FundingRecord,FundingRecord,class,14,59,48,394,6.68,0,0,[],[],[],1391,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh,aws_ec2_ssh,class,129,339,228,4029,11.88,10,10,[],[],[],3950,[],[],0
utilmy/zarchive/py3/util.py:testclass:__init__,testclass:__init__,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",128,[],[],0
utilmy/zarchive/py3/util.py:testclass:z_autotest,testclass:z_autotest,method,19,44,38,387,8.8,0,3,['self'],[None],[None],131,[],"['io.StringIO', 'f', 'self.redirect_internalshell_stdio', 'getopenfilename', '_', 'getcwd', 'self.close']",7
utilmy/zarchive/py3/util.py:FundingRecord:parse,FundingRecord:parse,method,7,35,26,223,6.37,0,0,"['klass', 'row']","[None, None]","[None, None]",1394,[],"['list', 'int', 'datetime.strptime', 'klass']",4
utilmy/zarchive/py3/util.py:FundingRecord:__str__,FundingRecord:__str__,method,6,18,18,118,6.56,0,0,['self'],[None],[None],1401,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh:__init__,aws_ec2_ssh:__init__,method,21,27,25,415,15.37,0,0,"['self', 'hostname', 'username', 'key_file', 'password']","[None, None, None, None, None]","[None, None, ""'ubuntu'"", 'None', 'None']",3966,[],"['socket.socket', 'paramiko.Transport', 'print']",3
utilmy/zarchive/py3/util.py:aws_ec2_ssh:command,aws_ec2_ssh:command,method,12,20,18,247,12.35,1,0,"['self', 'cmd']","[None, None]","[None, None]",4005,[],"['chan.get_pty', 'chan.invoke_shell', 'chan.settimeout', 'chan.send', 'cmd.split']",5
utilmy/zarchive/py3/util.py:aws_ec2_ssh:put,aws_ec2_ssh:put,method,17,33,29,650,19.7,2,2,"['self', 'localfile', 'remotefile']","[None, None, None]","[None, None, None]",4025,[],"['put_all', 'os.chdir', 'os.walk', 'print', 'self.put']",5
utilmy/zarchive/py3/util.py:aws_ec2_ssh:put_all,aws_ec2_ssh:put_all,method,15,30,26,575,19.17,2,2,"['self', 'localpath', 'remotepath']","[None, None, None]","[None, None, None]",4029,[],"['os.chdir', 'os.walk', 'print', 'self.put']",4
utilmy/zarchive/py3/util.py:aws_ec2_ssh:get,aws_ec2_ssh:get,method,1,1,1,35,35.0,0,0,"['self', 'remotefile', 'localfile']","[None, None, None]","[None, None, None]",4045,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh:sftp_walk,aws_ec2_ssh:sftp_walk,method,20,33,26,371,11.24,3,1,"['self', 'remotepath']","[None, None]","[None, None]",4049,[],"['S_ISDIR', 'folders.append', 'files.append', 'print', 'self.sftp_walk']",5
utilmy/zarchive/py3/util.py:aws_ec2_ssh:get_all,aws_ec2_ssh:get_all,method,15,38,30,601,15.82,2,2,"['self', 'remotepath', 'localpath']","[None, None, None]","[None, None, None]",4070,[],"['os.mkdir', 'self.sftp_walk', 'print', 'self.get']",4
utilmy/zarchive/py3/util.py:aws_ec2_ssh:write_command,aws_ec2_ssh:write_command,method,2,2,2,74,37.0,0,0,"['self', 'text', 'remotefile']","[None, None, None]","[None, None, None]",4094,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh:python_script,aws_ec2_ssh:python_script,method,5,12,10,119,9.92,0,0,"['self', 'script_path', 'args1']","[None, None, None]","[None, None, None]",4101,[],['self.cmd2'],1
utilmy/zarchive/py3/util.py:aws_ec2_ssh:command_list,aws_ec2_ssh:command_list,method,5,13,13,116,8.92,1,0,"['self', 'cmdlist']","[None, None]","[None, None]",4107,[],"['print', 'self.command']",2
utilmy/zarchive/py3/util.py:aws_ec2_ssh:listdir,aws_ec2_ssh:listdir,method,2,2,2,34,17.0,0,0,"['self', 'remotedir']","[None, None]","[None, None]",4114,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh:jupyter_kill,aws_ec2_ssh:jupyter_kill,method,3,9,9,130,14.44,0,0,['self'],[None],[None],4117,[],"['aws_ec2_cmd_ssh', 'print']",2
utilmy/zarchive/py3/util.py:aws_ec2_ssh:jupyter_start,aws_ec2_ssh:jupyter_start,method,0,1,1,4,4.0,0,0,['self'],[None],[None],4121,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh:cmd2,aws_ec2_ssh:cmd2,method,2,5,5,63,12.6,0,0,"['self', 'cmd1']","[None, None]","[None, None]",4124,[],['aws_ec2_cmd_ssh'],1
utilmy/zarchive/py3/util.py:aws_ec2_ssh:_help_ssh,aws_ec2_ssh:_help_ssh,method,18,29,29,132,4.55,0,1,['self'],[None],[None],4129,[],[],0
utilmy/zarchive/storage/allmodule.py:aa_isanaconda,aa_isanaconda,function,6,15,14,80,5.33,0,1,[],[],[],4,[],['txt.find'],1
utilmy/zarchive/storage/benchmarktest.py:payoff1,payoff1,function,4,5,5,61,12.2,0,0,['pricepath'],[None],[None],130,[],"['pricepath[len', 'np.maximum']",2
utilmy/zarchive/storage/benchmarktest.py:payoffeuro1,payoffeuro1,function,2,3,3,30,10.0,0,0,['st'],[None],[None],145,[],['np.maximum'],1
utilmy/zarchive/storage/benchmarktest.py:payoff2,payoff2,function,6,13,13,127,9.77,0,0,['pricepath'],[None],[None],181,[],"['np.shape', 'np.sum', 'np.maximum']",3
utilmy/zarchive/storage/benchmarktest.py:payoffeuro1,payoffeuro1,function,2,3,3,30,10.0,0,0,['st'],[None],[None],145,[],['np.maximum'],1
utilmy/zarchive/storage/codeanalysis.py:wi,wi,function,6,11,9,88,8.0,0,0,['*args)'],['  #Print with indentationaux'],"[""''' '*INDENT)for arg in args:""]",13,[],"['str', 'dx.replace']",2
utilmy/zarchive/storage/codeanalysis.py:printinfile,printinfile,function,5,12,10,53,4.42,1,1,"['vv', 'file2)', '""a"") as text_file']","[None, '  # print vvfile2', '    text_file.write(vv)*args):']","[None, None, None]",24,[],[],0
utilmy/zarchive/storage/codeanalysis.py:wi2,wi2,function,5,12,10,53,4.42,1,1,['*args'],[None],[None],28,[],[],0
utilmy/zarchive/storage/codeanalysis.py:indent,indent,function,17,43,34,344,8.0,0,4,[')'],['     global INDENT; INDENT +'],[' 4):      global INDENT; INDENT -= 4obj):'],33,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/codeanalysis.py:dedent,dedent,function,17,43,34,344,8.0,0,4,[')'],['      global INDENT; INDENT -'],[' 4obj):'],34,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/codeanalysis.py:describe_builtin,describe_builtin,function,17,43,34,344,8.0,0,4,['obj'],[None],[None],38,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/codeanalysis.py:describe_func,describe_func,function,18,59,46,443,7.51,0,5,"['obj', 'method']","[None, None]","[None, 'False']",58,[],"['inspect.getargspec', 'wi', 'str', 'len']",4
utilmy/zarchive/storage/codeanalysis.py:describe_klass,describe_klass,function,12,33,30,238,7.21,1,2,['obj'],[None],[None],81,[],"['wi', 'indent', 'getattr', 'inspect.ismethod', '1;describe_func', 'dedent']",6
utilmy/zarchive/storage/codeanalysis.py:describe,describe,function,61,353,164,2895,8.2,4,21,['obj'],[None],[None],97,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find', 'describe_func', 'inspect.getargspec', 'str', 'len', 'describe_klass', 'indent', 'getattr', 'inspect.ismethod', '1;describe_func', 'dedent', 'describe', 'dir', 'inspect.isclass', 'inspect.isfunction', 'inspect.isbuiltin', 'describe_builtin', 'describe_builtin2', 'describe_func2', 'describe_func3', 'aux.replace', 'aux.rstrip', 'describe_klass2', 'describe2']",27
utilmy/zarchive/storage/codeanalysis.py:describe_builtin2,describe_builtin2,function,16,33,26,272,8.24,0,3,"['obj', 'name1']","[None, None]","[None, None]",118,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/codeanalysis.py:describe_func2,describe_func2,function,9,21,21,143,6.81,0,1,"['obj', 'method', 'name1']","[None, None, None]","[None, 'False', ""''""]",135,[],"['inspect.getargspec', 'wi', 'str']",3
utilmy/zarchive/storage/codeanalysis.py:describe_func3,describe_func3,function,14,34,31,236,6.94,0,1,"['obj', 'method', 'name1']","[None, None, None]","[None, 'False', ""''""]",145,[],"['inspect.getargspec', 'str', 'aux.replace', 'aux.rstrip', 'wi']",5
utilmy/zarchive/storage/codeanalysis.py:describe_klass2,describe_klass2,function,8,18,18,151,8.39,1,1,"['obj', 'name1']","[None, None]","[None, ""''""]",158,[],"['getattr', 'inspect.ismethod', 'describe_func2']",3
utilmy/zarchive/storage/codeanalysis.py:describe2,describe2,function,13,43,33,377,8.77,1,2,"['module', 'type1']","[None, None]","[None, '0']",168,[],"['wi', 'dir', 'getattr', 'inspect.isclass', 'describe_klass2', 'inspect.isfunction', 'describe_func2', 'describe_func3', 'inspect.isbuiltin', 'describe_builtin2']",10
utilmy/zarchive/storage/codeanalysis.py:getmodule_doc,getmodule_doc,function,32,102,69,872,8.55,5,1,"['module1', 'file2']","[None, None]","[None, ""''""]",192,[],"['importlib.import_module', 'pkgutil.walk_packages', 'vv.append', 'wi', 'describe2', 'sys.exc_info', 'describe', 'print']",8
utilmy/zarchive/storage/derivatives.py:loadbrownian,loadbrownian,function,4,4,4,125,31.25,0,0,"['nbasset', 'step', 'nbsimul']","[None, None, None]","[None, None, None]",35,[],['np.load'],1
utilmy/zarchive/storage/derivatives.py:dN,dN,function,1,13,12,63,4.85,0,0,"['d)', 'y)', 'K', 't', 'T', 'r', 'd', 'vol)']","['   return    np.exp(-0.5*d*d)*ONE_SQRT_2PI   # ss.norm.pdf(d)x', '   return  np.exp(-0.5*x*x-0.5*y*y)*ONE_2PI   # ss.norm.pdf(d)d):    return  ss.norm.cdf(d)St', None, None, None, None, None, '']","[None, None, None, None, None, None, None, None]",47,[],['np.sqrt'],1
utilmy/zarchive/storage/derivatives.py:dN2d,dN2d,function,1,13,12,63,4.85,0,0,"['x', 'y)', 'K', 't', 'T', 'r', 'd', 'vol)']","[None, '   return  np.exp(-0.5*x*x-0.5*y*y)*ONE_2PI   # ss.norm.pdf(d)d):    return  ss.norm.cdf(d)St', None, None, None, None, None, '']","[None, None, None, None, None, None, None, None]",49,[],['np.sqrt'],1
utilmy/zarchive/storage/derivatives.py:N,N,function,1,13,12,63,4.85,0,0,"['d)', 'K', 't', 'T', 'r', 'd', 'vol)']","['    return  ss.norm.cdf(d)St', None, None, None, None, None, '']","[None, None, None, None, None, None, None]",54,[],['np.sqrt'],1
utilmy/zarchive/storage/derivatives.py:d1f,d1f,function,1,13,12,63,4.85,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",56,[],['np.sqrt'],1
utilmy/zarchive/storage/derivatives.py:d2f,d2f,function,1,13,12,63,4.85,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",59,[],['np.sqrt'],1
utilmy/zarchive/storage/derivatives.py:bsbinarycall,bsbinarycall,function,4,11,11,64,5.82,0,0,"['S0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",63,[],"['d2f', 'np.exp']",2
utilmy/zarchive/storage/derivatives.py:bscall,bscall,function,6,15,14,118,7.87,0,0,"['S0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",68,[],['d1f'],1
utilmy/zarchive/storage/derivatives.py:bsput,bsput,function,5,15,14,121,8.07,0,0,"['S0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",74,[],['d1f'],1
utilmy/zarchive/storage/derivatives.py:bs,bs,function,30,342,119,2051,6.0,0,2,"['S0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",80,[],"['d2f', 'np.exp', 'bscall', 'd1f', 'bsput', 'bs', 'bsdelta', 'N', 'bsgamma', 'np.sqrt', 'bsstrikedelta', 'bsstrikegamma', 'bstheta', 'bsrho', 'bsvega', 'dN', 'bsdvd', 'bsvanna', 'bsvolga', 'bsgammaspot']",20
utilmy/zarchive/storage/derivatives.py:bsdelta,bsdelta,function,4,19,19,102,5.37,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp1)', 'K', 't', 'T', 'r', 'd', 'vol)-d*(T-t)) * N(d1)-d*(T-t)) * (N(d1)-1)return auxSt', 'K', 't', 'T', 'r', 'd', 'vol', 'cp)']","[None, None, None, None, None, None, None, ' #be careful of equality for booleanSt', None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]",86,[],"['d1f', 'np.exp', 'np.sqrt']",3
utilmy/zarchive/storage/derivatives.py:bsgamma,bsgamma,function,4,19,19,102,5.37,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",93,[],"['d1f', 'np.exp', 'np.sqrt']",3
utilmy/zarchive/storage/derivatives.py:bsstrikedelta,bsstrikedelta,function,4,19,19,102,5.37,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol', 'cp1)', 'K', 't', 'T', 'r', 'd', 'vol)-r*T)*N(d2)-r*T)*N(-d2)return auxs0', 'K', 't', 'T', 'r', 'd', 'vol)']","[None, None, None, None, None, None, None, '  #discounted risk neutral probabilitys0', None, None, None, None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]",98,[],"['d1f', 'np.exp', 'np.sqrt']",3
utilmy/zarchive/storage/derivatives.py:bsstrikegamma,bsstrikegamma,function,4,19,19,102,5.37,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",105,[],"['d1f', 'np.exp', 'np.sqrt']",3
utilmy/zarchive/storage/derivatives.py:bstheta,bstheta,function,3,20,19,104,5.2,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",110,[],"['d1f', 'np.sqrt', 'N']",3
utilmy/zarchive/storage/derivatives.py:bsrho,bsrho,function,4,16,15,72,4.5,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",115,[],"['d2f', 'np.exp', 'N']",3
utilmy/zarchive/storage/derivatives.py:bsvega,bsvega,function,4,13,13,75,5.77,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",120,[],"['d1f', 'np.sqrt', 'dN']",3
utilmy/zarchive/storage/derivatives.py:bsdvd,bsdvd,function,3,22,20,97,4.41,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",125,[],"['d1f', 'np.sqrt', 'np.exp', 'N']",4
utilmy/zarchive/storage/derivatives.py:bsvanna,bsvanna,function,3,16,15,85,5.31,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",130,[],"['d1f', 'np.sqrt', 'dN']",3
utilmy/zarchive/storage/derivatives.py:bsvolga,bsvolga,function,4,18,16,103,5.72,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",135,[],"['d1f', 'np.sqrt', 'dN']",3
utilmy/zarchive/storage/derivatives.py:bsgammaspot,bsgammaspot,function,4,18,18,124,6.89,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",140,[],"['d1f', 'np.exp']",2
utilmy/zarchive/storage/derivatives.py:gdelta,gdelta,function,1,15,10,63,4.2,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'pv']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",149,[],['pv'],1
utilmy/zarchive/storage/derivatives.py:ggamma,ggamma,function,1,21,11,88,4.19,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'pv']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",152,[],"['pv', '2*pv']",2
utilmy/zarchive/storage/derivatives.py:gvega,gvega,function,1,15,11,58,3.87,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'pv']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",155,[],['pv'],1
utilmy/zarchive/storage/derivatives.py:gtheta,gtheta,function,1,15,11,66,4.4,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'pv']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",158,[],['pv'],1
utilmy/zarchive/storage/derivatives.py:genmatrix,genmatrix,function,9,14,12,83,5.93,2,0,"['ni', 'nj', 'gg']","[None, None, None]","[None, None, None]",166,[],"['np.zeros', 'range', 'gg']",3
utilmy/zarchive/storage/derivatives.py:gensymmatrix,gensymmatrix,function,9,19,15,89,4.68,2,1,"['ni', 'nj', 'pp']","[None, None, None]","[None, None, None]",175,[],"['np.zeros', 'range']",2
utilmy/zarchive/storage/derivatives.py:payoff1,payoff1,function,4,5,5,47,9.4,0,0,['pricepath'],[None],[None],434,[],['np.maximum'],1
utilmy/zarchive/storage/derivatives.py:payoffeuro1,payoffeuro1,function,2,3,3,30,10.0,0,0,['st'],[None],[None],439,[],['np.maximum'],1
utilmy/zarchive/storage/derivatives.py:payoff2,payoff2,function,6,13,13,124,9.54,0,0,['pricepath'],[None],[None],605,[],"['np.shape', 'sum', 'np.maximum']",3
utilmy/zarchive/storage/derivatives.py:savebrownian,savebrownian,function,1,8,8,58,7.25,0,0,"['nbasset', 'step', 'nbsimul']","[None, None, None]","[None, None, None]",30,[],[],0
utilmy/zarchive/storage/derivatives.py:plot_greeks,plot_greeks,function,39,78,68,528,6.77,2,0,"['function', 'greek']","[None, None]","[None, None]",1036,[],"['np.linspace', 'np.zeros', 'len', 'range', 'function', 'np.meshgrid', 'plt.figure', 'p3.Axes3D', 'plot.plot_wireframe', 'plot.set_xlabel', 'plot.set_ylabel', 'plot.set_zlabel']",12
utilmy/zarchive/storage/derivatives.py:plot_greeks,plot_greeks,function,39,78,68,528,6.77,2,0,"['function', 'greek']","[None, None]","[None, None]",1036,[],"['np.linspace', 'np.zeros', 'len', 'range', 'function', 'np.meshgrid', 'plt.figure', 'p3.Axes3D', 'plot.plot_wireframe', 'plot.set_xlabel', 'plot.set_ylabel', 'plot.set_zlabel']",12
utilmy/zarchive/storage/derivatives.py:plot_values,plot_values,function,32,125,76,888,7.1,0,0,['function'],[None],[None],1097,[],"['plt.figure', 'plt.subplot', 'np.linspace', 'plt.plot', 'plt.grid', 'plt.xlabel', 'plt.ylabel', 'plt.axis', 'plt.tight_layout']",9
utilmy/zarchive/storage/derivatives.py:CRR_option_value,CRR_option_value,function,32,121,84,518,4.28,1,1,"['S0', 'K', 'T', 'r', 'vol', 'otype', 'M']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, '4']",1153,"[""    ''' Cox-Ross-Rubinstein European option valuation.\n"", ""    otype : string  either 'call' or 'put'\n"", '    M : int  number of time intervals\n', ""    '''\n""]","['np.exp', 'np.sqrt', 'np.arange', 'np.resize', 'np.transpose', 'np.maximum', 'range']",7
utilmy/zarchive/storage/dl_utils.py:save_weights,save_weights,function,1,5,5,42,8.4,0,0,"['file', 'tuple_weights']","[None, None]","[None, None]",21,[],"['pickle.dump', 'open']",2
utilmy/zarchive/storage/dl_utils.py:save_prediction,save_prediction,function,1,5,5,39,7.8,0,0,"['file', 'prediction']","[None, None]","[None, None]",24,[],"['pickle.dump', 'open']",2
utilmy/zarchive/storage/dl_utils.py:log,log,function,4,6,6,91,15.17,0,0,"['msg', 'file']","[None, None]","[None, '""""']",27,[],"['open', 'logfile']",2
utilmy/zarchive/storage/dl_utils.py:logfile,logfile,function,5,8,8,76,9.5,0,0,"['msg', 'file']","[None, None]","[None, None]",30,[],"['open', 'myfile.write']",2
utilmy/zarchive/storage/dl_utils.py:log_p,log_p,function,3,2,2,23,11.5,0,0,"['msg', 'file']","[None, None]","[None, '""""']",34,[],['log'],1
utilmy/zarchive/storage/dl_utils.py:init_weight,init_weight,function,1,4,4,52,13.0,0,0,"['hidden1', 'hidden2', 'acti_type']","[None, None, None]","[None, None, None]",38,[],[],0
utilmy/zarchive/storage/dl_utils.py:get_all_data,get_all_data,function,21,26,25,476,18.31,1,2,['file'],[None],[None],52,[],"['str', 'open', 'line.strip', 'x.split']",4
utilmy/zarchive/storage/dl_utils.py:get_batch_data,get_batch_data,function,7,7,7,195,27.86,0,1,"['file', 'index', 'size)', '5->1', '2', '3', '4', '5array', 'index+size)']","[None, None, '#1', None, None, None, None, None, '']","[None, None, None, None, None, None, None, '[]arrayY=[]index', None]",75,[],"['line.strip', 'x.split']",2
utilmy/zarchive/storage/dl_utils.py:get_xy,get_xy,function,5,6,6,107,17.83,0,0,['line'],[None],[None],95,[],"['y=int', 'x.split']",2
utilmy/zarchive/storage/dl_utils.py:file_len,file_len,function,7,10,10,62,6.2,1,0,['fname'],[None],[None],103,[],"['open', 'enumerate']",2
utilmy/zarchive/storage/dl_utils.py:feats_len,feats_len,function,4,5,5,65,13.0,0,0,['fname'],[None],[None],111,[],['open'],1
utilmy/zarchive/storage/excel.py:get_workbook_name,get_workbook_name,function,3,5,5,48,9.6,0,0,[],[],[],9,"['    """"""Writes the name of the Workbook into Range(""D3"") of Sheet 1""""""\n']","['Workbook.caller', 'Range']",2
utilmy/zarchive/storage/excel.py:double_sum,double_sum,function,1,4,4,13,3.25,0,0,"['x', 'y']","[None, None]","[None, None]",16,"['    """"""Returns twice the sum of the two arguments""""""\n']",[],0
utilmy/zarchive/storage/excel.py:add_one,add_one,function,5,11,9,40,3.64,2,0,['data'],[None],[None],23,"['    """"""Adds 1 to every cell in Range""""""\n']",[],0
utilmy/zarchive/storage/excel.py:matrix_mult,matrix_mult,function,2,2,2,14,7.0,0,0,"['x', 'y']","[None, None]","[None, None]",31,"['    """"""Alternative implementation of Excel\'s MMULT, requires NumPy""""""\n']",['x.dot'],1
utilmy/zarchive/storage/excel.py:npdot,npdot,function,0,0,0,0,0.0,0,0,[],[],[],43,[],[],0
utilmy/zarchive/storage/java.py:importJAR,importJAR,function,7,26,16,261,10.04,0,3,"['path1', 'path2', 'path3', 'path4']","[None, None, None, None]","['""""', '""""', '""""', '""""']",24,[],['jp.startJVM'],1
utilmy/zarchive/storage/java.py:listallfile,listallfile,function,20,36,30,353,9.81,2,1,"['some_dir', 'pattern', 'dirlevel']","[None, None, None]","[None, '""*.*""', '1']",36,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'fnmatch.filter', 'matches.append']",6
utilmy/zarchive/storage/java.py:importFolderJAR,importFolderJAR,function,7,18,17,182,10.11,1,0,"['dir1', 'dirlevel']","[None, None]","['""""', '1']",52,[],"['listallfile', 'jp.startJVM']",2
utilmy/zarchive/storage/java.py:importFromMaven,importFromMaven,function,1,2,2,7,3.5,0,0,[],[],[],62,[],[],0
utilmy/zarchive/storage/java.py:showLoadedClass,showLoadedClass,function,5,10,10,93,9.3,0,0,[')'],[' #Code to see the JAR loaded.); vv'],[' [];):  vv.append(x.toString());return vvdir1) :'],68,[],"['zipfile.ZipFile', 'archive.namelist']",2
utilmy/zarchive/storage/java.py:inspectJAR,inspectJAR,function,5,10,10,93,9.3,0,0,['dir1'],[None],[None],77,[],"['zipfile.ZipFile', 'archive.namelist']",2
utilmy/zarchive/storage/java.py:loadSingleton,loadSingleton,function,6,7,7,102,14.57,0,0,['class1)'],['  single'],[' jp.JClass(class1);  return Single.getInstance()x):  jp.java.lang.System.out.println(x)   #Print in Java Consolejavafile):'],86,[],"['os.getenv', 'subprocess.check_call']",2
utilmy/zarchive/storage/java.py:java_print,java_print,function,6,7,7,102,14.57,0,0,['x)'],['  jp.java.lang.System.out.println(x)   #Print in Java Consolejavafile):'],[None],89,[],"['os.getenv', 'subprocess.check_call']",2
utilmy/zarchive/storage/java.py:compileJAVA,compileJAVA,function,6,7,7,102,14.57,0,0,['javafile'],[None],[None],92,[],"['os.getenv', 'subprocess.check_call']",2
utilmy/zarchive/storage/java.py:writeText,writeText,function,2,5,5,68,13.6,0,0,"['text', 'filename']","[None, None]","[None, None]",98,[],"['open', 'text_file.write', 'text_file.close']",3
utilmy/zarchive/storage/java.py:compileJAVAtext,compileJAVAtext,function,8,15,14,161,10.73,0,1,"['classname', 'javatxt', 'path1']","[None, None, None]","[None, None, '""""']",102,[],"['os.getcwd', 'text_file=open', 'text_file.write', 'text_file.close', 'compileJAVA']",5
utilmy/zarchive/storage/multiprocessfunc.py:multigbm_paralell_func,multigbm_paralell_func,function,34,117,81,913,7.8,1,4,"['nbsimul', 'ww', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price', 'type1', 'strike', 'cp']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, '0', '0', '1']",20,[],"['np.zeros', 'range', 'np.dot', 'np.multiply', 'np.exp', 'np.cumprod', 'np.maximum', 'sum', 'sum1/float']",9
utilmy/zarchive/storage/multiprocessfunc.py:func,func,function,6,10,10,56,5.6,1,0,"['val', 'lock']","[None, None]","[None, None]",73,[],"['range', 'time.sleep']",2
utilmy/zarchive/storage/multiprocessfunc.py:multigbm_processfast7,multigbm_processfast7,function,24,48,44,419,8.73,3,0,"['nbsimul', 's0', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",150,[],"['range', 'np.dot', 'bm_generator', 'np.exp', 'sum', 'sum1/float']",6
utilmy/zarchive/storage/multiprocessfunc.py:bm_generator,bm_generator,function,5,9,8,43,4.78,0,1,"['bm', 'dt', 'n', 'type1']","[None, None, None, None]","[None, None, None, None]",177,[],[],0
utilmy/zarchive/storage/multiprocessfunc.py:merge,merge,function,6,20,17,106,5.3,1,1,['d2'],[None],[None],211,[],"['time.sleep', 'd2.keys']",2
utilmy/zarchive/storage/multiprocessfunc.py:integratenp2,integratenp2,function,10,29,25,184,6.34,1,0,"['its', 'nchunk']","[None, None]","[None, None]",222,[],"['range', 'ne.evaluate']",2
utilmy/zarchive/storage/multiprocessfunc.py:integratenp,integratenp,function,27,77,47,454,5.9,2,0,"['its', 'nchunk']","[None, None]","[None, None]",234,[],"['range', 'ne.evaluate', 'integratenp', 'np.sum', 'float']",5
utilmy/zarchive/storage/multiprocessfunc.py:integratene,integratene,function,12,44,38,275,6.25,1,0,['its'],[None],[None],247,[],"['range', 'ne.evaluate', 'float']",3
utilmy/zarchive/storage/multiprocessfunc.py:parzen_estimation,parzen_estimation,function,7,30,26,185,6.17,2,1,"['x_samples', 'point_x', 'h']","[None, None, None]","[None, None, None]",268,[],"['np.abs', 'len']",2
utilmy/zarchive/storage/multiprocessfunc.py:init2,init2,function,2,4,4,13,3.25,0,0,['d'],[None],[None],282,[],[],0
utilmy/zarchive/storage/multiprocessfunc.py:init_global1,init_global1,function,2,2,2,37,18.5,0,0,"['l', 'r']","[None, None]","[None, None]",286,[],[],0
utilmy/zarchive/storage/multiprocessfunc.py:np_sin,np_sin,function,2,2,2,19,9.5,0,0,['value'],[None],[None],291,[],['np.sin'],1
utilmy/zarchive/storage/multiprocessfunc.py:ne_sin,ne_sin,function,2,2,2,27,13.5,0,0,['x'],[None],[None],294,[],['ne.evaluate'],1
utilmy/zarchive/storage/multiprocessfunc.py:res_shared2,res_shared2,function,4,16,14,94,5.88,0,0,[],[],[],297,[],['float'],1
utilmy/zarchive/storage/multiprocessfunc.py:list_append,list_append,function,3,4,4,54,13.5,1,0,"['count', 'id', 'out_list']","[None, None, None]","[None, None, None]",261,"['\t""""""Creates an empty list and then appends a random number to the list \'count\' number of times. A CPU-heavy operation!""""""\n']",['range'],1
utilmy/zarchive/storage/panda_util.py:excel_topandas,excel_topandas,function,14,26,26,215,8.27,1,0,"['filein', 'fileout']","[None, None]","[None, None]",72,[],"['pd.ExcelFile', 'xls_file.parse', 'df.to_hdf', 'pd.HDFStore']",4
utilmy/zarchive/storage/panda_util.py:panda_toexcel,panda_toexcel,function,0,0,0,0,0.0,0,0,[],[],[],84,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:panda_todabatase,panda_todabatase,function,0,0,0,0,0.0,0,0,[],[],[],88,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:database_topanda,database_topanda,function,0,0,0,0,0.0,0,0,[],[],[],92,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:sqlquery_topanda,sqlquery_topanda,function,0,0,0,0,0.0,0,0,[],[],[],96,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:folder_topanda,folder_topanda,function,0,0,0,0,0.0,0,0,[],[],[],100,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:panda_tofolder,panda_tofolder,function,0,0,0,0,0.0,0,0,[],[],[],104,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:numpy_topanda,numpy_topanda,function,2,6,6,65,10.83,0,0,"['vv', 'fileout', 'colname']","[None, None, None]","[None, '""""', '""data""']",354,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zarchive/storage/panda_util.py:panda_tonumpy,panda_tonumpy,function,6,10,10,92,9.2,0,0,"['filename', 'nsize', 'tablen']","[None, None, None]","[None, None, ""'data'""]",357,[],['pd.read_hdf'],1
utilmy/zarchive/storage/panda_util.py:df_topanda,df_topanda,function,2,5,5,68,13.6,0,0,"[""vv, filenameh5, colname='data')""]",[''],"['\'data\'):  # \'E:\\_data\\_data_outlier.h5\'filenameh5); pdf= pd.DataFrame(vv); store.append(colname, pdf); store.close()filenameh5, colname=""data""):  # \'E:\\_data\\_data_outlier.h5\'fileoutlier,colname); return pdf.values   #to numpy vectorfilein1, filename, tablen=\'data\', lineterminator="",""): #Big CSV in Datachunksize =     10 * 10 ** 6filein1, chunksize=chunksize, lineterminator=lineterminator)for chunk in list01:']",361,[],"['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zarchive/storage/panda_util.py:load_frompanda,load_frompanda,function,2,5,5,68,13.6,0,0,"['filenameh5, colname=""data"")']",[''],"['""data""):  # \'E:\\_data\\_data_outlier.h5\'fileoutlier,colname); return pdf.values   #to numpy vectorfilein1, filename, tablen=\'data\', lineterminator="",""): #Big CSV in Datachunksize =     10 * 10 ** 6filein1, chunksize=chunksize, lineterminator=lineterminator)for chunk in list01:']",364,[],"['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zarchive/storage/panda_util.py:csv_topanda,csv_topanda,function,2,5,5,68,13.6,0,0,"['filein1, filename, tablen=\'data\', lineterminator="","")']",[''],"['\'data\', lineterminator="",""): #Big CSV in Datachunksize =     10 * 10 ** 6filein1, chunksize=chunksize, lineterminator=lineterminator)for chunk in list01:']",368,[],"['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zarchive/storage/panda_util.py:getrandom_tonumpy,getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample', 'tablen']","[None, None, None, None]","[None, None, None, ""'data'""]",377,[],['pd.read_hdf'],1
utilmy/zarchive/storage/panda_util.py:numexpr_topanda,numexpr_topanda,function,10,28,22,248,8.86,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",385,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/panda_util.py:excel_topanda,excel_topanda,function,14,26,26,215,8.27,1,0,"['filein', 'fileout']","[None, None]","[None, None]",397,"[""'''\n"", '\n', "">>> %timeit df3.reset_index().drop_duplicates(subset='index', keep='first').set_index('index')\n"", '1000 loops, best of 3: 1.54 ms per loop\n', '\n', '>>> %timeit df3.groupby(df3.index).first()\n', '1000 loops, best of 3: 580 s per loop\n', '\n', ""'''\n""]","['pd.ExcelFile', 'xls_file.parse', 'df.to_hdf', 'pd.HDFStore']",4
utilmy/zarchive/storage/panda_util.py:array_toexcel,array_toexcel,function,4,8,8,148,18.5,0,0,"['vv', 'wk', 'r1)subset', 'take_last=True)level=0))a)']","[None, None, None, '']","[None, None, ""'rownum'"", 'True)level=0))a):']",402,"[""'''\n"", '\n', "">>> %timeit df3.reset_index().drop_duplicates(subset='index', keep='first').set_index('index')\n"", '1000 loops, best of 3: 1.54 ms per loop\n', '\n', '>>> %timeit df3.groupby(df3.index).first()\n', '1000 loops, best of 3: 580 s per loop\n', '\n', ""'''\n""]","['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/storage/panda_util.py:unique_rows,unique_rows,function,4,8,8,148,18.5,0,0,['a'],[None],[None],432,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/storage/panda_util.py:remove_zeros,remove_zeros,function,0,0,0,0,0.0,0,0,[],[],[],436,[],[],0
utilmy/zarchive/storage/panda_util.py:sort_array,sort_array,function,0,0,0,0,0.0,0,0,[],[],[],438,[],[],0
utilmy/zarchive/storage/portfolio.py:data_jpsector,data_jpsector,function,3,4,4,47,11.75,0,0,[],[],[],49,[],['util.load_obj'],1
utilmy/zarchive/storage/portfolio.py:date_earningquater,date_earningquater,function,9,103,42,604,5.86,0,5,['t1'],[None],[None],62,[],['datetime.datetime'],1
utilmy/zarchive/storage/portfolio.py:date_is_3rdfriday,date_is_3rdfriday,function,4,14,13,67,4.79,0,0,['s'],[None],[None],81,[],"['datetime.strptime', 'd.weekday']",2
utilmy/zarchive/storage/portfolio.py:date_option_expiry,date_option_expiry,function,10,52,33,360,6.92,0,2,['date'],[None],[None],86,[],['datetime.datetime'],1
utilmy/zarchive/storage/portfolio.py:date_find_kday_fromintradaydate,date_find_kday_fromintradaydate,function,2,3,3,68,22.67,0,0,"['kintraday', 'intradaydate', 'dailydate']","[None, None, None]","[None, None, None]",103,[],['util.np_find'],1
utilmy/zarchive/storage/portfolio.py:date_find_kintraday_fromdate,date_find_kintraday_fromdate,function,4,10,10,88,8.8,0,0,"['d1', 'intradaydate1', 'h1', 'm1']","[None, None, None, None]","[None, None, '9', '30']",107,[],"['datetime.datetime', 'util.np_find']",2
utilmy/zarchive/storage/portfolio.py:date_find_intradateid,date_find_intradateid,function,8,13,13,101,7.77,1,0,"['datetimelist', 'stringdate']","[None, None]","[None, ""['20160420223000']""]",114,[],"['util.datestring_todatetime', 'util.np_find', 'str']",3
utilmy/zarchive/storage/portfolio.py:datetime_convertzone1_tozone2,datetime_convertzone1_tozone2,function,16,29,25,343,11.83,1,1,"['tt', 'fromzone', 'tozone']","[None, None, None]","[None, ""'Japan'"", ""'US/Eastern'""]",125,[],"['pytz.timezone', 'type', 'tz.localize', 't2.append']",4
utilmy/zarchive/storage/portfolio.py:date_extract_dailyopenclosetime,date_extract_dailyopenclosetime,function,23,51,35,431,8.45,2,3,"['spdateref1', 'market']","[None, None]","[None, ""'us'""]",143,[],"['enumerate', 'spdailyopendate.append', 'np.array', 'spdailyclosedate.append']",4
utilmy/zarchive/storage/portfolio.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],161,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/storage/portfolio.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",172,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/storage/portfolio.py:datetime_todate,datetime_todate,function,6,20,18,160,8.0,1,1,['tt'],[None],[None],181,[],"['isinstance', 'datetime.date', 'date2.append']",3
utilmy/zarchive/storage/portfolio.py:datetime_toint,datetime_toint,function,12,37,28,424,11.46,2,2,['datelist1'],[None],[None],190,[],"['isinstance', 'int', 'date2.append', 'datetime_tointhour', 'yy2.append', 'np.array']",6
utilmy/zarchive/storage/portfolio.py:datetime_tointhour,datetime_tointhour,function,7,20,19,234,11.7,1,1,['datelist1'],[None],[None],198,[],"['isinstance', 'int', 'yy2.append', 'np.array']",4
utilmy/zarchive/storage/portfolio.py:dateint_tostring,dateint_tostring,function,7,15,14,183,12.2,1,1,"['datelist1', 'format1']","[None, None]","[None, ""'%b-%y'""]",206,[],"['isinstance', 'dateint_todatetime', 'date2.append', 'np.array']",4
utilmy/zarchive/storage/portfolio.py:dateint_todatetime,dateint_todatetime,function,6,14,12,126,9.0,1,1,['datelist1'],[None],[None],228,[],"['isint', 'parser.parse', 'date2.append']",3
utilmy/zarchive/storage/portfolio.py:datenumpy_todatetime,datenumpy_todatetime,function,9,48,26,381,7.94,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",237,[],['type'],1
utilmy/zarchive/storage/portfolio.py:datetime_tonumpypdate,datetime_tonumpypdate,function,2,2,2,22,11.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",251,[],['np.datetime64'],1
utilmy/zarchive/storage/portfolio.py:date_diffindays,date_diffindays,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",257,[],['dateint_todatetime'],1
utilmy/zarchive/storage/portfolio.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",262,[],['util.np_findfirst'],1
utilmy/zarchive/storage/portfolio.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],276,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/storage/portfolio.py:date_as_float,date_as_float,function,12,32,26,311,9.72,0,2,['dt'],[None],[None],283,[],"['isint', 'dateint_todatetime', 'datetime.datetime', 'isleap', 'timedelta']",5
utilmy/zarchive/storage/portfolio.py:datediff_inyear,datediff_inyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",296,[],['date_as_float'],1
utilmy/zarchive/storage/portfolio.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",300,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/storage/portfolio.py:date_add_bdays,date_add_bdays,function,12,37,30,369,9.97,1,2,"['from_date', 'add_days']","[None, None]","[None, None]",311,[],"['type', 'dateint_todatetime', 'datestring_todatetime', 'datetime.timedelta', 'current_date.weekday']",5
utilmy/zarchive/storage/portfolio.py:date_getspecificdate,date_getspecificdate,function,21,203,58,1312,6.46,8,19,"['datelist', 'datetype1', 'outputype1', 'includelastdate', 'includefirstdate', '']","[None, None, None, None, None, None]","[None, '""yearend""', '""intdate""', 'True', 'False', None]",325,[],"['isint', 'dateint_todatetime', 'enumerate', 'vec2.append', 'np.mod', 'np.array']",6
utilmy/zarchive/storage/portfolio.py:date_alignfromdateref,date_alignfromdateref,function,9,18,14,152,8.44,0,0,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",386,[],['np.float'],1
utilmy/zarchive/storage/portfolio.py:_date_align,_date_align,function,15,35,27,203,5.8,2,2,"['dateref', 'datei', 'tmax', 'closei']","[None, None, None, None]","[None, None, None, None]",411,[],"['np.zeros', 'range', 'len']",3
utilmy/zarchive/storage/portfolio.py:date_align,date_align,function,9,18,14,152,8.44,0,0,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",429,"["" ''' #Aligne the price with the same dates\n"", "" date\tyear\tmonth\tday\td\topen\tclose\thigh\tlow\tvolume\taclose '''\n""]",['np.float'],1
utilmy/zarchive/storage/portfolio.py:min_withposition,min_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],478,[],['min'],1
utilmy/zarchive/storage/portfolio.py:max_withposition,max_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],482,[],['max'],1
utilmy/zarchive/storage/portfolio.py:_reshape,_reshape,function,2,14,12,68,4.86,0,1,['x'],[None],[None],488,[],"['len', 'np.reshape', 'np.size']",3
utilmy/zarchive/storage/portfolio.py:_notnone,_notnone,function,39,213,113,1775,8.33,1,11,"['x)', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5)', 'label', ""'Time'"", ""'Y')"", 'legendloc', 'dpi', 'isband=1) ']","['  return not x is Noneasset', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None, ""('title'"", None, None, '""upper left""', '150', '1) :']",492,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend']",23
utilmy/zarchive/storage/portfolio.py:plot_price,plot_price,function,86,347,207,3422,9.86,3,15,"['asset', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None]",496,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend', 'plot_priceintraday', 'np.loadtxt', 'np.unique', 'xdays.append', 'np.hstack', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plot_pricedate', 'type', 'datestring_todatetime', 'np.row_stack', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'ax.savefig']",43
utilmy/zarchive/storage/portfolio.py:plot_priceintraday,plot_priceintraday,function,32,59,57,947,16.05,1,0,['data'],[None],[None],575,[],"['np.loadtxt', 'np.unique', 'np.arange', 'xdays.append', 'np.hstack', 'plt.figure', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plt.show']",14
utilmy/zarchive/storage/portfolio.py:plot_pricedate,plot_pricedate,function,19,63,51,550,8.73,1,4,"['date1', 'sym1', 'asset1', 'sym2', 'bsk1', 'verticaldate', 'savename1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None', ""''"", '(10', None]",618,[],"['type', 'datestring_todatetime', 'np.row_stack', 'np.concatenate', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'len', 'np.arange', 'int', 'ax.savefig']",11
utilmy/zarchive/storage/portfolio.py:generate_sepvertical,generate_sepvertical,function,9,13,12,159,12.23,0,1,"['asset1', 'tt', 'tmax', 'start', 'datebar']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",701,[],"['np.zeros', 'util.datestring_todatetime']",2
utilmy/zarchive/storage/portfolio.py:save_asset_tofile,save_asset_tofile,function,31,129,87,978,7.58,5,9,"['file1', 'asset1', 'asset2', 'asset3', 'date1', 'title1']","[None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None']",716,[],"['np.shape', 'len', 'np.reshape', 'print', 'np.zeros', 'range', 'int', 'np.row_stack', 'np.savetxt']",9
utilmy/zarchive/storage/portfolio.py:load_asset_fromfile,load_asset_fromfile,function,1,4,4,51,12.75,0,0,['file1'],[None],[None],755,[],[],0
utilmy/zarchive/storage/portfolio.py:array_todataframe,array_todataframe,function,11,41,27,259,6.32,0,2,"['price', 'symbols', 'date1']","[None, None, None]","[None, 'None', 'None']",759,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/storage/portfolio.py:dataframe_toarray,dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],770,[],[],0
utilmy/zarchive/storage/portfolio.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],779,[],['float'],1
utilmy/zarchive/storage/portfolio.py:isint,isint,function,29,98,56,994,10.14,0,8,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) )matx', 'type1', 'type2=""correl"") ']","[' return isinstance(x', None, None, None, None, None, None, '']","[None, None, None, None, None, None, '""robust""', '""correl"") :']",787,[],"['matx.copy', 'x.mean', 'x.std', 'np.corrcoef', 'correl_inv.copy', 'np.sqrt']",6
utilmy/zarchive/storage/portfolio.py:correlation_mat,correlation_mat,function,29,98,56,994,10.14,0,8,"['matx', 'type1', 'type2']","[None, None, None]","[None, '""robust""', '""correl""']",794,[],"['matx.copy', 'x.mean', 'x.std', 'np.corrcoef', 'correl_inv.copy', 'np.sqrt']",6
utilmy/zarchive/storage/portfolio.py:correl_reducebytrigger,correl_reducebytrigger,function,9,22,18,128,5.82,2,1,"['correl2', 'trigger']","[None, None]","[None, None]",839,"[""  ''' Put Zero below trigger  '''\n""]","['correl2.copy', 'range', 'abs']",3
utilmy/zarchive/storage/portfolio.py:sk_cov_fromcorrel,sk_cov_fromcorrel,function,8,14,13,118,8.43,0,0,"['correl', 'ret_close1']","[None, None]","[None, None]",851,[],"['pf.volhisto_fromret', 'np.diag', 'np.dot']",3
utilmy/zarchive/storage/portfolio.py:cointegration,cointegration,function,18,47,37,385,8.19,0,0,"['x', 'y']","[None, None]","[None, None]",857,"['  """""" Output :\n', '    coint_t :t-statistic of unit-root test on residuals\n', ""    pvalue :   MacKinnon's approximate p-value based on MacKinnon (1994)\n"", '    crit_value : Critical values for the test statistic at the 1 %, 5 %, and 10 %  Signifiance levels.\n', '\n', '    The Null hypothesis is that there is no cointegration, the alt hypothesis is that there is cointegrating relationship. \n', '    If the pvalue is small, below a critical size:  Reject Null Hypothesis -->  Cointegration\n', '           pvalue is high --> No Cointegration    \n', '    \n', '    Significance level, also denoted as alpha or , is the probability of rejecting  the null hypothesis when it is true.\n', '    Probability of incorrectly rejecting a true null hypothesis\n', '\n', '    P=0.05  , At least 23% (and typically close to 50%)\n', '    P=0.01  , At least 7% (and typically close to 15%\n', '\n', '    (-2.9607012342275936,\n', '    0.038730981052330332, 0,\n', '    249,\n', ""    {'1%': -3.4568881317725864,\n"", ""       '10%': -2.5729936189738876,\n"", ""     '5%': -2.8732185133016057},\n"", '      601.96849256295991)\n', '        It can be seen that the calculated test statistic of -2.96 is smaller than the 5% critical value of -2.87, \n', ""        which means that we can reject the null hypothesis that  there isn't a cointegrating relationship at the 5% level.\n"", '  """"""\n']",['np.zeros'],1
utilmy/zarchive/storage/portfolio.py:causality_y1_y2,causality_y1_y2,function,10,14,13,153,10.93,0,0,"['price2', 'price1', 'maxlag']","[None, None, None]","[None, None, None]",895,[],[],0
utilmy/zarchive/storage/portfolio.py:rolling_cointegration,rolling_cointegration,function,13,29,26,280,9.66,0,0,"['x', 'y']","[None, None]","[None, None]",905,[],"['rolling_coint', 'pd.expanding_apply']",2
utilmy/zarchive/storage/portfolio.py:regression,regression,function,117,328,220,3116,9.5,6,7,"['yreturn', 'xreturn', 'type1']","[None, None, None]","[None, None, '""elasticv""']",924,"["" '''Y = X* reg.coef_  +  reg.intercept_, r2 '''\n""]","['len', 'yreturn.ravel', 'xreturn.reshape', 'reg.fit', 'F', 'reg.score', 'regression_fixedsymbolstock', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max', 'regression_getpricefromww', 'np.copy', 'np.zeros', 'regression_allstocks_vs_riskfactors', 'np.shape', 'print', 'np.arange', 'np.empty', 'enumerate', 'pf.getlogret_fromquotes', 'pf.regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",27
utilmy/zarchive/storage/portfolio.py:regression_fixedsymbolstock,regression_fixedsymbolstock,function,30,61,55,597,9.79,1,1,"['sym', 'ret_close2', 'tsstart', 'tsample', 'ret_spy', 'spyclose', 'regonly']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, 'True']",961,"["" ''' Price, Weight, R2, Error  '''\n""]","['len', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max']",7
utilmy/zarchive/storage/portfolio.py:regression_getpricefromww,regression_getpricefromww,function,20,38,30,298,7.84,3,0,"['spyclose', 'ww01', 'regasset01', 'ret_close2', 'tstart', 'tlag']","[None, None, None, None, None, None]","[None, None, None, None, None, '1']",984,[],"['np.copy', 'np.zeros', 'range', 'len']",4
utilmy/zarchive/storage/portfolio.py:regression_allstocks_vs_riskfactors,regression_allstocks_vs_riskfactors,function,65,137,113,1360,9.93,2,1,"['symstock', 'pricestock', 'symriskfac', 'priceriskfac', 'nlaglist']","[None, None, None, None, None]","[None, None, None, None, None]",1005,"["" '''Make Regression on all stocks ''' \n""]","['np.shape', 'print', 'np.arange', 'np.empty', 'len', 'enumerate', 'pf.getlogret_fromquotes', 'range', 'np.reshape', 'pf.regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",13
utilmy/zarchive/storage/portfolio.py:getdiff_fromquotes,getdiff_fromquotes,function,4,6,6,73,12.17,0,0,"['close', 'timelag']","[None, None]","[None, None]",1102,[],['np.shape'],1
utilmy/zarchive/storage/portfolio.py:getret_fromquotes,getret_fromquotes,function,7,23,17,159,6.91,0,1,"['close', 'timelag']","[None, None]","[None, '1']",1106,[],"['np.shape', 'len']",2
utilmy/zarchive/storage/portfolio.py:getlogret_fromquotes,getlogret_fromquotes,function,4,7,7,81,11.57,0,0,"['close', 'timelag']","[None, None]","[None, '1']",1117,[],"['np.shape', 'np.log']",2
utilmy/zarchive/storage/portfolio.py:getprice_fromret,getprice_fromret,function,12,23,21,190,8.26,2,0,"['ret', 'normprice']","[None, None]","[None, '100']",1122,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/storage/portfolio.py:price_normalize100,price_normalize100,function,16,43,36,292,6.79,1,1,"['ret', 'normprice']","[None, None]","[None, '100']",1134,[],"['np.shape', 'len', 'np.reshape', 'np.zeros', 'range', 'np.cumprod']",6
utilmy/zarchive/storage/portfolio.py:price_normalize_1d,price_normalize_1d,function,8,22,19,147,6.68,0,0,"['ret', 'normprice', 'dtype1']","[None, None, None]","[None, '100', ' np.float16']",1154,[],"['np.empty', 'np.cumprod']",2
utilmy/zarchive/storage/portfolio.py:norm_fast,norm_fast,function,7,8,8,85,10.62,0,0,"['y', 'ny']","[None, None]","[None, None]",1163,[],['ne.evaluate'],1
utilmy/zarchive/storage/portfolio.py:correl_fast,correl_fast,function,8,13,13,116,8.92,0,0,"['xn', 'y', 'nx']","[None, None, None]","[None, None, None]",1171,[],['ne.evaluate'],1
utilmy/zarchive/storage/portfolio.py:volhisto_fromret,volhisto_fromret,function,2,16,12,174,10.88,0,1,"['retbsk', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1179,[],"['len', 'np.std']",2
utilmy/zarchive/storage/portfolio.py:volhisto_fromprice,volhisto_fromprice,function,6,27,18,251,9.3,0,1,"['price', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1186,[],"['len', 'np.shape', 'np.std']",3
utilmy/zarchive/storage/portfolio.py:rsk_calc_all_TA,rsk_calc_all_TA,function,11,76,33,593,7.8,0,0,['df'],[None],"[""'panda_dataframe'""]",1198,"[""  '''Add All TA RMI, RSI To the '''\n""]",[],0
utilmy/zarchive/storage/portfolio.py:ta_lowbandtrend1,ta_lowbandtrend1,function,43,151,76,871,5.77,0,10,"['close2', 'type1']","[None, None]","[None, '0']",1238,"[""  '''Get lower band trend '''\n""]","['linearreg2', 'np.array', 'np.sum', 'util.np_findlocalmin2', 'len', 'util.sort', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",9
utilmy/zarchive/storage/portfolio.py:ta_highbandtrend1,ta_highbandtrend1,function,43,172,76,939,5.46,0,11,"['close2', 'type1']","[None, None]","[None, '0']",1280,[],"['linearreg', 'np.array', 'np.sum', 'util.np_findlocalmax2', 'len', 'util.sort', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",9
utilmy/zarchive/storage/portfolio.py:pd_transform_asset,pd_transform_asset,function,11,35,27,409,11.69,0,1,"['q0', 'q1', 'type1']","[None, None, None]","[None, None, '""spread""']",1329,[],"['util.pd_date_intersection', 'util.pd_array_todataframe', 'util.pd_insertcol']",3
utilmy/zarchive/storage/portfolio.py:calcbasket_table,calcbasket_table,function,25,59,53,477,8.08,1,2,"['wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps']","[None, None, None, None, None, None]","[None, None, '""table""', '""constant""', '1', ' 0.000']",1343,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.mod', 'np.sum']",6
utilmy/zarchive/storage/portfolio.py:folio_lowcorrelation,folio_lowcorrelation,function,145,431,300,3927,9.11,8,7,"['sym01', 'nstock', 'periodlist', 'dateref', 'close1', 'kbenchmark', 'badlist', 'costbppa', 'showgraph']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, '0.02', 'True']",1370,[],"['ww_selection', 'np.corrcoef', 'np.nan_to_num', 'np.zeros', 'range', 'util.np_sortbycol', 'int', 'np.std', 'np.isnan', 'util.find', 'np.sum', 'stk_select.append', 'pf.volhisto_fromret', 'sum', '1/len', 'pf.getret_fromquotes', 'len', 'np.empty', 'np.ones', 'enumerate', 'pf.calcbasket_table', 'pf.price_normalize100', 'np.column_stack', 'np.zeros_like', 'np.array', 'np.concatenate', 'print', 'str', 'pf.plot_price', 'sym01[int', 'pf.volhisto_fromprice', 'xrange', 'folio_inverseetf']",33
utilmy/zarchive/storage/portfolio.py:folio_inverseetf,folio_inverseetf,function,8,18,18,151,8.39,1,0,"['price', 'costpa']","[None, None]","[None, '0.0']",1510,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/storage/portfolio.py:folio_voltarget,folio_voltarget,function,2,6,6,61,10.17,0,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1519,[],['folio_volta'],1
utilmy/zarchive/storage/portfolio.py:folio_volta,folio_volta,function,17,46,37,443,9.63,2,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1523,[],"['folio_volta', 'np.shape', 'np.zeros', 'range', 'np.std', 'min']",6
utilmy/zarchive/storage/portfolio.py:folio_fixedweightprice,folio_fixedweightprice,function,13,36,33,225,6.25,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1538,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/storage/portfolio.py:folio_fixedweightret,folio_fixedweightret,function,13,31,28,193,6.23,2,0,"['ret', 'fixedww']","[None, None]","[None, None]",1550,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/storage/portfolio.py:folio_cost_turnover,folio_cost_turnover,function,17,38,32,278,7.32,1,1,"['wwall', 'bsk', 'dateref']","[None, None, None]","[None, None, None]",1563,[],"['len', 'xrange', 'np.sum']",3
utilmy/zarchive/storage/portfolio.py:folio_riskpa,folio_riskpa,function,21,55,47,437,7.95,2,1,"['ret', 'targetvol', 'volrange']","[None, None, None]","[None, '0.1', '90']",1577,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.sum', 'np.std', 'isfloat']",7
utilmy/zarchive/storage/portfolio.py:objective_criteria,objective_criteria,function,21,82,54,585,7.13,1,6,"['bsk', 'criteria', 'date1']","[None, None, None]","[None, None, 'None']",2009,[],"['np.sum', 'range', 'np.std', 'np.var']",4
utilmy/zarchive/storage/portfolio.py:calcbasket_obj,calcbasket_obj,function,31,76,62,510,6.71,2,3,"['wwvec', '*data']","[None, None]","[None, None]",2037,[],"['np.zeros', 'range', 'np.mod', 'weightcalc_generic', 'np.sum', 'objective_criteria']",6
utilmy/zarchive/storage/portfolio.py:calc_optimal_weight,calc_optimal_weight,function,1,6,6,40,6.67,0,0,"['args', 'bounds', 'maxiter']","[None, None, None]","[None, None, '1']",2062,[],[],0
utilmy/zarchive/storage/portfolio.py:fitness,fitness,function,6,12,12,75,6.25,0,0,['p'],[None],[None],2104,[],['10*cos'],1
utilmy/zarchive/storage/portfolio.py:np_countretsign,np_countretsign,function,6,18,18,80,4.44,1,1,['x'],[None],[None],2860,[],"['range', 'len', 'np.sign']",3
utilmy/zarchive/storage/portfolio.py:np_trendtest,np_trendtest,function,32,96,68,535,5.57,3,3,"['x', 'alpha ']","[None, None]","[None, ' 0.05']",2867,"['    """"""\n', '    This function is derived from code originally posted by Sat Kumar Tomer (satkumartomer@gmail.com)\n', '    See also: http://vsp.pnnl.gov/help/Vsample/Design_Trend_Mann_Kendall.htm\n', '    The purpose of the Mann-Kendall (MK) test (Mann 1945, Kendall 1975, Gilbert 1987) is to statistically assess if there is a monotonic upward or downward trend of the variable of interest over time. A monotonic upward (downward) trend means that the variable consistently increases (decreases) through time, but the trend may or may not be linear. The MK test can be used in place of a parametric linear regression analysis, which can be used to test if the slope of the estimated linear regression line is different from zero. The regression analysis requires that the residuals from the fitted regression line be normally distributed; an assumption not required by the MK test, that is, the MK test is a non-parametric (distribution-free) test.\n', '    Hirsch, Slack and Smith (1982, page 107) indicate that the MK test is best viewed as an exploratory analysis and is most appropriately used to identify stations where changes are significant or of large magnitude and to quantify these findings.\n', '    Input:\n', '        x:   a vector of data\n', '        alpha: significance level (0.05 default)\n', '    \n', '    Output:\n', '        trend: tells the trend (increasing, decreasing or no trend)\n', '        h: True (if trend is present) or False (if trend is absence)\n', '        p: p value of the significance test\n', '        z: normalized test statistics \n', '        \n', '    Examples x = np.random.rand(100) trend,h,p,z = mk_test(x,0.05) \n', '    """"""\n']","['len', 'range', 'np.sign', 'np.unique', 'np.zeros', 'sum', 'np.sum', 'abs', 'norm.ppf']",9
utilmy/zarchive/storage/portfolio.py:correl_rankbystock,correl_rankbystock,function,13,32,28,258,8.06,1,0,"['stkid', '5', '6]', 'correl', '0]', '[0', '1]]']","[None, None, None, None, None, None, None]","['[2', None, None, '[[1', None, None, None]",2922,"[' """""" Ranking of stocks by correlation """"""\n']","['np.zeros', 'enumerate', 'np.sum', 'util.sortcol']",4
utilmy/zarchive/storage/portfolio.py:calc_print_correlrank,calc_print_correlrank,function,25,164,88,1540,9.39,2,2,"['close2', 'symjp1', 'nlag', 'refindexname', 'toprank2', 'customnameid', 'customnameid2']","[None, None, None, None, None, None, None]","[None, None, None, None, '5', '[]', '[]']",2936,"["" ''' Most correlated/Un-correlated from One Risk Factor'''\n""]","['util.np_findfirst', 'pf.calc_ranktable', 'np.shape', 'print', 'util.np_find', 'enumerate', 'int', 'util.np_mergelist', 'pf.getret_fromquotes', 'pf.price_normalize100', 'pf.plot_price']",11
utilmy/zarchive/storage/portfolio.py:calc_ranktable,calc_ranktable,function,20,44,41,354,8.05,1,0,"['close2', 'symjp1', 'nlag', 'refindex', 'funeval', 'funargs']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",2987,[],"['np.zeros', 'pf.getlogret_fromquotes', 'enumerate', 'funeval', 'util.np_sortbycolumn']",5
utilmy/zarchive/storage/portfolio.py:similarity_correl,similarity_correl,function,7,10,9,91,9.1,0,0,"['ret_close2', 'funargs']","[None, None]","[None, None]",3007,[],['pf.correlation_mat'],1
utilmy/zarchive/storage/portfolio.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3062,[],['np_distance_l1'],1
utilmy/zarchive/storage/portfolio.py:np_distance_l1,np_distance_l1,function,2,6,6,37,6.17,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3068,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/storage/portfolio.py:imp_findticker,imp_findticker,function,10,16,14,113,7.06,1,0,"['tickerlist', 'sym01', 'symname']","[None, None, None]","[None, None, None]",3354,[],['v.append'],1
utilmy/zarchive/storage/portfolio.py:imp_close_dateref,imp_close_dateref,function,27,72,65,631,8.76,2,1,"['sym01', 'sdate', 'edate', 'datasource', 'typeprice']","[None, None, None, None, None]","[None, '20100101', '20160628', ""''"", '""close""']",3363,[],"['imp_yahooticker', 'start=str', 'str', 'util.listallfile', 'range', 'len', 'liststockname.append', 'pf.imp_txt_getquotes', 'enumerate', 'print', 'pf.date_align', 'util.a_cleanmemory']",12
utilmy/zarchive/storage/portfolio.py:imp_yahooticker,imp_yahooticker,function,23,45,42,485,10.78,1,1,"['symbols', 'start', 'end', 'type1']","[None, None, None, None]","[None, '""20150101""', '""20160101""', '1']",3391,[],"['datetime.datetime', 'int', 'enumerate', 'quotes_historical_yahoo_ochl', 'quotes.append', 'correctlist.append', 'errorlist.append', 'print']",8
utilmy/zarchive/storage/portfolio.py:imp_errorticker,imp_errorticker,function,11,29,27,291,10.03,1,0,"['symbols', 'start', 'end']","[None, None, None]","[None, '""20150101""', '""20160101""']",3414,[],"['datetime.datetime', 'int', 'quotes_historical_yahoo_ochl', 'errorlist.append', 'print']",5
utilmy/zarchive/storage/portfolio.py:imp_yahoo_financials_url,imp_yahoo_financials_url,function,7,32,23,276,8.62,0,2,"['ticker_symbol', 'statement', 'quarterly']","[None, None, None]","[None, '""is""', 'False']",3434,[],"['BeautifulSoup', 'sys.exit']",2
utilmy/zarchive/storage/portfolio.py:imp_yahoo_periodic_figure,imp_yahoo_periodic_figure,function,17,80,60,610,7.62,1,4,"['soup', 'yahoo_figure']","[None, None]","[None, None]",3442,[],"['re.compile', 'soup.find', 'sys.exit', 'row.find_all', 'int', 'values.append']",6
utilmy/zarchive/storage/portfolio.py:imp_googleIntradayQuoteSave,imp_googleIntradayQuoteSave,function,10,19,18,180,9.47,0,0,"['name1', 'date1', 'inter', 'tframe', 'dircsv']","[None, None, None, None, None]","[None, None, None, None, None]",3578,[],"['googleIntradayQuote', 'name1.replace', 'str', 'q.write_csv']",4
utilmy/zarchive/storage/portfolio.py:imp_googleQuoteSave,imp_googleQuoteSave,function,11,21,21,173,8.24,0,0,"['name1', 'date1', 'date2', 'dircsv']","[None, None, None, None]","[None, None, None, None]",3585,[],"['googleQuote', 'name1.replace', 'str', 'q.write_csv']",4
utilmy/zarchive/storage/portfolio.py:imp_googleQuoteList,imp_googleQuoteList,function,6,34,21,228,6.71,2,1,"['symbols', 'date1', 'date2', 'inter', 'tframe', 'dircsv', 'intraday1']","[None, None, None, None, None, None, None]","[None, None, None, '23400', '2000', ""''"", 'True']",3594,[],"['imp_googleIntradayQuoteSave', 'print', 'imp_googleQuoteSave']",3
utilmy/zarchive/storage/portfolio.py:pd_filterbydate,pd_filterbydate,function,6,35,21,318,9.09,0,3,"['df', 'dtref', ""start='2016-06-06 00"", ""end='2016-06-14 00"", 'freq', 'timezone']","[None, None, '', '', None, None]","[None, 'None', ""'2016-06-06 00:00:00'"", ""'2016-06-14 00:00:00'"", ""'0d0h05min'"", ""'Japan'""]",3609,"["" ''' df: DateSeries or TimeSeries of Quotes   '''\n""]","['type', 'pd.date_range']",2
utilmy/zarchive/storage/portfolio.py:imp_panda_db_dumpinfo,imp_panda_db_dumpinfo,function,15,32,28,274,8.56,1,0,"[""dbfile='E""]",[''],"[""'E:\\_data\\stock\\intraday_google.h5'""]",3624,[],"['pd.HDFStore', 'store.keys', 'pd.read_hdf', 'extract.append', 'errsym.append', 'np.array']",6
utilmy/zarchive/storage/portfolio.py:imp_numpyclose_frompandas,imp_numpyclose_frompandas,function,47,129,93,1105,8.57,2,6,"['dbfile', 'symlist', 't0', 't1', 'priceid', 'maxasset', 'tmax2']","[None, None, None, None, None, None, None]","[None, '[]', '20010101', '20010101', '""close""', '2500', '2000']",3639,[],"['print', 'np.zeros', 'pd.HDFStore', 'store.select', 'enumerate', 'len', 'util.find', 'qlist.append', 'sym.append', 'np.mod', 'date_align', 'np.shape', 'pf.date_align', 'xrange']",14
utilmy/zarchive/storage/portfolio.py:imp_quotes_fromtxt,imp_quotes_fromtxt,function,26,76,65,583,7.67,2,2,"['stocklist01', ""filedir='E"", 'startdate', 'endate']","[None, '', None, None]","[None, ""'E:/_data/stock/daily/20160610/jp'"", '20150101', '20160616']",3686,[],"['util.listallfile', 'len', 'x.split', 'util.np_findfirst', 'print', 'pd.read_csv', 'quotes.append']",7
utilmy/zarchive/storage/portfolio.py:imp_quotes_errordate,imp_quotes_errordate,function,8,25,17,222,8.88,2,1,"['quotes', 'dateref']","[None, None]","[None, None]",3716,"["" ''' Show Symbol in Error when importing '''\n""]","['enumerate', 'print', 'util.datetime_tostring', 'util.datetime_toint', 'str']",5
utilmy/zarchive/storage/portfolio.py:imp_getcsvname,imp_getcsvname,function,7,12,11,88,7.33,0,0,"['name1', 'date1', 'inter', 'tframe']","[None, None, None, None]","[None, None, None, None]",3728,[],['str'],1
utilmy/zarchive/storage/portfolio.py:imp_quote_tohdfs,imp_quote_tohdfs,function,20,55,44,510,9.27,1,1,"['sym', 'qqlist', 'filenameh5', 'fromzone', 'tozone']","[None, None, None, None, None]","[None, None, None, ""'Japan'"", ""'UTC'""]",3763,[],"['pd.HDFStore', 'enumerate', 'copy.deepcopy', 'datetime_toint', 'pf.imp_hdfs_getquote', 'type', 'store.append', 'pd.concat', 'qq.drop_duplicates', 'qq.sort', 'print', 'str', 'store.close']",13
utilmy/zarchive/storage/portfolio.py:date_todatetime,date_todatetime,function,1,9,9,58,6.44,0,0,['tlist'],[None],[None],3785,[],[],0
utilmy/zarchive/storage/portfolio.py:date_removetimezone,date_removetimezone,function,1,6,6,63,10.5,0,0,['datelist'],[None],[None],3791,[],[],0
utilmy/zarchive/storage/portfolio.py:imp_csvquote_topanda,imp_csvquote_topanda,function,13,41,35,508,12.39,0,1,"['file1', 'filenameh5', 'dfname', 'fromzone', 'tozone']","[None, None, None, None, None]","[None, None, ""'sym1'"", ""'Japan'"", ""'UTC'""]",3796,[],"['tz.gettz', 'pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",5
utilmy/zarchive/storage/portfolio.py:imp_panda_insertfoldercsv,imp_panda_insertfoldercsv,function,10,34,32,300,8.82,1,2,"['dircsv', ""filepd= r'E"", 'fromtimezone', 'tozone']","[None, '', None, None]","[None, "" r'E:\\_data\\stock\\intraday_google.h5'"", ""'Japan'"", ""'UTC'""]",3813,[],"['util.listallfile', 'util.str_isfloat', 'print', 'imp_csvquote_topanda']",4
utilmy/zarchive/storage/portfolio.py:imp_panda_checkquote,imp_panda_checkquote,function,4,8,8,70,8.75,1,0,['quotes'],[None],[None],3822,[],['np.shape'],1
utilmy/zarchive/storage/portfolio.py:imp_panda_getquote,imp_panda_getquote,function,2,7,6,59,8.43,0,0,"['filenameh5', 'dfname']","[None, None]","[None, '""data""']",3826,[],['pd.read_hdf'],1
utilmy/zarchive/storage/portfolio.py:imp_pd_merge_database,imp_pd_merge_database,function,12,27,22,321,11.89,1,0,"['filepdfrom', 'filepdto']","[None, None]","[None, None]",3831,[],"['pd.HDFStore', 'store0.keys', 'pf.imp_hdfs_getquote', 'store1.append', 'qq.drop_duplicates', 'qq.sort', 'print', 'store0.close', 'store1.close']",9
utilmy/zarchive/storage/portfolio.py:imp_panda_getListquote,imp_panda_getListquote,function,28,58,46,567,9.78,1,3,"['symbols', 'close1', ""start='12/18/2015 00"", ""end='3/1/2016 00"", 'freq', ""filepd= 'E"", 'tozone', 'fillna', 'interpo']","[None, None, '', '', None, '', None, None, None]","[None, ""'close'"", ""'12/18/2015 00:00:00+00:00'"", ""'3/1/2016 00:00:00+00:00'"", ""'0d0h10min'"", "" 'E:\\_data\\stock\\intraday_google.h5'"", ""'Japan'"", 'True', 'True']",3846,[],"['pd.date_range', 'imp_panda_getquote', 'type', 'errorsym.append', 'qq.fillna', 'qq.interpolate', 'quotes.append', 'correctsym.append', 'util.datenumpy_todatetime']",9
utilmy/zarchive/storage/portfolio.py:imp_panda_cleanquotes,imp_panda_cleanquotes,function,9,26,21,295,11.35,0,0,"['df', 'datefilter']","[None, None]","[None, None]",3891,[],"['df.sort', 'df.interpolate', 'close.fillna', 'np.array']",4
utilmy/zarchive/storage/portfolio.py:imp_panda_storecopy,imp_panda_storecopy,function,12,20,20,253,12.65,1,0,[],[],[],3901,[],"['pd.HDFStore', 'store.keys', 'pf.imp_hdfs_getquote', 'store2.append', 'store.close', 'store2.close']",6
utilmy/zarchive/storage/portfolio.py:imp_panda_removeDuplicate,imp_panda_removeDuplicate,function,11,26,20,269,10.35,1,0,"[""filepd=  'E""]",[''],"[""  'E:\\_data\\stock\\intraday_google.h5'""]",3920,[],"['pd.HDFStore', 'store.keys', 'store.select', 'qq.drop_duplicates', 'qq.sort', 'list', 'store.remove', 'store.append', 'store.close']",9
utilmy/zarchive/storage/portfolio.py:calc_statestock,calc_statestock,function,137,805,298,6715,8.34,22,14,"['close2', 'dateref', 'symfull']","[None, None, None]","[None, None, None]",3983,[],"['sort', 'util.sortcol', 'perf', 'and2', 'mar', 'np.mean', 'ma', 'dd', 'util.find', 'gap', 'pf.getret_fromquotes', 'len', 'np.shape', 'print', 'str', 'np.zeros', 'np.arange', '100*ma', 'pf.volhisto_fromprice', 'util.np_find_minpos', 'util.np_find_maxpos', 'range', 'int', 'pf.regression', 'pf.np_countretsign', 'util.np_findlocalmax2', 'util.np_findlocalmin2', 'util.sort', 'ta_highbandtrend1', 'ta_lowbandtrend1', 'pf.ta_highbandtrend1', 'pf.ta_lowbandtrend1', 'np.array']",33
utilmy/zarchive/storage/portfolio.py:imp_screening_addrecommend,imp_screening_addrecommend,function,19,48,40,412,8.58,1,3,"['string1', 'dbname']","[None, None]","[None, ""'stock_recommend'""]",4384,[],"['string1.replace', 'ss.replace', 'ss.split', 'copy.deepcopy', 'len', 'util.find', 'aux.append', 'util.load_obj', 'stock_recommend.append', 'util.save_obj']",10
utilmy/zarchive/storage/portfolio.py:imp_finviz,imp_finviz,function,53,369,159,4708,12.76,8,0,[],[],[],4411,[],"['requests.get', 'BeautifulSoup', 'soup.find_all', 'len', 'int', 'titlesarray.append', 'titlesarray.insert', 'while', 'str', 'page', 'secondsoup.find_all', 'alldata.append', 'open', 'csv.DictWriter', 'overview.writeheader', 'overview.writerow', 'imp_finviz_news', 'imp_finviz_financials', 'financial.writeheader', 'financial.writerow']",20
utilmy/zarchive/storage/portfolio.py:imp_finviz_news,imp_finviz_news,function,11,18,17,222,12.33,0,0,[],[],[],4468,[],"['requests.get', 'BeautifulSoup', 'soup.find_all']",3
utilmy/zarchive/storage/portfolio.py:imp_finviz_financials,imp_finviz_financials,function,47,187,139,2445,13.07,4,0,[],[],[],4479,[],"['requests.get', 'BeautifulSoup', 'soup.find_all', 'len', 'int', 'titlesarray.append', 'titlesarray.insert', 'while', 'str', 'page', 'secondsoup.find_all', 'alldata.append', 'open', 'csv.DictWriter', 'financial.writeheader', 'financial.writerow']",16
utilmy/zarchive/storage/portfolio.py:get_price2book,get_price2book,function,18,38,35,327,8.61,0,0,['symbol'],[None],[None],4539,[],"['bs', 'soup.find', 'pb.find_next', 'print']",4
utilmy/zarchive/storage/portfolio.py:index,index,class,145,447,285,3718,8.32,3,16,[],[],[],1605,[],[],0
utilmy/zarchive/storage/portfolio.py:searchSimilarity,searchSimilarity,class,178,505,335,4637,9.18,8,17,[],[],[],3072,[],[],0
utilmy/zarchive/storage/portfolio.py:Quote,Quote,class,33,73,53,1228,16.82,2,0,[],[],[],3479,[],[],0
utilmy/zarchive/storage/portfolio.py:googleIntradayQuote,googleIntradayQuote,class,23,51,42,757,14.84,1,2,[],[],[],3521,[],[],0
utilmy/zarchive/storage/portfolio.py:googleQuote,googleQuote,class,21,43,39,840,19.53,1,1,[],[],[],3556,[],[],0
utilmy/zarchive/storage/portfolio.py:index:__init__,index:__init__,method,11,12,12,121,10.08,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1606,[],['util.date_generatedatetime'],1
utilmy/zarchive/storage/portfolio.py:index:close,index:close,method,0,1,1,4,4.0,0,0,[],[],[],1611,[],[],0
utilmy/zarchive/storage/portfolio.py:index:updatehisto,index:updatehisto,method,2,12,11,62,5.17,0,0,[')'],['  #Download Quotespass) :'],[None],1614,[],['print'],1
utilmy/zarchive/storage/portfolio.py:index:help,index:help,method,2,12,11,62,5.17,0,0,[],[],[],1618,[],['print'],1
utilmy/zarchive/storage/portfolio.py:index:_statecalc,index:_statecalc,method,31,148,79,1115,7.53,2,7,"['self)', 'bsk)']","[' #Calculate Risk State Vector at each time treturn s1self', '']","[None, None]",1672,[],"['np.sum', 'range', 'np.std', 'np.arange']",4
utilmy/zarchive/storage/portfolio.py:index:_objective_criteria,index:_objective_criteria,method,31,148,79,1115,7.53,2,7,"['self', 'bsk']","[None, None]","[None, None]",1685,[],"['np.sum', 'range', 'np.std', 'np.arange']",4
utilmy/zarchive/storage/portfolio.py:index:calcbasket_obj,index:calcbasket_obj,method,31,65,58,547,8.42,1,3,"['self', 'wwvec']","[None, None]","[None, None]",1730,[],"['np.zeros', 'xrange', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'self._objective_criteria']",6
utilmy/zarchive/storage/portfolio.py:index:calc_optimal_weight,index:calc_optimal_weight,method,14,23,22,356,15.48,0,1,"['self', 'maxiter']","[None, None]","[None, '1']",1769,[],"['np.reshape', 'np.sum', 'print']",3
utilmy/zarchive/storage/portfolio.py:index:_weightcalc_generic,index:_weightcalc_generic,method,6,26,17,235,9.04,0,3,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",1781,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'self._weightcalc_regime2', 'print']",4
utilmy/zarchive/storage/portfolio.py:index:_weightcalc_constant,index:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",1787,[],['np.sum'],1
utilmy/zarchive/storage/portfolio.py:index:_weightcalc_regime2,index:_weightcalc_regime2,method,2,2,2,14,7.0,0,0,"['self', 'wwvec', 't)']","[None, None, '  #Hyper-Parameters Optimizationnbrange']","[None, None, 'self.nbrange;   nbregime= self.nbregime; masset= self.massetif t < nbrange:']",1791,[],[],0
utilmy/zarchive/storage/portfolio.py:searchSimilarity:__init__,searchSimilarity:__init__,method,15,18,17,193,10.72,0,0,"['self', ""filejpstock=r'E"", 'sym01', 'symname', 'startdate', 'enddate', 'pricetype']","[None, '', None, None, None, None, None]","[None, ""r'E:/_data/stock/daily/20160616/jp'"", ""['7203']"", ""['Toyota']"", ' 20150101', '20160601', '""close""']",3073,[],[],0
utilmy/zarchive/storage/portfolio.py:searchSimilarity:load_quotes_fromdb,searchSimilarity:load_quotes_fromdb,method,15,35,33,361,10.31,0,1,"['self', 'picklefile']","[None, None]","[None, ""''""]",3078,[],"['util.load_obj', 'pf.imp_txt_getquotes', 'pf.date_align', 'util.a_cleanmemory']",4
utilmy/zarchive/storage/portfolio.py:searchSimilarity:__generate_return__,searchSimilarity:__generate_return__,method,4,4,4,67,16.75,0,0,"['self', 'nlag']","[None, None]","[None, None]",3089,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/portfolio.py:searchSimilarity:__overweight__,searchSimilarity:__overweight__,method,17,62,41,412,6.65,2,4,"['self', 'px']","[None, None]","[None, None]",3093,[],"['len', 'np.ones', 'util.np_findlocalmax', 'type', 'np.abs', 'wwerr[max', 'util.np_findlocalmin']",7
utilmy/zarchive/storage/portfolio.py:searchSimilarity:set_searchcriteria,searchSimilarity:set_searchcriteria,method,34,79,63,799,10.11,0,5,"['self', 'name1', 'date1', 'date2', 'nlag', 'searchperiodstart', 'typesearch', '']","[None, None, None, None, None, None, None, None]","[None, ""'7203'"", '20160301', '20160601', '1', '20120101', '""pattern2""', None]",3113,[],"['pf.getret_fromquotes', 'date_finddateid', 'max', 'util.np_findfirst', 'print', 'pf.price_normalize_1d', 'len', 'self.__overweight__']",8
utilmy/zarchive/storage/portfolio.py:searchSimilarity:launch_search,searchSimilarity:launch_search,method,53,108,82,916,8.48,3,3,['self'],[None],[None],3142,[],"['len', 'np.zeros', 'range', 'pf.price_normalize_1d', 'np_similarity', 'util.np_sortbycolumn', 'enumerate']",7
utilmy/zarchive/storage/portfolio.py:searchSimilarity:show_comparison_graph,searchSimilarity:show_comparison_graph,method,33,72,63,688,9.56,1,3,"['self', 'maxresult', 'show_only_different_time', 'fromid', 'fromend', 'filenameout']","[None, None, None, None, None, None]","[None, '20', 'True', '0', ' 0', ""''""]",3176,[],"['np.shape', 'range', 'int', 'print', 'pf.price_normalize_1d', 'str', 'pf.plot_price']",7
utilmy/zarchive/storage/portfolio.py:searchSimilarity:staticmethod,searchSimilarity:staticmethod,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",3205,[],[],0
utilmy/zarchive/storage/portfolio.py:searchSimilarity:get_rankresult,searchSimilarity:get_rankresult,method,24,63,53,496,7.87,2,1,"['self', 'filetosave']","[None, None]","[None, ""''""]",3209,[],"['len', 'np.savetxt', 'np.shape', 'np.array', 'np.empty', 'range', 'int', 'str']",8
utilmy/zarchive/storage/portfolio.py:searchSimilarity:export_results,searchSimilarity:export_results,method,5,7,7,57,8.14,0,0,"['self', 'filename']","[None, None]","[None, None]",3231,[],"['open', 'self.to_csv', 'f.write']",3
utilmy/zarchive/storage/portfolio.py:Quote:__init__,Quote:__init__,method,3,9,9,120,13.33,0,0,['self'],[None],[None],3483,[],['range'],1
utilmy/zarchive/storage/portfolio.py:Quote:append,Quote:append,method,7,7,7,209,29.86,0,0,"['self', 'dt', 'open_', 'high', 'low', 'close', 'volume']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",3488,[],[],0
utilmy/zarchive/storage/portfolio.py:Quote:to_csv,Quote:to_csv,method,3,9,9,272,30.22,1,0,['self'],[None],[None],3497,[],['xrange'],1
utilmy/zarchive/storage/portfolio.py:Quote:write_csv,Quote:write_csv,method,5,7,7,57,8.14,0,0,"['self', 'filename']","[None, None]","[None, None]",3503,[],"['open', 'self.to_csv', 'f.write']",3
utilmy/zarchive/storage/portfolio.py:Quote:read_csv,Quote:read_csv,method,11,23,20,346,15.04,1,0,"['self', 'filename']","[None, None]","[None, None]",3508,[],"['range', 'open', 'line.rstrip', 'self.append']",4
utilmy/zarchive/storage/portfolio.py:Quote:__repr__,Quote:__repr__,method,2,2,2,19,9.5,0,0,['self'],[None],[None],3518,[],['self.to_csv'],1
utilmy/zarchive/storage/portfolio.py:googleIntradayQuote:__init__,googleIntradayQuote:__init__,method,22,49,40,699,14.27,1,2,"['self', 'symbol', 'interval_seconds', 'num_days']","[None, None, None, None]","[None, None, '300', '5']",3525,[],"['super', 'symbol.upper', 'requests.post', 'print', 'csv.splitlines', 'xrange', 'float', 'self.append']",8
utilmy/zarchive/storage/portfolio.py:googleQuote:__init__,googleQuote:__init__,method,20,41,37,760,18.54,1,1,"['self', 'symbol', 'start_date', 'end_date']","[None, None, None, None]","[None, None, None, 'datetime.date.today(']",3559,[],"['super', 'symbol.upper', 'datetime.date', 'start.strftime', 'urllib.urlopen', 'csv.reverse', 'print', 'xrange', 'isfloat', 'self.append']",10
utilmy/zarchive/storage/rec_data.py:_get_movielens_path,_get_movielens_path,function,2,3,3,79,26.33,0,0,[],[],[],14,"['    """"""\n', '    Get path to the movielens dataset file.\n', '    """"""\n']",[],0
utilmy/zarchive/storage/rec_data.py:_download_movielens,_download_movielens,function,9,18,18,207,11.5,1,0,['dest_path'],[None],[None],23,"['    """"""\n', '    Download the dataset.\n', '    """"""\n']","['requests.get', 'print', 'open', 'req.iter_content', 'fd.write']",5
utilmy/zarchive/storage/rec_data.py:_get_raw_movielens_data,_get_raw_movielens_data,function,8,13,13,233,17.92,0,1,[],[],[],38,"['    """"""\n', '    Return the raw lines of the train and test files.\n', '    """"""\n']","['_get_movielens_path', '_download_movielens', 'zipfile.ZipFile', 'datafile.read']",4
utilmy/zarchive/storage/rec_data.py:_parse,_parse,function,7,22,16,120,5.45,1,1,['data'],[None],[None],53,"['    """"""\n', '    Parse movielens dataset lines.\n', '    """"""\n']",['line.split'],1
utilmy/zarchive/storage/rec_data.py:_build_interaction_matrix,_build_interaction_matrix,function,12,19,19,130,6.84,1,1,"['rows', 'cols', 'data']","[None, None, None]","[None, None, None]",68,[],"['sp.lil_matrix', 'mat.tocoo']",2
utilmy/zarchive/storage/rec_data.py:_get_movie_raw_metadata,_get_movie_raw_metadata,function,8,12,12,190,15.83,0,1,[],[],[],80,"['    """"""\n', '    Get raw lines of the genre file.\n', '    """"""\n']","['_get_movielens_path', '_download_movielens', 'zipfile.ZipFile', 'datafile.read']",4
utilmy/zarchive/storage/rec_data.py:get_movielens_item_metadata,get_movielens_item_metadata,function,25,57,46,474,8.32,5,3,['use_item_ids'],[None],[None],94,"['    """"""\n', '    Build a matrix of genre features (no_items, no_features).\n', '\n', '    If use_item_ids is True, per-item feeatures will also be used.\n', '    """"""\n']","['set', '_get_movie_raw_metadata', 'line.split', 'int', 'zip', 'genres.append', 'genre_set.add', 'sp.lil_matrix', 'len', 'features.items']",10
utilmy/zarchive/storage/rec_data.py:get_dense_triplets,get_dense_triplets,function,7,8,8,139,17.38,0,0,"['uids', 'pids', 'nids', 'num_users', 'num_items']","[None, None, None, None, None]","[None, None, None, None, None]",136,[],['np.identity'],1
utilmy/zarchive/storage/rec_data.py:get_triplets,get_triplets,function,4,5,5,71,14.2,0,0,['mat'],[None],[None],144,[],['size=len'],1
utilmy/zarchive/storage/rec_data.py:get_movielens_data,get_movielens_data,function,18,30,27,335,11.17,1,0,[],[],[],149,"['    """"""\n', '    Return (train_interactions, test_interactions).\n', '    """"""\n']","['_get_raw_movielens_data', 'set', 'itertools.chain', '_parse', 'uids.add', 'iids.add', 'max', '_build_interaction_matrix']",8
utilmy/zarchive/storage/rec_metrics.py:predict,predict,function,3,5,4,131,26.2,0,0,"['model', 'uid', 'pids']","[None, None, None]","[None, None, None]",6,[],[],0
utilmy/zarchive/storage/rec_metrics.py:precision_at_k,precision_at_k,function,21,39,38,538,13.79,1,1,"['model', 'ground_truth', 'k', 'user_features', 'item_features']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",14,"['    """"""\n', '    Measure precision at k for model and ground truth.\n', '\n', '    Arguments:\n', '    - lightFM instance model\n', '    - sparse matrix ground_truth (no_users, no_items)\n', '    - int k\n', '\n', '    Returns:\n', '    - float precision@k\n', '    """"""\n']","['ground_truth.tocsr', 'np.arange', 'enumerate', 'np.empty', 'uid_array.fill', 'model.predict', 'set', 'precisions.append', 'float', 'sum', 'len']",11
utilmy/zarchive/storage/rec_metrics.py:full_auc,full_auc,function,21,34,32,398,11.71,1,1,"['model', 'ground_truth']","[None, None]","[None, None]",52,"['    """"""\n', '    Measure AUC for model and ground truth on all items.\n', '\n', '    Returns:\n', '    - float AUC\n', '    """"""\n']","['ground_truth.tocsr', 'np.arange', 'enumerate', 'predict', 'np.zeros', 'len', 'scores.append', 'sum']",8
utilmy/zarchive/storage/sobol.py:convert_csv2hd5f,convert_csv2hd5f,function,10,21,19,181,8.62,1,0,"['filein1', 'filename']","[None, None]","[None, None]",64,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/storage/sobol.py:getrandom_tonumpy,getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample']","[None, None, None]","[None, None, None]",77,[],['pd.read_hdf'],1
utilmy/zarchive/storage/sobol.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",93,[],['ne.evaluate'],1
utilmy/zarchive/storage/sobol.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],101,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/storage/sobol.py:getdvector,getdvector,function,7,21,20,150,7.14,1,0,"['dimmax', 'istart', 'idimstart']","[None, None, None]","[None, None, None]",130,[],['range'],1
utilmy/zarchive/storage/sobol.py:pathScheme_std,pathScheme_std,function,3,3,3,28,9.33,0,0,"['T', 'n', 'zz)', 'n+1)']","[None, None, '   #Standard Path generationn+1);  sdt', '']","[None, None, ' np.sqrt(T/n);  ww[0]= 01', None]",140,[],[],0
utilmy/zarchive/storage/sobol.py:pathScheme_bb,pathScheme_bb,function,18,32,30,200,6.25,1,0,"['T', 'n', 'zz)', 'kkmax+1)']","[None, None, '  #Brownian Bridge generationn); # sdt', '']","[None, None, ' np.sqrt(T/n);np.round(np.log(n)  * 1.4426950408889634)) # n= 2^kmaxh= n; jmax=1T)1', None]",148,[],"['int', 'range', 'np.sqrt']",3
utilmy/zarchive/storage/sobol.py:pathScheme_,pathScheme_,function,3,3,3,28,9.33,0,0,"['T', 'n', 'zz)', 'n+1)']","[None, None, '   #Standard Path generationn+1);  sdt', '']","[None, None, ' np.sqrt(T/n);  ww[0]= 01', None]",167,"[""'''\n"", 'ttdim=1024  # dim= 2^k\n', '[[500, testdensity(500, ttdim, 400,-1)],\n', '[1000, testdensity(1000, ttdim, 400,-1)],\n', '[2000, testdensity(2000, ttdim, 400,-1)], \n', '[3000, testdensity(3000, ttdim, 400,-1)],\n', '[4000, testdensity(4000, ttdim, 400,-1)]]\n', ""'''\n""]",[],0
utilmy/zarchive/storage/sobol.py:testdensity,testdensity,function,27,59,56,415,7.03,3,0,"['nsample', 'totdim', 'bin01', 'Ti']","[None, None, None, None]","[None, None, None, '-1']",177,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'dx.dN', 'np.sum']",8
utilmy/zarchive/storage/sobol.py:plotdensity,plotdensity,function,29,65,63,531,8.17,1,0,"['nsample', 'totdim', 'bin01', 'tit0', 'Ti']","[None, None, None, None, None]","[None, None, None, None, '-1']",195,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'dx.dN', 'plt.plot', 'plt.axis', 'plt.title']",10
utilmy/zarchive/storage/sobol.py:testdensity2d,testdensity2d,function,39,85,74,702,8.26,2,0,"['nsample', 'totdim', 'bin01', 'nbasset']","[None, None, None, None]","[None, None, None, None]",240,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'np.arange', 'np.histogram2d', 'dx.dN2d', 'np.meshgrid', 'plt.imshow', 'np.sum']",10
utilmy/zarchive/storage/sobol.py:lognormal_process2d,lognormal_process2d,function,2,5,4,49,9.8,0,0,"['a1', 'z1', 'a2', 'z2', 'k']","[None, None, None, None, None]","[None, None, None, None, None]",281,[],"['np.maximum', 'np.exp']",2
utilmy/zarchive/storage/sobol.py:testdensity2d2,testdensity2d2,function,40,91,80,750,8.24,2,0,"['nsample', 'totdim', 'bin01', 'nbasset', 'process01', 'a1', 'a2', 'kk']","[None, None, None, None, None, None, None, None]","[None, None, None, None, 'lognormal_process2d', '0.25', '0.25', '1']",287,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'np.arange', 'np.histogram2d', 'dx.dN2d', 'process01', 'np.meshgrid', 'plt.imshow', 'np.sum']",11
utilmy/zarchive/storage/sobol.py:call_process,call_process,function,15,30,28,245,8.17,1,0,"['a', 'z', 'k)', 'np.exp(a*z)-k)@jita', 'z', 'k)', '[np.exp(a*z) > k]', '[1])@jittotdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt=10)']","[None, None, ' return np.maximum(0', None, None, '  return np.piecewise(z', None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, None, None, None, '0.25', '-1', '10):']",335,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/sobol.py:binary_process,binary_process,function,15,30,28,245,8.17,1,0,"['a', 'z', 'k)', '[np.exp(a*z) > k]', '[1])@jittotdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt=10)']","[None, None, '  return np.piecewise(z', None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, '0.25', '-1', '10):']",339,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/sobol.py:pricing01,pricing01,function,15,30,28,245,8.17,1,0,"['totdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, '0.25', '-1', '10']",345,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/sobol.py:plotdensity2,plotdensity2,function,35,78,74,590,7.56,2,0,"['nsample', 'totdim', 'bin01', 'tit0', 'process01', 'vol', 'tt', 'Ti']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, '0.25', '5', '-1']",369,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'process01', 'call_process', 'plt.plot', 'plt.axis', 'plt.title']",11
utilmy/zarchive/storage/sobol.py:Plot2D_random_show,Plot2D_random_show,function,46,106,80,855,8.07,0,0,"['dir1', 'title1', 'dimxmax', 'dimymax', 'dimstep', 'samplejump', 'nsamplegraph']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",421,[],"['pd.read_hdf', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'plt.show', 'np.mean', 'np.var', 'comoment']",9
utilmy/zarchive/storage/sobol.py:Plot2D_random_save,Plot2D_random_save,function,51,106,77,723,6.82,2,0,"['dir1', 'title1', 'dimxmax', 'dimymax', 'dimstep', 'samplejump', 'nsamplegraph', '']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",468,[],"['range', 'pd.read_hdf', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",8
utilmy/zarchive/storage/sobol.py:getoutlier_fromrandom,getoutlier_fromrandom,function,57,168,111,1242,7.39,2,2,"['filename', 'jmax1', 'imax1', 'isamplejum', 'nsample', ""fileoutlier=   'E""]","[None, None, None, None, None, '']","[None, None, None, None, None, ""   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'""]",518,[],"['range', 'pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'unique_rows', 'store.append', 'store.close']",7
utilmy/zarchive/storage/sobol.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, None, None, None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",586,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/sobol.py:getoutlier_fromrandom_fast,getoutlier_fromrandom_fast,function,71,183,130,1320,7.21,2,2,"['filename', 'jmax1', 'imax1', 'isamplejum', 'nsample', 'trigger1', ""fileoutlier=   'E""]","[None, None, None, None, None, None, '']","[None, None, None, None, None, '0.28', ""   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'""]",606,[],"['np.zeros', 'range', 'ne.evaluate', 'pd.HDFStore', 'store.append', 'store.close']",6
utilmy/zarchive/storage/sobol.py:outlier_clean,outlier_clean,function,7,16,15,98,6.12,1,1,['vv2'],[None],[None],674,[],['range'],1
utilmy/zarchive/storage/sobol.py:overwrite_data,overwrite_data,function,6,11,9,112,10.18,0,0,"['fileoutlier', 'vv2']","[None, None]","[None, None]",682,[],"['pd.HDFStore', 'store.remove', 'store.append', 'store.close']",4
utilmy/zarchive/storage/sobol.py:doublecheck_outlier,doublecheck_outlier,function,69,163,121,1260,7.73,1,1,"['fileoutlier', 'ijump', 'nsample', 'trigger1', '']","[None, None, None, None, None]","[None, None, '4000', '0.1', None]",702,[],"['pd.read_hdf', 'np.zeros', 'np.shape', 'range', 'ne.evaluate', 'pd.HDFStore', 'store.append', 'store.close']",8
utilmy/zarchive/storage/sobol.py:plot_outlier,plot_outlier,function,19,32,32,287,8.97,0,0,"['fileoutlier', 'kk']","[None, None]","[None, None]",762,[],"['pd.read_hdf', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",7
utilmy/zarchive/storage/sobol.py:permute,permute,function,24,64,53,631,9.86,2,0,"['yy', 'kmax']","[None, None]","[None, None]",845,[],"['int', 'np.copy', 'range', 'permute2', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'comoment']",9
utilmy/zarchive/storage/sobol.py:permute2,permute2,function,18,42,41,461,10.98,1,0,"['xx', 'yy', 'kmax']","[None, None, None]","[None, None, None]",858,[],"['int', 'np.copy', 'range', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'comoment']",8
utilmy/zarchive/storage/stateprocessor.py:sort,sort,function,5,8,8,84,10.5,0,0,"['x', 'col', 'asc)', 'col', 'asc)close', 't0', 't1)', 't1] / close2[', 't0] -1)tuple1)', 'symfull=symfull) ', 'symfull)  # 607close', 't0', 't1', 'lag)']","[None, None, ' return   util.sortcol(x', None, None, None, '  return  100*( close2[:', '', '  return np.logical_and.reduce(tuple1)x', '', None, None, None, '']","[None, None, None, None, None, None, None, None, None, 'symfull) : return util.find(x', None, None, None, None]",8,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/stateprocessor.py:perf,perf,function,5,8,8,84,10.5,0,0,"['close', 't0', 't1)', 't1] / close2[', 't0] -1)tuple1)', 'symfull=symfull) ', 'symfull)  # 607close', 't0', 't1', 'lag)']","[None, None, '  return  100*( close2[:', '', '  return np.logical_and.reduce(tuple1)x', '', None, None, None, '']","[None, None, None, None, None, 'symfull) : return util.find(x', None, None, None, None]",9,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/stateprocessor.py:and2,and2,function,5,8,8,84,10.5,0,0,"['tuple1)', 'symfull=symfull) ', 'symfull)  # 607close', 't0', 't1', 'lag)']","['  return np.logical_and.reduce(tuple1)x', '', None, None, None, '']","[None, 'symfull) : return util.find(x', None, None, None, None]",10,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/stateprocessor.py:ff,ff,function,5,8,8,84,10.5,0,0,"['x', 'symfull=symfull) ', 'symfull)  # 607close', 't0', 't1', 'lag)']","[None, '', None, None, None, '']","[None, 'symfull) : return util.find(x', None, None, None, None]",12,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/stateprocessor.py:gap,gap,function,5,8,8,84,10.5,0,0,"['close', 't0', 't1', 'lag']","[None, None, None, None]","[None, None, None, None]",15,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/stateprocessor.py:process_stock,process_stock,function,15,41,30,261,6.37,2,2,"['stkstr', 'show1']","[None, None]","[None, '1']",20,[],"['stkstr.split', 'enumerate', 'x.strip', 'list', 'v.sort']",5
utilmy/zarchive/storage/stateprocessor.py:printn,printn,function,19,44,39,364,8.27,1,0,"['ss', 'symfull', 's1']","[None, None, None]","[None, 'symfull', 's1']",33,[],"['util.sortcol', 'range', 'len', 'int', 'aux2.append', 'round']",6
utilmy/zarchive/storage/stateprocessor.py:show,show,function,10,144,88,862,5.99,1,2,"['ll', 's1']","[None, None]","[None, 's1']",50,[],['type'],1
utilmy/zarchive/storage/stateprocessor.py:get_treeselect,get_treeselect,function,48,110,86,745,6.77,2,3,"['stk', 's1', 'xnewdata', 'newsample', 'show1', 'nbtree', 'depthtree']","[None, None, None, None, None, None, None]","[None, 's1', 'None', '5', '1', '5', '10']",82,[],"['process_stock', 'util.find', 'np.array', 'range', 'np.shape', 'np.row_stack', 'np.ones', 'np.concatenate', 'np.max', 'np.min', 'util.sk_tree', 'np.sum', 'clfrf.predict', 'print']",14
utilmy/zarchive/storage/stateprocessor.py:store_patternstate,store_patternstate,function,14,25,25,236,9.44,1,0,"['tree', 'sym1', 'theme', 'symfull']","[None, None, None, None]","[None, None, None, 'symfull']",111,[],"['util.find', 'lstate.append', 'np.array', 'str', 'util.save_obj']",5
utilmy/zarchive/storage/stateprocessor.py:load_patternstate,load_patternstate,function,7,10,7,70,7.0,0,0,['name1'],[None],[None],125,[],['util.load_obj'],1
utilmy/zarchive/storage/stateprocessor.py:get_stocklist,get_stocklist,function,19,40,35,338,8.45,1,2,"['clf', 's11', 'initial', 'show1']","[None, None, None, None]","[None, None, None, '1']",130,[],"['process_stock', 'clf.predict', 'enumerate', 'str', 'laux.append', 'list', 'aux2.sort']",7
utilmy/zarchive/storage/symbolicmath.py:spp,spp,function,19,61,27,221,3.62,0,8,"[')', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', ""a8=''  )""]","[""\tprint'\\n\\n_________________________'a0"", None, None, None, None, None, None, None, '']","[None, ""''"", ""''"", ""''"", ""''"", ""''"", ""''"", ""''"", ""''  ):""]",66,[],['spp'],1
utilmy/zarchive/storage/symbolicmath.py:print2,print2,function,19,61,27,221,3.62,0,8,"['a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8']","[None, None, None, None, None, None, None, None, None]","[None, ""''"", ""''"", ""''"", ""''"", ""''"", ""''"", ""''"", ""''""]",68,[],['spp'],1
utilmy/zarchive/storage/symbolicmath.py:factorpoly,factorpoly,function,7,10,9,75,7.5,1,0,['pp'],[None],[None],87,[],"['rr=roots', 'rr.iteritems']",2
utilmy/zarchive/storage/symbolicmath.py:EEvarbrownian,EEvarbrownian,function,12,114,46,895,7.85,0,0,['ff1d'],[None],[None],104,[],"['symbols', 'factor', 'exp', 'Integral', 'ee.doit', 'simplify', '1/sqrt', 'ee.subs', 'vv.doit', 'vv.subs', 'EEvarbrownian2d']",11
utilmy/zarchive/storage/symbolicmath.py:EEvarbrownian2d,EEvarbrownian2d,function,11,60,36,482,8.03,0,0,['ff'],[None],[None],126,[],"['symbols', 'factor', 'exp', 'Integral', 'ee.doit', 'simplify', 'ee.subs', 'vv.doit', 'vv.subs']",9
utilmy/zarchive/storage/symbolicmath.py:lagrangian2d,lagrangian2d,function,12,50,45,592,11.84,1,0,['ll'],[None],[None],168,[],"['simplify', 'print2', 'solvers.solve', 'range', 'res.__len__', 'str']",6
utilmy/zarchive/storage/symbolicmath.py:decomposecorrel,decomposecorrel,function,16,47,39,402,8.55,0,0,['m1'],[None],[None],195,[],"['factor', 'print2', 'm1.eigenvals', 'm1.eigenvects', 'simplify', 'm1.LDLdecomposition']",6
utilmy/zarchive/storage/symbolicmath.py:nn,nn,function,3,26,21,196,7.54,0,1,['x'],[None],[None],233,[],"['1/sqrt', 'nn2', 'abs', 'Integral']",4
utilmy/zarchive/storage/symbolicmath.py:nn2,nn2,function,2,20,18,129,6.45,0,1,"['x', 'y', 'p']","[None, None, None]","[None, None, None]",236,[],"['abs', 'Integral']",2
utilmy/zarchive/storage/symbolicmath.py:dnn2,dnn2,function,1,3,3,54,18.0,0,0,"['x', 'y', 'p']","[None, None, None]","[None, None, None]",241,[],['exp'],1
utilmy/zarchive/storage/symbolicmath.py:dnn,dnn,function,2,7,6,95,13.57,0,0,"['x', 'y', 'p']","[None, None, None]","[None, None, None]",245,[],"['exp', 'dnn', '1/sqrt']",3
utilmy/zarchive/storage/symbolicmath.py:taylor2,taylor2,function,11,24,22,197,8.21,1,0,"['ff', 'x0', 'n']","[None, None, None]","[None, None, None]",249,[],"['simplify', 'range', 'Derivative', 'dffk.doit']",4
utilmy/zarchive/storage/symbolicmath.py:diffn,diffn,function,7,11,11,111,10.09,0,0,"['ff', 'x0', 'kk']","[None, None, None]","[None, None, None]",260,[],"['Derivative', 'simplify', 'dffk.doit']",3
utilmy/zarchive/storage/symbolicmath.py:dN,dN,function,1,2,2,29,14.5,0,0,['x'],[None],[None],270,[],['1/sqrt'],1
utilmy/zarchive/storage/symbolicmath.py:N,N,function,1,5,5,51,10.2,0,0,['x'],[None],[None],273,[],['1/sqrt'],1
utilmy/zarchive/storage/symbolicmath.py:d1f,d1f,function,2,14,12,68,4.86,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",276,[],"['log', 'sqrt']",2
utilmy/zarchive/storage/symbolicmath.py:d2f,d2f,function,2,14,12,68,4.86,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",281,[],"['log', 'sqrt']",2
utilmy/zarchive/storage/symbolicmath.py:d1xf,d1xf,function,2,8,8,28,3.5,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",286,[],['sqrt'],1
utilmy/zarchive/storage/symbolicmath.py:d2xf,d2xf,function,2,8,8,28,3.5,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",289,[],['sqrt'],1
utilmy/zarchive/storage/symbolicmath.py:bsbinarycall,bsbinarycall,function,6,11,11,61,5.55,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",293,[],"['d2f', 'exp']",2
utilmy/zarchive/storage/symbolicmath.py:bscall,bscall,function,8,15,14,109,7.27,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",299,[],"['d1f', 'vol*sqrt', 's0*exp', 'K*exp']",4
utilmy/zarchive/storage/symbolicmath.py:bsput,bsput,function,7,15,14,112,7.47,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",306,[],"['d1f', 'vol*sqrt', 'K*exp']",3
utilmy/zarchive/storage/symbolicmath.py:bs,bs,function,38,337,112,1970,5.85,1,2,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",313,[],"['d2f', 'exp', 'bscall', 'd1f', 'vol*sqrt', 's0*exp', 'K*exp', 'bsput', 'bs', 'bsdelta', 'N', 'bsstrikedelta', 'bsstrikegamma', 'sqrt', 'bsgamma', 'bstheta', 'St*exp', 'bsrho', 'bsvega', 'dN', 'bsdvd', 'bsvanna', 'bsvolga', 'bsgammaspot']",24
utilmy/zarchive/storage/symbolicmath.py:bsdelta,bsdelta,function,11,27,25,132,4.89,1,1,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",320,[],"['d1f', 'exp', 'N']",3
utilmy/zarchive/storage/symbolicmath.py:bsstrikedelta,bsstrikedelta,function,7,28,22,158,5.64,0,1,"['s0', 'K', 't', 'T', 'r', 'd', 'vol', 'cp1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",328,[],"['d2f', 'exp']",2
utilmy/zarchive/storage/symbolicmath.py:bsstrikegamma,bsstrikegamma,function,4,19,19,96,5.05,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",337,[],"['d1f', 'exp', 'sqrt']",3
utilmy/zarchive/storage/symbolicmath.py:bsgamma,bsgamma,function,4,19,19,96,5.05,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",341,[],"['d1f', 'exp', 'sqrt']",3
utilmy/zarchive/storage/symbolicmath.py:bstheta,bstheta,function,5,20,19,98,4.9,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",345,[],"['d1f', 'St*exp', 'sqrt', 'N']",4
utilmy/zarchive/storage/symbolicmath.py:bsrho,bsrho,function,6,14,13,65,4.64,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",351,[],"['sqrt', 'exp', 'N']",3
utilmy/zarchive/storage/symbolicmath.py:bsvega,bsvega,function,4,13,13,70,5.38,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",356,[],"['d1f', 'St*exp', 'sqrt', 'dN']",4
utilmy/zarchive/storage/symbolicmath.py:bsdvd,bsdvd,function,3,16,15,72,4.5,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",361,[],"['d1f', 'exp', 'N']",3
utilmy/zarchive/storage/symbolicmath.py:bsvanna,bsvanna,function,6,16,15,79,4.94,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",366,[],"['d1f', 'sqrt', 'dN']",3
utilmy/zarchive/storage/symbolicmath.py:bsvolga,bsvolga,function,7,18,16,94,5.22,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",372,[],"['d1f', 'sqrt', 'St*exp', 'dN']",4
utilmy/zarchive/storage/symbolicmath.py:bsgammaspot,bsgammaspot,function,4,18,18,118,6.56,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",378,[],"['d1f', 'exp']",2
utilmy/zarchive/storage/technical_indicator.py:np_find,np_find,function,5,11,10,55,5.0,1,1,"['item', 'vec']","[None, None]","[None, None]",5,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/storage/technical_indicator.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],12,[],['min'],1
utilmy/zarchive/storage/technical_indicator.py:np_find_maxpos,np_find_maxpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],16,[],['max'],1
utilmy/zarchive/storage/technical_indicator.py:date_earningquater,date_earningquater,function,4,15,13,96,6.4,0,1,"['t1)', '12] ']","['   #JP Morgan Qearing datet1.month', '']","['=10 and t1.day >= 14) or (t1.month==1 and t1.day < 14) or t1.month in [11', None]",20,[],['datetime'],1
utilmy/zarchive/storage/technical_indicator.py:date_option_expiry,date_option_expiry,function,10,60,33,387,6.45,0,2,['date'],[None],[None],39,[],['datetime'],1
utilmy/zarchive/storage/technical_indicator.py:linearreg,linearreg,function,11,11,11,57,5.18,0,0,"['a', '*args']","[None, None]","[None, None]",57,[],['np.sum'],1
utilmy/zarchive/storage/technical_indicator.py:np_sortbycolumn,np_sortbycolumn,function,6,8,8,70,8.75,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",62,[],"['pd.DataFrame', 'df.sort']",2
utilmy/zarchive/storage/technical_indicator.py:np_findlocalmax,np_findlocalmax,function,22,47,34,233,4.96,1,3,['v'],[None],[None],68,[],"['n=len', 'np.zeros', 'enumerate', 'np_sortbycolumn', 'np_find_maxpos']",5
utilmy/zarchive/storage/technical_indicator.py:findhigher,findhigher,function,5,12,11,54,4.5,1,1,"['item', 'vec']","[None, None]","[None, None]",82,[],['xrange'],1
utilmy/zarchive/storage/technical_indicator.py:findlower,findlower,function,5,12,11,54,4.5,1,1,"['item', 'vec']","[None, None]","[None, None]",87,[],['xrange'],1
utilmy/zarchive/storage/technical_indicator.py:np_findlocalmin,np_findlocalmin,function,24,50,37,250,5.0,1,3,['v'],[None],[None],93,[],"['n=len', 'np.zeros', 'enumerate', 'np_sortbycolumn', 'np_find_minpos']",5
utilmy/zarchive/storage/technical_indicator.py:supportmaxmin1,supportmaxmin1,function,115,500,206,3613,7.23,2,11,['df1'],[None],[None],113,[],"['np_findlocalmax', 'len', 'np_find_maxpos', 'range', 'findhigher', 'np.abs', 'np.shape', 'np.arange', 'min', 'np.zeros', 'max', 'np_findlocalmin', 'np_find_minpos', 'findlower', 'pd.Series', 'df1.join']",16
utilmy/zarchive/storage/technical_indicator.py:RET,RET,function,10,21,16,123,5.86,0,0,"['df', 'n']","[None, None]","[None, None]",265,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:qearning_dist,qearning_dist,function,19,38,32,317,8.34,1,0,['df'],[None],[None],274,[],"['np.zeros', 'enumerate', 'date_earningquater', 'pd.Series', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:optionexpiry_dist,optionexpiry_dist,function,15,26,23,212,8.15,1,0,['df'],[None],[None],287,[],"['np.zeros', 'enumerate', 'date_option_expiry', 'pd.Series', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:nbtime_reachtop,nbtime_reachtop,function,17,34,31,284,8.35,1,0,"['df', 'n', 'trigger']","[None, None, None]","[None, None, '0.005']",298,"[""  '''nb of days from 1 year low '''\n""]","['np.zeros', 'range', 'len', 'np_find_maxpos', 'np.abs', 'np.sign', 'pd.Series', 'str', 'df.join']",9
utilmy/zarchive/storage/technical_indicator.py:nbday_high,nbday_high,function,20,39,32,333,8.54,1,0,"['df', 'n']","[None, None]","[None, None]",312,"[""  '''nb of days from 1 year low '''\n""]","['np.zeros', 'range', 'len', 'np_find_maxpos', 'pd.Series', 'str', 'df.join']",7
utilmy/zarchive/storage/technical_indicator.py:distance_day,distance_day,function,14,28,24,192,6.86,1,0,"['df', 'tk', 'tkname']","[None, None, None]","[None, None, None]",328,[],"['datetime.date', 'np.zeros', 'range', 'len', 'pd.Series', 'df.join']",6
utilmy/zarchive/storage/technical_indicator.py:distance,distance,function,16,44,36,298,6.77,1,0,"['df', 'tk', 'tkname']","[None, None, None]","[None, None, None]",339,[],"['datetime.date', 'np.zeros', 'range', 'len', 'pd.Series', 'df.join', 'distance']",7
utilmy/zarchive/storage/technical_indicator.py:MA,MA,function,5,12,10,86,7.17,0,0,"['df', 'n']","[None, None]","[None, None]",346,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:EMA,EMA,function,5,16,14,102,6.38,0,0,"['df', 'n']","[None, None]","[None, None]",352,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:MOM,MOM,function,5,11,9,79,7.18,0,0,"['df', 'n']","[None, None]","[None, None]",358,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:ROC,ROC,function,9,20,15,111,5.55,0,0,"['df', 'n']","[None, None]","[None, None]",364,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:ATR,ATR,function,12,47,32,280,5.96,1,0,"['df', 'n']","[None, None]","[None, None]",372,[],"['max', 'df.get_value', 'min', 'TR_l.append', 'pd.Series', 'str', 'df.join']",7
utilmy/zarchive/storage/technical_indicator.py:BBANDS,BBANDS,function,10,41,25,261,6.37,0,0,"['df', 'n']","[None, None]","[None, None]",385,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:PPSR,PPSR,function,14,55,37,378,6.87,0,0,['df'],[None],[None],398,[],"['pd.Series', 'pd.DataFrame', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:STOK,STOK,function,5,13,11,98,7.54,0,0,['df'],[None],[None],412,[],"['pd.Series', 'df.join']",2
utilmy/zarchive/storage/technical_indicator.py:STO,STO,function,7,40,24,282,7.05,0,0,['df'],[None],[None],418,[],"['pd.Series', 'df.join', 'STO', 'str']",4
utilmy/zarchive/storage/technical_indicator.py:TRIX,TRIX,function,14,58,33,286,4.93,1,0,"['df', 'n']","[None, None]","[None, None]",425,[],"['pd.ewma', 'ROC_l.append', 'pd.Series', 'str', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:ADX,ADX,function,25,152,68,821,5.4,2,2,"['df', 'n', 'n_ADX']","[None, None, None]","[None, None, None]",440,[],"['df.get_value', 'UpI.append', 'DoI.append', 'max', 'min', 'TR_l.append', 'pd.Series', 'str', 'df.join']",9
utilmy/zarchive/storage/technical_indicator.py:MACD,MACD,function,9,57,32,465,8.16,0,0,"['df', 'n_fast', 'n_slow']","[None, None, None]","[None, None, None]",473,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:MassI,MassI,function,11,34,22,202,5.94,0,0,['df'],[None],[None],485,[],"['pd.ewma', 'pd.Series', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:Vortex,Vortex,function,14,72,36,456,6.33,2,0,"['df', 'n']","[None, None]","[None, None]",495,[],"['max', 'df.get_value', 'min', 'TR.append', 'abs', 'VM.append', 'pd.Series', 'pd.rolling_sum', 'str', 'df.join']",10
utilmy/zarchive/storage/technical_indicator.py:KST,KST,function,13,83,42,485,5.84,0,0,"['df', 'r1', 'r2', 'r3', 'r4', 'n1', 'n2', 'n3', 'n4']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None]",513,[],"['pd.Series', 'pd.rolling_sum', 'str', 'df.join']",4
utilmy/zarchive/storage/technical_indicator.py:RSI,RSI,function,19,103,46,512,4.97,1,2,"['df', 'n']","[None, None]","[None, '14']",531,[],"['df.get_value', 'UpI.append', 'DoI.append', 'pd.Series', 'str', 'df.join']",6
utilmy/zarchive/storage/technical_indicator.py:RMI,RMI,function,20,102,50,567,5.56,1,2,"['df', 'n', 'm']","[None, None, None]","[None, '14', '10']",558,[],"['list', 'df.get_value', 'UpI.append', 'DoI.append', 'pd.Series', 'str', 'df.join']",7
utilmy/zarchive/storage/technical_indicator.py:TSI,TSI,function,12,52,31,333,6.4,0,0,"['df', 'r', 's']","[None, None, None]","[None, None, None]",588,[],"['pd.Series', 'abs', 'str', 'df.join']",4
utilmy/zarchive/storage/technical_indicator.py:ACCDIST,ACCDIST,function,11,32,22,184,5.75,0,0,"['df', 'n']","[None, None]","[None, None]",600,[],"['ad.diff', 'ad.shift', 'pd.Series', 'str', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:Chaikin,Chaikin,function,6,28,22,205,7.32,0,0,['df'],[None],[None],610,[],"['pd.Series', 'pd.ewma', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:MFI,MFI,function,15,60,40,322,5.37,1,1,"['df', 'n']","[None, None]","[None, None]",617,[],"['PosMF.append', 'df.get_value', 'pd.Series', 'str', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:OBV,OBV,function,10,66,30,404,6.12,1,3,"['df', 'n']","[None, None]","[None, None]",635,[],"['df.get_value', 'OBV.append', 'pd.Series', 'str', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:FORCE,FORCE,function,5,12,10,97,8.08,0,0,"['df', 'n']","[None, None]","[None, None]",652,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:EOM,EOM,function,6,20,17,170,8.5,0,0,"['df', 'n']","[None, None]","[None, None]",658,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:CCI,CCI,function,6,21,18,146,6.95,0,0,"['df', 'n']","[None, None]","[None, None]",665,[],"['pd.Series', 'pd.rolling_mean', 'pd.rolling_std', 'str', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:COPP,COPP,function,11,48,24,261,5.44,0,0,"['df', 'n']","[None, None]","[None, None]",672,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:KELCH,KELCH,function,7,45,24,362,8.04,0,0,"['df', 'n']","[None, None]","[None, None]",684,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:ULTOSC,ULTOSC,function,15,67,40,552,8.24,1,0,['df'],[None],[None],694,[],"['max', 'df.get_value', 'min', 'TR_l.append', 'BP_l.append', 'pd.Series', 'pd.rolling_sum', 'df.join']",8
utilmy/zarchive/storage/technical_indicator.py:DONCH,DONCH,function,13,57,27,249,4.37,2,0,"['df', 'n']","[None, None]","[None, None]",709,[],"['DC_l.append', 'max', 'min', 'pd.Series', 'str', 'DonCh.shift', 'df.join']",7
utilmy/zarchive/storage/technical_indicator.py:STDDEV,STDDEV,function,3,9,8,80,8.89,0,0,"['df', 'n']","[None, None]","[None, None]",726,[],"['df.join', 'str']",2
utilmy/zarchive/storage/technical_indicator.py:RWI,RWI,function,1,2,2,7,3.5,0,0,"['df', 'nn', 'nATR']","[None, None, None]","[None, None, None]",731,[],[],0
utilmy/zarchive/storage/technical_indicator.py:nbday_low,nbday_low,function,20,39,32,331,8.49,1,0,"['df', 'n']","[None, None]","[None, None]",745,"[""  '''nb of days from 1 year low '''\n""]","['np.zeros', 'range', 'len', 'np_find_minpos', 'pd.Series', 'str', 'df.join']",7
utilmy/zarchive/storage/technical_indicator.py:nbday_high,nbday_high,function,20,39,32,333,8.54,1,0,"['df', 'n']","[None, None]","[None, None]",312,"[""  '''nb of days from 1 year low '''\n""]","['np.zeros', 'range', 'len', 'np_find_maxpos', 'pd.Series', 'str', 'df.join']",7
utilmy/zarchive/storage/testmulti.py:mc01,mc01,function,0,0,0,0,0.0,0,0,[],[],[],18,"[""'''\n"", '\n', 'from __future__ import print_function\n', '\n', 'import multiprocessing\n', 'import ctypes\n', 'import numpy as np\n', '\n', 'def shared_array(shape):\n', '    """"""\n', '    Form a shared memory numpy array.\n', '    \n', '    http://stackoverflow.com/questions/5549190/is-shared-readonly-data-copied-to-different-processes-for-python-multiprocessing \n', '    """"""\n', '    \n', '    shared_array_base = multiprocessing.Array(ctypes.c_double, shape[0]*shape[1])\n', '    shared_array = np.ctypeslib.as_array(shared_array_base.get_obj())\n', '    shared_array = shared_array.reshape(*shape)\n', '    return shared_array\n', '\n', '\n', '# Form a shared array and a lock, to protect access to shared memory.\n', 'array = shared_array((1000, 1000))\n', 'lock = multiprocessing.Lock()\n', '\n', '\n', 'def parallel_function(i, def_param=(lock, array)):\n', '    """"""\n', '    Function that operates on shared memory.\n', '    """"""\n', '    \n', '    # Make sure your not modifying data when someone else is.\n', '    lock.acquire()    \n', '    \n', '    array[i, :] = i\n', '    \n', '    # Always release the lock!\n', '    lock.release()\n', '\n', ""if __name__ == '__main__':\n"", '    """"""\n', '    The processing pool needs to be instantiated in the main \n', '    thread of execution. \n', '    """"""\n', '        \n', '    pool = multiprocessing.Pool(processes=4)\n', '        \n', '    # Call the parallel function with different inputs.\n', '    args = [(0), \n', '            (1), \n', '            (2)]\n', '    \n', '    # Use map - blocks until all processes are done.\n', '    pool.map(parallel_function, args )\n', '    \n', '    print(array)\n', '    \n', '    \n', ""    '''\n""]",[],0
utilmy/zarchive/storage/testmulti.py:mc02,mc02,function,0,0,0,0,0.0,0,0,[],[],[],28,"[""'''\n"", '\n', 'from __future__ import print_function\n', '\n', 'import multiprocessing\n', 'import ctypes\n', 'import numpy as np\n', '\n', 'def shared_array(shape):\n', '    """"""\n', '    Form a shared memory numpy array.\n', '    \n', '    http://stackoverflow.com/questions/5549190/is-shared-readonly-data-copied-to-different-processes-for-python-multiprocessing \n', '    """"""\n', '    \n', '    shared_array_base = multiprocessing.Array(ctypes.c_double, shape[0]*shape[1])\n', '    shared_array = np.ctypeslib.as_array(shared_array_base.get_obj())\n', '    shared_array = shared_array.reshape(*shape)\n', '    return shared_array\n', '\n', '\n', '# Form a shared array and a lock, to protect access to shared memory.\n', 'array = shared_array((1000, 1000))\n', 'lock = multiprocessing.Lock()\n', '\n', '\n', 'def parallel_function(i, def_param=(lock, array)):\n', '    """"""\n', '    Function that operates on shared memory.\n', '    """"""\n', '    \n', '    # Make sure your not modifying data when someone else is.\n', '    lock.acquire()    \n', '    \n', '    array[i, :] = i\n', '    \n', '    # Always release the lock!\n', '    lock.release()\n', '\n', ""if __name__ == '__main__':\n"", '    """"""\n', '    The processing pool needs to be instantiated in the main \n', '    thread of execution. \n', '    """"""\n', '        \n', '    pool = multiprocessing.Pool(processes=4)\n', '        \n', '    # Call the parallel function with different inputs.\n', '    args = [(0), \n', '            (1), \n', '            (2)]\n', '    \n', '    # Use map - blocks until all processes are done.\n', '    pool.map(parallel_function, args )\n', '    \n', '    print(array)\n', '    \n', '    \n', ""    '''\n""]",[],0
utilmy/zarchive/storage/testmulti.py:serial,serial,function,1,8,8,54,6.75,0,0,"['samples', 'x', 'widths']","[None, None, None]","[None, None, None]",149,[],[],0
utilmy/zarchive/storage/testmulti.py:multiprocess,multiprocess,function,5,27,22,231,8.56,0,0,"['processes', 'samples', 'x', 'widths']","[None, None, None, None]","[None, None, None, None]",152,[],"['mp.Pool', 'pool.terminate', 'pool.join', 'print']",4
utilmy/zarchive/storage/testmulti.py:test01,test01,function,28,54,39,407,7.54,3,0,[],[],[],209,[],"['range', 'list', 'mp.Process']",3
utilmy/zarchive/storage/testmulti.py:random_tree,random_tree,function,3,3,3,42,14.0,0,0,['Data'],[None],[None],251,[],"['calculation', 'forest.append']",2
utilmy/zarchive/storage/testmulti.py:random_tree,random_tree,function,3,3,3,42,14.0,0,0,['Data'],[None],[None],251,[],"['calculation', 'forest.append']",2
utilmy/zarchive/storage/testmulti.py:test01,test01,function,28,54,39,407,7.54,3,0,[],[],[],209,[],"['range', 'list', 'mp.Process']",3
utilmy/zarchive/storage/theano_imdb.py:prepare_data,prepare_data,function,30,71,54,552,7.77,2,3,"['seqs', 'labels', 'maxlen']","[None, None, None]","[None, None, 'None']",12,"['    """"""Create the matrices from the datasets.\n', '\n', '    This pad each sequence to the same lenght: the lenght of the\n', '    longuest sequence or maxlen.\n', '\n', '    if maxlen is set, we will cut all sequence to this maximum\n', '    lenght.\n', '\n', '    This swap the axis!\n', '    """"""\n']","['zip', 'new_seqs.append', 'new_labels.append', 'new_lengths.append', 'len', 'numpy.max', 'numpy.zeros', 'enumerate']",8
utilmy/zarchive/storage/theano_imdb.py:get_dataset_file,get_dataset_file,function,16,43,35,416,9.67,0,3,"['dataset', 'default_dataset', 'origin']","[None, None, None]","[None, None, None]",54,"[""    '''Look for it as if it was a full path, if not, try local file,\n"", '    if not try in the data directory.\n', '\n', '    Download dataset if it is not present\n', '\n', ""    '''\n""]",['print'],1
utilmy/zarchive/storage/theano_imdb.py:load_data,load_data,function,54,180,103,1753,9.74,13,5,"['path', 'n_words', 'valid_portion', 'maxlen', 'sort_by_len']","[None, None, None, None, None]","['""imdb.pkl""', '100000', '0.1', 'None', 'True']",82,"[""    '''Loads the dataset\n"", '\n', '    :type path: String\n', '    :param path: The path to the dataset (here IMDB)\n', '    :type n_words: int\n', '    :param n_words: The number of word to keep in the vocabulary.\n', '        All extra words are set to unknow (1).\n', '    :type valid_portion: float\n', '    :param valid_portion: The proportion of the full train set used for\n', '        the validation set.\n', '    :type maxlen: None or positive int\n', '    :param maxlen: the max sequence length we use in the train/valid set.\n', '    :type sort_by_len: bool\n', '    :name sort_by_len: Sort by the sequence lenght for the train,\n', '        valid and test set. This allow faster execution as it cause\n', '        less padding per minibatch. Another mechanism must be used to\n', '        shuffle the train set at each epoch.\n', '\n', ""    '''\n""]","['get_dataset_file', 'path.endswith', 'gzip.open', 'open', 'pickle.load', 'f.close', 'zip', 'len', 'new_train_set_x.append', 'new_train_set_y.append', 'int', 'remove_unk', 'len_argsort', 'sorted']",14
utilmy/zarchive/storage/theano_lstm.py:numpy_floatX,numpy_floatX,function,2,3,3,45,15.0,0,0,['data'],[None],[None],26,[],['numpy.asarray'],1
utilmy/zarchive/storage/theano_lstm.py:get_minibatches_idx,get_minibatches_idx,function,11,29,26,373,12.86,1,1,"['n', 'minibatch_size', 'shuffle']","[None, None, None]","[None, None, 'False']",30,"['    """"""\n', '    Used to shuffle the dataset at each iteration.\n', '    """"""\n']","['numpy.arange', 'range', 'minibatches.append', 'zip']",4
utilmy/zarchive/storage/theano_lstm.py:get_dataset,get_dataset,function,3,3,3,41,13.67,0,0,['name'],[None],[None],54,[],[],0
utilmy/zarchive/storage/theano_lstm.py:zipp,zipp,function,4,6,6,51,8.5,1,0,"['params', 'tparams']","[None, None]","[None, None]",58,"['    """"""\n', '    When we reload the model. Needed for the GPU stuff.\n', '    """"""\n']",['params.items'],1
utilmy/zarchive/storage/theano_lstm.py:unzip,unzip,function,8,11,10,97,8.82,1,0,['zipped'],[None],[None],66,"['    """"""\n', '    When we pickle the model. Needed for the GPU stuff.\n', '    """"""\n']","['OrderedDict', 'zipped.items', 'vv.get_value']",3
utilmy/zarchive/storage/theano_lstm.py:dropout_layer,dropout_layer,function,4,12,11,146,12.17,0,0,"['state_before', 'use_noise', 'trng']","[None, None, None]","[None, None, None]",76,[],"['tensor.switch', 'trng.binomial']",2
utilmy/zarchive/storage/theano_lstm.py:_p,_p,function,1,5,5,23,4.6,0,0,"['pp', 'name']","[None, None]","[None, None]",86,[],[],0
utilmy/zarchive/storage/theano_lstm.py:init_params,init_params,function,13,20,18,394,19.7,0,0,['options'],[None],[None],90,"['    """"""\n', '    Global (not LSTM) parameter. For the embeding and the classifier.\n', '    """"""\n']","['OrderedDict', 'get_layer', 'numpy.zeros']",3
utilmy/zarchive/storage/theano_lstm.py:load_params,load_params,function,11,25,22,128,5.12,1,1,"['path', 'params']","[None, None]","[None, None]",110,[],"['numpy.load', 'params.items', 'Warning']",3
utilmy/zarchive/storage/theano_lstm.py:init_tparams,init_tparams,function,8,12,11,107,8.92,1,0,['params'],[None],[None],120,[],"['OrderedDict', 'params.items', 'theano.shared']",3
utilmy/zarchive/storage/theano_lstm.py:get_layer,get_layer,function,3,4,3,26,6.5,0,0,['name'],[None],[None],127,[],[],0
utilmy/zarchive/storage/theano_lstm.py:ortho_weight,ortho_weight,function,8,9,9,87,9.67,0,0,['ndim'],[None],[None],132,[],['u.astype'],1
utilmy/zarchive/storage/theano_lstm.py:param_init_lstm,param_init_lstm,function,9,26,18,487,18.73,0,0,"['options', 'params', 'prefix']","[None, None, None]","[None, None, ""'lstm'""]",138,"['    """"""\n', '    Init the LSTM parameter:\n', '\n', '    :see: init_params\n', '    """"""\n']","['numpy.concatenate', 'ortho_weight', 'params[_p', 'numpy.zeros', 'b.astype']",5
utilmy/zarchive/storage/theano_lstm.py:lstm_layer,lstm_layer,function,41,115,79,988,8.59,0,2,"['tparams', 'state_below', 'options', 'prefix', 'mask']","[None, None, None, None, None]","[None, None, None, ""'lstm'"", 'None']",160,[],"['_slice', '_step', 'tensor.dot', 'tparams[_p', 'tensor.tanh', 'theano.scan', 'tensor.alloc', 'name=_p']",8
utilmy/zarchive/storage/theano_lstm.py:sgd,sgd,function,8,46,38,359,7.8,0,0,"['lr', 'tparams', 'grads', 'x', 'mask', 'y', 'cost']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",213,"['    """""" Stochastic Gradient Descent\n', '\n', '    :note: A more complicated version of sgd then needed.  This is\n', '        done like that for adadelta and rmsprop.\n', '\n', '    """"""\n']","['tparams.items', 'zip', 'theano.function']",3
utilmy/zarchive/storage/theano_lstm.py:adadelta,adadelta,function,12,112,70,907,8.1,0,0,"['lr', 'tparams', 'grads', 'x', 'mask', 'y', 'cost']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",241,"['    """"""\n', '    An adaptive learning rate optimizer\n', '\n', '    Parameters\n', '    ----------\n', '    lr : Theano SharedVariable\n', '        Initial learning rate\n', '    tpramas: Theano SharedVariable\n', '        Model parameters\n', '    grads: Theano variable\n', '        Gradients of cost w.r.t to parameres\n', '    x: Theano variable\n', '        Model inputs\n', '    mask: Theano variable\n', '        Sequence mask\n', '    y: Theano variable\n', '        Targets\n', '    cost: Theano variable\n', '        Objective fucntion to minimize\n', '\n', '    Notes\n', '    -----\n', '    For more information, see [ADADELTA]_.\n', '\n', '    .. [ADADELTA] Matthew D. Zeiler, *ADADELTA: An Adaptive Learning\n', '       Rate Method*, arXiv:1212.5701.\n', '    """"""\n']","['numpy_floatX', 'tparams.items', 'zip', 'theano.function', 'tensor.sqrt']",5
utilmy/zarchive/storage/theano_lstm.py:rmsprop,rmsprop,function,16,129,77,1028,7.97,1,0,"['lr', 'tparams', 'grads', 'x', 'mask', 'y', 'cost']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",302,"['    """"""\n', '    A variant of  SGD that scales the step size by running average of the\n', '    recent step norms.\n', '\n', '    Parameters\n', '    ----------\n', '    lr : Theano SharedVariable\n', '        Initial learning rate\n', '    tpramas: Theano SharedVariable\n', '        Model parameters\n', '    grads: Theano variable\n', '        Gradients of cost w.r.t to parameres\n', '    x: Theano variable\n', '        Model inputs\n', '    mask: Theano variable\n', '        Sequence mask\n', '    y: Theano variable\n', '        Targets\n', '    cost: Theano variable\n', '        Objective fucntion to minimize\n', '\n', '    Notes\n', '    -----\n', '    For more information, see [Hint2014]_.\n', '\n', '    .. [Hint2014] Geoff Hinton, *Neural Networks for Machine Learning*,\n', '       lecture 6a,\n', '       http://cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf\n', '    """"""\n']","['numpy_floatX', 'tparams.items', 'zip', 'theano.function', 'tensor.sqrt']",5
utilmy/zarchive/storage/theano_lstm.py:build_model,build_model,function,39,78,66,934,11.97,0,3,"['tparams', 'options']","[None, None]","[None, None]",367,[],"['RandomStreams', 'theano.shared', 'tensor.matrix', 'tensor.vector', 'get_layer', 'mask.sum', 'dropout_layer', 'theano.function', 'pred.argmax']",9
utilmy/zarchive/storage/theano_lstm.py:pred_probs,pred_probs,function,18,41,37,377,9.2,1,1,"['f_pred_prob', 'prepare_data', 'data', 'iterator', 'verbose']","[None, None, None, None, None]","[None, None, None, None, 'False']",406,"['    """""" If you want to use a trained model, this is useful to compute\n', '    the probabilities of new examples.\n', '    """"""\n']","['len', 'numpy.zeros', 'prepare_data', 'numpy.array', 'f_pred_prob', 'print']",6
utilmy/zarchive/storage/theano_lstm.py:pred_error,pred_error,function,15,32,27,303,9.47,1,0,"['f_pred', 'prepare_data', 'data', 'iterator', 'verbose']","[None, None, None, None, None]","[None, None, None, None, 'False']",429,"['    """"""\n', '    Just compute the error\n', '    f_pred: Theano fct computing the prediction\n', '    prepare_data: usual prepare_data for that dataset.\n', '    """"""\n']","['prepare_data', 'numpy.array', 'f_pred', 'numpy_floatX', 'len']",5
utilmy/zarchive/storage/theano_lstm.py:train_lstm,train_lstm,function,95,417,264,3684,8.83,3,16,"['dim_proj', '# word embeding dimension and LSTM number of hidden units.patience', '# Number of epoch to wait before early stop if no progressmax_epochs', '# The maximum number of epoch to rundispFreq', '# Display to stdout the training progress every N updatesdecay_c', '# Weight decay for the classifier applied to the U weights.not used for adadelta and rmsprop)n_words', '# Vocabulary sizeprobably need momentum and decaying learning rate).encoder', '# TODO', '# The best model will be saved therevalidFreq', '# Compute the validation error after this number of update.saveFreq', '# Save the parameters after every saveFreq updatesmaxlen', '# Sequence longer then this get ignoredbatch_size', '# The batch size during training.valid_batch_size', '# The batch size used for validation/test set.dataset', 'noise_std', 'use_dropout', '# if False slightly faster', 'but worst test errorreload_model', '# Path to a saved model we want to start from.test_size', '# If >0', 'we keep only this number of test example.']","[None, None, None, None, None, None, None, ' can be removed must be lstm.saveto', None, None, None, None, None, None, None, None, None, None, None, None, None]","['128', '10', '5000', '10', '0.', '10000', ""'lstm'"", ""'lstm_model.npz'"", '370', '1110', '100', '16', '64', ""'imdb'"", '0.', 'True', None, 'None', '-1', None, None]",448,[],"['locals', 'print', 'get_dataset', 'load_data', 'numpy.arange', 'numpy.max', 'init_params', 'load_params', 'init_tparams', 'build_model', 'theano.shared', 'theano.function', 'tensor.grad', 'wrt=list', 'tensor.scalar', 'optimizer', 'get_minibatches_idx', 'len', 'time.time', 'range', 'use_noise.set_value', 'prepare_data', 'f_grad_shared', 'f_update', 'numpy.isnan', 'numpy.isinf', 'numpy.mod', 'unzip', 'numpy.savez', 'pickle.dump', 'open', 'pred_error', 'history_errs.append', 'numpy.array', 'zipp']",35
utilmy/templates/templist/pypi_package/run_pipy.py:get_current_githash,get_current_githash,function,6,10,8,126,12.6,0,0,[],[],[],39,[],"['subprocess.check_output', 'label.decode']",2
utilmy/templates/templist/pypi_package/run_pipy.py:update_version,update_version,function,12,30,28,315,10.5,0,0,"['path', 'n']","[None, None]","[None, '1']",46,[],"['open', 'Version.parse', 'print', 'int', 'file.write', 'version.new_version']",6
utilmy/templates/templist/pypi_package/run_pipy.py:git_commit,git_commit,function,3,29,19,164,5.66,0,2,['message'],[None],[None],65,[],"['ask', 'exit', 'os.system']",3
utilmy/templates/templist/pypi_package/run_pipy.py:ask,ask,function,2,3,3,42,14.0,0,0,"['question', 'ans']","[None, None]","[None, ""'yes'""]",77,[],"['input', 'ans.lower']",2
utilmy/templates/templist/pypi_package/run_pipy.py:pypi_upload,pypi_upload,function,5,40,35,391,9.78,1,1,[],[],[],81,"['    """"""\n', '      It requires credential in .pypirc  files\n', '      __token__\n', '      or in github SECRETS\n', '\n', '    """"""\n']","['os.system', 'print', 'os.listdir', 'item.endswith']",4
utilmy/templates/templist/pypi_package/run_pipy.py:main,main,function,2,6,6,75,12.5,0,0,['*args'],[None],[None],102,[],"['print', 'update_version']",2
utilmy/templates/templist/pypi_package/run_pipy.py:Version,Version,class,21,58,48,650,11.21,0,1,[],[],[],10,[],[],0
utilmy/templates/templist/pypi_package/run_pipy.py:Version:__init__,Version:__init__,method,6,6,6,50,8.33,0,0,"['self', 'major', 'minor', 'patch']","[None, None, None, None]","[None, None, None, None]",13,[],[],0
utilmy/templates/templist/pypi_package/run_pipy.py:Version:__str__,Version:__str__,method,2,2,2,36,18.0,0,0,['self'],[None],[None],18,[],"[""f'Version""]",1
utilmy/templates/templist/pypi_package/run_pipy.py:Version:__repr__,Version:__repr__,method,2,2,2,20,10.0,0,0,['self'],[None],[None],21,[],['self.__str__'],1
utilmy/templates/templist/pypi_package/run_pipy.py:Version:stringify,Version:stringify,method,1,2,2,51,25.5,0,0,['self'],[None],[None],24,[],[],0
utilmy/templates/templist/pypi_package/run_pipy.py:Version:new_version,Version:new_version,method,1,3,3,53,17.67,0,0,"['self', 'orig']","[None, None]","[None, None]",27,[],['self.stringify'],1
utilmy/templates/templist/pypi_package/run_pipy.py:Version:parse,Version:parse,method,5,23,22,192,8.35,0,1,"['cls', 'string']","[None, None]","[None, None]",31,[],"['re.findall', 'len', 'Exception', 'cls']",4
utilmy/templates/templist/pypi_package/setup.py:get_current_githash,get_current_githash,function,6,10,8,123,12.3,0,0,[],[],[],17,[],"['subprocess.check_output', 'label.decode']",2
utilmy/zarchive/storage/aapackagedev/random.py:convert_csv2hd5f,convert_csv2hd5f,function,10,21,19,181,8.62,1,0,"['filein1', 'filename']","[None, None]","[None, None]",61,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/storage/aapackagedev/random.py:getrandom_tonumpy,getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample']","[None, None, None]","[None, None, None]",74,[],['pd.read_hdf'],1
utilmy/zarchive/storage/aapackagedev/random.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",90,[],['ne.evaluate'],1
utilmy/zarchive/storage/aapackagedev/random.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],98,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/storage/aapackagedev/random.py:getdvector,getdvector,function,7,21,20,141,6.71,1,0,"['dimmax', 'istart', 'idimstart']","[None, None, None]","[None, None, None]",126,[],['range'],1
utilmy/zarchive/storage/aapackagedev/random.py:pathScheme_std,pathScheme_std,function,3,3,3,28,9.33,0,0,"['T', 'n', 'zz)', 'n+1)']","[None, None, '   #Standard Path generationn+1);  sdt', '']","[None, None, ' np.sqrt(T/n);  ww[0]= 01', None]",136,[],[],0
utilmy/zarchive/storage/aapackagedev/random.py:pathScheme_bb,pathScheme_bb,function,18,32,30,200,6.25,1,0,"['T', 'n', 'zz)', 'kkmax+1)']","[None, None, '  #Brownian Bridge generationn); # sdt', '']","[None, None, ' np.sqrt(T/n);np.round(np.log(n)  * 1.4426950408889634)) # n= 2^kmaxh= n; jmax=1T)1', None]",144,[],"['int', 'range', 'np.sqrt']",3
utilmy/zarchive/storage/aapackagedev/random.py:pathScheme_,pathScheme_,function,3,3,3,28,9.33,0,0,"['T', 'n', 'zz)', 'n+1)']","[None, None, '   #Standard Path generationn+1);  sdt', '']","[None, None, ' np.sqrt(T/n);  ww[0]= 01', None]",163,"[""'''\n"", 'ttdim=1024  # dim= 2^k\n', '[[500, testdensity(500, ttdim, 400,-1)],\n', '[1000, testdensity(1000, ttdim, 400,-1)],\n', '[2000, testdensity(2000, ttdim, 400,-1)], \n', '[3000, testdensity(3000, ttdim, 400,-1)],\n', '[4000, testdensity(4000, ttdim, 400,-1)]]\n', ""'''\n""]",[],0
utilmy/zarchive/storage/aapackagedev/random.py:testdensity,testdensity,function,27,57,54,404,7.09,3,0,"['nsample', 'totdim', 'bin01', 'Ti']","[None, None, None, None]","[None, None, None, '-1']",173,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'dx.dN', 'np.sum']",8
utilmy/zarchive/storage/aapackagedev/random.py:plotdensity,plotdensity,function,29,65,63,531,8.17,1,0,"['nsample', 'totdim', 'bin01', 'tit0', 'Ti']","[None, None, None, None, None]","[None, None, None, None, '-1']",191,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'dx.dN', 'plt.plot', 'plt.axis', 'plt.title']",10
utilmy/zarchive/storage/aapackagedev/random.py:testdensity2d,testdensity2d,function,39,85,74,702,8.26,2,0,"['nsample', 'totdim', 'bin01', 'nbasset']","[None, None, None, None]","[None, None, None, None]",236,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'np.arange', 'np.histogram2d', 'dx.dN2d', 'np.meshgrid', 'plt.imshow', 'np.sum']",10
utilmy/zarchive/storage/aapackagedev/random.py:lognormal_process2d,lognormal_process2d,function,2,5,4,49,9.8,0,0,"['a1', 'z1', 'a2', 'z2', 'k']","[None, None, None, None, None]","[None, None, None, None, None]",277,[],"['np.maximum', 'np.exp']",2
utilmy/zarchive/storage/aapackagedev/random.py:testdensity2d2,testdensity2d2,function,40,91,80,750,8.24,2,0,"['nsample', 'totdim', 'bin01', 'nbasset', 'process01', 'a1', 'a2', 'kk']","[None, None, None, None, None, None, None, None]","[None, None, None, None, 'lognormal_process2d', '0.25', '0.25', '1']",283,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'np.arange', 'np.histogram2d', 'dx.dN2d', 'process01', 'np.meshgrid', 'plt.imshow', 'np.sum']",11
utilmy/zarchive/storage/aapackagedev/random.py:call_process,call_process,function,15,30,28,245,8.17,1,0,"['a', 'z', 'k)', 'np.exp(a*z)-k)@jita', 'z', 'k)', '[np.exp(a*z) > k]', '[1])@jittotdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt=10)']","[None, None, ' return np.maximum(0', None, None, '  return np.piecewise(z', None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, None, None, None, '0.25', '-1', '10):']",331,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/aapackagedev/random.py:binary_process,binary_process,function,15,30,28,245,8.17,1,0,"['a', 'z', 'k)', '[np.exp(a*z) > k]', '[1])@jittotdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt=10)']","[None, None, '  return np.piecewise(z', None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, '0.25', '-1', '10):']",335,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/aapackagedev/random.py:pricing01,pricing01,function,15,30,28,245,8.17,1,0,"['totdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, '0.25', '-1', '10']",341,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/aapackagedev/random.py:plotdensity2,plotdensity2,function,35,78,74,590,7.56,2,0,"['nsample', 'totdim', 'bin01', 'tit0', 'process01', 'vol', 'tt', 'Ti']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, '0.25', '5', '-1']",365,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'process01', 'call_process', 'plt.plot', 'plt.axis', 'plt.title']",11
utilmy/zarchive/storage/aapackagedev/random.py:Plot2D_random_show,Plot2D_random_show,function,46,106,80,855,8.07,0,0,"['dir1', 'title1', 'dimxmax', 'dimymax', 'dimstep', 'samplejump', 'nsamplegraph']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",417,[],"['pd.read_hdf', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'plt.show', 'np.mean', 'np.var', 'comoment']",9
utilmy/zarchive/storage/aapackagedev/random.py:Plot2D_random_save,Plot2D_random_save,function,51,106,77,723,6.82,2,0,"['dir1', 'title1', 'dimxmax', 'dimymax', 'dimstep', 'samplejump', 'nsamplegraph', '']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",464,[],"['range', 'pd.read_hdf', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",8
utilmy/zarchive/storage/aapackagedev/random.py:getoutlier_fromrandom,getoutlier_fromrandom,function,57,168,111,1242,7.39,2,2,"['filename', 'jmax1', 'imax1', 'isamplejum', 'nsample', ""fileoutlier=   'E""]","[None, None, None, None, None, '']","[None, None, None, None, None, ""   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'""]",514,[],"['range', 'pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'unique_rows', 'store.append', 'store.close']",7
utilmy/zarchive/storage/aapackagedev/random.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",582,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/aapackagedev/random.py:getoutlier_fromrandom_fast,getoutlier_fromrandom_fast,function,71,183,130,1320,7.21,2,2,"['filename', 'jmax1', 'imax1', 'isamplejum', 'nsample', 'trigger1', ""fileoutlier=   'E""]","[None, None, None, None, None, None, '']","[None, None, None, None, None, '0.28', ""   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'""]",602,[],"['np.zeros', 'range', 'ne.evaluate', 'pd.HDFStore', 'store.append', 'store.close']",6
utilmy/zarchive/storage/aapackagedev/random.py:outlier_clean,outlier_clean,function,7,16,15,98,6.12,1,1,['vv2'],[None],[None],670,[],['range'],1
utilmy/zarchive/storage/aapackagedev/random.py:overwrite_data,overwrite_data,function,6,11,9,112,10.18,0,0,"['fileoutlier', 'vv2']","[None, None]","[None, None]",678,[],"['pd.HDFStore', 'store.remove', 'store.append', 'store.close']",4
utilmy/zarchive/storage/aapackagedev/random.py:doublecheck_outlier,doublecheck_outlier,function,8,12,11,100,8.33,0,0,"['fileoutlier', 'ijump', 'nsample', 'trigger1', "")fileoutlier=   'E"", ""'data')    #from filevv5"", '4)', 'dtype', 'kkmax1', '1) ', '0];   dimy', '1]y0= dimy * ijump + istartyym= dimy* ijump + nsample + istartyyyu1= yy1[y0']","[None, None, None, None, '', None, None, None, None, '  #Decrasing: dimy0 to dimmindimx', None, '']","[None, None, '4000', '0.1', ""   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'fileoutlier"", ' pdf.values   #to numpy vectordel pdfistartx= 0; istarty= 0nsample= 4000trigger1=  0.1crrmax = 250000kk=0(crrmax', None, ""'int')  #empty listvv5)[0]0"", None, ' vv5[kk', ' vv5[kk', ' dimy * ijump + istartyym= dimy* ijump + nsample + istartyyyu1= yy1[y0:ym];   yyu2= yy2[y0:ym];   yyu3= yy3[y0:ym]x0= dimx * ijump + istartxxm= dimx* ijump + nsample + istartxxxu1= yy1[x0:xm];   xxu2= yy2[x0:xm];   xxu3= yy3[x0:xm]""sum( xxu3 * yyu1)"") / (nsample) # X3.Y moments""sum( xxu1 * yyu3)"") / (nsample)""sum( xxu2 * yyu2)"") / (nsample)abs(c22) > trigger1)  :']",698,[],[],0
utilmy/zarchive/storage/aapackagedev/random.py:plot_outlier,plot_outlier,function,13,20,19,144,7.2,1,0,"['fileoutlier', 'kk)fileoutlier', ""'data')    #from filevv"", '0]yy', '1]xx', 'yy', 's', '1000', '00', ""1000])nsample)+'sampl D_'+str(dimx)+' X D_'+str(dimy)tit1)'_img/'+tit1+'_outlier.jpg'"", 'dpi', 'kmax)']","[None, None, None, None, None, None, None, None, None, None, None, '']","[None, None, ' df.values   #to numpy vectordel dfxx= vv[kk', ' vv[kk', None, None, '1 )[00', None, None, None, '100))yy', None]",758,"[""'''\n"", ""fileoutlier=   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'   \n"", ""df=  pd.read_hdf(fileoutlier,'data')    #from file\n"", '\n', 'nn= len(vv)\n', 'vv1= np.zeros((10001,2))\n', 'for ii in range(0,   nn ):\n', '    \n', '  ix1= vv[ii,0]  \n', '  ix2= vv[ii,1]  \n', '  \n', '  vv1[ix1,0]= ix1\n', '  vv1[ix2,0]= ix2\n', '  vv1[ix1,1]+= 1\n', '  vv1[ix2,1]+= 1\n', '  \n', '\n', 'plt.scatter(xx, yy, s=1 )\n', 'plt.axis([0, 3500, 0, 100])  \n', '\n', '\n', 'np.mean(yy[:3000])    :65.163333333333327\n', 'np.var(yy[:3000])   : 66.519322222222229\n', '\n', 'np.mean(yy[3001:10000])    :29.998285469352766    35.16504786398056\n', '\n', '\n', 'xx= vv1[:,0]\n', 'yy= vv1[:,1]\n', '\n', 'yy[3001:10000] = yy[3001:10000] +  np.random.normal(35.16,6, 6999)\n', '\n', '\n', 'plt.scatter(xx, yy, s=1 )\n', 'plt.axis([0, 10000, 0, 100]) \n', '\n', 'tit1= ""Histogram of outliers per dim 1 to 10000""\n', 'plt.title(tit1)\n', ""plt.savefig('_img/'+'histogram of outliers per dim 1 to 10000.jpg',dpi=100)\n"", 'plt.clf()\n', '\n', '0.006  0.6% are defective...\n', ""'''\n""]","['int', 'np.copy', 'range']",3
utilmy/zarchive/storage/aapackagedev/random.py:permute,permute,function,24,64,53,631,9.86,2,0,"['yy', 'kmax']","[None, None]","[None, None]",841,[],"['int', 'np.copy', 'range', 'permute2', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'comoment']",9
utilmy/zarchive/storage/aapackagedev/random.py:permute2,permute2,function,18,42,41,461,10.98,1,0,"['xx', 'yy', 'kmax']","[None, None, None]","[None, None, None]",854,[],"['int', 'np.copy', 'range', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'comoment']",8
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:wi,wi,function,10,24,21,160,6.67,1,1,['*args'],[None],[None],27,[],"['str', 'dx.replace', 'printinfile']",3
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:printinfile,printinfile,function,3,6,6,51,8.5,0,0,"['vv', 'file1']","[None, None]","[None, None]",38,[],"['open', 'text_file.write']",2
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:wi2,wi2,function,4,10,10,57,5.7,1,1,['*args'],[None],[None],44,[],['print'],1
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:indent,indent,function,17,43,34,344,8.0,0,4,[')'],['     global INDENT; INDENT +'],[' 4):      global INDENT; INDENT -= 4obj):'],49,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:dedent,dedent,function,17,43,34,344,8.0,0,4,[')'],['      global INDENT; INDENT -'],[' 4obj):'],50,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_builtin,describe_builtin,function,17,43,34,344,8.0,0,4,['obj'],[None],[None],54,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_func,describe_func,function,18,59,45,444,7.53,0,5,"['obj', 'method']","[None, None]","[None, 'False']",74,[],"['inspect.getargspec', 'wi', 'str', 'len']",4
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_klass,describe_klass,function,12,32,30,240,7.5,1,2,['obj'],[None],[None],99,[],"['wi', 'indent', 'getattr', 'inspect.ismethod', '1;describe_func', 'print', 'dedent']",7
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe,describe,function,54,315,151,2625,8.33,4,20,['obj'],[None],[None],116,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find', 'describe_func', 'inspect.getargspec', 'str', 'len', 'describe_klass', 'indent', 'getattr', 'inspect.ismethod', '1;describe_func', 'print', 'dedent', 'describe', 'dir', 'inspect.isclass', 'inspect.isfunction', 'inspect.isbuiltin', 'describe_builtin', 'describe_builtin2', 'describe_func2', 'describe_klass2', 'describe2']",25
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_builtin2,describe_builtin2,function,16,33,26,272,8.24,0,3,"['obj', 'name1']","[None, None]","[None, None]",143,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_func2,describe_func2,function,10,29,23,203,7.0,0,2,"['obj', 'method', 'name1']","[None, None, None]","[None, 'False', ""''""]",162,[],"['inspect.getargspec', 'wi', 'str']",3
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_klass2,describe_klass2,function,9,21,21,169,8.05,1,1,"['obj', 'name1']","[None, None]","[None, ""''""]",174,[],"['getattr', 'inspect.ismethod', 'describe_func2']",3
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe2,describe2,function,9,33,30,313,9.48,1,1,['module'],[None],[None],184,[],"['wi', 'dir', 'getattr', 'inspect.isclass', 'describe_klass2', 'print', 'inspect.isfunction', 'describe_func2', 'inspect.isbuiltin', 'describe_builtin2']",10
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:getmodule_doc,getmodule_doc,function,19,60,42,623,10.38,3,0,"['module1', 'file1']","[None, None]","[None, ""'moduledoc.txt'""]",200,[],"['importlib.import_module', 'pkgutil.walk_packages', 'vv.append', 'wi', 'describe2', 'print', 'describe']",7
utilmy/zarchive/storage/aapackage_gen/util.py:getmodule_doc,getmodule_doc,function,4,6,6,56,9.33,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",35,[],['ca.getmodule_doc'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:dataset_build_meta_mnist,dataset_build_meta_mnist,function,16,51,38,409,8.02,2,3,"['path', 'pathlib.Path]] ', 'get_image_fn', 'meta', 'image_suffix', '**kwargs', '']","[' Optional[Union[str', None, None, None, None, None, None]","[None, ' None', 'None', 'None', '""*.png""', None, None]",230,"['    """"""\n', '    Args:\n', '    * path - directory of the dataset or meta-data\n', '    * get_image_fn - function for getting i-th image of the dataset\n', '    directly metadat part\n', '\n', '    """"""\n']","['isinstance', 'pathlib.Path', 'path.exists', 'path.is_dir', 'path.iterdir', 'label_dir.is_dir', 'label_dir.glob', 'meta_rows.append', 'str', 'pd.DataFrame', 'len', 'meta.to_csv']",12
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:NlpDataset,NlpDataset,class,16,63,44,471,7.48,0,1,[],[],[],34,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:PhoneNlpDataset,PhoneNlpDataset,class,19,58,43,564,9.72,2,1,[],[],[],72,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset,ImageDataset,class,47,185,129,1631,8.82,3,8,[],[],[],116,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:NlpDataset:__init__,NlpDataset:__init__,method,8,32,26,209,6.53,0,1,"['self', 'meta']","[None, ' pd.DataFrame']","[None, None]",40,[],"['is_int', 'int', 'len', 'logw']",4
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:NlpDataset:__len__,NlpDataset:__len__,method,1,2,2,20,10.0,0,0,['self'],[None],[None],57,"['        """"""Return number of elements in this dataset.""""""\n']",['len'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:NlpDataset:get_sample,NlpDataset:get_sample,method,4,5,4,59,11.8,0,0,"['self', 'idx']","[None, ' int']","[None, None]",61,[],['self.get_text_only'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:NlpDataset:get_text_only,NlpDataset:get_text_only,method,5,6,5,54,9.0,0,0,"['self', 'idx']","[None, ' int']","[None, None]",65,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:PhoneNlpDataset:__init__,PhoneNlpDataset:__init__,method,12,33,24,373,11.3,2,0,"['self', 'size']","[None, ' int ']","[None, ' 1']",77,[],"['PhoneNumber', 'int', 'range', 'self.get_phone_number', 'meta_rows.append', 'super']",6
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:PhoneNlpDataset:__len__,PhoneNlpDataset:__len__,method,1,2,2,20,10.0,0,0,['self'],[None],[None],57,"['        """"""Return number of elements in this dataset.""""""\n']",['len'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:PhoneNlpDataset:get_phone_number,PhoneNlpDataset:get_phone_number,method,5,10,8,71,7.1,0,1,"['self', 'idx', 'islocal']","[None, None, None]","[None, None, 'False']",105,[],['s.replace'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:__init__,ImageDataset:__init__,method,17,50,39,396,7.92,2,3,"['self', 'path', 'pathlib.Path]] ', 'get_image_fn', 'meta', 'image_suffix', '**kwargs', '']","[None, ' Optional[Union[str', None, None, None, None, None, None]","[None, None, ' None', 'None', 'None', '""*.png""', None, None]",125,"['        """"""\n', '        Args:\n', '        * path - directory of the dataset or meta-data\n', '        * get_image_fn - function for getting i-th image of the dataset\n', '          directly from metadata part\n', '\n', '        """"""\n']","['isinstance', 'pathlib.Path', 'path.is_dir', 'path.iterdir', 'label_dir.is_dir', 'label_dir.glob', 'meta_rows.append', 'str', 'pd.DataFrame', 'len']",10
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:__len__,ImageDataset:__len__,method,1,2,2,20,10.0,0,0,['self'],[None],[None],57,"['        """"""Return number of elements in this dataset.""""""\n']",['len'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:get_image_only,ImageDataset:get_image_only,method,5,11,10,134,12.18,0,1,"['self', 'idx']","[None, ' int']","[None, None]",167,"['        """"""Return image of the single element of the dataset""""""\n']","['self.read_image', 'self.get_image_fn']",2
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:get_sample,ImageDataset:get_sample,method,6,18,15,121,6.72,0,1,"['self', 'idx']","[None, ' int']","[None, None]",177,[],['self.get_image_only'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:get_label_list,ImageDataset:get_label_list,method,6,11,10,123,11.18,0,1,"['self', 'label']","[None, ' Any']","[None, None]",190,"['        """"""Return indices of the elements which have certain label.""""""\n']","['isinstance', 'np.asarray', 'np.flatnonzero']",3
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:read_image,ImageDataset:read_image,method,2,2,2,47,23.5,0,0,"['self', 'filepath_or_buffer', 'io.BytesIO]']","[None, ' Union[str', None]","[None, None, None]",198,"['        """"""\n', '        Read a file into an image object\n', '        Args:\n', '            filepath_or_buffer: The path to the file, a URL, or any object\n', '                with a `read` method (such as `io.BytesIO`)\n', '        """"""\n']",['util_image.image_read'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:save,ImageDataset:save,method,13,36,33,306,8.5,1,2,"['self', 'path', 'prefix', 'suffix', 'nrows']","[None, ' str', ' str ', ' str ', ' int ']","[None, None, ' ""img""', ' ""png""', ' -1']",209,"['        """"""Serialize on Disk the dataset elements\n', '        Args:\n', '            path:\n', '        Returns: None\n', '\n', '        """"""\n']","['os.makedirs', 'len', 'min', 'range', 'self.get_sample', 'cv2.imwrite']",6
utilmy/templates/templist/pypi_package/mygenerator/pipeline.py:run_generate_numbers_sequence,run_generate_numbers_sequence,function,25,80,53,756,9.45,0,0,"['sequence', 'min_spacing', 'max_spacing', 'image_width', '### image_widthoutput_path', 'config_file', '']","[' str', ' int ', ' int ', ' int ', ' str ', ' str ', None]","[None, ' 1', ' 10', ' 280', ' ""./""', ' ""config/config.yaml""', None]",14,[],"['len', 'config_load', 'pathlib.Path', 'dataset.NlpDataset', 'transform.TextToImage', 'tf.fit_transform', 'ds_img.save']",7
utilmy/templates/templist/pypi_package/mygenerator/pipeline.py:run_generate_phone_numbers,run_generate_phone_numbers,function,27,76,57,697,9.17,0,0,"['num_images', 'min_spacing', 'max_spacing', 'image_width', 'output_path', 'config_file', '']","[' int ', ' int ', ' int ', ' int ', ' str ', ' str ', None]","[' 10', ' 1', ' 10', ' 280', ' ""./""', ' ""config/config.yaml""', None]",60,[],"['config_load', 'pathlib.Path', 'dataset.PhoneNlpDataset', 'transform.TextToImage', 'tf.fit_transform', 'ds_img.save']",6
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ImageTransform,ImageTransform,class,7,24,14,245,10.21,0,0,[],[],[],14,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CharToImages,CharToImages,class,23,53,41,636,12.0,1,1,[],[],[],56,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:RemoveWhitePadding,RemoveWhitePadding,class,9,23,18,319,13.87,0,0,[],[],[],112,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CombineImagesHorizontally,CombineImagesHorizontally,class,68,234,178,2451,10.47,1,3,[],[],[],145,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ScaleImage,ScaleImage,class,17,47,40,567,12.06,0,0,[],[],[],307,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:TextToImage,TextToImage,class,18,59,46,619,10.49,1,0,[],[],[],337,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ImageTransform:__init__,ImageTransform:__init__,method,6,22,13,226,10.27,0,0,['self'],[None],[None],20,"['        """"""\n', '        Parameters\n', '        ----------\n', '        """"""\n']","['transform', 'fit', 'fit_transform', 'self.fit']",4
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ImageTransform:transform,ImageTransform:transform,method,2,2,2,8,4.0,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",26,"['        """"""\n', '        Transform Dataset into Dataset\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']",[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ImageTransform:fit,ImageTransform:fit,method,3,10,9,113,11.3,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",35,"['        """"""\n', '        fit the transformation\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns: Object\n', '        """"""\n']","['fit_transform', 'self.fit']",2
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ImageTransform:fit_transform,ImageTransform:fit_transform,method,2,2,2,32,16.0,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",44,"['        """"""\n', '        Updates internal parameters of this transformation and then\n', '        applies it to the provided dataset.\n', '\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']",['self.fit'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CharToImages:__init__,CharToImages:__init__,method,2,2,2,22,11.0,0,0,"['self', 'font']","[None, ' dataset.ImageDataset']","[None, None]",62,"['        """"""\n', '        Parameters\n', '        ----------\n', '        font: dataset which contains images of characters. Images are features\n', ""        of the font dataset and characters are it's labels. Each character\n"", '        can have more than one image.\n', '        """"""\n']",[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CharToImages:transform,CharToImages:transform,method,16,27,26,356,13.19,1,1,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",72,"['        """"""\n', '        Replaces features of the input dataset by mapping feature (string type)\n', '        to a list of character images (List[np.array] type)\n', '        """"""\n']","['_get_image_fn', 'ds.get_text_only', 'len', 'img_list.append', 'dataset.ImageDataset']",5
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CharToImages:fit,CharToImages:fit,method,3,10,9,111,11.1,0,0,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",96,"['        """"""\n', '        Args:\n', '            ds: dataset.NlpDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']","['fit_transform', 'self.fit']",2
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CharToImages:fit_transform,CharToImages:fit_transform,method,2,2,2,32,16.0,0,0,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",104,"['        """"""\n', '        Updates internal parameters of this transformation and then\n', '        applies it to the provided dataset.\n', '        """"""\n']",['self.fit'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:RemoveWhitePadding:transform,RemoveWhitePadding:transform,method,8,17,13,253,14.88,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",26,"['        """"""\n', '        Transform Dataset into Dataset\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']","['_get_image_fn', 'ds.get_image_only', 'self.transform_sample', 'dataset.ImageDataset', 'transform_sample', 'util_image.image_remove_extra_padding']",6
utilmy/templates/templist/pypi_package/mygenerator/transform.py:RemoveWhitePadding:transform_sample,RemoveWhitePadding:transform_sample,method,2,2,2,50,25.0,0,0,"['self', 'image']","[None, ' np.ndarray']","[None, None]",129,"['        """"""\n', '        Remove surrounding white spaces in digit image\n', '\n', '        Parameters\n', '        ----------\n', '        image: image of the digit\n', '\n', '        returns\n', '        -------\n', '        crop: cropped image\n', '        """"""\n']",['util_image.image_remove_extra_padding'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CombineImagesHorizontally:__init__,CombineImagesHorizontally:__init__,method,5,5,5,86,17.2,0,0,"['self', 'padding_range', 'int]', 'combined_width']","[None, ' Tuple[int', None, ' int']","[None, None, None, None]",152,"['        """"""\n', '        Parameters\n', '        ----------\n', '        spacing_range:\n', '            a (minimum, maximum) int pair (tuple), representing the min and max spacing\n', '            between digits. Unit should be pixel.\n', '        image_width:\n', '            specifies the width of the image in pixels.\n', '        """"""\n']",['super'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CombineImagesHorizontally:transform,CombineImagesHorizontally:transform,method,13,26,24,415,15.96,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",26,"['        """"""\n', '        Transform Dataset into Dataset\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']","['_get_image_fn', 'ds.get_image_only', 'self.transform_sample', 'dataset.ImageDataset', 'transform_sample']",5
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CombineImagesHorizontally:transform_sample,CombineImagesHorizontally:transform_sample,method,51,189,141,1812,9.59,1,3,"['self', 'image_list', '1', '1)', 'combined_width', 'min_image_width', 'validate', '']","[None, ' List[np.ndarray]', None, None, None, None, None, None]","[None, None, None, None, '10', '2', 'True', None]",176,"['        """"""\n', '        Combine images of individual digits horizontally to make image of the complete number\n', '        Parameters\n', '        ----------\n', '        image_list: list of np.ndarray containing images of each digit\n', '        padding_range: (minimum space between two digits, maximum space between two digits)\n', '        combined_width: total width of the image\n', '        returns\n', '        -------\n', '        final_image: combined image of number\n', '        padding_size: padding between each digits in a number\n', '        """"""\n']","['len', 'util_image.padding_generate', 'np.sum', 'int', 'enumerate', 'cv2.resize', 'new_img_list.append', 'Exception', 'util_image.image_merge', 'cv2.bitwise_not', 'image_padding_validate', 'logw', 'np.zeros']",13
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ScaleImage:__init__,ScaleImage:__init__,method,7,7,7,71,10.14,0,0,"['self', 'width', 'height', 'inter']","[None, ' Optional[int] ', ' Optional[int] ', None]","[None, ' None', ' None', 'cv2.INTER_AREA']",312,"['        """"""\n', '        width and height specify output image dimensions\n', '        """"""\n']",['super'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ScaleImage:transform,ScaleImage:transform,method,8,23,20,336,14.61,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",26,"['        """"""\n', '        Transform Dataset into Dataset\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']","['_get_image_fn', 'ds.get_image_only', 'self.transform_sample', 'dataset.ImageDataset', 'transform_sample', 'util_image.image_resize']",6
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ScaleImage:transform_sample,ScaleImage:transform_sample,method,2,5,5,70,14.0,0,0,"['self', 'image', 'width', 'height', 'inter']","[None, None, None, None, None]","[None, None, 'None', 'None', 'cv2.INTER_AREA']",330,"['        """"""\n', '        Resizes a image and maintains aspect ratio.\n', '        """"""\n']",['util_image.image_resize'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:TextToImage:__init__,TextToImage:__init__,method,9,19,16,255,13.42,0,0,"['self', 'font_dir', 'pathlib.Path]', 'spacing_range', 'int]', 'image_width']","[None, ' Union[str', None, ' Tuple[int', None, ' int']","[None, None, None, None, None, None]",312,"['        """"""\n', '        width and height specify output image dimensions\n', '        """"""\n']","['dataset.ImageDataset', 'RemoveWhitePadding', 'CharToImages', 'CombineImagesHorizontally']",4
utilmy/templates/templist/pypi_package/mygenerator/transform.py:TextToImage:transform,TextToImage:transform,method,5,8,7,52,6.5,1,0,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",72,"['        """"""\n', '        Replaces features of the input dataset by mapping feature (string type)\n', '        to a list of character images (List[np.array] type)\n', '        """"""\n']",['tr.transform'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:TextToImage:fit,TextToImage:fit,method,3,10,9,111,11.1,0,0,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",96,"['        """"""\n', '        Args:\n', '            ds: dataset.NlpDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']","['fit_transform', 'self.fit']",2
utilmy/templates/templist/pypi_package/mygenerator/transform.py:TextToImage:fit_transform,TextToImage:fit_transform,method,2,2,2,32,16.0,0,0,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",104,"['        """"""\n', '        Updates internal parameters of this transformation and then\n', '        applies it to the provided dataset.\n', '        """"""\n']",['self.fit'],1
utilmy/templates/templist/pypi_package/mygenerator/utils.py:log,log,function,10,39,25,357,9.15,0,0,['*s'],[None],[None],19,[],"['logger.info', 'log2', 'logger.debug', 'logw', 'logger.warning', 'loge', 'logger.error', 'logger_setup', 'logger.configure']",9
utilmy/templates/templist/pypi_package/mygenerator/utils.py:log2,log2,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],23,[],['logger.debug'],1
utilmy/templates/templist/pypi_package/mygenerator/utils.py:logw,logw,function,1,5,5,41,8.2,0,0,['*s'],[None],[None],27,[],['logger.warning'],1
utilmy/templates/templist/pypi_package/mygenerator/utils.py:loge,loge,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],31,[],['logger.error'],1
utilmy/templates/templist/pypi_package/mygenerator/utils.py:logger_setup,logger_setup,function,2,15,13,138,9.2,0,0,[],[],[],35,[],['logger.configure'],1
utilmy/templates/templist/pypi_package/mygenerator/utils.py:config_load,config_load,function,16,73,62,816,11.18,0,1,"['config_path', 'pathlib.Path]] ']","[' Optional[Union[str', None]","[None, ' None']",52,"['    """"""Load Config file into a dict\n', '    1) load config_path\n', '    2) If not, load in HOME USER\n', '    3) If not, create default one\n', '    Args:\n', ""        config_path: path of config or 'default' tag value\n"", '    Returns: dict config\n', '    """"""\n']","['logw', 'log2', 'yaml.load', 'str', 'log', 'os.makedirs', 'open', 'yaml.dump']",8
utilmy/templates/templist/pypi_package/mygenerator/utils.py:dataset_donwload,dataset_donwload,function,9,19,17,246,12.95,0,0,"['url', 'path_target']","[None, None]","[None, None]",96,"['    """"""Donwload on disk the tar.gz file\n', '    Args:\n', '        url:\n', '        path_target:\n', '    Returns:\n', '\n', '    """"""\n']","['log', 'os.makedirs', 'wget.download', 'url.split', 'os_extract_archive', 'log2']",6
utilmy/templates/templist/pypi_package/mygenerator/utils.py:dataset_get_path,dataset_get_path,function,17,53,44,527,9.94,0,3,['cfg'],[' dict'],[None],113,[],"['cfg.get', 'cfgd.get', 'glob.glob', 'log2', 'len', 'dataset_donwload', 'Exception']",7
utilmy/templates/templist/pypi_package/mygenerator/utils.py:os_extract_archive,os_extract_archive,function,19,63,47,671,10.65,1,8,"['file_path', 'path', 'archive_format']","[None, None, None]","[None, '"".""', '""auto""']",142,"['    """"""Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n', '    Args:\n', '        file_path: path to the archive file\n', '        path: path to extract the archive file\n', '        archive_format: Archive format to try for extracting the file.\n', ""            Options are 'auto', 'tar', 'zip', and None.\n"", ""            'tar' includes tar, tar.gz, and tar.bz files.\n"", ""            The default 'auto' is ['tar', 'zip'].\n"", '            None or an empty list will return no matches found.\n', '    Returns:\n', '        True if a match was found and an archive extraction was completed,\n', '        False otherwise.\n', '    """"""\n']","['isinstance', 'is_match_fn', 'open_fn', 'archive.extractall', 'os.remove', 'shutil.rmtree']",6
utilmy/templates/templist/pypi_package/mygenerator/utils.py:to_file,to_file,function,3,7,7,51,7.29,0,0,"['s', 'filep']","[None, None]","[None, None]",189,[],"['open', 'fp.write']",2
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:log,log,function,10,39,25,357,9.15,0,0,['*s'],[None],[None],19,[],"['logger.info', 'log2', 'logger.debug', 'logw', 'logger.warning', 'loge', 'logger.error', 'logger_setup', 'logger.configure']",9
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:log2,log2,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],23,[],['logger.debug'],1
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:logw,logw,function,1,5,5,41,8.2,0,0,['*s'],[None],[None],27,[],['logger.warning'],1
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:loge,loge,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],31,[],['logger.error'],1
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:logger_setup,logger_setup,function,2,15,13,138,9.2,0,0,[],[],[],35,[],['logger.configure'],1
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:config_load,config_load,function,16,73,62,816,11.18,0,1,"['config_path', 'pathlib.Path]] ']","[' Optional[Union[str', None]","[None, ' None']",52,"['    """"""Load Config file into a dict\n', '    1) load config_path\n', '    2) If not, load in HOME USER\n', '    3) If not, create default one\n', '    Args:\n', ""        config_path: path of config or 'default' tag value\n"", '    Returns: dict config\n', '    """"""\n']","['logw', 'log2', 'yaml.load', 'str', 'log', 'os.makedirs', 'open', 'yaml.dump']",8
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:dataset_donwload,dataset_donwload,function,9,19,17,246,12.95,0,0,"['url', 'path_target']","[None, None]","[None, None]",96,"['    """"""Donwload on disk the tar.gz file\n', '    Args:\n', '        url:\n', '        path_target:\n', '    Returns:\n', '\n', '    """"""\n']","['log', 'os.makedirs', 'wget.download', 'url.split', 'os_extract_archive', 'log2']",6
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:dataset_get_path,dataset_get_path,function,17,53,44,527,9.94,0,3,['cfg'],[' dict'],[None],113,[],"['cfg.get', 'cfgd.get', 'glob.glob', 'log2', 'len', 'dataset_donwload', 'Exception']",7
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:os_extract_archive,os_extract_archive,function,19,63,47,671,10.65,1,8,"['file_path', 'path', 'archive_format']","[None, None, None]","[None, '"".""', '""auto""']",142,"['    """"""Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n', '    Args:\n', '        file_path: path to the archive file\n', '        path: path to extract the archive file\n', '        archive_format: Archive format to try for extracting the file.\n', ""            Options are 'auto', 'tar', 'zip', and None.\n"", ""            'tar' includes tar, tar.gz, and tar.bz files.\n"", ""            The default 'auto' is ['tar', 'zip'].\n"", '            None or an empty list will return no matches found.\n', '    Returns:\n', '        True if a match was found and an archive extraction was completed,\n', '        False otherwise.\n', '    """"""\n']","['isinstance', 'is_match_fn', 'open_fn', 'archive.extractall', 'os.remove', 'shutil.rmtree']",6
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:to_file,to_file,function,3,7,7,51,7.29,0,0,"['s', 'filep']","[None, None]","[None, None]",189,[],"['open', 'fp.write']",2
utilmy/templates/templist/pypi_package/mygenerator/util_image.py:padding_generate,padding_generate,function,2,5,5,80,16.0,0,0,"['paddings_number', 'min_padding', 'max_padding']","[' int ', ' int ', ' int ']","[' 1', ' 1', ' 1']",12,"['    """"""\n', '    Args:\n', '        paddings_number:  4\n', '        min_padding:      1\n', '        max_padding:    100\n', '\n', '    Returns: padding list\n', '    """"""\n']",[],0
utilmy/templates/templist/pypi_package/mygenerator/util_image.py:image_merge,image_merge,function,32,73,51,554,7.59,1,3,"['image_list', 'n_dim', 'padding_size', 'max_height', 'total_width']","[None, None, None, None, None]","[None, None, None, None, None]",26,"['    """"""\n', '    Args:\n', '        image_list:  list of image\n', '        n_dim:\n', '        padding_size: padding size max\n', '        max_height:   max height\n', '        total_width:  total width\n', '\n', '    Returns:\n', '\n', '    """"""\n']","['np.zeros', 'len', 'enumerate']",3
utilmy/templates/templist/pypi_package/mygenerator/util_image.py:image_remove_extra_padding,image_remove_extra_padding,function,31,73,63,518,7.1,0,2,"['img', 'inverse', 'removedot']","[None, None, None]","[None, 'False', 'True']",62,"['    """"""TODO: Issue with small dot noise points : noise or not ?\n', '              Padding calc has also issues with small blobs.\n', '    Args:\n', '        img: image\n', '    Returns: image cropped of extra padding\n', '    """"""\n']","['cv2.cvtColor', 'max', 'int', 'np.where', 'morphology.remove_small_objects', 'graybin.astype', 'cv2.findNonZero', 'cv2.boundingRect']",8
utilmy/templates/templist/pypi_package/mygenerator/util_image.py:image_resize,image_resize,function,8,38,27,219,5.76,0,2,"['image', 'width', 'height', 'inter']","[None, None, None, None]","[None, 'None', 'None', 'cv2.INTER_AREA']",92,"['    """"""Resizes a image and maintains aspect ratio.\n', '    Args:\n', '        image:\n', '        width:\n', '        height:\n', '        inter:\n', '\n', '    Returns:\n', '\n', '    """"""\n']","['float', 'int', 'cv2.resize']",3
utilmy/templates/templist/pypi_package/mygenerator/util_image.py:image_read,image_read,function,12,45,34,578,12.84,0,3,"['filepath_or_buffer', 'io.BytesIO]']","[' Union[str', None]","[None, None]",126,"['    """"""\n', '    Read a file into an image object\n', '    Args:\n', '        filepath_or_buffer: The path to the file, a URL, or any object\n', '            with a `read` method (such as `io.BytesIO`)\n', '    """"""\n']","['isinstance', 'hasattr', 'np.asarray', 'cv2.imdecode', 'filepath_or_buffer.endswith', 'tifffile.imread', 'cv2.imread', 'cv2.cvtColor']",8
utilmy/templates/templist/pypi_package/mygenerator/validate.py:image_padding_validate,image_padding_validate,function,6,30,28,259,8.63,0,1,"['final_image', 'min_padding', 'max_padding']","[None, None, None]","[None, None, None]",12,"['    """"""\n', '    Args:\n', '        final_image:\n', '        min_padding:\n', '        max_padding:\n', '\n', '    Returns:\n', '\n', '    """"""\n']","['image_padding_get', 'sum', 'len', 'logw']",4
utilmy/templates/templist/pypi_package/mygenerator/validate.py:image_padding_load,image_padding_load,function,6,9,7,117,13.0,0,0,"['img_path', 'threshold']","[None, None]","[None, '15']",34,"['    """"""\n', '    Args:\n', '        img_path:\n', '        threshold:\n', '\n', '    Returns number of consecutive blank columns in the image.\n', '    Example return value: [4, 8, 3] means that image contains\n', '    3 blank columns. The size of each corresponding column in pixels\n', '    is 4, 8 and 3.\n', '    """"""\n']","['util_image.image_read', 'image_padding_get']",2
utilmy/templates/templist/pypi_package/mygenerator/validate.py:image_padding_get,image_padding_get,function,21,81,40,476,5.88,1,7,"['img', 'threshold', 'inverse']","[None, None, None]","[None, '0', 'True']",50,"['    """"""\n', '    Args:\n', '         img_path:\n', '         threshold:\n', '      Returns number of consecutive blank columns in the image.\n', '      Example return value: [4, 8, 3] means that image contains\n', '      3 blank columns. The size of each corresponding column in pixels\n', '      is 4, 8 and 3.\n', '    """"""\n']","['cv2.bitwise_not', 'range', 'np.sum', 'xpad_list.append', 'xchar_list.append']",5
utilmy/templates/templist/pypi_package/mygenerator/validate.py:run_image_padding_validate,run_image_padding_validate,function,14,59,47,463,7.85,1,2,"['min_spacing', 'max_spacing', 'image_width', 'input_path', 'inverse_image', 'config_file', '**kwargs', '']","[' int ', ' int ', ' int ', ' str ', ' bool ', ' str ', None, None]","[' 1', ' 1', ' 5', ' """"', ' True', ' ""default""', None, None]",104,"['    """"""\n', '    Args:\n', '        min_spacing:\n', '        max_spacing:\n', '        image_width:\n', '        input_path:\n', '        config_file:\n', '        **kwargs:\n', '    Returns: None\n', '\n', '    """"""\n']","['sorted', 'log', 'len', 'util_image.image_read', 'image_padding_get', 'logw', 'sum']",7
utilmy/templates/templist/pypi_package/tests/test_dataset.py:test_image_dataset_get_label_list,test_image_dataset_get_label_list,function,5,12,12,161,13.42,0,0,[],[],[],7,[],"['dataset.ImageDataset', 'ds.get_label_list', 'np.asarray']",3
utilmy/templates/templist/pypi_package/tests/test_dataset.py:test_image_dataset_len,test_image_dataset_len,function,3,11,10,92,8.36,0,0,[],[],[],15,[],"['dataset.ImageDataset', 'len']",2
utilmy/templates/templist/pypi_package/tests/test_dataset.py:test_image_dataset_get_sampe,test_image_dataset_get_sampe,function,11,37,31,318,8.59,0,0,[],[],[],23,[],"['_dummy_get_image_fn', 'dataset.ImageDataset', 'ds.get_sample']",3
utilmy/templates/templist/pypi_package/tests/test_dataset.py:test_image_dataset_get_image_only,test_image_dataset_get_image_only,function,12,35,31,351,10.03,0,0,[],[],[],40,[],"['_get_image_fn', 'np.asarray', 'dataset.ImageDataset', 'ds.get_image_only']",4
utilmy/templates/templist/pypi_package/tests/test_dataset.py:test_nlp_dataset_len,test_nlp_dataset_len,function,2,10,10,96,9.6,0,0,[],[],[],61,[],"['dataset.NlpDataset', 'range', 'len']",3
utilmy/templates/templist/pypi_package/tests/test_import.py:test_import,test_import,function,13,26,16,175,6.73,0,0,[],[],[],3,[],[],0
utilmy/templates/templist/pypi_package/tests/test_pipeline.py:test_generate_phone_numbers,test_generate_phone_numbers,function,19,51,42,579,11.35,1,0,['tmp_path'],[None],[None],10,[],"['random.seed', 'pipeline.run_generate_phone_numbers', 'output_path=str', 'meta_file.exists', 'meta_file.is_file', 'pd.read_csv', 'len', 'output_path.glob', 'cv2.imread']",9
utilmy/templates/templist/pypi_package/tests/test_transform.py:test_chars_to_images_transform,test_chars_to_images_transform,function,20,92,66,803,8.73,0,0,[],[],[],13,[],"['_get_image_fn', 'np.asarray', 'dataset.ImageDataset', 'dataset.NlpDataset', 'transform.CharToImages', 'tr.fit_transform', 'len', 'ds.get_sample', 'meta.to_dict']",9
utilmy/templates/templist/pypi_package/tests/test_transform.py:test_combine_images_horizontally_transform,test_combine_images_horizontally_transform,function,22,67,53,566,8.45,0,0,[],[],[],50,[],"['_get_image_fn', 'np.zeros', 'dataset.ImageDataset', 'transform.CombineImagesHorizontally', 'len', 'ds.get_sample', 'meta.to_dict']",7
utilmy/templates/templist/pypi_package/tests/test_transform.py:test_scale_image_transform,test_scale_image_transform,function,9,78,52,571,7.32,0,0,[],[],[],88,[],"['_get_image_fn', 'np.asarray', 'dataset.ImageDataset', 'transform.ScaleImage', 'len', 'ds.get_image_only']",6
utilmy/templates/templist/pypi_package/tests/test_transform.py:create_font_files,create_font_files,function,19,44,42,425,9.66,1,0,['font_dir'],[None],[None],143,"['    """"""\n', '    Args:\n', '        font_dir:  image directory\n', '    Returns:\n', '\n', '    """"""\n']","['range', 'str', 'dig_folder.mkdir', 'np.zeros', 'cv2.putText', 'cv2.imwrite']",6
utilmy/templates/templist/pypi_package/tests/test_transform.py:test_text_to_image_transform,test_text_to_image_transform,function,23,75,50,742,9.89,0,0,['tmp_path'],[None],[None],169,[],"['random.seed', 'create_font_files', 'dataset.NlpDataset', 'transform.TextToImage', 'len', 'ds.get_sample', 'np.mean', 'meta.to_dict']",8
utilmy/templates/templist/pypi_package/tests/test_util_image.py:create_blank_image,create_blank_image,function,6,11,10,101,9.18,0,0,"['width', 'height', 'rgb_color', '0', '0']","[None, None, None, None, None]","[None, None, '(0', None, None]",8,"['    """"""Create new image(numpy array) filled with certain color in RGB""""""\n']","['np.zeros', 'tuple']",2
utilmy/templates/templist/pypi_package/tests/test_util_image.py:test_image_merge,test_image_merge,function,6,93,36,395,4.25,0,0,[],[],[],23,[],"['np.asarray', 'util_image.image_merge']",2
utilmy/templates/templist/pypi_package/tests/test_util_image.py:test_image_remove_extra_padding,test_image_remove_extra_padding,function,15,39,34,472,12.1,0,0,[],[],[],63,[],"['create_blank_image', 'cv2.rectangle', 'util_image.image_remove_extra_padding', 'log2']",4
utilmy/templates/templist/pypi_package/tests/test_util_image.py:test_image_resize,test_image_resize,function,4,38,21,223,5.87,0,0,[],[],[],80,[],"['np.asarray', 'util_image.image_resize']",2
utilmy/templates/templist/pypi_package/tests/test_util_image.py:test_image_read,test_image_read,function,8,12,12,203,16.92,0,0,['tmp_path'],[None],[None],107,[],"['create_blank_image', 'str', 'cv2.imwrite', 'util_image.image_read']",4
utilmy/templates/templist/pypi_package/tests/test_validate.py:test_image_padding_get,test_image_padding_get,function,8,43,31,295,6.86,0,0,[],[],[],8,[],"['np.zeros', 'image_padding_get']",2
utilmy/zarchive/storage/aapackage_gen/34/util34.py:getmodule_doc,getmodule_doc,function,6,8,8,69,8.62,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",18,[],['ca.getmodule_doc'],1
utilmy/zarchive/storage/aapackage_gen/34/Working Copy of util34.py:getmodule_doc,getmodule_doc,function,6,8,8,69,8.62,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",18,[],['ca.getmodule_doc'],1
utilmy/zarchive/storage/aapackage_gen/old/util27.py:getmodule_doc,getmodule_doc,function,6,8,8,69,8.62,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",20,[],['ca.getmodule_doc'],1
utilmy/zarchive/storage/aapackage_gen/old/util34.py:getmodule_doc,getmodule_doc,function,6,8,8,69,8.62,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",18,[],['ca.getmodule_doc'],1
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",14,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:numexpr_topanda,numexpr_topanda,function,10,28,22,248,8.86,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",27,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:convertcsv_topanda,convertcsv_topanda,function,9,22,19,182,8.27,1,0,"['filein1', 'filename', 'tablen']","[None, None, None]","[None, None, ""'data'""]",39,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:getpanda_tonumpy,getpanda_tonumpy,function,6,10,10,92,9.2,0,0,"['filename', 'nsize', 'tablen']","[None, None, None]","[None, None, ""'data'""]",51,[],['pd.read_hdf'],1
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:getrandom_tonumpy,getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample', 'tablen']","[None, None, None, None]","[None, None, None, ""'data'""]",56,[],['pd.read_hdf'],1
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",87,[],['ne.evaluate'],1
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],95,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:unique_rows,unique_rows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],116,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:remove_zeros,remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",121,[],[],0
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:sort_array,sort_array,function,2,8,8,74,9.25,0,0,['vv'],[None],[None],124,[],[],0
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:save_topanda,save_topanda,function,7,16,16,199,12.44,0,0,"['vv', 'filenameh5)', 'pdf); store.close()filenameh5)', ""'data')    #from filereturn pdf.values   #to numpy vectorxx"", 'yy', 'title1="""")']","[None, ""  # 'E:\\_data\\_data_outlier.h5'filenameh5)vv); store.append('data'"", ""  # 'E:\\_data\\_data_outlier.h5'fileoutlier"", None, None, '']","[None, None, None, None, None, '""""):']",129,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:load_frompanda,load_frompanda,function,7,16,16,199,12.44,0,0,"['filenameh5)', ""'data')    #from filereturn pdf.values   #to numpy vectorxx"", 'yy', 'title1="""")']","[""  # 'E:\\_data\\_data_outlier.h5'fileoutlier"", None, None, '']","[None, None, None, '""""):']",134,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:plotsave,plotsave,function,7,16,16,199,12.44,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",145,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:plotshow,plotshow,function,6,15,15,159,10.6,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",156,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.show']",5
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:parsePDF,parsePDF,function,38,80,69,838,10.47,1,0,['url'],[None],[None],320,[],"['urllib2.urlopen', 'StringIO', 'PDFParser', 'PDFDocument', 'PDFResourceManager', 'LAParams', 'TextConverter', 'PDFPageInterpreter', 'PDFPage.create_pages', 'interpreter.process_page', 'retstr.getvalue', 're.findall', 're.search', 'float', 'match.group']",15
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",14,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:numexpr_topanda,numexpr_topanda,function,10,28,22,248,8.86,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",27,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:convertcsv_topanda,convertcsv_topanda,function,9,22,19,182,8.27,1,0,"['filein1', 'filename', 'tablen']","[None, None, None]","[None, None, ""'data'""]",39,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:getpanda_tonumpy,getpanda_tonumpy,function,6,10,10,92,9.2,0,0,"['filename', 'nsize', 'tablen']","[None, None, None]","[None, None, ""'data'""]",51,[],['pd.read_hdf'],1
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:getrandom_tonumpy,getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample', 'tablen']","[None, None, None, None]","[None, None, None, ""'data'""]",56,[],['pd.read_hdf'],1
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",87,[],['ne.evaluate'],1
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],95,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:unique_rows,unique_rows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],116,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:remove_zeros,remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",121,[],[],0
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:sort_array,sort_array,function,2,8,8,74,9.25,0,0,['vv'],[None],[None],124,[],[],0
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:save_topanda,save_topanda,function,7,16,16,199,12.44,0,0,"['vv', 'filenameh5)', 'pdf); store.close()filenameh5)', ""'data')    #from filereturn pdf.values   #to numpy vectorxx"", 'yy', 'title1="""")']","[None, ""  # 'E:\\_data\\_data_outlier.h5'filenameh5)vv); store.append('data'"", ""  # 'E:\\_data\\_data_outlier.h5'fileoutlier"", None, None, '']","[None, None, None, None, None, '""""):']",129,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:load_frompanda,load_frompanda,function,7,16,16,199,12.44,0,0,"['filenameh5)', ""'data')    #from filereturn pdf.values   #to numpy vectorxx"", 'yy', 'title1="""")']","[""  # 'E:\\_data\\_data_outlier.h5'fileoutlier"", None, None, '']","[None, None, None, '""""):']",134,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:plotsave,plotsave,function,7,16,16,199,12.44,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",145,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:plotshow,plotshow,function,6,15,15,159,10.6,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",156,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.show']",5
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:parsePDF,parsePDF,function,38,80,69,838,10.47,1,0,['url'],[None],[None],320,[],"['urllib2.urlopen', 'StringIO', 'PDFParser', 'PDFDocument', 'PDFResourceManager', 'LAParams', 'TextConverter', 'PDFPageInterpreter', 'PDFPage.create_pages', 'interpreter.process_page', 'retstr.getvalue', 're.findall', 're.search', 'float', 'match.group']",15
utilmy/zarchive/storage/aapackage_gen/old/Working Copy of util34.py:getmodule_doc,getmodule_doc,function,6,8,8,69,8.62,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",18,[],['ca.getmodule_doc'],1
uri,name,type,n_variable,n_words,n_words_unique,n_characters,avg_char_per_word,n_loop,n_ifthen,arg_name,arg_type,arg_value,line,docs,list_functions,n_functions
utilmy/dates.py:log,log,function,1,1,1,9,9.0,0,0,['*s'],[None],[None],6,[],['print'],1
utilmy/dates.py:pd_date_split,pd_date_split,function,31,153,68,1005,6.57,1,2,"['df', 'coldate ', 'prefix_col ', 'verbose']","[None, None, None, None]","[None, ""  'time_key'"", '""""', 'False']",11,[],"['df.drop_duplicates', 'pd.to_datetime', 'x.weekday', 'date_weekmonth', 'date_weekmonth2', 'x.isocalendar', 'date_weekyear2', 'df.apply', 'int', 'merge1', 'date_is_holiday', 'log']",12
utilmy/dates.py:date_now,date_now,function,14,17,15,220,12.94,0,0,"['fmt=""%Y-%m-%d %H', 'add_days', 'timezone']","['', None, None]","['""%Y-%m-%d %H:%M:%S %Z%z""', '0', ""'Asia/Tokyo'""]",41,[],"['datetime.now', 'datetime.timedelta', 'now_new.astimezone', 'now_pacific.strftime']",4
utilmy/dates.py:date_is_holiday,date_is_holiday,function,8,23,21,146,6.35,0,0,['array'],[None],[None],53,"['    """"""\n', '      is_holiday([ pd.to_datetime(""2015/1/1"") ] * 10)\n', '\n', '    """"""\n']","['holidays.CountryHoliday', 'np.array', 'x.astype']",3
utilmy/dates.py:date_weekmonth2,date_weekmonth2,function,3,17,12,51,3.0,0,1,['d'],[None],[None],63,[],[],0
utilmy/dates.py:date_weekmonth,date_weekmonth,function,4,37,18,194,5.24,0,2,['d'],[None],[None],71,[],"['date_weekmonth', 'date_value.replace']",2
utilmy/dates.py:date_weekyear2,date_weekyear2,function,1,6,6,53,8.83,0,0,['dt'],[None],[None],80,[],['datetime.datetime'],1
utilmy/dates.py:date_weekday_excel,date_weekday_excel,function,7,17,15,98,5.76,0,1,['x'],[None],[None],84,[],"['arrow.get', 'str']",2
utilmy/dates.py:date_weekyear_excel,date_weekyear_excel,function,14,47,40,302,6.43,0,1,['x'],[None],[None],91,[],"['arrow.get', 'str', 'dd.isocalendar', 'date_weekday_excel', 'int']",5
utilmy/dates.py:date_generate,date_generate,function,8,17,16,174,10.24,0,0,"['start', 'ndays']","[None, None]","[""'2018-01-01'"", '100']",110,[],"['relativedelta', 'range']",2
utilmy/decorators.py:thread_decorator,thread_decorator,function,6,14,13,185,13.21,0,0,['func'],[None],[None],11,"['    """""" A decorator to run function in background on thread\n', '\tReturn:\n', '\t\tbackground_thread: ``Thread``\n', '    """"""\n']","['wrapper', 'Thread', 'background_thread.start']",3
utilmy/decorators.py:timeout_decorator,timeout_decorator,function,11,25,21,297,11.88,0,0,"['seconds', 'error_message']","[None, None]","['10', 'os.strerror(errno.ETIME']",36,"['    """"""Decorator to throw timeout error, if function doesnt complete in certain time\n', '    Args:\n', '        seconds:``int``\n', '            No of seconds to wait\n', '        error_message:``str``\n', '            Error message\n', '            \n', '    """"""\n']","['decorator', '_handle_timeout', '_TimeoutError', 'wrapper', 'signal.signal', 'signal.alarm', 'func', 'wraps']",8
utilmy/decorators.py:timer_decorator,timer_decorator,function,8,22,20,208,9.45,0,0,['func'],[None],[None],63,"['    """"""\n', '    Decorator to show the execution time of a function or a method in a class.\n', '    """"""\n']","['wrapper', 'time.perf_counter', 'func', 'print']",4
utilmy/decorators.py:profiler_context,profiler_context,function,9,20,20,191,9.55,0,0,[],[],[],81,"['    """"""\n', ""    Context Manager the will profile code inside it's bloc.\n"", '    And print the result of profiler.\n', '    Example:\n', '        with profiler_context():\n', '            # code to profile here\n', '    """"""\n']","['Profiler', 'profiler.start', 'profiler.stop', 'print']",4
utilmy/decorators.py:profiler_decorator,profiler_decorator,function,26,45,39,511,11.36,0,0,['func'],[None],[None],101,"['    """"""\n', '    A decorator that will profile a function\n', '    And print the result of profiler.\n', '    """"""\n']","['wrapper', 'Profiler', 'profiler.start', 'func', 'profiler.stop', 'print', 'profiler_decorator_base', 'inner', 'cProfile.Profile', 'pr.enable', 'fnc', 'pr.disable', 'io.StringIO', 'pstats.Stats', 'ps.print_stats']",15
utilmy/decorators.py:profiler_decorator_base,profiler_decorator_base,function,15,23,22,245,10.65,0,0,['fnc'],[None],[None],119,"['    """"""\n', '    A decorator that uses cProfile to profile a function\n', '    And print the result\n', '    """"""\n']","['inner', 'cProfile.Profile', 'pr.enable', 'fnc', 'pr.disable', 'io.StringIO', 'pstats.Stats', 'ps.print_stats', 'print']",9
utilmy/decorators.py:_TimeoutError,_TimeoutError,class,0,1,1,4,4.0,0,0,[],[],[],30,[],[],0
utilmy/deeplearning.py:tensorboard_log,tensorboard_log,function,23,58,46,498,8.59,2,4,"['pars_dict', 'writer', 'verbose']","['dict', None, None]","['None', 'None', 'True']",6,"['    """"""\n', '    #### Usage 1 \n', ""    logdir = 'logs/params'\n"", '\n', '    from tensorboardX import SummaryWriter\n', '    # from tensorboard import SummaryWriter\n', '    tb_writer = SummaryWriter(logdir)\n', '    tensorboard_log(cc, writer= tb_writer)\n', '\n', '    %reload_ext tensorboard\n', '    %tensorboard --logdir logs/params/\n', '    """"""\n']","['dict_flatten', 'd.items', 'isinstance', 'items.extend', 'items.append', 'dict', 'print', 'flatten_box.items', 'writer.add_scalar', 'writer.add_text', 'str', 'writer.close']",12
utilmy/distributed.py:log_mem,log_mem,function,3,9,9,76,8.44,0,0,['*s'],[None],[None],11,[],"['log2', 'str']",2
utilmy/distributed.py:date_now,date_now,function,11,14,12,174,12.43,0,0,"['fmt = ""%Y-%m-%d %H']",[''],"[' ""%Y-%m-%d %H:%M:%S %Z%z""']",22,[],"['datetime.now', 'now_utc.astimezone', 'now_pacific.strftime']",3
utilmy/distributed.py:sleep_random,sleep_random,function,4,6,6,52,8.67,0,0,['nmax'],[None],['5'],31,[],"['time.sleep', 'random.randrange']",2
utilmy/distributed.py:load_serialize,load_serialize,function,5,10,9,66,6.6,0,0,['name'],[None],[None],36,[],"['log2', 'load']",2
utilmy/distributed.py:save_serialize,save_serialize,function,3,8,7,56,7.0,0,0,"['name', 'value']","[None, None]","[None, None]",44,[],"['log2', 'save']",2
utilmy/distributed.py:os_lock_acquireLock,os_lock_acquireLock,function,6,12,11,144,12.0,0,0,['plock'],[None],[None],51,[],"['open', 'fcntl.flock']",2
utilmy/distributed.py:os_lock_releaseLock,os_lock_releaseLock,function,3,4,4,61,15.25,0,0,['locked_file_descriptor'],[None],[None],59,[],['fcntl.flock'],1
utilmy/distributed.py:os_lock_execute,os_lock_execute,function,8,25,20,160,6.4,1,0,"['fun_run', 'pars', 'ntry', 'plock']","[None, None, None, None]","[None, None, '5', '""tmp/plock.lock""']",66,[],"['acquireLock', 'fun_run', 'releaseLock', 'log2', 'time.sleep']",5
utilmy/distributed.py:IndexLock,IndexLock,class,20,78,52,564,7.23,1,1,[],[],[],82,[],[],0
utilmy/distributed.py:IndexLock:__init__,IndexLock:__init__,method,4,4,4,35,8.75,0,0,"['self', 'findex', 'plock']","[None, None, None]","[None, None, None]",89,[],[],0
utilmy/distributed.py:IndexLock:get,IndexLock:get,method,5,10,9,66,6.6,0,0,"['self', 'val', 'ntry', 'plock']","[None, None, None, None]","[None, '""""', '5', '""tmp/plock.lock""']",94,[],"['open', 'fp.readlines']",2
utilmy/distributed.py:IndexLock:put,IndexLock:put,method,13,48,38,327,6.81,1,1,"['self', 'val', 'ntry', 'plock']","[None, None, None, None]","[None, '""""', '5', '""tmp/plock.lock""']",100,[],"['os_lock_acquireLock', 'open', 'fp.readlines', 'set', 'fp.write', 'fpath.strip', 'os_lock_releaseLock', 'print', 'time.sleep']",9
utilmy/images.py:log,log,function,1,1,1,8,8.0,0,0,['*s'],[None],[None],13,[],['print'],1
utilmy/images.py:deps,deps,function,5,7,7,74,10.57,0,0,[],[],[],17,[],"['open', 'fp.readlines', 'print']",3
utilmy/images.py:read_image,read_image,function,18,50,37,703,14.06,0,4,"['filepath_or_buffer', 'io.BytesIO]']","[' typing.Union[str', None]","[None, None]",24,"['    """"""Read a file into an image object\n', '    Args:\n', '        filepath_or_buffer: The path to the file, a URL, or any object\n', '            with a `read` method (such as `io.BytesIO`)\n', '    """"""\n']","['isinstance', 'hasattr', 'np.asarray', 'cv2.imdecode', 'validators.url', 'read', 'filepath_or_buffer.endswith', 'tifffile.imread', 'cv2.imread', 'cv2.cvtColor']",10
utilmy/images.py:visualize_in_row,visualize_in_row,function,12,24,24,239,9.96,1,0,['**images'],[None],[None],53,"['    """"""Plot images in one row.""""""\n']","['len', 'plt.figure', 'enumerate', 'plt.subplot', 'plt.xticks', 'plt.yticks', 'plt.title', 'plt.imshow', 'plt.show']",9
utilmy/images.py:maintain_aspect_ratio_resize,maintain_aspect_ratio_resize,function,10,40,29,229,5.72,0,2,"['image', 'width', 'height', 'inter']","[None, None, None, None]","[None, 'None', 'None', 'cv2.INTER_AREA']",68,[],"['float', 'int', 'cv2.resize']",3
utilmy/io.py:screenshot,screenshot,function,9,22,16,132,6.0,0,0,"['output', 'monitors']","[None, None]","[""'fullscreen.png'"", '-1']",4,"['  """"""\n', '  with mss() as sct:\n', '    for _ in range(100):\n', '        sct.shot()\n', '  # MacOS X\n', '  from mss.darwin import MSS as mss\n', '  \n', '  \n', '  """"""\n']","['sct.shot', 'print']",2
utilmy/multithread.py:multithread_run,multithread_run,function,38,114,84,1004,8.81,7,2,"['fun_async', 'input_list', 'n_pool', 'verbose']","[None, 'list', None, None]","[None, None, '5', 'True']",8,"['    """"""  input is as list of tuples  [(x1,x2,x3), (y1,y2,y3) ]\n', '    def fun_async(xlist):\n', '      for x in xlist :\n', '            hdfs.upload(x[0], x[1])\n', '    """"""\n']","['range', 'enumerate', 'ThreadPool', 'job_list.append', 'pool.apply_async', 'log', 'len', 'res_list.append', 'pool.terminate', 'pool.join', 'multithread_run_list', 'ThreadWithResult', '__init__', 'function', 'target', 'super', 'kwargs.values', 'list_of_threads.append', 'thread.start', 'zip', 'kwargs.keys', 'thread.join', 'results.append']",23
utilmy/multithread.py:multithread_run_list,multithread_run_list,function,19,48,40,530,11.04,3,0,['**kwargs'],[None],[None],37,"['    """""" Creating n number of threads:  1 thread per function,    starting them and waiting for their subsequent completion\n', '    os_multithread(function1=(test_print, (""some text"",)),\n', '                          function2=(test_print, (""bbbbb"",)),\n', '                          function3=(test_print, (""ccccc"",)))\n', '    """"""\n']","['ThreadWithResult', '__init__', 'function', 'target', 'super', 'kwargs.values', 'list_of_threads.append', 'thread.start', 'zip', 'kwargs.keys', 'thread.join', 'results.append']",12
utilmy/tabular.py:log,log,function,1,1,1,8,8.0,0,0,['*s'],[None],[None],12,[],['print'],1
utilmy/tabular.py:test_anova,test_anova,function,23,78,55,663,8.5,2,1,"['df', 'col1', 'col2']","[None, None, None]","[None, None, None]",19,"['    """"""\n', '    ANOVA test two categorical features\n', '    Input dfframe, 1st feature and 2nd feature\n', '    """"""\n']","['edu_frame.groupby', 'groups.keys', 'globals', 'lg.append', 'dfd=len', 'print', 'stats.f_oneway', 'dfn=len']",8
utilmy/tabular.py:test_normality2,test_normality2,function,19,122,59,890,7.3,1,6,"['df', 'column', 'test_type']","[None, None, None]","[None, None, None]",48,"['    """"""\n', '    Function to check Normal Distribution of a Feature by 3 methods\n', '    Input dfframe, feature name, and a test type\n', '    Three types of test\n', ""    1)'Shapiro'\n"", ""    2)'Normal'\n"", ""    3)'Anderson'\n"", '\n', '    output the statistical test score and result whether accept or reject\n', '    Accept mean the feature is Gaussain\n', '    Reject mean the feature is not Gaussain\n', '    """"""\n']","['shapiro', 'print', 'normaltest', 'anderson', 'range']",5
utilmy/tabular.py:test_plot_qqplot,test_plot_qqplot,function,15,29,25,338,11.66,0,0,"['df', 'col_name']","[None, None]","[None, None]",95,"['    """"""\n', '    Function to plot boxplot, histplot and qqplot for numerical feature analyze\n', '    """"""\n']","['plt.subplots', 'fig.suptitle', 'sns.boxplot', 'sns.histplot', 'sm.qqplot', 'print']",6
utilmy/tabular.py:test_heteroscedacity,test_heteroscedacity,function,61,111,85,993,8.95,0,0,"['y', 'y_pred', 'pred_value_only']","[None, None, None]","[None, None, '1']",112,[],"['Linear', 'custom_stat', 'np.sqrt', 'print', 'df.profile_report', 'profile.to_file', 'profile.get_rejected_variables']",7
utilmy/tabular.py:pd_stat_distribution_colnum,pd_stat_distribution_colnum,function,23,84,72,646,7.69,1,3,"['df', 'nrows', 'verbose']","[None, None, None]","[None, '2000', 'False']",289,"['    """""" Stats the tables\n', '    """"""\n']","['df.sample', 'getstat', 'str', 'len', 'pd.DataFrame', 'pd.concat', 'print', 'np.arange']",8
utilmy/tabular.py:pd_stat_histogram,pd_stat_histogram,function,10,21,20,220,10.48,0,0,"['df', 'bins', 'coltarget']","[None, None, None]","[None, '50', '""diff""']",329,"['    """"""\n', '    :param df:\n', '    :param bins:\n', '    :param coltarget:\n', '    :return:\n', '    """"""\n']","['np.histogram', 'pd.DataFrame']",2
utilmy/tabular.py:np_col_extractname,np_col_extractname,function,7,38,24,216,5.68,1,5,['col_onehot'],[None],[None],344,"['    """"""\n', '    Column extraction from onehot name\n', '    :param col_onehotp\n', '    :return:\n', '    """"""\n']","['len', 'colnew.append']",2
utilmy/tabular.py:np_list_remove,np_list_remove,function,12,42,26,214,5.1,3,4,"['cols', 'colsremove', 'mode']","[None, None, None]","[None, None, '""exact""']",367,"['    """"""\n', '    """"""\n']","['cols.remove', 'cols3.append']",2
utilmy/tabular.py:pd_stat_shift_trend_changes,pd_stat_shift_trend_changes,function,20,41,35,660,16.1,0,0,"['df', 'feature', 'target_col', 'threshold']","[None, None, None, None]","[None, None, None, '0.03']",392,"['    """"""\n', '    Calculates number of times the trend of feature wrt target changed direction.\n', '    :param df: df_grouped dataset\n', '    :param feature: feature column name\n', '    :param target_col: target column\n', '    :param threshold: minimum % difference required to count as trend change\n', '    :return: number of trend chagnes for the feature\n', '    """"""\n']","['target_diffs.fillna', 'target_diffs.divide', 'target_diffs_norm.diff', 'target_diffs_lvl2.fillna', 'int']",5
utilmy/tabular.py:pd_stat_shift_trend_correlation,pd_stat_shift_trend_correlation,function,19,63,55,788,12.51,0,2,"['df', 'df_test', 'colname', 'target_col']","[None, None, None, None]","[None, None, None, None]",416,"['    """"""\n', '    Calculates correlation between train and test trend of colname wrt target.\n', '    :param df: train df data\n', '    :param df_test: test df data\n', '    :param colname: colname column name\n', '    :param target_col: target column name\n', '    :return: trend correlation between train and test\n', '    """"""\n']","['df.merge', 'pd.isnull', 'len', 'np.corrcoef', 'print']",5
utilmy/tabular.py:pd_stat_shift_changes,pd_stat_shift_changes,function,33,99,81,1236,12.48,1,4,"['df', 'target_col', 'features_list', 'bins', 'df_test']","[None, None, None, None, None]","[None, None, '0', '10', '0']",447,"['    """"""\n', '    Calculates trend changes and correlation between train/test for list of features\n', '    :param df: dfframe containing features and target columns\n', '    :param target_col: target column name\n', '    :param features_list: by default creates plots for all features. If list passed, creates plots of only those features.\n', '    :param bins: number of bins to be created from continuous colname\n', '    :param df_test: test df which has to be compared with input df for correlation\n', '    :return: dfframe with trend changes and trend correlation (if test df passed)\n', '    """"""\n']","['type', 'list', 'features_list.remove', 'ignored.append', 'pd_colnum_tocat_stat', 'pd_stat_shift_trend_correlation', 'pd_stat_shift_changes', 'stats_all.append', 'pd.DataFrame', 'len', 'print', 'str']",12
utilmy/tabular.py:np_conv_to_one_col,np_conv_to_one_col,function,5,11,10,137,12.45,0,0,"['np_array', 'sep_char']","[None, None]","[None, '""_""']",492,"['    """"""\n', '    converts string/numeric columns to one string column\n', '    :param np_array: the numpy array with more than one column\n', '    :param sep_char: the separator character\n', '    """"""\n']","['row2string', 'sep_char.join']",2
utilmy/text.py:log,log,function,1,1,1,8,8.0,0,0,['*s'],[None],[None],17,[],['print'],1
utilmy/text.py:pd_text_hash_create_lsh,pd_text_hash_create_lsh,function,22,32,29,327,10.22,2,0,"['df', 'col', 'sep', 'threshold', 'num_perm']","[None, None, None, None, None]","[None, None, '"" ""', '0.7', '10']",24,"[""    '''\n"", '    For each of the entry create a hash function\n', ""    '''\n""]","['MinHashLSH', 'enumerate', 'sentence.split', 'MinHash', 'set', 'v.update', 'hash_lines.append', 'lsh.insert']",8
utilmy/text.py:pd_text_getcluster,pd_text_getcluster,function,16,37,32,367,9.92,1,1,"['df', 'col', 'threshold', 'num_perm']","[None, None, None, None]","[None, None, None, None]",53,"[""    '''\n"", '    For each of the hash function find a cluster and assign unique id to the dataframe cluster_id\n', ""    '''\n""]","['pd_text_hash_create_lsh', 'enumerate', 'lsh.query', 'list']",4
utilmy/text.py:pd_similarity,pd_similarity,function,20,65,51,548,8.43,1,3,"['df', 'cols', 'algo']","[' pd.DataFrame', None, None]","[None, '[]', ""''""]",81,"[""    '''\n"", '        Return similarities between two columns with \n', ""        python's SequenceMatcher algorithm\n"", '\n', '        Args:\n', '            df (pd.DataFrame): Pandas Dataframe.\n', '            algo (String)    : rapidfuzz | editdistance \n', '            cols (list[str]) : List of of columns name (2 columns)\n', '\n', '        Returns:\n', '            pd.DataFrame\n', '\n', ""    '''\n""]","['len', 'Exception', 'find_similarity', 'fuzz.ratio', 'editdistance.eval', 'SequenceMatcher', 'df.apply']",7
utilmy/text.py:test_lsh,test_lsh,function,10,28,27,222,7.93,0,0,[],[],[],120,[],"['pd.DataFrame', 'pd_text_getcluster', 'df.head', 'print']",4
utilmy/utilmy.py:log,log,function,3,10,9,76,7.6,0,1,['*s'],[None],[None],6,[],"['print', 'log2']",2
utilmy/utilmy.py:log2,log2,function,2,6,6,32,5.33,0,1,"['*s', 'verbose']","[None, None]","[None, '1']",9,[],['print'],1
utilmy/utilmy.py:pd_merge,pd_merge,function,3,17,16,120,7.06,0,0,"['df1', 'df2', 'on', 'colkeep']","[None, None, None, None]","[None, None, 'None', 'None']",15,[],"['list', 'df1.join']",2
utilmy/utilmy.py:pd_plot_multi,pd_plot_multi,function,40,109,78,1103,10.12,2,3,"['df', 'plot_type', 'cols_axe1', 'cols_axe2', 'figsize', '4']","[None, None, 'list', 'list', None, None]","[None, 'None', '[]', '[]', '(8', None]",21,[],"['plt.figure', 'len', 'getattr', 'df.plot', 'plt.show', 'ax.set_ylabel', 'range', 'ax.get_legend_handles_labels', 'ax.twinx', 'ax_new.set_ylabel', 'ax_new.get_legend_handles_labels', 'ax.legend']",12
utilmy/utilmy.py:pd_filter,pd_filter,function,18,106,52,531,5.01,2,7,"['df', 'filter_dict', 'verbose']","[None, None, None]","[None, '""shop_id=11, l1_genre_id>600, l2_genre_id<80311,""', 'False']",70,"['    """"""\n', '     dfi = pd_filter2(dfa, ""shop_id=11, l1_genre_id>600, l2_genre_id<80311,"" )\n', '     dfi2 = pd_filter(dfa, {""shop_id"" : 11} )\n', '     ### Dilter dataframe with basic expr\n', '    """"""\n']","['isinstance', 'filter_dict.items', 'filter_dict.split', 'x_convert', 'str', 'dict', 'float', 'x.strip', 'print', 'len', 'x.split']",11
utilmy/utilmy.py:pd_to_file,pd_to_file,function,14,35,24,272,7.77,0,3,"['df', 'filei', 'check', 'verbose', '**kw']","[None, None, None, None, None]","[None, None, '""check""', 'True', None]",108,[],"['Path', 'os.makedirs', 'df.to_pickle', 'df.to_parquet', 'df.to_csv', 'gc.collect']",6
utilmy/utilmy.py:pd_read_file,pd_read_file,function,66,249,142,1645,6.61,4,18,"['path_glob', 'ignore_index', 'cols', 'verbose', 'nrows', 'concat_sort', 'n_pool', 'drop_duplicates', 'col_filter', 'col_filter_val', 'dtype_reduce', '**kw']","[None, None, None, None, None, None, None, None, None, None, None, None]","['""*.pkl""', 'True', 'None', 'False', '-1', 'True', '1', 'None', 'None', 'None', 'None', None]",134,"['  """"""  Read file in parallel from disk : very Fast\n', '  :param path_glob: list of pattern, or sep by "";""\n', '  :return:\n', '  """"""\n']","['log', 'print', 'isinstance', 'path_glob.split', 'file_list.extend', 'sorted', 'glob.glob', 'len', 'ThreadPool', 'pd.DataFrame', 'range', 'job_list.append', 'pool.apply_async', 'pd_dtype_reduce', 'dfi.drop_duplicates', 'gc.collect', 'pd.concat', 'pool.terminate', 'pool.join']",19
utilmy/utilmy.py:pd_sample_strat,pd_sample_strat,function,5,10,9,104,10.4,0,0,"['df', 'col', 'n']","[None, None, None]","[None, None, None]",217,[],"['df.groupby', 'x.sample']",2
utilmy/utilmy.py:pd_cartesian,pd_cartesian,function,12,22,18,154,7.0,0,0,"['df1', 'df2']","[None, None]","[None, None]",225,[],"['list', 'pd.merge']",2
utilmy/utilmy.py:pd_plot_histogram,pd_plot_histogram,function,24,71,45,428,6.03,0,4,"['dfi', 'path_save', 'nbin', 'q5', 'q95', 'nsample', 'show', 'clear']","[None, None, None, None, None, None, None, None]","[None, 'None', '20.0', '0.005', '0.995', ' -1', 'False', 'True']",237,[],"['dfi.quantile', 'dfi.hist', 'dfi.sample', 'plt.title', 'path_save.split', 'plt.show', 'os.makedirs', 'plt.savefig', 'print', 'plt.close']",10
utilmy/utilmy.py:pd_col_bins,pd_col_bins,function,8,19,18,128,6.74,0,0,"['df', 'col', 'nbins']","[None, None, None]","[None, None, '5']",262,[],"['pd.qcut', 'np.arange']",2
utilmy/utilmy.py:pd_dtype_reduce,pd_dtype_reduce,function,9,35,23,238,6.8,1,1,"['dfm', 'int0 ', 'float0 ']","[None, None, None]","[None, ""'int32'"", "" 'float32'""]",269,[],['np.dtype'],1
utilmy/utilmy.py:pd_dtype_count_unique,pd_dtype_count_unique,function,17,73,57,539,7.38,1,3,"['df', 'col_continuous']","[None, None]","[None, '[]']",278,"['    """"""Learns the number of categories in each variable and standardizes the data.\n', '        ----------\n', '        data: pd.DataFrame\n', '        continuous_ids: list of ints\n', '            List containing the indices of known continuous variables. Useful for\n', '            discrete data like age, which is better modeled as continuous.\n', '        Returns\n', '        -------\n', '        ncat:  number of categories of each variable. -1 if the variable is  continuous.\n', '    """"""\n']","['gef_is_continuous', 'np.sum', 'np.round', 'len', 'n', 'any', 'list', 'n=min']",8
utilmy/utilmy.py:pd_dtype_to_category,pd_dtype_to_category,function,15,36,29,350,9.72,1,3,"['df', 'col_exclude', 'treshold']","[None, None, None]","[None, None, '0.5']",317,"['  """"""\n', '    Convert string to category\n', '  """"""\n']","['isinstance', 'df.select_dtypes', 'len', 'float', 'pd.to_datetime', 'print']",6
utilmy/utilmy.py:pd_dtype_getcontinuous,pd_dtype_getcontinuous,function,10,43,29,261,6.07,1,2,"['df', 'cols_exclude', 'nsample']","[None, 'list', None]","[None, '[]', '-1']",336,[],"['len', 'str']",2
utilmy/utilmy.py:pd_del,pd_del,function,6,13,13,50,3.85,1,0,"['df', 'cols']","[None, 'list']","[None, None]",352,[],[],0
utilmy/utilmy.py:pd_add_noise,pd_add_noise,function,18,41,33,295,7.2,1,1,"['df', 'level', 'cols_exclude']","[None, None, 'list']","[None, '0.05', '[]']",361,[],"['pd.DataFrame', 'pd_dtype_getcontinuous', 'print']",3
utilmy/utilmy.py:pd_cols_unique_count,pd_cols_unique_count,function,10,43,29,261,6.07,1,2,"['df', 'cols_exclude', 'nsample']","[None, 'list', None]","[None, '[]', '-1']",375,[],"['len', 'str']",2
utilmy/utilmy.py:pd_show,pd_show,function,6,10,10,116,11.6,0,0,"['df', 'nrows', 'reader', '**kw']","[None, None, None, None]","[None, '100', ""'notepad.exe'"", None]",393,"['    """""" Show from Dataframe\n', '    """"""\n']",['os_makedirs'],1
utilmy/utilmy.py:diskcache_save,diskcache_save,function,20,55,44,366,6.65,1,1,"['df', 'colkey', 'colvalue', 'db_path', 'size_limit', 'timeout', 'shards']","[None, 'str', 'str', 'str', None, None, 'int']","[None, None, None, '""""', '50000000000', '999', '1']",407,"['    """""" Create dict type on disk, < 100 Gb\n', '       shards>1 : disk spaced is BLOCKED in advance, so high disk usage\n', '       shards is for concurrent writes\n', '    """"""\n']","['dc.Cache', 'FanoutCache', 'range', 'print', 'len']",5
utilmy/utilmy.py:diskcache_load,diskcache_load,function,11,34,29,213,6.26,0,1,"['db_path', 'size_limit', 'timeout', 'force_create']","[None, None, None, None]","['""""', '50000000000', '2', 'False']",427,"['    """""" Load cache dict from disk and use as dict\n', '       val = cache[mykey]\n', '    \n', '    """"""\n']","['dc.Cache', 'print', 'len']",3
utilmy/utilmy.py:to_dict,to_dict,function,2,2,2,8,4.0,0,0,['**kw'],[None],[None],448,[],[],0
utilmy/utilmy.py:to_timeunix,to_timeunix,function,2,16,12,187,11.69,0,2,['datex'],[None],"['""2018-01-16""']",453,[],"['isinstance', 'int', 'datex.timetuple']",3
utilmy/utilmy.py:to_datetime,to_datetime,function,5,8,8,45,5.62,0,0,['x'],[None],[None],461,[],"['pd.to_datetime', 'str']",2
utilmy/utilmy.py:np_list_intersection,np_list_intersection,function,4,10,8,24,2.4,1,1,"['l1', 'l2']","[None, None]","[None, None]",466,[],[],0
utilmy/utilmy.py:np_add_remove,np_add_remove,function,7,10,9,116,11.6,1,0,"['set_', 'to_remove', 'to_add']","[None, None, None]","[None, None, None]",470,[],"['set_.copy', 'result_temp.remove', 'result_temp.add']",3
utilmy/utilmy.py:to_float,to_float,function,1,8,6,46,5.75,0,0,['x'],[None],[None],479,[],['float'],1
utilmy/utilmy.py:to_int,to_int,function,1,8,6,44,5.5,0,0,['x'],[None],[None],486,[],"['int', 'float']",2
utilmy/utilmy.py:is_int,is_int,function,1,9,7,42,4.67,0,0,['x'],[None],[None],493,[],['int'],1
utilmy/utilmy.py:is_float,is_float,function,1,9,7,44,4.89,0,0,['x'],[None],[None],500,[],['float'],1
utilmy/utilmy.py:config_load,config_load,function,31,126,90,1072,8.51,2,4,"['config_path', 'path_default', 'config_default']","['str ', 'str', 'dict']","[' None', 'None', 'None']",512,"['    """"""Load Config file into a dict  from .json or .yaml file\n', '    TODO .cfg file\n', '    1) load config_path\n', '    2) If not, load default from HOME USER\n', '    3) If not, create default on in python code\n', '    Args:\n', ""        config_path: path of config or 'default' tag value\n"", '    Returns: dict config\n', '    """"""\n']","['str', 'log', 'pathlib.Path', 'yaml.load', 'x.items', 'json.load', 'os.makedirs', 'open', 'yaml.dump']",9
utilmy/utilmy.py:os_path_split,os_path_split,function,10,27,21,215,7.96,0,2,['fpath'],['str'],"['""""']",574,[],"['fpath.replace', 'fpath.split']",2
utilmy/utilmy.py:os_file_replacestring,os_file_replacestring,function,13,35,30,416,11.89,2,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",591,"['    """""" #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",\n', '        pattern=""*.html"", dirlevel=5  )\n', '    """"""\n']","['os_file_replacestring1', 'fileinput.FileInput', 'line.replace', 'file1.close', 'print', 'format', 'os_walk']",7
utilmy/utilmy.py:os_walk,os_walk,function,26,64,44,507,7.92,4,2,"['path', 'pattern', 'dirlevel']","[None, None, None]","[None, '""*""', '50']",613,"['    """""" dirlevel=0 : root directory\n', '        dirlevel=1 : 1 path below\n', '\n', '    """"""\n']","['path.replace', 'dir1.count', 'os.walk', 'root.replace', 'root.count', 'fnmatch.filter']",6
utilmy/utilmy.py:z_os_search_fast,z_os_search_fast,function,29,122,72,893,7.32,4,4,"['fname', 'texts', 'mode']","[None, None, None]","[None, 'None', '""regex/str""']",640,[],"['re.compile', 'enumerate', 're.search', 'line.decode', 'res.append', 'found.start', 'text.encode', 'line.find', 'print']",9
utilmy/utilmy.py:os_search_content,os_search_content,function,13,37,33,301,8.14,1,1,"['srch_pattern', 'mode', 'dir1', 'file_pattern', 'dirlevel']","[None, None, None, None, None]","['None', '""str""', '""""', '""*.*""', '1']",684,"['    """"""  search inside the files\n', '\n', '    """"""\n']","['os_walk', 'z_os_search_fast', 'pd.DataFrame']",3
utilmy/utilmy.py:os_get_function_name,os_get_function_name,function,6,31,18,199,6.42,0,0,[],[],[],700,[],"['str', 'socket.gethostname', 'sys._getframe']",3
utilmy/utilmy.py:os_variable_init,os_variable_init,function,3,12,10,45,3.75,1,0,"['ll', 'globs']","[None, None]","[None, None]",713,[],[],0
utilmy/utilmy.py:os_import,os_import,function,14,59,37,426,7.22,3,3,"['mod_name', 'globs', 'verbose']","[None, None, None]","['""myfile.config.model""', 'None', 'True']",721,[],"['__import__', 'hasattr', 'dir', 'name.startswith', 'all_names2.append', 'print', 'globs.update', 'getattr']",8
utilmy/utilmy.py:os_variable_exist,os_variable_exist,function,4,19,16,111,5.84,0,1,"['x', 'globs', 'msg']","[None, None, None]","[None, None, '""""']",748,[],"['str', 'log']",2
utilmy/utilmy.py:os_variable_check,os_variable_check,function,9,31,26,149,4.81,1,2,"['ll', 'globs', 'do_terminate']","[None, None, None]","[None, 'None', 'True']",758,[],"['Exception', 'log', 'sys.exit']",3
utilmy/utilmy.py:os_clean_memory,os_clean_memory,function,5,13,12,56,4.31,1,0,"['varlist', 'globx']","[None, None]","[None, None]",770,[],['gc.collect'],1
utilmy/utilmy.py:os_system_list,os_system_list,function,11,45,38,219,4.87,1,1,"['ll', 'logfile', 'sleep_sec']","[None, None, None]","[None, 'None', '10']",778,[],"['len', 'enumerate', 'log', 'os.system', 'time.sleep']",5
utilmy/utilmy.py:os_file_check,os_file_check,function,4,16,14,121,7.56,0,0,['fp'],[None],[None],800,[],"['log', 'os.stat', 'time.ctime']",3
utilmy/utilmy.py:os_to_file,os_to_file,function,3,7,7,52,7.43,0,0,"['txt', 'filename', 'mode']","[None, None, None]","['""""', '""ztmp.txt""', ""'a'""]",808,[],"['open', 'fp.write']",2
utilmy/utilmy.py:os_platform_os,os_platform_os,function,2,2,2,18,9.0,0,0,[],[],[],813,[],[],0
utilmy/utilmy.py:os_cpu,os_cpu,function,2,2,2,20,10.0,0,0,[],[],[],818,[],['os.cpu_count'],1
utilmy/utilmy.py:os_platform_ip,os_platform_ip,function,0,1,1,4,4.0,0,0,[],[],[],823,[],[],0
utilmy/utilmy.py:os_memory,os_memory,function,13,36,30,278,7.72,1,1,[],[],[],828,"['    """""" Get node total memory and memory usage in linux\n', '    """"""\n']","['open', 'i.split', 'str', 'int']",4
utilmy/utilmy.py:os_sleep_cpu,os_sleep_cpu,function,8,19,14,169,8.89,1,0,"['priority', 'cpu_min', 'sleep']","[None, None, None]","['300', '50', '10']",845,[],"['psutil.cpu_percent', 'time.sleep']",2
utilmy/utilmy.py:os_ram_object,os_ram_object,function,17,58,39,319,5.5,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",859,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'o.items']",7
utilmy/utilmy.py:os_copy,os_copy,function,11,21,21,231,11.0,1,1,"['src', 'dst', 'overwrite', 'exclude']","[None, None, None, None]","[None, None, 'False', '""""']",890,[],"['ignore_pyc_files', 'name.endswith', 'exclude.split', 'os.makedirs', 'shutil.copytree', 'shutil.ignore_patterns']",6
utilmy/utilmy.py:os_removedirs,os_removedirs,function,12,48,32,294,6.12,3,1,['path'],[None],[None],902,"['    """"""  issues with no empty Folder\n', ""    # Delete everything reachable from the directory named in 'top',\n"", '    # assuming there are no symbolic links.\n', ""    # CAUTION:  This is dangerous!  For example, if top == '/', it could delete all your disk files.\n"", '    """"""\n']","['len', 'print', 'os.walk', 'os.remove', 'os.rmdir']",5
utilmy/utilmy.py:os_getcwd,os_getcwd,function,3,6,5,66,11.0,0,0,[],[],[],929,[],[],0
utilmy/utilmy.py:os_system,os_system,function,11,45,38,219,4.87,1,1,"['ll', 'logfile', 'sleep_sec']","[None, None, None]","[None, 'None', '10']",935,"['  """""" get values\n', '       os_system( f""   ztmp "",  doprint=True)\n', '  """"""\n']","['len', 'enumerate', 'log', 'os.system', 'time.sleep']",5
utilmy/utilmy.py:os_makedirs,os_makedirs,function,2,13,12,198,15.23,0,1,['dir_or_file'],[None],[None],952,[],"['dir_or_file.split', 'os.makedirs']",2
utilmy/utilmy.py:global_verbosity,global_verbosity,function,10,54,35,442,8.19,0,2,"['cur_path', 'path_relative', 'default', 'key', '']","[None, None, None, None, None]","[None, '""/../../config.json""', '5', ""'verbosity'"", None]",961,"['    """""" Get global verbosity\n', '    verbosity = global_verbosity(__file__, ""/../../config.json"", default=5 )\n', '\n', '    verbosity = global_verbosity(""repo_root"", ""config/config.json"", default=5 )\n', '\n', '    :param cur_path:\n', '    :param path_relative:\n', '    :param key:\n', '    :param default:\n', '    :return:\n', '    """"""\n']","['git_repo_root', 'json.load', 'yaml.load', 'Exception', 'int']",5
utilmy/utilmy.py:hdfs_put,hdfs_put,function,52,179,108,1171,6.54,7,2,"['from_dir', 'to_dir', 'verbose', 'n_pool', 'dirlevel', '**kw']","[None, None, None, None, None, None]","['""""', '""""', 'True', '25', '50', None]",1005,"['    """""" \n', '     hdfs_put LocalFile into HDFS in multi-thread\n', '    from_dir = ""hdfs://nameservice1/user/\n', '    to_dir   = ""data/""\n', '    \n', '    """"""\n']","['log', 'print', 'hdfs.mkdir', 'os_walk', 'sorted', 'len', 'enumerate', 'file_list2.append', 'filei.replace', 't.replace', 'range', 'fun_async', 'open', 'hdfs.upload', 'time.sleep', 'ThreadPool', 'job_list.append', 'pool.apply_async', 'res_list.append', 'pool.terminate', 'pool.join']",21
utilmy/utilmy.py:hdfs_walk,hdfs_walk,function,9,30,19,121,4.03,2,1,"['path=""hdfs', 'dirlevel', 'hdfs=None)']","['', None, '']","['""hdfs://nameservice1/user/""', '3', 'None):   ### python  prepro.py hdfs_walkimport pyarrow as pa) if hdfs is None else hdfspath = ""hdfs://nameservice1/"" + path if \'hdfs://\' not in path else pathfdirs):']",1078,[],"['flist3.extend', 'hdfs.ls', 'hdfs.isdir']",3
utilmy/utilmy.py:hdfs_get,hdfs_get,function,40,135,94,981,7.27,5,3,"['from_dir', 'to_dir', 'verbose', 'n_pool', '**kw']","[None, None, None, None, None]","['""""', '""""', 'True', '20', None]",1101,"['    """""" \n', '    import fastcounter\n', '    counter = fastcounter.FastWriteCounter,()\n', '    counter.increment(1)    \n', '    cnt.value\n', '    """"""\n']","['log', 'print', 'os.makedirs', 'hdfs_walk', 'fun_async', 'hdfs.download', 'time.sleep', 'sorted', 'len', 'range', 'enumerate', 'filei.split', 'ThreadPool', 'job_list.append', 'pool.apply_async', 'res_list.append', 'pool.terminate', 'pool.join']",18
utilmy/utilmy.py:git_repo_root,git_repo_root,function,7,23,19,142,6.17,0,1,[],[],[],1173,[],"['os_system', 'mout.split', 'len']",3
utilmy/utilmy.py:git_current_hash,git_current_hash,function,6,12,10,123,10.25,0,0,['mode'],[None],"[""'full'""]",1183,[],"['subprocess.check_output', 'label.decode']",2
utilmy/utilmy.py:plot_to_html,plot_to_html,function,21,53,39,426,8.04,1,1,"['dir_input', 'out_file', 'title', 'verbose']","[None, None, None, None]","['""*.png""', '""graph.html""', '""""', 'False']",1195,"['    """"""\n', '      plot_to_html( model_path + ""/graph_shop_17_past/*.png"" , model_path + ""shop_17.html"" )\n', '\n', '    """"""\n']","['glob.glob', 'flist.sorted', 'print', 'open', 'base64.b64encode', 'f.write']",6
utilmy/utilmy.py:save,save,function,5,10,10,140,14.0,0,0,"['dd', 'to_file', 'verbose']","[None, None, None]","[None, '""""', 'False']",1294,[],"['os.makedirs', 'pickle.dump', 'open']",3
utilmy/utilmy.py:load,load,function,5,7,6,61,8.71,0,0,['to_file'],[None],"['""""']",1301,[],['pickle.load'],1
utilmy/utilmy.py:print_everywhere,print_everywhere,function,14,35,32,209,5.97,1,0,[],[],[],1311,"['    """"""\n', '    https://github.com/alexmojaki/snoop\n', '    """"""\n']","['snoop.install', 'myfun', 'pp', 'print', 'type', 'str']",6
utilmy/utilmy.py:log5,log5,function,5,6,6,33,5.5,0,0,['*s'],[None],[None],1341,"['    """"""    ### Equivalent of print, but more :  https://github.com/gruns/icecream\n', '    pip install icrecream\n', '    ic()  --->  ic| example.py:4 in foo()\n', ""    ic(var)  -->   ic| d['key'][1]: 'one'\n"", '    \n', '    """"""\n']",['ic'],1
utilmy/utilmy.py:log_trace,log_trace,function,4,4,4,37,9.25,0,0,"['msg', 'dump_path', 'globs']","[None, None, None]","['""""', '""""', 'None']",1352,[],"['print', 'pdb.set_trace']",2
utilmy/utilmy.py:profiler_start,profiler_start,function,6,9,9,82,9.11,0,0,[],[],[],1358,[],"['Profiler', 'profiler.start']",2
utilmy/utilmy.py:profiler_stop,profiler_stop,function,3,5,5,83,16.6,0,0,[],[],[],1366,[],"['profiler.stop', 'print']",2
utilmy/utilmy.py:dict_to_namespace,dict_to_namespace,class,3,5,5,36,7.2,0,0,[],[],[],442,[],[],0
utilmy/utilmy.py:Session,Session,class,42,178,114,1402,7.88,3,2,[],[],[],1225,[],[],0
utilmy/utilmy.py:dict_to_namespace:__init__,dict_to_namespace:__init__,method,2,2,2,15,7.5,0,0,"['self', 'd']","[None, None]","[None, None]",444,[],[],0
utilmy/utilmy.py:Session:__init__,Session:__init__,method,5,7,7,113,16.14,0,0,"['self', 'dir_session', '']","[None, None, None]","[None, '""ztmp/session/""', None]",1231,[],"['os.makedirs', 'print']",2
utilmy/utilmy.py:Session:show,Session:show,method,5,7,7,62,8.86,0,0,['self'],[None],[None],1237,[],"['glob.glob', 'print']",2
utilmy/utilmy.py:Session:save,Session:save,method,4,8,8,146,18.25,0,0,"['self', 'name', 'glob', 'tag']","[None, None, None, None]","[None, None, 'None', '""""']",1242,[],"['os.makedirs', 'self.save_session']",2
utilmy/utilmy.py:Session:load,Session:load,method,4,9,9,126,14.0,0,0,"['self', 'name', 'glob', 'tag']","[None, None, 'dict', None]","[None, None, 'None', '""""']",1248,[],"['print', 'self.load_session']",2
utilmy/utilmy.py:Session:save_session,Session:save_session,method,19,82,58,516,6.29,1,2,"['self', 'folder', 'globs', 'tag']","[None, None, None, None]","[None, None, None, '""""']",1255,[],"['os.makedirs', 'globs.items', 'x.startswith', 'str', 'pd.to_pickle', 'save', 'print']",7
utilmy/utilmy.py:Session:load_session,Session:load_session,method,11,33,28,208,6.3,2,0,"['self', 'folder', 'globs']","[None, None, None]","[None, None, 'None']",1278,"['      """"""\n', '      """"""\n']","['print', 'os.walk', 'x.replace', 'load']",4
utilmy/util_default.py:log,log,function,10,39,25,357,9.15,0,0,['*s'],[None],[None],18,[],"['logger.info', 'log2', 'logger.debug', 'logw', 'logger.warning', 'loge', 'logger.error', 'logger_setup', 'logger.configure']",9
utilmy/util_default.py:log2,log2,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],22,[],['logger.debug'],1
utilmy/util_default.py:logw,logw,function,1,5,5,41,8.2,0,0,['*s'],[None],[None],26,[],['logger.warning'],1
utilmy/util_default.py:loge,loge,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],30,[],['logger.error'],1
utilmy/util_default.py:logger_setup,logger_setup,function,2,15,13,138,9.2,0,0,[],[],[],34,[],['logger.configure'],1
utilmy/util_default.py:config_load,config_load,function,16,74,63,807,10.91,0,1,"['config_path', 'pathlib.Path]] ']","[' Optional[Union[str', None]","[None, ' None']",51,"['    """"""Load Config file into a dict\n', '    1) load config_path\n', '    2) If not, load in HOME USER\n', '    3) If not, create default one\n', ""    # config_default = yaml.load(os.path.join(os.path.dirname(__file__), 'config', 'config.yaml'))\n"", '\n', '    Args:\n', ""        config_path: path of config or 'default' tag value\n"", '    Returns: dict config\n', '    """"""\n']","['str', 'logw', 'log2', 'yaml.load', 'log', 'os.makedirs', 'open', 'json.dump']",8
utilmy/util_default.py:dataset_donwload,dataset_donwload,function,9,19,17,246,12.95,0,0,"['url', 'path_target']","[None, None]","[None, None]",99,"['    """"""Donwload on disk the tar.gz file\n', '    Args:\n', '        url:\n', '        path_target:\n', '    Returns:\n', '\n', '    """"""\n']","['log', 'os.makedirs', 'wget.download', 'url.split', 'os_extract_archive', 'log2']",6
utilmy/util_default.py:os_extract_archive,os_extract_archive,function,19,63,47,671,10.65,1,8,"['file_path', 'path', 'archive_format']","[None, None, None]","[None, '"".""', '""auto""']",117,"['    """"""Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n', '    Args:\n', '        file_path: path to the archive file\n', '        path: path to extract the archive file\n', '        archive_format: Archive format to try for extracting the file.\n', ""            Options are 'auto', 'tar', 'zip', and None.\n"", ""            'tar' includes tar, tar.gz, and tar.bz files.\n"", ""            The default 'auto' is ['tar', 'zip'].\n"", '            None or an empty list will return no matches found.\n', '    Returns:\n', '        True if a match was found and an archive extraction was completed,\n', '        False otherwise.\n', '    """"""\n']","['isinstance', 'is_match_fn', 'open_fn', 'archive.extractall', 'os.remove', 'shutil.rmtree']",6
utilmy/util_default.py:to_file,to_file,function,3,7,7,51,7.29,0,0,"['s', 'filep']","[None, None]","[None, None]",164,[],"['open', 'fp.write']",2
utilmy/zutil.py:session_load_function,session_load_function,function,6,9,9,88,9.78,0,0,['name'],[None],"['""test_20160815""']",66,[],"['dill.load_session', 'print']",2
utilmy/zutil.py:session_save_function,session_save_function,function,6,11,10,111,10.09,0,0,['name'],[None],"['""test""']",75,[],"['date_now', 'dill.dump_session', 'print']",3
utilmy/zutil.py:py_save_obj_dill,py_save_obj_dill,function,16,52,42,502,9.65,0,1,"['obj1', 'keyname', 'otherfolder']","[None, None, None]","[None, '""""', '0']",83,[],"['z_key_splitinto_dir_name', 'os_folder_create', 'open', 'dill.dumps', 'print']",5
utilmy/zutil.py:aa_unicode_ascii_utf8_issue,aa_unicode_ascii_utf8_issue,function,0,0,0,0,0.0,0,0,[],[],[],111,"['    """"""Take All csv in a folder and provide Table, Column Schema, type\n', '\n', ' METHOD FOR Unicode / ASCII issue\n', '1. Decode early\n', ""Decode to <type 'unicode'> ASAP\n"", ""df['PREF_NAME']=       df['PREF_NAME'].apply(to_unicode)\n"", '\n', '2. Unicode everywhere\n', '\n', '\n', '3. Encode late\n', ""# >>> f = open('/tmp/ivan_out.txt','w')\n"", ""# >>> f.write(ivan_uni.encode('utf-8'))\n"", '\n', 'Important methods\n', ""s.decode(encoding)  <type 'str'> to <type 'unicode'>\n"", ""u.encode(encoding)  <type 'unicode'> to <type 'str'>\n"", '\n', 'http://farmdev.com/talks/unicode/\n', '\n', '   """"""\n']",[],0
utilmy/zutil.py:isfloat,isfloat,function,4,13,11,79,6.08,0,1,['x'],[None],[None],135,[],['float'],1
utilmy/zutil.py:isint,isint,function,2,6,6,50,8.33,0,0,['x'],[None],[None],145,[],['isinstance'],1
utilmy/zutil.py:isanaconda,isanaconda,function,4,10,9,65,6.5,0,1,[],[],[],149,[],['txt.find'],1
utilmy/zutil.py:a_run_ipython,a_run_ipython,function,1,1,1,33,33.0,0,0,['cmd1'],[None],[None],157,"['    """""" Execute Ipython Command in python code\n', '     run -i :  run including current interprete variable\n', ' """"""\n']",['IPython.get_ipython'],1
utilmy/zutil.py:py_autoreload,py_autoreload,function,1,4,4,64,16.0,0,0,[],[],[],164,[],['a_run_ipython'],1
utilmy/zutil.py:os_platform,os_platform,function,1,2,2,8,4.0,0,0,[],[],[],169,[],[],0
utilmy/zutil.py:a_start_log,a_start_log,function,3,15,14,103,6.87,0,0,"['id1', 'folder']","[None, None]","['""""', '""aaserialize/log/""']",173,[],"['a_run_ipython', 'str', 'os_platform', 'date_now']",4
utilmy/zutil.py:a_cleanmemory,a_cleanmemory,function,3,3,3,21,7.0,0,0,[],[],[],187,[],['gc.collect'],1
utilmy/zutil.py:a_info_conda_jupyter,a_info_conda_jupyter,function,1,2,2,5,2.5,0,0,[],[],[],193,[],[],0
utilmy/zutil.py:print_object_tofile,print_object_tofile,function,15,45,35,236,5.24,2,2,"['vv', 'txt', 'file1=""d']","[None, None, '']","[None, None, '""d:/regression_output.py""']",355,"['    """""" #Print to file Object   Table   """"""\n']","['open', 'file1.write', 'np.shape', 'range', 'str']",5
utilmy/zutil.py:print_progressbar,print_progressbar,function,9,32,29,316,9.88,0,1,"['iteration', 'total', 'prefix', 'suffix', 'decimals', 'bar_length']","[None, None, None, None, None, None]","[None, None, '""""', '""""', '1', '100']",372,"['    """"""# Print iterations progress\n', '     Call in a loop to create terminal progress bar\n', '    @params:\n', '        iteration   - Required  : current iteration (Int)\n', '        total       - Required  : total iterations (Int)\n', '        prefix      - Optional  : prefix string (Str)\n', '        suffix      - Optional  : suffix string (Str)\n', '        decimals    - Optional  : positive number of decimals in percent complete (Int)\n', '        bar_length   - Optional  : character length of bar (Int)\n', '    """"""\n']","['str', 'format_str.format', 'float', 'int']",4
utilmy/zutil.py:os_zip_checkintegrity,os_zip_checkintegrity,function,7,27,24,173,6.41,0,1,['filezip1'],[None],[None],401,[],"['zipfile.ZipFile', 'zip_file.testzip', 'print']",3
utilmy/zutil.py:os_zipfile,os_zipfile,function,19,37,32,376,10.16,2,2,"['folderin', 'folderzipname', 'iscompress']","[None, None, None]","[None, None, 'True']",414,[],"['zipfile.ZipFile', 'os.walk', 'zf.write', 'zf.close', 'os_zip_checkintegrity', 'print']",6
utilmy/zutil.py:os_zipfolder,os_zipfolder,function,2,8,5,116,14.5,0,0,"['dir_tozip', 'zipname', 'dir_prefix', 'iscompress=Trueimport shutil_ = iscompressdir_tozip = dir_tozip if dir_tozip[-1] != ""/"" else dir_tozip[']","[None, None, None, '']","['""/zdisks3/output""', '""/zdisk3/output.zip""', 'True', 'Trueimport shutil_ = iscompressdir_tozip = dir_tozip if dir_tozip[-1] != ""/"" else dir_tozip[:-1]if dir_prefix:']",432,"['    """"""\n', "" shutil.make_archive('/zdisks3/results/output', 'zip',\n"", ""                     root_dir=/zdisks3/results/',\n"", ""                     base_dir='output')\n"", ' os_zipfolder(\'zdisk/test/aapackage\', \'zdisk/test/aapackage.zip\', \'zdisk/test\')""""""\n']",['dir_tozip.split'],1
utilmy/zutil.py:os_zipextractall,os_zipextractall,function,23,61,51,536,8.79,1,3,"['filezip_or_dir', 'tofolderextract', 'isprint']","[None, None, None]","['""folder1/*.zip""', '""zdisk/test""', '1']",484,"['    """"""os_zipextractall( \'aapackage.zip\',\'zdisk/test/\'      )  """"""\n']","['filezip_or_dir.find', 'os_file_listall', 'os_file_getname', 'zipfile.ZipFile', 'zip_ref.extractall', 'zip_ref.close', 'print']",7
utilmy/zutil.py:os_folder_copy,os_folder_copy,function,15,39,36,391,10.03,0,2,"['src', 'dst', 'symlinks', 'pattern1', 'fun_file_toignore']","[None, None, None, None, None]","[None, None, 'False', '""*.py""', 'None']",518,"['    """"""\n', '       callable(src, names) -> ignored_names\n', ""       'src' parameter, which is the directory being visited by copytree(), and\n"", ""       'names' which is the list of `src` contents, as returned by os.listdir():\n"", '\n', '    Since copytree() is called recursively, the callable will be called once for each\n', '    directory that is copied.\n', '    It returns a  list of names relative to the `src` directory that should not be copied.\n', '   """"""\n']","['_default_fun_file_toignore', 'fnmatch.filter', 'shutil.copytree', 'shutil.copy']",4
utilmy/zutil.py:os_folder_create,os_folder_create,function,5,7,7,86,12.29,0,1,['directory'],[None],[None],548,[],"['os.getcwd', 'os.makedirs', 'os.chdir']",3
utilmy/zutil.py:os_folder_robocopy,os_folder_robocopy,function,3,15,15,163,10.87,0,1,"['from_folder', 'to_folder', 'my_log=""H']","[None, None, '']","['""""', '""""', '""H:/robocopy_log.txt""']",555,"['    """"""\n', '    Copy files to working directory\n', '    robocopy <Source> <Destination> [<File>[ ...]] [<Options>]\n', '    We want to copy the files to a fast SSD drive\n', '    """"""\n']","['subprocess.call', 'print']",2
utilmy/zutil.py:os_file_replace,os_file_replace,function,27,73,56,824,11.29,3,0,"['source_file_path', 'pattern', 'substring']","[None, None, None]","[None, None, None]",568,[],"['mkstemp', 'open', 'target_file.write', 'remove', 'move', 'os_file_replacestring1', 'fileinput.FileInput', 'line.replace', 'file1.close', 'print', 'format', 'os_file_replacestring2', 'os_file_listall']",13
utilmy/zutil.py:os_file_replacestring1,os_file_replacestring1,function,9,18,17,201,11.17,1,0,"['find_str', 'rep_str', 'file_path']","[None, None, None]","[None, None, None]",582,"['    """"""replaces all find_str by rep_str in file file_path""""""\n']","['fileinput.FileInput', 'line.replace', 'file1.close', 'print', 'format']",5
utilmy/zutil.py:os_file_replacestring2,os_file_replacestring2,function,5,13,12,162,12.46,1,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",594,"['    """""" #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",\n', '    pattern=""*.html"", dirlevel=5  )\n', '  """"""\n']","['os_file_listall', 'os_file_replacestring1']",2
utilmy/zutil.py:os_file_getname,os_file_getname,function,8,9,8,75,8.33,0,0,['path'],[None],[None],604,[],"['ntpath.split', 'ntpath.basename']",2
utilmy/zutil.py:os_file_getpath,os_file_getpath,function,7,7,7,52,7.43,0,0,['path'],[None],[None],611,[],['ntpath.split'],1
utilmy/zutil.py:os_file_gettext,os_file_gettext,function,4,8,8,55,6.88,0,0,['file1'],[None],[None],618,[],"['open', 'f.read']",2
utilmy/zutil.py:os_file_listall,os_file_listall,function,23,40,34,476,11.9,2,1,"['dir1', 'pattern', 'dirlevel', 'onlyfolder']","[None, None, None, None]","[None, '""*.*""', '1', '0']",625,[],"['dir1.rstrip', 'dir1.count', 'os.walk', 'root.count', 'fnmatch.filter']",5
utilmy/zutil.py:_os_file_search_fast,_os_file_search_fast,function,27,120,70,884,7.37,4,4,"['fname', 'texts', 'mode']","[None, None, None]","[None, 'None', '""regex/str""']",695,[],"['re.compile', 'enumerate', 're.search', 'line.decode', 'res.append', 'found.start', 'text.encode', 'line.find', 'print']",9
utilmy/zutil.py:os_file_search_content,os_file_search_content,function,10,33,29,296,8.97,1,1,"['srch_pattern', 'mode', 'dir1', 'file_pattern', 'dirlevel']","[None, None, None, None, None]","['None', '""str""', '""""', '""*.*""', '1']",740,[],"['os_file_listall', '_os_file_search_fast', 'pd.DataFrame']",3
utilmy/zutil.py:os_file_rename,os_file_rename,function,33,53,45,644,12.15,2,1,"['some_dir', 'pattern', 'pattern2', 'dirlevel']","[None, None, None, None]","[None, '""*.*""', '""""', '1']",758,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 're.sub', 'os.rename', 'np.array']",9
utilmy/zutil.py:os_gui_popup_show,os_gui_popup_show,function,25,37,36,408,11.03,0,0,['txt'],[None],[None],788,[],"['os_gui_popup_show2', 'Tk', 'Scrollbar', 'Text', 'scrollbar.pack', 'text.pack', 'scrollbar.config', 'text.config', 'text.insert', 'root.attributes', 'mainloop']",11
utilmy/zutil.py:os_print_tofile,os_print_tofile,function,1,1,1,24,24.0,0,0,"['vv', 'file1', 'mode1=""a"")', 'mode1) as text_file']","[None, None, '', '']","[None, None, '""a""):  # print into a file=\'afile1', None]",808,"['    """"""\n', '    Here is a list of the different modes of opening a file:\n', 'r\n', 'Opens a file for reading only. The file pointer is placed at the beginning of the file.\n', 'This is the default mode.\n', '\n', 'rb\n', '\n', 'Opens a file for reading only in binary format. The file pointer is placed at the\n', 'beginning of the file. This is the default mode.\n', 'r+\n', '\n', 'Opens a file for both reading and writing. The file pointer will be at the beginning of the file.\n', 'rb+\n', '\n', 'Opens a file for both reading and writing in binary format. The file pointer will be at the\n', 'beginning of the file.\n', 'w\n', '\n', 'Opens a file for writing only. Overwrites the file if the file exists. If the file does not exist,\n', 'creates a new file for writing.\n', 'wb\n', '\n', 'Opens a file for writing only in binary format. Overwrites the file if the file exists.\n', 'If the file does not exist, creates a new file for writing.\n', 'w+\n', '\n', 'Opens a file for both writing and reading. Overwrites the existing file if the file exists.\n', 'If the file does not exist, creates a new file for reading and writing.\n', 'wb+\n', '\n', 'Opens a file for both writing and reading in binary format. Overwrites the existing file if\n', 'the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'a\n', '\n', 'Opens a file for appending. The file pointer is at the end of the file if the file exists. That is,\n', 'the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'ab\n', '\n', 'Opens a file for appending in binary format. The file pointer is at the end of the file if the file\n', 'exists. That is, the file is in the append mode. If the file does not exist, it creates a new file\n', 'for writing.\n', 'a+\n', '\n', 'Opens a file for both appending and reading. The file pointer is at the end of the file if the\n', 'file exists. The file opens in the append mode. If the file does not exist, it creates a new file\n', 'for reading and writing.\n', 'ab+\n', '\n', 'Opens a file for both appending and reading in binary format. The file pointer is at the end of\n', 'the file if the file exists. The file opens in the append mode. If the file does not exist,\n', 'it creates a new file for reading and writing.\n', 'To open a text file, use:\n', 'fh = open(""hello.txt"", ""r"")\n', '\n', 'To read a text file, use:\n', 'print fh.read()\n', '\n', 'To read one line at a time, use:\n', 'print fh.readline()\n', '\n', 'To read a list of lines use:\n', 'print fh.readlines()\n', '\n', 'To write to a file, use:\n', 'fh = open(""hello.txt"", ""w"")\n', 'lines_of_text = [""a line of text"", ""another line of text"", ""a third line""]\n', 'fh.writelines(lines_of_text)\n', 'fh.close()\n', '\n', 'To append to file, use:\n', 'fh = open(""Hello.txt"", ""a"")\n', 'fh.close()\n', '\n', '    """"""\n']",['text_file.write'],1
utilmy/zutil.py:os_path_norm,os_path_norm,function,8,20,18,175,8.75,0,1,['pth)'],"['  # Normalize path for Python directoryr"""""" #r""D:\\_devs\\Python01\\project\\03-Connect_Java_CPP_Excel\\PyBindGen\\examples"" """""") ']",['= 2:'],888,[],"['pth.find', 'b.lstrip']",2
utilmy/zutil.py:os_path_change,os_path_change,function,3,8,8,68,8.5,0,0,['path1'],[None],[None],902,[],"['os_path_norm', 'os.chdir']",2
utilmy/zutil.py:os_path_current,os_path_current,function,2,2,2,17,8.5,0,0,[],[],[],907,[],['os.getcwd'],1
utilmy/zutil.py:os_file_exist,os_file_exist,function,2,2,2,27,13.5,0,0,['file1'],[None],[None],911,[],[],0
utilmy/zutil.py:os_file_size,os_file_size,function,2,2,2,28,14.0,0,0,['file1'],[None],[None],915,[],[],0
utilmy/zutil.py:os_file_read,os_file_read,function,4,5,5,34,6.8,0,0,['file1'],[None],[None],919,[],"['open', 'fh.read']",2
utilmy/zutil.py:os_file_isame,os_file_isame,function,4,5,5,44,8.8,0,0,"['file1', 'file2']","[None, None]","[None, None]",924,[],['filecmp.cmp'],1
utilmy/zutil.py:os_file_get_extension,os_file_get_extension,function,5,12,10,98,8.17,0,2,['file_path'],[None],[None],930,"['    """"""\n', '    # >>> get_file_extension(""/a/b/c"")\n', ""    ''\n"", '    # >>> get_file_extension(""/a/b/c.tar.xz"")\n', ""    'xz'\n"", '    """"""\n']",['_ext.startswith'],1
utilmy/zutil.py:os_file_normpath,os_file_normpath,function,2,8,8,67,8.38,0,0,['path'],[None],[None],944,"['    """"""Normalize path.\n', '    - eliminating double slashes, etc. (os.path.normpath)\n', '    - ensure paths contain ~[user]/ expanded.\n', '\n', '    :param path: Path string :: str\n', '    """"""\n']",[],0
utilmy/zutil.py:os_folder_is_path,os_folder_is_path,function,2,3,3,36,12.0,0,0,['path_or_stream'],[None],[None],954,"['    """"""\n', '    Is given object `path_or_stream` a file path?\n', '    :param path_or_stream: file path or stream, file/file-like object\n', '    :return: True if `path_or_stream` is a file path\n', '    """"""\n']",['isinstance'],1
utilmy/zutil.py:os_file_get_path_from_stream,os_file_get_path_from_stream,function,7,20,15,187,9.35,0,2,['maybe_stream'],[None],[None],963,"['    """"""\n', '    Try to get file path from given stream `stream`.\n', '\n', '    :param maybe_stream: A file or file-like object\n', '    :return: Path of given file or file-like object or None\n', '\n', '    # >>> __file__ == get_path_from_stream(__file__)\n', '    True\n', ""    # >>> __file__ == get_path_from_stream(open(__file__, 'r'))\n"", '    True\n', '    # >>> strm = anyconfig.compat.StringIO()\n', '    # >>> get_path_from_stream(strm) is None\n', '    True\n', '    """"""\n']","['os_folder_is_path', 'getattr']",2
utilmy/zutil.py:os_file_try_to_get_extension,os_file_try_to_get_extension,function,4,12,10,112,9.33,0,1,['path_or_strm'],[None],[None],988,"['    """"""\n', '    Try to get file extension from given path or file object.\n', '    :return: File extension or None\n', '    """"""\n']","['os_file_get_path_from_stream', 'os_file_get_extension']",2
utilmy/zutil.py:os_file_are_same_file_types,os_file_are_same_file_types,function,5,20,14,154,7.7,0,2,['paths'],[None],[None],1000,"['    """"""\n', '    Are given (maybe) file paths same type (extension) ?\n', '    :param paths: A list of file path or file(-like) objects\n', '\n', '    # >>> are_same_file_types([])\n', '    False\n', '    # >>> are_same_file_types([""a.conf""])\n', '    True\n', '    # >>> are_same_file_types([""a.yml"", ""b.json""])\n', '    False\n', '    # >>> strm = anyconfig.compat.StringIO()\n', '    # >>> are_same_file_types([""a.yml"", ""b.yml"", strm])\n', '    False\n', '    """"""\n']","['os_file_try_to_get_extension', 'all']",2
utilmy/zutil.py:os_file_norm_paths,os_file_norm_paths,function,18,54,35,387,7.17,2,3,"['paths', 'marker']","[None, None]","[None, '""*""']",1024,"['    """"""\n', '    :param paths:\n', '        A glob path pattern string, or a list consists of path strings or glob\n', '        path pattern strings or file objects\n', ""    :param marker: Glob marker character or string, e.g. '*'\n"", '    :return: List of path strings\n', '    # >>> norm_paths([])\n', '    []\n', '    # >>> norm_paths(""/usr/lib/a/b.conf /etc/a/b.conf /run/a/b.conf"".split())\n', ""    ['/usr/lib/a/b.conf', '/etc/a/b.conf', '/run/a/b.conf']\n"", '    # >>> paths_s = os.path.join(os.path.dirname(__file__), ""u*.py"")\n', '    # >>> ref = sglob(paths_s)\n', '    # >>> ref = [""/etc/a.conf""] + ref\n', '    # >>> assert norm_paths([""/etc/a.conf"", paths_s]) == ref\n', '    # >>> strm = anyconfig.compat.StringIO()\n', '    # >>> assert norm_paths([""/etc/a.conf"", strm]) == [""/etc/a.conf"", strm]\n', '    """"""\n']","['sglob', 'sorted', '_norm_paths_itr', 'os_folder_is_path', 'list']",5
utilmy/zutil.py:os_file_mergeall,os_file_mergeall,function,10,19,19,173,9.11,1,0,"['nfile', 'dir1', 'pattern1', 'deepness']","[None, None, None, None]","[None, None, None, '2']",1068,[],"['os_file_listall', 'open', 'os_file_gettext', 'nfile1.write', 'nfile1.close']",5
utilmy/zutil.py:os_file_extracttext,os_file_extracttext,function,16,32,30,285,8.91,1,0,"['output_file', 'dir1', 'pattern1', 'htmltag', 'deepness']","[None, None, None, None, None]","[None, None, '""*.html""', '""p""', '2']",1077,"['    """""" Extract text from html """"""\n']","['os_file_listall', 'open', 'os_file_gettext', 'BeautifulSoup', 'soup.find_all', 'txt2.strip', 'output_file1.write']",7
utilmy/zutil.py:os_path_append,os_path_append,function,4,19,11,124,6.53,0,3,"['p1', 'p2', 'p3', 'p4']","[None, None, None, None]","[None, 'None', 'None', 'None']",1093,[],[],0
utilmy/zutil.py:os_wait_cpu,os_wait_cpu,function,5,21,16,257,12.24,1,0,"['priority', 'cpu_min']","[None, None]","['300', '50']",1104,[],"['psutil.cpu_percent', 'print', 'arrow.utcnow', 'time.sleep']",4
utilmy/zutil.py:os_split_dir_file,os_split_dir_file,function,7,15,13,114,7.6,0,1,['dirfile'],[None],[None],1116,[],"['dirfile.split', 'len']",2
utilmy/zutil.py:os_process_run,os_process_run,function,11,31,30,281,9.06,0,1,"['cmd_list', 'capture_output']","[None, None]","[None, 'False']",1126,"['    """"""os_process_run\n', '    \n', '    Args:\n', '         cmd_list: list [""program"", ""arg1"", ""arg2""]\n', '         capture_output: bool\n', '    """"""\n']","['subprocess.Popen', 'proc.communicate', 'print', 'str']",4
utilmy/zutil.py:os_process_2,os_process_2,function,0,1,1,4,4.0,0,0,[],[],[],1149,[],[],0
utilmy/zutil.py:py_importfromfile,py_importfromfile,function,12,24,20,269,11.21,0,1,"['modulename', 'dir1']","[None, None]","[None, None]",1183,[],"['a_get_pythonversion', 'SourceFileLoader', 'foo.MyClass', 'importlib.import_module']",4
utilmy/zutil.py:py_memorysize,py_memorysize,function,17,58,39,319,5.5,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",1199,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'o.items']",7
utilmy/zutil.py:save,save,function,2,4,4,64,16.0,0,0,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, '""/folder1/keyname""', '0']",1229,[],['py_save_obj'],1
utilmy/zutil.py:load,load,function,2,3,3,60,20.0,0,0,"['folder', 'isabsolutpath']","[None, None]","['""/folder1/keyname""', '0']",1233,[],['py_load_obj'],1
utilmy/zutil.py:save_test,save_test,function,5,10,10,126,12.6,0,0,"['folder', 'isabsolutpath']","[None, None]","['""/folder1/keyname""', '0']",1237,[],"['py_load_obj', 'print', 'str', 'gc.collect']",4
utilmy/zutil.py:py_save_obj,py_save_obj,function,16,52,42,502,9.65,0,1,"['obj1', 'keyname', 'otherfolder']","[None, None, None]","[None, '""""', '0']",1244,[],"['z_key_splitinto_dir_name', 'os_folder_create', 'open', 'dill.dumps', 'print']",5
utilmy/zutil.py:py_load_obj,py_load_obj,function,18,33,30,277,8.39,0,1,"['folder', 'isabsolutpath', 'encoding1']","[None, None, None]","['""/folder1/keyname""', '0', '""utf-8""']",1257,"['    """"""def load_obj(name, encoding1=\'utf-8\' ):\n', ""         with open('D:/_devs/Python01/aaserialize/' + name + '.pkl', 'rb') as f:\n"", '            return pickle.load(f, encoding=encoding1)\n', '    """"""\n']","['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.load']",5
utilmy/zutil.py:z_key_splitinto_dir_name,z_key_splitinto_dir_name,function,7,15,13,114,7.6,0,1,['keyname'],[None],[None],1277,[],"['keyname.split', 'len']",2
utilmy/zutil.py:os_config_setfile,os_config_setfile,function,9,32,23,223,6.97,1,1,"['dict_params', 'outfile', 'mode1']","[None, None, None]","[None, None, '""w+""']",1287,[],"['open', 'dict_params.items', 'isinstance', 'f1.write', 'str', 'f1.close', 'print']",7
utilmy/zutil.py:os_config_getfile,os_config_getfile,function,6,14,14,73,5.21,1,0,['file1'],[None],[None],1299,[],"['open', 'f1.readlines', 'print']",3
utilmy/zutil.py:os_csv_process,os_csv_process,function,2,2,2,7,3.5,0,0,['file1'],[None],[None],1307,[],[],0
utilmy/zutil.py:pd_toexcel,pd_toexcel,function,24,91,60,862,9.47,0,8,"['df', 'outfile', 'sheet_name', 'append', 'returnfile']","[None, None, None, None, None]","[None, '""file.xlsx""', '""sheet1""', '1', '1']",1427,"['    """"""\n', '# Create a Pandas Excel writer using XlsxWriter as the engine.\n', ""writer = pd.ExcelWriter('test.xlsx', engine='xlsxwriter')\n"", ""df.to_excel(writer, sheet_name='Sheet1')\n"", 'writer.save()\n', '\n', '# Get the xlsxwriter objects from the dataframe writer object.\n', 'workbook  = writer.book\n', ""worksheet = writer.sheets['Sheet1']\n"", '\n', '# Add some cell formats.\n', ""format1 = workbook.add_format({'num_format': '#,##0.00'})\n"", ""format2 = workbook.add_format({'num_format': '0%'})\n"", ""format3 = workbook.add_format({'num_format': 'h:mm:ss AM/PM'})\n"", '\n', '# Set the column width and format.\n', ""worksheet.set_column('B:B', 18, format1)\n"", '\n', '# Set the format but not the column width.\n', ""worksheet.set_column('C:C', None, format2)\n"", '\n', ""worksheet.set_column('D:D', 16, format3)\n"", '\n', '# Close the Pandas Excel writer and output the Excel file.\n', 'writer.save()\n', '\n', 'from openpyxl import load_workbook\n', 'wb = load_workbook(outfile)\n', 'ws = wb.active\n', ""ws.title = 'Table 1'\n"", '\n', 'tableshape = np.shape(table)\n', 'alph = list(string.ascii_uppercase)\n', '\n', 'for i in range(tableshape[0]):\n', '    for j in range(tableshape[1]):\n', '        ws[alph[i]+str(j+1)] = table[i, j]\n', '\n', ""for cell in ws['A'] + ws[1]:\n"", ""    cell.style = 'Pandas'\n"", '\n', ""wb.save('Scores.xlsx')\n"", '\n', '   """"""\n']","['os_file_exist', 'load_workbook', 'pd.ExcelWriter', 'dict', 'df.to_excel', 'writer.save', 'pd_toexcel_many', 'pd_toexcel']",8
utilmy/zutil.py:pd_toexcel_many,pd_toexcel_many,function,1,3,3,40,13.33,0,0,"['outfile', 'df1', 'df2', 'df3', 'df4', 'df5', 'df6', 'outfile', 'sheet_name=""df1"")if df2 is not None']","[None, None, None, None, None, None, None, None, '']","['""file1.xlsx""', 'None', 'None', 'None', 'None', 'None', 'Nonedf1', None, '""df1"")if df2 is not None:']",1492,[],['pd_toexcel'],1
utilmy/zutil.py:find_fuzzy,find_fuzzy,function,4,10,10,49,4.9,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1509,"['    """""" if xstring matches partially, add to the list   """"""\n']",['xi.find'],1
utilmy/zutil.py:str_match_fuzzy,str_match_fuzzy,function,4,12,11,65,5.42,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1514,"['    """""" if any of list_strinf elt matches partially xstring """"""\n']",['xstring.find'],1
utilmy/zutil.py:str_parse_stringcalendar,str_parse_stringcalendar,function,14,40,30,282,7.05,3,1,['cal'],[None],[None],1522,"['    """"""----------Parse Calendar  --------""""""\n']","['cal.split', 'x.find', 'cal4.append', 'np.array', 'print']",5
utilmy/zutil.py:str_make_unicode,str_make_unicode,function,6,13,10,123,9.46,0,1,"['input_str', 'errors']","[None, None]","[None, '""replace""']",1539,[],"['type', 'input_str.decode']",2
utilmy/zutil.py:str_empty_string_array,str_empty_string_array,function,8,33,23,182,5.52,2,1,"['x', 'y']","[None, None]","[None, '1']",1548,[],"['range', 'str_empty_string_array_numpy', 'np.empty']",3
utilmy/zutil.py:str_empty_string_array_numpy,str_empty_string_array_numpy,function,4,9,8,56,6.22,0,0,"['nx', 'ny']","[None, None]","[None, '1']",1555,[],['np.empty'],1
utilmy/zutil.py:str_isfloat,str_isfloat,function,2,8,7,58,7.25,0,0,['value'],[None],[None],1561,[],['float'],1
utilmy/zutil.py:str_is_azchar,str_is_azchar,function,2,8,7,54,6.75,0,0,['x'],[None],[None],1569,[],['float'],1
utilmy/zutil.py:str_is_az09char,str_is_az09char,function,2,8,7,54,6.75,0,0,['x'],[None],[None],1577,[],['float'],1
utilmy/zutil.py:str_reindent,str_reindent,function,3,8,7,65,8.12,0,0,"['s', 'num_spaces)', 'string', 'maxsplit=0)', 'delimiters))regex_pattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, '  # change indentation of multine string""\\n"")num_spaces * "" "") + line.lstrip() for line in s]s)return sdelimiters', None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, None, '0):  # Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, '0):  # Find Sentence Patternimport re_ = maxsplitsep2)""("" + regex_pat + r"")|(?:(?!"" + regex_pat + "").)*""', None, None]",1585,"['    """"""\n', '   if args:\n', ""       aux= name1+'.'+obj.__name__ +'('+ str(args) +')  \\n' + str(inspect.getdoc(obj))\n"", ""       aux= aux.replace('\\n', '\\n       ')\n"", '       aux= aux.rstrip()\n', ""       aux= aux + ' \\n'\n"", '       wi( aux)\n', '    """"""\n']",['x.decode'],1
utilmy/zutil.py:str_split2,str_split2,function,3,8,7,65,8.12,0,0,"['delimiters', 'string', 'maxsplit=0)', 'delimiters))regex_pattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, '0):  # Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, '0):  # Find Sentence Patternimport re_ = maxsplitsep2)""("" + regex_pat + r"")|(?:(?!"" + regex_pat + "").)*""', None, None]",1600,[],['x.decode'],1
utilmy/zutil.py:str_split_pattern,str_split_pattern,function,3,8,7,65,8.12,0,0,"['sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, '0):  # Find Sentence Patternimport re_ = maxsplitsep2)""("" + regex_pat + r"")|(?:(?!"" + regex_pat + "").)*""', None, None]",1607,[],['x.decode'],1
utilmy/zutil.py:pd_str_isascii,pd_str_isascii,function,3,8,7,65,8.12,0,0,['x'],[None],[None],1619,[],['x.decode'],1
utilmy/zutil.py:str_to_utf8,str_to_utf8,function,2,2,2,23,11.5,0,0,['x'],[None],[None],1627,"['    """""" Do it before saving/output to external printer """"""\n']",['x.encode'],1
utilmy/zutil.py:str_to_unicode,str_to_unicode,function,4,13,9,80,6.15,0,2,"['x', 'encoding']","[None, None]","[None, '""utf-8""']",1632,"['    """""" Do it First after Loading some text """"""\n']","['isinstance', 'str']",2
utilmy/zutil.py:np_minimize,np_minimize,function,28,116,91,902,7.78,2,5,"['fun_obj', 'x0', 'argext', '0']","[None, None, None, None]","[None, 'None', '(0', None]",1642,[],"['penalty', 'enumerate', 'max', 'loss', 'fun_obj', 'np_minimize_de', 'range', 'next', 'print', 'save', 'date_now', 'np_int_tostr', 'np.mod', 'np.abs']",14
utilmy/zutil.py:np_minimize_de,np_minimize_de,function,17,56,47,452,8.07,1,3,"['fun_obj', 'bounds', 'name1', 'maxiter', 'popsize', 'solver']","[None, None, None, None, None, None]","[None, None, None, '10', '5', 'None']",1662,[],"['range', 'next', 'print', 'save', 'date_now', 'np_int_tostr', 'np.mod', 'np.abs']",8
utilmy/zutil.py:np_remove_na_inf_2d,np_remove_na_inf_2d,function,12,26,23,117,4.5,2,1,['x'],[None],[None],1686,[],"['np.shape', 'range', 'np.isnan', 'np.isinf']",4
utilmy/zutil.py:np_addcolumn,np_addcolumn,function,7,10,9,85,8.5,0,0,"['arr', 'nbcol']","[None, None]","[None, None]",1695,[],"['np.shape', 'np.zeros', 'np.column_stack']",3
utilmy/zutil.py:np_addrow,np_addrow,function,8,18,17,138,7.67,0,1,"['arr', 'nbrow']","[None, None]","[None, None]",1702,[],"['np.shape', 'len', 'np.zeros', 'np.row_stack', 'np.append']",5
utilmy/zutil.py:np_int_tostr,np_int_tostr,function,3,17,12,72,4.24,0,1,['i'],[None],[None],1712,[],['str'],1
utilmy/zutil.py:np_dictordered_create,np_dictordered_create,function,5,6,6,52,8.67,0,0,[],[],[],1721,[],['OrderedDict'],1
utilmy/zutil.py:np_list_unique,np_list_unique,function,1,2,2,20,10.0,0,0,['seq'],[None],[None],1727,[],['list'],1
utilmy/zutil.py:np_list_tofreqdict,np_list_tofreqdict,function,10,41,25,214,5.22,2,2,"['l1', 'wweight']","[None, None]","[None, 'None']",1731,[],"['dict', 'len', 'enumerate']",3
utilmy/zutil.py:np_list_flatten,np_list_flatten,function,11,25,19,132,5.28,2,1,['seq'],[None],[None],1754,[],"['type', 'np_list_flatten', 'ret.append']",3
utilmy/zutil.py:np_dict_tolist,np_dict_tolist,function,6,18,14,100,5.56,2,1,"['dd', 'withkey']","[None, None]","[None, '0']",1766,[],['list'],1
utilmy/zutil.py:np_dict_tostr_val,np_dict_tostr_val,function,1,7,7,52,7.43,0,0,['dd'],[None],[None],1773,[],['list'],1
utilmy/zutil.py:np_dict_tostr_key,np_dict_tostr_key,function,1,7,7,52,7.43,0,0,['dd'],[None],[None],1777,[],['list'],1
utilmy/zutil.py:np_removelist,np_removelist,function,7,20,16,100,5.0,1,2,"['x0', 'xremove']","[None, None]","[None, 'None']",1781,[],"['np_findfirst', 'xnew.append']",2
utilmy/zutil.py:np_transform2d_int_1d,np_transform2d_int_1d,function,18,47,39,238,5.06,2,0,"['m2d', 'onlyhalf']","[None, None]","[None, 'False']",1792,[],"['np.shape', 'np.zeros', 'range', 'np.abs', 'np_sortbycol']",5
utilmy/zutil.py:np_mergelist,np_mergelist,function,5,9,9,55,6.11,1,0,"['x0', 'x1']","[None, None]","[None, None]",1809,[],"['list', 'xnew.append']",2
utilmy/zutil.py:np_enumerate2,np_enumerate2,function,8,16,14,84,5.25,1,0,['vec_1d'],[None],[None],1816,[],"['np.empty', 'enumerate']",2
utilmy/zutil.py:np_pivottable_count,np_pivottable_count,function,10,24,21,170,7.08,1,0,['mylist'],[None],[None],1825,[],"['np_dict_tolist', 'sorted', 'int']",3
utilmy/zutil.py:np_nan_helper,np_nan_helper,function,2,5,5,40,8.0,0,0,['y'],[None],[None],1834,"['    """""" Input:  - y, 1d numpy array with possible NaNs\n', '        Output - nans, logical indices of NaNs - index, a function, with signature\n', '              indices= index(logical_indices),\n', ""              to convert logical indices of NaNs to 'equivalent' indices\n"", '    """"""\n']","['np.isnan', 'z.nonzero']",2
utilmy/zutil.py:np_interpolate_nan,np_interpolate_nan,function,7,9,9,76,8.44,0,0,['y'],[None],[None],1843,[],"['np_nan_helper', 'np.interp', 'x']",3
utilmy/zutil.py:np_and1,np_and1,function,8,69,25,362,5.25,0,6,"['x', 'y', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']","[None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None', 'None', 'None']",1849,[],[],0
utilmy/zutil.py:np_sortcol,np_sortcol,function,6,7,7,77,11.0,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",1864,"['    """""" df.sort([\'A\', \'B\'], ascending=[1, 0])  """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zutil.py:np_ma,np_ma,function,2,6,6,45,7.5,0,0,"['vv', 'n']","[None, None]","[None, None]",1871,"['    """"""Moving average """"""\n']","['np.convolve', 'np.ones']",2
utilmy/zutil.py:np_cleanmatrix,np_cleanmatrix,function,12,25,21,125,5.0,2,1,['m'],[None],[None],1877,[],"['np.nan_to_num', 'np.shape', 'range', 'abs']",4
utilmy/zutil.py:np_torecarray,np_torecarray,function,2,6,6,105,17.5,0,0,"['arr', 'colname']","[None, None]","[None, None]",1887,[],['np.shape'],1
utilmy/zutil.py:np_sortbycolumn,np_sortbycolumn,function,6,7,7,77,11.0,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1893,[],"['pd.DataFrame', 'df.sort_values']",2
utilmy/zutil.py:np_sortbycol,np_sortbycol,function,8,26,19,257,9.88,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1899,[],"['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zutil.py:np_min_kpos,np_min_kpos,function,2,5,5,36,7.2,0,0,"['arr', 'kth']","[None, None]","[None, None]",1912,"['    """""" return kth mininimun """"""\n']",['np.partition'],1
utilmy/zutil.py:np_max_kpos,np_max_kpos,function,3,10,8,53,5.3,0,0,"['arr', 'kth']","[None, None]","[None, None]",1917,"['    """""" return kth mininimun """"""\n']","['len', 'np.partition']",2
utilmy/zutil.py:np_findfirst,np_findfirst,function,5,11,10,55,5.0,1,1,"['item', 'vec']","[None, None]","[None, None]",1924,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zutil.py:np_find,np_find,function,5,11,10,55,5.0,1,1,"['item', 'vec']","[None, None]","[None, None]",1933,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zutil.py:find,find,function,4,10,10,49,4.9,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1941,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xi.find'],1
utilmy/zutil.py:findnone,findnone,function,4,12,11,55,4.58,1,1,['vec'],[None],[None],1949,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zutil.py:findx,findx,function,8,24,19,130,5.42,0,2,"['item', 'vec']","[None, None]","[None, None]",1957,"['    """"""return the index of the first occurence of item in vec""""""\n']","['type', 'vec.index', 'np.where', 'len']",4
utilmy/zutil.py:finds,finds,function,9,30,20,158,5.27,2,3,"['itemlist', 'vec']","[None, None]","[None, None]",1970,"['    """"""return the index of the first occurence of item in vec""""""\n']","['range', 'idlist.append']",2
utilmy/zutil.py:findhigher,findhigher,function,5,12,11,51,4.25,1,1,"['x', 'vec']","[None, None]","[None, None]",1987,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zutil.py:findlower,findlower,function,5,12,11,51,4.25,1,1,"['x', 'vec']","[None, None]","[None, None]",1995,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zutil.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],2003,[],['min'],1
utilmy/zutil.py:np_find_maxpos,np_find_maxpos,function,16,47,35,274,5.83,1,3,['values'],[None],[None],2008,[],"['max', 'np_find_maxpos_2nd', 'float', 'enumerate']",4
utilmy/zutil.py:np_find_maxpos_2nd,np_find_maxpos_2nd,function,12,39,29,146,3.74,1,3,['numbers'],[None],[None],2013,[],"['float', 'enumerate']",2
utilmy/zutil.py:np_findlocalmax2,np_findlocalmax2,function,32,141,83,689,4.89,2,5,"['v', 'trig']","[None, None]","[None, None]",2028,[],"['len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'np_sortbycolumn', 'range', 'findhigher', 'np.abs']",8
utilmy/zutil.py:np_findlocalmin2,np_findlocalmin2,function,32,145,83,702,4.84,2,6,"['v', 'trig']","[None, None]","[None, None]",2064,[],"['len', 'np.zeros', 'np_find_minpos', 'enumerate', 'np_sortbycolumn', 'range', 'findlower', 'np.abs']",8
utilmy/zutil.py:np_findlocalmax,np_findlocalmax,function,32,141,83,689,4.89,2,5,"['v', 'trig']","[None, None]","[None, None]",2100,[],"['len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'np_sortbycolumn', 'range', 'findhigher', 'np.abs']",8
utilmy/zutil.py:np_findlocalmin,np_findlocalmin,function,32,145,83,702,4.84,2,6,"['v', 'trig']","[None, None]","[None, None]",2116,[],"['len', 'np.zeros', 'np_find_minpos', 'enumerate', 'np_sortbycolumn', 'range', 'findlower', 'np.abs']",8
utilmy/zutil.py:np_stack,np_stack,function,11,63,21,347,5.51,0,7,"['v1', 'v2', 'v3', 'v4', 'v5']","[None, None, None, None, None]","[None, 'None', 'None', 'None', 'None']",2134,[],"['np.shape', 'np.row_stack', 'np.column_stack']",3
utilmy/zutil.py:np_uniquerows,np_uniquerows,function,6,9,9,148,16.44,0,0,['a'],[None],[None],2156,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zutil.py:np_remove_zeros,np_remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",2162,[],[],0
utilmy/zutil.py:np_sort,np_sort,function,6,7,7,77,11.0,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2166,"['    """"""\n', '    Creates a cross-tab or pivot table from a normalised input table. Use this\n', ""    function to 'denormalize' a table of normalized records.\n"", '\n', '    * The table argument can be a list of dictionaries or a Table object.\n', '    (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/334621)\n', '    * The left argument is a tuple of headings which are displayed down the\n', '    left side of the new table.\n', '    * The top argument is a tuple of headings which are displayed across the\n', '    top of the new table.\n', '    Tuples are used so that multiple element headings and columns can be used.\n', '\n', '    E.g. To transform the list (listOfDicts):\n', '\n', '    Name,   Year,  Value\n', '    -----------------------\n', ""    'Simon', 2004, 32\n"", ""    'Simon', 2005, 128\n"", ""    'Russel', 2004, 64\n"", ""    'Eric', 2004, 52\n"", ""    'Russel', 2005, 32\n"", '\n', '    into the new list:\n', '\n', ""    'Name',   2004, 2005\n"", '    ------------------------\n', ""    'Simon',  32,     128\n"", ""    'Russel',  64,     32\n"", ""    'Eric',   52,     NA\n"", '\n', '    you would call pivot with the arguments:\n', '\n', ""    newList = pivot(listOfDicts, ('Name',), ('Year',), 'Value')\n"", '\n', '    """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zutil.py:np_memory_array_adress,np_memory_array_adress,function,2,2,2,38,19.0,0,0,['x'],[None],[None],2170,[],[],0
utilmy/zutil.py:np_pivotable_create,np_pivotable_create,function,28,100,60,701,7.01,4,5,"['table', 'left', 'top', 'value']","[None, None, None, None]","[None, None, None, None]",2175,"['    """"""\n', '    Creates a cross-tab or pivot table from a normalised input table. Use this\n', ""    function to 'denormalize' a table of normalized records.\n"", '\n', '    * The table argument can be a list of dictionaries or a Table object.\n', '    (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/334621)\n', '    * The left argument is a tuple of headings which are displayed down the\n', '    left side of the new table.\n', '    * The top argument is a tuple of headings which are displayed across the\n', '    top of the new table.\n', '    Tuples are used so that multiple element headings and columns can be used.\n', '\n', '    E.g. To transform the list (listOfDicts):\n', '\n', '    Name,   Year,  Value\n', '    -----------------------\n', ""    'Simon', 2004, 32\n"", ""    'Simon', 2005, 128\n"", ""    'Russel', 2004, 64\n"", ""    'Eric', 2004, 52\n"", ""    'Russel', 2005, 32\n"", '\n', '    into the new list:\n', '\n', ""    'Name',   2004, 2005\n"", '    ------------------------\n', ""    'Simon',  32,     128\n"", ""    'Russel',  64,     32\n"", ""    'Eric',   52,     NA\n"", '\n', '    you would call pivot with the arguments:\n', '\n', ""    newList = pivot(listOfDicts, ('Name',), ('Year',), 'Value')\n"", '\n', '    """"""\n']","['tuple', 'ysort.append', 'xsort.append', 'len', 'list', 'xsort.sort', 'headings.extend', 'sortedkeys.sort', 'row.extend', 't.append']",10
utilmy/zutil.py:pd_info,pd_info,function,12,24,22,257,10.71,1,2,"['df', 'doreturn']","[None, None]","[None, '1']",2259,[],"['df.info', 'print', 'type', 'pd_info_memsize', 'pd_info', 'df.memory_usage']",6
utilmy/zutil.py:pd_info_memsize,pd_info_memsize,function,5,7,7,85,12.14,0,1,"['df', 'memusage']","[None, None]","[None, '0']",2268,[],"['df.info', 'pd_info', 'df.memory_usage']",3
utilmy/zutil.py:pd_row_findlast,pd_row_findlast,function,7,11,11,58,5.27,1,1,"['df', 'colid', 'emptyrowid']","[None, None, None]","[None, '0', 'None']",2275,[],['df.iterrows'],1
utilmy/zutil.py:pd_row_select,pd_row_select,function,13,112,53,862,7.7,1,3,"['df', '**conditions']","[None, None]","[None, None]",2282,"['    """"""Select rows from a df according to conditions\n', '    pdselect(data, a=2, b__lt=3) __gt __ge __lte  __in  __not_in\n', ""    will select all rows where 'a' is 2 and 'b' is less than 3\n"", '    """"""\n']","['type', 'pd.DataFrame', 'list', 'c.endswith', 'np.in1d', 'ValueError']",6
utilmy/zutil.py:pd_csv_randomread,pd_csv_randomread,function,13,47,38,267,5.68,0,1,"['filename', 'nsample', 'filemaxline', 'dtype']","[None, None, None, None]","[None, '10000', '-1', 'None']",2328,[],"['sum', 'open', 'np.sort', 'pd.read_csv']",4
utilmy/zutil.py:pd_array_todataframe,pd_array_todataframe,function,14,37,30,313,8.46,0,2,"['array', 'colname', 'index1', 'dotranspose']","[None, None, None, None]","[None, 'None', 'None', 'False']",2341,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zutil.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,11,10,103,9.36,0,0,['df'],[None],[None],2352,[],['df.reset_index'],1
utilmy/zutil.py:pd_createdf,pd_createdf,function,2,4,4,55,13.75,0,0,"['array1', 'col1', 'idx1']","[None, None, None]","[None, 'None', 'None']",2359,[],['pd.DataFrame'],1
utilmy/zutil.py:pd_create_colmapdict_nametoint,pd_create_colmapdict_nametoint,function,9,13,12,77,5.92,1,0,['df'],[None],[None],2363,"['    """""" \'close\' ---> 5    """"""\n']",['enumerate'],1
utilmy/zutil.py:pd_extract_col_idx_val,pd_extract_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],2373,[],[],0
utilmy/zutil.py:pd_extract_col_uniquevalue_tocsv,pd_extract_col_uniquevalue_tocsv,function,5,7,6,101,14.43,0,0,"['df', 'colname', 'csvfile']","[None, None, None]","[None, '""""', '""""']",2377,"['    """""" Write one column into a file   """"""\n']","['np.array', 'pd.DataFrame', 'print']",3
utilmy/zutil.py:pd_split_col_idx_val,pd_split_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],2385,[],[],0
utilmy/zutil.py:pd_splitdf_inlist,pd_splitdf_inlist,function,14,34,25,254,7.47,3,2,"['df', 'colid', 'type1']","[None, None, None]","[None, None, '""dict""']",2389,"['    """""" Split df into dictionnary of dict/list """"""\n']","['list', 'l1.append']",2
utilmy/zutil.py:pd_find,pd_find,function,35,142,88,1051,7.4,4,8,"['df', 'regex_pattern', 'col_restrict', 'isnumeric', 'doreturnposition']","[None, None, None, None, None]","[None, '""*""', 'None', 'False', 'False']",2405,"['    """""" Find string / numeric values inside df columns, return position where found\n', '     col_restrict : restrict to these columns """"""\n']","['str', 'print', 'enumerate', 'np.column_stack', 'len', 'gc.collect', 'np_dictordered_create', 'range', 'np.array']",9
utilmy/zutil.py:pd_dtypes_totype2,pd_dtypes_totype2,function,6,8,8,59,7.38,1,0,"['df', 'columns']","[None, None]","[None, '(']",2466,[],[],0
utilmy/zutil.py:pd_dtypes,pd_dtypes,function,21,58,46,358,6.17,2,2,"['df', 'columns']","[None, None]","[None, '(']",2472,[],"['pd_dtypes', 'OrderedDict', 'enumerate', 'eval', 'print']",5
utilmy/zutil.py:pd_df_todict2,pd_df_todict2,function,14,31,26,249,8.03,1,2,"['df', 'colkey', 'excludekey', '']","[None, None, None, None]","[None, '""table""', '(""""', None]",2492,[],"['df.drop_duplicates', 'range', 'len', 'dict0.setdefault']",4
utilmy/zutil.py:pd_df_todict,pd_df_todict,function,21,49,39,414,8.45,2,2,"['df', 'colkey', 'excludekey', '']","[None, None, None, None]","[None, '""table""', '(""""', None]",2507,[],"['df.drop_duplicates', 'range', 'len', 'dict0.setdefault', 'pd_df_todict', 'df.iterrows']",6
utilmy/zutil.py:pd_col_addfrom_dfmap,pd_col_addfrom_dfmap,function,4,7,6,69,9.86,0,0,"['df', 'dfmap', 'colkey', 'colval', 'df_colused', 'df_colnew', 'exceptval', 'inplace', 'colkey', 'colval=colval)rowi)']","[None, None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, '-1', 'Truedfmap', 'colkey', 'colval)rowi):']",2518,"['    """""" Add new columns based on df_map:  In Place Modification of df\n', '    df:     Dataframe of transactions.\n', '    dfmap:  FSMaster Dataframe\n', '      colkey: colum used for dict key.  machine_code\n', '      colval: colum used for dict val.  adress\n', '\n', '    df_colused  :     ""machine_code""\n', ""    exception val:  -1 or ''\n"", '  """"""\n']",[],0
utilmy/zutil.py:pd_applyfun_col,pd_applyfun_col,function,5,10,9,109,10.9,0,1,"['df', 'newcol', 'ff', 'use_colname']","[None, None, None, None]","[None, None, None, '""all/[colname]""']",2578,"['    """""" use all Columns to compute values """"""\n']",['ff'],1
utilmy/zutil.py:pd_date_intersection,pd_date_intersection,function,7,17,13,157,9.24,1,0,['qlist'],[None],[None],2599,[],"['set', 'set.intersection', 'list', 'sorted']",4
utilmy/zutil.py:pd_is_categorical,pd_is_categorical,function,3,13,11,118,9.08,0,1,['z'],[None],[None],2609,[],['isinstance'],1
utilmy/zutil.py:pd_str_encoding_change,pd_str_encoding_change,function,6,8,8,76,9.5,1,0,"['df', 'cols', 'fromenc', 'toenc']","[None, None, None, None]","[None, None, '""iso-8859-1""', '""utf-8""']",2618,[],[],0
utilmy/zutil.py:pd_str_unicode_tostr,pd_str_unicode_tostr,function,4,6,6,72,12.0,0,0,"['df', 'targetype']","[None, None]","[None, 'str']",2625,"['    """"""\n', ' https://www.azavea.com/blog/2014/03/24/solving-unicode-problems-in-python-2-7/\n', ' Nearly every Unicode problem can be solved by the proper application of these tools;\n', ' they will help you build an airlock to keep the inside of your code nice and clean:\n', '\n', 'encode(): Gets you from Unicode -> bytes\n', 'decode(): Gets you from bytes -> Unicode\n', 'codecs.open(encoding=""utf-8""): Read and write files directly to/from Unicode (you can use any\n', 'encoding,\n', ' not just utf-8, but utf-8 is most common).\n', 'u"": Makes your string literals into Unicode objects rather than byte sequences.\n', ""Warning: Don't use encode() on bytes or decode() on Unicode objects\n"", '\n', '# >>> uni_greeting % utf8_name\n', 'Traceback (most recent call last):\n', ' File ""<stdin>"", line 1, in <module>\n', ""UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 3: ordinal not in range(128)\n"", '# Solution:\n', ""# >>> uni_greeting % utf8_name.decode('utf-8')\n"", ""u'Hi, my name is Josxe9.'\n"", '\n', ' """"""\n']",['pd_dtypes_type1_totype2'],1
utilmy/zutil.py:pd_dtypes_type1_totype2,pd_dtypes_type1_totype2,function,7,11,11,100,9.09,1,1,"['df', 'fromtype', 'targetype']","[None, None, None]","[None, 'str', 'str']",2653,[],['isinstance'],1
utilmy/zutil.py:pd_resetindex,pd_resetindex,function,3,5,5,50,10.0,0,0,['df'],[None],[None],2661,[],"['list', 'len']",2
utilmy/zutil.py:pd_insertdatecol,pd_insertdatecol,function,4,7,7,71,10.14,0,0,"['df', 'col', 'format1=""%Y-%m-%d %H']","[None, None, '']","[None, None, '""%Y-%m-%d %H:%M:%S:%f""']",2666,[],['date_nowtime'],1
utilmy/zutil.py:pd_replacevalues,pd_replacevalues,function,11,14,14,104,7.43,1,0,"['df', 'matrix']","[None, None]","[None, None]",2671,"['    """""" Matrix replaces df.values  """"""\n']",['np.shape'],1
utilmy/zutil.py:pd_removerow,pd_removerow,function,2,2,2,29,14.5,0,0,"['df', 'row_list_index', '45']","[None, None, None]","[None, '(23', None]",2681,[],['df.drop'],1
utilmy/zutil.py:pd_removecol,pd_removecol,function,2,3,3,28,9.33,0,0,"['df1', 'name1']","[None, None]","[None, None]",2685,[],['df1.drop'],1
utilmy/zutil.py:pd_insertrow,pd_insertrow,function,7,11,10,112,10.18,0,0,"['df', 'rowval', 'index1', 'isreset']","[None, None, None, None]","[None, None, 'None', '1']",2689,[],"['pd_array_todataframe', 'df.append']",2
utilmy/zutil.py:pd_h5_cleanbeforesave,pd_h5_cleanbeforesave,function,4,13,11,91,7.0,0,0,['df'],[None],[None],2699,"['    """"""Clean Column type before Saving in HDFS: Unicode, Datetime  """"""\n']","['pd_resetindex', 'pd_str_unicode_tostr']",2
utilmy/zutil.py:pd_h5_addtable,pd_h5_addtable,function,6,16,16,148,9.25,0,1,"['df', 'tablename', 'dbfile=""F']","[None, None, '']","[None, None, '""F:\\temp_pandas.h5""']",2716,[],"['pd.HDFStore', 'find', 'list', 'print', 'store.append', 'store.close']",6
utilmy/zutil.py:pd_h5_tableinfo,pd_h5_tableinfo,function,4,4,4,65,16.25,0,0,"['filenameh5', 'table']","[None, None]","[None, None]",2726,[],"['pd.HDFStore', 'store.get_storer']",2
utilmy/zutil.py:pd_h5_dumpinfo,pd_h5_dumpinfo,function,13,28,26,334,11.93,1,0,"['dbfile=r""E']",[''],"['r""E:\\_data\\stock\\intraday_google.h5""']",2731,[],"['pd.HDFStore', 'list', 'pd.DataFrame', 'extract.append', 'datetime_tostring', 'errsym.append', 'np.array']",7
utilmy/zutil.py:pd_h5_save,pd_h5_save,function,4,5,5,64,12.8,0,0,"['df', 'filenameh5=""E', 'key']","[None, '', None]","[None, '""E:/_data/_data_outlier.h5""', '""data""']",2753,"['    """""" File is release after saving it""""""\n']","['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zutil.py:pd_h5_load,pd_h5_load,function,9,24,20,210,8.75,0,2,"['filenameh5=""E', 'table_id', 'exportype', 'rowstart', 'rowend', ')', '']","['', None, None, None, None, None, None]","['""E:/_data/_data_outlier.h5""', '""data""', '""pandas""', '-1', '-1', None, None]",2760,[],"['pd.read_hdf', 'pd.DataFrame']",2
utilmy/zutil.py:pd_h5_fromcsv_tohdfs,pd_h5_fromcsv_tohdfs,function,29,80,63,661,8.26,3,2,"['dircsv', 'filepattern', 'tofilehdfs', 'tablename', ')', 'dtype0', 'encoding', 'chunksize', 'mode', 'form', 'complib', '']","[None, None, None, None, None, None, None, None, None, None, None, None]","['""dir1/dir2/""', '""*.csv""', '""file1.h5""', '""df""', None, 'None', '""utf-8""', '2000000', '""a""', '""table""', 'None', None]",2780,[],"['os_file_listall', 'pd.HDFStore', 'enumerate', 'pd.read_csv', 'print', 'store.append', 'store.close', 'os_file_exist']",8
utilmy/zutil.py:pd_np_toh5file,pd_np_toh5file,function,6,8,7,82,10.25,0,0,"['numpyarr', 'fileout', 'table1']","[None, None, None]","[None, '""file.h5""', '""data""']",2837,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zutil.py:date_allinfo,date_allinfo,function,0,0,0,0,0.0,0,0,[],[],[],2844,"['    """"""\n', '\n', 'https://aboutsimon.com/blog/2016/08/04/datetime-vs-Arrow-vs-Pendulum-vs-Delorean-vs-udatetime.html\n', '\n', '\n', '   """"""\n']",[],0
utilmy/zutil.py:datetime_tostring,datetime_tostring,function,9,21,15,245,11.67,1,2,['datelist1'],[None],[None],2853,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zutil.py:date_remove_bdays,date_remove_bdays,function,14,36,26,354,9.83,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2866,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zutil.py:date_add_bdays,date_add_bdays,function,14,36,27,353,9.81,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2884,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zutil.py:datenumpy_todatetime,datenumpy_todatetime,function,9,40,24,384,9.6,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",2902,[],['type'],1
utilmy/zutil.py:datetime_tonumpydate,datetime_tonumpydate,function,4,4,4,36,9.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",2919,[],['np.datetime64'],1
utilmy/zutil.py:datestring_todatetime,datestring_todatetime,function,9,16,14,136,8.5,1,1,"['datelist1', 'format1']","[None, None]","[None, '""%Y%m%d""']",2925,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zutil.py:datetime_toint,datetime_toint,function,6,14,12,156,11.14,1,1,['datelist1'],[None],[None],2937,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zutil.py:date_holiday,date_holiday,function,0,0,0,0,0.0,0,0,[],[],[],2946,"['    """"""\n', '   https://jakevdp.github.io/blog/2015/07/23/learning-seattles-work-habits-from-bicycle-counts/\n', '\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'cal = USFederalHolidayCalendar()\n', ""holidays = cal.holidays('2012', '2016', return_name=True)\n"", 'holidays.head()\n', '\n', 'holidays_all = pd.concat([holidays, ""Day Before "" + holidays.shift(-1, \'D\'),  ""Day After ""\n', ""+ holidays.shift(1, 'D')])\n"", 'holidays_all = holidays_all.sort_index()\n', 'holidays_all.head()\n', '\n', 'from pandas.tseries.offsets import CustomBusinessDay\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'bday_us = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n', 'dateref[-1] - bday_us- bday_us\n', '\n', '   """"""\n']",[],0
utilmy/zutil.py:date_add_bday,date_add_bday,function,14,36,27,353,9.81,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2968,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zutil.py:dateint_todatetime,dateint_todatetime,function,7,14,12,136,9.71,1,1,['datelist1'],[None],[None],2983,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zutil.py:date_diffinday,date_diffinday,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",2993,[],['dateint_todatetime'],1
utilmy/zutil.py:date_diffinbday,date_diffinbday,function,7,11,9,112,10.18,0,0,"['intd2', 'intd1']","[None, None]","[None, None]",2998,[],"['dateint_todatetime', 'd1.date', 'd2.date', 'np.busday_count']",4
utilmy/zutil.py:date_gencalendar,date_gencalendar,function,11,16,14,242,15.12,0,0,"['start', 'end', 'country']","[None, None, None]","['""2010-01-01""', '""2010-01-15""', '""us""']",3007,[],"['CustomBusinessDay', 'np.array']",2
utilmy/zutil.py:date_finddateid,date_finddateid,function,3,75,12,447,5.96,0,10,"['date1', 'dateref']","[None, None]","[None, None]",3017,[],['np_findfirst'],1
utilmy/zutil.py:datestring_toint,datestring_toint,function,6,14,12,108,7.71,1,1,['datelist1'],[None],[None],3042,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zutil.py:date_now,date_now,function,14,44,29,401,9.11,0,2,['i'],[None],['0'],3051,[],"['datetime.now', 'date_add_bdays', 'date_remove_bdays', 'str', 'date_nowtime', 'datetime.today', 'd.strftime']",7
utilmy/zutil.py:date_nowtime,date_nowtime,function,8,22,18,208,9.45,0,1,"['type1', 'format1=""%Y-%m-%d %H']","[None, '']","['""str""', '""%Y-%m-%d %H:%M:%S:%f""']",3062,"['    """""" str / stamp /  """"""\n']","['datetime.today', 'd.strftime']",2
utilmy/zutil.py:date_generatedatetime,date_generatedatetime,function,17,32,28,268,8.38,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",3076,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zutil.py:np_numexpr_vec_calc,np_numexpr_vec_calc,function,5,12,12,110,9.17,0,0,[],[],[],3088,[],[],0
utilmy/zutil_features.py:log,log,function,6,30,20,188,6.27,0,2,"['*s', 'n', 'm', '**kw']","[None, None, None, None]","[None, '0', '1', None]",12,[],"['print', 'log2', 'log3']",3
utilmy/zutil_features.py:log2,log2,function,2,7,7,40,5.71,0,1,"['*s', '**kw']","[None, None]","[None, None]",18,[],['print'],1
utilmy/zutil_features.py:log3,log3,function,2,7,7,40,5.71,0,1,"['*s', '**kw']","[None, None]","[None, None]",21,[],['print'],1
utilmy/zutil_features.py:os_get_function_name,os_get_function_name,function,4,4,4,47,11.75,0,0,[],[],[],32,[],['sys._getframe'],1
utilmy/zutil_features.py:os_getcwd,os_getcwd,function,3,6,5,66,11.0,0,0,[],[],[],37,[],[],0
utilmy/zutil_features.py:pa_read_file,pa_read_file,function,38,129,74,709,5.5,2,9,"['path', 'cols', 'n_rows', 'file_start', 'file_end', 'verbose', '']","[None, None, None, None, None, None, None]","[""  'folder_parquet/'"", 'None', '1000', '0', '100000', '1', None]",43,"['    """"""Requied HDFS connection\n', '       http://arrow.apache.org/docs/python/parquet.html\n', '\n', '       conda install libhdfs3 pyarrow\n', '       in your script.py:\n', '        import os\n', ""        os.environ['ARROW_LIBHDFS_DIR'] = '/opt/cloudera/parcels/CDH/lib64/'\n"", '\n', '       https://stackoverflow.com/questions/18123144/missing-server-jvm-java-jre7-bin-server-jvm-dll\n', '\n', '    """"""\n']","['hdfs.ls', 'glob.glob', 'fi.split', 'print', 'pq.read_table', 'arr_table.to_pandas', 'gc.collect', 'pd.concat', 'len', 'dfall.head']",10
utilmy/zutil_features.py:pa_write_file,pa_write_file,function,23,62,45,599,9.66,0,4,"['df', 'path', 'cols', 'n_rows', 'partition_cols', 'overwrite', 'verbose', 'filesystem ']","[None, None, None, None, None, None, None, None]","[None, ""  'folder_parquet/'"", 'None', '1000', 'None', 'True', '1', "" 'hdfs'""]",97,"['    """""" Pandas to HDFS\n', ""      pyarrow.parquet.write_table(table, where, row_group_size=None, version='1.0',\n"", ""      use_dictionary=True, compression='snappy', write_statistics=True, use_deprecated_int96_timestamps=None,\n"", '      coerce_timestamps=None, allow_truncated_timestamps=False, data_page_size=None,\n', ""      flavor=None, filesystem=None, compression_level=None, use_byte_stream_split=False, data_page_version='1.0', **kwargs)\n"", '\n', '      https://arrow.apache.org/docs/python/generated/pyarrow.parquet.write_to_dataset.html#pyarrow.parquet.write_to_dataset\n', '\n', '    """"""\n']","['hdfs.rm', 'hdfs.mkdir', 'pq.write_to_dataset', 'hdfs.ls', 'print', 'os.removedirs', 'os.makedirs', 'os.listdir']",8
utilmy/zutil_features.py:test_get_classification_data,test_get_classification_data,function,20,44,40,470,10.68,1,0,['name'],[None],['None'],143,[],"['make_classification', 'range', 'pd.DataFrame', 'np.arange', 'len', 'dfX.set_index', 'dfy.set_index']",7
utilmy/zutil_features.py:params_check,params_check,function,7,56,26,259,4.62,1,5,"['pars', 'check_list', 'name']","[None, None, None]","[None, None, '""""']",160,"['    """"""\n', '      Validate a dict parans\n', '    :param pars:\n', '    :param check_list:\n', '    :param name:\n', '    :return:\n', '    """"""\n']","['isinstance', 'Exception']",2
utilmy/zutil_features.py:save_features,save_features,function,7,30,26,275,9.17,0,2,"['df', 'name', 'path']","[None, None, None]","[None, None, 'None']",186,"['    """""" Save dataframe on disk\n', '    :param df:\n', '    :param name:\n', '    :param path:\n', '    :return:\n', '    """"""\n']","['os.makedirs', 'isinstance', 'log', 'list', 'df0.to_parquet']",5
utilmy/zutil_features.py:load_features,load_features,function,3,10,9,110,11.0,0,0,"['name', 'path']","[None, None]","[None, None]",206,[],"['pd.read_parquet', 'log']",2
utilmy/zutil_features.py:save_list,save_list,function,8,21,20,166,7.9,1,0,"['path', 'name_list', 'glob']","[None, None, None]","[None, None, None]",214,[],"['os.makedirs', 'log', 'pickle.dump', 'open']",4
utilmy/zutil_features.py:save,save,function,7,30,26,275,9.17,0,2,"['df', 'name', 'path']","[None, None, None]","[None, None, 'None']",221,"['  """"""\n', '      Read file in parallel from disk : very Fast\n', '  :param path_glob:\n', '  :param ignore_index:\n', '  :param cols:\n', '  :param verbose:\n', '  :param nrows:\n', '  :param concat_sort:\n', '  :param n_pool:\n', '  :param drop_duplicates:\n', '  :param shop_id:\n', '  :param kw:\n', '  :return:\n', '  """"""\n']","['os.makedirs', 'isinstance', 'log', 'list', 'df0.to_parquet']",5
utilmy/zutil_features.py:load,load,function,3,10,9,110,11.0,0,0,"['name', 'path']","[None, None]","[None, None]",228,"['  """"""\n', '      Read file in parallel from disk : very Fast\n', '  :param path_glob:\n', '  :param ignore_index:\n', '  :param cols:\n', '  :param verbose:\n', '  :param nrows:\n', '  :param concat_sort:\n', '  :param n_pool:\n', '  :param drop_duplicates:\n', '  :param shop_id:\n', '  :param kw:\n', '  :return:\n', '  """"""\n']","['pd.read_parquet', 'log']",2
utilmy/zutil_features.py:pd_read_file,pd_read_file,function,52,161,100,1083,6.73,3,10,"['path_glob', 'ignore_index', 'cols', 'verbose', 'nrows', 'concat_sort', 'n_pool', 'drop_duplicates', 'col_filter', 'col_filter_val', '**kw']","[None, None, None, None, None, None, None, None, None, None, None]","['""*.pkl""', 'True', 'None', 'False', '-1', 'True', '1', 'None', 'None', 'None', None]",233,"['  """"""\n', '      Read file in parallel from disk : very Fast\n', '  :param path_glob:\n', '  :param ignore_index:\n', '  :param cols:\n', '  :param verbose:\n', '  :param nrows:\n', '  :param concat_sort:\n', '  :param n_pool:\n', '  :param drop_duplicates:\n', '  :param shop_id:\n', '  :param kw:\n', '  :return:\n', '  """"""\n']","['ThreadPool', 'glob.glob', 'pd.DataFrame', 'len', 'log', 'range', 'job_list.append', 'pool.apply_async', 'dfi.drop_duplicates', 'gc.collect', 'pd.concat']",11
utilmy/zutil_features.py:load_dataset,load_dataset,function,35,207,126,1727,8.34,3,11,"['path_data_x', 'path_data_y', 'colid', 'n_sample']","[None, None, None, None]","[None, ""''"", '""jobId""', '-1']",300,"['    """"""\n', '      return a datraframe\n', '      https://raw.github.com/someguy/brilliant/master/somefile.txt\n', '\n', '    :param path_data_x:\n', '    :param path_data_y:\n', '    :param colid:\n', '    :param n_sample:\n', '    :return:\n', '    """"""\n']","['log', 'fetch_spark_koalas', 'fetch_dataset', 'glob.glob', 'ntpath.dirname', 'ntpath.basename', 'len', 'print', 'pd.read_csv', 'fi.endswith', 'pd.read_parquet', 'pd.read_pickle', 'pd.concat', 'df.head', 'list', 'np.arange', 'df.set_index', 'pd_read_file', 'dfy.head', 'df.join']",20
utilmy/zutil_features.py:fetch_spark_koalas,fetch_spark_koalas,function,9,11,11,109,9.91,0,0,"['path_data_x', 'path_data_y', 'colid', 'n_sample']","[None, None, None, None]","[None, ""''"", '""jobId""', '-1']",378,[],"['path_data_x.replace', 'ks.read_parquet']",2
utilmy/zutil_features.py:fetch_dataset,fetch_dataset,function,52,177,125,1978,11.18,1,6,"['url_dataset', 'path_target', 'file_target']","[None, None, None]","[None, 'None', 'None']",386,"['    """"""Fetch dataset from a given URL and save it.\n', '\n', '    Currently `github`, `gdrive` and `dropbox` are the only supported sources of\n', '    data. Also only zip files are supported.\n', '\n', '    :param url_dataset:   URL to send\n', '    :param path_target:   Path to save dataset\n', '    :param file_target:   File to save dataset\n', '\n', '    """"""\n']","['log', 'mkdtemp', 'pathlib.Path', 'mktemp', 'url_dataset.replace', 'urlx.replace', 'urlpath.split', 'os.makedirs', 'requests.Session', 's.get', 'print', 'open', 'f.write', 'res.raise_for_status', 'urlparse', 'parse_qs', 'download_googledrive', 'download_dtopbox', 'os.listdir', 'os.unlink', 'os.link']",21
utilmy/zutil_features.py:load_function_uri,load_function_uri,function,25,66,59,691,10.47,0,0,"['uri_name=""myfolder/myfile.py']",[''],"['""myfolder/myfile.py::myFunction""']",491,"['    """"""\n', '    #load dynamically function from URI pattern\n', '    #""dataset""        : ""mlmodels.preprocess.generic:pandasDataset""\n', '    ###### External File processor :\n', '    #""dataset""        : ""MyFolder/preprocess/myfile.py:pandasDataset""\n', '    """"""\n']","['uri_name.split', 'len', 'package_path.replace', 'getattr', 'str', 'log', 'Path', 'NameError']",8
utilmy/zutil_features.py:metrics_eval,metrics_eval,function,23,71,52,902,12.7,2,3,"['metric_list', 'ytrue', 'ypred', 'ypred_proba', 'return_dict']","[None, None, None, None, None]","['[""mean_squared_error""]', 'None', 'None', 'None', 'False']",531,"['    """"""\n', '      Generic metrics calculation, using sklearn naming pattern\n', '    """"""\n']","['len', 'isinstance', 'getattr', 'range', 'mval_.append', 'np.mean', 'np.sqrt', 'metric_scorer', 'pd.DataFrame']",9
utilmy/zutil_features.py:pd_stat_dataset_shift,pd_stat_dataset_shift,function,14,24,23,328,13.67,1,0,"['dftrain', 'dftest', 'colused', 'nsample', 'buckets', 'axis']","[None, None, None, None, None, None]","[None, None, None, '10000', '5', '0']",572,[],"['print', 'pd_stat_datashift_psi', 'pd.DataFrame']",3
utilmy/zutil_features.py:pd_stat_datashift_psi,pd_stat_datashift_psi,function,25,122,83,1188,9.74,1,5,"['expected', 'actual', 'buckettype', 'buckets', 'axis']","[None, None, None, None, None]","[None, None, ""'bins'"", '10', '0']",588,"[""    '''Calculate the PSI (population stability index) across all variables\n"", '    Args:\n', '       expected: numpy matrix of original values\n', '       actual: numpy matrix of new values, same size as expected\n', '       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n', '       buckets: number of quantiles to use in bucketing variables\n', '       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n', '    Returns:\n', '       psi_values: ndarray of psi values for each variable\n', ""    '''\n""]","['psi', 'scale_range', 'np.max', 'np.arange', 'np.min', 'np.stack', 'np.histogram', 'len', 'sub_psi', 'np.log', 'np.sum', 'range', 'np.empty']",13
utilmy/zutil_features.py:feature_importance_perm,feature_importance_perm,function,31,57,54,761,13.35,1,1,"['clf', 'Xtrain', 'ytrain', 'cols', 'n_repeats', 'scoring', 'show_graph']","[None, None, None, None, None, None, None]","[None, None, None, None, '8', ""'neg_root_mean_squared_error'"", '1']",660,[],"['permutation_importance', 'list', 'pd.DataFrame', 'np.arange', 'min', 'len', 'plt.subplots', 'ax1.boxplot', 'ax1.set_yticklabels', 'ax1.set_ylim', 'fig.tight_layout', 'plt.show']",12
utilmy/zutil_features.py:feature_selection_multicolinear,feature_selection_multicolinear,function,25,44,36,510,11.59,3,0,"['df', 'threshold']","[None, None]","[None, '1.0']",694,[],"['list', 'spearmanr', 'hierarchy.ward', 'hierarchy.fcluster', 'defaultdict', 'enumerate', 'cluster_id_to_feature_ids.values']",7
utilmy/zutil_features.py:feature_correlation_cat,feature_correlation_cat,function,24,45,41,582,12.93,0,0,"['df', 'colused']","[None, None]","[None, None]",712,[],"['plt.subplots', 'spearmanr', 'hierarchy.ward', 'hierarchy.dendrogram', 'np.arange', 'len', 'ax2.imshow', 'ax2.set_xticks', 'ax2.set_yticks', 'ax2.set_xticklabels', 'ax2.set_yticklabels', 'fig.tight_layout', 'plt.show']",13
utilmy/zutil_features.py:pd_feature_generate_cross,pd_feature_generate_cross,function,33,70,59,485,6.93,2,2,"['df', 'cols', 'cols_cross_input', 'pct_threshold', 'm_combination']","[None, None, None, None, None]","[None, None, 'None', '0.2', '2']",735,"['    """"""\n', '       Generate Xi.Xj features and filter based on stats threshold\n', '    """"""\n']","['len', 'itertools.combinations', 'range', 'y.sum', 'col_cross.append']",5
utilmy/zutil_features.py:pd_col_to_onehot,pd_col_to_onehot,function,20,94,61,616,6.55,3,6,"['dfref', 'colname', 'colonehot', 'return_val']","[None, None, None, None]","[None, 'None', 'None', '""dataframe,column""']",770,"['    """"""\n', '    :param df:\n', '    :param colname:\n', '    :param colonehot: previous one hot columns\n', '    :param returncol:\n', '    :return:\n', '    """"""\n']","['copy.deepcopy', 'list', 'len', 'print', 'pd.concat', 'pd.get_dummies', 'coladded.append']",7
utilmy/zutil_features.py:pd_colcat_mergecol,pd_colcat_mergecol,function,17,41,32,255,6.22,2,1,"['df', 'col_list', 'x0', 'colid']","[None, None, None, None]","[None, None, None, '""easy_id""']",813,"['    """"""\n', '       Merge category onehot column\n', '    :param df:\n', '    :param l:\n', '    :param x0:\n', '    :return:\n', '    """"""\n']","['pd.DataFrame', 't.rfind', 'int', 'print', 'dfz.set_index']",5
utilmy/zutil_features.py:pd_colcat_tonum,pd_colcat_tonum,function,21,62,43,534,8.61,1,4,"['df', 'colcat', 'drop_single_label', 'drop_fact_dict']","[None, None, None, None]","[None, '""all""', 'False', 'True']",837,"['    """"""\n', '    Encoding a data-set with mixed data (numerical and categorical) to a numerical-only data-set,\n', '    using the following logic:\n', '    * categorical with only a single value will be marked as zero (or dropped, if requested)\n', '    * categorical with two values will be replaced with the result of Pandas `factorize`\n', '    * categorical with more than two values will be replaced with the result of Pandas `get_dummies`\n', '    * numerical columns will not be modified\n', '    **Returns:** DataFrame or (DataFrame, dict). If `drop_fact_dict` is True, returns the encoded DataFrame.\n', '    else, returns a tuple of the encoded DataFrame and dictionary, where each key is a two-value column, and the\n', '    value is the original labels, as supplied by Pandas `factorize`. Will be empty if no two-value columns are\n', '    present in the data-set\n', '    Parameters\n', '    ----------\n', '    df : NumPy ndarray / Pandas DataFrame\n', '        The data-set to encode\n', '    colcat : sequence / string\n', ""        A sequence of the nominal (categorical) columns in the dataset. If string, must be 'all' to state that\n"", ""        all columns are nominal. If None, nothing happens. Default: 'all'\n"", '    drop_single_label : Boolean, default = False\n', '        If True, nominal columns with a only a single value will be dropped.\n', '    drop_fact_dict : Boolean, default = True\n', '        If True, the return value will be the encoded DataFrame alone. If False, it will be a tuple of\n', '        the DataFrame and the dictionary of the binary factorization (originating from pd.factorize)\n', '    """"""\n']","['pd.DataFrame', 'dict', 'pd.unique', 'len', 'pd.factorize', 'pd.get_dummies', 'pd.concat']",7
utilmy/zutil_features.py:pd_colcat_mapping,pd_colcat_mapping,function,9,35,20,271,7.74,4,0,"['df', 'colname']","[None, None]","[None, None]",889,"['    """"""\n', '       map category to integers\n', '    :param df:\n', '    :param colname:\n', '    :return:\n', '    """"""\n']",['enumerate'],1
utilmy/zutil_features.py:pd_colcat_toint,pd_colcat_toint,function,28,78,50,628,8.05,4,2,"['dfref', 'colname', 'colcat_map', 'suffix']","[None, None, None, None]","[None, None, 'None', 'None']",909,[],"['isinstance', 'pd.DataFrame', 'print', 'ddict.get', 'colname_new.append', 'enumerate']",6
utilmy/zutil_features.py:pd_colnum_tocat,pd_colnum_tocat,function,42,147,98,1134,7.71,2,6,"['df', 'colname', 'colexclude', 'colbinmap', 'bins', 'suffix', 'method', 'na_value', 'return_val', 'params={""KMeans_n_clusters""', '""KMeans_init""', '""KMeans_n_init""']","[None, None, None, None, None, None, None, None, None, '', "" 'k-means++'"", ' 10,""KMeans_max_iter"": 300, ""KMeans_tol"": 0.0001, ""KMeans_precompute_distances"": \'auto\',""KMeans_verbose"": 0, ""KMeans_random_state"": None,""KMeans_copy_x"": True, ""KMeans_n_jobs"": None, ""KMeans_algorithm"": \'auto\'}']","[None, 'None', 'None', 'None', '5', '""_bin""', '""uniform""', '-1', '""dataframe,param""', '{""KMeans_n_clusters"": 8', None, None]",948,"['    """"""\n', '    colbinmap = for each column, definition of bins\n', '    https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n', '       :param df:\n', '       :param method:\n', '       :return:\n', '    """"""\n']","['list', 'OrderedDict', 'bin_create', 'dfc.min', 'dfc.max', 'range', 'bin_create_quantile', 'np.arange', 'dfc.quantile', 'print', 'colbinmap.get', 'len', 'pd.cut', 'df.groupby', 'colnew.append']",15
utilmy/zutil_features.py:pd_colnum_normalize,pd_colnum_normalize,function,29,134,64,840,6.27,3,6,"['df0', 'colname', 'pars', 'suffix', 'return_val']","[None, None, None, None, None]","[None, None, None, '""_norm""', ""'dataframe,param'""]",1039,"['    """"""\n', '    :param df:\n', '    :param colnum_log:\n', '    :param colproba:\n', '    :return:\n', '    """"""\n']","['np.log', 'max', 'min', 'log', 'list']",5
utilmy/zutil_features.py:pd_col_merge_onehot,pd_col_merge_onehot,function,11,26,20,136,5.23,2,1,"['df', 'colname']","[None, None]","[None, None]",1085,"['    """"""\n', '      Merge columns into single (hotn\n', '    :param df:\n', '    :param colname:\n', '    :return :\n', '    """"""\n']","['t[len', 'len', 'merge_array.append']",3
utilmy/zutil_features.py:pd_col_to_num,pd_col_to_num,function,9,27,24,184,6.81,1,0,"['df', 'colname', 'default']","[None, None, None]","[None, 'None', 'np.nan']",1102,[],"['to_float', 'float', 'list']",3
utilmy/zutil_features.py:pd_col_filter,pd_col_filter,function,12,28,23,186,6.64,1,2,"['df', 'filter_val', 'iscol']","[None, None, None]","[None, 'None', '1']",1115,"['    """"""\n', '   # Remove Columns where Index Value is not in the filter_value\n', ""   # filter1= X_client['client_id'].values\n"", '   :param df:\n', '   :param filter_val:\n', '   :param iscol:\n', '   :return:\n', '   """"""\n']","['col_delete.append', 'df.drop']",2
utilmy/zutil_features.py:pd_col_fillna,pd_col_fillna,function,22,70,49,586,8.37,1,6,"['dfref', 'colname', 'method', 'value', 'colgroupby', 'return_val', '']","[None, None, None, None, None, None, None]","[None, 'None', '""frequent""', 'None', 'None', '""dataframe,param""', None]",1134,"['    """"""\n', '    Function to fill NaNs with a specific value in certain columns\n', '    Arguments:\n', '        df:            dataframe\n', '        colname:      list of columns to remove text\n', '        value:         value to replace NaNs with\n', '    Returns:\n', '        df:            new dataframe with filled values\n', '    """"""\n']","['list', 'df.groupby', 'print']",3
utilmy/zutil_features.py:pd_pipeline_apply,pd_pipeline_apply,function,8,29,22,259,8.93,1,0,"['df', 'pipeline']","[None, None]","[None, None]",1180,"['    """"""\n', '      pipe_preprocess_colnum = [\n', '      (pd_col_to_num, {""val"": ""?"", })\n', '    , (pd_colnum_tocat, {""colname"": None, ""colbinmap"": colnum_binmap, \'bins\': 5,\n', '                         ""method"": ""uniform"", ""suffix"": ""_bin"",\n', '                         ""return_val"": ""dataframe""})\n', '    , (pd_col_to_onehot, {""colname"": None, ""colonehot"": colnum_onehot,\n', '                          ""return_val"": ""dataframe""})\n', '      ]\n', '    :param df:\n', '    :param pipeline:\n', '    :return:\n', '    """"""\n']","['copy.deepcopy', 'enumerate', 'print', 'str']",4
utilmy/zutil_features.py:pd_stat_correl_pair,pd_stat_correl_pair,function,12,33,30,316,9.58,1,1,"['df', 'coltarget', 'colname']","[None, None, None]","[None, 'None', 'None']",1204,"['    """"""\n', '      Genearte correletion between the column and target column\n', '      df represents the dataframe comprising the column and colname comprising the target column\n', '    :param df:\n', '    :param colname: list of columns\n', '    :param coltarget : target column\n', '    :return:\n', '    """"""\n']","['list', 'target_corr.append', 'pd.DataFrame', 'len']",4
utilmy/zutil_features.py:pd_stat_pandas_profile,pd_stat_pandas_profile,function,7,9,8,175,19.44,0,0,"['df', 'savefile', 'title']","[None, None, None]","[None, '""report.html""', '""Pandas Profile""']",1225,"['    """""" Describe the tables\n', '        #Pandas-Profiling 2.0.0\n', '        df.profile_report()\n', '    """"""\n']","['print', 'df.profile_report', 'profile.to_file', 'profile.get_rejected_variables']",4
utilmy/zutil_features.py:pd_stat_distribution_colnum,pd_stat_distribution_colnum,function,23,84,72,646,7.69,1,3,"['df', 'nrows', 'verbose']","[None, None, None]","[None, '2000', 'False']",1238,"['    """""" Stats the tables\n', '    """"""\n']","['df.sample', 'getstat', 'str', 'len', 'pd.DataFrame', 'pd.concat', 'print', 'np.arange']",8
utilmy/zutil_features.py:pd_stat_histogram,pd_stat_histogram,function,8,19,18,210,11.05,0,0,"['df', 'bins', 'coltarget']","[None, None, None]","[None, '50', '""diff""']",1278,"['    """"""\n', '    :param df:\n', '    :param bins:\n', '    :param coltarget:\n', '    :return:\n', '    """"""\n']","['np.histogram', 'pd.DataFrame']",2
utilmy/zutil_features.py:col_extractname,col_extractname,function,7,37,23,207,5.59,1,5,['col_onehot'],[None],[None],1293,"['    """"""\n', '    Column extraction from onehot name\n', '    :param col_onehot\n', '    :return:\n', '    """"""\n']","['len', 'colnew.append']",2
utilmy/zutil_features.py:col_remove,col_remove,function,12,42,26,214,5.1,3,4,"['cols', 'colsremove', 'mode']","[None, None, None]","[None, None, '""exact""']",1316,"['    """"""\n', '    """"""\n']","['cols.remove', 'cols3.append']",2
utilmy/zutil_features.py:pd_colnum_tocat_stat,pd_colnum_tocat_stat,function,53,152,107,1986,13.07,1,5,"['df', 'feature', 'target_col', 'bins', 'cuts']","[None, None, None, None, None]","[None, None, None, None, '0']",1341,"['    """"""\n', '    Bins continuous features into equal sample size buckets and returns the target mean in each bucket. Separates out\n', '    nulls into another bucket.\n', '    :param df: dataframe containg features and target column\n', '    :param feature: feature column name\n', '    :param target_col: target column\n', '    :param bins: Number bins required\n', '    :param cuts: if buckets of certain specific cuts are required. Used on test data to use cuts from train.\n', '    :return: If cuts are passed only df_grouped data is returned, else cuts and df_grouped data is returned\n', '    """"""\n']","['pd.isnull', 'df.reset_index', 'min', 'range', 'np.percentile', 'cuts.append', 'pd.cut', 'df.groupby', 'df_grouped.reset_index', 'list', 'df_grouped.rename', 'str', 'len', 'pd.concat']",14
utilmy/zutil_features.py:pd_stat_shift_trend_changes,pd_stat_shift_trend_changes,function,20,41,35,660,16.1,0,0,"['df', 'feature', 'target_col', 'threshold']","[None, None, None, None]","[None, None, None, '0.03']",1410,"['    """"""\n', '    Calculates number of times the trend of feature wrt target changed direction.\n', '    :param df: df_grouped dataset\n', '    :param feature: feature column name\n', '    :param target_col: target column\n', '    :param threshold: minimum % difference required to count as trend change\n', '    :return: number of trend chagnes for the feature\n', '    """"""\n']","['target_diffs.fillna', 'target_diffs.divide', 'target_diffs_norm.diff', 'target_diffs_lvl2.fillna', 'int']",5
utilmy/zutil_features.py:pd_stat_shift_trend_correlation,pd_stat_shift_trend_correlation,function,19,63,55,788,12.51,0,2,"['df', 'df_test', 'colname', 'target_col']","[None, None, None, None]","[None, None, None, None]",1434,"['    """"""\n', '    Calculates correlation between train and test trend of colname wrt target.\n', '    :param df: train df data\n', '    :param df_test: test df data\n', '    :param colname: colname column name\n', '    :param target_col: target column name\n', '    :return: trend correlation between train and test\n', '    """"""\n']","['df.merge', 'pd.isnull', 'len', 'np.corrcoef', 'print']",5
utilmy/zutil_features.py:pd_stat_shift_changes,pd_stat_shift_changes,function,33,99,81,1236,12.48,1,4,"['df', 'target_col', 'features_list', 'bins', 'df_test']","[None, None, None, None, None]","[None, None, '0', '10', '0']",1465,"['    """"""\n', '    Calculates trend changes and correlation between train/test for list of features\n', '    :param df: dfframe containing features and target columns\n', '    :param target_col: target column name\n', '    :param features_list: by default creates plots for all features. If list passed, creates plots of only those features.\n', '    :param bins: number of bins to be created from continuous colname\n', '    :param df_test: test df which has to be compared with input df for correlation\n', '    :return: dfframe with trend changes and trend correlation (if test df passed)\n', '    """"""\n']","['type', 'list', 'features_list.remove', 'ignored.append', 'pd_colnum_tocat_stat', 'pd_stat_shift_trend_correlation', 'pd_stat_shift_changes', 'stats_all.append', 'pd.DataFrame', 'len', 'print', 'str']",12
utilmy/zutil_features.py:np_conv_to_one_col,np_conv_to_one_col,function,5,11,10,137,12.45,0,0,"['np_array', 'sep_char']","[None, None]","[None, '""_""']",1510,"['    """"""\n', '    converts string/numeric columns to one string column\n', '    :param np_array: the numpy array with more than one column\n', '    :param sep_char: the separator character\n', '    """"""\n']","['row2string', 'sep_char.join']",2
utilmy/zutil_features.py:dict2,dict2,class,3,5,5,36,7.2,0,0,[],[],[],28,[],[],0
utilmy/zutil_features.py:dict2:__init__,dict2:__init__,method,2,2,2,15,7.5,0,0,"['self', 'd']","[None, None]","[None, None]",29,[],[],0
utilmy/configs/util_config.py:log,log,function,2,5,4,54,10.8,0,0,['*s'],[None],[None],23,[],"['print', 'loge']",2
utilmy/configs/util_config.py:loge,loge,function,1,2,2,20,10.0,0,0,['*s'],[None],[None],27,[],['print'],1
utilmy/configs/util_config.py:config_load,config_load,function,31,124,88,1231,9.93,0,5,"['config_path', 'path_default', 'config_default', 'save_default', 'to_dataclass', '']","[' str ', ' str ', ' dict ', ' bool ', ' bool ', None]","[' None', ' None', ' None', ' False', ' True', None]",32,"['    """"""Load Config file into a dict\n', '    1) load config_path\n', '    2) If not, load in USER/.myconfig/.config.yaml\n', '    3) If not, create default save in USER/.myconfig/.config.yaml\n', '    Args:\n', ""        config_path:   path of config or 'default' tag value\n"", '        path_default : path of default config\n', '        config_default: dict value of default config\n', '        save_default: save default config on disk\n', '    Returns: dict config\n', '    """"""\n']","['log', 'pathlib.Path', 'yaml.safe_load', 'json.loads', 'SafeConfigParser', 'cfg.read', 'toml.loads', 'Exception', 'Box', 'os.makedirs', 'open', 'yaml.dump']",12
utilmy/configs/util_config.py:config_isvalid_yamlschema,config_isvalid_yamlschema,function,6,21,20,242,11.52,0,1,"['config_dict', 'schema_path', 'silent']","[' dict', ' str ', ' bool ']","[None, "" 'config_val.yaml'"", ' False']",105,"['    """"""Validate using a  yaml file\n', '    Args:\n', '        config_dict:\n', '        schema_path:\n', '        silent:\n', '    Returns: True/False\n', '    """"""\n']","['schema.validate', 'result.isValid', 'yamale.YamaleError', 'loge']",4
utilmy/configs/util_config.py:config_isvalid_pydantic,config_isvalid_pydantic,function,2,9,8,56,6.22,0,0,"['config_dict', 'pydanctic_schema', 'silent']","[' dict', ' str ', ' bool ']","[None, "" 'config_py.yaml'"", ' False']",129,"['    """"""Validate using a pydantic files\n', '    Args:\n', '        config_dict:\n', '        pydanctic_schema:\n', '        silent:\n', '    Returns: True/False\n', '    """"""\n']",[],0
utilmy/configs/util_config.py:convert_yaml_to_box,convert_yaml_to_box,function,6,8,8,57,7.12,0,0,['yaml_path'],[' str'],[None],147,[],"['open', 'yaml.load', 'Box']",3
utilmy/configs/util_config.py:convert_dict_to_pydantic,convert_dict_to_pydantic,function,10,13,13,253,19.46,0,0,"['config_dict', 'schema_name']","[' dict', ' str']","[None, None]",153,[],"['SchemaGen', 'generated.to_file', 'importlib.import_module', 'pydantic_module.MainSchema']",4
utilmy/configs/util_config.py:pydantic_model_generator,pydantic_model_generator,function,8,34,32,299,8.79,0,0,"['input_file', 'str]', 'input_file_type', 'output_file', '**kwargs', '']","[' Union[Path', None, None, ' Path', None, None]","[None, None, None, None, None, None]",166,"['    """"""\n', '    Args:\n', '        input_file:\n', '        input_file_type:\n', '        output_file:\n', '        **kwargs:\n', '\n', '    Returns:\n', '    # https://github.com/koxudaxi/datamodel-code-generator\n', '    # pip install datamodel-code-generator\n', '\n', '    """"""\n']","['generate', 'loge', 'log']",3
utilmy/configs/util_config.py:test_yamlschema,test_yamlschema,function,5,6,6,104,17.33,0,0,[],[],[],200,[],"['config_load', 'config_isvalid_yamlschema', 'log']",3
utilmy/configs/util_config.py:test_pydanticgenrator,test_pydanticgenrator,function,6,26,20,373,14.35,0,0,[],[],[],206,[],"['pydantic_model_generator', 'Path']",2
utilmy/configs/util_config.py:test4,test4,function,5,8,8,155,19.38,0,0,[],[],[],221,[],"['config_load', 'convert_dict_to_pydantic', 'isinstance']",3
utilmy/configs/util_config.py:test_example,test_example,function,1,2,2,6,3.0,0,0,[],[],[],227,[],[],0
utilmy/docs/code_parser.py:export_stats_pertype,export_stats_pertype,function,9,46,22,381,8.28,0,4,"['in_path', 'type', 'out_path']","['str', 'str', 'str']","['None', 'None', 'None']",55,"['    """"""\n', '        python code_parser.py type <in_path> <type> <out_path>\n', '    Returns:\n', '\n', '    """"""\n']","['get_list_function_stats', 'print', 'df.to_csv', 'get_list_class_stats', 'get_list_method_stats']",5
utilmy/docs/code_parser.py:export_stats_perfile,export_stats_perfile,function,8,36,16,336,9.33,0,3,"['in_path', 'out_path']","['str', 'str']","['None', 'None']",81,"['    """"""\n', '        python code_parser.py  export_stats_perfile <in_path> <out_path>\n', '\n', '    Returns:\n', '\n', '    """"""\n']","['get_list_function_stats', 'print', 'df.to_csv', 'get_list_class_stats', 'get_list_method_stats']",5
utilmy/docs/code_parser.py:export_stats_perrepo_txt,export_stats_perrepo_txt,function,1,4,4,59,14.75,0,0,"['in_path', 'out_path', 'repo_name']","['str', 'str', 'str']","['None', 'None', 'None']",105,"['    """"""\n', '        python code_parser.py  repo_txt   parser/test3    parser/output/output_repo.csv\n', '\n', '    Returns:\n', '        1  txt file\n', '    """"""\n']",['export_stats_perrepo'],1
utilmy/docs/code_parser.py:export_stats_perrepo,export_stats_perrepo,function,31,235,87,2231,9.49,5,15,"['in_path', 'out_path', 'repo_name']","['str', 'str', 'str']","['None', 'None', 'None']",115,[],"['export_stats_perrepo', 'glob.glob', 'range', 'get_list_function_stats', 'print', 'open', 'f.write', 'x.replace', 'df.to_csv', 'df.iterrows', 'zip', 'get_list_class_stats', 'get_list_method_stats']",13
utilmy/docs/code_parser.py:export_stats_repolink_txt,export_stats_repolink_txt,function,1,3,3,52,17.33,0,0,"['repo_link', 'out_path']","[' str', 'str']","[None, 'None']",202,"['    """"""\n', '        python code_parser.py repo_url_txt https://github.com/lucidrains/DALLE-pytorch.git docs/test_example1.csv\n', '\n', '    Returns:\n', '        1  txt   --->  data info detail\n', '    """"""\n']",['export_stats_repolink'],1
utilmy/docs/code_parser.py:export_stats_repolink,export_stats_repolink,function,9,39,35,479,12.28,0,2,"['repo_link', 'out_path']","[' str', 'str']","[None, 'None']",212,[],"['export_stats_repolink', 'repo_link.split', 'shutil.rmtree', 'print', 'os.system', 'export_stats_perrepo']",6
utilmy/docs/code_parser.py:export_call_graph_url,export_call_graph_url,function,6,17,16,219,12.88,0,1,"['repo_link', 'out_path']","[' str', 'str']","[None, 'None']",238,"['    """"""\n', '        python code_parser.py  export_call_graph_url <repo_link> <out_path>\n', '    Returns:\n', '        1  csv output\n', '    """"""\n']","['repo_link.split', 'print', 'os.system', 'export_call_graph']",4
utilmy/docs/code_parser.py:export_call_graph,export_call_graph,function,34,220,93,2216,10.07,9,8,"['repo_link', 'out_path']","[' str', 'str']","[None, 'None']",256,[],"['repo_link.split', 'print', 'os.system', 'export_call_graph', 'glob.glob', 'range', 'get_list_class_stats', 'zip', 'list_classes.append', 'get_list_function_stats', 'get_list_imported_func', 'get_list_import_class_as', 'open', 'f.write', 'write_to_file', 'get_list_method_stats']",16
utilmy/docs/code_parser.py:get_list_function_name,get_list_function_name,function,17,27,26,352,13.04,1,1,['file_path'],[None],[None],366,"['    """"""The function use to get all functions of the python file\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: list_functions   - List all python functions in the input file\n', '    Example Output:\n', ""        ['func1', 'func2']\n"", '    """"""\n']","['_get_all_line', '_get_and_clean_all_lines', 'list', 're.match', 'line.rstrip', 're_response.group', 'all_lines.index', 'list_functions.append']",8
utilmy/docs/code_parser.py:get_list_class_name,get_list_class_name,function,17,27,26,347,12.85,1,1,['file_path'],[None],[None],388,"['    """"""The function use to get all classes of the python file\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: list_classes     - List all python classes in the input file\n', '    Example Output:\n', ""        ['Class1', 'Class1']\n"", '    """"""\n']","['_get_all_line', '_get_and_clean_all_lines', 'list', 're.match', 'line.rstrip', 're_response.group', 'all_lines.index', 'list_classes.append']",8
utilmy/docs/code_parser.py:get_list_class_methods,get_list_class_methods,function,26,42,37,620,14.76,2,1,['file_path'],[None],[None],413,"['    """"""The function use to get all classes and all methods in this class of the python file\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: An array of class info [{dict}, {dict}, ...]\n', '    Example Output:\n', '    [\n', '        {""class_name"": ""Class1"", ""listMethods"": [""method1"", ""method2"", ""method3""]},\n', '        {""class_name"": ""Class2"", ""listMethods"": [""method4"", ""method5"", ""method6""]},\n', '    ]\n', '    """"""\n']","['_get_all_line', '_get_and_clean_all_lines', 'get_list_class_name', '_get_all_lines_in_class', 're.match', 'line.rstrip', 're_response.group', 'all_lines.index', 'list_names.append']",9
utilmy/docs/code_parser.py:get_list_variable_global,get_list_variable_global,function,12,26,24,357,13.73,1,2,['file_path'],[None],[None],445,"['    """"""The function use to get all global variable of the python file\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: list_var         - Array of all global variable\n', '    Example Output:\n', ""        ['Var1', 'Var2']\n"", '    """"""\n']","['_get_and_clean_all_lines', 're.match', 'line.rstrip', 'list_var.append', 'list']",5
utilmy/docs/code_parser.py:_get_docs,_get_docs,function,12,77,32,669,8.69,1,6,"['all_lines', 'index_1', 'func_lines']","[None, None, None]","[None, None, None]",467,[],"['line.strip', 'len', 'response.append']",3
utilmy/docs/code_parser.py:get_list_function_info,get_list_function_info,function,29,55,48,787,14.31,2,0,['file_path'],[None],[None],507,"['    """"""The function use to get functions stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Array of functions, lines of the function, and variable in function\n', '    Example Output:\n', '        [\n', '            {""name"": ""function_name1"", ""lines"": 20, ""variables"": [""a"", ""b"", ""c""]},\n', '            {""name"": ""function_name2"", ""lines"": 30, ""variables"": []},\n', '        ]\n', '    """"""\n']","['_get_all_line', '_get_and_clean_all_lines', 'get_list_function_name', '_get_all_lines_in_function', 'len', '_get_function_stats', '_get_docs', '_get_all_lines_define_function', '_get_define_function_stats', 'output.append']",10
utilmy/docs/code_parser.py:get_list_class_info,get_list_class_info,function,20,49,42,584,11.92,2,0,['file_path'],[None],[None],545,"['    """"""The class use to get functions stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Array of functions, lines of the function, and variable in function\n', '    Example Output:\n', '        [\n', '            {""function"": ""function_name1"", ""lines"": 20, ""variables"": [""a"", ""b"", ""c""]},\n', '            {""function"": ""function_name2"", ""lines"": 30, ""variables"": []},\n', '        ]\n', '    """"""\n']","['_get_and_clean_all_lines', 'get_list_class_name', '_get_all_lines_in_class', 'len', '_get_function_stats', 'output.append']",6
utilmy/docs/code_parser.py:get_list_method_info,get_list_method_info,function,35,65,54,966,14.86,3,0,['file_path'],[None],[None],581,"['    """"""get_list_method_info\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Array of methods in class\n', '    Example Output:\n', '        [\n', '            {""function"": ""function_name1"", ""lines"": 20, ""variables"": [""a"", ""b"", ""c""]},\n', '            {""function"": ""function_name2"", ""lines"": 30, ""variables"": []},\n', '        ]\n', '    """"""\n']","['_get_all_line', '_get_and_clean_all_lines', 'get_list_class_methods', '_get_all_lines_in_class', '_get_all_lines_in_function', 'len', '_get_function_stats', '_get_docs', '_get_all_lines_define_function', '_get_define_function_stats', 'output.append']",11
utilmy/docs/code_parser.py:get_list_method_stats,get_list_method_stats,function,6,12,11,148,12.33,0,1,['file_path'],[None],[None],623,"['    """"""The function use to get methods stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Dataframe with bellow fields\n', '            uri:   path1/path2/filename.py:function1\n', '            name: function1\n', '            n_lines\n', '            n_words\n', '            n_words_unqiue\n', '            n_characters\n', '            avg_char_per_word = n_charaecter / n_words\n', '            n_loop  : nb of for, while loop\n', '            n_ifthen  : nb of if_then\n', '        \n', '        **** return None if no function in file\n', '    Example Output:\n', '                                                    uri                                               name    type  n_variable  n_words  n_words_unique  n_characters  avg_char_per_word  n_loop  n_ifthen\n', '    0   d:/Project/job/test2/zz936/parser/test/keys.py...                              VerifyingKey:__init__  method           2       11              11           100           9.090909       0         1      \n', '    1   d:/Project/job/test2/zz936/parser/test/keys.py...                     VerifyingKey:from_public_point  method          10       13              12           185          14.230769       0         0      \n', '    2   d:/Project/job/test2/zz936/parser/test/keys.py...                           VerifyingKey:from_string  method          17       45              39           504          11.200000       0         1      \n', '    3   d:/Project/job/test2/zz936/parser/test/keys.py...                              VerifyingKey:from_pem  method           2        2               2            39          19.500000       0         0      \n', '    4   d:/Project/job/test2/zz936/parser/test/keys.py...                              VerifyingKey:from_der  method          19       64              38           683          10.671875       0         3      \n', '    5   d:/Project/job/test2/zz936/parser/test/keys.py...              VerifyingKey:from_public_key_recovery  method           4        8               8           137          17.125000       0         0      \n', '    6   d:/Project/job/test2/zz936/parser/test/keys.py...  VerifyingKey:from_public_key_recovery_with_digest  method          13       24              23           288          12.000000       0         0      \n', '    7   d:/Project/job/test2/zz936/parser/test/keys.py...                             VerifyingKey:to_string  method           6       11               8           145          13.181818       0         0      \n', '    8   d:/Project/job/test2/zz936/parser/test/keys.py...                                VerifyingKey:to_pem  method           2        4               4            42          10.500000       0         0  \n', '    """"""\n']","['get_list_method_info', 'get_stats']",2
utilmy/docs/code_parser.py:get_list_class_stats,get_list_class_stats,function,6,12,11,147,12.25,0,1,['file_path'],[None],[None],659,"['    """"""The class use to get functions stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Dataframe with bellow fields\n', '            uri:   path1/path2/filename.py:function1\n', '            name: function1\n', '            n_lines\n', '            n_words\n', '            n_words_unqiue\n', '            n_characters\n', '            avg_char_per_word = n_charaecter / n_words\n', '            n_loop  : nb of for, while loop\n', '            n_ifthen  : nb of if_then\n', '        \n', '        **** return None if no function in file\n', '    Example Output:\n', '                                                    uri               name   type  n_variable  n_words  n_words_unique  n_characters  avg_char_per_word  n_loop  n_ifthen\n', '    0  d:/Project/job/test2/zz936/parser/test/keys.py...  BadSignatureError  class           0        1               1             4           4.000000       0         0\n', '    1  d:/Project/job/test2/zz936/parser/test/keys.py...     BadDigestError  class           0        1               1             4           4.000000       0         0\n', '    2  d:/Project/job/test2/zz936/parser/test/keys.py...       VerifyingKey  class          84      301             189          3584          11.906977       0         7\n', '    3  d:/Project/job/test2/zz936/parser/test/keys.py...         SigningKey  class         138      482             310          4615           9.574689       3         9\n', '    """"""\n']","['get_list_class_info', 'get_stats']",2
utilmy/docs/code_parser.py:get_list_function_stats,get_list_function_stats,function,6,12,11,150,12.5,0,1,['file_path'],[None],[None],690,"['    """"""The function use to get functions stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Dataframe with bellow fields\n', '            uri:   path1/path2/filename.py:function1\n', '            name: function1\n', '            n_lines\n', '            n_words\n', '            n_words_unqiue\n', '            n_characters\n', '            avg_char_per_word = n_charaecter / n_words\n', '            n_loop  : nb of for, while loop\n', '            n_ifthen  : nb of if_then\n', '        \n', '        **** return None if no function in file\n', '    Example Output:\n', '            uri                                 name  n_variable  n_words  n_words_unique  n_characters  avg_char_per_word  n_loop  n_ifthen\n', '        0   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...     prepare_target_and_clean_up_test           8       92              32           535           5.815217       0         0\n', '        1   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...                 clean_up_config_test           6       55              19           241           4.381818       0         1\n', '        2   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...         check_default_network_config          22      388              74           955           2.461340       1         5\n', '        3   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...                     check_module_env           9      250              54           553           2.212000       1         1\n', '        4   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...     provision_certificates_to_target           7      101              29           384           3.801980       0         3\n', '        5   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...            config_session_connection           2       14               8            97           6.928571       0         0\n', '        6   d:\\Project\\job\\test2\\zz936\\parser/test/test2.p...  config_cipher_suite_and_tcps_action           8      101              30           335           3.316832       0         3\n', '    """"""\n']","['get_list_function_info', 'get_stats']",2
utilmy/docs/code_parser.py:get_stats,get_stats,function,19,84,52,808,9.62,0,0,"['df', 'file_path']","['pd.DataFrame', 'str']","[None, None]",726,"['    """""" Calculate stats from datafaframe\n', '    Args:\n', '        df: pandas DataFrame\n', '\n', '    Returns:\n', '        pandas DataFrame\n', '\n', '    """"""\n']","['len', 'df.apply', '_get_words', '_get_avg_char_per_word', '_get_functions']",5
utilmy/docs/code_parser.py:get_file_stats,get_file_stats,function,11,21,19,244,11.62,1,0,['file_path'],[None],[None],759,"['    """"""The function use to get file stars\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: Dict of file stars\n', '    Example Output:\n', '        {\n', '            ""total_functions"": 22,\n', '            ""avg_lines"" : 110.2,\n', '            ""total_class"": 3\n', '        }\n', '    """"""\n']","['get_list_function_stats', 'len', 'avg_lines/len']",3
utilmy/docs/code_parser.py:get_list_imported_func,get_list_imported_func,function,13,44,30,467,10.61,2,3,['file_path'],[' str'],[None],782,"['    """"""Get list funtions was imported in python file.\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: List function\n', '    Example Output:\n', '        [\n', ""            {'func1': 'zc.Class'},\n"", ""            {'func2': 'Hola'}\n"", '        ]\n', '    """"""\n']","['dict', '_get_and_clean_all_lines', 're.search', 'line.rstrip', 'line.split', 'functions.split']",6
utilmy/docs/code_parser.py:get_list_import_class_as,get_list_import_class_as,function,18,41,37,463,11.29,1,1,['file_path'],[' str'],[None],816,"['    """"""Get list funtions was imported in python file.\n', '    Args:\n', '        IN: file_path         - the file path input\n', '        OUT: List function\n', '    Example Output:\n', '        [\n', ""            {'class': 'zc.Class'},\n"", ""            {'class': 'Hola'}\n"", '        ]\n', '    """"""\n']","['dict', '_get_and_clean_all_lines', 're.match', 'line.rstrip', 'print', 'line.split', 'importlib.import_module']",7
utilmy/docs/code_parser.py:_get_words,_get_words,function,6,23,21,154,6.7,1,1,['row'],[None],[None],853,[],[],0
utilmy/docs/code_parser.py:_get_functions,_get_functions,function,10,32,26,389,12.16,1,2,['row'],[None],[None],863,[],"['re.match', 'list_funcs.append', 'list', 'return']",4
utilmy/docs/code_parser.py:_get_avg_char_per_word,_get_avg_char_per_word,function,1,9,9,76,8.44,0,0,['row'],[None],[None],883,[],[],0
utilmy/docs/code_parser.py:_validate_file,_validate_file,function,5,34,18,227,6.68,0,3,['file_path'],[None],[None],887,"['    """"""Check if the file is existed and it\'s a python file\n', '    """"""\n']",['print'],1
utilmy/docs/code_parser.py:_clean_data,_clean_data,function,10,75,27,699,9.32,3,9,['array'],[None],[None],902,"['    """"""Remove empty lines and comment lines start with #\n', '    """"""\n']","['array.copy', '_remove_empty_line', '_remmove_commemt_line', 'response.remove', 'response.copy', 'line.strip', 'len']",7
utilmy/docs/code_parser.py:_remove_empty_line,_remove_empty_line,function,2,7,7,37,5.29,0,1,['line'],[None],[None],945,[],['line.strip'],1
utilmy/docs/code_parser.py:_remmove_commemt_line,_remmove_commemt_line,function,2,17,14,97,5.71,0,1,['line'],[None],[None],949,[],['line.strip'],1
utilmy/docs/code_parser.py:_get_and_clean_all_lines,_get_and_clean_all_lines,function,5,11,8,124,11.27,0,1,['file_path'],[None],[None],955,"['    """"""Prepare all lines of the file\n', '    """"""\n']","['_validate_file', '_get_all_line', '_clean_data']",3
utilmy/docs/code_parser.py:_get_all_line,_get_all_line,function,33,247,85,2442,9.89,7,17,['file_path'],[None],[None],965,[],"['open', '_get_all_lines_in_function', 'array.copy', 're.match', 'line.rstrip', 'response.remove', 'len', 'range', 'list', 'list_lines.append', '_get_all_lines_in_class', '_get_all_lines_define_function']",12
utilmy/docs/code_parser.py:_get_all_lines_in_function,_get_all_lines_in_function,function,21,87,52,810,9.31,3,7,"['function_name', 'array', 'indentMethod']","[None, None, None]","[None, None, ""''""]",971,"['    """"""The function use to get all lines of the function\n', '    Args:\n', '        IN: function_name - name of the function will be used to get all line\n', '        IN: array         - list all lines of the file have this input function\n', '        OUT: list_lines   - Array of all line of this function\n', '        OUT: indent       - The indent of this function (this will be used for another calculation)\n', '    """"""\n']","['array.copy', 're.match', 'line.rstrip', 'response.remove', 'len', 'range', 'list', 'list_lines.append']",8
utilmy/docs/code_parser.py:_get_all_lines_in_class,_get_all_lines_in_class,function,16,71,46,670,9.44,2,4,"['class_name', 'array']","[None, None]","[None, None]",1023,"['    """"""The function use to get all lines of the class\n', '    Args:\n', '        IN: class_name    - name of the class will be used to get all line\n', '        IN: array         - list all lines of the file have this input class\n', '        OUT: list_lines   - Array of all line of this class\n', '    """"""\n']","['array.copy', 're.match', 'line.rstrip', 'response.remove', 'len', 'list', 'list_lines.append']",7
utilmy/docs/code_parser.py:_get_all_lines_define_function,_get_all_lines_define_function,function,20,71,46,687,9.68,2,6,"['function_name', 'array', 'indentMethod']","[None, None, None]","[None, None, ""''""]",1065,"['    """"""The function use to get all lines define_function\n', '    Args:\n', '        IN: function_name - name of the function will be used to get all line\n', '        IN: array         - list all lines of the file have this input function\n', '        OUT: list_lines   - Array of all line used to define the function\n', '        OUT: indent       - The indent of this function (this will be used for another calculation)\n', '    """"""\n']","['list', 'array.copy', 're.match', 'line.rstrip', 'response.remove', 'len', 'list_lines.append', 'range']",8
utilmy/docs/code_parser.py:_get_define_function_stats,_get_define_function_stats,function,24,145,71,1337,9.22,4,8,['array'],[None],[None],1109,"['    """"""The function use to get define function stats: arg_name, arg_type, arg_value\n', '    Args:\n', '        IN: array         - list all lines of function to get variables\n', '        OUT: function stats: arg_name, arg_type, arg_value\n', '    """"""\n']","['len', 'line.strip', 'print', 'i.start', 're.finditer', 'range', 'data.split', 'arg.replace', 'arg.strip', 'arg.find', 'arg_name.append', 'arg_type.append', 'arg_value.append']",13
utilmy/docs/code_parser.py:_get_function_stats,_get_function_stats,function,16,206,105,1958,9.5,4,11,"['array', 'indent']","[None, None]","[None, None]",1170,"['    """"""The function use to get all lines of the function\n', '    Args:\n', '        IN: indent        - indent string\n', '        IN: array         - list all lines of function to get variables\n', '        OUT: list_var     - Array of all variables\n', '    """"""\n']","['array.copy', 'check_array.copy', 'line.rstrip', 'check_array.remove', 'line.split', 're.match', 'list_var.append', 'list']",8
utilmy/docs/code_parser.py:write_to_file,write_to_file,function,25,163,71,1808,11.09,1,8,"['uri', 'type', 'list_functions', 'list_classes', 'list_imported', 'dict_functions', 'list_class_as', 'out_path']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",1259,[],"['importlib.import_module', 'function.split', 'print', 'open', 'f.write']",5
utilmy/docs/code_parser.py:test_example,test_example,function,3,7,7,233,33.29,0,0,[],[],[],1338,[],"['export_stats_pertype', 'export_stats_perfile', 'export_stats_perrepo']",3
utilmy/docs/generate_doc.py:markdown_create_function,markdown_create_function,function,21,81,65,768,9.48,2,0,"['uri', 'name', 'type', 'args_name', 'args_type', 'args_value', 'start_line', 'list_docs', 'prefix']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, '""""']",22,[],"['uri.split', 'literal_eval', 'zip', 'rsp.format']",4
utilmy/docs/generate_doc.py:markdown_create_file,markdown_create_file,function,1,2,2,7,3.5,0,0,"['list_info', 'prefix']","[None, None]","[None, ""''""]",58,[],[],0
utilmy/docs/test.py:log,log,function,3,10,9,81,8.1,0,0,['data'],[None],[None],20,[],"['open', 'f.write', 'str']",3
utilmy/docs/test.py:list_buy_price,list_buy_price,function,8,32,28,256,8.0,1,1,"['start', 'bottom', 'delta']","[None, None, None]","[None, None, None]",27,[],"['while', 'list_output.insert', 'round', 'log', 'list']",5
utilmy/docs/test.py:calculateSellPrice,calculateSellPrice,function,2,3,3,40,13.33,0,0,"['enter', 'profit']","[None, None]","[None, None]",42,[],['round'],1
utilmy/docs/test.py:list_sell_price,list_sell_price,function,8,32,28,248,7.75,1,1,"['start', 'top', 'delta']","[None, None, None]","[None, None, None]",46,[],"['while', 'list_output.insert', 'round', 'log', 'list']",5
utilmy/docs/test.py:calculateBuyPrice,calculateBuyPrice,function,2,3,3,40,13.33,0,0,"['enter', 'profit']","[None, None]","[None, None]",61,[],['round'],1
utilmy/docs/test.py:get_list_price,get_list_price,function,19,151,84,1833,12.14,4,9,[],[],[],69,[],"['list_buy_price', 'str', 'print', 'gInfoTradingUp[str', 'calculateSellPrice', 'len', 'float', 'list_sell_price', 'gInfoTradingDown[str', 'calculateBuyPrice', 'threading.Timer', 't.start']",12
utilmy/docs/test.py:trading_up,trading_up,function,28,178,97,2240,12.58,1,11,[],[],[],144,[],"['exchange.fetch_orders', 'print', 'exchange.create_order', 'log', 'str', 'threading.Timer', 't.start']",7
utilmy/docs/test.py:trading_down,trading_down,function,28,175,95,2315,13.23,1,11,[],[],[],218,[],"['exchange.fetch_orders', 'print', 'exchange.create_order', 'log', 'str', 'threading.Timer', 't.start']",7
utilmy/docs/test.py:update_price,update_price,function,5,8,8,89,11.12,0,0,[],[],[],289,[],"['threading.Timer', 't.start']",2
utilmy/logs/test_log.py:test1,test1,function,17,28,28,206,7.36,0,0,[],[],[],9,[],"['log3', 'log2', 'log', 'logw', 'logc', 'logr', 'loge']",7
utilmy/logs/test_log.py:test2,test2,function,19,35,34,331,9.46,0,0,[],[],[],28,[],"['print', 'util_log.logger_setup', 'log3', 'log2', 'log', 'logw', 'logc', 'logr', 'loge']",9
utilmy/logs/test_log.py:test_launch_server,test_launch_server,function,12,16,16,155,9.69,0,0,[],[],[],81,"[""\t'''\n"", '\tServer code from loguru.readthedocs.io\n', '\tUse to test network logging\n', '\n', '     python   test.py test_launch_server\n', '\n', '\n', ""\t'''\n""]",['socketserver.TCPServer'],1
utilmy/logs/test_log.py:test_server,test_server,function,19,35,34,337,9.63,0,0,[],[],[],95,[],"['print', 'util_log.logger_setup', 'log3', 'log2', 'log', 'logw', 'logc', 'logr', 'loge']",9
utilmy/logs/test_log.py:LoggingStreamHandler,LoggingStreamHandler,class,13,34,28,381,11.21,2,1,[],[],[],65,[],[],0
utilmy/logs/test_log.py:LoggingStreamHandler:handle,LoggingStreamHandler:handle,method,12,32,26,364,11.38,2,1,['self'],[None],[None],66,[],"['len', 'struct.unpack', 'pickle.loads', 'json.loads', 'logger.patch', 'record.update']",6
utilmy/logs/util_log.py:logger_setup,logger_setup,function,33,105,82,1013,9.65,2,3,"['log_config_path', 'log_template', '**kwargs']","[' str ', ' str ', None]","[' None', ' ""default""', None]",34,"['    """""" Generic Logging setup\n', '      Overide logging using loguru setup\n', '      1) Custom config from log_config_path .yaml file\n', '      2) Use shortname log, log2, logw, loge for logging output\n', '\n', '    Args:\n', '        log_config_path:\n', '        template_name:\n', '        **kwargs:\n', '    Returns:None\n', '\n', '    TODO:\n', '\n', '\n', '    """"""\n']","['open', 'yaml.safe_load', 'print', 'cfg.pop', 'globals_.pop', 'int', 'SocketHandler', 'handler.get', 'handler.items', 'handler.update', 'logger.configure', 'logger.level']",12
utilmy/logs/util_log.py:log,log,function,33,105,82,1013,9.65,2,3,"['log_config_path', 'log_template', '**kwargs']","[' str ', ' str ', None]","[' None', ' ""default""', None]",115,[],"['open', 'yaml.safe_load', 'print', 'cfg.pop', 'globals_.pop', 'int', 'SocketHandler', 'handler.get', 'handler.items', 'handler.update', 'logger.configure', 'logger.level']",12
utilmy/logs/util_log.py:log2,log2,function,1,6,6,62,10.33,0,0,['*s'],[None],[None],119,[],['logger.opt'],1
utilmy/logs/util_log.py:log3,log3,function,1,6,6,64,10.67,0,0,['*s)'],['  ### Debuggine level 2depth'],"['1, lazy=True).log(""DEBUG_2"", "","".join([str(t) for t in s]))*s):']",123,[],['logger.opt'],1
utilmy/logs/util_log.py:logw,logw,function,1,6,6,64,10.67,0,0,['*s'],[None],[None],128,[],['logger.opt'],1
utilmy/logs/util_log.py:logc,logc,function,1,6,6,65,10.83,0,0,['*s'],[None],[None],132,[],['logger.opt'],1
utilmy/logs/util_log.py:loge,loge,function,1,6,6,66,11.0,0,0,['*s'],[None],[None],136,[],['logger.opt'],1
utilmy/logs/util_log.py:logr,logr,function,1,6,6,62,10.33,0,0,['*s'],[None],[None],140,[],['logger.opt'],1
utilmy/logs/util_log.py:test,test,function,8,18,18,151,8.39,0,0,[],[],[],145,[],"['log3', 'log2', 'log', 'logw', 'loge', 'logc', 'logr']",7
utilmy/logs/util_log.py:z_logger_stdout_override,z_logger_stdout_override,function,18,36,33,384,10.67,1,0,[],[],[],162,"['    """""" Redirect stdout --> logger\n', '    Returns:\n', '    """"""\n']","['__init__', 'write', 'buffer.rstrip', 'logger.opt', 'line.rstrip', 'flush', 'logger.remove', 'logger.add', 'StreamToLogger', 'contextlib.redirect_stdout', 'print']",11
utilmy/logs/util_log.py:z_logger_custom_1,z_logger_custom_1,function,38,110,92,1250,11.36,2,1,[],[],[],187,[],"['InterceptHandler', 'emit', 'logger.level', 'str', 'logging.currentframe', 'logger.opt', 'record.getMessage', 'format_record', 'pformat', 'setup_logging', 'logging.getLogger', 'logger.configure']",12
utilmy/templates/cli.py:run_cli,run_cli,function,9,30,23,332,11.07,0,2,[],[],[],5,"['    """""" USage\n', '    \n', '    template  copy  --repo_dir utilmy/\n', '    """"""\n']","['argparse.ArgumentParser', 'add', 'p.parse_args', 'template_show', 'template_copy']",5
utilmy/templates/cli.py:template_show,template_show,function,7,9,9,115,12.78,0,0,[],[],[],26,[],"['os.walk', 'print']",2
utilmy/templates/cli.py:template_copy,template_copy,function,12,26,22,249,9.58,0,0,"['name', 'out_dir']","[None, None]","[None, None]",33,[],"['os_copy', 'print', 'Path']",3
utilmy/viz/embedding.py:log,log,function,1,2,2,23,11.5,0,0,['*s'],[None],[None],38,[],['print'],1
utilmy/viz/toptoolbar.py:TopToolbar,TopToolbar,class,35,67,55,571,8.52,0,2,[],[],[],4,[],[],0
utilmy/viz/vizhtml.py:log,log,function,1,2,2,20,10.0,0,0,['*s'],[None],[None],23,[],['print'],1
utilmy/viz/vizhtml.py:test_getdata,test_getdata,function,14,38,34,669,17.61,1,1,['verbose'],[None],['True'],29,"['    """"""\n', '    data = test_get_data()\n', ""    df   = data['housing.csv']\n"", '    df.head(3)\n', '    https://github.com/szrlee/Stock-Time-Series-Analysis/tree/master/data\n', '    """"""\n']","['url.split', 'print', 'pd.read_csv']",3
utilmy/viz/vizhtml.py:test1,test1,function,60,279,175,3299,11.82,0,5,[],[],[],57,[],"['htmlDoc', 'vi.test2', 'pretty_html_table.build_table', 'random.randint', 'html_code.replace', 'pd_plot_tseries_matplot', 'mpld3.fig_to_html', 'pd_plot_tseries_highcharts', 'plot_histogram', 'pd_plot_histogram_matplot', 'self.fig_to_html', 'pd_plot_histogram_highcharts', 'plot_scatter', 'pd_plot_scatter_matplot', 'pd_plot_scatter_highcharts', 'images_dir', 'images_to_html', 'pd_plot_network']",18
utilmy/viz/vizhtml.py:pd_plot_tseries_highcharts,pd_plot_tseries_highcharts,function,33,204,125,1718,8.42,2,1,"['df', 'coldate', 'date_format', 'cols_axe1', 'cols_axe2', 'figsize', 'title', 'x_label', 'axe1_label', 'axe2_label', 'cfg', 'mode', 'save_img']","[None, 'str', 'str', 'list ', 'list ', 'tuple ', 'str', 'str', 'str', 'str', 'dict', None, None]","[None, 'None', ""'%m/%d/%Y'"", '[]', '[]', '  None', 'None', 'None', 'None', 'None', '{}', ""'d3'"", '""""']",919,"[""    '''\n"", '        function to return highchart json cord for time_series.\n', '        input parameter\n', '        df : panda dataframe on which you want to apply time_series\n', '        cols_axe1: column name for y-axis one\n', '        cols_axe2: column name for y-axis second\n', '        x_label : label of x-axis\n', '        cols_axe1_label : label for yaxis 1\n', '        cols_axe2_label : label for yaxis 2\n', '        date_format : %m for moth , %d for day and %Y for Year.\n', ""    '''\n""]","['Box', 'cc.get', 'str', 'pd.to_datetime', 'Highchart', 'H.set_dict_options', 'float', 'range', 'H.add_data_set', 'H.buildcontent']",10
utilmy/viz/vizhtml.py:pd_plot_histogram_highcharts,pd_plot_histogram_highcharts,function,25,128,97,1201,9.38,0,0,"['df', 'colname', 'binsNumber', 'binWidth', 'title', 'xaxis_label', 'yaxis_label', 'cfg', 'mode', 'save_img', 'show']","['pd.DataFrame', 'str', None, None, 'str', 'str', 'str', 'dict', None, None, None]","[None, 'None', 'None', 'None', '""""', ' ""x-axis""', '""y-axis""', '{}', ""'d3'"", '""""', 'False']",1014,"[""    ''' function to return highchart json code for histogram.\n"", '        input parameter\n', '        df : panda dataframe on which you want to apply histogram\n', '        colname : column name from dataframe in which histogram will apply\n', '        xaxis_label: label for x-axis\n', '        yaxis_label: label for y-axis\n', '        binsNumber: Number of bin in bistogram.\n', '        binWidth : width of each bin in histogram\n', '        title : title of histogram\n', '        cols_axe2_label : label for yaxis 2\n', '        date_format : %m for moth , %d for day and %Y for Year.\n', '\n', ""        df        = data['housing.csv']\n"", '        html_code = pd_plot_histogram_hcharts(df,colname=""median_income"",xaxis_label= ""x-axis"",yaxis_label=""y-axis"",cfg={}, mode=\'d3\', save_img=False)\n', '        # highcharts_show_chart(html_code)\n', ""    '''\n""]","['Box', 'cc.get', 'str']",3
utilmy/viz/vizhtml.py:html_show_chart_highchart,html_show_chart_highchart,function,14,19,17,194,10.21,0,1,"['html_code', 'verbose']","[None, None]","[None, 'True']",1108,[],"['Highchart', 'hc.buildhtmlheader', 'print', 'display']",4
utilmy/viz/vizhtml.py:html_show,html_show,function,15,28,21,300,10.71,0,1,"['html_code', 'verbose']","[None, None]","[None, 'True']",1121,[],"['Highchart', 'hc.buildhtmlheader', 'print', 'display', 'html_show']",5
utilmy/viz/vizhtml.py:images_to_html,images_to_html,function,22,43,36,343,7.98,1,1,"['dir_input', 'title', 'verbose']","[None, None, None]","['""*.png""', '""""', 'False']",1131,"['    """"""\n', '        images_to_html( model_path + ""/graph_shop_17_past/*.png"" , model_path + ""shop_17.html"" )\n', '    """"""\n']","['glob.glob', 'flist.sorted', 'print', 'open', 'fp2.read', 'base64.b64encode']",6
utilmy/viz/vizhtml.py:pd_plot_network,pd_plot_network,function,50,136,104,1484,10.91,3,4,"['df', 'cola', 'colb', 'coledge', 'colweight', 'html_code']","['pd.DataFrame', ' str', ' str', ' str', ' str', 'bool ']","[None, ""'col_node1'"", ""'col_node2'"", ""'col_edge'"", '""weight""', ' True']",1156,"['    """"""\n', '        https://pyviz.org/tools.html\n', '    """"""\n']","['convert_to_networkx', 'nx.Graph', 'df.iterrows', 'g.add_edge', 'nx.draw', 'draw_graph', 'net.Network', 'networkx_graph.nodes', 'pyvis_graph.add_node', 'networkx_graph.edges', 'pyvis_graph.add_edge', 'str', 'pyvis_graph.show_buttons', 'pyvis_graph.show', 'extract_text', 're.findall', 'open', 'f.read']",18
utilmy/viz/vizhtml.py:help_get_codesource,help_get_codesource,function,7,15,14,177,11.8,0,0,['func'],[None],[None],1320,"['    """""" Using the magic method __doc__, we KNOW the size of the docstring.\n', '        We then, just substract this from the total length of the function\n', '    """"""\n']","['len', 'inspect.getsourcelines']",2
utilmy/viz/vizhtml.py:zz_css_get_template,zz_css_get_template,function,39,117,93,983,8.4,0,0,['css_name'],['str'],"[' ""A4_size""']",1350,[],"['rgba', 'rgb', 'Box', 'cc.get']",4
utilmy/viz/zvizhtml2.py:log,log,function,1,2,2,20,10.0,0,0,['*s'],[None],[None],21,[],['print'],1
utilmy/viz/zvizhtml2.py:test_getdata,test_getdata,function,14,38,34,669,17.61,1,1,['verbose'],[None],['True'],27,"['    """"""\n', '    data = test_get_data()\n', ""    df   = data['housing.csv']\n"", '    df.head(3)\n', '\n', '    https://github.com/szrlee/Stock-Time-Series-Analysis/tree/master/data\n', '    """"""\n']","['url.split', 'print', 'pd.read_csv']",3
utilmy/viz/zvizhtml2.py:test1,test1,function,57,244,157,2843,11.65,0,5,[],[],[],56,[],"['htmlDoc', 'vi.test2', 'pretty_html_table.build_table', 'random.randint', 'html_code.replace', 'pd_plot_tseries_matplot', 'mpld3.fig_to_html', 'pd_plot_tseries_highcharts', 'plot_histogram', 'pd_plot_histogram_matplot', 'self.fig_to_html', 'pd_plot_histogram_highcharts', 'plot_scatter', 'pd_plot_scatter_matplot', 'pd_plot_scatter_highcharts']",15
utilmy/viz/zvizhtml2.py:pd_plot_tseries_highcharts,pd_plot_tseries_highcharts,function,33,204,125,1714,8.4,2,1,"['df', 'coldate', 'date_format', 'cols_axe1', 'cols_axe2', 'figsize', 'title', 'x_label', 'axe1_label', 'axe2_label', 'cfg', 'mode', 'save_img']","[None, 'str', None, None, None, None, None, None, None, None, 'dict', None, None]","[None, 'None', ""'%m/%d/%Y'"", '[]', '[]', 'None', 'None', 'None', 'None', 'None', '{}', ""'d3'"", '""""']",864,"[""    '''\n"", '        function to return highchart json cord for time_series.\n', '        input parameter\n', '        df : panda dataframe on which you want to apply time_series\n', '        cols_axe1: column name for y-axis one\n', '        cols_axe2: column name for y-axis second\n', '        x_label : label of x-axis\n', '        cols_axe1_label : label for yaxis 1\n', '        cols_axe2_label : label for yaxis 2\n', '        date_format : %m for moth , %d for day and %Y for Year.\n', ""    '''\n""]","['Box', 'cc.get', 'str', 'pd.to_datetime', 'Highchart', 'H.set_dict_options', 'float', 'range', 'H.add_data_set', 'H.buildcontent']",10
utilmy/viz/zvizhtml2.py:pd_plot_histogram_highcharts,pd_plot_histogram_highcharts,function,25,128,97,1201,9.38,0,0,"['df', 'colname', 'binsNumber', 'binWidth', 'title', 'xaxis_label', 'yaxis_label', 'cfg', 'mode', 'save_img', 'show']","['pd.DataFrame', ' str', None, None, ' str', ' str', ' str', 'dict', None, None, None]","[None, 'None', 'None', 'None', '""""', ' ""x-axis""', '""y-axis""', '{}', ""'d3'"", '""""', 'False']",960,"[""    ''' function to return highchart json code for histogram.\n"", '\n', ""        df        = data['housing.csv']\n"", '        html_code = pd_plot_histogram_hcharts(df,colname=""median_income"",xaxis_label= ""x-axis"",yaxis_label=""y-axis"",cfg={}, mode=\'d3\', save_img=False)\n', '        # highcharts_show_chart(html_code)\n', '\n', '        input parameter\n', '        df : panda dataframe on which you want to apply histogram\n', '        colname : column name from dataframe in which histogram will apply\n', '        xaxis_label: label for x-axis\n', '        yaxis_label: label for y-axis\n', '        binsNumber: Number of bin in bistogram.\n', '        binWidth : width of each bin in histogram\n', '        title : title of histogram\n', '        cols_axe2_label : label for yaxis 2\n', '        date_format : %m for moth , %d for day and %Y for Year.\n', ""    '''\n""]","['Box', 'cc.get', 'str']",3
utilmy/viz/zvizhtml2.py:html_show_chart_highchart,html_show_chart_highchart,function,14,19,17,194,10.21,0,1,"['html_code', 'verbose']","[None, None]","[None, 'True']",1055,[],"['Highchart', 'hc.buildhtmlheader', 'print', 'display']",4
utilmy/viz/zvizhtml2.py:html_show,html_show,function,15,28,21,300,10.71,0,1,"['html_code', 'verbose']","[None, None]","[None, 'True']",1068,[],"['Highchart', 'hc.buildhtmlheader', 'print', 'display', 'html_show']",5
utilmy/viz/zvizhtml2.py:images_to_html,images_to_html,function,22,43,36,343,7.98,1,1,"['dir_input', 'title', 'verbose']","[None, None, None]","['""*.png""', '""""', 'False']",1078,"['    """"""\n', '        images_to_html( model_path + ""/graph_shop_17_past/*.png"" , model_path + ""shop_17.html"" )\n', '    """"""\n']","['glob.glob', 'flist.sorted', 'print', 'open', 'fp2.read', 'base64.b64encode']",6
utilmy/viz/zvizhtml2.py:pd_plot_network,pd_plot_network,function,49,134,103,1475,11.01,3,4,"['df', 'cola', 'colb', 'coledge', 'colweight', 'html_code']","['pd.DataFrame', ' str', ' str', ' str', ' str', 'bool ']","[None, ""'col_node1'"", ""'col_node2'"", ""'col_edge'"", '""weight""', ' True']",1103,"['    """"""\n', '        https://pyviz.org/tools.html\n', '    """"""\n']","['convert_to_networkx', 'nx.Graph', 'df.iterrows', 'g.add_edge', 'nx.draw', 'draw_graph', 'net.Network', 'networkx_graph.nodes', 'pyvis_graph.add_node', 'networkx_graph.edges', 'pyvis_graph.add_edge', 'str', 'pyvis_graph.show_buttons', 'pyvis_graph.show', 'extract_text', 're.findall', 'open', 'f.read']",18
utilmy/viz/zvizhtml2.py:help,help,function,35,128,101,1009,7.88,2,1,[],[],[],1248,[],"['pd_plot_tseries_highcharts', 'highcharts_show_chart', 'vi.test_getdata', 'vi.htmlDoc', 'doc.h1', 'doc.hr', 'doc.br', 'doc.h2', 'range', 'len', 'doc.plot_tseries', 'doc.table', 'doc.save', 'doc.open_browser', 'Box', 'cc.get']",16
utilmy/zarchive/allmodule.py:pprint,pprint,function,10,32,23,378,11.81,0,1,"['table1', 'tablefmt']","[None, None]","[None, '""simple""']",34,"[' """"""To print nice column headers, supply the second argument (`headers`):\n', '      - `headers` can be an explicit list of column headers\n', '      - if `headers=""firstrow""`, then the first row of data is used\n', '      - if `headers=""keys""`, then dictionary keys or column indices are used\n', '    print(tabulate([[1, 2.34], [-56, ""8.999""], [""2"", ""10001""]]))\n', '  """"""\n']","['isinstance', 'tabulate', 'pprint2', 'pprint.PrettyPrinter', 'pp.pprint']",5
utilmy/zarchive/allmodule.py:pprint2,pprint2,function,5,5,5,59,11.8,0,0,['x'],[None],[None],51,"[""  '''import pprint\n"", ""     stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']\n"", 'stuff.insert(0, stuff[:])\n', 'pp = pprint.PrettyPrinter(indent=4)\n', 'pp.pprint(ALLDB)\n', ""  '''\n""]","['pprint.PrettyPrinter', 'pp.pprint']",2
utilmy/zarchive/allmodule.py:str_convert_beforeprint,str_convert_beforeprint,function,2,2,2,23,11.5,0,0,['x'],[None],[None],64,"[""  ''' #Before writing/output to printer put in utf-8 '''\n""]",['x.encode'],1
utilmy/zarchive/allmodule.py:str_to_utf8,str_to_utf8,function,2,2,2,23,11.5,0,0,['x'],[None],[None],69,"[""  ''' #Before writing/output to printer put in utf-8 '''\n""]",['x.encode'],1
utilmy/zarchive/allmodule.py:str_to_unicode,str_to_unicode,function,4,16,12,98,6.12,0,2,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",74,"[""  ''' #After Loading Text from CSV ---> Immediately in unicode '''\n""]","['isinstance', 'unicode']",2
utilmy/zarchive/coke_functions.py:date_diffsecond,date_diffsecond,function,4,8,7,71,8.88,0,0,"['str_t1', 'str_t0', ""fmt='YYYY-MM-DD HH""]","[None, None, '']","[None, None, ""'YYYY-MM-DD HH:mm:SS'""]",8,[],"['arrow.get', 'dd.total_seconds']",2
utilmy/zarchive/coke_functions.py:date_diffstart,date_diffstart,function,4,9,8,31,3.44,1,0,"['t) ', 'str_t0=t0)t) ', 'str_t0=t)dd) ']","[' return date_diffsecond(str_t1', '', '']","['t', 't0)t) :   return date_diffsecond(str_t1=t1', 't)dd) :']",13,[],['dd.items'],1
utilmy/zarchive/coke_functions.py:date_diffend,date_diffend,function,4,9,8,31,3.44,1,0,"['t) ', 'str_t0=t)dd) ']","['   return date_diffsecond(str_t1', '']","['t1', 't)dd) :']",14,[],['dd.items'],1
utilmy/zarchive/coke_functions.py:np_dict_tolist,np_dict_tolist,function,4,9,8,31,3.44,1,0,['dd'],[None],[None],17,[],['dd.items'],1
utilmy/zarchive/coke_functions.py:np_dict_tostr_val,np_dict_tostr_val,function,1,9,9,46,5.11,0,0,['dd'],[None],[None],20,[],"['str', 'dd.items']",2
utilmy/zarchive/coke_functions.py:np_dict_tostr_key,np_dict_tostr_key,function,1,8,8,46,5.75,0,0,['dd'],[None],[None],23,[],"['str', 'dd.items']",2
utilmy/zarchive/coke_functions.py:day,day,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['    return int(s[8:10])s):  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",31,[],['arrow.get'],1
utilmy/zarchive/coke_functions.py:month,month,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",32,[],['arrow.get'],1
utilmy/zarchive/coke_functions.py:year,year,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",33,[],['arrow.get'],1
utilmy/zarchive/coke_functions.py:hour,hour,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",34,[],['arrow.get'],1
utilmy/zarchive/coke_functions.py:weekday,weekday,function,9,16,15,117,7.31,0,0,"['s', 'fmt', 'i0', 'i1']","[None, None, None, None]","[None, ""'YYYY-MM-DD'"", '0', '10']",38,[],['arrow.get'],1
utilmy/zarchive/coke_functions.py:season,season,function,4,15,13,47,3.13,0,1,['d'],[None],[None],48,[],['int'],1
utilmy/zarchive/coke_functions.py:daytime,daytime,function,7,42,23,123,2.93,0,1,['d'],[None],[None],53,[],['int'],1
utilmy/zarchive/coke_functions.py:pd_date_splitall,pd_date_splitall,function,11,22,17,255,11.59,0,0,"['df', 'coldate']","[None, None]","[None, ""'purchased_at'""]",62,[],['copy.deepcopy'],1
utilmy/zarchive/datanalysis.py:pd_filter_column,pd_filter_column,function,12,25,22,218,8.72,1,2,"['df_client_product', 'filter_val', 'iscol']","[None, None, None]","[None, '[]', '1']",73,"[""   '''\n"", '   # Remove Columns where Index Value is not in the filter_value\n', ""   # filter1= X_client['client_id'].values\n"", '   :param df_client_product:\n', '   :param filter_val:\n', '   :param iscol:\n', '   :return:\n', ""   '''\n""]",['col_delete1.append'],1
utilmy/zarchive/datanalysis.py:pd_missing_show,pd_missing_show,function,0,1,1,4,4.0,0,0,[],[],[],90,[],[],0
utilmy/zarchive/datanalysis.py:pd_describe,pd_describe,function,22,86,65,578,6.72,1,2,['df'],[None],[None],119,"[""   ''' Describe the tables\n"", '        \n', '       \n', ""   '''\n""]","['getstat', 'list', 'str', 'len', 'pd.Series', 'pd.DataFrame', 'pd.concat']",7
utilmy/zarchive/datanalysis.py:pd_stack_dflist,pd_stack_dflist,function,8,29,24,157,5.41,1,1,['df_list'],[None],[None],158,[],"['enumerate', 'df0.append', 'print']",3
utilmy/zarchive/datanalysis.py:pd_validation_struct,pd_validation_struct,function,0,1,1,4,4.0,0,0,[],[],[],168,[],[],0
utilmy/zarchive/datanalysis.py:pd_checkpoint,pd_checkpoint,function,0,1,1,4,4.0,0,0,[],[],[],178,[],[],0
utilmy/zarchive/datanalysis.py:xl_setstyle,xl_setstyle,function,34,82,50,743,9.06,2,0,['file1'],[None],[None],237,"["" '''\n"", '   http://openpyxl.readthedocs.io/en/default/styles.html#cell-styles-and-named-styles\n', '  import openpyxl.styles.builtins  as bi\n', '  import openpyxl.styles.builtins\n', '\n', ""  col = ws.column_dimensions['A']\n"", '  col.font = Font(bold=True)\n', '\n', ""  for cell in ws['A'] + ws[1]:\n"", ""    cell.style = 'data01'\n"", '\n', '  bd = Side(style=\'thick\', color=""000000"")\n', '  highlight.border = BORDER_NONE\n', '  from openpyxl.styles import\n', "" '''\n""]","['load_workbook', 'print', 'named_styles.NamedStyle', 'Font', 'wb.get_sheet_names', 'wb.get_sheet_by_name', 'range', 'wb.save']",8
utilmy/zarchive/datanalysis.py:xl_val,xl_val,function,7,14,13,108,7.71,0,0,"['ws', 'colj', 'rowi']","[None, None, None]","[None, None, None]",282,[],"['ws[gcol', 'str']",2
utilmy/zarchive/datanalysis.py:isnull,isnull,function,4,6,6,20,3.33,0,0,['x'],[None],[None],289,[],[],0
utilmy/zarchive/datanalysis.py:xl_get_rowcol,xl_get_rowcol,function,8,44,37,220,5.0,1,1,"['ws', 'i0', 'j0', 'imax', 'jmax']","[None, None, None, None, None]","[None, None, None, None, None]",292,[],"['range', 'isnull', 'rmat.append']",3
utilmy/zarchive/datanalysis.py:xl_getschema,xl_getschema,function,71,250,174,1902,7.61,4,8,"['dirxl', 'filepattern', 'dirlevel', 'outfile']","[None, None, None, None]","['""""', ""'*.xlsx'"", '1', ""'.xlsx'""]",302,"["" '''Take All excel in a folder and provide Table, Column Schema, type into master file\n"", "" '''\n""]","['xl_is_data_block_start', 'isnull', 'xl_find_start_block', 'range', '_xl_getschema', 'util.os_file_getname', 'load_workbook', 'print', 'wb.get_sheet_names', 'wb.get_sheet_by_name', 'gcol', 'str', 'np.array', 'np.column_stack', 'df_list.append', 'pd_stack_dflist', 'util.os_file_listall', 'enumerate', 'df0.append', 'util.pd_toexcel']",20
utilmy/zarchive/datanalysis.py:str_to_unicode,str_to_unicode,function,4,13,11,63,4.85,0,1,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",381,[],"['isinstance', 'str']",2
utilmy/zarchive/datanalysis.py:csv_dtypes_getdict,csv_dtypes_getdict,function,6,20,16,122,6.1,0,1,"['df', 'csvfile']","[None, None]","['None', 'None']",389,[],['pd.read_csv'],1
utilmy/zarchive/datanalysis.py:csv_fast_processing,csv_fast_processing,function,0,0,0,0,0.0,0,0,[],[],[],396,"[""   '''\n"", '   http://word.bitly.com/post/74069870671/optimizing-text-processing\n', '\n', 'import sys\n', 'from collections import defaultdict\n', 'OUT_FILES = defaultdict(dict)\n', '\n', 'open_outfiles()  # open all files I could possibly need\n', '\n', 'for line in sys.stdin:\n', '    # 1. parse line for account_id and metric_type\n', ""    key = line.split(',')\n"", '    account_id = key[ACCOUNT_ID_INDEX][1:] # strip leading quote\n', '\n', '    # 2. write to appropriate file for account_id and metric_type\n', '    OUT_FILES[account_id][key[METRIC_TYPE_INDEX]].write(line)\n', '\n', '   close_outfiles()  # close all the files we opened\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/datanalysis.py:csv_col_schema_toexcel,csv_col_schema_toexcel,function,87,291,205,2615,8.99,3,8,"['dircsv', 'filepattern', 'outfile', 'returntable', 'maxrow', 'maxcol_pertable', 'maxstrlen']","[None, None, None, None, None, None, None]","['""""', ""'*.csv'"", ""'.xlsx'"", '1', '5000000', '90', ""'U80'""]",418,"["" '''Take All csv in a folder and provide Table, Column Schema, type\n"", ' str(df[col].dtype)  USE str always, otherwise BIG Issue\n', '\n', 'METHOD FOR Unicode / ASCII issue\n', ""1. Decode early:  Decode to <type 'unicode'> ASAP\n"", ""    df['PREF_NAME']=       df['PREF_NAME'].apply(to_unicode)\n"", '2. Unicode everywhere\n', ""3. Encode late :f = open('/tmp/ivan_out.txt','w')\n"", ""                f.write(ivan_uni.encode('utf-8'))\n"", "" '''\n""]","['util.os_file_listall', 'len', 'np.array', 'enumerate', 'print', 'pd.read_csv', 'str', 'util.pd_toexcel', 'df.apply', 'np.zeros', 'range', 'float', 'gc.collect', 'pd.DataFrame', 'util.save', 'outfile.replace']",16
utilmy/zarchive/datanalysis.py:csv_col_get_dict_categoryfreq,csv_col_get_dict_categoryfreq,function,39,80,64,553,6.91,4,4,"['dircsv', 'filepattern', 'category_cols', 'maxline', 'fileencoding']","[None, None, None, None, None]","[None, '""*.csv""', '[]', '-1', '""utf-8""']",510,"[""  ''' Find Category Freq in large CSV Transaction Column   '''\n""]","['datetime.now', 'defaultdict', 'util.os_file_listall', 'enumerate', 'line.split', 'print']",6
utilmy/zarchive/datanalysis.py:csv_row_reduce_line,csv_row_reduce_line,function,22,80,63,477,5.96,1,5,"['fromfile', 'tofile', 'condfilter', 'catval_tokeep', 'header', 'maxline']","[None, None, None, None, None, None]","[None, None, None, None, 'True', '-1']",536,"[""  ''' Reduce Data Row by filtering on some Category\n"", '    file_category=  in1+ ""offers.csv""\n', '    ncol= 8\n', '    catval_tokeep=[ {} for i in xrange(0, ncol)]\n', '    for i, line in enumerate(open(file_category)):\n', '      ll=  line.split("","")\n', '      catval_tokeep[3][  ll[1] ]  = 1  # Offer_file_col1 --> Transact_file_col_4\n', '      catval_tokeep[4][  ll[3] ] =  1  # Offer_file_col3 --> Transact_file_col_4\n', '\n', '  def condfilter(colk, catval_tokeep) :\n', '    if colk[3] in catval_tokeep[3] or colk[4] in catval_tokeep[4]: return True\n', '    else: return False\n', ""  '''\n""]","['datetime.now', 'open', 'next', 'outfile.write', 'enumerate', 'line.split', 'condfilter', 'print']",8
utilmy/zarchive/datanalysis.py:csv_analysis,csv_analysis,function,0,0,0,0,0.0,0,0,[],[],[],576,"[""   '''\n"", '   https://csvkit.readthedocs.io/en/540/tutorial/1_getting_started.html\n', '\n', '   sudo pip install csvkit\n', '\n', '   :return:\n', ""   '''\n""]",[],0
utilmy/zarchive/datanalysis.py:csv_row_reduce_line_manual,csv_row_reduce_line_manual,function,25,77,54,499,6.48,2,4,"['file_category', 'file_transact', 'file_reduced']","[None, None, None]","[None, None, None]",587,"[""  ''' Reduce Data by filtering on some Category '''\n""]","['datetime.now', 'enumerate', 'line.split', 'open', 'outfile.write', 'print']",6
utilmy/zarchive/datanalysis.py:csv_row_mapreduce,csv_row_mapreduce,function,17,29,26,282,9.72,2,0,"['dircsv', 'outfile', 'type_mapreduce', 'nrow', 'chunk']","[None, None, None, None, None]","['""""', '""""', ""'sum'"", '1000000', ' 5000000']",617,"["" '''Take All csv in a folder and provide Table, Column Schema'''\n""]","['util.os_file_listall', 'int', 'pd.DataFrame', 'enumerate', 'range', 'pd.read_csv']",6
utilmy/zarchive/datanalysis.py:csv_pivotable,csv_pivotable,function,13,57,38,576,10.11,1,4,"['dircsv', 'filepattern', 'fileh5', 'leftX', 'topY', 'centerZ', 'mapreduce', 'chunksize', 'tablename']","[None, None, None, None, None, None, None, None, None]","['""""', ""'*.csv'"", ""'.h5'"", ""'col0'"", ""'col2'"", ""'coli'"", ""'sum'"", ' 500000', ""'df'""]",634,"["" ''' return df Pivot Table from series of csv file (transfer to d5 temporary)\n"", '\n', 'Edit: you can groupby/sum from the store iteratively since this ""map-reduces"" over the chunks:\n', '\n', 'reduce(lambda x, y: x.add(y, fill_value=0),\n', ""       (df.groupby().sum() for df in store.select('df', chunksize=50000)))\n"", '\n', "" '''\n""]","['util.pd_h5_fromcsv_tohdfs', 'pd.HDFStore', 'store.select', 'pd.concat']",4
utilmy/zarchive/datanalysis.py:csv_bigcompute,csv_bigcompute,function,0,1,1,4,4.0,0,0,[],[],[],664,[],[],0
utilmy/zarchive/datanalysis.py:db_getdata,db_getdata,function,0,1,1,4,4.0,0,0,[],[],[],671,[],[],0
utilmy/zarchive/datanalysis.py:db_sql,db_sql,function,0,1,1,4,4.0,0,0,[],[],[],674,[],[],0
utilmy/zarchive/datanalysis.py:db_meta_add,db_meta_add,function,26,85,61,761,8.95,1,4,"['metadb', 'dbname', 'new_table', '[]']","[None, None, None, None]","[None, None, ""(''"", None]",677,"[""   ''' Create Meta database to store infos on the tables : csv, zip, HFS, Postgres\n"", ""ALL_DB['japancoupon']= {}\n"", ""ALL_DB['japancoupon']['schema']=    df_schema\n"", ""ALL_DB['japancoupon']['df_table_uri']= df_schema_dictionnary\n"", ""ALL_DB['japancoupon']['df_table_columns']= df_schema_dict\n"", '        DBname, db_schema, db_table_uri, db_table_columns(dict_table->colum_list),\n', ""   '''\n""]","['pd_df_todict', 'df.drop_duplicates', 'range', 'dict0.setdefault']",4
utilmy/zarchive/datanalysis.py:db_meta_find,db_meta_find,function,22,86,67,617,7.17,3,4,"['ALLDB', 'query', 'filter_db', 'filter_table', 'filter_column']","[None, None, None, None, None]","[None, ""''"", '[]', '[]', '[]']",714,"[""  ''' Find string in all the meta table name, column\n"", ""  db_meta_find(ALLDB, query='bottler', filter_db=['cokeon'],   filter_table=['table'], filter_column=['table'] )\n"", '  dbname: should be exact name\n', '  fitler_table: partial match is ok\n', '  fitler_column : partial name is ok\n', '  return   (dbname, meta_table_name,  meta_table_filtered_by_row_containing query)\n', ""  '''\n""]","['list', 'len', 'isinstance', 'util.str_match_fuzzy', 'util.find_fuzzy', 'util.pd_find', 'rs.append']",7
utilmy/zarchive/datanalysis.py:col_study_getcategorydict_freq,col_study_getcategorydict_freq,function,16,26,25,408,15.69,1,0,['catedict'],[None],[None],745,"[""  ''' Generate Frequency of category : Id, Freq, Freqin%, CumSum%, ZScore\n"", '      given a dictionnary of category parsed previously\n', ""  '''\n""]","['list', 'util.pd_array_todataframe', 'df.sort_values', 'np.arange', 'catlist.append']",5
utilmy/zarchive/datanalysis.py:col_feature_importance,col_feature_importance,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",760,"[""   ''' random forest for column importance '''\n""]",[],0
utilmy/zarchive/datanalysis.py:pd_col_study_distribution_show,pd_col_study_distribution_show,function,22,96,71,1000,10.42,3,3,"['df', 'col_include', 'col_exclude', ""pars={'binsize'""]","[None, None, None, '']","[None, 'None', 'None', ""{'binsize':20}""]",764,"["" '''  Perfom Full Study of the pandas columns'''\n""]","['np.count_nonzero', 'sorted', 'print', 'len', 'np.max', 'np.min', 'np.median', 'np.mean', 'np.std', 'plot_Y', 'plt.title', 'plt.plot', 'plt.hist', 'plt.show', 'plt.figure', 'np.percentile', 'list']",17
utilmy/zarchive/datanalysis.py:col_study_summary,col_study_summary,function,18,57,53,606,10.63,1,3,"['Xmat', '0.0]', 'Xcolname', ""'col2']"", 'Xcolselect', '9]', 'isprint']","[None, None, None, None, None, None, None]","['[0.0', None, ""['col1'"", None, '[9', None, '0']",794,[],"['np.arange', 'len', 'print', 'np.min', 'np.max', 'np.median', 'np.mean', 'np.std', 'colanalysis.append', 'pd.DataFrame', 'np.shape']",11
utilmy/zarchive/datanalysis.py:pd_col_pair_plot,pd_col_pair_plot,function,14,34,32,261,7.68,1,1,"['dfX', 'Xcolname_selectlist', 'dfY', 'Ycolname']","[None, None, None, None]","[None, 'None', 'None', 'None']",811,[],"['str', 'plt.scatter', 'plt.autoscale', 'plt.title', 'plt.show']",5
utilmy/zarchive/datanalysis.py:col_pair_correl,col_pair_correl,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",825,[],[],0
utilmy/zarchive/datanalysis.py:col_pair_interaction,col_pair_interaction,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",828,"[""   ''' random forest for pairwise interaction '''\n""]",[],0
utilmy/zarchive/datanalysis.py:plot_col_pair,plot_col_pair,function,1,4,4,69,17.25,0,0,"['dfX', 'Xcolname_selectlist', 'dfY', 'Ycolname']","[None, None, None, None]","[None, 'None', 'None', 'None']",832,[],['pd_col_pair_plot'],1
utilmy/zarchive/datanalysis.py:tf_transform_catlabel_toint,tf_transform_catlabel_toint,function,13,18,18,218,12.11,1,0,['Xmat'],[None],[None],838,"[""   '''\n"", '     # [""paris"", ""paris"", ""tokyo"", ""amsterdam""]  --> 2 ,5,6\n', '     # np.array(le.inverse_transform([2, 2, 1]))\n', '     le = preprocessing.LabelEncoder()\n', '     le.fit([""paris"", ""paris"", ""tokyo"", ""amsterdam""])\n', 'LabelEncoder()\n', 'list(le.classes_)\n', ""['amsterdam', 'paris', 'tokyo']\n"", 'le.transform([""tokyo"", ""tokyo"", ""paris""])\n', 'array([2, 2, 1]...)\n', 'list(le.inverse_transform([2, 2, 1]))\n', ""['tokyo', 'tokyo', 'paris']\n"", ""   '''\n""]","['range', 'le.get_params']",2
utilmy/zarchive/datanalysis.py:tf_transform_pca,tf_transform_pca,function,3,4,4,78,19.5,0,0,"['Xmat', 'dimpca', 'whiten']","[None, None, None]","[None, '2', 'True']",863,"[""   '''Project ndim data into dimpca sub-space  '''\n""]","['pca=PCA', 'pca.transform']",2
utilmy/zarchive/datanalysis.py:plot_distance_heatmap,plot_distance_heatmap,function,19,30,29,363,12.1,0,0,"['Xmat_dist', 'Xcolname']","[None, None]","[None, None]",872,[],"['pd.DataFrame', 'plt.figure', 'fig.add_subplot', 'ax.imshow', 'pyplot.get_cmap', 'ax.set_xlabel', 'ax.set_ylabel', 'ax.set_title', 'plt.colorbar']",9
utilmy/zarchive/datanalysis.py:plot_cluster_2D,plot_cluster_2D,function,10,20,20,237,11.85,1,0,"['X_2dim', 'target_class', 'target_names']","[None, None, None]","[None, None, None]",888,"[""   ''' Plot 2d of Clustering Class,\n"", '       X2d: Nbsample x 2 dim  (projection on 2D sub-space)\n', ""   '''\n""]","['target_ids=range', 'len', 'pl.figure', 'zip', 'pl.scatter', 'pl.legend', 'pl.show']",7
utilmy/zarchive/datanalysis.py:plot_cluster_tsne,plot_cluster_tsne,function,23,53,46,590,11.13,0,3,"['Xmat', 'Xcluster_label', 'metric', 'perplexity', 'ncomponent', 'savefile', 'isprecompute', 'returnval']","[None, None, None, None, None, None, None, None]","[None, 'None', ""'euclidean'"", '50', '2', ""''"", 'False', 'True']",901,"["" '''Plot High dimemnsionnal State using TSNE method\n"", ""   'euclidean, 'minkowski', 'cityblock', 'seuclidean', 'sqeuclidean, 'cosine, 'correlation, 'hamming, 'jaccard, 'chebyshev,\n"", ""   'canberra, 'braycurtis, 'mahalanobis', VI=None) 'yule, 'matching, 'dice, 'kulsinski, 'rogerstanimoto, 'russellrao, 'sokalmichener, 'sokalsneath,\n"", '\n', '   Xtsne= da.plot_cluster_tsne(Xtrain_dist, Xcluster_label=None, perplexity=40, ncomponent=2, isprecompute=True)\n', '\n', '   Xtrain_dist= sci.spatial.distance.squareform(sci.spatial.distance.pdist(Xtrain_d,\n', ""               metric='cityblock', p=2, w=None, V=None, VI=None))\n"", ""   '''\n""]","['np.set_printoptions', 'model.fit_transform', 'np.arange', 'plot_XY']",4
utilmy/zarchive/datanalysis.py:plot_cluster_pca,plot_cluster_pca,function,22,51,44,480,9.41,0,3,"['Xmat', 'Xcluster_label', 'metric', 'dimpca', 'whiten', 'isprecompute', 'savefile', 'doreturn']","[None, None, None, None, None, None, None, None]","[None, 'None', ""'euclidean'"", '2', 'True', 'False', ""''"", '1']",930,[],"['PCA', 'model.fit_transform', 'np.zeros', 'plot_XY']",4
utilmy/zarchive/datanalysis.py:plot_cluster_hiearchy,plot_cluster_hiearchy,function,30,87,78,957,11.0,1,3,"['Xmat_dist', 'p', 'truncate_mode', 'color_threshold', 'get_leaves', 'orientation', 'labels', 'count_sort', 'distance_sort', 'show_leaf_counts', 'do_plot', 'no_labels', 'leaf_font_size', 'leaf_rotation', 'leaf_label_func', 'show_contracted', 'link_color_func', 'ax', 'above_threshold_color', 'annotate_above']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]","[None, '30', 'None', 'None', 'True', ""'top'"", 'None', 'False', 'False', 'True', '1', 'False', 'None', 'None', 'None', 'False', 'None', 'None', ""'b'"", '0']",948,[],"['dendrogram', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'zip', 'sum', 'plt.plot', 'plt.annotate', 'plt.axhline']",9
utilmy/zarchive/datanalysis.py:plot_distribution_density,plot_distribution_density,function,28,58,52,631,10.88,0,0,"['Xsample', 'kernel', 'N', 'bandwith']","[None, None, None, None]","[None, ""'gaussian'"", '10', '1 / 10.0']",978,[],"['plt.subplots', 'len', 'np.min', 'np.max', 'np.linspace', 'np.ones_like', 'np.ones', 'ax.hist', 'kde.score_samples', 'np.log', 'ax.plot', 'np.exp', 'ax.set_xlim', 'plt.show']",14
utilmy/zarchive/datanalysis.py:plot_Y,plot_Y,function,4,7,7,88,12.57,0,0,"['Yval', 'typeplot', 'tsize', 'labels', 'title', 'xlabel', 'ylabel', 'zcolor_label', 'figsize', '6']","[None, None, None, None, None, None, None, None, None, None]","[None, ""'.b'"", 'None', 'None', ""''"", ""''"", ""''"", ""''"", '(8', None]",1021,[],"['plt.figure', 'plt.title', 'plt.plot', 'plt.show']",4
utilmy/zarchive/datanalysis.py:plot_XY,plot_XY,function,72,197,147,1805,9.16,0,7,"['xx', 'yy', 'zcolor', 'tsize', 'labels', 'title', 'xlabel', 'ylabel', 'zcolor_label', 'figsize', '6']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', ""''"", ""''"", ""''"", ""''"", '(8', None]",1028,"[""  '''\n"", '      labels= numpy array, ---> Generate HTML File with the labels interactives\n', '      Color: Plasma\n', ""  '''\n""]","['isinstance', 'np.array', 'np.abs', 'plt.get_cmap', 'np.min', 'plt.subplots', 'fig.set_size_inches', 'fig.set_dpi', 'fig.tight_layout', 'ax1.scatter', 'ax1.set_xlabel', 'ax1.set_ylabel', 'ax1.set_title', 'ax1.grid', 'np.max', 'scatter.set_clim', 'fig.colorbar', 'cb.set_label', 'list', 'mpld3.save_html', 'plt.show', 'util.os_folder_create', 'plt.savefig', 'plot_XY_plotly', 'go.Scatter', 'py.iplot', 'py.plot', 'plot_XY_seaborn', 'sns.set_context', 'sns.set_color_codes', 'sns.color_palette', 'np.unique', 'plt.scatter', 'plt.gca', 'plt.title']",35
utilmy/zarchive/datanalysis.py:plot_XY_plotly,plot_XY_plotly,function,15,31,26,261,8.42,0,1,"['xx', 'yy', 'towhere']","[None, None, None]","[None, None, ""'url'""]",1095,"[""  ''' Create Interactive Plotly   '''\n""]","['go.Scatter', 'py.iplot', 'py.plot']",3
utilmy/zarchive/datanalysis.py:plot_XY_seaborn,plot_XY_seaborn,function,14,44,42,400,9.09,0,1,"['X', 'Y', 'Zcolor']","[None, None, None]","[None, None, 'None']",1118,[],"['sns.set_context', 'sns.set_color_codes', 'sns.color_palette', 'np.unique', 'plt.scatter', 'plt.gca', 'plt.title']",7
utilmy/zarchive/datanalysis.py:optim_is_pareto_efficient,optim_is_pareto_efficient,function,15,35,31,304,8.69,1,2,"['Xmat_cost', 'epsilon', 'ret_boolean']","[None, None, None]","[None, ' 0.01', '1']",1160,"['    """""" Calculate Pareto Frontier of Multi-criteria Optimization program\n', '    c1, c2  has to be minimized : -Sharpe, -Perf, +Drawdown\n', '    :param Xmat_cost: An (n_points, k_costs) array\n', '    :return: A (n_points, ) boolean array, indicating whether each point is Pareto efficient\n', '    """"""\n']","['np.ones', 'enumerate', 'np.any']",3
utilmy/zarchive/datanalysis.py:sk_catboost_classifier,sk_catboost_classifier,function,22,54,51,581,10.76,0,2,"['Xtrain', 'Ytrain', 'Xcolname', 'pars= {""learning_rate""', '""iterations""', '""random_seed""', '""loss_function""', 'isprint']","[None, None, None, '', '1000', '0', ' ""MultiClass"" }', None]","[None, None, 'None', ' {""learning_rate"":0.1', None, None, None, '0']",1245,"[""  '''\n"", '  from catboost import Pool, CatBoostClassifier\n', '\n', ""TRAIN_FILE = '../data/cloudness_small/train_small'\n"", ""TEST_FILE = '../data/cloudness_small/test_small'\n"", ""CD_FILE = '../data/cloudness_small/train.cd'\n"", '# Load data from files to Pool\n', 'train_pool = Pool(TRAIN_FILE, column_description=CD_FILE)\n', 'test_pool = Pool(TEST_FILE, column_description=CD_FILE)\n', '# Initialize CatBoostClassifier\n', ""model = CatBoostClassifier(iterations=2, learning_rate=1, depth=2, loss_function='MultiClass')\n"", '# Fit model\n', 'model.fit(train_pool)\n', '# Get predicted classes\n', 'preds_class = model.predict(test_pool)\n', '# Get predicted probabilities for each class\n', 'preds_proba = model.predict_proba(test_pool)\n', '# Get predicted RawFormulaVal\n', ""  preds_raw = model.predict(test_pool, prediction_type='RawFormulaVal')  \n"", '  \n', '  \n', '  https://tech.yandex.com/catboost/doc/dg/concepts/python-usages-examples-docpage/\n', '  \n', ""  '''\n""]","['dict2', 'str', 'range', 'pd.DataFrame', 'catboost.CatBoostClassifier', 'clf.fit', 'clf.predict', 'cm.astype', 'cm.sum', 'print']",10
utilmy/zarchive/datanalysis.py:sk_catboost_regressor,sk_catboost_regressor,function,0,1,1,4,4.0,0,0,[],[],[],1291,[],[],0
utilmy/zarchive/datanalysis.py:sk_model_auto_tpot,sk_model_auto_tpot,function,21,41,36,562,13.71,0,1,"['Xmat', 'y', 'outfolder', 'model_type', 'train_size', 'generation', 'population_size', 'verbosity']","[None, None, None, None, None, None, None, None]","[None, None, ""'aaserialize/'"", ""'regressor/classifier'"", '0.5', '1', '5', '2']",1308,"[""  ''' Automatic training of Xmat--->Y, Generate SKlearn code in outfile\n"", '      Very Slow Process, use lower number of Sample\n', '  :param Xmat:\n', '  :param y:\n', '  :param outfolder:\n', '  :param model_type:\n', '  :param train_size:\n', '  :param generation: \n', '  :param population_size:\n', '  :param verbosity:\n', '  :return:\n', ""  '''\n""]","['train_test_split', 'TPOTRegressor', 'TPOTClassifier', 'tpot.fit', 'print', 'str', 'tpot.export']",7
utilmy/zarchive/datanalysis.py:sk_params_search_best,sk_params_search_best,function,30,61,50,840,13.77,0,3,"['Xmat', 'Ytarget', 'model1', ""param_grid={'alpha'"", '1', '5) }', 'method', ""param_search= {'scoretype'"", ""'cv'"", ""'population_size'"", ""'generations_number'""]","[None, None, None, '', None, None, None, '', '5', '5', '3 }']","[None, None, None, ""{'alpha':  np.linspace(0"", None, None, ""'gridsearch'"", "" {'scoretype':'r2'"", None, None, None]",1336,"[""  '''\n"", '   genetic: population_size=5, ngene_mutation_prob=0.10,,gene_crossover_prob=0.5, tournament_size=3,  generations_number=3\n', '\n', '  :param Xmat:\n', '  :param Ytarget:\n', '  :param model1:\n', '  :param param_grid:\n', '  :param method:\n', '  :param param_search:\n', '  :return:\n', ""  '''\n""]","['make_scorer', 'GridSearchCV', 'grid.fit', 'EvolutionaryAlgorithmSearchCV', 'cv=StratifiedKFold', 'cv.fit']",6
utilmy/zarchive/datanalysis.py:sk_distribution_kernel_bestbandwidth,sk_distribution_kernel_bestbandwidth,function,8,17,17,176,10.35,0,0,['kde'],[None],[None],1403,"["" '''Find best Bandwidht for a  given kernel\n"", '  :param kde:\n', '  :return:\n', "" '''\n""]","['GridSearchCV', 'np.linspace', 'grid.fit']",3
utilmy/zarchive/datanalysis.py:sk_distribution_kernel_sample,sk_distribution_kernel_sample,function,15,31,29,211,6.81,1,0,"['kde', 'n']","[None, None]","['None', '1']",1414,"["" ''' \n"", '  kde = sm.nonparametric.KDEUnivariate(np.array(Y[Y_cluster==0],dtype=np.float64))\n', '  kde = sm.nonparametric.KDEMultivariate()  # ... you already did this\n', "" '''\n""]","['np.zeros', 'func', 'kde.cdf', 'range', 'brentq']",5
utilmy/zarchive/datanalysis.py:sk_correl_rank,sk_correl_rank,function,16,38,31,289,7.61,2,0,"['correl', '0]', '[0', '1]]']","[None, None, None, None]","['[[1', None, None, None]",1432,"[' """""" Correl Ranking:  Col i, Col j, Correl_i_j, Abs_Correl_i_j    """"""\n']","['np.shape', 'np.zeros', 'range', 'abs', 'util.sortcol']",5
utilmy/zarchive/datanalysis.py:sk_error_r2,sk_error_r2,function,8,19,16,175,9.21,0,1,"['Ypred', 'y_true', 'sample_weight', 'multioutput']","[None, None, None, None]","[None, None, 'None', 'None']",1447,[],"['r2_score', 'np.sign']",2
utilmy/zarchive/datanalysis.py:sk_error_rmse,sk_error_rmse,function,6,10,10,100,10.0,0,0,"['Ypred', 'Ytrue']","[None, None]","[None, None]",1454,[],"['np.sqrt', 'len', 'np.std']",3
utilmy/zarchive/datanalysis.py:sk_cluster_distance_pair,sk_cluster_distance_pair,function,5,16,14,195,12.19,0,2,"['Xmat', 'metric']","[None, None]","[None, ""'jaccard'""]",1458,"[""   '''\n"", ""    'euclidean, 'minkowski', 'cityblock', 'seuclidean', 'sqeuclidean, 'cosine, 'correlation, 'hamming, 'jaccard, 'chebyshev, 'canberra, 'braycurtis, 'mahalanobis', VI=None) 'yule, 'matching, 'dice, 'kulsinski, 'rogerstanimoto, 'russellrao, 'sokalmichener, 'sokalsneath,\n"", '\n', ""    'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance,\n"", "" 'canberra': hdbscan.dist_metrics.CanberraDistance,\n"", "" 'chebyshev': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'cityblock': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'dice': hdbscan.dist_metrics.DiceDistance,\n"", "" 'euclidean': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'hamming': hdbscan.dist_metrics.HammingDistance,\n"", "" 'haversine': hdbscan.dist_metrics.HaversineDistance,\n"", "" 'infinity': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'jaccard': hdbscan.dist_metrics.JaccardDistance,\n"", "" 'kulsinski': hdbscan.dist_metrics.KulsinskiDistance,\n"", "" 'l1': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'l2': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance,\n"", "" 'manhattan': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'matching': hdbscan.dist_metrics.MatchingDistance,\n"", "" 'minkowski': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'p': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'pyfunc': hdbscan.dist_metrics.PyFuncDistance,\n"", "" 'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance,\n"", "" 'russellrao': hdbscan.dist_metrics.RussellRaoDistance,\n"", "" 'seuclidean': hdbscan.dist_metrics.SEuclideanDistance,\n"", "" 'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance,\n"", "" 'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance,\n"", "" 'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance}\n"", '   #Visualize discretization scheme\n', '\n', '   Xtrain_dist= sci.spatial.distance.squareform(sci.spatial.distance.pdist(Xtrain_d,\n', ""             metric='cityblock', p=2, w=None, V=None, VI=None))\n"", '\n', ""   Xtsne= da.plot_cluster_tsne(Xtrain_dist, metric='', perplexity=40, ncomponent=2, isprecompute=True)\n"", '\n', ""   '''\n""]",['fast.distance_jaccard_X'],1
utilmy/zarchive/datanalysis.py:sk_cluster,sk_cluster,function,52,173,122,1635,9.45,2,11,"['Xmat', 'metric']","[None, None]","[None, ""'jaccard'""]",1500,[],"['fast.distance_jaccard_X', 'sk_cluster', 'hdbscan.HDBSCAN', 'print', 'len', 'np.std', 'np.mean', 'Xmat.reshape', 'KMeans', 'kmeans.fit', 'range', 'plt.plot', 'plt.show', 'sk_cluster_algo_custom', 'algorithm']",15
utilmy/zarchive/datanalysis.py:sk_cluster_algo_custom,sk_cluster_algo_custom,function,9,17,15,174,10.24,0,1,"['Xmat', 'algorithm', 'args', 'kwds', 'returnval']","[None, None, None, None, None]","[None, None, None, None, '1']",1563,"[""    ''' Plot the cLuster using specific Algo\n"", '    distance_matrix = pairwise_distances(blobs)\n', ""    clusterer = hdbscan.HDBSCAN(metric='precomputed')\n"", '    clusterer.fit(distance_matrix)\n', '    clusterer.labels_\n', '\n', ""    {'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance,\n"", "" 'canberra': hdbscan.dist_metrics.CanberraDistance,\n"", "" 'chebyshev': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'cityblock': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'dice': hdbscan.dist_metrics.DiceDistance,\n"", "" 'euclidean': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'hamming': hdbscan.dist_metrics.HammingDistance,\n"", "" 'haversine': hdbscan.dist_metrics.HaversineDistance,\n"", "" 'infinity': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'jaccard': hdbscan.dist_metrics.JaccardDistance,\n"", "" 'kulsinski': hdbscan.dist_metrics.KulsinskiDistance,\n"", "" 'l1': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'l2': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance,\n"", "" 'manhattan': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'matching': hdbscan.dist_metrics.MatchingDistance,\n"", "" 'minkowski': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'p': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'pyfunc': hdbscan.dist_metrics.PyFuncDistance,\n"", "" 'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance,\n"", "" 'russellrao': hdbscan.dist_metrics.RussellRaoDistance,\n"", "" 'seuclidean': hdbscan.dist_metrics.SEuclideanDistance,\n"", "" 'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance,\n"", "" 'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance,\n"", "" 'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance}\n"", '\n', ""    '''\n""]","['algorithm', 'print', 'len']",3
utilmy/zarchive/datanalysis.py:sk_optim_de,sk_optim_de,function,35,125,96,1182,9.46,1,4,"['obj_fun', 'bounds', 'maxiter', 'name1', 'solver1', 'isreset', 'popsize']","[None, None, None, None, None, None, None]","[None, None, '1', ""''"", 'None', '1', '15']",1636,"[""    ''' Optimization and Save Data into file'''\n""]","['print', 'load_obj', 'int', 'copy.deepcopy', 'range', 'next', 'util.save_obj', 'util.date_now', 'util.np_int_tostr', 'np.mod', 'np.abs']",11
utilmy/zarchive/datanalysis.py:sk_feature_importance,sk_feature_importance,function,8,19,19,230,12.11,1,1,"['clfrf', 'feature_name']","[None, None]","[None, None]",1739,[],"['np.argsort', 'range', 'len', 'print', 'str']",5
utilmy/zarchive/datanalysis.py:sk_showconfusion,sk_showconfusion,function,11,22,21,246,11.18,0,1,"['clfrf', 'X_train', 'Y_train', 'isprint']","[None, None, None, None]","[None, None, None, 'True']",1747,[],"['clfrf.predict', 'cm.astype', 'cm.sum', 'print']",4
utilmy/zarchive/datanalysis.py:sk_tree,sk_tree,function,13,33,32,447,13.55,0,1,"['Xtrain', 'Ytrain', 'nbtree', 'maxdepth', 'isprint1', 'njobs']","[None, None, None, None, None, None]","[None, None, None, None, '1', '1']",1756,[],"['clfrf.fit', 'clfrf.predict', 'cm.astype', 'cm.sum', 'print']",5
utilmy/zarchive/datanalysis.py:sk_gen_ensemble_weight,sk_gen_ensemble_weight,function,14,29,27,213,7.34,1,0,"['vv', 'acclevel', 'maxlevel']","[None, None, None]","[None, None, '0.88']",1768,[],"['min', 'np.empty', 'range', 'estww.append', 'np.log', 'np.array']",6
utilmy/zarchive/datanalysis.py:sk_votingpredict,sk_votingpredict,function,19,33,28,267,8.09,2,1,"['estimators', 'voting', 'ww', 'X_test']","[None, None, None, None]","[None, None, None, None]",1782,[],"['np.zeros', 'enumerate', 'clf.predict_proba', 'range', 'len']",5
utilmy/zarchive/datanalysis.py:sk_tree_get_ifthen,sk_tree_get_ifthen,function,26,91,64,780,8.57,2,3,"['tree', 'feature_names', 'target_names', 'spacer_base']","[None, None, None, None]","[None, None, None, '"" ""']",1797,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['recurse', 'print', 'str', 'zip', 'int']",5
utilmy/zarchive/datanalysis.py:sk_model_template1,sk_model_template1,class,39,143,87,1197,8.37,0,3,[],[],[],1683,[],[],0
utilmy/zarchive/datanalysis.py:sk_stateRule,sk_stateRule,class,38,138,104,1121,8.12,0,5,[],[],[],1868,[],[],0
utilmy/zarchive/datanalysis.py:sk_model_template1:__init__,sk_model_template1:__init__,method,10,13,13,166,12.77,0,0,"['self', 'alpha', 'low_y_cut', 'high_y_cut', 'ww0']","[None, None, None, None, None]","[None, '0.5', '-0.09', '0.09', '0.95']",1684,[],['Ridge'],1
utilmy/zarchive/datanalysis.py:sk_model_template1:fit,sk_model_template1:fit,method,17,46,40,471,10.24,0,1,"['self', 'X', 'Y']","[None, None, None]","[None, None, 'None']",1690,[],"['len', 'print', 'np.median']",3
utilmy/zarchive/datanalysis.py:sk_model_template1:predict,sk_model_template1:predict,method,10,27,21,166,6.15,0,1,"['self', 'X', 'y', 'ymedian']","[None, None, None, None]","[None, None, 'None', 'None']",1708,[],['Y.clip'],1
utilmy/zarchive/datanalysis.py:sk_model_template1:score,sk_model_template1:score,method,14,32,27,216,6.75,0,1,"['self', 'X', 'Ytrue', 'ymedian']","[None, None, None, None]","[None, None, 'None', 'None']",1719,[],"['Y.clip', 'r2_score']",2
utilmy/zarchive/datanalysis.py:sk_stateRule:__init__,sk_stateRule:__init__,method,8,44,37,370,8.41,0,1,"['self', 'state', 'trigger', 'colname']","[None, None, None, None]","[None, None, None, '[]']",1871,[],"['np.empty', 'np.shape', 'len', 'range', 'util.np_torecarray']",5
utilmy/zarchive/datanalysis.py:sk_stateRule:addrule,sk_stateRule:addrule,method,20,47,42,383,8.15,0,2,"['self', 'rulefun', 'name', 'desc']","[None, None, None, None]","[None, None, ""''"", ""''""]",1883,[],"['util.findnone', 'util.find', 'print', 'util.np_addcolumn', 'rulefun', 'copy.deepcopy']",6
utilmy/zarchive/datanalysis.py:sk_stateRule:eval,sk_stateRule:eval,method,9,29,24,233,8.03,0,2,"['self', 'idrule', 't', 'ktrig']","[None, None, None, None]","[None, None, None, '0']",1901,[],"['isinstance', 'util.find', 'print']",3
utilmy/zarchive/datanalysis.py:sk_stateRule:help,sk_stateRule:help,method,0,0,0,0,0.0,0,0,[],[],[],1909,"[""    '''\n"", 's1= np.arange(5000).reshape((1000, 5))\n', 'trig1= np.ones((1,5))\n', ""state1= sk_stateRule(aa, trig1, ['drawdown','ma100d','ret10d','state_1','state_2'] )\n"", '\n', 'def fun1(s, tr,t):\n', '  return  s.drawdown[t] < tr.drawdown[0] and  s.drawdown[t] < tr.drawdown[0]\n', '\n', 'def fun2(s, tr,t):\n', ' return  s.drawdown[t] > tr.drawdown[0] and  s.drawdown[t] < tr.drawdown[0]\n', '\n', ""state1.addrule(fun1, 'rule6')\n"", ""state1.addrule(fun2, 'rule5')\n"", '\n', 'state1.eval(idrule=0,t=5)\n', '\n', 'state1.eval(idrule=1,t=5)\n', '\n', ""state1.eval(idrule='rule5',t=6)\n"", '\n', ""util.save_obj(state1, 'state1')\n"", '\n', 'np.shape(aa2)\n', '\n', ""aa2= util.np_torecarray(aa,  ['drawdown','a2','a3','a4','a5'])\n"", '\n', 'util.find(5.0, aa2[0])\n', '\n', 'recordarr = np.rec.array([(1,2.,7),(2,3.,5)],\n', ""                   dtype=[('col1', 'f8'),('col2', 'f8'), ('col3', 'f8')])\n"", 'recordarr.col3[0]\n', '\n', 'state1= stateRule(np.ones((100,10)), np.ones((1,10)))\n', '\n', 'col= aa2.a2\n', '\n', ""'''\n""]",[],0
utilmy/zarchive/excel.py:get_workbook_name,get_workbook_name,function,3,5,5,48,9.6,0,0,[],[],[],9,"['    """"""Writes the name of the Workbook into Range(""D3"") of Sheet 1""""""\n']","['Workbook.caller', 'Range']",2
utilmy/zarchive/excel.py:double_sum,double_sum,function,1,4,4,13,3.25,0,0,"['x', 'y']","[None, None]","[None, None]",16,"['    """"""Returns twice the sum of the two arguments""""""\n']",[],0
utilmy/zarchive/excel.py:add_one,add_one,function,5,11,9,40,3.64,2,0,['data'],[None],[None],23,"['    """"""Adds 1 to every cell in Range""""""\n']",[],0
utilmy/zarchive/excel.py:matrix_mult,matrix_mult,function,2,2,2,14,7.0,0,0,"['x', 'y']","[None, None]","[None, None]",31,"['    """"""Alternative implementation of Excel\'s MMULT, requires NumPy""""""\n']",['x.dot'],1
utilmy/zarchive/excel.py:npdot,npdot,function,0,0,0,0,0.0,0,0,[],[],[],43,[],[],0
utilmy/zarchive/fast.py:day,day,function,9,15,14,125,8.33,0,0,['s)'],['    return int(s[8:10])s):  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],130,[],['arrow.get'],1
utilmy/zarchive/fast.py:month,month,function,9,15,14,125,8.33,0,0,['s)'],['  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],131,[],['arrow.get'],1
utilmy/zarchive/fast.py:year,year,function,9,15,14,125,8.33,0,0,['s)'],['   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],132,[],['arrow.get'],1
utilmy/zarchive/fast.py:hour,hour,function,9,15,14,125,8.33,0,0,['s)'],['   return int(s[11:13])cache_weekday'],[' {}s):'],133,[],['arrow.get'],1
utilmy/zarchive/fast.py:weekday,weekday,function,9,15,14,125,8.33,0,0,['s'],[None],[None],139,[],['arrow.get'],1
utilmy/zarchive/fast.py:season,season,function,4,15,13,47,3.13,0,1,['d'],[None],[None],148,[],['int'],1
utilmy/zarchive/fast.py:daytime,daytime,function,5,40,23,123,3.08,0,1,['d'],[None],[None],154,[],['int'],1
utilmy/zarchive/fast.py:fastStrptime,fastStrptime,function,8,46,35,288,6.26,0,2,"['val', 'format']","[None, None]","[None, None]",164,[],"['len', 'int', 'datetime.datetime']",3
utilmy/zarchive/fast.py:drawdown_calc_fast,drawdown_calc_fast,function,36,80,63,618,7.72,1,3,['price'],[None],[None],190,[],"['len', 'np.zeros', 'range']",3
utilmy/zarchive/fast.py:std,std,function,6,12,12,61,5.08,0,0,['x'],[None],[None],225,"['    """"""Std Deviation 1D array""""""\n']","['x.sum', 'sqrt']",2
utilmy/zarchive/fast.py:mean,mean,function,2,3,3,24,8.0,0,0,['x'],[None],[None],236,"['    """"""Mean  """"""\n']",['x.sum'],1
utilmy/zarchive/fast.py:_compute_overlaps,_compute_overlaps,function,13,27,20,108,4.0,1,0,"['u', 'v']","[None, None]","[None, None]",249,[],['xrange'],1
utilmy/zarchive/fast.py:distance_jaccard2,distance_jaccard2,function,5,11,11,55,5.0,0,0,"['u', 'v']","[None, None]","[None, None]",260,[],"['_compute_overlaps', 'float']",2
utilmy/zarchive/fast.py:distance_jaccard,distance_jaccard,function,5,11,11,55,5.0,0,0,"['u', 'v']","[None, None]","[None, None]",266,[],"['_compute_overlaps', 'float']",2
utilmy/zarchive/fast.py:distance_jaccard_X,distance_jaccard_X,function,13,21,19,163,7.76,2,0,['X'],[None],[None],277,[],"['np.zeros', 'xrange', 'distance_jaccard']",3
utilmy/zarchive/fast.py:cosine,cosine,function,11,43,26,262,6.09,0,2,"['u', 'v']","[None, None]","[None, None]",292,[],['np.sqrt'],1
utilmy/zarchive/fast.py:rmse,rmse,function,1,7,6,31,4.43,0,0,"['y', 'yhat']","[None, None]","[None, None]",321,"['    """""" Calculate and return Root Mean Squared Error (RMSE)\n', '    Returns: float: Root Mean Squared Error\n', '    """"""\n']",[],0
utilmy/zarchive/fast.py:cross,cross,function,17,31,25,211,6.81,0,0,"['vec1', 'vec2']","[None, None]","[None, None]",329,"['    """""" Calculate the dot product of two 3d vectors. """"""\n']","['double', 'np.zeros']",2
utilmy/zarchive/fast.py:norm,norm,function,4,8,8,61,7.62,1,0,['vec'],[None],[None],341,"['    """""" Calculate the norm of a 3d vector. """"""\n']","['sqrt', 'range']",2
utilmy/zarchive/fast.py:log_exp_sum2,log_exp_sum2,function,0,1,1,5,5.0,0,0,"['a', 'b']","[None, None]","[None, None]",242,[],[],0
utilmy/zarchive/fast_parallel.py:task_summary,task_summary,function,4,17,17,142,8.35,1,0,['tasks'],[None],[None],76,[],"['print', 'enumerate', 't.get']",3
utilmy/zarchive/fast_parallel.py:task_progress,task_progress,function,8,26,23,161,6.19,1,1,['tasks'],[None],[None],83,"[""  ''' Monitor progress '''\n""]","['np.mean', 'print']",2
utilmy/zarchive/fast_parallel.py:task_find_best,task_find_best,function,3,11,11,80,7.27,0,0,"['tasks', 'n_top']","[None, None]","[None, '5']",94,"['    """"""Compute the best score of tasks_folder""""""\n']","['t.ready', 'sorted']",2
utilmy/zarchive/fast_parallel.py:task_parallel_job_01,task_parallel_job_01,function,19,33,32,336,10.18,0,0,"['name', 'param', 'datadict']","[None, None, None]","[None, None, None]",101,"[""   ''' Sample task run in Parallel '''\n""]","['os.chdir', 'util.a_run_ipython', 'str']",3
utilmy/zarchive/filelock.py:FileLock,FileLock,class,41,133,94,1246,9.37,2,6,[],[],[],36,[],[],0
utilmy/zarchive/filelock.py:FileLock:__init__,FileLock:__init__,method,11,27,23,279,10.33,1,1,"['self', 'protected_file_path', 'timeout', 'delay', 'lock_file_contents']","[None, None, None, None, None]","[None, None, 'None', '1', 'None']",53,"['        """""" Prepare the file locker. Specify the file to lock and optionally\n', '            the maximum timeout and the delay between each attempt to lock.\n', '        """"""\n']",[],0
utilmy/zarchive/filelock.py:FileLock:locked,FileLock:locked,method,2,2,2,20,10.0,0,0,['self'],[None],[None],67,"['        """"""\n', '        Returns True iff the file is owned by THIS FileLock instance.\n', '        (Even if this returns false, the file could be owned by another FileLock instance, possibly in a different thread or process).\n', '        """"""\n']",[],0
utilmy/zarchive/filelock.py:FileLock:available,FileLock:available,method,2,3,3,38,12.67,0,0,['self'],[None],[None],74,"['        """"""\n', '        Returns True iff the file is currently available to be locked.\n', '        """"""\n']",[],0
utilmy/zarchive/filelock.py:FileLock:acquire,FileLock:acquire,method,18,55,48,410,7.45,1,3,"['self', 'blocking']","[None, None]","[None, 'True']",80,"['        """""" Acquire the lock, if possible. If the lock is in use, and `blocking` is False, return False.\n', '            Otherwise, check again every `self.delay` seconds until it either gets the lock or\n', '            exceeds `timeout` number of seconds, in which case it raises an exception.\n', '        """"""\n']","['time.time', 'os.open', 'os.fdopen', 'f.write', 'FileLock.FileLockException', 'time.sleep']",6
utilmy/zarchive/filelock.py:FileLock:release,FileLock:release,method,2,3,3,45,15.0,0,0,['self'],[None],[None],106,"['        """""" Get rid of the lock by deleting the lockfile.\n', '            When working in a `with` statement, this gets automatically\n', '            called at the end.\n', '        """"""\n']",['os.unlink'],1
utilmy/zarchive/filelock.py:FileLock:__enter__,FileLock:__enter__,method,2,3,3,25,8.33,0,0,['self'],[None],[None],115,"['        """""" Activated when used in the with statement.\n', '            Should automatically acquire a lock to be used in the with block.\n', '        """"""\n']",['self.acquire'],1
utilmy/zarchive/filelock.py:FileLock:__exit__,FileLock:__exit__,method,1,1,1,14,14.0,0,0,"['self', 'type', 'value', 'traceback']","[None, None, None, None]","[None, None, None, None]",123,"['        """""" Activated at the end of the with statement.\n', ""            It automatically releases the lock if it isn't locked.\n"", '        """"""\n']",['self.release'],1
utilmy/zarchive/filelock.py:FileLock:__del__,FileLock:__del__,method,2,3,3,32,10.67,0,1,['self'],[None],[None],130,"['        """""" Make sure this ``FileLock`` instance doesn\'t leave a .lock file\n', '            lying around.\n', '        """"""\n']",['self.release'],1
utilmy/zarchive/filelock.py:FileLock:purge,FileLock:purge,method,3,7,6,70,10.0,0,1,['self'],[None],[None],137,"['        """"""\n', '        For debug purposes only.  Removes the lock file from the hard disk.\n', '        """"""\n']",['self.release'],1
utilmy/zarchive/function_custom.py:mapping_calc_risk_elvis_v03,mapping_calc_risk_elvis_v03,function,4,9,9,63,7.0,0,0,"['ss', 'tr', 't', 'riskout']","[None, None, None, None]","[None, None, None, None]",18,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",['mapping_calc_risk_v01'],1
utilmy/zarchive/function_custom.py:mapping_calc_risk_v02,mapping_calc_risk_v02,function,18,190,75,704,3.71,0,2,"['ss', 'tr', 't', 'risk0']","[None, None, None, None]","[None, None, None, None]",31,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",[],0
utilmy/zarchive/function_custom.py:mapping_calc_risk_v01,mapping_calc_risk_v01,function,19,130,56,532,4.09,0,2,"['ss', 'tr', 't', 'risk0']","[None, None, None, None]","[None, None, None, None]",72,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",[],0
utilmy/zarchive/function_custom.py:mapping_risk_ww_v01,mapping_risk_ww_v01,function,12,56,29,245,4.38,0,1,"['risk', 'wwmat', 'ww2']","[None, None, None]","[None, None, None]",98,[],"['np.sum', 'np.array']",2
utilmy/zarchive/function_custom.py:mapping_calc_risk_v00,mapping_calc_risk_v00,function,16,68,45,286,4.21,0,1,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",107,[],[],0
utilmy/zarchive/function_custom.py:getweight,getweight,function,7,13,12,70,5.38,0,1,"['ww', 'size', '3']","[None, None, None]","[None, '(9', None]",133,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/function_custom.py:fun_obj,fun_obj,function,6,11,11,120,10.91,0,0,"['vv', 'ext']","[None, None]","[None, None]",139,[],"['pf.folio_volta', 'int', 'pf.volhisto_fromprice', 'len']",4
utilmy/zarchive/geospatial.py:coordinates_box,coordinates_box,class,1,2,2,16,8.0,0,0,[],[],[],33,[],[],0
utilmy/zarchive/kagglegym.py:r_score,r_score,function,4,15,12,146,9.73,0,1,"['y_true', 'y_pred', 'sample_weight', 'multioutput']","[None, None, None, None]","[None, None, 'None', 'None']",77,[],['r2_score'],1
utilmy/zarchive/kagglegym.py:make,make,function,2,2,2,19,9.5,0,0,[],[],[],175,[],['Environment'],1
utilmy/zarchive/kagglegym.py:Observation,Observation,class,7,11,11,99,9.0,0,0,[],[],[],86,[],[],0
utilmy/zarchive/kagglegym.py:Environment,Environment,class,49,148,101,1719,11.61,0,1,[],[],[],93,[],[],0
utilmy/zarchive/kagglegym.py:Observation:__init__,Observation:__init__,method,6,6,6,58,9.67,0,0,"['self', 'train', 'target', 'features']","[None, None, None, None]","[None, None, None, None]",87,[],[],0
utilmy/zarchive/kagglegym.py:Environment:__init__,Environment:__init__,method,21,37,35,452,12.22,0,0,['self'],[None],[None],94,[],"['pd.HDFStore', 'hfdata.get', 'len', 'int']",4
utilmy/zarchive/kagglegym.py:Environment:reset,Environment:reset,method,16,36,34,403,11.19,0,0,['self'],[None],[None],115,[],"['int', 'Observation']",2
utilmy/zarchive/kagglegym.py:Environment:step,Environment:step,method,29,64,52,765,11.95,0,1,"['self', 'target']","[None, None]","[None, None]",135,[],"['r_score', 'Observation']",2
utilmy/zarchive/kagglegym.py:Environment:__str__,Environment:__str__,method,1,2,2,21,10.5,0,0,['self'],[None],[None],171,[],[],0
utilmy/zarchive/linux.py:load_session,load_session,function,4,7,7,86,12.29,0,0,['name'],[None],"[""'test_20160815'""]",100,[],['dill.load_session'],1
utilmy/zarchive/linux.py:save_session,save_session,function,6,9,9,107,11.89,0,0,['name'],[None],"[""''""]",106,[],"['date_now', 'dill.dump_session']",2
utilmy/zarchive/linux.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],121,[],['float'],1
utilmy/zarchive/linux.py:isint,isint,function,6,15,14,80,5.33,0,1,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, None, '']","[None, None, None, None, None, None]",129,[],['txt.find'],1
utilmy/zarchive/linux.py:aa_isanaconda,aa_isanaconda,function,6,15,14,80,5.33,0,1,[],[],[],132,[],['txt.find'],1
utilmy/zarchive/linux.py:aa_cleanmemory,aa_cleanmemory,function,3,3,3,21,7.0,0,0,[],[],[],147,[],['gc.collect'],1
utilmy/zarchive/linux.py:aa_getmodule_doc,aa_getmodule_doc,function,8,13,13,110,8.46,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",150,[],"['ca.getmodule_doc', 'np.isnan', 'z.nonzero']",3
utilmy/zarchive/linux.py:np_interpolate_nan,np_interpolate_nan,function,7,9,9,78,8.67,0,0,['y'],[None],[None],1176,[],"['__np_nan_helper', 'np.interp', 'x']",3
utilmy/zarchive/linux.py:and1,and1,function,8,55,22,356,6.47,0,6,"['x', 'y', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']","[None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None', 'None', 'None']",1182,[],[],0
utilmy/zarchive/linux.py:sortcol,sortcol,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",1192,"[' """""" df.sort([\'A\', \'B\'], ascending=[1, 0])  """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/linux.py:sort,sort,function,7,20,12,181,9.05,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",1198,[],"['pd.DataFrame', 'df.sort_values', 'sort']",3
utilmy/zarchive/linux.py:np_ma,np_ma,function,2,3,3,45,15.0,0,0,"['vv', 'n']","[None, None]","[None, None]",1205,"[""  '''Moving average '''\n""]","['np.convolve', 'np.ones']",2
utilmy/zarchive/linux.py:np_cleanmatrix,np_cleanmatrix,function,11,22,20,124,5.64,2,1,['m'],[None],[None],1211,[],"['np.nan_to_num', 'np.shape', 'range', 'abs']",4
utilmy/zarchive/linux.py:np_sortbycolumn,np_sortbycolumn,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1222,[],"['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/linux.py:np_sortbycol,np_sortbycol,function,8,30,20,257,8.57,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1227,[],"['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/linux.py:np_findfirst,np_findfirst,function,5,11,10,55,5.0,1,1,"['item', 'vec']","[None, None]","[None, None]",1238,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/linux.py:np_find,np_find,function,6,24,13,133,5.54,2,2,"['item', 'vec']","[None, None]","[None, None]",1244,[],"['xrange', 'np_find']",2
utilmy/zarchive/linux.py:find,find,function,12,42,30,219,5.21,1,3,"['item', 'vec']","[None, None]","[None, None]",1250,"['    """"""return the index of the first occurence of item in vec""""""\n']","['xrange', 'findx', 'type', 'vec.index', 'len', 'finds']",6
utilmy/zarchive/linux.py:findx,findx,function,6,27,18,119,4.41,0,2,"['item', 'vec']","[None, None]","[None, None]",1257,"['    """"""return the index of the first occurence of item in vec""""""\n']","['type', 'vec.index', 'len']",3
utilmy/zarchive/linux.py:finds,finds,function,12,34,23,156,4.59,2,3,"['itemlist', 'vec']","[None, None]","[None, None]",1268,"['  """"""return the index of the first occurence of item in vec""""""\n']","['xrange', 'idlist.append']",2
utilmy/zarchive/linux.py:findhigher,findhigher,function,5,13,12,51,3.92,1,1,"['x', 'vec']","[None, None]","[None, None]",1280,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/linux.py:findlower,findlower,function,5,12,11,51,4.25,1,1,"['x', 'vec']","[None, None]","[None, None]",1287,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/linux.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],1297,[],['min'],1
utilmy/zarchive/linux.py:np_find_maxpos,np_find_maxpos,function,17,45,34,266,5.91,1,3,['values'],[None],[None],1301,[],"['max', 'np_find_maxpos_2nd', 'float', 'enumerate']",4
utilmy/zarchive/linux.py:np_find_maxpos_2nd,np_find_maxpos_2nd,function,13,37,28,138,3.73,1,3,['numbers'],[None],[None],1306,[],"['float', 'enumerate']",2
utilmy/zarchive/linux.py:np_findlocalmax2,np_findlocalmax2,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",1320,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/linux.py:np_findlocalmin2,np_findlocalmin2,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",1355,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/linux.py:np_findlocalmax,np_findlocalmax,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",1392,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/linux.py:np_findlocalmin,np_findlocalmin,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",1407,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/linux.py:np_stack,np_stack,function,12,53,25,323,6.09,0,7,"['v1', 'v2', 'v3', 'v4', 'v5']","[None, None, None, None, None]","[None, 'None', 'None', 'None', 'None']",1428,[],"['np.shape', 'np.row_stack', 'np.column_stack']",3
utilmy/zarchive/linux.py:np_uniquerows,np_uniquerows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],1443,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/linux.py:np_remove_zeros,np_remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",1448,[],[],0
utilmy/zarchive/linux.py:np_sort,np_sort,function,8,30,20,257,8.57,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1451,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/linux.py:np_memory_array_adress,np_memory_array_adress,function,2,2,2,38,19.0,0,0,['x'],[None],[None],1454,[],[],0
utilmy/zarchive/linux.py:sk_featureimportance,sk_featureimportance,function,9,21,21,228,10.86,1,1,"['clfrf', 'feature_name']","[None, None]","[None, None]",1463,[],"['np.argsort', 'range', 'len', 'str']",4
utilmy/zarchive/linux.py:sk_showconfusion,sk_showconfusion,function,11,22,21,244,11.09,0,1,"['clfrf', 'X_train', 'Y_train', 'isprint']","[None, None, None, None]","[None, None, None, 'True']",1471,[],"['clfrf.predict', 'cm.astype', 'cm.sum', 'print']",4
utilmy/zarchive/linux.py:sk_tree,sk_tree,function,13,34,32,430,12.65,0,1,"['Xtrain', 'Ytrain', 'nbtree', 'maxdepth', 'print1']","[None, None, None, None, None]","[None, None, None, None, None]",1479,[],"['clfrf.fit', 'clfrf.predict', 'cm.astype', 'cm.sum', 'print']",5
utilmy/zarchive/linux.py:sk_gen_ensemble_weight,sk_gen_ensemble_weight,function,14,30,28,213,7.1,1,0,"['vv', 'acclevel', 'maxlevel']","[None, None, None]","[None, None, '0.88']",1492,[],"['min', 'np.empty', 'range', 'estww.append', 'np.log', 'np.array']",6
utilmy/zarchive/linux.py:sk_votingpredict,sk_votingpredict,function,19,33,28,267,8.09,2,1,"['estimators', 'voting', 'ww', 'X_test']","[None, None, None, None]","[None, None, None, None]",1506,[],"['np.zeros', 'enumerate', 'clf.predict_proba', 'range', 'len']",5
utilmy/zarchive/linux.py:sk_tree_get_ifthen,sk_tree_get_ifthen,function,26,89,62,768,8.63,2,3,"['tree', 'feature_names', 'target_names', 'spacer_base']","[None, None, None, None]","[None, None, None, '"" ""']",1524,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['recurse', 'print', 'str', 'zip', 'int']",5
utilmy/zarchive/linux.py:pd_array_todataframe,pd_array_todataframe,function,13,45,29,277,6.16,0,2,"['price', 'symbols', 'date1', 'dotranspose']","[None, None, None, None]","[None, 'None', 'None', 'False']",1562,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/linux.py:pd_date_intersection,pd_date_intersection,function,7,18,15,157,8.72,1,0,['qlist'],[None],[None],1574,[],"['set', 'set.intersection', 'list', 'sorted']",4
utilmy/zarchive/linux.py:pd_resetindex,pd_resetindex,function,3,4,4,50,12.5,0,0,['df'],[None],[None],1585,[],['list'],1
utilmy/zarchive/linux.py:pd_create_colmap_nametoid,pd_create_colmap_nametoid,function,9,12,12,77,6.42,1,0,['df'],[None],[None],1591,"[""  ''' 'close' ---> 5    '''\n""]",['enumerate'],1
utilmy/zarchive/linux.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],1599,[],[],0
utilmy/zarchive/linux.py:pd_changeencoding,pd_changeencoding,function,6,8,8,89,11.12,1,0,"['data', 'cols']","[None, None]","[None, None]",1606,[],[],0
utilmy/zarchive/linux.py:pd_createdf,pd_createdf,function,2,4,4,53,13.25,0,0,"['val1', 'col1', 'idx1']","[None, None, None]","[None, 'None', 'None']",1613,[],['pd.DataFrame'],1
utilmy/zarchive/linux.py:pd_insertcolumn,pd_insertcolumn,function,12,29,27,179,6.17,1,1,"['df', 'colname', 'vec']","[None, None, None]","[None, None, None]",1618,"["" ''' Vec and Colname must be aligned '''\n""]","['len', 'np.shape', 'range', 'df.insert']",4
utilmy/zarchive/linux.py:pd_insertrows,pd_insertrows,function,17,31,30,237,7.65,1,1,"['df', 'rowval', 'index1']","[None, None, None]","[None, None, 'None']",1632,[],"['np.shape', 'np.arange', 'pd.DataFrame', 'range', 'df.append']",5
utilmy/zarchive/linux.py:pd_replacevalues,pd_replacevalues,function,11,14,14,101,7.21,1,0,"['df', 'matrix']","[None, None]","[None, None]",1645,"["" ''' Matrix replaces df.values  '''\n""]",['np.shape'],1
utilmy/zarchive/linux.py:pd_storeadddf,pd_storeadddf,function,6,15,15,113,7.53,0,1,"['df', 'dfname', ""dbfile='F""]","[None, None, '']","[None, None, ""'F:\\temp_pandas.h5'""]",1655,[],"['pd.HDFStore', 'find', 'store.keys', 'store.append', 'store.close']",5
utilmy/zarchive/linux.py:pd_storedumpinfo,pd_storedumpinfo,function,13,29,24,298,10.28,1,0,"[""dbfile='E""]",[''],"[""'E:\\_data\\stock\\intraday_google.h5'""]",1663,[],"['pd.HDFStore', 'store.keys', 'pd.read_hdf', 'extract.append', 'datetime_tostring', 'errsym.append', 'np.array']",7
utilmy/zarchive/linux.py:pd_remove_row,pd_remove_row,function,2,2,2,29,14.5,0,0,"['df', 'row_list_index', '45]']","[None, None, None]","[None, '[23', None]",1677,[],['df.drop'],1
utilmy/zarchive/linux.py:pd_extract_col_idx_val,pd_extract_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],1680,[],[],0
utilmy/zarchive/linux.py:pd_split_col_idx_val,pd_split_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],1684,[],[],0
utilmy/zarchive/linux.py:pd_addcolumn,pd_addcolumn,function,10,23,19,190,8.26,1,1,"['df1', 'name1']","[None, None]","[None, ""'new'""]",1688,[],"['len', 'type', 'pd.Series']",3
utilmy/zarchive/linux.py:pd_removecolumn,pd_removecolumn,function,2,3,3,23,7.67,0,0,"['df1', 'name1']","[None, None]","[None, None]",1697,[],['df1.drop'],1
utilmy/zarchive/linux.py:pd_save_vectopanda,pd_save_vectopanda,function,9,22,19,182,8.27,1,0,"['vv', 'filenameh5)', 'pdf); store.close()filenameh5', ""store_id='data')"", 'store_id)    #from filereturn pdf.values   #to numpy vectorfilein1', 'filename', ""tablen='data')""]","[None, ""  # 'E:\\_data\\_data_outlier.h5'filenameh5)vv); store.append('data'"", None, '', None, None, '']","[None, None, None, ""'data'):  # 'E:\\_data\\_data_outlier.h5'filenameh5"", None, None, ""'data'):""]",1701,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/linux.py:pd_load_panda2vec,pd_load_panda2vec,function,9,22,19,182,8.27,1,0,"['filenameh5', ""store_id='data')"", 'store_id)    #from filereturn pdf.values   #to numpy vectorfilein1', 'filename', ""tablen='data')""]","[None, '', None, None, '']","[None, ""'data'):  # 'E:\\_data\\_data_outlier.h5'filenameh5"", None, None, ""'data'):""]",1706,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/linux.py:pd_csv_topanda,pd_csv_topanda,function,9,22,19,182,8.27,1,0,"['filein1', 'filename', 'tablen']","[None, None, None]","[None, None, ""'data'""]",1711,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/linux.py:pd_getpanda_tonumpy,pd_getpanda_tonumpy,function,6,10,10,92,9.2,0,0,"['filename', 'nsize', 'tablen']","[None, None, None]","[None, None, ""'data'""]",1723,[],['pd.read_hdf'],1
utilmy/zarchive/linux.py:pd_getrandom_tonumpy,pd_getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample', 'tablen']","[None, None, None, None]","[None, None, None, ""'data'""]",1728,[],['pd.read_hdf'],1
utilmy/zarchive/linux.py:sk_cluster_kmeans,sk_cluster_kmeans,function,21,38,37,375,9.87,1,1,"['x', 'nbcluster', 'isplot']","[None, None, None]","[None, '5', 'True']",1861,[],"['np.std', 'kmeans.fit', 'range', 'plt.plot', 'plt.show']",5
utilmy/zarchive/linux.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],1885,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/linux.py:date_remove_bdays,date_remove_bdays,function,16,41,28,351,8.56,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",1896,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/linux.py:date_add_bdays,date_add_bdays,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",1914,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/linux.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",1929,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/linux.py:datetime_toint,datetime_toint,function,6,15,13,155,10.33,1,1,['datelist1'],[None],[None],1938,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/linux.py:dateint_todatetime,dateint_todatetime,function,6,15,13,135,9.0,1,1,['datelist1'],[None],[None],1946,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/linux.py:date_diffindays,date_diffindays,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",1955,[],['dateint_todatetime'],1
utilmy/zarchive/linux.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",1960,[],['util.np_findfirst'],1
utilmy/zarchive/linux.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],1974,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/linux.py:date_now,date_now,function,10,18,16,130,7.22,0,1,['i'],[None],['0'],1981,[],"['datetime.now', 'date_add_bdays', 'date_remove_bdays', 'str']",4
utilmy/zarchive/linux.py:date_as_float,date_as_float,function,11,28,23,273,9.75,0,1,['dt'],[None],[None],1989,[],"['datetime.datetime', 'isleap', 'timedelta']",3
utilmy/zarchive/linux.py:datediff_inyear,datediff_inyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",2001,[],['date_as_float'],1
utilmy/zarchive/linux.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",2005,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/linux.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],1885,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/linux.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",1929,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/linux.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],1974,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/linux.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",2048,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/linux.py:numexpr_topanda,numexpr_topanda,function,10,28,22,248,8.86,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",2060,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/linux.py:textvect_topanda,textvect_topanda,function,2,8,8,70,8.75,0,0,"['vv', 'fileout']","[None, None]","[None, '""""']",2070,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zarchive/linux.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",2093,[],['ne.evaluate'],1
utilmy/zarchive/linux.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],2101,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/linux.py:plotsave,plotsave,function,7,16,16,199,12.44,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",2124,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/linux.py:plotshow,plotshow,function,4,9,9,101,11.22,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",2135,[],"['plt.scatter', 'plt.autoscale', 'plt.title', 'plt.show']",4
utilmy/zarchive/linux.py:compileVSsolution,compileVSsolution,function,5,33,19,239,7.24,0,4,"['dir1', 'flags1', 'type1', 'compilerdir']","[None, None, None, None]","[None, '""""', '""devenv""', '""""']",2568,[],['os.system'],1
utilmy/zarchive/linux.py:VS_start,VS_start,function,18,56,52,881,15.73,0,2,"['self', 'version']","[None, None]","[None, None]",2597,[],"['os.getenv', 'Exception', 'default.append', 'libs.append']",4
utilmy/zarchive/linux.py:VS_build,VS_build,function,16,62,54,614,9.9,1,2,"['self', 'lib_to_build']","[None, None]","[None, None]",2632,[],"['print', 'subprocess.Popen', 'process.poll', 'process.communicate']",4
utilmy/zarchive/linux.py:set_rc_version,set_rc_version,function,12,43,39,500,11.63,0,0,"['rcfile', 'target_version']","[None, None]","[None, None]",2666,[],"['open', 'f.read', 're.compile', 're.sub', 'f.seek', 'f.write', 'f.truncate']",7
utilmy/zarchive/multiprocessfunc.py:multigbm_paralell_func,multigbm_paralell_func,function,34,117,81,913,7.8,1,4,"['nbsimul', 'ww', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price', 'type1', 'strike', 'cp']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, '0', '0', '1']",20,[],"['np.zeros', 'range', 'np.dot', 'np.multiply', 'np.exp', 'np.cumprod', 'np.maximum', 'sum', 'sum1/float']",9
utilmy/zarchive/multiprocessfunc.py:func,func,function,6,10,10,56,5.6,1,0,"['val', 'lock']","[None, None]","[None, None]",73,[],"['range', 'time.sleep']",2
utilmy/zarchive/multiprocessfunc.py:multigbm_processfast7,multigbm_processfast7,function,24,48,44,419,8.73,3,0,"['nbsimul', 's0', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",150,[],"['range', 'np.dot', 'bm_generator', 'np.exp', 'sum', 'sum1/float']",6
utilmy/zarchive/multiprocessfunc.py:bm_generator,bm_generator,function,5,9,8,43,4.78,0,1,"['bm', 'dt', 'n', 'type1']","[None, None, None, None]","[None, None, None, None]",177,[],[],0
utilmy/zarchive/multiprocessfunc.py:merge,merge,function,6,20,17,106,5.3,1,1,['d2'],[None],[None],211,[],"['time.sleep', 'd2.keys']",2
utilmy/zarchive/multiprocessfunc.py:integratenp2,integratenp2,function,10,29,25,184,6.34,1,0,"['its', 'nchunk']","[None, None]","[None, None]",222,[],"['range', 'ne.evaluate']",2
utilmy/zarchive/multiprocessfunc.py:integratenp,integratenp,function,27,77,47,454,5.9,2,0,"['its', 'nchunk']","[None, None]","[None, None]",234,[],"['range', 'ne.evaluate', 'integratenp', 'np.sum', 'float']",5
utilmy/zarchive/multiprocessfunc.py:integratene,integratene,function,12,44,38,275,6.25,1,0,['its'],[None],[None],247,[],"['range', 'ne.evaluate', 'float']",3
utilmy/zarchive/multiprocessfunc.py:parzen_estimation,parzen_estimation,function,7,30,26,185,6.17,2,1,"['x_samples', 'point_x', 'h']","[None, None, None]","[None, None, None]",268,[],"['np.abs', 'len']",2
utilmy/zarchive/multiprocessfunc.py:init2,init2,function,2,4,4,13,3.25,0,0,['d'],[None],[None],282,[],[],0
utilmy/zarchive/multiprocessfunc.py:init_global1,init_global1,function,2,2,2,37,18.5,0,0,"['l', 'r']","[None, None]","[None, None]",286,[],[],0
utilmy/zarchive/multiprocessfunc.py:np_sin,np_sin,function,2,2,2,19,9.5,0,0,['value'],[None],[None],291,[],['np.sin'],1
utilmy/zarchive/multiprocessfunc.py:ne_sin,ne_sin,function,2,2,2,27,13.5,0,0,['x'],[None],[None],294,[],['ne.evaluate'],1
utilmy/zarchive/multiprocessfunc.py:res_shared2,res_shared2,function,4,16,14,94,5.88,0,0,[],[],[],297,[],['float'],1
utilmy/zarchive/multiprocessfunc.py:list_append,list_append,function,3,4,4,54,13.5,1,0,"['count', 'id', 'out_list']","[None, None, None]","[None, None, None]",261,"['\t""""""Creates an empty list and then appends a random number to the list \'count\' number of times. A CPU-heavy operation!""""""\n']",['range'],1
utilmy/zarchive/portfolio.py:data_jpsector,data_jpsector,function,3,4,4,47,11.75,0,0,[],[],[],37,[],['util.load_obj'],1
utilmy/zarchive/portfolio.py:date_earningquater,date_earningquater,function,9,103,42,604,5.86,0,5,['t1'],[None],[None],47,[],['datetime.datetime'],1
utilmy/zarchive/portfolio.py:date_is_3rdfriday,date_is_3rdfriday,function,4,14,13,67,4.79,0,0,['s'],[None],[None],66,[],"['datetime.strptime', 'd.weekday']",2
utilmy/zarchive/portfolio.py:date_option_expiry,date_option_expiry,function,10,50,33,354,7.08,0,2,['date'],[None],[None],71,[],['datetime.datetime'],1
utilmy/zarchive/portfolio.py:date_find_kday_fromintradaydate,date_find_kday_fromintradaydate,function,2,3,3,68,22.67,0,0,"['kintraday', 'intradaydate', 'dailydate']","[None, None, None]","[None, None, None]",88,[],['util.np_find'],1
utilmy/zarchive/portfolio.py:date_find_kintraday_fromdate,date_find_kintraday_fromdate,function,4,10,10,88,8.8,0,0,"['d1', 'intradaydate1', 'h1', 'm1']","[None, None, None, None]","[None, None, '9', '30']",92,[],"['datetime.datetime', 'util.np_find']",2
utilmy/zarchive/portfolio.py:date_find_intradateid,date_find_intradateid,function,8,13,13,96,7.38,1,0,"['datetimelist', 'stringdate']","[None, None]","[None, ""['20160420223000']""]",99,[],"['datestring_todatetime', 'util.np_find', 'str']",3
utilmy/zarchive/portfolio.py:datetime_convertzone1_tozone2,datetime_convertzone1_tozone2,function,16,29,25,343,11.83,1,1,"['tt', 'fromzone', 'tozone']","[None, None, None]","[None, ""'Japan'"", ""'US/Eastern'""]",110,[],"['pytz.timezone', 'type', 'tz.localize', 't2.append']",4
utilmy/zarchive/portfolio.py:date_extract_dailyopenclosetime,date_extract_dailyopenclosetime,function,23,51,35,431,8.45,2,3,"['spdateref1', 'market']","[None, None]","[None, ""'us'""]",127,[],"['enumerate', 'spdailyopendate.append', 'np.array', 'spdailyclosedate.append']",4
utilmy/zarchive/portfolio.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",147,[],['util.np_findfirst'],1
utilmy/zarchive/portfolio.py:date_alignfromdateref,date_alignfromdateref,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",162,[],"['range', 'np.float', 'len']",3
utilmy/zarchive/portfolio.py:_date_align,_date_align,function,16,42,33,256,6.1,2,2,"['dateref', 'datei', 'tmax', 'closei']","[None, None, None, None]","[None, None, None, None]",187,[],"['np.zeros', 'range', 'len']",3
utilmy/zarchive/portfolio.py:date_align,date_align,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",201,"["" ''' #Aligne the price with the same dates date\tyear\tmonth\tday\td\topen\tclose\thigh\tlow\tvolume\taclose '''\n""]","['range', 'np.float', 'len']",3
utilmy/zarchive/portfolio.py:min_withposition,min_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],249,[],['min'],1
utilmy/zarchive/portfolio.py:max_withposition,max_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],253,[],['max'],1
utilmy/zarchive/portfolio.py:_reshape,_reshape,function,2,14,12,68,4.86,0,1,['x'],[None],[None],259,[],"['len', 'np.reshape', 'np.size']",3
utilmy/zarchive/portfolio.py:_notnone,_notnone,function,39,211,114,1769,8.38,1,11,"['x)', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5)', 'label', ""'Time'"", ""'Y')"", 'legendloc', 'dpi', 'isband=0) ']","['  return not x is Noneasset', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None, ""('title'"", None, None, '""upper left""', '150', '0) :']",263,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend']",23
utilmy/zarchive/portfolio.py:plot_price,plot_price,function,69,272,170,2746,10.1,2,11,"['asset', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None]",267,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend', 'plot_priceintraday', 'np.loadtxt', 'np.unique', 'xdays.append', 'np.hstack', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick']",35
utilmy/zarchive/portfolio.py:plot_priceintraday,plot_priceintraday,function,32,59,57,947,16.05,1,0,['data'],[None],[None],346,[],"['np.loadtxt', 'np.unique', 'np.arange', 'xdays.append', 'np.hstack', 'plt.figure', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plt.show']",14
utilmy/zarchive/portfolio.py:plot_check,plot_check,function,8,19,19,257,13.53,0,0,"['close', 'tt0i', 'tt1i', 'dateref', 'sym', 'tickperday']","[None, None, None, None, None, None]","[None, '20140102', '20160815', '[]', '[]', '120']",388,[],"['util.find', 'getret_fromquotes', 'price_normalize100', 'plot_price']",4
utilmy/zarchive/portfolio.py:plot_pricedate,plot_pricedate,function,18,61,49,534,8.75,1,4,"['date1', 'sym1', 'asset1', 'sym2', 'bsk1', 'verticaldate', 'savename1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None', ""''"", '(10', None]",398,[],"['type', 'datestring_todatetime', 'np.row_stack', 'np.concatenate', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'np.arange', 'int', 'len', 'ax.savefig']",11
utilmy/zarchive/portfolio.py:generate_sepvertical,generate_sepvertical,function,9,13,12,149,11.46,0,1,"['asset1', 'tt', 'tmax', 'start', 'datebar']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",480,[],"['np.zeros', 'datestring_todatetime']",2
utilmy/zarchive/portfolio.py:save_asset_tofile,save_asset_tofile,function,31,129,87,978,7.58,5,9,"['file1', 'asset1', 'asset2', 'asset3', 'date1', 'title1']","[None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None']",495,[],"['np.shape', 'len', 'np.reshape', 'print', 'np.zeros', 'range', 'int', 'np.row_stack', 'np.savetxt']",9
utilmy/zarchive/portfolio.py:load_asset_fromfile,load_asset_fromfile,function,1,4,4,51,12.75,0,0,['file1'],[None],[None],534,[],[],0
utilmy/zarchive/portfolio.py:array_todataframe,array_todataframe,function,11,41,27,259,6.32,0,2,"['price', 'symbols', 'date1']","[None, None, None]","[None, 'None', 'None']",538,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/portfolio.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],549,[],[],0
utilmy/zarchive/portfolio.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],558,[],['float'],1
utilmy/zarchive/portfolio.py:isint,isint,function,32,105,61,1036,9.87,0,8,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) )Xmat', 'type1', 'type2=""correl"") ']","[' return isinstance(x', None, None, None, None, None, None, '']","[None, None, None, None, None, None, '""robust""', '""correl"") :']",566,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/portfolio.py:correlation_mat,correlation_mat,function,32,105,61,1036,9.87,0,8,"['Xmat', 'type1', 'type2']","[None, None, None]","[None, '""robust""', '""correl""']",573,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/portfolio.py:correl_reducebytrigger,correl_reducebytrigger,function,9,22,18,128,5.82,2,1,"['correl2', 'trigger']","[None, None]","[None, None]",621,"[""  ''' Put Zero below trigger  '''\n""]","['correl2.copy', 'range', 'abs']",3
utilmy/zarchive/portfolio.py:sk_cov_fromcorrel,sk_cov_fromcorrel,function,8,14,13,115,8.21,0,0,"['correl', 'ret_close1']","[None, None]","[None, None]",633,[],"['volhisto_fromret', 'np.diag', 'np.dot']",3
utilmy/zarchive/portfolio.py:cointegration,cointegration,function,18,47,37,385,8.19,0,0,"['x', 'y']","[None, None]","[None, None]",639,"['  """""" Output :\n', '    coint_t :t-statistic of unit-root test on residuals\n', ""    pvalue :   MacKinnon's approximate p-value based on MacKinnon (1994)\n"", '    crit_value : Critical values for the test statistic at the 1 %, 5 %, and 10 %  Signifiance levels.\n', '\n', '    The Null hypothesis is that there is no cointegration, the alt hypothesis is that there is cointegrating relationship. \n', '    If the pvalue is small, below a critical size:  Reject Null Hypothesis -->  Cointegration\n', '           pvalue is high --> No Cointegration    \n', '    \n', '    Significance level, also denoted as alpha or , is the probability of rejecting  the null hypothesis when it is true.\n', '    Probability of incorrectly rejecting a true null hypothesis\n', '\n', '    P=0.05  , At least 23% (and typically close to 50%)\n', '    P=0.01  , At least 7% (and typically close to 15%\n', '\n', '    (-2.9607012342275936,\n', '    0.038730981052330332, 0,\n', '    249,\n', ""    {'1%': -3.4568881317725864,\n"", ""       '10%': -2.5729936189738876,\n"", ""     '5%': -2.8732185133016057},\n"", '      601.96849256295991)\n', '        It can be seen that the calculated test statistic of -2.96 is smaller than the 5% critical value of -2.87, \n', ""        which means that we can reject the null hypothesis that  there isn't a cointegrating relationship at the 5% level.\n"", '  """"""\n']",['np.zeros'],1
utilmy/zarchive/portfolio.py:causality_y1_y2,causality_y1_y2,function,10,14,13,153,10.93,0,0,"['price2', 'price1', 'maxlag']","[None, None, None]","[None, None, None]",677,[],[],0
utilmy/zarchive/portfolio.py:reg_slope,reg_slope,function,16,24,24,261,10.88,1,0,"['close', 'dateref', 'tlag', 'type1']","[None, None, None, None]","[None, None, None, ""'elasticv'""]",685,[],"['np.ones', 'xrange', 'regression', 'np.arange']",4
utilmy/zarchive/portfolio.py:rolling_cointegration,rolling_cointegration,function,13,29,26,280,9.66,0,0,"['x', 'y']","[None, None]","[None, None]",700,[],"['rolling_coint', 'pd.expanding_apply']",2
utilmy/zarchive/portfolio.py:regression,regression,function,13,67,32,589,8.79,0,5,"['yreturn', 'xreturn', 'type1']","[None, None, None]","[None, None, '""elasticv""']",719,"["" '''Y = X* reg.coef_  +  reg.intercept_, r2 '''\n""]","['len', 'yreturn.ravel', 'xreturn.reshape', 'reg.fit', 'F', 'reg.score']",6
utilmy/zarchive/portfolio.py:regression_fixedsymbolstock,regression_fixedsymbolstock,function,30,59,54,591,10.02,1,1,"['sym', 'ret_close2', 'tsstart', 'tsample', 'ret_spy', 'spyclose', 'regonly']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, 'True']",756,"["" ''' Price, Weight, R2, Error  '''\n""]","['len', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max']",7
utilmy/zarchive/portfolio.py:regression_getpricefromww,regression_getpricefromww,function,20,38,30,298,7.84,3,0,"['spyclose', 'ww01', 'regasset01', 'ret_close2', 'tstart', 'tlag']","[None, None, None, None, None, None]","[None, None, None, None, None, '1']",779,[],"['np.copy', 'np.zeros', 'range', 'len']",4
utilmy/zarchive/portfolio.py:regression_allstocks_vs_riskfactors,regression_allstocks_vs_riskfactors,function,65,137,113,1351,9.86,2,1,"['symstock', 'pricestock', 'symriskfac', 'priceriskfac', 'nlaglist']","[None, None, None, None, None]","[None, None, None, None, None]",800,"["" '''Make Regression on all stocks ''' \n""]","['np.shape', 'print', 'np.arange', 'np.empty', 'len', 'enumerate', 'getlogret_fromquotes', 'range', 'np.reshape', 'regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",13
utilmy/zarchive/portfolio.py:getdiff_fromquotes,getdiff_fromquotes,function,4,6,6,73,12.17,0,0,"['close', 'timelag']","[None, None]","[None, None]",897,[],['np.shape'],1
utilmy/zarchive/portfolio.py:getret_fromquotes,getret_fromquotes,function,7,23,17,159,6.91,0,1,"['close', 'timelag']","[None, None]","[None, '1']",901,[],"['np.shape', 'len']",2
utilmy/zarchive/portfolio.py:getlogret_fromquotes,getlogret_fromquotes,function,4,7,7,81,11.57,0,0,"['close', 'timelag']","[None, None]","[None, '1']",912,[],"['np.shape', 'np.log']",2
utilmy/zarchive/portfolio.py:getprice_fromret,getprice_fromret,function,12,23,21,190,8.26,2,0,"['ret', 'normprice']","[None, None]","[None, '100']",917,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio.py:price_normalize100,price_normalize100,function,16,43,36,292,6.79,1,1,"['ret', 'normprice']","[None, None]","[None, '100']",929,[],"['np.shape', 'len', 'np.reshape', 'np.zeros', 'range', 'np.cumprod']",6
utilmy/zarchive/portfolio.py:price_normalize_1d,price_normalize_1d,function,8,22,19,147,6.68,0,0,"['ret', 'normprice', 'dtype1']","[None, None, None]","[None, '100', ' np.float32']",949,[],"['np.empty', 'np.cumprod']",2
utilmy/zarchive/portfolio.py:norm_fast,norm_fast,function,7,8,8,85,10.62,0,0,"['y', 'ny']","[None, None]","[None, None]",958,[],['ne.evaluate'],1
utilmy/zarchive/portfolio.py:correl_fast,correl_fast,function,8,13,13,116,8.92,0,0,"['xn', 'y', 'nx']","[None, None, None]","[None, None, None]",966,[],['ne.evaluate'],1
utilmy/zarchive/portfolio.py:volhisto_fromret,volhisto_fromret,function,2,14,11,168,12.0,0,1,"['retbsk', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",974,[],"['len', 'np.std']",2
utilmy/zarchive/portfolio.py:volhisto_fromprice,volhisto_fromprice,function,6,25,17,245,9.8,0,1,"['price', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",981,[],"['len', 'np.shape', 'np.std']",3
utilmy/zarchive/portfolio.py:volhistorolling_fromprice,volhistorolling_fromprice,function,16,42,30,318,7.57,2,1,"['price', 'volrange']","[None, None]","[None, None]",990,[],"['np.shape', 'len', 'np.zeros', 'xrange', 'volhisto_fromprice']",5
utilmy/zarchive/portfolio.py:rsk_calc_all_TA,rsk_calc_all_TA,function,51,223,105,1352,6.06,0,10,['df'],[None],"[""'panda_dataframe'""]",1009,"[""  '''Add All TA RMI, RSI To the '''\n""]","['ta.MA', 'ta.distance', 'ta.RET', 'ta.RMI', 'ta.STDDEV', 'ta.nbday_low', 'ta.nbday_high', 'ta.RSI', 'ta.qearning_dist', 'ta.optionexpiry_dist', 'linearreg2', 'np.array', 'np.sum', 'util.np_findlocalmin2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",18
utilmy/zarchive/portfolio.py:ta_highbandtrend1,ta_highbandtrend1,function,42,170,75,910,5.35,0,11,"['close2', 'type1']","[None, None]","[None, '0']",1091,[],"['linearreg', 'np.array', 'np.sum', 'util.np_findlocalmax2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",8
utilmy/zarchive/portfolio.py:pd_transform_asset,pd_transform_asset,function,11,35,27,409,11.69,0,1,"['q0', 'q1', 'type1']","[None, None, None]","[None, None, '""spread""']",1140,[],"['util.pd_date_intersection', 'util.pd_array_todataframe', 'util.pd_insertcol']",3
utilmy/zarchive/portfolio.py:calcbasket_table,calcbasket_table,function,25,59,53,477,8.08,1,2,"['wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps']","[None, None, None, None, None, None]","[None, None, '""table""', '""constant""', '1', ' 0.000']",1154,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.mod', 'np.sum']",6
utilmy/zarchive/portfolio.py:folio_createvolta_asset,folio_createvolta_asset,function,10,19,19,159,8.37,1,0,"['close', 'vol', 'volrange', 'lev']","[None, None, None, None]","[None, '0.12', '120', '1.0']",1181,[],"['np.zeros_like', 'np.shape', 'xrange', 'folio_volta']",4
utilmy/zarchive/portfolio.py:folio_lowcorrelation,folio_lowcorrelation,function,145,431,300,3894,9.03,8,7,"['sym01', 'nstock', 'periodlist', 'dateref', 'close1', 'kbenchmark', 'badlist', 'costbppa', 'showgraph']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, '0.02', 'True']",1189,[],"['ww_selection', 'np.corrcoef', 'np.nan_to_num', 'np.zeros', 'range', 'util.np_sortbycol', 'int', 'np.std', 'np.isnan', 'util.find', 'np.sum', 'stk_select.append', 'volhisto_fromret', 'sum', '1/len', 'getret_fromquotes', 'len', 'np.empty', 'np.ones', 'enumerate', 'calcbasket_table', 'price_normalize100', 'np.column_stack', 'np.zeros_like', 'np.array', 'np.concatenate', 'print', 'str', 'plot_price', 'sym01[int', 'volhisto_fromprice', 'xrange', 'folio_inverseetf']",33
utilmy/zarchive/portfolio.py:folio_leverageetf,folio_leverageetf,function,8,23,20,156,6.78,1,0,"['price', 'lev', 'costpa']","[None, None, None]","[None, '1.0', '0.0']",1327,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio.py:folio_inverseetf,folio_inverseetf,function,8,18,18,151,8.39,1,0,"['price', 'costpa']","[None, None]","[None, '0.0']",1336,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio.py:folio_longshort_unit,folio_longshort_unit,function,59,240,112,1594,6.64,2,7,"['long1', 'short1', 'ww', '-1]', 'costpa', 'tlag', 'istable', 'wwschedule']","[None, None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1', '[]']",1345,[],"['len', 'np.zeros', 'xrange', 'np.mod', 'folio_longshort_unitfixed']",5
utilmy/zarchive/portfolio.py:folio_longshort_unitfixed,folio_longshort_unitfixed,function,43,111,73,719,6.48,1,3,"['long1', 'short1', 'nn', '-1]', 'costpa', 'tlag', 'istable']","[None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1']",1386,[],"['len', 'np.zeros', 'xrange', 'np.mod']",4
utilmy/zarchive/portfolio.py:folio_longshort_pct,folio_longshort_pct,function,8,21,20,189,9.0,1,0,"['long1', 'short1', 'ww', '-1]', 'costpa']","[None, None, None, None, None]","[None, None, '[1', None, '0.0']",1424,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio.py:folio_histogram,folio_histogram,function,13,75,41,914,12.19,0,0,['close'],[None],[None],1432,[],"['getret_fromquotes', 'plt.subplots', 'np.ones_like', 'ax2.hist', 'ax2.set_title', 'ax2.set_xlabel', 'ax2.set_ylabel', 'ax2.axvline', 'plt.show', 'print']",10
utilmy/zarchive/portfolio.py:folio_voltarget,folio_voltarget,function,2,6,6,61,10.17,0,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1460,[],['folio_volta'],1
utilmy/zarchive/portfolio.py:folio_volta,folio_volta,function,54,197,112,1663,8.44,2,8,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1464,[],"['folio_volta', 'len', 'np.shape', 'np.zeros', 'range', 'np.std', 'util.findhigher', 'max', 'min', 'folio_volta2', 'np.abs']",11
utilmy/zarchive/portfolio.py:folio_volta2,folio_volta2,function,29,61,54,514,8.43,1,2,"['bsk', 'riskind', 'par', 'targetvol', 'volrange', 'cap', 'floor', 'costbp']","[None, None, None, None, None, None, None, None]","[None, None, None, '0.11', ' 90', '1.5', '0.0', '0.0005']",1503,[],"['np.shape', 'np.zeros', 'range', 'np.std', 'max', 'min', 'np.abs']",7
utilmy/zarchive/portfolio.py:folio_fixedunitprice,folio_fixedunitprice,function,13,36,33,221,6.14,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1528,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio.py:folio_fixedweightprice,folio_fixedweightprice,function,13,36,33,225,6.25,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1542,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio.py:folio_fixedweightret,folio_fixedweightret,function,13,31,28,193,6.23,2,0,"['ret', 'fixedww']","[None, None]","[None, None]",1554,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio.py:folio_cost_turnover,folio_cost_turnover,function,26,88,71,825,9.38,1,1,"['wwall', 'bsk', 'dateref', 'costbp']","[None, None, None, None]","[None, None, None, None]",1567,[],"['len', 'np.zeros', 'xrange', 'np.sum', 'plot_price', 'date1=dateint_tostring']",6
utilmy/zarchive/portfolio.py:folio_riskpa,folio_riskpa,function,20,52,40,422,8.12,2,0,"['ret', 'targetvol', 'volrange', 'cap']","[None, None, None, None]","[None, '0.1', '90', '1.0']",1597,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.sum', 'np.std', 'min', 'list']",8
utilmy/zarchive/portfolio.py:folio_perfreport_schedule,folio_perfreport_schedule,function,14,20,19,189,9.45,1,0,"['sym', 'dateref', 'close', 'wwind', 't0', 'scheduleperiod']","[None, None, None, None, None, None]","[None, None, None, None, None, '""1monthend""']",1911,[],"['np.shape', 'generate_schedule', 'np.zeros', 'enumerate']",4
utilmy/zarchive/portfolio.py:folio_concenfactor2,folio_concenfactor2,function,7,12,12,103,8.58,0,0,"['ww', 'masset']","[None, None]","[None, '12']",2211,[],"['getweight', 'np.sum', 'np.mean']",3
utilmy/zarchive/portfolio.py:calcbasket_objext,calcbasket_objext,function,50,203,96,1094,5.39,1,7,"['RETURN', 'TMAX', 'riskind_i', 'wwmat', 'wwasset0', 'ww0', 'nbrange', 'criteria']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",2229,[],"['xrange', 'np.sum', 'math.sqrt']",3
utilmy/zarchive/portfolio.py:calc_ranktable,calc_ranktable,function,20,44,41,351,7.98,1,0,"['close2', 'symjp1', 'nlag', 'refindex', 'funeval', 'funargs']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",3639,[],"['np.zeros', 'getlogret_fromquotes', 'enumerate', 'funeval', 'util.np_sortbycolumn']",5
utilmy/zarchive/portfolio.py:similarity_correl,similarity_correl,function,7,10,9,88,8.8,0,0,"['ret_close2', 'funargs']","[None, None]","[None, None]",3659,[],['correlation_mat'],1
utilmy/zarchive/portfolio.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3714,[],['np_distance_l1'],1
utilmy/zarchive/portfolio.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3720,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/portfolio.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3714,[],['np_distance_l1'],1
utilmy/zarchive/portfolio.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3720,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/portfolio.py:get,get,function,11,44,26,436,9.91,0,1,"['close', 'timelag']","[None, None]","[None, None]",4085,"['    """"""Return dataframe of requested dataset from Quandl.\n', '    :param dataset: str or list, depending on single dataset usage or multiset usage\n', '            Dataset codes are available on the Quandl website\n', '    :param str api_key: Downloads are limited to 50 unless api_key is specified\n', '    :param str start_date, end_date: Optional datefilers, otherwise entire dataset is returned\n', '    :param str collapse: Options are daily, weekly, monthly, quarterly, annual\n', '    :param str transform: options are diff, rdiff, cumul, and normalize\n', '    :param int rows: Number of rows which will be returned\n', '    :param str order: options are asc, desc. Default: `asc`\n', '    :param str returns: specify what format you wish your dataset returned as,\n', '        either `numpy` for a numpy ndarray or `pandas`. Default: `pandas`\n', '    :returns: :class:`pandas.DataFrame` or :class:`numpy.ndarray`\n', '    Any other `kwargs` passed to `get` are sent as field/value params to Quandl\n', '    with no interference.\n', '\n', ""'''\n"", '\n', '\n', '\n', '#--------------------Import data from Yahoo --------------------------------------------------\n', 'def imp_yahoo_getquotes(symbols, start=""20150101"", end=""20160101"", type1=1):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', '# symbols = np.array(symbol1)\n', ' quotes= []; errorlist=[]; correctlist=[]\n', ' for i, symbol in enumerate(symbols) :\n', '   # if np.mod(i,400) ==0 and i != 0 :\n', ""     # print('Waiting 30s'); time.sleep(30)\n"", '   try:   \n', '     array1= quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '     df= pd.DataFrame.from_records(array1)\n', '     quotes.append(df)\n', '     correctlist.append(symbol)\n', '   except :\n', '       errorlist.append(symbol)\n', ""       print('Err: '+symbol)\n"", ' #quotes = [quotes_historical_yahoo(symbol, d1, d2, asobject=True)  for symbol in symbols]\n', ' #print(errorlist) \n', ' if type1==1 :  return quotes, correctlist\n', ' else: return quotes, correctlist, errorlist  \n', '\n', '              \n', '#Find error in Ticker import\n', 'def imp_yahoo_geterrorticker(symbols, start=""20150101"", end=""20160101""):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', ' errorlist= []\n', ' for symbol in symbols :\n', '   try :  \n', '     quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '   except :\n', '     errorlist.append(symbol)\n', '     print(symbol)       \n', ' return errorlist\n', ' \n', ""'''\n"", ""symbols0= ['KHC', 'PYPL', 'HPE', 'BXLT', 'SYF', 'WLTW', 'CFG', 'BF-B', 'WRK']\n"", '\n', '#Show list of ticker in error\n', 'import_errorticker(symbols0,""20110101"",""20150601""  )\n', ""'''\n"", '\n', '\n', 'def imp_yahoo_financials_url(ticker_symbol, statement=""is"", quarterly=False):\n', '    if statement == ""is"" or statement == ""bs"" or statement == ""cf"":\n', '        url = ""https://finance.yahoo.com/q/"" + statement + ""?s="" + ticker_symbol\n', '        if not quarterly:\n', '            url += ""&annual""; return BeautifulSoup(requests.get(url).text, ""html.parser"")\n', '    return sys.exit(""Invalid financial statement code \'"" + statement + ""\' passed."")\n', '\n', 'def imp_yahoo_periodic_figure(soup, yahoo_figure):\n', '    values = []; pattern = re.compile(yahoo_figure)\n', '\n', '    title = soup.find(""strong"", text=pattern)    # works for the figures printed in bold\n', '    if title:  row = title.parent.parent\n', '    else:\n', '        title = soup.find(""td"", text=pattern)    # works for any other available figure\n', '        if title:  row = title.parent\n', '        else:      sys.exit(""Invalid figure \'"" + yahoo_figure + ""\' passed."")\n', '\n', '    cells = row.find_all(""td"")[1:]    # exclude the <td> with figure name\n', '    for cell in cells:\n', '        if cell.text.strip() != yahoo_figure:    # needed because some figures are indented\n', '            str_value = cell.text.strip().replace("","", """").replace(""("", ""-"").replace("")"", """")\n', '            if str_value == ""-"": str_value = 0\n', '            value = int(str_value) * 1000\n', '            values.append(value)\n', '\n', '    return values\n', '    \n', '# print(imp_yahoo_periodic(imp_yahoo_financials_url(""AAPL"", ""is""), ""Income Tax Expense""))\n', '\n', ' \n', '\n', '#--------------------Import Quotes Google  ------------------------------------------\n', 'import requests.packages.urllib3\n', 'requests.packages.urllib3.disable_warnings()\n', 'import urllib, os\n', '\n', ""dirstockcsv= 'E:\\_data\\stock\\csv'\n"", '\n', 'def imp_googleIntradayQuote(symbol, freqsec=300, nday=5):\n', ""    ''' Intraday quotes from google. Specify interval seconds and number of days\n"", '    http://www.google.com/finance/getprices?q=7261&i=300&p=3d&f=d,o,h,l,c,v\n', ""    '''\n"", '    url =""http://www.google.com/finance/getprices?q={0}"".format(symbol)\n', '    url +=""&i={0}&p={1}d&f=d,o,h,l,c,v"".format(freqsec, nday)\n', '    try :      \n', '       resp= requests.post(url)\n', '       csv= resp.text\n', '       csv= csv.splitlines()\n', '    except :\n', ""       print('Err Intaday '+symbol)\n"", '\n', '    if len(csv) < 9 :\n', ""      print 'Using Daily',\n"", '\n', ""      url='http://www.google.com/finance/historical?q='+symbol+'&i='+str(freqsec)+'&p=3d&f=d,o,h,l,c,v&output=csv'\n"", '      csv = urllib.urlopen(url).readlines()\n', '      csv.reverse()\n', '      q=[]\n', '      for bar in xrange(0,len(csv)-1):\n', ""        ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '        if isfloat(open_) and isfloat(high) :\n', '          open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""          dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '          q.append([dt,open_,high,low,close,volume])\n', ""      df= util.pd_array_todataframe(q, ['date','open','high','low','close','volume'])\n"", '      return df\n', '\n', '\n', '    # print(csv)\n', '    qq=[]\n', '    for bar in xrange(7,len(csv)):\n', ""      if csv[bar].count(',')!=5: continue\n"", ""      offset,close,high,low,open_,volume = csv[bar].split(',')\n"", '      \n', ""      if offset[0]=='a':\n"", '        day = float(offset[1:])\n', '        offset = 0\n', '      else:\n', '        offset = float(offset)\n', '      open_, high, low, close = [float(x) for x in [open_,high,low,close]]\n', '      dt = datetime.datetime.fromtimestamp(day + (freqsec * offset))\n', '      #print (dt,open_,high,low,close,volume)\n', '      qq.append([dt,open_,high,low,close,volume])\n', ""    df= util.pd_array_todataframe(qq, ['date','open','high','low','close','volume'])\n"", '    return df\n', '\n', ""def imp_googleIntradayQuoteSave(symbols=['NKE'], freqsec=300, nday=2000, dircsv='', dbname=''):\n"", "" ''' Save Under various format: csv / db / output in Dataframe '''\n"", ' if isinstance(symbols, str) : symbols= [symbols]\n', ' symout,qlist, sym_error= [], [], []\n', ' for sym in symbols:\n', '   try :\n', '    q = imp_googleIntradayQuote(sym, freqsec, nday)  #interval, timeframe\n', '    print sym,\n', ""    sym= sym.replace(':', '_')\n"", '\n', ""    if dircsv != '' :\n"", '      if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""      start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""      file1= dircsv+ '\\\\' + sym + '_' + str(start1) + '_' + str(freqsec) + '_' + str(nday) + '.csv'\n"", '\n', ""      q= util.pd_addcol(q, 'symbol'); q['symbol']= sym\n"", '      q.to_csv(file1, index=False)\n', '\n', ""    elif dbname != '' :\n"", '      import sqlalchemy as sql\n', '      dbcon= sql.create_engine(dbname)\n', '      if interv_sec== 300 : # 5mins\n', ""        q.to_sql('q5min', dbcon)\n"", '\n', '    else :\n', '      qlist.append(q);   symout.append(sym)\n', '   except:\n', ""      print('Error:'+sym, )\n"", '      sym_error.append(sym)\n', '\n', ' return qlist, symout, sym_error\n', '\n', ""def imp_googleQuote(symbol, start_date='20160101', end_date= '20160101') : # datetime.date.today().isoformat()):\n"", ""    ''' Daily quotes from google. Date format='yyyymmdd' '''\n"", '    symbol = symbol.upper()\n', '    start = datetime.date(int(start_date[0:4]),int(start_date[4:6]),int(start_date[6:8]))\n', '    end =   datetime.date(int(end_date[0:4]),int(end_date[4:6]),int(end_date[6:8]))\n', '    url =""http://www.google.com/finance/historical?q={0}"".format(symbol)\n', '    url +=""&startdate={0}&enddate={1}&output=csv"".format( start.strftime(\'%b %d, %Y\'),end.strftime(\'%b %d, %Y\'))\n', '    csv = urllib.urlopen(url).readlines()\n', '    csv.reverse()\n', '    # print(url)\n', '    q=[]\n', '    for bar in xrange(0,len(csv)-1):\n', ""      ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '      if isfloat(open_) and isfloat(high) :\n', '        open_,high,low,close = [float(x) for x in [open_, high, low, close]  ]\n', ""        dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '        q.append([dt,open_,high,low,close,volume])\n', '    return  pd.DataFrame(np.array(q), columns= [""date"",""open"",""high"",""low"",""Close"",""volume""])\n', '\n', '\n', 'def imp_googleQuoteSave(symbols, date1, date2, dircsv):\n', ' if isinstance(symbols, str) : symbols= [symbols]\n', ' for sym in symbols:\n', '   try :\n', '      q = imp_googleQuote(sym, date1, date2)   #interval, timeframe\n', ""   except: print('Error:'+symbol)\n"", '\n', ""   sym= sym.replace(':', '_')\n"", '\n', ""   if dircsv != '' :\n"", '     if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""     start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""     file1= dircsv+ '\\\\'+ name1+'_'+ start1 +'_'+ str(date2) +'.csv'\n"", '     q.to_csv(file1)\n', '\n', ""   if dbname != '' :\n"", '     import sqlalchemy as sql\n', '     dbcon= sql.create_engine(dbname)\n', '     if interv_sec== 300 : # 5mins\n', ""       q.to_sql('q5min', dbcon)\n"", '\n', '\n', '\n', ""def imp_csv_dbupdate(indir='E:/_data/stock/intraday/intraday_google_usetf2.h5',\n"", ""                     outdir='E:/_data/stock/intraday/q5min/us/etf/', filelist=[], intype='csv',\n"", ""                     refcols=['date', 'open', 'high', 'low', 'close', 'volume', 'symbol']) :\n"", '\n', '  for file1 in filelist :\n', ""    sym=  file1[:file1.find('_')]  #Clean Up name\n"", '    print sym,\n', ""    outfile= outdir+'/'+sym+'.csv'\n"", '    if os.path.isfile(outfile) :\n', ""      df0= imp_csv_toext(file1=outfile, fromzone='Japan', tozone='UTC', header=0, cols=refcols)\n"", '    else :\n', '      df0= None\n', '\n', ""    if intype== 'hdfs':\n"", '      df1= imp_hdfs_getquote(indir, sym)\n', '      if isinstance(df1, float) : df1= None\n', '\n', ""    if intype=='csv' :\n"", ""      infile= indir+'/'+ file1   #csv\n"", ""      df1= imp_csv_toext(file1=infile, header=0, cols=refcols, fromzone='Japan', tozone='UTC')\n"", '\n', '    if df1 is not None :\n', '       if df0 is not None  : df1= imp_pd_merge(df1[refcols], df0[refcols])\n', '       # return outfile, df1\n', '       df1[refcols].to_csv(outfile, index=False)\n', '\n', '\n', '#####################################################################################\n', 'def imp_numpy_close_fromdb(dbname=\'/aaserialize/store/yahoo.db\', table1=\'\', symlist=[], t0=20010101, t1=20010101, priceid=""close"", batchsize= 400, maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from DB SQL"")\n', ' import data.hist_data_storage as yhh\n', ' dstore= yhh.dailyDataStore(dbname)\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', '\n', "" dateref0= dstore.get_histo(['SPY'], table1='daily_us_etf', start1=str(t0), end1=str(t1),  split_df=0).date.values\n"", ' \n', ' k=0; symfull=[];   i=0\n', ' nsym= len(symlist); nbatch= int(nsym / batchsize)+1\n', ' for j in xrange(0, nbatch) : \n', '      qlist, sym= dstore.get_histo(symlist[i:min(nsym,i+batchsize)], table1=table1, start1=str(t0), end1=str(t1),  split_df=1)\n', '\n', '      #print(""batch: ""+str(j), len(qlist), len(qlist[0].index) )\n', '      #for k,q in enumerate(qlist) :print sym[k], len(q.index)\n', '      i= i + batchsize\n', '      symfull= np.concatenate((symfull,sym))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)\n', '      print(""batch: ""+str(j), len(sym),dateref[0],dateref[-1] )\n', '      qlist=None; sym=None\n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[k:k+masset,0:tmax] = close\n', '      k=k+ masset\n', '\n', ' maxasset= k\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', 'def imp_numpy_close_fromhdfs(dbfile, symlist=[], t0=20010101, t1=20010101, priceid=""close"", maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from Pandas"")\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', ' store = pd.HDFStore(dbfile)\n', ' \n', "" df= store.select('SPY')\n"", ' df= df[(df.date >= t0) & (df.date <= t1 )]\n', ' dateref0= df.date.values\n', ' \n', ' k=0; symfull=[]; qlist=[]; sym=[]; tmax= 2000\n', ' for j, symbol in enumerate(store.keys()):\n', '  symbol=  symbol[1:]\n', '\n', '  if len(symlist)==0  or  util.find(symbol,symlist) > -1 : \n', '   #print symbol, util.find(symbol,symlist) \n', '   df= store.select(symbol) \n', '   if t0 !=t1 :     df= df[(df.date >= t0) & (df.date <= t1 )]\n', '   \n', '   qlist.append(df);   sym.append(symbol)\n', '   if np.mod(j+1, 401) == 0 :\n', '      print(""batch: ""+str(j))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)   \n', '      print len(sym),dateref[0],dateref[-1] \n', '      symfull= symfull+sym\n', '      qlist=[]; sym=[]\n', ' \n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[(k):(k+masset),0:tmax] = close\n', '      k=k+ masset   \n', '     \n', ' if len(qlist) > 0:\n', '  # return qlist, qlist[0] ,  qlist[1] \n', '   close,dateref= date_align(qlist,type1=priceid)   \n', '   print len(sym),dateref[0],dateref[-1] \n', '   symfull= symfull+sym\n', '   masset,tmax= np.shape(close);\n', '   close2[(k):(k+masset),0:tmax] = close\n', ' \n', ' maxasset= k+masset\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', '\n', ""def imp_sql_getquotes(stocklist01, dbname='sqlite:///aaserialize/store/yahoo.db', start1=20150101, end1=20160616, table1='daily_us_stock'):\n"", '    import data.hist_data_storage as yhh\n', '    dstore = yhh.dailyDataStore(dbname)\n', '    qlist, sym= dstore.get_histo(stocklist01, table1=table1,  start1=start1, end1=end1, split_df=1)\n', '    return qlist, sym\n', '\n', ""def imp_txt_getquotes(stocklist01, filedir='E:/_data/stock/daily/20160610/jp', startdate=20150101, endate=20160616):\n"", ' liststockfile= util.listallfile(filedir, ""*.txt"", dirlevel=5)\n', ' #print liststockfile\n', ' if len(np.shape(liststockfile)) > 1 :\n', '  liststockname=[ x.split(""."")[0] for x in liststockfile[:,0] ]\n', '#  for k in range(0, np.shape(liststockfile)[0]):  liststockname.append( (liststockfile[k,0])[0:4])   \n', '   \n', ' else: \n', '  stk0= liststockfile[0]; #stk2= liststockfile[2]\n', '#  liststockname=[ x[0:4] for x in stk0 ]\n', '  liststockname=[ x for x in stk0 ]\n', '\n', '#  liststockname=[]\n', '#  for k in range(0, len(stk0)):  liststockname.append( (stk0[k])[0:4])\n', ' \n', ' quotes=[]\n', ' print liststockname\n', ' for sym in stocklist01:\n', '   kstock= util.np_findfirst(sym, liststockname)\n', '   if kstock == -1 :\n', ""     print('Not Found '+sym)\n"", '   else :\n', '     df= pd.read_csv(liststockfile[kstock][2])\n', ""     df.columns = ['date', 'open', 'high','low','close', 'volume', 'openint']  #Change Column Name\n"", '     df2= df[(df.date > startdate  )& ( df.date   < endate )] # Filter by date\n', '     quotes.append(df2)\n', '  \n', ' return quotes \n', '\n', '\n', 'def imp_csv_getname(name1, date1, inter, tframe):\n', "" file1= dirstockcsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", ' return file1\n', '\n', '\n', ""def imp_csv_toext(file1='SPY.csv', outputfile='.h5', fromzone='Japan', tozone='UTC', header=None,\n"", ""                  cols=['date', 'time','open','high','low','close','volume', 'symbol'], coldate=[0]):\n"", ""  ''' cols: column name,  coldate: position of date column   '''\n"", '  from dateutil import parser\n', '\n', '  if os.path.getsize(file1)> 500 :\n', ""   df = pd.read_csv(file1,sep=',',header=header)  # date_parser=dateparse)  # parse_dates={'date': [] },\n"", '   df.date= [ parser.parse(x) for x in  df.date]\n', '\n', ""   #if util.find('symbol', df.columns.values) < 0 :\n"", ""     #df= util.pd_addcol(df, 'symbol')\n"", ""     #df['symbol']= sym\n"", '\n', ""   type1= outputfile[outputfile.find('.'):]\n"", '\n', ""   if outputfile=='':\n"", '     # df.columns = [  x.lower() for x in df.columns.values ]\n', ""     # df.columns = ['date', 'symbol','open','high','low','close','volume']\n"", '     df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""     df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""     df.columns = ['date', 'open','high','low','close','volume', 'symbol']\n"", '     return df[cols]\n', '\n', ""   if type1=='csv' :\n"", ""     df[cols].to_csv(outputfile , index=False)  # , compression='gzip' )\n"", '\n', ""   if type1== 'h5' :\n"", ""      # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '      dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '      # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '      # df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '      # df.date= [x.to_datetime() for x in  df.date]\n', '\n', '      df.drop(df.columns[[0]], axis=1, inplace=True)\n', '      print filenameh5\n', ""      if util.find('symbol', df.columns.values) < 0 :\n"", ""         df= util.pd_addcol(df, 'symbol'); df['symbol']= dfname\n"", '      store = pd.HDFStore(outputfile); store.append(dfname, df);  store.close()\n', '\n', '\n', '\n', ""def imp_hdfs_db_updatefromcsv(dircsv, filepd=r'E:\\_data\\stock\\intraday_google.h5', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= filepd + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2, name1, fromtimezone, tozone)\n', '\n', ""def imp_hdfs_db_dumpinfo(dbfile='E:\\_data\\stock\\intraday_google.h5'):\n"", '  store = pd.HDFStore(dbfile)\n', '  extract=[]; errsym=[]\n', '  for symbol in store.keys():\n', '     try:\n', '       df= pd.read_hdf(dbfile, symbol)\n', ""       t0= df['date'].values[0]\n"", ""       t1= df['date'].values[-1]\n"", '\n', '       extract.append([symbol[1:], df.shape[1],   df.shape[0], t0, t1 ])\n', '\n', '     except: errsym.append(symbol)\n', '  return np.array(extract), errsym\n', '\n', 'def imp_hdfs_mergedb(filepdfrom, filepdto) :\n', '  store0 = pd.HDFStore(filepdfrom)\n', '  store1 = pd.HDFStore(filepdto)\n', '\n', '  for symbol in store0.keys():\n', '    qq= imp_hdfs_getquote(filepdfrom, symbol)\n', '    store1.append(symbol, qq)\n', '\n', '    qq= imp_hdfs_getquote(filepdto, symbol)\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    print(symbol)\n', '  store0.close(); store1.close()\n', '\n', ""def imp_hdfs_storecopy(hdfs1='F:/usstock8.h5', hdfs2='F:/usstock8.h5'):\n"", ' store = pd.HDFStore(hdfs1);  store2 = pd.HDFStore(hdfs2)\n', ' for symbol in store.keys() :\n', '   df= imp_hdfs_getquote(hdfs1, symbol)\n', '   symbol= symbol[1:].replace(""-"",""_"")\n', '   store2.append(symbol, df, data_columns=True)\n', ' store.close(); store2.close()\n', '\n', 'def imp_hdfs_getquote(filenameh5, dfname=""data""):\n', '  try: return  pd.read_hdf(filenameh5, dfname)\n', '  except: return -1.0;\n', '\n', ""def imp_hdfs_getListquote(symbols, close1='close', start='12/18/2015 00:00:00+00:00',\n"", ""                          end='3/1/2016 00:00:00+00:00', freq='0d0h10min', filepd= 'E:\\_data\\stock\\intraday_google.h5',\n"", ""                          tozone='Japan', fillna=True, interpo=True):\n"", '\n', ' datefilter= pd.date_range(start=start, end=end, freq= freq,tz=tozone).values\n', '\n', ' errorsym=[]; quotes=[]; correctsym=[]\n', ' for symbol in symbols:  # Issue Not same size\n', '   qq= imp_hdfs_getquote(filepd, symbol)\n', '\n', '   if type(qq)==np.float :  # Error qq=-1\n', '        errorsym.append(symbol)\n', '   else:\n', ""       qq.columns = ['date', 'symbol','open','high','low','close','volume']\n"", ""       qq= qq[qq['date'].isin(datefilter)]   #Only date in the range\n"", ""       #qq= qq.drop_duplicates(cols='date', take_last=True)\n"", ""       #  qq= qq.sort('date', asc=True)\n"", '\n', '       #print qq.date.values[0]\n', ""       if fillna : qq= qq.fillna(method='backfill')\n"", '       if interpo : qq= qq.interpolate()\n', '       quotes.append(qq)\n', '       correctsym.append(symbol)\n', '\n', ' datefilter= datenumpy_todatetime(datefilter)\n', ' return quotes,datefilter, correctsym,   errorsym\n', '\n', '\n', ""def imp_hdfs_removeDuplicate(filepd='E:\\_data\\stock\\intraday_google.h5') :\n"", '  #-------Clean by removing duplicate-------------------------------------------------\n', '  store = pd.HDFStore(filepd)\n', '  for symbol in store.keys():\n', '    #qq= imp_hdfs_getquote(filepd, symbol);\n', '    qq= store.select(symbol[1:])\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    qq.index = list(np.arange(0,len(qq.index)))\n', '\n', '    store.remove(symbol); store.append(symbol, qq);\n', '  store.close()\n', '\n', '\n', '\n', ""def imp_pd_tohdfs(sym, qqlist, filenameh5, fromzone='Japan', tozone='UTC') :\n"", ""  ''' df list to HDFS '''\n"", '  store = pd.HDFStore(filenameh5);\n', '  for k, df2 in enumerate(qqlist) :\n', '    df= copy.deepcopy(df2)\n', ""    df['date']= datetime_toint(df.date.values)\n"", '\n', ""    symbol= sym[k].replace('-','_')\n"", '    qq= imp_hdfs_getquote(filenameh5, symbol)\n', '    # print symbol, type(qq)\n', '    if type(qq) ==  float or  type(qq) ==  int  :\n', '      store.append(symbol, df)  # , data_columns=True\n', '      # print(symbol + str(df.date.values[-1]))\n', '    else :\n', '      qq= pd.concat([qq, df], ignore_index=True)\n', ""      qq= qq.drop_duplicates(subset='date', keep='last')\n"", ""      qq= qq.sort('date', ascending=1)\n"", '      store.append(symbol, qq)  #Too much space , data_columns=True\n', '      print(symbol + str(qq.date.values[-1]))\n', '\n', '  store.close()\n', '\n', 'def imp_pd_merge(df1, df2) :\n', '  df= pd.concat([df1, df2], axis=0)\n', ""  df= df.drop_duplicates(subset='date', keep='last')\n"", ""  df= df.sort_values(by=['date'], ascending=1)\n"", '  df.index = list(np.arange(0,len(df.index)))\n', '  return df\n', '\n', 'def imp_pd_checkquote(quotes) :\n', ""   for c in quotes: print np.shape(c), c['date'].values[0], c['date'].values[-1]\n"", '\n', 'def imp_pd_getclose(df, datefilter=None):\n', ' if datefilter is  not None :\n', ""    df= df[df['date'].isin(datefilter)]   #Only date in the range\n"", "" df= df.sort('date')\n"", "" close= df.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", ' \n', ' close= np.array(close.values[1:,1:]).astype(np.float)            #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close\n', '\n', 'def imp_pd_cashyield(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  100 * np.cumprod( (1 + np.ones(len(vv)) * 0.005/365.0 ))\n', '     qbond[id1]= pbond\n', '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_yield_tobond(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  1/ np.power(1+ vv*0.01,duration) *100\n', '     qbond[id1]= pbond\n', ""#     print 'ok'\n"", '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_errordate(quotes, dateref):\n', "" ''' Show Symbol in Error when importing '''\n"", ' for i, stock in enumerate(quotes) :\n', '   print(i, symbols1[i],  datetime_tostring(stock[0][0]))\n', ' print(""\\n\\n"")\n', '\n', ' for i, stock in enumerate(quotes) :\n', '   date1= datetime_toint(stock[0][0])\n', '   if date1 != dateref : print(i, symbols1[i],  str(date1))\n', '\n', 'def imp_pd_fxtoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', 'def imp_pd_fxinversetoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(1.0 / q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', ""def imp_pd_filterbydate(df, dtref=None, start='2016-06-06 00:00:00', end='2016-06-14 00:00:00', freq='0d0h05min', timezone='Japan'):\n"", "" ''' df: DateSeries or TimeSeries of Quotes   '''\n"", '\n', ' if type(df) in {pd.core.frame.DataFrame} :  #Data frame version\n', '   if type(dtref)== str:\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', ""   return df[df['date'].isin(dtref)]\n"", ' else :\n', '   if type(dtref)== str:  #Date version\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', '   return df[df.isin(dtref)].values\n', '\n', 'def imp_pd_cleanquote(q):\n', ' col= q.columns.values\n', "" if isinstance(q['date'].values[0] , str) :\n"", ""   q['date']= datetime_todate(datestring_todatetime(q['date'].values))\n"", '\n', ' for kid in col:\n', ""   if kid not in ['date', 'day','month','year'] :\n"", ""      q[kid]= pd.to_numeric(q[kid], errors='coerce').values  #Put NA on string\n"", '\n', "" q= q.fillna(method='pad')\n"", ' return q\n', '\n', 'def imp_pd_divide(q1, q2, funapply):\n', "" close, dateref= date_align([q1,q2], type1='close')\n"", ' m,tt= np.shape(close)\n', '\n', ' q3= util.pd_createdf( np.zeros((tt,len(q1.columns))) ,q1.columns, dateref)\n', "" q3['date']= dateref\n"", "" q3['close']= (close[0,:] / close[1,:])\n"", '\n', ' for kid in q1.columns :\n', ""   if kid not in ['close', 'volume','date','day','month', 'year'] :\n"", '     close, _= date_align([q1,q2], type1=kid)\n', '     q3[kid]= (close[0,:] / close[1,:])\n', ' return q3\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""def imp_quote_csvdir_tofile(dircsv='', outdir1='E:/_data/stock/', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= outdir + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2,  header=True, fromzone=fromtimezone, tozone=tozone)\n', ""'''\n"", '\n', '\n', ""'''\n"", ""close1='Close' ; start='12/18/2015 00:00:00';\n"", ""end='3/1/2016 00:00:00'; freq='1d0h00min';\n"", ""filepd= 'E:\\_data\\stock\\intraday_google.h5'\n"", '\n', 'datefilter= pd.date_range(start=start, end=end,   freq= freq).values\n', '\n', 'symbols, names = np.array(list(symbol_dict.items())).T\n', 'i=0; vv=[]\n', 'for symbol in symbols:  # Issue Not same size\n', '   qq= quote_frompanda(filepd, symbol); i+=1\n', '   if isfloat(qq) :  vv.append(symbol)\n', '   else:\n', ""     if i==1: close = qq[['Datetime']]  #new dataframe    \n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', '     if not tmp.isnull().values.all():\n', ""      close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""      close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', ""close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", ""close= close.sort('Datetime')\n"", ""close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", 'close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', 'close= close[(np.abs(stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', ""'''\n"", 'from datetime import datetime\n', 'from dateutil import tz\n', '\n', ""from_zone = tz.gettz('Japan'); to_zone = tz.gettz('UTC')\n"", '\n', ""date1 = datetime.strptime('2011-01-21 09:00:00', '%Y-%m-%d %H:%M:%S')\n"", 'date1 = date1.replace(tzinfo=from_zone)\n', 'dateutc = date1.astimezone(to_zone)\n', 'date1, dateutc\n', '\n', ""Suppose you have a column 'datetime' with your string, then:\n"", ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\n"", ' combine multiple columns into a single datetime column,\n', ""this merges a 'date' and a 'time' column into a single 'datetime' column:\n"", '\n', ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)\n"", ""'''\n"", '\n', '\n', '#date1 = ""20160302""; inter= 60; tframe=80; name1= ""spy""\n', '#googleIntradayQuoteSave(name1, inter, tframe)\n', '\n', '\n', '\n', 'def ta_mar(close,t,m):  return  100*( np.mean(close[(t-m):(t+1)], axis=0) / close[t] )\n', 'def ta_ma(close,t,m):  return   np.mean(close[(t-m):(t+1)], axis=0)\n', '\n', '\n', '############################################################################\n', '#---------------------Calculate the Statistics         --------------------  \n', 'def calc_statestock(close2, dateref, symfull):\n', ' def sort(x,col,asc): return   util.sortcol(x,col,asc)\n', ' def perf(close,t0,t1):  return  100*( close[:,t1] / close[:,t0] -1)\n', ' def and2(tuple1):  return np.logical_and.reduce(tuple1)\n', ' def mar(close,t,m):  return  100*( np.mean(close[:,(t-m):(t+1)], axis=1) / close[:,t] )\n', ' def ma(close,t,m):  return   np.mean(close[:,(t-m):(t+1)], axis=1)\n', '\n', '\n', ' # a= ma(close2, tmax, 5) / ma(close2, tmax, 50)  \n', '\n', '\n', ' def dd(t) :\n', '  x= util.find(t,dateref)  # 607\n', ""  if x==-1 : print 'Error date not found in dateref '+str(t) ; return np.nan\n"", '  else :  return x\n', '\n', ' def gap(close,t0,t1,lag):   \n', '  ret= getret_fromquotes(close[:,t0:t1],lag)\n', '  rmin= 100*np.amin(ret,axis=1)\n', '  return rmin\n', ' \n', ' #--------------------Size----------------------------------------- \n', ' masset= len(symfull)\n', ' ttmax= util.find(0,close2[0,:])\n', ' if ttmax==-1 : ttmax= np.shape(close2)[1]\n', ' close2= close2[0:masset,0:ttmax]\n', ' m, tmax= masset, ttmax-1\n', ' \n', ' #correl\n', ' #close3= np.array(close2[:,0:ttmax],dtype=np.float16)\n', ' #close2ret= getret_fromquotes(close3)\n', ' #close2ret= np.nan_to_num(close2ret)\n', ' #close2ret= util.np_cleanmatrix(close2ret);  del close3\n', '\n', '##################################################################################\n', '#1: 1d,2:5d,3:10d,4:15d,5:20d,11:50d,12:60d,13:90d,15:1y\n', '#16: YTD,17:From Feb,21: 2015Ret,45: Price,50,51: Min,52,53: Max\n', ' print(""Calcul the Stats "" + str(dateref[-1]))\n', ' stat= np.zeros((2600,200),dtype=np.float16)\n', '\n', ' k=0\n', ' stat[k:(k+m),0]= np.arange(k,k+m)\n', ' stat[k:(k+m),1]=  perf(close2,tmax-1,tmax)  \n', ' stat[k:(k+m),2]=  perf(close2,tmax-5,tmax)  \n', ' stat[k:(k+m),3]=  perf(close2,tmax-10,tmax)  \n', ' stat[k:(k+m),4]=  perf(close2,tmax-15,tmax)  \n', ' stat[k:(k+m),5]=  perf(close2,tmax-20,tmax)  \n', '# stat[k:(k+m),6]=  perf(close2,tmax-25,tmax)  \n', ' stat[k:(k+m),7]=  perf(close2,tmax-30,tmax)  \n', '# stat[k:(k+m),8]=  perf(close2,tmax-35,tmax)  \n', ' stat[k:(k+m),9]=  perf(close2,tmax-40,tmax)  \n', '# stat[k:(k+m),10]=  perf(close2,tmax-45,tmax)  \n', ' stat[k:(k+m),11]=  perf(close2,tmax-50,tmax)  \n', ' stat[k:(k+m),12]=  perf(close2,tmax-60,tmax)  \n', ' stat[k:(k+m),13]=  perf(close2,tmax-90,tmax)  \n', ' stat[k:(k+m),14]=  perf(close2,tmax-120,tmax)  \n', ' stat[k:(k+m),15]=  perf(close2,tmax-250,tmax)  \n', '\n', '\n', '# stat[k:(k+m),16]=  perf(close2, dd(20160105),tmax)   #1Jan 2016\n', '# stat[k:(k+m),17]=  perf(close2, dd(20160222),tmax)   # 22 Feb 2016\n', '# stat[k:(k+m),18]=  perf(close2,dd(20160105),dd(20160222))   # Crash DrawDown\n', ' # stat[k:(k+m),19]=  perf(close2,624,tmax)   #  24 June 2016\n', ' # stat[k:(k+m),20]=  perf(close2,623,625)   #  Crash 24 June 2016\n', ' # stat[k:(k+m),21]=  perf(close2,dd(20151230)-250,dd(20151230))    #2015 Return\n', '\n', ' stat[k:(k+m),22]= gap(close2,tmax-80,tmax,1) #Max 1 days Gap\n', ' stat[k:(k+m),23]= gap(close2,tmax-80,tmax,5) #Max 5 days Gap\n', ' stat[k:(k+m),24]= perf(close2,tmax-2,tmax)  \n', ' stat[k:(k+m),25]= perf(close2,tmax-3,tmax)  \n', ' stat[k:(k+m),26]= perf(close2,tmax-4,tmax)  \n', '\n', ' stat[k:(k+m),27]= perf(close2,tmax-2,tmax-1)   \n', ' stat[k:(k+m),28]= perf(close2,tmax-3,tmax-2)   \n', ' stat[k:(k+m),29]= perf(close2,tmax-4,tmax-3)   \n', ' stat[k:(k+m),30]= perf(close2,tmax-5,tmax-4)\n', ' \n', ' stat[k:(k+m),120]= mar(close2, tmax, 20) \n', ' stat[k:(k+m),121]= mar(close2, tmax, 50) \n', ' stat[k:(k+m),122]= 100*ma(close2, tmax, 5) / ma(close2, tmax, 50)  #OverSold /OverBought\n', ' stat[k:(k+m),123]= mar(close2, tmax, 100)  \n', ' stat[k:(k+m),124]= mar(close2, tmax, 10) \n', '# stat[k:(k+m),35]= 0 \n', '# stat[k:(k+m),36]= 0 \n', '# stat[k:(k+m),37]= 0 \n', '# stat[k:(k+m),38]= 0 \n', '# stat[k:(k+m),39]= 0 \n', '\n', ' # stat[k:(k+m),30]= volume / AvgVol3M\n', ' # stat[k:(k+m),30]= Nbday_to_Earnings\n', ' #Volume/3M AvgVolume\n', ' # stat[k:(k+m),26]=  volume(volume2,tmax-120,tmax)  \n', '\n', ' #==============================================================================\n', ' #-------------- Data Fundamental    -------------------------------------------\n', "" df= util.sql_query(sqlr='SELECT ticker,shortratio,sector1_id, sector2_id, marketcap   FROM stockfundamental ', dburl='/aaserialize/store/finviz.db')\n"", ' npdf= df.values; del df\n', ' npdf0= npdf[:,0]  \n', ' for i in range(0,m):  \n', '   try :\n', '     kid= util.find(symfull[i], npdf0)\n', '     if kid != -1 :\n', '      stat[i,150]=  float(npdf[kid, 1])   # short ratio\n', '      stat[i,151]=  float(npdf[kid, 2])   # sector 1      \n', '      stat[i,152]=  float(npdf[kid, 3])   # sector 2     \n', '      stat[i,153]=  float(npdf[kid, 4] / 100000000.0)   # market Cap    \n', '   except : pass\n', ' del npdf, npdf0\n', '\n', '\n', '#==============================================================================\n', ' ################ Volatility\n', ' stat[k:(k+m),40]= volhisto_fromprice(close2,tmax,20,axis=1)* 100\n', ' stat[k:(k+m),41]= volhisto_fromprice(close2,tmax,60,axis=1)* 100\n', ' stat[k:(k+m),42]= volhisto_fromprice(close2,tmax,252,axis=1)* 100\n', '# stat[k:(k+m),43]= stat[k:(k+m),12] / stat[k:(k+m),41] #Sharpe 3Month\n', '# stat[k:(k+m),44]= stat[k:(k+m),15] / stat[k:(k+m),42] #Sharpe 1Year\n', '\n', ' stat[k:(k+m),45]= close2[:,tmax] #Last Close\n', '\n', '# stat[k:(k+m),46]= 0 \n', '# stat[k:(k+m),47]= 0 \n', '# stat[k:(k+m),48]= 0 \n', '# stat[k:(k+m),49]= 0 \n', '\n', '\n', ' ###############  Technical Indicator\n', ' #Min of last 6 months, Max of last 6months\n', ' for i in range(0,m):\n', '  pp0= stat[i,45]\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-120):tmax])\n', '  stat[i,50]= kmin+(tmax-120);  stat[i,51]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-120):tmax])\n', '  stat[i,52]= kmax+(tmax-120);  stat[i,53]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-10):tmax])\n', '  stat[i,66]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-10):tmax])\n', '  stat[i,67]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-5):tmax])\n', '  stat[i,68]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-5):tmax])\n', '  stat[i,69]= 100*pp0 / pmax\n', '\n', ' del kmax,pmax,i,k  \n', '\n', '\n', ' #Regression from Min Price Time\n', ' for i in range(0,m):\n', '  t0= int(stat[i,50])\n', '  try :\n', '    res= regression(close2[i,t0:tmax ]  ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,54]=  res[2]  #R2\n', '    stat[i,55]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from Max Price Time\n', ' for i in range(0,m):  \n', '  t0= stat[i,52]\n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,56]=  res[2]  #R2\n', '    stat[i,57]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from 5 days ago\n', ' t0= tmax-5\n', ' for i in range(0,m): \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,58]=  res[2]  #R2\n', '    stat[i,59]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', '#Regression from 10 days ago\n', ' t0= tmax-10\n', ' for i in range(0,m):  \n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,60]=  res[2]  #R2\n', '    stat[i,61]=  res[0][0]  #Slope\n', '   except : pass\n', '\n', "" '''\n"", '#Regression from 1 month\n', ' t0= tmax-20   \n', ' for i in range(0,m):\n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,62]=  res[2]  #R2\n', '    stat[i,63]=  res[0][0]  #Slope\n', '   except : pass\n', "" '''\n"", '\n', "" '''\n"", '#Regression from 2 months ago\n', ' t0= tmax-40\n', ' for i in range(0,m):  \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,64]=  res[2]  #R2\n', '    stat[i,65]=  res[0][0]  #Slope\n', '  except : pass\n', "" '''\n"", '\n', '#Nb of Positive days last 5d\n', ' for i in range(0,m):  stat[i,66]=  np_countretsign(close2[i,(tmax-5):tmax])  \n', '\n', '#Nb of Positive days last 10d\n', ' for i in range(0,m):  stat[i,67]=  np_countretsign(close2[i,(tmax-10):tmax])  \n', '\n', '#Nb of Positive days last 20d\n', '# for i in range(0,m):  stat[i,68]=  np_countretsign(close2[i,(tmax-20):tmax])  \n', '\n', '\n', '#Regression from Max Values,200days\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,70]=  res[2]  #R2\n', '    stat[i,71]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmax\n', '\n', '\n', '#Regression from Min Values,200days \n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,72]=  res[2]  #R2\n', '    stat[i,73]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmin\n', '\n', '\n', '#Regression from Max Values,100days\n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,74]=  res[2]  #R2\n', '    stat[i,75]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmax\n', '\n', '\n', '#Regression from Min Values,100days \n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,76]=  res[2]  #R2\n', '    stat[i,77]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmin\n', '\n', '\n', '\n', '# Upside Trend with Higher Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '   vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '   vmax= util.sort(vmax,0,asc=0)\n', '   stat[i,80]=  -1\n', '   if len(vmax) > 1 :\n', '    ss=0\n', '    for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '    if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,80]=  ss  \n', '        stat[i,81]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Upside Trend with Higher High detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '    vmax= util.sort(vmax,0,asc=0)\n', '    stat[i,82]=  -1\n', '    if len(vmax) > 1 :\n', '      ss=0\n', '      for k in range(0,len(vmax)-1):\n', '        if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher high\n', '        else : break;\n', '      if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,82]=  ss  \n', '        stat[i,83]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Downside Trend with lower Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,84]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,84]=  ss  \n', '        stat[i,85]=  vmax[0,0] + t0\n', '\n', '\n', '# Downside Trend  with lower highs detection\n', ' t0= tmax-20*6\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,80]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,86]=  ss    #Nb  of lower high consecutive\n', '        stat[i,87]=  vmax[0,0] + t0\n', '\n', "" print('Higher/Lower Band Support')\n"", '#-----higher band Support / Lower Band Support 120days-------------------------------\n', ' t0= tmax-120\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,90]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,91]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,92]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '    # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1]) \n', '    # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 200days-------------------------------\n', ' t0= tmax-200\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,93]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,94]= 100.0 * stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,95]= 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 300days-------------------------------------\n', ' t0= tmax-300\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,96]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,97]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,98]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', ""  '''\n"", '  # -----higher band Support / Lower Band Support 60days-------------------------------\n', '  t0 = tmax - 60\n', '  for i in range(0, m):\n', '      try:\n', '          res1 = ta_highbandtrend1(close2[i, t0:tmax])\n', '          pmax = (res1.x[0] * (tmax - t0) + res1.x[1])\n', '          stat[i, 99] = 100.0 * stat[i, 45] / pmax  # Higher Band\n', '\n', '          res2 = ta_lowbandtrend1(close2[i, t0:tmax])\n', '          pmin = (res2.x[0] * (tmax - t0) + res2.x[1])\n', '          stat[i, 100] = 100.0 * stat[i, 45] / pmin  # LowerBand\n', '\n', '          stat[i, 101] = 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)  # Price inside Range\n', '\n', '          # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1])\n', '          # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '      except:\n', '          pass\n', ""  '''\n"", '\n', '  #-----Technical Indicator------------------------------------------------\n', '# for i in range(0,m): \n', '#  try :\n', '#   res2=0\n', '   # df= pd.read_hdf(dbfile, symfull[i])\n', '   # stat[i,110]= ta.RMI(close2[i,:])\n', '   # stat[i,111]= 100*close2[i,:] / ta.MA(close2[i,:],20)\n', '   # stat[i,112]= 100*close2[i,:] / ta.MA(close2[i,:],50)   \n', '#  except: pass\n', '\n', '\n', ' return np.array(stat, dtype=np.float16) \n', '\n', '\n', ""'''  \n"", 'i=1964  \n', 'stat= s1\n', 'stat[i, 91]  \n', '\n', 'tt= np.arange(t0, tmax)\n', 'plot_price(close2[i,t0:tmax], (res2.x[0] * (tt-t0) + res2.x[1]) )\n', ""'''\n"", '\n', '  \n', '#------------------- Stock Monitoring Tools ------------------------------------------------\n', ""def monitor_addrecommend(string1, dbname='stock_recommend') :\n"", ' ss= string1.replace(""("","" "").replace(\')\',\' \').replace(\':\',\' \')\n', "" ss= ss.replace('\\t', ' ').replace('\\n', ' ')\n"", ' sl1= ss.split("" "")\n', ' print sl1\n', ' aux= [datestring_toint(util.date_now())]\n', ' symfull= copy.deepcopy(a_us_all)\n', ' for x in sl1:\n', '   if len(x) < 5 :\n', '    if util.find(x,symfull) > 0 :   aux.append(x)\n', '\n', ' if len(aux) >  1 :\n', '  stock_recommend= util.load_obj(dbname)\n', '  stock_recommend.append(aux)\n', '  util.save_obj(stock_recommend,dbname)\n', '  print aux\n', ' return stock_recommend\n', '\n', '\n', '\n', '#################### Finviz  ###############################################################\n', 'from bs4 import BeautifulSoup\n', 'import csv,datetime, requests\n', 'def imp_finviz():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Overview Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=111&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(111) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 10].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 10\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockoverview.csv', 'wb') as csvfile:\n"", ""    overview = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    overview.writeheader()\n', '\n', '    for stock in alldata:\n', '        overview.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10] })\n', '\n', ' print ""Finviz Overview Completed""\n', ' return overview\n', ' \n', '\n', 'def imp_finviz_news():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Performance Start""\n', ' url = ""http://www.finviz.com/quote.ashx?t=intc""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', ' titleslist = soup.find_all(\'a\',{""class"" : ""tab-link-news""})\n', ' return titleslist\n', '\n', '\n', 'def imp_finviz_financials():\n', ' import datetime\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=161&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(161) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 17].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 16].text,stockdata[datalength - 15].text,stockdata[datalength - 14].text,stockdata[datalength - 13].text,stockdata[datalength - 12].text,stockdata[datalength - 11].text,stockdata[datalength - 10].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 17\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockfinancial.csv', 'wb') as csvfile:\n"", ""    financial = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    financial.writeheader()\n', '\n', '    for stock in alldata:\n', '        financial.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10],titlesarray[11] : stock[11],titlesarray[12] : stock[12],titlesarray[13] : stock[13],titlesarray[14] : stock[14],titlesarray[15] : stock[15],titlesarray[16] : stock[16],titlesarray[17] : stock[17] })\n', '\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Completed""\n', '\n', '\n', '\n', 'def get_price2book( symbol ):\n', '   from bs4 import BeautifulSoup as bs\n', '   import urllib as u\n', '   try:\n', ""    \turl = r'http://finviz.com/quote.ashx?t={}'.format(symbol.lower())\n"", '        html = u.request.urlopen(url).read()\n', ""        soup = bs(html, 'lxml')\n"", '        # Change the text below to get a diff metric\n', ""        pb =  soup.find(text = r'P/B')\n"", ""        pb_ = pb.find_next(class_='snapshot-td2').text\n"", ""        print( '{} price to book = {}'.format(symbol, pb_) )\n"", '        return pb_\n', '   except Exception as e:\n', '        print(e)\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ' try:\n', '   q = imp_googleQuote(name1, date1, date2)  #interval, timeframe\n', ""   name1= name1.replace(':','_')\n"", ""   file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(date2) +'.csv'\n"", '   q.write_csv(file1)\n', ' except: print\n', ""'''\n"", '\n', '\n', ""'''\n"", 'def imp_googleQuoteList(symbols, freqsec=300, nday=1, intraday1=True) :\n', ' qlist=[]; sym=[]\n', ' if intraday1:\n', '  for symbol in symbols:\n', '     #try :\n', '        q = imp_googleIntradayQuote(symbol, freqsec, nday)  #interval, timeframe\n', '        qlist.append(q)\n', '        sym.append(symbol)\n', ""     #except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       q = imp_googleQuote(name1, freqsec, num_days)  #interval, timeframe\n', '     except: print(symbol)\n', '\n', ' return qlist, sym\n', ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''        \n"", ""stock_list = ['XOM','AMZN','AAPL','SWKS']\n"", 'p2b_series = pd.Series( index=stock_list )\n', '\n', 'for sym in stock_list:\tp2b_series[sym] = get_price2book(sym)\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", "" # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", ' from dateutil.parser import parse\n', ' if os.path.getsize(file1)> 500 :\n', '  from_zone = tz.gettz(fromzone); tozone = tz.gettz(tozone)\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%m-%d-%Y %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', '  dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '\n', '  # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '  print file1\n', ""  #df = pd.read_csv(file1,sep=',',header=None, parse_dates={'date': [1]}, date_parser=dateparse)\n"", '\n', ""  df = pd.read_csv(file1,sep=',',header=0)\n"", '  #df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '  #df.date= [x.to_datetime() for x in  df.date]\n', '\n', '\n', '  df.drop(df.columns[[0]], axis=1, inplace=True)\n', ""  df= util.pd_addcol(df, 'symbol')\n"", ""  df['symbol']= dfname\n"", '\n', '  print filenameh5\n', ""  df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", ""  df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", '\n', '  # store = pd.HDFStore(filenameh5);\n', '  # store.append(dfname, df);  store.close()\n', ""'''\n"", '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dropcol=[], type1='csv', hasheader=True, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", ' if os.path.getsize(file1)> 500 :\n', '   header= 0 if hasheader else None\n', ""   df = pd.read_csv(file1, sep=',',header=0)\n"", '\n', '   df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""   df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""   df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", '\n', ""   if type1=='csv' :\n"", ""     df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""     if i==1: close = qq[['Datetime']]  #new dataframe\n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', ""     close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""     close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', "" close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", "" close= close.sort('Datetime')\n"", "" close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", '\n', ' close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", 'class Quote(object):\n', ""  DATE_FMT = '%Y-%m-%d';  TIME_FMT = '%H:%M:%S'\n"", '\n', '  def __init__(self):\n', ""    self.symbol = '';    self.exchn=''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', '\n', '  def append(self,dt,open_,high,low,close,volume):\n', '    self.date.append(dt.date())\n', '    self.time.append(dt.time())\n', '    self.open_.append(float(open_))\n', '    self.high.append(float(high))\n', '    self.low.append(float(low))\n', '    self.close.append(float(close))\n', '    self.volume.append(int(volume))\n', '\n', '  def to_csv(self):\n', '    return \'\'.join([""{0},{1},{2},{3:.2f},{4:.2f},{5:.2f},{6:.2f},{7}\\n"".format(self.symbol,\n', ""              self.date[bar].strftime('%Y-%m-%d'),self.time[bar].strftime('%H:%M:%S'),\n"", '              self.open_[bar],self.high[bar],self.low[bar],self.close[bar],self.volume[bar])\n', '              for bar in xrange(len(self.close))])\n', '\n', '  def write_csv(self,filename):\n', ""    with open(filename,'w') as f:\n"", '      txt= self.to_csv()\n', '      f.write(txt)\n', '\n', '  def read_csv(self,filename):\n', ""    self.symbol = ''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', ""    for line in open(filename,'r'):\n"", ""      symbol,ds,ts,open_,high,low,close,volume = line.rstrip().split(',')\n"", '      self.symbol = symbol\n', ""      dt = datetime.datetime.strptime(ds+' '+ts,self.DATE_FMT+' '+self.TIME_FMT)\n"", '      self.append(dt,open_,high,low,close,volume)\n', '    return True\n', '\n', '  def __repr__(self):\n', '    return self.to_csv()\n', ""'''\n"", '\n', ' \n', '\n', ""'''\n"", ""def imp_googleIntradayQuoteSave2(name1, date1, inter, tframe, dircsv='', dbname=''):\n"", ' q = imp_googleIntradayQuote(name1, inter, tframe)  #interval, timeframe\n', "" name1= name1.replace(':','_')\n"", '\n', "" if dircsv != '' :\n"", ""    file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", '    q.to_csv(file1)\n', '\n', "" if dbname != '' :\n"", '    import sqlalchemy as sql\n', '    dbcon= sql.create_engine(dbname)\n', '    if inter== 300 : # 5mins\n', ""      q.to_sql('q5min', dbcon)\n"", '\n', '\n', ""def imp_googleQuoteList_save(symbols, date1, date2, inter=23400, tframe=2000, dircsv='', intraday1=True) :\n"", ' if intraday1:\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleIntradayQuoteSave(symbol, date1, inter, tframe, dircsv)\n', ""     except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleQuoteSave(symbol, date1, date2, dircsv)\n', '     except: print(symbol)\n', ""'''\n"", '\n']","['np.shape', 'getret_fromquotes', 'len', 'getlogret_fromquotes', 'np.log', 'getprice_fromret']",6
utilmy/zarchive/portfolio.py:index,index,class,103,300,221,3009,10.03,1,3,[],[],[],1625,[],[],0
utilmy/zarchive/portfolio.py:folioCalc,folioCalc,class,125,509,332,4736,9.3,2,17,[],[],[],1924,[],[],0
utilmy/zarchive/portfolio.py:folioRiskIndicator,folioRiskIndicator,class,89,306,215,3180,10.39,1,9,[],[],[],2099,[],[],0
utilmy/zarchive/portfolio.py:folioOptimizationF,folioOptimizationF,class,280,1291,671,10994,8.52,6,39,[],[],[],2277,[],[],0
utilmy/zarchive/portfolio.py:searchSimilarity,searchSimilarity,class,173,497,328,4550,9.15,8,17,[],[],[],3724,[],[],0
utilmy/zarchive/portfolio.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1626,[],['date_generatedatetime'],1
utilmy/zarchive/portfolio.py:index:close,index:close,method,0,1,1,4,4.0,0,0,['self'],[None],[None],1631,[],[],0
utilmy/zarchive/portfolio.py:index:updatehisto,index:updatehisto,method,2,12,11,62,5.17,0,0,['self)'],['  #Download Quotespassself) :'],[None],1634,[],['print'],1
utilmy/zarchive/portfolio.py:index:help,index:help,method,2,12,11,62,5.17,0,0,['self'],[None],[None],1638,[],['print'],1
utilmy/zarchive/portfolio.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]",['date_generatedatetime'],1
utilmy/zarchive/portfolio.py:index:calc_baskettable_pct,index:calc_baskettable_pct,method,37,95,77,782,8.23,1,2,"['self', 'type1', 'showdetail']","[None, None, None]","[None, '""table""', '0']",1703,"[""      '''   Calc Basket Values from Input data '''\n""]","['np.zeros', 'np.sum', 'self._udpate_wwindpct', 'range', 'np.mod', 'self._wwpct_rebal']",6
utilmy/zarchive/portfolio.py:index:_wwpct_rebal,index:_wwpct_rebal,method,3,4,3,41,10.25,0,0,"['self', 'wwpct_actual', 't', 'trebal)', '']","[None, None, None, '  # BskUnit', ']np.abs(wwpct_actual/wwpct_th  -1 )) > self.rebal_trigger:']","[None, None, None, ' 1.0  !!!wwpct_th = self.wwasset[trebal', None]",1730,[],[],0
utilmy/zarchive/portfolio.py:index:_udpate_wwindpct,index:_udpate_wwindpct,method,11,25,17,224,8.96,0,0,"['self', 't', 'bskt', 'hedgecost', 'wwpct_actual', 'wwpct_th']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",1740,[],[],0
utilmy/zarchive/portfolio.py:index:calc_baskettable_unit,index:calc_baskettable_unit,method,0,0,0,0,0.0,0,0,[],[],[],1749,"[""    '''   t           --->  t+1                 ---->   t+2\n"", '            wwactual:    B[t]    -->   B[t+1]   using  w[t+1], B[t] /   S[t]\n', '            wwnew   :    B[t+1]  -->   B[t+2]   using  w[t+2], B[t+1] /   S[t+1]\n', ""    '''\n""]",[],0
utilmy/zarchive/portfolio.py:folioCalc:__init__,folioCalc:__init__,method,21,39,37,356,9.13,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1925,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioCalc:set_symclose,folioCalc:set_symclose,method,17,34,33,312,9.18,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1938,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioCalc:setcriteria,folioCalc:setcriteria,method,41,76,71,1046,13.76,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",1947,"[""        ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '            wwtype:     constant / regime /regimExtra\n', '            initperiod: NbOfDays_initial_Risk_Monitoring\n', '            riskid:     spprice/spperf/multi\n', ""        '''\n""]","['np.array', 'len']",2
utilmy/zarchive/portfolio.py:folioCalc:_weightcalc_generic,folioCalc:_weightcalc_generic,method,5,35,23,396,11.31,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",1997,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/portfolio.py:folioCalc:_weightcalc_regime,folioCalc:_weightcalc_regime,method,10,37,32,272,7.35,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2008,[],"['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/portfolio.py:folioCalc:_regimecalc,folioCalc:_regimecalc,method,3,7,6,83,11.86,0,0,"['self', 't', 'wwextra)', 't - 1]self.riskind[0', 't - 1] / self.riskind[0', 't - 1 - self.nbrange] - 1if self.riskid == ""multi""']","[None, None, '  # Risk Indicatorif self.riskid ', None, None, '']","[None, None, '= ""spprice"":   return self.riskind[0', None, None, '= ""multi"":']",2018,[],['self._mapping_calc_risk'],1
utilmy/zarchive/portfolio.py:folioCalc:_weightcalc_constant,folioCalc:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2027,[],['np.sum'],1
utilmy/zarchive/portfolio.py:folioCalc:getweight,folioCalc:getweight,method,5,12,9,126,10.5,0,0,['self'],[None],[None],2031,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/portfolio.py:folioCalc:calc_baskettable,folioCalc:calc_baskettable,method,33,111,83,811,7.31,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', '0.000', '0']",2038,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/portfolio.py:folioCalc:plot,folioCalc:plot,method,10,29,26,295,10.17,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2066,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/portfolio.py:folioCalc:multiperiod_ww,folioCalc:multiperiod_ww,method,15,36,29,240,6.67,1,1,"['self', 't']","[None, None]","[None, None]",2077,[],['xrange'],1
utilmy/zarchive/portfolio.py:folioCalc:help,folioCalc:help,method,1,2,2,13,6.5,0,0,['self'],[None],[None],2090,[],['print'],1
utilmy/zarchive/portfolio.py:folioRiskIndicator:__init__,folioRiskIndicator:__init__,method,23,40,38,356,8.9,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioRiskIndicator:set_symclose,folioRiskIndicator:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2114,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioRiskIndicator:setcriteria,folioRiskIndicator:setcriteria,method,34,81,70,1006,12.42,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2124,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'np.zeros']",3
utilmy/zarchive/portfolio.py:folioRiskIndicator:calcrisk,folioRiskIndicator:calcrisk,method,13,18,17,220,12.22,1,0,"['self', 'wwvec', 'initval']","[None, None, None]","[None, '[]', '1']",2172,[],"['xrange', 'self._weightcalc_generic', 'np.column_stack']",3
utilmy/zarchive/portfolio.py:folioRiskIndicator:_weightcalc_generic,folioRiskIndicator:_weightcalc_generic,method,4,34,24,327,9.62,0,3,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2184,[],"['self._weightcalc_regime', 'print']",2
utilmy/zarchive/portfolio.py:folioRiskIndicator:_weightcalc_regime,folioRiskIndicator:_weightcalc_regime,method,3,11,11,68,6.18,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2193,[],['self._regimecalc'],1
utilmy/zarchive/portfolio.py:folioRiskIndicator:_regimecalc,folioRiskIndicator:_regimecalc,method,7,18,17,216,12.0,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )self.riskind', 'wwextra', 't', 'self.riskind_out)self', 'maxiter', 'name1', 'isreset', 'popsize=15) ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, None, None, None, None, None, None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, None, None, None, None, '1', ""''"", '1', '15) :']",2198,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio.py:folioRiskIndicator:calc_optimal_weight,folioRiskIndicator:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2204,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:__init__,folioOptimizationF:__init__,method,23,39,37,340,8.72,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioOptimizationF:set_symclose,folioOptimizationF:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2114,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio.py:folioOptimizationF:setcriteria,folioOptimizationF:setcriteria,method,44,128,103,1669,13.04,0,2,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2124,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'print', 'list']",4
utilmy/zarchive/portfolio.py:folioOptimizationF:calcbasket_obj2,folioOptimizationF:calcbasket_obj2,method,23,76,63,756,9.95,0,1,"['self', 'wwvec']","[None, None]","[None, None]",2362,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float']",6
utilmy/zarchive/portfolio.py:folioOptimizationF:calcbasket_obj,folioOptimizationF:calcbasket_obj,method,55,157,118,1494,9.52,1,4,"['self', 'wwvec']","[None, None]","[None, None]",2388,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float', 'calcbasket_obj', 'concenfactor=folio_concenfactor2', 'np.zeros', 'xrange', 'np.mod', 'self._weightcalc_generic', 'self._loss_obj', 'self._objective_criteria']",14
utilmy/zarchive/portfolio.py:folioOptimizationF:_loss_obj,folioOptimizationF:_loss_obj,method,4,6,6,68,11.33,0,0,"['self', 'ww2', 'wwpenalty']","[None, None, None]","[None, None, None]",2413,[],['np.sum'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:_weightcalc_generic,folioOptimizationF:_weightcalc_generic,method,5,40,26,394,9.85,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2184,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/portfolio.py:folioOptimizationF:_weightcalc_regime,folioOptimizationF:_weightcalc_regime,method,8,32,28,239,7.47,0,0,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2193,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']","['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/portfolio.py:folioOptimizationF:_regimecalc,folioOptimizationF:_regimecalc,method,4,7,7,83,11.86,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )if self.riskid== ""multi""   ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, '= ""multi""   :']",2198,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']",['self._mapping_calc_risk'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:_weightcalc_constant,folioOptimizationF:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2452,[],['np.sum'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:calc_optimal_weight,folioOptimizationF:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2204,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:getweight,folioOptimizationF:getweight,method,6,11,9,126,11.45,0,0,['self'],[None],[None],2461,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/portfolio.py:folioOptimizationF:calc_baskettable,folioOptimizationF:calc_baskettable,method,36,86,72,827,9.62,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', ' 0.000', '0']",2469,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/portfolio.py:folioOptimizationF:plot,folioOptimizationF:plot,method,11,31,30,294,9.48,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2498,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/portfolio.py:folioOptimizationF:_objective_criteria,folioOptimizationF:_objective_criteria,method,31,147,78,1105,7.52,2,7,"['self', 'bsk']","[None, None]","[None, None]",2510,[],"['np.std', 'np.sum', 'range', 'np.arange']",4
utilmy/zarchive/portfolio.py:folioOptimizationF:multiperiod_ww,folioOptimizationF:multiperiod_ww,method,18,29,27,238,8.21,1,1,"['self', 't']","[None, None]","[None, None]",2557,[],['xrange'],1
utilmy/zarchive/portfolio.py:folioOptimizationF:help,folioOptimizationF:help,method,50,152,103,1472,9.68,1,6,['self'],[None],[None],2569,[],"['print', 'util.load_obj', 'int', 'copy.deepcopy', 'xrange', 'next', 'util.save_obj', 'np.mod', 'np.abs', 'np.reshape', 'np.sum']",11
utilmy/zarchive/portfolio.py:folioOptimizationF:mapping_risk_ww,folioOptimizationF:mapping_risk_ww,method,12,56,29,245,4.38,0,1,"['self', 'risk', 'wwmat', 'ww2']","[None, None, None, None]","[None, None, None, 'self.wwasset0']",2628,[],"['np.sum', 'np.array']",2
utilmy/zarchive/portfolio.py:folioOptimizationF:_mapping_calc_risk,folioOptimizationF:_mapping_calc_risk,method,27,201,76,831,4.13,0,3,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",2640,[],[],0
utilmy/zarchive/portfolio.py:searchSimilarity:__init__,searchSimilarity:__init__,method,15,18,17,193,10.72,0,0,"['self', ""filejpstock=r'E"", 'sym01', 'symname', 'startdate', 'enddate', 'pricetype']","[None, '', None, None, None, None, None]","[None, ""r'E:/_data/stock/daily/20160616/jp'"", ""['7203']"", ""['Toyota']"", ' 20150101', '20160601', '""close""']",3725,[],[],0
utilmy/zarchive/portfolio.py:searchSimilarity:load_quotes_fromdb,searchSimilarity:load_quotes_fromdb,method,15,35,33,355,10.14,0,1,"['self', 'picklefile']","[None, None]","[None, ""''""]",3730,[],"['util.load_obj', 'imp_txt_getquotes', 'date_align', 'util.a_cleanmemory']",4
utilmy/zarchive/portfolio.py:searchSimilarity:__generate_return__,searchSimilarity:__generate_return__,method,4,4,4,64,16.0,0,0,"['self', 'nlag']","[None, None]","[None, None]",3741,[],['getret_fromquotes'],1
utilmy/zarchive/portfolio.py:searchSimilarity:__overweight__,searchSimilarity:__overweight__,method,17,62,41,412,6.65,2,4,"['self', 'px']","[None, None]","[None, None]",3745,[],"['len', 'np.ones', 'util.np_findlocalmax', 'type', 'np.abs', 'wwerr[max', 'util.np_findlocalmin']",7
utilmy/zarchive/portfolio.py:searchSimilarity:set_searchcriteria,searchSimilarity:set_searchcriteria,method,34,79,63,793,10.04,0,5,"['self', 'name1', 'date1', 'date2', 'nlag', 'searchperiodstart', 'typesearch', '']","[None, None, None, None, None, None, None, None]","[None, ""'7203'"", '20160301', '20160601', '1', '20120101', '""pattern2""', None]",3765,[],"['getret_fromquotes', 'date_finddateid', 'max', 'util.np_findfirst', 'print', 'price_normalize_1d', 'len', 'self.__overweight__']",8
utilmy/zarchive/portfolio.py:searchSimilarity:launch_search,searchSimilarity:launch_search,method,53,107,81,908,8.49,3,3,['self'],[None],[None],3794,[],"['len', 'np.zeros', 'range', 'price_normalize_1d', 'np_similarity', 'util.np_sortbycolumn', 'enumerate']",7
utilmy/zarchive/portfolio.py:searchSimilarity:show_comparison_graph,searchSimilarity:show_comparison_graph,method,33,72,63,682,9.47,1,3,"['self', 'maxresult', 'show_only_different_time', 'fromid', 'fromend', 'filenameout']","[None, None, None, None, None, None]","[None, '20', 'True', '0', ' 0', ""''""]",3828,[],"['np.shape', 'range', 'int', 'print', 'price_normalize_1d', 'str', 'plot_price']",7
utilmy/zarchive/portfolio.py:searchSimilarity:staticmethod,searchSimilarity:staticmethod,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",3857,[],[],0
utilmy/zarchive/portfolio.py:searchSimilarity:get_rankresult,searchSimilarity:get_rankresult,method,24,63,53,496,7.87,2,1,"['self', 'filetosave']","[None, None]","[None, ""''""]",3861,[],"['len', 'np.savetxt', 'np.shape', 'np.array', 'np.empty', 'range', 'int', 'str']",8
utilmy/zarchive/portfolio.py:searchSimilarity:export_results,searchSimilarity:export_results,method,0,0,0,0,0.0,0,0,[],[],[],3883,"[""'''\n"", '#####################################################################################\n', '#---------Run over all the indexes, with time lag -----------------------------------\n', 'def np_similarity(x,y, wwerr=[], type1=0):\n', '  if type1==2 : return np_distance_l1(x,y, wwerr)\n', '  if type1==1: return sci.spatial.distance.correlation(x, y)  \n', '  if type1==0 : return 1-np.corrcoef(x,y)[0,1]\n', '\n', 'def np_distance_l1(x,y, wwerr) :\n', ' return np.sum(wwerr * np.abs(x-y))  \n', '  \n', '#---------------------  Universe Load         ---------------------------------------\n', ""filejpstock= r'E:/_data/stock/daily/20160616/jp'\n"", 'sym01= nk400list\n', '\n', 'quotes= imp_txt_getquotes(sym01, filejpstock, startdate=20090101, endate=20160616)\n', 'open1, dateref= date_align(quotes, type1=""close"")    #Get the data and align dates\n', 'del quotes; util.a_cleanmemory()\n', '\n', ""#util.save_obj(open1, 'close_nk400_2009_2016')\n"", ""#util.save_obj(dateref, 'dateref_nk400_2009_2016')\n"", '\n', ""open1= util.load_obj('close_nk400_2009_2016')\n"", ""dateref= util.load_obj( 'dateref_nk400_2009_2016')\n"", '\n', 'nlag=1\n', 'ret_open1 =  getdailyret_fromquotes(open1,nlag)\n', 'del open1\n', '\n', '#--------------------  Search Asset Input     ---------------------------------------\n', ""name1= '7203' \n"", 'date1= 20160328\n', 'date2= 20160531\n', 'twindow= util.np_findfirst(date2, dateref) - util.np_findfirst(date1, dateref) \n', '\n', '\n', 'tstartx= util.np_findfirst(date1, dateref)          # Date Index\n', 'stockx= util.np_findfirst(name1, sym01)\n', 'retx= ret_open1[stockx, tstartx:(tstartx+twindow-1)]    # Recent Period\n', 'px= price_normalize_1d(retx)\n', 'nx= len(px)\n', '\n', '\n', '#----OverWeight for Local Min, Local Max         -----------------------------------\n', 'wwerr= np.ones(nx, dtype=np.float16)\n', 'vvmax= util.np_findlocalmax(px); xprev=0\n', 'for x in vvmax:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', 'vvmin= util.np_findlocalmin(px); xprev=0\n', 'for x in vvmin:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', '\n', '#--------------------  Search the Pattern       -------------------------------------\n', 'tmaxx= len(dateref)-1\n', 'similar_list= np.zeros((nstock*(tmaxx-twindow)+1, 3), np.float16)\n', 'i=0\n', 'for iy in range(0, nstock) :\n', ' for t in range(0, tmaxx-twindow):\n', '   if iy == stockx and t > tstartx : \n', '     pass\n', '   else :\n', '    rety= ret_open1[iy, t:(t+twindow-1)]\n', '    py=   price_normalize_1d(rety)\n', '    ss= np_similarity(px, py, wwerr=wwerr, type1=2)\n', '    i+=1\n', '    similar_list[i,0]= iy\n', '    similar_list[i,1]= t\n', '    similar_list[i,2]= ss\n', '\n', '\n', ' #-------------------Clean the table -------------------------------------------------\n', 'rank= util.np_sortbycolumn(similar_list,2, asc=True)\n', 'for i,x in enumerate(rank) :\n', '  if rank[i,2]==0.0 : rank[i,2]= 1000         # Empty cell\n', '  if rank[i,1]> tstartx-3 : rank[i,2]= 100    # Start Element\n', 'rank= util.np_sortbycolumn(rank,2, asc=True)  \n', '\n', '\n', ' #----- Show Similar Stocks ---------------------------------------------------------\n', 'show_only_different_time= True\n', '\n', 'for i in range(0,10) :\n', ' tstarti= rank[i,1]\n', ' stocki= int(rank[i,0])\n', ' \n', ' if show_only_different_time and tstarti < tstartx-1  :\n', '   py= price_normalize100(ret_open1[stocki, tstarti:(tstarti+twindow-1)]) \n', '\n', '   namei= sym01[stocki]\n', '   namefulli= nk400name[util.np_findfirst(namei, nk400list)]\n', '\n', '   tit= namei+ "" "" +namefulli+ "" "" + str(dateref[tstarti])          \n', ""   plot_price(px-100, py-100, label=('Similar '+tit, 'Time','% Var') )\n"", '\n', '\n', 'kix= util.np_findfirst(name1, statsjp[:,0, ilag])\n', 'stocklist01[390]\n', '\n', '\n', 'stocklist01[157] , nk400name[157] ,  dateref1adj[86]     \n', 'plot_price(price_normalize100(ret_open1[157, 86:86+twindow-1])-100,px-100   )\n', ""'''    \n""]",[],0
utilmy/zarchive/portfolio_withdate.py:data_jpsector,data_jpsector,function,3,4,4,47,11.75,0,0,[],[],[],30,[],['util.load_obj'],1
utilmy/zarchive/portfolio_withdate.py:date_earningquater,date_earningquater,function,9,103,42,604,5.86,0,5,['t1'],[None],[None],40,[],['datetime.datetime'],1
utilmy/zarchive/portfolio_withdate.py:date_is_3rdfriday,date_is_3rdfriday,function,4,14,13,67,4.79,0,0,['s'],[None],[None],59,[],"['datetime.strptime', 'd.weekday']",2
utilmy/zarchive/portfolio_withdate.py:date_option_expiry,date_option_expiry,function,10,50,33,354,7.08,0,2,['date'],[None],[None],64,[],['datetime.datetime'],1
utilmy/zarchive/portfolio_withdate.py:date_find_kday_fromintradaydate,date_find_kday_fromintradaydate,function,2,3,3,68,22.67,0,0,"['kintraday', 'intradaydate', 'dailydate']","[None, None, None]","[None, None, None]",81,[],['util.np_find'],1
utilmy/zarchive/portfolio_withdate.py:date_find_kintraday_fromdate,date_find_kintraday_fromdate,function,4,10,10,88,8.8,0,0,"['d1', 'intradaydate1', 'h1', 'm1']","[None, None, None, None]","[None, None, '9', '30']",85,[],"['datetime.datetime', 'util.np_find']",2
utilmy/zarchive/portfolio_withdate.py:date_find_intradateid,date_find_intradateid,function,8,13,13,96,7.38,1,0,"['datetimelist', 'stringdate']","[None, None]","[None, ""['20160420223000']""]",92,[],"['datestring_todatetime', 'util.np_find', 'str']",3
utilmy/zarchive/portfolio_withdate.py:datetime_convertzone1_tozone2,datetime_convertzone1_tozone2,function,16,29,25,343,11.83,1,1,"['tt', 'fromzone', 'tozone']","[None, None, None]","[None, ""'Japan'"", ""'US/Eastern'""]",103,[],"['pytz.timezone', 'type', 'tz.localize', 't2.append']",4
utilmy/zarchive/portfolio_withdate.py:date_extract_dailyopenclosetime,date_extract_dailyopenclosetime,function,23,51,35,431,8.45,2,3,"['spdateref1', 'market']","[None, None]","[None, ""'us'""]",120,[],"['enumerate', 'spdailyopendate.append', 'np.array', 'spdailyclosedate.append']",4
utilmy/zarchive/portfolio_withdate.py:datetime_tostring,datetime_tostring,function,6,34,22,269,7.91,1,3,['tt'],[None],[None],138,[],"['isinstance', 'tt.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/portfolio_withdate.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",149,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/portfolio_withdate.py:datetime_todate,datetime_todate,function,6,40,25,319,7.97,1,3,['tt'],[None],[None],158,[],"['isinstance', 'datetime.date', 'pd.to_datetime', 'date2.append']",4
utilmy/zarchive/portfolio_withdate.py:datetime_toint,datetime_toint,function,12,37,28,424,11.46,2,2,['datelist1'],[None],[None],169,[],"['isinstance', 'int', 'date2.append', 'datetime_tointhour', 'yy2.append', 'np.array']",6
utilmy/zarchive/portfolio_withdate.py:datetime_tointhour,datetime_tointhour,function,7,20,19,234,11.7,1,1,['datelist1'],[None],[None],177,[],"['isinstance', 'int', 'yy2.append', 'np.array']",4
utilmy/zarchive/portfolio_withdate.py:dateint_tostring,dateint_tostring,function,7,15,14,183,12.2,1,1,"['datelist1', 'format1']","[None, None]","[None, ""'%b-%y'""]",185,[],"['isinstance', 'dateint_todatetime', 'date2.append', 'np.array']",4
utilmy/zarchive/portfolio_withdate.py:dateint_todatetime,dateint_todatetime,function,6,14,12,126,9.0,1,1,['datelist1'],[None],[None],207,[],"['isint', 'parser.parse', 'date2.append']",3
utilmy/zarchive/portfolio_withdate.py:datenumpy_todatetime,datenumpy_todatetime,function,9,48,26,381,7.94,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",218,[],['type'],1
utilmy/zarchive/portfolio_withdate.py:datetime_tonumpypdate,datetime_tonumpypdate,function,2,2,2,22,11.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",232,[],['np.datetime64'],1
utilmy/zarchive/portfolio_withdate.py:date_diffindays,date_diffindays,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",237,[],['dateint_todatetime'],1
utilmy/zarchive/portfolio_withdate.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",242,[],['util.np_findfirst'],1
utilmy/zarchive/portfolio_withdate.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],256,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/portfolio_withdate.py:date_as_float,date_as_float,function,12,32,26,311,9.72,0,2,['dt'],[None],[None],263,[],"['isint', 'dateint_todatetime', 'datetime.datetime', 'isleap', 'timedelta']",5
utilmy/zarchive/portfolio_withdate.py:date_todatetime,date_todatetime,function,1,9,9,58,6.44,0,0,['tlist'],[None],[None],277,[],[],0
utilmy/zarchive/portfolio_withdate.py:date_removetimezone,date_removetimezone,function,1,6,6,63,10.5,0,0,['datelist'],[None],[None],281,[],[],0
utilmy/zarchive/portfolio_withdate.py:datediff_inyear,datediff_inyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",285,[],['date_as_float'],1
utilmy/zarchive/portfolio_withdate.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",289,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/portfolio_withdate.py:date_add_bdays,date_add_bdays,function,12,37,30,369,9.97,1,2,"['from_date', 'add_days']","[None, None]","[None, None]",298,[],"['type', 'dateint_todatetime', 'datestring_todatetime', 'datetime.timedelta', 'current_date.weekday']",5
utilmy/zarchive/portfolio_withdate.py:date_getspecificdate,date_getspecificdate,function,21,203,58,1312,6.46,8,19,"['datelist', 'datetype1', 'outputype1', 'includelastdate', 'includefirstdate', '']","[None, None, None, None, None, None]","[None, '""yearend""', '""intdate""', 'True', 'False', None]",312,[],"['isint', 'dateint_todatetime', 'enumerate', 'vec2.append', 'np.mod', 'np.array']",6
utilmy/zarchive/portfolio_withdate.py:date_alignfromdateref,date_alignfromdateref,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",373,[],"['range', 'np.float', 'len']",3
utilmy/zarchive/portfolio_withdate.py:_date_align,_date_align,function,16,42,33,256,6.1,2,2,"['dateref', 'datei', 'tmax', 'closei']","[None, None, None, None]","[None, None, None, None]",398,[],"['np.zeros', 'range', 'len']",3
utilmy/zarchive/portfolio_withdate.py:date_align,date_align,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",412,"["" ''' #Aligne the price with the same dates date\tyear\tmonth\tday\td\topen\tclose\thigh\tlow\tvolume\taclose '''\n""]","['range', 'np.float', 'len']",3
utilmy/zarchive/portfolio_withdate.py:min_withposition,min_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],459,[],['min'],1
utilmy/zarchive/portfolio_withdate.py:max_withposition,max_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],463,[],['max'],1
utilmy/zarchive/portfolio_withdate.py:_reshape,_reshape,function,2,14,12,68,4.86,0,1,['x'],[None],[None],469,[],"['len', 'np.reshape', 'np.size']",3
utilmy/zarchive/portfolio_withdate.py:_notnone,_notnone,function,39,211,114,1769,8.38,1,11,"['x)', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5)', 'label', ""'Time'"", ""'Y')"", 'legendloc', 'dpi', 'isband=0) ']","['  return not x is Noneasset', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None, ""('title'"", None, None, '""upper left""', '150', '0) :']",473,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend']",23
utilmy/zarchive/portfolio_withdate.py:plot_price,plot_price,function,69,272,170,2746,10.1,2,11,"['asset', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None]",477,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend', 'plot_priceintraday', 'np.loadtxt', 'np.unique', 'xdays.append', 'np.hstack', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick']",35
utilmy/zarchive/portfolio_withdate.py:plot_priceintraday,plot_priceintraday,function,32,59,57,947,16.05,1,0,['data'],[None],[None],556,[],"['np.loadtxt', 'np.unique', 'np.arange', 'xdays.append', 'np.hstack', 'plt.figure', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plt.show']",14
utilmy/zarchive/portfolio_withdate.py:plot_check,plot_check,function,8,19,19,257,13.53,0,0,"['close', 'tt0i', 'tt1i', 'dateref', 'sym', 'tickperday']","[None, None, None, None, None, None]","[None, '20140102', '20160815', '[]', '[]', '120']",598,[],"['util.find', 'getret_fromquotes', 'price_normalize100', 'plot_price']",4
utilmy/zarchive/portfolio_withdate.py:plot_pricedate,plot_pricedate,function,18,61,49,534,8.75,1,4,"['date1', 'sym1', 'asset1', 'sym2', 'bsk1', 'verticaldate', 'savename1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None', ""''"", '(10', None]",608,[],"['type', 'datestring_todatetime', 'np.row_stack', 'np.concatenate', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'np.arange', 'int', 'len', 'ax.savefig']",11
utilmy/zarchive/portfolio_withdate.py:generate_sepvertical,generate_sepvertical,function,9,13,12,149,11.46,0,1,"['asset1', 'tt', 'tmax', 'start', 'datebar']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",690,[],"['np.zeros', 'datestring_todatetime']",2
utilmy/zarchive/portfolio_withdate.py:save_asset_tofile,save_asset_tofile,function,31,129,87,978,7.58,5,9,"['file1', 'asset1', 'asset2', 'asset3', 'date1', 'title1']","[None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None']",705,[],"['np.shape', 'len', 'np.reshape', 'print', 'np.zeros', 'range', 'int', 'np.row_stack', 'np.savetxt']",9
utilmy/zarchive/portfolio_withdate.py:load_asset_fromfile,load_asset_fromfile,function,1,4,4,51,12.75,0,0,['file1'],[None],[None],744,[],[],0
utilmy/zarchive/portfolio_withdate.py:array_todataframe,array_todataframe,function,11,41,27,259,6.32,0,2,"['price', 'symbols', 'date1']","[None, None, None]","[None, 'None', 'None']",748,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/portfolio_withdate.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],759,[],[],0
utilmy/zarchive/portfolio_withdate.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],768,[],['float'],1
utilmy/zarchive/portfolio_withdate.py:isint,isint,function,32,105,61,1036,9.87,0,8,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) )Xmat', 'type1', 'type2=""correl"") ']","[' return isinstance(x', None, None, None, None, None, None, '']","[None, None, None, None, None, None, '""robust""', '""correl"") :']",776,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/portfolio_withdate.py:correlation_mat,correlation_mat,function,32,105,61,1036,9.87,0,8,"['Xmat', 'type1', 'type2']","[None, None, None]","[None, '""robust""', '""correl""']",783,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/portfolio_withdate.py:correl_reducebytrigger,correl_reducebytrigger,function,9,22,18,128,5.82,2,1,"['correl2', 'trigger']","[None, None]","[None, None]",831,"[""  ''' Put Zero below trigger  '''\n""]","['correl2.copy', 'range', 'abs']",3
utilmy/zarchive/portfolio_withdate.py:sk_cov_fromcorrel,sk_cov_fromcorrel,function,8,14,13,115,8.21,0,0,"['correl', 'ret_close1']","[None, None]","[None, None]",843,[],"['volhisto_fromret', 'np.diag', 'np.dot']",3
utilmy/zarchive/portfolio_withdate.py:cointegration,cointegration,function,18,47,37,385,8.19,0,0,"['x', 'y']","[None, None]","[None, None]",849,"['  """""" Output :\n', '    coint_t :t-statistic of unit-root test on residuals\n', ""    pvalue :   MacKinnon's approximate p-value based on MacKinnon (1994)\n"", '    crit_value : Critical values for the test statistic at the 1 %, 5 %, and 10 %  Signifiance levels.\n', '\n', '    The Null hypothesis is that there is no cointegration, the alt hypothesis is that there is cointegrating relationship. \n', '    If the pvalue is small, below a critical size:  Reject Null Hypothesis -->  Cointegration\n', '           pvalue is high --> No Cointegration    \n', '    \n', '    Significance level, also denoted as alpha or , is the probability of rejecting  the null hypothesis when it is true.\n', '    Probability of incorrectly rejecting a true null hypothesis\n', '\n', '    P=0.05  , At least 23% (and typically close to 50%)\n', '    P=0.01  , At least 7% (and typically close to 15%\n', '\n', '    (-2.9607012342275936,\n', '    0.038730981052330332, 0,\n', '    249,\n', ""    {'1%': -3.4568881317725864,\n"", ""       '10%': -2.5729936189738876,\n"", ""     '5%': -2.8732185133016057},\n"", '      601.96849256295991)\n', '        It can be seen that the calculated test statistic of -2.96 is smaller than the 5% critical value of -2.87, \n', ""        which means that we can reject the null hypothesis that  there isn't a cointegrating relationship at the 5% level.\n"", '  """"""\n']",['np.zeros'],1
utilmy/zarchive/portfolio_withdate.py:causality_y1_y2,causality_y1_y2,function,10,14,13,153,10.93,0,0,"['price2', 'price1', 'maxlag']","[None, None, None]","[None, None, None]",887,[],[],0
utilmy/zarchive/portfolio_withdate.py:reg_slope,reg_slope,function,16,24,24,261,10.88,1,0,"['close', 'dateref', 'tlag', 'type1']","[None, None, None, None]","[None, None, None, ""'elasticv'""]",895,[],"['np.ones', 'xrange', 'regression', 'np.arange']",4
utilmy/zarchive/portfolio_withdate.py:rolling_cointegration,rolling_cointegration,function,13,29,26,280,9.66,0,0,"['x', 'y']","[None, None]","[None, None]",910,[],"['rolling_coint', 'pd.expanding_apply']",2
utilmy/zarchive/portfolio_withdate.py:regression,regression,function,13,67,32,589,8.79,0,5,"['yreturn', 'xreturn', 'type1']","[None, None, None]","[None, None, '""elasticv""']",929,"["" '''Y = X* reg.coef_  +  reg.intercept_, r2 '''\n""]","['len', 'yreturn.ravel', 'xreturn.reshape', 'reg.fit', 'F', 'reg.score']",6
utilmy/zarchive/portfolio_withdate.py:regression_fixedsymbolstock,regression_fixedsymbolstock,function,30,59,54,591,10.02,1,1,"['sym', 'ret_close2', 'tsstart', 'tsample', 'ret_spy', 'spyclose', 'regonly']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, 'True']",966,"["" ''' Price, Weight, R2, Error  '''\n""]","['len', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max']",7
utilmy/zarchive/portfolio_withdate.py:regression_getpricefromww,regression_getpricefromww,function,20,38,30,298,7.84,3,0,"['spyclose', 'ww01', 'regasset01', 'ret_close2', 'tstart', 'tlag']","[None, None, None, None, None, None]","[None, None, None, None, None, '1']",989,[],"['np.copy', 'np.zeros', 'range', 'len']",4
utilmy/zarchive/portfolio_withdate.py:regression_allstocks_vs_riskfactors,regression_allstocks_vs_riskfactors,function,65,137,113,1351,9.86,2,1,"['symstock', 'pricestock', 'symriskfac', 'priceriskfac', 'nlaglist']","[None, None, None, None, None]","[None, None, None, None, None]",1010,"["" '''Make Regression on all stocks ''' \n""]","['np.shape', 'print', 'np.arange', 'np.empty', 'len', 'enumerate', 'getlogret_fromquotes', 'range', 'np.reshape', 'regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",13
utilmy/zarchive/portfolio_withdate.py:getdiff_fromquotes,getdiff_fromquotes,function,4,6,6,73,12.17,0,0,"['close', 'timelag']","[None, None]","[None, None]",1107,[],['np.shape'],1
utilmy/zarchive/portfolio_withdate.py:getret_fromquotes,getret_fromquotes,function,7,23,17,159,6.91,0,1,"['close', 'timelag']","[None, None]","[None, '1']",1111,[],"['np.shape', 'len']",2
utilmy/zarchive/portfolio_withdate.py:getlogret_fromquotes,getlogret_fromquotes,function,4,7,7,81,11.57,0,0,"['close', 'timelag']","[None, None]","[None, '1']",1122,[],"['np.shape', 'np.log']",2
utilmy/zarchive/portfolio_withdate.py:getprice_fromret,getprice_fromret,function,12,23,21,190,8.26,2,0,"['ret', 'normprice']","[None, None]","[None, '100']",1127,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio_withdate.py:price_normalize100,price_normalize100,function,16,43,36,292,6.79,1,1,"['ret', 'normprice']","[None, None]","[None, '100']",1139,[],"['np.shape', 'len', 'np.reshape', 'np.zeros', 'range', 'np.cumprod']",6
utilmy/zarchive/portfolio_withdate.py:price_normalize_1d,price_normalize_1d,function,8,22,19,147,6.68,0,0,"['ret', 'normprice', 'dtype1']","[None, None, None]","[None, '100', ' np.float32']",1159,[],"['np.empty', 'np.cumprod']",2
utilmy/zarchive/portfolio_withdate.py:norm_fast,norm_fast,function,7,8,8,85,10.62,0,0,"['y', 'ny']","[None, None]","[None, None]",1168,[],['ne.evaluate'],1
utilmy/zarchive/portfolio_withdate.py:correl_fast,correl_fast,function,8,13,13,116,8.92,0,0,"['xn', 'y', 'nx']","[None, None, None]","[None, None, None]",1176,[],['ne.evaluate'],1
utilmy/zarchive/portfolio_withdate.py:volhisto_fromret,volhisto_fromret,function,2,14,11,168,12.0,0,1,"['retbsk', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1184,[],"['len', 'np.std']",2
utilmy/zarchive/portfolio_withdate.py:volhisto_fromprice,volhisto_fromprice,function,6,25,17,245,9.8,0,1,"['price', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1191,[],"['len', 'np.shape', 'np.std']",3
utilmy/zarchive/portfolio_withdate.py:volhistorolling_fromprice,volhistorolling_fromprice,function,16,42,30,318,7.57,2,1,"['price', 'volrange']","[None, None]","[None, None]",1200,[],"['np.shape', 'len', 'np.zeros', 'xrange', 'volhisto_fromprice']",5
utilmy/zarchive/portfolio_withdate.py:rsk_calc_all_TA,rsk_calc_all_TA,function,51,223,105,1352,6.06,0,10,['df'],[None],"[""'panda_dataframe'""]",1219,"[""  '''Add All TA RMI, RSI To the '''\n""]","['ta.MA', 'ta.distance', 'ta.RET', 'ta.RMI', 'ta.STDDEV', 'ta.nbday_low', 'ta.nbday_high', 'ta.RSI', 'ta.qearning_dist', 'ta.optionexpiry_dist', 'linearreg2', 'np.array', 'np.sum', 'util.np_findlocalmin2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",18
utilmy/zarchive/portfolio_withdate.py:ta_highbandtrend1,ta_highbandtrend1,function,42,170,75,910,5.35,0,11,"['close2', 'type1']","[None, None]","[None, '0']",1301,[],"['linearreg', 'np.array', 'np.sum', 'util.np_findlocalmax2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",8
utilmy/zarchive/portfolio_withdate.py:pd_transform_asset,pd_transform_asset,function,11,35,27,409,11.69,0,1,"['q0', 'q1', 'type1']","[None, None, None]","[None, None, '""spread""']",1350,[],"['util.pd_date_intersection', 'util.pd_array_todataframe', 'util.pd_insertcol']",3
utilmy/zarchive/portfolio_withdate.py:calcbasket_table,calcbasket_table,function,25,59,53,477,8.08,1,2,"['wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps']","[None, None, None, None, None, None]","[None, None, '""table""', '""constant""', '1', ' 0.000']",1364,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.mod', 'np.sum']",6
utilmy/zarchive/portfolio_withdate.py:folio_createvolta_asset,folio_createvolta_asset,function,10,19,19,159,8.37,1,0,"['close', 'vol', 'volrange', 'lev']","[None, None, None, None]","[None, '0.12', '120', '1.0']",1391,[],"['np.zeros_like', 'np.shape', 'xrange', 'folio_volta']",4
utilmy/zarchive/portfolio_withdate.py:folio_lowcorrelation,folio_lowcorrelation,function,145,431,300,3894,9.03,8,7,"['sym01', 'nstock', 'periodlist', 'dateref', 'close1', 'kbenchmark', 'badlist', 'costbppa', 'showgraph']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, '0.02', 'True']",1399,[],"['ww_selection', 'np.corrcoef', 'np.nan_to_num', 'np.zeros', 'range', 'util.np_sortbycol', 'int', 'np.std', 'np.isnan', 'util.find', 'np.sum', 'stk_select.append', 'volhisto_fromret', 'sum', '1/len', 'getret_fromquotes', 'len', 'np.empty', 'np.ones', 'enumerate', 'calcbasket_table', 'price_normalize100', 'np.column_stack', 'np.zeros_like', 'np.array', 'np.concatenate', 'print', 'str', 'plot_price', 'sym01[int', 'volhisto_fromprice', 'xrange', 'folio_inverseetf']",33
utilmy/zarchive/portfolio_withdate.py:folio_leverageetf,folio_leverageetf,function,8,23,20,156,6.78,1,0,"['price', 'lev', 'costpa']","[None, None, None]","[None, '1.0', '0.0']",1537,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio_withdate.py:folio_inverseetf,folio_inverseetf,function,8,18,18,151,8.39,1,0,"['price', 'costpa']","[None, None]","[None, '0.0']",1546,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio_withdate.py:folio_longshort_unit,folio_longshort_unit,function,59,240,112,1594,6.64,2,7,"['long1', 'short1', 'ww', '-1]', 'costpa', 'tlag', 'istable', 'wwschedule']","[None, None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1', '[]']",1555,[],"['len', 'np.zeros', 'xrange', 'np.mod', 'folio_longshort_unitfixed']",5
utilmy/zarchive/portfolio_withdate.py:folio_longshort_unitfixed,folio_longshort_unitfixed,function,43,111,73,719,6.48,1,3,"['long1', 'short1', 'nn', '-1]', 'costpa', 'tlag', 'istable']","[None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1']",1596,[],"['len', 'np.zeros', 'xrange', 'np.mod']",4
utilmy/zarchive/portfolio_withdate.py:folio_longshort_pct,folio_longshort_pct,function,8,21,20,189,9.0,1,0,"['long1', 'short1', 'ww', '-1]', 'costpa']","[None, None, None, None, None]","[None, None, '[1', None, '0.0']",1634,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/portfolio_withdate.py:folio_histogram,folio_histogram,function,13,75,41,914,12.19,0,0,['close'],[None],[None],1642,[],"['getret_fromquotes', 'plt.subplots', 'np.ones_like', 'ax2.hist', 'ax2.set_title', 'ax2.set_xlabel', 'ax2.set_ylabel', 'ax2.axvline', 'plt.show', 'print']",10
utilmy/zarchive/portfolio_withdate.py:folio_voltarget,folio_voltarget,function,2,6,6,61,10.17,0,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1670,[],['folio_volta'],1
utilmy/zarchive/portfolio_withdate.py:folio_volta,folio_volta,function,54,197,112,1663,8.44,2,8,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1674,[],"['folio_volta', 'len', 'np.shape', 'np.zeros', 'range', 'np.std', 'util.findhigher', 'max', 'min', 'folio_volta2', 'np.abs']",11
utilmy/zarchive/portfolio_withdate.py:folio_volta2,folio_volta2,function,29,61,54,514,8.43,1,2,"['bsk', 'riskind', 'par', 'targetvol', 'volrange', 'cap', 'floor', 'costbp']","[None, None, None, None, None, None, None, None]","[None, None, None, '0.11', ' 90', '1.5', '0.0', '0.0005']",1713,[],"['np.shape', 'np.zeros', 'range', 'np.std', 'max', 'min', 'np.abs']",7
utilmy/zarchive/portfolio_withdate.py:folio_fixedunitprice,folio_fixedunitprice,function,13,36,33,221,6.14,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1738,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio_withdate.py:folio_fixedweightprice,folio_fixedweightprice,function,13,36,33,225,6.25,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1752,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio_withdate.py:folio_fixedweightret,folio_fixedweightret,function,13,31,28,193,6.23,2,0,"['ret', 'fixedww']","[None, None]","[None, None]",1764,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/portfolio_withdate.py:folio_cost_turnover,folio_cost_turnover,function,26,88,71,825,9.38,1,1,"['wwall', 'bsk', 'dateref', 'costbp']","[None, None, None, None]","[None, None, None, None]",1777,[],"['len', 'np.zeros', 'xrange', 'np.sum', 'plot_price', 'date1=dateint_tostring']",6
utilmy/zarchive/portfolio_withdate.py:folio_riskpa,folio_riskpa,function,20,52,40,422,8.12,2,0,"['ret', 'targetvol', 'volrange', 'cap']","[None, None, None, None]","[None, '0.1', '90', '1.0']",1807,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.sum', 'np.std', 'min', 'list']",8
utilmy/zarchive/portfolio_withdate.py:folio_perfreport_schedule,folio_perfreport_schedule,function,14,20,19,189,9.45,1,0,"['sym', 'dateref', 'close', 'wwind', 't0', 'scheduleperiod']","[None, None, None, None, None, None]","[None, None, None, None, None, '""1monthend""']",2121,[],"['np.shape', 'generate_schedule', 'np.zeros', 'enumerate']",4
utilmy/zarchive/portfolio_withdate.py:folio_concenfactor2,folio_concenfactor2,function,7,12,12,103,8.58,0,0,"['ww', 'masset']","[None, None]","[None, '12']",2421,[],"['getweight', 'np.sum', 'np.mean']",3
utilmy/zarchive/portfolio_withdate.py:calcbasket_objext,calcbasket_objext,function,50,203,96,1094,5.39,1,7,"['RETURN', 'TMAX', 'riskind_i', 'wwmat', 'wwasset0', 'ww0', 'nbrange', 'criteria']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",2439,[],"['xrange', 'np.sum', 'math.sqrt']",3
utilmy/zarchive/portfolio_withdate.py:calc_ranktable,calc_ranktable,function,20,44,41,351,7.98,1,0,"['close2', 'symjp1', 'nlag', 'refindex', 'funeval', 'funargs']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",3849,[],"['np.zeros', 'getlogret_fromquotes', 'enumerate', 'funeval', 'util.np_sortbycolumn']",5
utilmy/zarchive/portfolio_withdate.py:similarity_correl,similarity_correl,function,7,10,9,88,8.8,0,0,"['ret_close2', 'funargs']","[None, None]","[None, None]",3869,[],['correlation_mat'],1
utilmy/zarchive/portfolio_withdate.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3924,[],['np_distance_l1'],1
utilmy/zarchive/portfolio_withdate.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3930,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/portfolio_withdate.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3924,[],['np_distance_l1'],1
utilmy/zarchive/portfolio_withdate.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3930,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/portfolio_withdate.py:get,get,function,11,44,26,436,9.91,0,1,"['close', 'timelag']","[None, None]","[None, None]",4293,"['    """"""Return dataframe of requested dataset from Quandl.\n', '    :param dataset: str or list, depending on single dataset usage or multiset usage\n', '            Dataset codes are available on the Quandl website\n', '    :param str api_key: Downloads are limited to 50 unless api_key is specified\n', '    :param str start_date, end_date: Optional datefilers, otherwise entire dataset is returned\n', '    :param str collapse: Options are daily, weekly, monthly, quarterly, annual\n', '    :param str transform: options are diff, rdiff, cumul, and normalize\n', '    :param int rows: Number of rows which will be returned\n', '    :param str order: options are asc, desc. Default: `asc`\n', '    :param str returns: specify what format you wish your dataset returned as,\n', '        either `numpy` for a numpy ndarray or `pandas`. Default: `pandas`\n', '    :returns: :class:`pandas.DataFrame` or :class:`numpy.ndarray`\n', '    Any other `kwargs` passed to `get` are sent as field/value params to Quandl\n', '    with no interference.\n', '\n', ""'''\n"", '\n', '\n', '\n', '#--------------------Import data from Yahoo --------------------------------------------------\n', 'def imp_yahoo_getquotes(symbols, start=""20150101"", end=""20160101"", type1=1):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', '# symbols = np.array(symbol1)\n', ' quotes= []; errorlist=[]; correctlist=[]\n', ' for i, symbol in enumerate(symbols) :\n', '   # if np.mod(i,400) ==0 and i != 0 :\n', ""     # print('Waiting 30s'); time.sleep(30)\n"", '   try:   \n', '     array1= quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '     df= pd.DataFrame.from_records(array1)\n', '     quotes.append(df)\n', '     correctlist.append(symbol)\n', '   except :\n', '       errorlist.append(symbol)\n', ""       print('Err: '+symbol)\n"", ' #quotes = [quotes_historical_yahoo(symbol, d1, d2, asobject=True)  for symbol in symbols]\n', ' #print(errorlist) \n', ' if type1==1 :  return quotes, correctlist\n', ' else: return quotes, correctlist, errorlist  \n', '\n', '              \n', '#Find error in Ticker import\n', 'def imp_yahoo_geterrorticker(symbols, start=""20150101"", end=""20160101""):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', ' errorlist= []\n', ' for symbol in symbols :\n', '   try :  \n', '     quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '   except :\n', '     errorlist.append(symbol)\n', '     print(symbol)       \n', ' return errorlist\n', ' \n', ""'''\n"", ""symbols0= ['KHC', 'PYPL', 'HPE', 'BXLT', 'SYF', 'WLTW', 'CFG', 'BF-B', 'WRK']\n"", '\n', '#Show list of ticker in error\n', 'import_errorticker(symbols0,""20110101"",""20150601""  )\n', ""'''\n"", '\n', '\n', 'def imp_yahoo_financials_url(ticker_symbol, statement=""is"", quarterly=False):\n', '    if statement == ""is"" or statement == ""bs"" or statement == ""cf"":\n', '        url = ""https://finance.yahoo.com/q/"" + statement + ""?s="" + ticker_symbol\n', '        if not quarterly:\n', '            url += ""&annual""; return BeautifulSoup(requests.get(url).text, ""html.parser"")\n', '    return sys.exit(""Invalid financial statement code \'"" + statement + ""\' passed."")\n', '\n', 'def imp_yahoo_periodic_figure(soup, yahoo_figure):\n', '    values = []; pattern = re.compile(yahoo_figure)\n', '\n', '    title = soup.find(""strong"", text=pattern)    # works for the figures printed in bold\n', '    if title:  row = title.parent.parent\n', '    else:\n', '        title = soup.find(""td"", text=pattern)    # works for any other available figure\n', '        if title:  row = title.parent\n', '        else:      sys.exit(""Invalid figure \'"" + yahoo_figure + ""\' passed."")\n', '\n', '    cells = row.find_all(""td"")[1:]    # exclude the <td> with figure name\n', '    for cell in cells:\n', '        if cell.text.strip() != yahoo_figure:    # needed because some figures are indented\n', '            str_value = cell.text.strip().replace("","", """").replace(""("", ""-"").replace("")"", """")\n', '            if str_value == ""-"": str_value = 0\n', '            value = int(str_value) * 1000\n', '            values.append(value)\n', '\n', '    return values\n', '    \n', '# print(imp_yahoo_periodic(imp_yahoo_financials_url(""AAPL"", ""is""), ""Income Tax Expense""))\n', '\n', ' \n', '\n', '#--------------------Import Quotes Google  ------------------------------------------\n', 'import requests.packages.urllib3\n', 'requests.packages.urllib3.disable_warnings()\n', 'import urllib, os\n', '\n', ""dirstockcsv= 'E:\\_data\\stock\\csv'\n"", '\n', 'def imp_googleIntradayQuote(symbol, freqsec=300, nday=5):\n', ""    ''' Intraday quotes from google. Specify interval seconds and number of days\n"", '    http://www.google.com/finance/getprices?q=7261&i=300&p=3d&f=d,o,h,l,c,v\n', ""    '''\n"", '    url =""http://www.google.com/finance/getprices?q={0}"".format(symbol)\n', '    url +=""&i={0}&p={1}d&f=d,o,h,l,c,v"".format(freqsec, nday)\n', '    try :      \n', '       resp= requests.post(url)\n', '       csv= resp.text\n', '       csv= csv.splitlines()\n', '    except :\n', ""       print('Err Intaday '+symbol)\n"", '\n', '    if len(csv) < 9 :\n', ""      print 'Using Daily',\n"", '\n', ""      url='http://www.google.com/finance/historical?q='+symbol+'&i='+str(freqsec)+'&p=3d&f=d,o,h,l,c,v&output=csv'\n"", '      csv = urllib.urlopen(url).readlines()\n', '      csv.reverse()\n', '      q=[]\n', '      for bar in xrange(0,len(csv)-1):\n', ""        ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '        if isfloat(open_) and isfloat(high) :\n', '          open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""          dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '          q.append([dt,open_,high,low,close,volume])\n', ""      df= util.pd_array_todataframe(q, ['date','open','high','low','close','volume'])\n"", '      return df\n', '\n', '\n', '    # print(csv)\n', '    qq=[]\n', '    for bar in xrange(7,len(csv)):\n', ""      if csv[bar].count(',')!=5: continue\n"", ""      offset,close,high,low,open_,volume = csv[bar].split(',')\n"", '      \n', ""      if offset[0]=='a':\n"", '        day = float(offset[1:])\n', '        offset = 0\n', '      else:\n', '        offset = float(offset)\n', '      open_, high, low, close = [float(x) for x in [open_,high,low,close]]\n', '      dt = datetime.datetime.fromtimestamp(day + (freqsec * offset))\n', '      #print (dt,open_,high,low,close,volume)\n', '      qq.append([dt,open_,high,low,close,volume])\n', ""    df= util.pd_array_todataframe(qq, ['date','open','high','low','close','volume'])\n"", '    return df\n', '\n', ""def imp_googleIntradayQuoteSave(symbols=['NKE'], freqsec=300, nday=2000, dircsv='', dbname=''):\n"", "" ''' Save Under various format: csv / db / output in Dataframe '''\n"", ' if isinstance(symbols, str) : symbols= [symbols]\n', ' symout,qlist, sym_error= [], [], []\n', ' for sym in symbols:\n', '   try :\n', '    q = imp_googleIntradayQuote(sym, freqsec, nday)  #interval, timeframe\n', '    print sym,\n', ""    sym= sym.replace(':', '_')\n"", '\n', ""    if dircsv != '' :\n"", '      if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""      start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""      file1= dircsv+ '\\\\' + sym + '_' + str(start1) + '_' + str(freqsec) + '_' + str(nday) + '.csv'\n"", '\n', ""      q= util.pd_addcol(q, 'symbol'); q['symbol']= sym\n"", '      q.to_csv(file1, index=False)\n', '\n', ""    elif dbname != '' :\n"", '      import sqlalchemy as sql\n', '      dbcon= sql.create_engine(dbname)\n', '      if interv_sec== 300 : # 5mins\n', ""        q.to_sql('q5min', dbcon)\n"", '\n', '    else :\n', '      qlist.append(q);   symout.append(sym)\n', '   except:\n', ""      print('Error:'+sym, )\n"", '      sym_error.append(sym)\n', '\n', ' return qlist, symout, sym_error\n', '\n', ""def imp_googleQuote(symbol, start_date='20160101', end_date= '20160101') : # datetime.date.today().isoformat()):\n"", ""    ''' Daily quotes from google. Date format='yyyymmdd' '''\n"", '    symbol = symbol.upper()\n', '    start = datetime.date(int(start_date[0:4]),int(start_date[4:6]),int(start_date[6:8]))\n', '    end =   datetime.date(int(end_date[0:4]),int(end_date[4:6]),int(end_date[6:8]))\n', '    url =""http://www.google.com/finance/historical?q={0}"".format(self.symbol)\n', '    url +=""&startdate={0}&enddate={1}&output=csv"".format( start.strftime(\'%b %d, %Y\'),end.strftime(\'%b %d, %Y\'))\n', '    csv = urllib.urlopen(url).readlines()\n', '    csv.reverse()\n', '    # print(url)\n', '    q=[]\n', '    for bar in xrange(0,len(csv)-1):\n', ""      ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '      if isfloat(open_) and isfloat(high) :\n', '        open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""        dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '        q.append([dt,open_,high,low,close,volume])\n', '    return q\n', '\n', 'def imp_googleQuoteSave(symbols, date1, date2, dircsv):\n', ' if isinstance(symbols, str) : symbols= [symbols]\n', ' for sym in symbols:\n', '   try :\n', '      q = imp_googleQuote(sym, date1, date2)   #interval, timeframe\n', ""   except: print('Error:'+symbol)\n"", '\n', ""   sym= sym.replace(':', '_')\n"", '\n', ""   if dircsv != '' :\n"", '     if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""     start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""     file1= dircsv+ '\\\\'+ name1+'_'+ start1 +'_'+ str(date2) +'.csv'\n"", '     q.to_csv(file1)\n', '\n', ""   if dbname != '' :\n"", '     import sqlalchemy as sql\n', '     dbcon= sql.create_engine(dbname)\n', '     if interv_sec== 300 : # 5mins\n', ""       q.to_sql('q5min', dbcon)\n"", '\n', '\n', '\n', ""def imp_csv_dbupdate(indir='E:/_data/stock/intraday/intraday_google_usetf2.h5',\n"", ""                     outdir='E:/_data/stock/intraday/q5min/us/etf/', filelist=[], intype='csv',\n"", ""                     refcols=['date', 'open', 'high', 'low', 'close', 'volume', 'symbol']) :\n"", '\n', '  for file1 in filelist :\n', ""    sym=  file1[:file1.find('_')]  #Clean Up name\n"", '    print sym,\n', ""    outfile= outdir+'/'+sym+'.csv'\n"", '    if os.path.isfile(outfile) :\n', ""      df0= imp_csv_toext(file1=outfile, fromzone='Japan', tozone='UTC', header=0, cols=refcols)\n"", '    else :\n', '      df0= None\n', '\n', ""    if intype== 'hdfs':\n"", '      df1= imp_hdfs_getquote(indir, sym)\n', '      if isinstance(df1, float) : df1= None\n', '\n', ""    if intype=='csv' :\n"", ""      infile= indir+'/'+ file1   #csv\n"", ""      df1= imp_csv_toext(file1=infile, header=0, cols=refcols, fromzone='Japan', tozone='UTC')\n"", '\n', '    if df1 is not None :\n', '       if df0 is not None  : df1= imp_pd_merge(df1[refcols], df0[refcols])\n', '       # return outfile, df1\n', '       df1[refcols].to_csv(outfile, index=False)\n', '\n', '\n', '#####################################################################################\n', 'def imp_numpy_close_fromdb(dbname=\'/aaserialize/store/yahoo.db\', table1=\'\', symlist=[], t0=20010101, t1=20010101, priceid=""close"", batchsize= 400, maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from DB SQL"")\n', ' import data.hist_data_storage as yhh\n', ' dstore= yhh.dailyDataStore(dbname)\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', '\n', "" dateref0= dstore.get_histo(['SPY'], table1='daily_us_etf', start1=str(t0), end1=str(t1),  split_df=0).date.values\n"", ' \n', ' k=0; symfull=[];   i=0\n', ' nsym= len(symlist); nbatch= int(nsym / batchsize)+1\n', ' for j in xrange(0, nbatch) : \n', '      qlist, sym= dstore.get_histo(symlist[i:min(nsym,i+batchsize)], table1=table1, start1=str(t0), end1=str(t1),  split_df=1)\n', '\n', '      #print(""batch: ""+str(j), len(qlist), len(qlist[0].index) )\n', '      #for k,q in enumerate(qlist) :print sym[k], len(q.index)\n', '      i= i + batchsize\n', '      symfull= np.concatenate((symfull,sym))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)\n', '      print(""batch: ""+str(j), len(sym),dateref[0],dateref[-1] )\n', '      qlist=None; sym=None\n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[k:k+masset,0:tmax] = close\n', '      k=k+ masset\n', '\n', ' maxasset= k\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', 'def imp_numpy_close_fromhdfs(dbfile, symlist=[], t0=20010101, t1=20010101, priceid=""close"", maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from Pandas"")\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', ' store = pd.HDFStore(dbfile)\n', ' \n', "" df= store.select('SPY')\n"", ' df= df[(df.date >= t0) & (df.date <= t1 )]\n', ' dateref0= df.date.values\n', ' \n', ' k=0; symfull=[]; qlist=[]; sym=[]; tmax= 2000\n', ' for j, symbol in enumerate(store.keys()):\n', '  symbol=  symbol[1:]\n', '\n', '  if len(symlist)==0  or  util.find(symbol,symlist) > -1 : \n', '   #print symbol, util.find(symbol,symlist) \n', '   df= store.select(symbol) \n', '   if t0 !=t1 :     df= df[(df.date >= t0) & (df.date <= t1 )]\n', '   \n', '   qlist.append(df);   sym.append(symbol)\n', '   if np.mod(j+1, 401) == 0 :\n', '      print(""batch: ""+str(j))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)   \n', '      print len(sym),dateref[0],dateref[-1] \n', '      symfull= symfull+sym\n', '      qlist=[]; sym=[]\n', ' \n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[(k):(k+masset),0:tmax] = close\n', '      k=k+ masset   \n', '     \n', ' if len(qlist) > 0:\n', '  # return qlist, qlist[0] ,  qlist[1] \n', '   close,dateref= date_align(qlist,type1=priceid)   \n', '   print len(sym),dateref[0],dateref[-1] \n', '   symfull= symfull+sym\n', '   masset,tmax= np.shape(close);\n', '   close2[(k):(k+masset),0:tmax] = close\n', ' \n', ' maxasset= k+masset\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', '\n', ""def imp_sql_getquotes(stocklist01, dbname='sqlite:///aaserialize/store/yahoo.db', start1=20150101, end1=20160616, table1='daily_us_stock'):\n"", '    import data.hist_data_storage as yhh\n', '    dstore = yhh.dailyDataStore(dbname)\n', '    qlist, sym= dstore.get_histo(stocklist01, table1=table1,  start1=start1, end1=end1, split_df=1)\n', '    return qlist, sym\n', '\n', ""def imp_txt_getquotes(stocklist01, filedir='E:/_data/stock/daily/20160610/jp', startdate=20150101, endate=20160616):\n"", ' liststockfile= util.listallfile(filedir, ""*.txt"", dirlevel=5)\n', ' #print liststockfile\n', ' if len(np.shape(liststockfile)) > 1 :\n', '  liststockname=[ x.split(""."")[0] for x in liststockfile[:,0] ]\n', '#  for k in range(0, np.shape(liststockfile)[0]):  liststockname.append( (liststockfile[k,0])[0:4])   \n', '   \n', ' else: \n', '  stk0= liststockfile[0]; #stk2= liststockfile[2]\n', '#  liststockname=[ x[0:4] for x in stk0 ]\n', '  liststockname=[ x for x in stk0 ]\n', '\n', '#  liststockname=[]\n', '#  for k in range(0, len(stk0)):  liststockname.append( (stk0[k])[0:4])\n', ' \n', ' quotes=[]\n', ' print liststockname\n', ' for sym in stocklist01:\n', '   kstock= util.np_findfirst(sym, liststockname)\n', '   if kstock == -1 :\n', ""     print('Not Found '+sym)\n"", '   else :\n', '     df= pd.read_csv(liststockfile[kstock][2])\n', ""     df.columns = ['date', 'open', 'high','low','close', 'volume', 'openint']  #Change Column Name\n"", '     df2= df[(df.date > startdate  )& ( df.date   < endate )] # Filter by date\n', '     quotes.append(df2)\n', '  \n', ' return quotes \n', '\n', '\n', 'def imp_csv_getname(name1, date1, inter, tframe):\n', "" file1= dirstockcsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", ' return file1\n', '\n', '\n', 'from dateutil import tz\n', ""def imp_csv_toext(file1='SPY.csv', outputfile='.h5', fromzone='Japan', tozone='UTC', header=None,\n"", ""                  cols=['date', 'time','open','high','low','close','volume', 'symbol'], coldate=[0]):\n"", ""  ''' cols: column name,  coldate: position of date column   '''\n"", '  from dateutil import parser\n', '\n', '  if os.path.getsize(file1)> 500 :\n', ""   df = pd.read_csv(file1,sep=',',header=header)  # date_parser=dateparse)  # parse_dates={'date': [] },\n"", '   df.date= [ parser.parse(x) for x in  df.date]\n', '\n', ""   #if util.find('symbol', df.columns.values) < 0 :\n"", ""     #df= util.pd_addcol(df, 'symbol')\n"", ""     #df['symbol']= sym\n"", '\n', ""   type1= outputfile[outputfile.find('.'):]\n"", '\n', ""   if outputfile=='':\n"", '     # df.columns = [  x.lower() for x in df.columns.values ]\n', ""     # df.columns = ['date', 'symbol','open','high','low','close','volume']\n"", '     df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""     df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""     df.columns = ['date', 'open','high','low','close','volume', 'symbol']\n"", '     return df[cols]\n', '\n', ""   if type1=='csv' :\n"", ""     df[cols].to_csv(outputfile , index=False)  # , compression='gzip' )\n"", '\n', ""   if type1== 'h5' :\n"", ""      # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '      dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '      # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '      # df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '      # df.date= [x.to_datetime() for x in  df.date]\n', '\n', '      df.drop(df.columns[[0]], axis=1, inplace=True)\n', '      print filenameh5\n', ""      if util.find('symbol', df.columns.values) < 0 :\n"", ""         df= util.pd_addcol(df, 'symbol'); df['symbol']= dfname\n"", '      store = pd.HDFStore(outputfile); store.append(dfname, df);  store.close()\n', '\n', '\n', '\n', ""def imp_hdfs_db_updatefromcsv(dircsv, filepd=r'E:\\_data\\stock\\intraday_google.h5', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= filepd + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2, name1, fromtimezone, tozone)\n', '\n', ""def imp_hdfs_db_dumpinfo(dbfile='E:\\_data\\stock\\intraday_google.h5'):\n"", '  store = pd.HDFStore(dbfile)\n', '  extract=[]; errsym=[]\n', '  for symbol in store.keys():\n', '     try:\n', '       df= pd.read_hdf(dbfile, symbol)\n', ""       t0= df['date'].values[0]\n"", ""       t1= df['date'].values[-1]\n"", '\n', '       extract.append([symbol[1:], df.shape[1],   df.shape[0], t0, t1 ])\n', '\n', '     except: errsym.append(symbol)\n', '  return np.array(extract), errsym\n', '\n', 'def imp_hdfs_mergedb(filepdfrom, filepdto) :\n', '  store0 = pd.HDFStore(filepdfrom)\n', '  store1 = pd.HDFStore(filepdto)\n', '\n', '  for symbol in store0.keys():\n', '    qq= imp_hdfs_getquote(filepdfrom, symbol)\n', '    store1.append(symbol, qq)\n', '\n', '    qq= imp_hdfs_getquote(filepdto, symbol)\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    print(symbol)\n', '  store0.close(); store1.close()\n', '\n', ""def imp_hdfs_storecopy(hdfs1='F:/usstock8.h5', hdfs2='F:/usstock8.h5'):\n"", ' store = pd.HDFStore(hdfs1);  store2 = pd.HDFStore(hdfs2)\n', ' for symbol in store.keys() :\n', '   df= imp_hdfs_getquote(hdfs1, symbol)\n', '   symbol= symbol[1:].replace(""-"",""_"")\n', '   store2.append(symbol, df, data_columns=True)\n', ' store.close(); store2.close()\n', '\n', 'def imp_hdfs_getquote(filenameh5, dfname=""data""):\n', '  try: return  pd.read_hdf(filenameh5, dfname)\n', '  except: return -1.0;\n', '\n', ""def imp_hdfs_getListquote(symbols, close1='close', start='12/18/2015 00:00:00+00:00',\n"", ""                          end='3/1/2016 00:00:00+00:00', freq='0d0h10min', filepd= 'E:\\_data\\stock\\intraday_google.h5',\n"", ""                          tozone='Japan', fillna=True, interpo=True):\n"", '\n', ' datefilter= pd.date_range(start=start, end=end, freq= freq,tz=tozone).values\n', '\n', ' errorsym=[]; quotes=[]; correctsym=[]\n', ' for symbol in symbols:  # Issue Not same size\n', '   qq= imp_hdfs_getquote(filepd, symbol)\n', '\n', '   if type(qq)==np.float :  # Error qq=-1\n', '        errorsym.append(symbol)\n', '   else:\n', ""       qq.columns = ['date', 'symbol','open','high','low','close','volume']\n"", ""       qq= qq[qq['date'].isin(datefilter)]   #Only date in the range\n"", ""       #qq= qq.drop_duplicates(cols='date', take_last=True)\n"", ""       #  qq= qq.sort('date', asc=True)\n"", '\n', '       #print qq.date.values[0]\n', ""       if fillna : qq= qq.fillna(method='backfill')\n"", '       if interpo : qq= qq.interpolate()\n', '       quotes.append(qq)\n', '       correctsym.append(symbol)\n', '\n', ' datefilter= datenumpy_todatetime(datefilter)\n', ' return quotes,datefilter, correctsym,   errorsym\n', '\n', '\n', ""def imp_hdfs_removeDuplicate(filepd='E:\\_data\\stock\\intraday_google.h5') :\n"", '  #-------Clean by removing duplicate-------------------------------------------------\n', '  store = pd.HDFStore(filepd)\n', '  for symbol in store.keys():\n', '    #qq= imp_hdfs_getquote(filepd, symbol);\n', '    qq= store.select(symbol[1:])\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    qq.index = list(np.arange(0,len(qq.index)))\n', '\n', '    store.remove(symbol); store.append(symbol, qq);\n', '  store.close()\n', '\n', '\n', '\n', ""def imp_pd_tohdfs(sym, qqlist, filenameh5, fromzone='Japan', tozone='UTC') :\n"", ""  ''' df list to HDFS '''\n"", '  store = pd.HDFStore(filenameh5);\n', '  for k, df2 in enumerate(qqlist) :\n', '    df= copy.deepcopy(df2)\n', ""    df['date']= datetime_toint(df.date.values)\n"", '\n', ""    symbol= sym[k].replace('-','_')\n"", '    qq= imp_hdfs_getquote(filenameh5, symbol)\n', '    # print symbol, type(qq)\n', '    if type(qq) ==  float or  type(qq) ==  int  :\n', '      store.append(symbol, df)  # , data_columns=True\n', '      # print(symbol + str(df.date.values[-1]))\n', '    else :\n', '      qq= pd.concat([qq, df], ignore_index=True)\n', ""      qq= qq.drop_duplicates(subset='date', keep='last')\n"", ""      qq= qq.sort('date', ascending=1)\n"", '      store.append(symbol, qq)  #Too much space , data_columns=True\n', '      print(symbol + str(qq.date.values[-1]))\n', '\n', '  store.close()\n', '\n', 'def imp_pd_merge(df1, df2) :\n', '  df= pd.concat([df1, df2], axis=0)\n', ""  df= df.drop_duplicates(subset='date', keep='last')\n"", ""  df= df.sort_values(by=['date'], ascending=1)\n"", '  df.index = list(np.arange(0,len(df.index)))\n', '  return df\n', '\n', 'def imp_pd_checkquote(quotes) :\n', ""   for c in quotes: print np.shape(c), c['date'].values[0], c['date'].values[-1]\n"", '\n', 'def imp_pd_getclose(df, datefilter=None):\n', ' if datefilter is  not None :\n', ""    df= df[df['date'].isin(datefilter)]   #Only date in the range\n"", "" df= df.sort('date')\n"", "" close= df.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", ' \n', ' close= np.array(close.values[1:,1:]).astype(np.float)            #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close\n', '\n', 'def imp_pd_cashyield(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  100 * np.cumprod( (1 + np.ones(len(vv)) * 0.005/365.0 ))\n', '     qbond[id1]= pbond\n', '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_yield_tobond(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  1/ np.power(1+ vv*0.01,duration) *100\n', '     qbond[id1]= pbond\n', ""#     print 'ok'\n"", '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_errordate(quotes, dateref):\n', "" ''' Show Symbol in Error when importing '''\n"", ' for i, stock in enumerate(quotes) :\n', '   print(i, symbols1[i],  datetime_tostring(stock[0][0]))\n', ' print(""\\n\\n"")\n', '\n', ' for i, stock in enumerate(quotes) :\n', '   date1= datetime_toint(stock[0][0])\n', '   if date1 != dateref : print(i, symbols1[i],  str(date1))\n', '\n', 'def imp_pd_fxtoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', 'def imp_pd_fxinversetoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(1.0 / q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', ""def imp_pd_filterbydate(df, dtref=None, start='2016-06-06 00:00:00', end='2016-06-14 00:00:00', freq='0d0h05min', timezone='Japan'):\n"", "" ''' df: DateSeries or TimeSeries of Quotes   '''\n"", '\n', ' if type(df) in {pd.core.frame.DataFrame} :  #Data frame version\n', '   if type(dtref)== str:\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', ""   return df[df['date'].isin(dtref)]\n"", ' else :\n', '   if type(dtref)== str:  #Date version\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', '   return df[df.isin(dtref)].values\n', '\n', 'def imp_pd_cleanquote(q):\n', ' col= q.columns.values\n', "" if isinstance(q['date'].values[0] , str) :\n"", ""   q['date']= datetime_todate(datestring_todatetime(q['date'].values))\n"", '\n', ' for kid in col:\n', ""   if kid not in ['date', 'day','month','year'] :\n"", ""      q[kid]= pd.to_numeric(q[kid], errors='coerce').values  #Put NA on string\n"", '\n', "" q= q.fillna(method='pad')\n"", ' return q\n', '\n', 'def imp_pd_divide(q1, q2, funapply):\n', "" close, dateref= date_align([q1,q2], type1='close')\n"", ' m,tt= np.shape(close)\n', '\n', ' q3= util.pd_createdf( np.zeros((tt,len(q1.columns))) ,q1.columns, dateref)\n', "" q3['date']= dateref\n"", "" q3['close']= (close[0,:] / close[1,:])\n"", '\n', ' for kid in q1.columns :\n', ""   if kid not in ['close', 'volume','date','day','month', 'year'] :\n"", '     close, _= date_align([q1,q2], type1=kid)\n', '     q3[kid]= (close[0,:] / close[1,:])\n', ' return q3\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""def imp_quote_csvdir_tofile(dircsv='', outdir1='E:/_data/stock/', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= outdir + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2,  header=True, fromzone=fromtimezone, tozone=tozone)\n', ""'''\n"", '\n', '\n', ""'''\n"", ""close1='Close' ; start='12/18/2015 00:00:00';\n"", ""end='3/1/2016 00:00:00'; freq='1d0h00min';\n"", ""filepd= 'E:\\_data\\stock\\intraday_google.h5'\n"", '\n', 'datefilter= pd.date_range(start=start, end=end,   freq= freq).values\n', '\n', 'symbols, names = np.array(list(symbol_dict.items())).T\n', 'i=0; vv=[]\n', 'for symbol in symbols:  # Issue Not same size\n', '   qq= quote_frompanda(filepd, symbol); i+=1\n', '   if isfloat(qq) :  vv.append(symbol)\n', '   else:\n', ""     if i==1: close = qq[['Datetime']]  #new dataframe    \n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', '     if not tmp.isnull().values.all():\n', ""      close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""      close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', ""close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", ""close= close.sort('Datetime')\n"", ""close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", 'close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', 'close= close[(np.abs(stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', ""'''\n"", 'from datetime import datetime\n', 'from dateutil import tz\n', '\n', ""from_zone = tz.gettz('Japan'); to_zone = tz.gettz('UTC')\n"", '\n', ""date1 = datetime.strptime('2011-01-21 09:00:00', '%Y-%m-%d %H:%M:%S')\n"", 'date1 = date1.replace(tzinfo=from_zone)\n', 'dateutc = date1.astimezone(to_zone)\n', 'date1, dateutc\n', '\n', ""Suppose you have a column 'datetime' with your string, then:\n"", ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\n"", ' combine multiple columns into a single datetime column,\n', ""this merges a 'date' and a 'time' column into a single 'datetime' column:\n"", '\n', ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)\n"", ""'''\n"", '\n', '\n', '#date1 = ""20160302""; inter= 60; tframe=80; name1= ""spy""\n', '#googleIntradayQuoteSave(name1, inter, tframe)\n', '\n', '\n', '\n', 'def ta_mar(close,t,m):  return  100*( np.mean(close[(t-m):(t+1)], axis=0) / close[t] )\n', 'def ta_ma(close,t,m):  return   np.mean(close[(t-m):(t+1)], axis=0)\n', '\n', '\n', '############################################################################\n', '#---------------------Calculate the Statistics         --------------------  \n', 'def calc_statestock(close2, dateref, symfull):\n', ' def sort(x,col,asc): return   util.sortcol(x,col,asc)\n', ' def perf(close,t0,t1):  return  100*( close[:,t1] / close[:,t0] -1)\n', ' def and2(tuple1):  return np.logical_and.reduce(tuple1)\n', ' def mar(close,t,m):  return  100*( np.mean(close[:,(t-m):(t+1)], axis=1) / close[:,t] )\n', ' def ma(close,t,m):  return   np.mean(close[:,(t-m):(t+1)], axis=1)\n', '\n', '\n', ' # a= ma(close2, tmax, 5) / ma(close2, tmax, 50)  \n', '\n', '\n', ' def dd(t) :\n', '  x= util.find(t,dateref)  # 607\n', ""  if x==-1 : print 'Error date not found in dateref '+str(t) ; return np.nan\n"", '  else :  return x\n', '\n', ' def gap(close,t0,t1,lag):   \n', '  ret= getret_fromquotes(close[:,t0:t1],lag)\n', '  rmin= 100*np.amin(ret,axis=1)\n', '  return rmin\n', ' \n', ' #--------------------Size----------------------------------------- \n', ' masset= len(symfull)\n', ' ttmax= util.find(0,close2[0,:])\n', ' if ttmax==-1 : ttmax= np.shape(close2)[1]\n', ' close2= close2[0:masset,0:ttmax]\n', ' m, tmax= masset, ttmax-1\n', ' \n', ' #correl\n', ' #close3= np.array(close2[:,0:ttmax],dtype=np.float16)\n', ' #close2ret= getret_fromquotes(close3)\n', ' #close2ret= np.nan_to_num(close2ret)\n', ' #close2ret= util.np_cleanmatrix(close2ret);  del close3\n', '\n', '##################################################################################\n', '#1: 1d,2:5d,3:10d,4:15d,5:20d,11:50d,12:60d,13:90d,15:1y\n', '#16: YTD,17:From Feb,21: 2015Ret,45: Price,50,51: Min,52,53: Max\n', ' print(""Calcul the Stats "" + str(dateref[-1]))\n', ' stat= np.zeros((2600,200),dtype=np.float16)\n', '\n', ' k=0\n', ' stat[k:(k+m),0]= np.arange(k,k+m)\n', ' stat[k:(k+m),1]=  perf(close2,tmax-1,tmax)  \n', ' stat[k:(k+m),2]=  perf(close2,tmax-5,tmax)  \n', ' stat[k:(k+m),3]=  perf(close2,tmax-10,tmax)  \n', ' stat[k:(k+m),4]=  perf(close2,tmax-15,tmax)  \n', ' stat[k:(k+m),5]=  perf(close2,tmax-20,tmax)  \n', '# stat[k:(k+m),6]=  perf(close2,tmax-25,tmax)  \n', ' stat[k:(k+m),7]=  perf(close2,tmax-30,tmax)  \n', '# stat[k:(k+m),8]=  perf(close2,tmax-35,tmax)  \n', ' stat[k:(k+m),9]=  perf(close2,tmax-40,tmax)  \n', '# stat[k:(k+m),10]=  perf(close2,tmax-45,tmax)  \n', ' stat[k:(k+m),11]=  perf(close2,tmax-50,tmax)  \n', ' stat[k:(k+m),12]=  perf(close2,tmax-60,tmax)  \n', ' stat[k:(k+m),13]=  perf(close2,tmax-90,tmax)  \n', ' stat[k:(k+m),14]=  perf(close2,tmax-120,tmax)  \n', ' stat[k:(k+m),15]=  perf(close2,tmax-250,tmax)  \n', '\n', '\n', '# stat[k:(k+m),16]=  perf(close2, dd(20160105),tmax)   #1Jan 2016\n', '# stat[k:(k+m),17]=  perf(close2, dd(20160222),tmax)   # 22 Feb 2016\n', '# stat[k:(k+m),18]=  perf(close2,dd(20160105),dd(20160222))   # Crash DrawDown\n', ' # stat[k:(k+m),19]=  perf(close2,624,tmax)   #  24 June 2016\n', ' # stat[k:(k+m),20]=  perf(close2,623,625)   #  Crash 24 June 2016\n', ' # stat[k:(k+m),21]=  perf(close2,dd(20151230)-250,dd(20151230))    #2015 Return\n', '\n', ' stat[k:(k+m),22]= gap(close2,tmax-80,tmax,1) #Max 1 days Gap\n', ' stat[k:(k+m),23]= gap(close2,tmax-80,tmax,5) #Max 5 days Gap\n', ' stat[k:(k+m),24]= perf(close2,tmax-2,tmax)  \n', ' stat[k:(k+m),25]= perf(close2,tmax-3,tmax)  \n', ' stat[k:(k+m),26]= perf(close2,tmax-4,tmax)  \n', '\n', ' stat[k:(k+m),27]= perf(close2,tmax-2,tmax-1)   \n', ' stat[k:(k+m),28]= perf(close2,tmax-3,tmax-2)   \n', ' stat[k:(k+m),29]= perf(close2,tmax-4,tmax-3)   \n', ' stat[k:(k+m),30]= perf(close2,tmax-5,tmax-4)\n', ' \n', ' stat[k:(k+m),120]= mar(close2, tmax, 20) \n', ' stat[k:(k+m),121]= mar(close2, tmax, 50) \n', ' stat[k:(k+m),122]= 100*ma(close2, tmax, 5) / ma(close2, tmax, 50)  #OverSold /OverBought\n', ' stat[k:(k+m),123]= mar(close2, tmax, 100)  \n', ' stat[k:(k+m),124]= mar(close2, tmax, 10) \n', '# stat[k:(k+m),35]= 0 \n', '# stat[k:(k+m),36]= 0 \n', '# stat[k:(k+m),37]= 0 \n', '# stat[k:(k+m),38]= 0 \n', '# stat[k:(k+m),39]= 0 \n', '\n', ' # stat[k:(k+m),30]= volume / AvgVol3M\n', ' # stat[k:(k+m),30]= Nbday_to_Earnings\n', ' #Volume/3M AvgVolume\n', ' # stat[k:(k+m),26]=  volume(volume2,tmax-120,tmax)  \n', '\n', ' #==============================================================================\n', ' #-------------- Data Fundamental    -------------------------------------------\n', "" df= util.sql_query(sqlr='SELECT ticker,shortratio,sector1_id, sector2_id, marketcap   FROM stockfundamental ', dburl='/aaserialize/store/finviz.db')\n"", ' npdf= df.values; del df\n', ' npdf0= npdf[:,0]  \n', ' for i in range(0,m):  \n', '   try :\n', '     kid= util.find(symfull[i], npdf0)\n', '     if kid != -1 :\n', '      stat[i,150]=  float(npdf[kid, 1])   # short ratio\n', '      stat[i,151]=  float(npdf[kid, 2])   # sector 1      \n', '      stat[i,152]=  float(npdf[kid, 3])   # sector 2     \n', '      stat[i,153]=  float(npdf[kid, 4] / 100000000.0)   # market Cap    \n', '   except : pass\n', ' del npdf, npdf0\n', '\n', '\n', '#==============================================================================\n', ' ################ Volatility\n', ' stat[k:(k+m),40]= volhisto_fromprice(close2,tmax,20,axis=1)* 100\n', ' stat[k:(k+m),41]= volhisto_fromprice(close2,tmax,60,axis=1)* 100\n', ' stat[k:(k+m),42]= volhisto_fromprice(close2,tmax,252,axis=1)* 100\n', '# stat[k:(k+m),43]= stat[k:(k+m),12] / stat[k:(k+m),41] #Sharpe 3Month\n', '# stat[k:(k+m),44]= stat[k:(k+m),15] / stat[k:(k+m),42] #Sharpe 1Year\n', '\n', ' stat[k:(k+m),45]= close2[:,tmax] #Last Close\n', '\n', '# stat[k:(k+m),46]= 0 \n', '# stat[k:(k+m),47]= 0 \n', '# stat[k:(k+m),48]= 0 \n', '# stat[k:(k+m),49]= 0 \n', '\n', '\n', ' ###############  Technical Indicator\n', ' #Min of last 6 months, Max of last 6months\n', ' for i in range(0,m):\n', '  pp0= stat[i,45]\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-120):tmax])\n', '  stat[i,50]= kmin+(tmax-120);  stat[i,51]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-120):tmax])\n', '  stat[i,52]= kmax+(tmax-120);  stat[i,53]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-10):tmax])\n', '  stat[i,66]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-10):tmax])\n', '  stat[i,67]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-5):tmax])\n', '  stat[i,68]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-5):tmax])\n', '  stat[i,69]= 100*pp0 / pmax\n', '\n', ' del kmax,pmax,i,k  \n', '\n', '\n', ' #Regression from Min Price Time\n', ' for i in range(0,m):\n', '  t0= int(stat[i,50])\n', '  try :\n', '    res= regression(close2[i,t0:tmax ]  ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,54]=  res[2]  #R2\n', '    stat[i,55]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from Max Price Time\n', ' for i in range(0,m):  \n', '  t0= stat[i,52]\n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,56]=  res[2]  #R2\n', '    stat[i,57]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from 5 days ago\n', ' t0= tmax-5\n', ' for i in range(0,m): \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,58]=  res[2]  #R2\n', '    stat[i,59]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', '#Regression from 10 days ago\n', ' t0= tmax-10\n', ' for i in range(0,m):  \n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,60]=  res[2]  #R2\n', '    stat[i,61]=  res[0][0]  #Slope\n', '   except : pass\n', '\n', "" '''\n"", '#Regression from 1 month\n', ' t0= tmax-20   \n', ' for i in range(0,m):\n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,62]=  res[2]  #R2\n', '    stat[i,63]=  res[0][0]  #Slope\n', '   except : pass\n', "" '''\n"", '\n', "" '''\n"", '#Regression from 2 months ago\n', ' t0= tmax-40\n', ' for i in range(0,m):  \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,64]=  res[2]  #R2\n', '    stat[i,65]=  res[0][0]  #Slope\n', '  except : pass\n', "" '''\n"", '\n', '#Nb of Positive days last 5d\n', ' for i in range(0,m):  stat[i,66]=  np_countretsign(close2[i,(tmax-5):tmax])  \n', '\n', '#Nb of Positive days last 10d\n', ' for i in range(0,m):  stat[i,67]=  np_countretsign(close2[i,(tmax-10):tmax])  \n', '\n', '#Nb of Positive days last 20d\n', '# for i in range(0,m):  stat[i,68]=  np_countretsign(close2[i,(tmax-20):tmax])  \n', '\n', '\n', '#Regression from Max Values,200days\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,70]=  res[2]  #R2\n', '    stat[i,71]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmax\n', '\n', '\n', '#Regression from Min Values,200days \n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,72]=  res[2]  #R2\n', '    stat[i,73]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmin\n', '\n', '\n', '#Regression from Max Values,100days\n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,74]=  res[2]  #R2\n', '    stat[i,75]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmax\n', '\n', '\n', '#Regression from Min Values,100days \n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,76]=  res[2]  #R2\n', '    stat[i,77]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmin\n', '\n', '\n', '\n', '# Upside Trend with Higher Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '   vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '   vmax= util.sort(vmax,0,asc=0)\n', '   stat[i,80]=  -1\n', '   if len(vmax) > 1 :\n', '    ss=0\n', '    for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '    if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,80]=  ss  \n', '        stat[i,81]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Upside Trend with Higher High detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '    vmax= util.sort(vmax,0,asc=0)\n', '    stat[i,82]=  -1\n', '    if len(vmax) > 1 :\n', '      ss=0\n', '      for k in range(0,len(vmax)-1):\n', '        if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher high\n', '        else : break;\n', '      if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,82]=  ss  \n', '        stat[i,83]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Downside Trend with lower Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,84]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,84]=  ss  \n', '        stat[i,85]=  vmax[0,0] + t0\n', '\n', '\n', '# Downside Trend  with lower highs detection\n', ' t0= tmax-20*6\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,80]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,86]=  ss    #Nb  of lower high consecutive\n', '        stat[i,87]=  vmax[0,0] + t0\n', '\n', "" print('Higher/Lower Band Support')\n"", '#-----higher band Support / Lower Band Support 120days-------------------------------\n', ' t0= tmax-120\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,90]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,91]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,92]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '    # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1]) \n', '    # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 200days-------------------------------\n', ' t0= tmax-200\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,93]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,94]= 100.0 * stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,95]= 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 300days-------------------------------------\n', ' t0= tmax-300\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,96]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,97]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,98]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', ""  '''\n"", '  # -----higher band Support / Lower Band Support 60days-------------------------------\n', '  t0 = tmax - 60\n', '  for i in range(0, m):\n', '      try:\n', '          res1 = ta_highbandtrend1(close2[i, t0:tmax])\n', '          pmax = (res1.x[0] * (tmax - t0) + res1.x[1])\n', '          stat[i, 99] = 100.0 * stat[i, 45] / pmax  # Higher Band\n', '\n', '          res2 = ta_lowbandtrend1(close2[i, t0:tmax])\n', '          pmin = (res2.x[0] * (tmax - t0) + res2.x[1])\n', '          stat[i, 100] = 100.0 * stat[i, 45] / pmin  # LowerBand\n', '\n', '          stat[i, 101] = 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)  # Price inside Range\n', '\n', '          # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1])\n', '          # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '      except:\n', '          pass\n', ""  '''\n"", '\n', '  #-----Technical Indicator------------------------------------------------\n', '# for i in range(0,m): \n', '#  try :\n', '#   res2=0\n', '   # df= pd.read_hdf(dbfile, symfull[i])\n', '   # stat[i,110]= ta.RMI(close2[i,:])\n', '   # stat[i,111]= 100*close2[i,:] / ta.MA(close2[i,:],20)\n', '   # stat[i,112]= 100*close2[i,:] / ta.MA(close2[i,:],50)   \n', '#  except: pass\n', '\n', '\n', ' return np.array(stat, dtype=np.float16) \n', '\n', '\n', ""'''  \n"", 'i=1964  \n', 'stat= s1\n', 'stat[i, 91]  \n', '\n', 'tt= np.arange(t0, tmax)\n', 'plot_price(close2[i,t0:tmax], (res2.x[0] * (tt-t0) + res2.x[1]) )\n', ""'''\n"", '\n', '  \n', '#------------------- Stock Monitoring Tools ------------------------------------------------\n', ""def monitor_addrecommend(string1, dbname='stock_recommend') :\n"", ' ss= string1.replace(""("","" "").replace(\')\',\' \').replace(\':\',\' \')\n', "" ss= ss.replace('\\t', ' ').replace('\\n', ' ')\n"", ' sl1= ss.split("" "")\n', ' print sl1\n', ' aux= [datestring_toint(util.date_now())]\n', ' symfull= copy.deepcopy(a_us_all)\n', ' for x in sl1:\n', '   if len(x) < 5 :\n', '    if util.find(x,symfull) > 0 :   aux.append(x)\n', '\n', ' if len(aux) >  1 :\n', '  stock_recommend= util.load_obj(dbname)\n', '  stock_recommend.append(aux)\n', '  util.save_obj(stock_recommend,dbname)\n', '  print aux\n', ' return stock_recommend\n', '\n', '\n', '\n', '#################### Finviz  ###############################################################\n', 'from bs4 import BeautifulSoup\n', 'import csv,datetime, requests\n', 'def imp_finviz():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Overview Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=111&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(111) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 10].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 10\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockoverview.csv', 'wb') as csvfile:\n"", ""    overview = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    overview.writeheader()\n', '\n', '    for stock in alldata:\n', '        overview.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10] })\n', '\n', ' print ""Finviz Overview Completed""\n', ' return overview\n', ' \n', '\n', 'def imp_finviz_news():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Performance Start""\n', ' url = ""http://www.finviz.com/quote.ashx?t=intc""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', ' titleslist = soup.find_all(\'a\',{""class"" : ""tab-link-news""})\n', ' return titleslist\n', '\n', '\n', 'def imp_finviz_financials():\n', ' import datetime\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=161&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(161) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 17].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 16].text,stockdata[datalength - 15].text,stockdata[datalength - 14].text,stockdata[datalength - 13].text,stockdata[datalength - 12].text,stockdata[datalength - 11].text,stockdata[datalength - 10].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 17\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockfinancial.csv', 'wb') as csvfile:\n"", ""    financial = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    financial.writeheader()\n', '\n', '    for stock in alldata:\n', '        financial.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10],titlesarray[11] : stock[11],titlesarray[12] : stock[12],titlesarray[13] : stock[13],titlesarray[14] : stock[14],titlesarray[15] : stock[15],titlesarray[16] : stock[16],titlesarray[17] : stock[17] })\n', '\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Completed""\n', '\n', '\n', '\n', 'def get_price2book( symbol ):\n', '   from bs4 import BeautifulSoup as bs\n', '   import urllib as u\n', '   try:\n', ""    \turl = r'http://finviz.com/quote.ashx?t={}'.format(symbol.lower())\n"", '        html = u.request.urlopen(url).read()\n', ""        soup = bs(html, 'lxml')\n"", '        # Change the text below to get a diff metric\n', ""        pb =  soup.find(text = r'P/B')\n"", ""        pb_ = pb.find_next(class_='snapshot-td2').text\n"", ""        print( '{} price to book = {}'.format(symbol, pb_) )\n"", '        return pb_\n', '   except Exception as e:\n', '        print(e)\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ' try:\n', '   q = imp_googleQuote(name1, date1, date2)  #interval, timeframe\n', ""   name1= name1.replace(':','_')\n"", ""   file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(date2) +'.csv'\n"", '   q.write_csv(file1)\n', ' except: print\n', ""'''\n"", '\n', '\n', ""'''\n"", 'def imp_googleQuoteList(symbols, freqsec=300, nday=1, intraday1=True) :\n', ' qlist=[]; sym=[]\n', ' if intraday1:\n', '  for symbol in symbols:\n', '     #try :\n', '        q = imp_googleIntradayQuote(symbol, freqsec, nday)  #interval, timeframe\n', '        qlist.append(q)\n', '        sym.append(symbol)\n', ""     #except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       q = imp_googleQuote(name1, freqsec, num_days)  #interval, timeframe\n', '     except: print(symbol)\n', '\n', ' return qlist, sym\n', ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''        \n"", ""stock_list = ['XOM','AMZN','AAPL','SWKS']\n"", 'p2b_series = pd.Series( index=stock_list )\n', '\n', 'for sym in stock_list:\tp2b_series[sym] = get_price2book(sym)\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", "" # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", ' from dateutil.parser import parse\n', ' if os.path.getsize(file1)> 500 :\n', '  from_zone = tz.gettz(fromzone); tozone = tz.gettz(tozone)\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%m-%d-%Y %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', '  dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '\n', '  # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '  print file1\n', ""  #df = pd.read_csv(file1,sep=',',header=None, parse_dates={'date': [1]}, date_parser=dateparse)\n"", '\n', ""  df = pd.read_csv(file1,sep=',',header=0)\n"", '  #df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '  #df.date= [x.to_datetime() for x in  df.date]\n', '\n', '\n', '  df.drop(df.columns[[0]], axis=1, inplace=True)\n', ""  df= util.pd_addcol(df, 'symbol')\n"", ""  df['symbol']= dfname\n"", '\n', '  print filenameh5\n', ""  df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", ""  df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", '\n', '  # store = pd.HDFStore(filenameh5);\n', '  # store.append(dfname, df);  store.close()\n', ""'''\n"", '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dropcol=[], type1='csv', hasheader=True, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", ' if os.path.getsize(file1)> 500 :\n', '   header= 0 if hasheader else None\n', ""   df = pd.read_csv(file1, sep=',',header=0)\n"", '\n', '   df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""   df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""   df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", '\n', ""   if type1=='csv' :\n"", ""     df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""     if i==1: close = qq[['Datetime']]  #new dataframe\n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', ""     close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""     close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', "" close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", "" close= close.sort('Datetime')\n"", "" close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", '\n', ' close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", 'class Quote(object):\n', ""  DATE_FMT = '%Y-%m-%d';  TIME_FMT = '%H:%M:%S'\n"", '\n', '  def __init__(self):\n', ""    self.symbol = '';    self.exchn=''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', '\n', '  def append(self,dt,open_,high,low,close,volume):\n', '    self.date.append(dt.date())\n', '    self.time.append(dt.time())\n', '    self.open_.append(float(open_))\n', '    self.high.append(float(high))\n', '    self.low.append(float(low))\n', '    self.close.append(float(close))\n', '    self.volume.append(int(volume))\n', '\n', '  def to_csv(self):\n', '    return \'\'.join([""{0},{1},{2},{3:.2f},{4:.2f},{5:.2f},{6:.2f},{7}\\n"".format(self.symbol,\n', ""              self.date[bar].strftime('%Y-%m-%d'),self.time[bar].strftime('%H:%M:%S'),\n"", '              self.open_[bar],self.high[bar],self.low[bar],self.close[bar],self.volume[bar])\n', '              for bar in xrange(len(self.close))])\n', '\n', '  def write_csv(self,filename):\n', ""    with open(filename,'w') as f:\n"", '      txt= self.to_csv()\n', '      f.write(txt)\n', '\n', '  def read_csv(self,filename):\n', ""    self.symbol = ''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', ""    for line in open(filename,'r'):\n"", ""      symbol,ds,ts,open_,high,low,close,volume = line.rstrip().split(',')\n"", '      self.symbol = symbol\n', ""      dt = datetime.datetime.strptime(ds+' '+ts,self.DATE_FMT+' '+self.TIME_FMT)\n"", '      self.append(dt,open_,high,low,close,volume)\n', '    return True\n', '\n', '  def __repr__(self):\n', '    return self.to_csv()\n', ""'''\n"", '\n', ' \n', '\n', ""'''\n"", ""def imp_googleIntradayQuoteSave2(name1, date1, inter, tframe, dircsv='', dbname=''):\n"", ' q = imp_googleIntradayQuote(name1, inter, tframe)  #interval, timeframe\n', "" name1= name1.replace(':','_')\n"", '\n', "" if dircsv != '' :\n"", ""    file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", '    q.to_csv(file1)\n', '\n', "" if dbname != '' :\n"", '    import sqlalchemy as sql\n', '    dbcon= sql.create_engine(dbname)\n', '    if inter== 300 : # 5mins\n', ""      q.to_sql('q5min', dbcon)\n"", '\n', '\n', ""def imp_googleQuoteList_save(symbols, date1, date2, inter=23400, tframe=2000, dircsv='', intraday1=True) :\n"", ' if intraday1:\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleIntradayQuoteSave(symbol, date1, inter, tframe, dircsv)\n', ""     except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleQuoteSave(symbol, date1, date2, dircsv)\n', '     except: print(symbol)\n', ""'''\n"", '\n']","['np.shape', 'getret_fromquotes', 'len', 'getlogret_fromquotes', 'np.log', 'getprice_fromret']",6
utilmy/zarchive/portfolio_withdate.py:index,index,class,103,300,221,3009,10.03,1,3,[],[],[],1835,[],[],0
utilmy/zarchive/portfolio_withdate.py:folioCalc,folioCalc,class,125,509,332,4736,9.3,2,17,[],[],[],2134,[],[],0
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator,folioRiskIndicator,class,89,306,215,3180,10.39,1,9,[],[],[],2309,[],[],0
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF,folioOptimizationF,class,280,1291,671,10994,8.52,6,39,[],[],[],2487,[],[],0
utilmy/zarchive/portfolio_withdate.py:searchSimilarity,searchSimilarity,class,173,497,328,4550,9.15,8,17,[],[],[],3934,[],[],0
utilmy/zarchive/portfolio_withdate.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1836,[],['date_generatedatetime'],1
utilmy/zarchive/portfolio_withdate.py:index:close,index:close,method,0,1,1,4,4.0,0,0,['self'],[None],[None],1841,[],[],0
utilmy/zarchive/portfolio_withdate.py:index:updatehisto,index:updatehisto,method,2,12,11,62,5.17,0,0,['self)'],['  #Download Quotespassself) :'],[None],1844,[],['print'],1
utilmy/zarchive/portfolio_withdate.py:index:help,index:help,method,2,12,11,62,5.17,0,0,['self'],[None],[None],1848,[],['print'],1
utilmy/zarchive/portfolio_withdate.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]",['date_generatedatetime'],1
utilmy/zarchive/portfolio_withdate.py:index:calc_baskettable_pct,index:calc_baskettable_pct,method,37,95,77,782,8.23,1,2,"['self', 'type1', 'showdetail']","[None, None, None]","[None, '""table""', '0']",1913,"[""      '''   Calc Basket Values from Input data '''\n""]","['np.zeros', 'np.sum', 'self._udpate_wwindpct', 'range', 'np.mod', 'self._wwpct_rebal']",6
utilmy/zarchive/portfolio_withdate.py:index:_wwpct_rebal,index:_wwpct_rebal,method,3,4,3,41,10.25,0,0,"['self', 'wwpct_actual', 't', 'trebal)', '']","[None, None, None, '  # BskUnit', ']np.abs(wwpct_actual/wwpct_th  -1 )) > self.rebal_trigger:']","[None, None, None, ' 1.0  !!!wwpct_th = self.wwasset[trebal', None]",1940,[],[],0
utilmy/zarchive/portfolio_withdate.py:index:_udpate_wwindpct,index:_udpate_wwindpct,method,11,25,17,224,8.96,0,0,"['self', 't', 'bskt', 'hedgecost', 'wwpct_actual', 'wwpct_th']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",1950,[],[],0
utilmy/zarchive/portfolio_withdate.py:index:calc_baskettable_unit,index:calc_baskettable_unit,method,0,0,0,0,0.0,0,0,[],[],[],1959,"[""    '''   t           --->  t+1                 ---->   t+2\n"", '            wwactual:    B[t]    -->   B[t+1]   using  w[t+1], B[t] /   S[t]\n', '            wwnew   :    B[t+1]  -->   B[t+2]   using  w[t+2], B[t+1] /   S[t+1]\n', ""    '''\n""]",[],0
utilmy/zarchive/portfolio_withdate.py:folioCalc:__init__,folioCalc:__init__,method,21,39,37,356,9.13,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2135,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioCalc:set_symclose,folioCalc:set_symclose,method,17,34,33,312,9.18,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2148,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioCalc:setcriteria,folioCalc:setcriteria,method,41,76,71,1046,13.76,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2157,"[""        ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '            wwtype:     constant / regime /regimExtra\n', '            initperiod: NbOfDays_initial_Risk_Monitoring\n', '            riskid:     spprice/spperf/multi\n', ""        '''\n""]","['np.array', 'len']",2
utilmy/zarchive/portfolio_withdate.py:folioCalc:_weightcalc_generic,folioCalc:_weightcalc_generic,method,5,35,23,396,11.31,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2207,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/portfolio_withdate.py:folioCalc:_weightcalc_regime,folioCalc:_weightcalc_regime,method,10,37,32,272,7.35,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2218,[],"['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/portfolio_withdate.py:folioCalc:_regimecalc,folioCalc:_regimecalc,method,3,7,6,83,11.86,0,0,"['self', 't', 'wwextra)', 't - 1]self.riskind[0', 't - 1] / self.riskind[0', 't - 1 - self.nbrange] - 1if self.riskid == ""multi""']","[None, None, '  # Risk Indicatorif self.riskid ', None, None, '']","[None, None, '= ""spprice"":   return self.riskind[0', None, None, '= ""multi"":']",2228,[],['self._mapping_calc_risk'],1
utilmy/zarchive/portfolio_withdate.py:folioCalc:_weightcalc_constant,folioCalc:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2237,[],['np.sum'],1
utilmy/zarchive/portfolio_withdate.py:folioCalc:getweight,folioCalc:getweight,method,5,12,9,126,10.5,0,0,['self'],[None],[None],2241,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/portfolio_withdate.py:folioCalc:calc_baskettable,folioCalc:calc_baskettable,method,33,111,83,811,7.31,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', '0.000', '0']",2248,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/portfolio_withdate.py:folioCalc:plot,folioCalc:plot,method,10,29,26,295,10.17,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2276,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/portfolio_withdate.py:folioCalc:multiperiod_ww,folioCalc:multiperiod_ww,method,15,36,29,240,6.67,1,1,"['self', 't']","[None, None]","[None, None]",2287,[],['xrange'],1
utilmy/zarchive/portfolio_withdate.py:folioCalc:help,folioCalc:help,method,1,2,2,13,6.5,0,0,['self'],[None],[None],2300,[],['print'],1
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:__init__,folioRiskIndicator:__init__,method,23,40,38,356,8.9,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:set_symclose,folioRiskIndicator:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2324,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:setcriteria,folioRiskIndicator:setcriteria,method,34,81,70,1006,12.42,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2334,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'np.zeros']",3
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:calcrisk,folioRiskIndicator:calcrisk,method,13,18,17,220,12.22,1,0,"['self', 'wwvec', 'initval']","[None, None, None]","[None, '[]', '1']",2382,[],"['xrange', 'self._weightcalc_generic', 'np.column_stack']",3
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:_weightcalc_generic,folioRiskIndicator:_weightcalc_generic,method,4,34,24,327,9.62,0,3,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2394,[],"['self._weightcalc_regime', 'print']",2
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:_weightcalc_regime,folioRiskIndicator:_weightcalc_regime,method,3,11,11,68,6.18,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2403,[],['self._regimecalc'],1
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:_regimecalc,folioRiskIndicator:_regimecalc,method,7,18,17,216,12.0,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )self.riskind', 'wwextra', 't', 'self.riskind_out)self', 'maxiter', 'name1', 'isreset', 'popsize=15) ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, None, None, None, None, None, None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, None, None, None, None, '1', ""''"", '1', '15) :']",2408,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio_withdate.py:folioRiskIndicator:calc_optimal_weight,folioRiskIndicator:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2414,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:__init__,folioOptimizationF:__init__,method,23,39,37,340,8.72,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:set_symclose,folioOptimizationF:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2324,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:setcriteria,folioOptimizationF:setcriteria,method,44,128,103,1669,13.04,0,2,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2334,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'print', 'list']",4
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:calcbasket_obj2,folioOptimizationF:calcbasket_obj2,method,23,76,63,756,9.95,0,1,"['self', 'wwvec']","[None, None]","[None, None]",2572,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float']",6
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:calcbasket_obj,folioOptimizationF:calcbasket_obj,method,55,157,118,1494,9.52,1,4,"['self', 'wwvec']","[None, None]","[None, None]",2598,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float', 'calcbasket_obj', 'concenfactor=folio_concenfactor2', 'np.zeros', 'xrange', 'np.mod', 'self._weightcalc_generic', 'self._loss_obj', 'self._objective_criteria']",14
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_loss_obj,folioOptimizationF:_loss_obj,method,4,6,6,68,11.33,0,0,"['self', 'ww2', 'wwpenalty']","[None, None, None]","[None, None, None]",2623,[],['np.sum'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_weightcalc_generic,folioOptimizationF:_weightcalc_generic,method,5,40,26,394,9.85,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2394,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_weightcalc_regime,folioOptimizationF:_weightcalc_regime,method,8,32,28,239,7.47,0,0,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2403,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']","['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_regimecalc,folioOptimizationF:_regimecalc,method,4,7,7,83,11.86,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )if self.riskid== ""multi""   ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, '= ""multi""   :']",2408,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']",['self._mapping_calc_risk'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_weightcalc_constant,folioOptimizationF:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2662,[],['np.sum'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:calc_optimal_weight,folioOptimizationF:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2414,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:getweight,folioOptimizationF:getweight,method,6,11,9,126,11.45,0,0,['self'],[None],[None],2671,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:calc_baskettable,folioOptimizationF:calc_baskettable,method,36,86,72,827,9.62,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', ' 0.000', '0']",2679,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:plot,folioOptimizationF:plot,method,11,31,30,294,9.48,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2708,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_objective_criteria,folioOptimizationF:_objective_criteria,method,31,147,78,1105,7.52,2,7,"['self', 'bsk']","[None, None]","[None, None]",2720,[],"['np.std', 'np.sum', 'range', 'np.arange']",4
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:multiperiod_ww,folioOptimizationF:multiperiod_ww,method,18,29,27,238,8.21,1,1,"['self', 't']","[None, None]","[None, None]",2767,[],['xrange'],1
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:help,folioOptimizationF:help,method,50,152,103,1472,9.68,1,6,['self'],[None],[None],2779,[],"['print', 'util.load_obj', 'int', 'copy.deepcopy', 'xrange', 'next', 'util.save_obj', 'np.mod', 'np.abs', 'np.reshape', 'np.sum']",11
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:mapping_risk_ww,folioOptimizationF:mapping_risk_ww,method,12,56,29,245,4.38,0,1,"['self', 'risk', 'wwmat', 'ww2']","[None, None, None, None]","[None, None, None, 'self.wwasset0']",2838,[],"['np.sum', 'np.array']",2
utilmy/zarchive/portfolio_withdate.py:folioOptimizationF:_mapping_calc_risk,folioOptimizationF:_mapping_calc_risk,method,27,201,76,831,4.13,0,3,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",2850,[],[],0
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:__init__,searchSimilarity:__init__,method,15,18,17,193,10.72,0,0,"['self', ""filejpstock=r'E"", 'sym01', 'symname', 'startdate', 'enddate', 'pricetype']","[None, '', None, None, None, None, None]","[None, ""r'E:/_data/stock/daily/20160616/jp'"", ""['7203']"", ""['Toyota']"", ' 20150101', '20160601', '""close""']",3935,[],[],0
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:load_quotes_fromdb,searchSimilarity:load_quotes_fromdb,method,15,35,33,355,10.14,0,1,"['self', 'picklefile']","[None, None]","[None, ""''""]",3940,[],"['util.load_obj', 'imp_txt_getquotes', 'date_align', 'util.a_cleanmemory']",4
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:__generate_return__,searchSimilarity:__generate_return__,method,4,4,4,64,16.0,0,0,"['self', 'nlag']","[None, None]","[None, None]",3951,[],['getret_fromquotes'],1
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:__overweight__,searchSimilarity:__overweight__,method,17,62,41,412,6.65,2,4,"['self', 'px']","[None, None]","[None, None]",3955,[],"['len', 'np.ones', 'util.np_findlocalmax', 'type', 'np.abs', 'wwerr[max', 'util.np_findlocalmin']",7
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:set_searchcriteria,searchSimilarity:set_searchcriteria,method,34,79,63,793,10.04,0,5,"['self', 'name1', 'date1', 'date2', 'nlag', 'searchperiodstart', 'typesearch', '']","[None, None, None, None, None, None, None, None]","[None, ""'7203'"", '20160301', '20160601', '1', '20120101', '""pattern2""', None]",3975,[],"['getret_fromquotes', 'date_finddateid', 'max', 'util.np_findfirst', 'print', 'price_normalize_1d', 'len', 'self.__overweight__']",8
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:launch_search,searchSimilarity:launch_search,method,53,107,81,908,8.49,3,3,['self'],[None],[None],4004,[],"['len', 'np.zeros', 'range', 'price_normalize_1d', 'np_similarity', 'util.np_sortbycolumn', 'enumerate']",7
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:show_comparison_graph,searchSimilarity:show_comparison_graph,method,33,72,63,682,9.47,1,3,"['self', 'maxresult', 'show_only_different_time', 'fromid', 'fromend', 'filenameout']","[None, None, None, None, None, None]","[None, '20', 'True', '0', ' 0', ""''""]",4038,[],"['np.shape', 'range', 'int', 'print', 'price_normalize_1d', 'str', 'plot_price']",7
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:staticmethod,searchSimilarity:staticmethod,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",4067,[],[],0
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:get_rankresult,searchSimilarity:get_rankresult,method,24,63,53,496,7.87,2,1,"['self', 'filetosave']","[None, None]","[None, ""''""]",4071,[],"['len', 'np.savetxt', 'np.shape', 'np.array', 'np.empty', 'range', 'int', 'str']",8
utilmy/zarchive/portfolio_withdate.py:searchSimilarity:export_results,searchSimilarity:export_results,method,0,0,0,0,0.0,0,0,[],[],[],4093,"[""'''\n"", '#####################################################################################\n', '#---------Run over all the indexes, with time lag -----------------------------------\n', 'def np_similarity(x,y, wwerr=[], type1=0):\n', '  if type1==2 : return np_distance_l1(x,y, wwerr)\n', '  if type1==1: return sci.spatial.distance.correlation(x, y)  \n', '  if type1==0 : return 1-np.corrcoef(x,y)[0,1]\n', '\n', 'def np_distance_l1(x,y, wwerr) :\n', ' return np.sum(wwerr * np.abs(x-y))  \n', '  \n', '#---------------------  Universe Load         ---------------------------------------\n', ""filejpstock= r'E:/_data/stock/daily/20160616/jp'\n"", 'sym01= nk400list\n', '\n', 'quotes= imp_txt_getquotes(sym01, filejpstock, startdate=20090101, endate=20160616)\n', 'open1, dateref= date_align(quotes, type1=""close"")    #Get the data and align dates\n', 'del quotes; util.a_cleanmemory()\n', '\n', ""#util.save_obj(open1, 'close_nk400_2009_2016')\n"", ""#util.save_obj(dateref, 'dateref_nk400_2009_2016')\n"", '\n', ""open1= util.load_obj('close_nk400_2009_2016')\n"", ""dateref= util.load_obj( 'dateref_nk400_2009_2016')\n"", '\n', 'nlag=1\n', 'ret_open1 =  getdailyret_fromquotes(open1,nlag)\n', 'del open1\n', '\n', '#--------------------  Search Asset Input     ---------------------------------------\n', ""name1= '7203' \n"", 'date1= 20160328\n', 'date2= 20160531\n', 'twindow= util.np_findfirst(date2, dateref) - util.np_findfirst(date1, dateref) \n', '\n', '\n', 'tstartx= util.np_findfirst(date1, dateref)          # Date Index\n', 'stockx= util.np_findfirst(name1, sym01)\n', 'retx= ret_open1[stockx, tstartx:(tstartx+twindow-1)]    # Recent Period\n', 'px= price_normalize_1d(retx)\n', 'nx= len(px)\n', '\n', '\n', '#----OverWeight for Local Min, Local Max         -----------------------------------\n', 'wwerr= np.ones(nx, dtype=np.float16)\n', 'vvmax= util.np_findlocalmax(px); xprev=0\n', 'for x in vvmax:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', 'vvmin= util.np_findlocalmin(px); xprev=0\n', 'for x in vvmin:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', '\n', '#--------------------  Search the Pattern       -------------------------------------\n', 'tmaxx= len(dateref)-1\n', 'similar_list= np.zeros((nstock*(tmaxx-twindow)+1, 3), np.float16)\n', 'i=0\n', 'for iy in range(0, nstock) :\n', ' for t in range(0, tmaxx-twindow):\n', '   if iy == stockx and t > tstartx : \n', '     pass\n', '   else :\n', '    rety= ret_open1[iy, t:(t+twindow-1)]\n', '    py=   price_normalize_1d(rety)\n', '    ss= np_similarity(px, py, wwerr=wwerr, type1=2)\n', '    i+=1\n', '    similar_list[i,0]= iy\n', '    similar_list[i,1]= t\n', '    similar_list[i,2]= ss\n', '\n', '\n', ' #-------------------Clean the table -------------------------------------------------\n', 'rank= util.np_sortbycolumn(similar_list,2, asc=True)\n', 'for i,x in enumerate(rank) :\n', '  if rank[i,2]==0.0 : rank[i,2]= 1000         # Empty cell\n', '  if rank[i,1]> tstartx-3 : rank[i,2]= 100    # Start Element\n', 'rank= util.np_sortbycolumn(rank,2, asc=True)  \n', '\n', '\n', ' #----- Show Similar Stocks ---------------------------------------------------------\n', 'show_only_different_time= True\n', '\n', 'for i in range(0,10) :\n', ' tstarti= rank[i,1]\n', ' stocki= int(rank[i,0])\n', ' \n', ' if show_only_different_time and tstarti < tstartx-1  :\n', '   py= price_normalize100(ret_open1[stocki, tstarti:(tstarti+twindow-1)]) \n', '\n', '   namei= sym01[stocki]\n', '   namefulli= nk400name[util.np_findfirst(namei, nk400list)]\n', '\n', '   tit= namei+ "" "" +namefulli+ "" "" + str(dateref[tstarti])          \n', ""   plot_price(px-100, py-100, label=('Similar '+tit, 'Time','% Var') )\n"", '\n', '\n', 'kix= util.np_findfirst(name1, statsjp[:,0, ilag])\n', 'stocklist01[390]\n', '\n', '\n', 'stocklist01[157] , nk400name[157] ,  dateref1adj[86]     \n', 'plot_price(price_normalize100(ret_open1[157, 86:86+twindow-1])-100,px-100   )\n', ""'''    \n""]",[],0
utilmy/zarchive/report.py:map_show,map_show,function,0,1,1,4,4.0,0,0,[],[],[],36,[],[],0
utilmy/zarchive/report.py:xl_create_pivot,xl_create_pivot,function,4,9,9,134,14.89,0,0,"['infile', 'index_list', '""Rep""', '""Product""]', 'value_list', '""Quantity""]']","[None, None, None, None, None, None]","[None, '[""Manager""', None, None, '[""Price""', None]",65,"[""   ''' Read in the Excel file, create a pivot table and return it as a DataFrame '''\n""]",[],0
utilmy/zarchive/report.py:xl_save_report,xl_save_report,function,6,10,10,167,16.7,1,0,"['report', 'outfile']","[None, None]","[None, None]",72,"[""   '''  Take a report and save it to a single Excel file\n"", '       sales_report = create_pivot(args.infile.name)\n', '       save_report(sales_report, args.outfile.name)\n', ""   '''\n""]","['temp_df.to_excel', 'writer.save']",2
utilmy/zarchive/report.py:xl_create_pdf,xl_create_pdf,function,23,44,39,743,16.89,1,0,[],[],[],97,[],"['sales_report=create_pivot', 'manager_df.append', 'sales_report.xs', 'env=Environment', 'get_summary_stats', 'sales_report.to_html', 'HTML']",7
utilmy/zarchive/rstatpy.py:stl,stl,function,32,165,104,1260,7.64,0,11,"['data', 'ns', 'np', 'nt', 'nl', 'isdeg', 'itdeg', 'ildeg', 'nsjump', 'ntjump', 'nljump', 'ni', 'no', 'fulloutput']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', '0', '1', '1', 'None', 'None', 'None', '2', '0', 'False']",9,"['    """"""\n', '    Seasonal-Trend decomposition procedure based on LOESS\n', '    data : pandas.Series\n', '    ns : int\n', '        Length of the seasonal smoother.\n', '        The value of  ns should be an odd integer greater than or equal to 3.\n', '        A value ns>6 is recommended. As ns  increases  the  values  of  the\n', '        seasonal component at a given point in the seasonal cycle (e.g., January\n', '        values of a monthly series with  a  yearly cycle) become smoother.\n', '    np : int\n', '        Period of the seasonal component.\n', '        For example, if  the  time series is monthly with a yearly cycle, then\n', '        np=12.\n', '        If no value is given, then the period will be determined from the\n', '        ``data`` timeseries.\n', '    nt : int\n', '        Length of the trend smoother.\n', '        The  value  of  nt should be an odd integer greater than or equal to 3.\n', '        A value of nt between 1.5*np and 2*np is  recommended. As nt increases,\n', '        the values of the trend component become  smoother.\n', '        If nt is None, it is estimated as the smallest odd integer greater\n', '        or equal to ``(1.5*np)/[1-(1.5/ns)]``\n', '    nl : int\n', '        Length of the low-pass filter.\n', '        The value of nl should  be an odd integer greater than or equal to 3.\n', '        The smallest odd integer greater than or equal to np is used by default.\n', '    isdeg : int\n', '        Degree of locally-fitted polynomial in seasonal smoothing.\n', '        The value is 0 or 1.\n', '    itdeg : int\n', '        Degree of locally-fitted polynomial in trend smoothing.\n', '        The value is 0 or 1.\n', '    ildeg : int\n', '        Degree of locally-fitted polynomial in low-pass smoothing.\n', '        The value is 0 or 1.\n', '    nsjump : int\n', '        Skipping value for seasonal smoothing.\n', '        The seasonal smoother skips ahead nsjump points and then linearly\n', '        interpolates in between.  The value  of nsjump should be a positive\n', '        integer; if nsjump=1, a seasonal smooth is calculated at all n points.\n', '        To make the procedure run faster, a reasonable choice for nsjump is\n', '        10%-20% of ns. By default, nsjump= 0.1*ns.\n', '    ntjump : int\n', '        Skipping value for trend smoothing. If None, ntjump= 0.1*nt\n', '    nljump : int\n', '        Skipping value for low-pass smoothing. If None, nljump= 0.1*nl\n', '    ni :int\n', '        Number of loops for updating the seasonal and trend  components.\n', '        The value of ni should be a positive integer.\n', '        See the next argument for advice on the  choice of ni.\n', '        If ni is None, ni is set to 2 for robust fitting, to 5 otherwise.\n', '    no : int\n', '        Number of iterations of robust fitting. The value of no should\n', '        be a nonnegative integer. If the data are well behaved without\n', '        outliers, then robustness iterations are not needed. In this case\n', '        set no=0, and set ni=2 to 5 depending on how much security\n', '        you want that  the seasonal-trend looping converges.\n', '        If outliers are present then no=3 is a very secure value unless\n', '        the outliers are radical, in which case no=5 or even 10 might\n', '        be better.  If no>0 then set ni to 1 or 2.\n', '        If None, then no is set to 15 for robust fitting, to 0 otherwise.\n', '    fulloutput : bool\n', '        If True, a dictionary holding the full output of the original R routine\n', '        will be returned.\n', '    returns\n', '    data : pandas.DataFrame\n', '        The seasonal, trend, and remainder components\n', '    """"""\n']","['data.copy', '_data.dropna', 'pandas.DateRange', 'pandas.Series', 'ceil', 'robjects.IntVector', 'ts_', 'stl_', 'asarray', 'pandas.DataFrame']",10
utilmy/zarchive/util.py:session_save,session_save,function,39,72,64,1009,14.01,0,2,"['filename', 'globals1']","[None, None]","['""/folder1/name1""', 'None']",278,"[""    '''Need to pass globals() Cannot Get Save data to .spydata file\n"", '\n', '   BIG issue with Import, Impor FULL MODULE ----> BIG ISSUE\n', '     BIG ISSUE with DICT, USE LIST INSTEAD\n', '        If you try to put this code in a module and import the function then you will have to pass globals() to the function explicitly as the globals() in the function is not the IPython global namespace. However, you can put the above code inside your ~/.ipython/profile_PROFILE/startup/startup.ipy file and it will work as expected.\n', '       PROFILE is the name of the profile that you plan to start IPython with.\n', ""    '''\n""]","['print', 'spyutil.globalsfilter', 'filters=tuple', 'filename.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'iofunc.save_dictionary', 'os.chdir']",8
utilmy/zarchive/util.py:aa_unicode_ascii_utf8_issue,aa_unicode_ascii_utf8_issue,function,0,0,0,0,0.0,0,0,[],[],[],356,"[""   '''Take All csv in a folder and provide Table, Column Schema, type\n"", '\n', ' METHOD FOR Unicode / ASCII issue\n', '1. Decode early\n', ""Decode to <type 'unicode'> ASAP\n"", ""df['PREF_NAME']=       df['PREF_NAME'].apply(to_unicode)\n"", '\n', '2. Unicode everywhere\n', '\n', '\n', '3. Encode late\n', "">>> f = open('/tmp/ivan_out.txt','w')\n"", "">>> f.write(ivan_uni.encode('utf-8'))\n"", '\n', 'Important methods\n', ""s.decode(encoding)  <type 'str'> to <type 'unicode'>\n"", ""u.encode(encoding)  <type 'unicode'> to <type 'str'>\n"", '\n', 'http://farmdev.com/talks/unicode/\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/util.py:isexist,isexist,function,3,9,8,46,5.11,0,0,['a'],[None],[None],380,[],[],0
utilmy/zarchive/util.py:isfloat,isfloat,function,5,16,14,67,4.19,0,1,['x'],[None],[None],386,[],['float'],1
utilmy/zarchive/util.py:isint,isint,function,6,15,14,80,5.33,0,1,"['x)', '( int', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, '']","[None, None, None, None, None]",393,[],['txt.find'],1
utilmy/zarchive/util.py:a_isanaconda,a_isanaconda,function,6,15,14,80,5.33,0,1,[],[],[],395,[],['txt.find'],1
utilmy/zarchive/util.py:a_run_ipython,a_run_ipython,function,1,1,1,33,33.0,0,0,['cmd1'],[None],[None],405,"["" ''' Execute Ipython Command in python code\n"", '     run -i :  run including current interprete variable\n', "" '''\n""]",['IPython.get_ipython'],1
utilmy/zarchive/util.py:a_autoreload,a_autoreload,function,1,4,4,64,16.0,0,0,[],[],[],411,[],['a_run_ipython'],1
utilmy/zarchive/util.py:a_start_log,a_start_log,function,1,14,12,98,7.0,0,0,"['id1', 'folder']","[None, None]","[""''"", ""'aaserialize/log/'""]",414,[],"['a_run_ipython', 'str', 'a_get_platform', 'date_now']",4
utilmy/zarchive/util.py:a_cleanmemory,a_cleanmemory,function,3,3,3,21,7.0,0,0,[],[],[],417,[],['gc.collect'],1
utilmy/zarchive/util.py:a_module_codesample,a_module_codesample,function,6,9,9,130,14.44,0,0,['module_str'],[None],"[""'pandas'""]",420,[],"['os_file_read', 'os_gui_popup_show']",2
utilmy/zarchive/util.py:a_module_doc,a_module_doc,function,6,9,9,123,13.67,0,0,['module_str'],[None],"[""'pandas'""]",426,[],"['os_file_read', 'os_gui_popup_show']",2
utilmy/zarchive/util.py:a_module_generatedoc,a_module_generatedoc,function,8,16,16,180,11.25,0,1,"['module_str', 'fileout']","[None, None]","['""pandas""', ""''""]",432,"['  \'\'\' #  getmodule_doc(""jedi"", r""D:\\_devs\\Python01\\aapackage\\doc.txt"")\'\'\'\n']","['os.makedirs', 'ca.getmodule_doc']",2
utilmy/zarchive/util.py:a_info_conda_jupyter,a_info_conda_jupyter,function,61,133,110,1071,8.05,1,3,[],[],[],440,[],"['printProgress', 'shutil.make_archive', 'os_zipfolder', 'dir_tozip.split', 'os_zip_checkintegrity', 'print']",6
utilmy/zarchive/util.py:os_zipextractall,os_zipextractall,function,23,59,48,538,9.12,1,3,"['filezip_or_dir', 'tofolderextract', 'isprint']","[None, None, None]","['""folder1/*.zip""', ""'zdisk/test'"", '1']",711,"[""   '''os_zipextractall( 'aapackage.zip','zdisk/test/'      )  '''\n""]","['filezip_or_dir.find', 'os_file_listall', 'os_file_getname', 'zipfile.ZipFile', 'zip_ref.extractall', 'zip_ref.close', 'print']",7
utilmy/zarchive/util.py:os_folder_copy,os_folder_copy,function,17,36,35,345,9.58,0,1,"['src', 'dst', 'symlinks', 'pattern1', 'fun_file_toignore']","[None, None, None, None, None]","[None, None, 'False', '""*.py""', 'None']",741,"[""   '''\n"", '       callable(src, names) -> ignored_names\n', ""       'src' parameter, which is the directory being visited by copytree(), and\n"", ""       'names' which is the list of `src` contents, as returned by os.listdir():\n"", '\n', '    Since copytree() is called recursively, the callable will be called once for each directory that is copied.\n', '    It returns a  list of names relative to the `src` directory that should not be copied.\n', '   :param fun_ignore:\n', ""   '''\n""]","['fun_file_toignore', 'fnmatch.filter', 'shutil.copytree', 'shutil.copy']",4
utilmy/zarchive/util.py:os_folder_create,os_folder_create,function,4,7,7,85,12.14,0,1,['directory'],[None],[None],764,[],"['os.getcwd', 'os.makedirs', 'os.chdir']",3
utilmy/zarchive/util.py:os_folder_robocopy,os_folder_robocopy,function,3,15,15,163,10.87,0,1,"['from_folder', 'to_folder', ""my_log='H""]","[None, None, '']","[""''"", ""''"", ""'H:/robocopy_log.txt'""]",769,"['    """"""\n', '    Copy files to working directory\n', '    robocopy <Source> <Destination> [<File>[ ...]] [<Options>]\n', '    We want to copy the files to a fast SSD drive\n', '    """"""\n']","['subprocess.call', 'print']",2
utilmy/zarchive/util.py:os_file_replace,os_file_replace,function,26,69,57,697,10.1,2,0,"['source_file_path', 'pattern', 'substring']","[None, None, None]","[None, None, None]",784,[],"['mkstemp', 'open', 'target_file.write', 'remove', 'move', 'os_file_replacestring1', 'fileinput.FileInput', 'line.replace', 'file1.close', 'print', 'os_file_replacestring2']",11
utilmy/zarchive/util.py:os_file_replacestring1,os_file_replacestring1,function,11,26,25,240,9.23,1,0,"['findStr', 'repStr', 'filePath']","[None, None, None]","[None, None, None]",798,[],"['fileinput.FileInput', 'line.replace', 'file1.close', 'print']",4
utilmy/zarchive/util.py:os_file_replacestring2,os_file_replacestring2,function,6,14,13,161,11.5,1,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",809,"['  \'\'\' #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",    pattern=""*.html"", dirlevel=5  )\n', ""  '''\n""]","['os_file_listall', 'os_file_replacestring1']",2
utilmy/zarchive/util.py:os_file_getname,os_file_getname,function,8,9,8,75,8.33,0,0,['path'],[None],[None],817,[],"['ntpath.split', 'ntpath.basename']",2
utilmy/zarchive/util.py:os_file_getpath,os_file_getpath,function,7,7,7,52,7.43,0,0,['path'],[None],[None],822,[],['ntpath.split'],1
utilmy/zarchive/util.py:os_file_gettext,os_file_gettext,function,4,8,8,56,7.0,0,0,['file1'],[None],[None],827,[],"['open', 'f.read']",2
utilmy/zarchive/util.py:os_file_listall,os_file_listall,function,28,82,46,904,11.02,4,3,"['dir1', 'pattern', 'dirlevel', 'onlyfolder']","[None, None, None, None]","[None, '""*.*""', '1', '0']",833,"[""  '''\n"", '   # DIRCWD=r""D:\\_devs\\Python01\\project""\n', '   # aa= listallfile(DIRCWD, ""*.*"", 2)\n', '   # aa[0][30];   aa[2][30]\n', '\n', '   :param dir1:\n', '   :param pattern:\n', '   :param dirlevel:\n', '   :param onlyfolder:\n', '   :return:\n', ""  '''\n""]","['dir1.rstrip', 'dir1.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 'np.array']",7
utilmy/zarchive/util.py:os_file_rename,os_file_rename,function,32,60,48,643,10.72,2,1,"['some_dir', 'pattern', 'pattern2', 'dirlevel']","[None, None, None, None]","[None, '""*.*""', '""""', '1']",870,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 're.sub', 'os.rename', 'np.array']",9
utilmy/zarchive/util.py:os_gui_popup_show,os_gui_popup_show,function,25,38,37,361,9.5,0,0,['txt'],[None],[None],891,[],"['os_gui_popup_show2', 'Tk', 'Scrollbar', 'Text', 'S.pack', 'T.pack', 'S.config', 'T.config', 'T.insert', 'root.attributes', 'mainloop']",11
utilmy/zarchive/util.py:os_print_tofile,os_print_tofile,function,8,21,19,174,8.29,0,1,"['vv', 'file1', ""mode1='a')"", 'mode1) as text_file']","[None, None, '', '  text_file.write(str(vv))pth): #Normalize path for Python directory)']","[None, None, ""'a'):  # print into a file='afile1"", '=2:']",908,"[""    '''\n"", '    Here is a list of the different modes of opening a file:\n', 'r\n', 'Opens a file for reading only. The file pointer is placed at the beginning of the file. This is the default mode.\n', '\n', 'rb\n', '\n', 'Opens a file for reading only in binary format. The file pointer is placed at the beginning of the file. This is the default mode.\n', 'r+\n', '\n', 'Opens a file for both reading and writing. The file pointer will be at the beginning of the file.\n', 'rb+\n', '\n', 'Opens a file for both reading and writing in binary format. The file pointer will be at the beginning of the file.\n', 'w\n', '\n', 'Opens a file for writing only. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'wb\n', '\n', 'Opens a file for writing only in binary format. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'w+\n', '\n', 'Opens a file for both writing and reading. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'wb+\n', '\n', 'Opens a file for both writing and reading in binary format. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'a\n', '\n', 'Opens a file for appending. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'ab\n', '\n', 'Opens a file for appending in binary format. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'a+\n', '\n', 'Opens a file for both appending and reading. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'ab+\n', '\n', 'Opens a file for both appending and reading in binary format. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'To open a text file, use:\n', 'fh = open(""hello.txt"", ""r"")\n', '\n', 'To read a text file, use:\n', 'print fh.read()\n', '\n', 'To read one line at a time, use:\n', 'print fh.readline()\n', '\n', 'To read a list of lines use:\n', 'print fh.readlines()\n', '\n', 'To write to a file, use:\n', 'fh = open(""hello.txt"", ""w"")\n', 'lines_of_text = [""a line of text"", ""another line of text"", ""a third line""]\n', 'fh.writelines(lines_of_text)\n', 'fh.close()\n', '\n', 'To append to file, use:\n', 'fh = open(""Hello.txt"", ""a"")\n', 'fh.close()\n', '\n', ""    '''\n""]","['pth.find', 'b.lstrip']",2
utilmy/zarchive/util.py:os_path_norm,os_path_norm,function,8,21,19,174,8.29,0,1,['pth)'],[' #Normalize path for Python directory)'],['=2:'],972,"['    \'\'\' #r""D:\\_devs\\Python01\\project\\03-Connect_Java_CPP_Excel\\PyBindGen\\examples"" \'\'\'\n']","['pth.find', 'b.lstrip']",2
utilmy/zarchive/util.py:os_path_change,os_path_change,function,4,4,4,34,8.5,0,0,['path1)'],[' path1'],[' normpath(path1); os.chdir(path1)    #Change Working directory path): return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],984,[],"['open', 'fh.read']",2
utilmy/zarchive/util.py:os_path_current,os_path_current,function,4,4,4,34,8.5,0,0,[')'],[' return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],986,[],"['open', 'fh.read']",2
utilmy/zarchive/util.py:os_file_exist,os_file_exist,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],988,[],"['open', 'fh.read']",2
utilmy/zarchive/util.py:os_file_size,os_file_size,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.getsize(file1)file1):'],[None],990,[],"['open', 'fh.read']",2
utilmy/zarchive/util.py:os_file_read,os_file_read,function,4,4,4,34,8.5,0,0,['file1'],[None],[None],992,[],"['open', 'fh.read']",2
utilmy/zarchive/util.py:os_file_isame,os_file_isame,function,4,7,7,44,6.29,0,0,"['file1', 'file2']","[None, None]","[None, None]",997,[],['filecmp.cmp'],1
utilmy/zarchive/util.py:os_file_get_file_extension,os_file_get_file_extension,function,5,12,10,98,8.17,0,2,['file_path'],[None],[None],1004,"['    """"""\n', '    >>> get_file_extension(""/a/b/c"")\n', ""    ''\n"", '    >>> get_file_extension(""/a/b/c.tar.xz"")\n', ""    'xz'\n"", '    """"""\n']",['_ext.startswith'],1
utilmy/zarchive/util.py:os_file_normpath,os_file_normpath,function,2,8,8,67,8.38,0,0,['path'],[None],[None],1021,"['    """"""Normalize path.\n', '    - eliminating double slashes, etc. (os.path.normpath)\n', '    - ensure paths contain ~[user]/ expanded.\n', '\n', '    :param path: Path string :: str\n', '    """"""\n']",[],0
utilmy/zarchive/util.py:os_folder_is_path,os_folder_is_path,function,2,3,3,36,12.0,0,0,['path_or_stream'],[None],[None],1031,"['    """"""\n', '    Is given object `path_or_stream` a file path?\n', '    :param path_or_stream: file path or stream, file/file-like object\n', '    :return: True if `path_or_stream` is a file path\n', '    """"""\n']",['isinstance'],1
utilmy/zarchive/util.py:os_file_get_path_from_stream,os_file_get_path_from_stream,function,7,20,15,187,9.35,0,2,['maybe_stream'],[None],[None],1040,"['    """"""\n', '    Try to get file path from given stream `stream`.\n', '\n', '    :param maybe_stream: A file or file-like object\n', '    :return: Path of given file or file-like object or None\n', '\n', '    >>> __file__ == get_path_from_stream(__file__)\n', '    True\n', ""    >>> __file__ == get_path_from_stream(open(__file__, 'r'))\n"", '    True\n', '    >>> strm = anyconfig.compat.StringIO()\n', '    >>> get_path_from_stream(strm) is None\n', '    True\n', '    """"""\n']","['os_folder_is_path', 'getattr']",2
utilmy/zarchive/util.py:os_file_try_to_get_extension,os_file_try_to_get_extension,function,4,12,10,117,9.75,0,1,['path_or_strm'],[None],[None],1065,"['    """"""\n', '    Try to get file extension from given path or file object.\n', '    :return: File extension or None\n', '    """"""\n']","['os_file_get_path_from_stream', 'os_file_get_file_extension']",2
utilmy/zarchive/util.py:os_file_are_same_file_types,os_file_are_same_file_types,function,5,20,14,152,7.6,0,2,['paths'],[None],[None],1077,"['    """"""\n', '    Are given (maybe) file paths same type (extension) ?\n', '    :param paths: A list of file path or file(-like) objects\n', '\n', '    >>> are_same_file_types([])\n', '    False\n', '    >>> are_same_file_types([""a.conf""])\n', '    True\n', '    >>> are_same_file_types([""a.yml"", ""b.json""])\n', '    False\n', '    >>> strm = anyconfig.compat.StringIO()\n', '    >>> are_same_file_types([""a.yml"", ""b.yml"", strm])\n', '    False\n', '    """"""\n']","['os_file_try_to_get_extension', 'all']",2
utilmy/zarchive/util.py:os_file_norm_paths,os_file_norm_paths,function,18,55,36,393,7.15,2,3,"['paths', 'marker']","[None, None]","[None, ""'*'""]",1099,"['    """"""\n', '    :param paths:\n', '        A glob path pattern string, or a list consists of path strings or glob\n', '        path pattern strings or file objects\n', ""    :param marker: Glob marker character or string, e.g. '*'\n"", '    :return: List of path strings\n', '    >>> norm_paths([])\n', '    []\n', '    >>> norm_paths(""/usr/lib/a/b.conf /etc/a/b.conf /run/a/b.conf"".split())\n', ""    ['/usr/lib/a/b.conf', '/etc/a/b.conf', '/run/a/b.conf']\n"", '    >>> paths_s = os.path.join(os.path.dirname(__file__), ""u*.py"")\n', '    >>> ref = sglob(paths_s)\n', '    >>> ref = [""/etc/a.conf""] + ref\n', '    >>> assert norm_paths([""/etc/a.conf"", paths_s]) == ref\n', '    >>> strm = anyconfig.compat.StringIO()\n', '    >>> assert norm_paths([""/etc/a.conf"", strm]) == [""/etc/a.conf"", strm]\n', '    """"""\n']","['sglob', 'sorted', '_norm_paths_itr', 'os_folder_is_path', 'list']",5
utilmy/zarchive/util.py:os_file_mergeall,os_file_mergeall,function,10,20,20,185,9.25,1,0,"['nfile', 'dir1', 'pattern1', 'deepness']","[None, None, None, None]","[None, None, None, '2']",1144,[],"['os_file_listall', 'open', 'os_file_gettext', 'nfile1.write', 'nfile1.close']",5
utilmy/zarchive/util.py:os_file_extracttext,os_file_extracttext,function,14,31,29,286,9.23,1,0,"['output_file', 'dir1', 'pattern1', 'htmltag', 'deepness']","[None, None, None, None, None]","[None, None, '""*.html""', ""'p'"", '2']",1154,"["" ''' Extract text from html '''\n""]","['os_file_listall', 'open', 'os_file_gettext', 'BeautifulSoup', 'soup.find_all', 'txt2.strip', 'output_file1.write']",7
utilmy/zarchive/util.py:os_path_append,os_path_append,function,4,19,11,121,6.37,0,3,"['p1', 'p2', 'p3', 'p4']","[None, None, None, None]","[None, 'None', 'None', 'None']",1169,[],[],0
utilmy/zarchive/util.py:os_wait_cpu,os_wait_cpu,function,12,31,27,286,9.23,1,0,"['priority', 'cpu_min']","[None, None]","['300', '50']",1178,[],"['psutil.cpu_percent', 'print', 'arrow.utcnow', 'sleep']",4
utilmy/zarchive/util.py:os_split_dir_file,os_split_dir_file,function,6,15,15,112,7.47,0,1,['dirfile'],[None],[None],1187,[],"['dirfile.split', 'len']",2
utilmy/zarchive/util.py:os_process_run,os_process_run,function,13,31,31,321,10.35,0,1,"['cmd_list', ""'arg1'"", ""'arg2']"", 'capture_output']","[None, None, None, None]","[""['program'"", None, None, 'False']",1193,[],"['subprocess.Popen', 'proc.communicate', 'print', 'str']",4
utilmy/zarchive/util.py:os_process_2,os_process_2,function,0,1,1,4,4.0,0,0,[],[],[],1209,[],[],0
utilmy/zarchive/util.py:py_importfromfile,py_importfromfile,function,12,21,19,251,11.95,0,1,"['modulename', 'dir1']","[None, None]","[None, None]",1246,[],"['a_get_pythonversion', 'SourceFileLoader', 'foo.MyClass', 'imp.load_source']",4
utilmy/zarchive/util.py:py_memorysize,py_memorysize,function,16,56,38,312,5.57,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",1258,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'o.items']",7
utilmy/zarchive/util.py:save,save,function,2,4,4,64,16.0,0,0,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",1286,[],['py_save_obj'],1
utilmy/zarchive/util.py:load,load,function,2,3,3,60,20.0,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",1289,[],['py_load_obj'],1
utilmy/zarchive/util.py:save_test,save_test,function,6,11,11,126,11.45,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",1292,[],"['py_load_obj', 'print', 'str', 'gc.collect']",4
utilmy/zarchive/util.py:py_save_obj,py_save_obj,function,17,36,35,308,8.56,0,1,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",1298,[],"['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.dump']",5
utilmy/zarchive/util.py:py_load_obj,py_load_obj,function,16,30,28,265,8.83,0,1,"['folder', 'isabsolutpath', 'encoding1']","[None, None, None]","[""'/folder1/keyname'"", '0', ""'utf-8'""]",1311,"[""    '''def load_obj(name, encoding1='utf-8' ):\n"", ""         with open('D:/_devs/Python01/aaserialize/' + name + '.pkl', 'rb') as f:\n"", '            return pickle.load(f, encoding=encoding1)\n', ""    '''\n""]","['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.load']",5
utilmy/zarchive/util.py:z_key_splitinto_dir_name,z_key_splitinto_dir_name,function,6,15,15,112,7.47,0,1,['keyname'],[None],[None],1327,[],"['keyname.split', 'len']",2
utilmy/zarchive/util.py:sql_getdate,sql_getdate,function,0,1,1,4,4.0,0,0,[],[],[],1337,[],[],0
utilmy/zarchive/util.py:obj_getclass_of_method,obj_getclass_of_method,function,7,15,13,114,7.6,1,1,['meth'],[None],[None],1409,[],['inspect.getmro'],1
utilmy/zarchive/util.py:obj_getclass_property,obj_getclass_property,function,4,9,9,63,7.0,1,0,['pfi'],[None],[None],1417,[],"['vars', 'print']",2
utilmy/zarchive/util.py:print_topdf,print_topdf,function,27,114,95,912,8.0,0,0,[],[],[],1434,[],"['PdfPages', 'plt.figure', 'plt.plot', 'plt.title', 'pdf.savefig', 'plt.close', 'plt.rc', 'np.arange', 'np.sin', 'pdf.infodict', 'datetime.datetime']",11
utilmy/zarchive/util.py:os_config_setfile,os_config_setfile,function,9,39,26,229,5.87,1,1,"['dict_params', 'outfile', 'mode1']","[None, None, None]","[None, None, ""'w+'""]",1481,[],"['open', 'dict_params.items', 'isinstance', 'f1.write', 'str', 'f1.close', 'print']",7
utilmy/zarchive/util.py:os_config_getfile,os_config_getfile,function,7,16,15,73,4.56,1,0,['file1'],[None],[None],1493,[],"['open', 'f1.readlines', 'print']",3
utilmy/zarchive/util.py:os_csv_process,os_csv_process,function,1,2,2,9,4.5,0,0,['file1'],[None],[None],1501,[],['print'],1
utilmy/zarchive/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1527,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1527,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1527,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/util.py:str_match_fuzzy,str_match_fuzzy,function,4,12,11,64,5.33,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1687,"["" ''' if any of list_strinf elt matches partially xstring '''\n""]",['xstring.find'],1
utilmy/zarchive/util.py:str_parse_stringcalendar,str_parse_stringcalendar,function,14,39,29,278,7.13,3,1,['cal'],[None],[None],1694,"[""    '''----------Parse Calendar  --------'''\n""]","['cal.split', 'x.find', 'cal4.append', 'np.array', 'print']",5
utilmy/zarchive/util.py:str_make_unicode,str_make_unicode,function,7,16,13,102,6.38,0,1,"['input', 'errors']","[None, None]","[None, ""'replace'""]",1708,[],"['type', 'input.decode']",2
utilmy/zarchive/util.py:str_empty_string_array,str_empty_string_array,function,9,30,23,184,6.13,2,1,"['x', 'y']","[None, None]","[None, '1']",1714,[],"['range', 'str_empty_string_array_numpy', 'np.empty']",3
utilmy/zarchive/util.py:str_empty_string_array_numpy,str_empty_string_array_numpy,function,4,9,8,56,6.22,0,0,"['nx', 'ny']","[None, None]","[None, '1']",1718,[],['np.empty'],1
utilmy/zarchive/util.py:str_isfloat,str_isfloat,function,1,8,7,46,5.75,0,0,['value'],[None],[None],1723,[],['float'],1
utilmy/zarchive/util.py:str_is_azchar,str_is_azchar,function,1,8,7,42,5.25,0,0,['x'],[None],[None],1727,[],['float'],1
utilmy/zarchive/util.py:str_is_az09char,str_is_az09char,function,1,8,7,42,5.25,0,0,['x'],[None],[None],1731,[],['float'],1
utilmy/zarchive/util.py:str_reindent,str_reindent,function,1,3,3,28,9.33,0,0,"['s', 'numSpaces)', ""'\\n')numSpaces * ' ') + string.lstrip(line) for line in s]s"", ""'\\n')return sdelimiters"", 'string', 'maxsplit=0)', 'delimiters))regexPattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, ' #change indentation of multine strings', None, None, None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, None, None, None, '0):  #Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1735,"[""    '''\n"", '   if args:\n', ""       aux= name1+'.'+obj.__name__ +'('+ str(args) +')  \\n' + str(inspect.getdoc(obj))\n"", ""       aux= aux.replace('\\n', '\\n       ')\n"", '       aux= aux.rstrip()\n', ""       aux= aux + ' \\n'\n"", '       wi( aux)\n', ""    '''\n""]",['x.decode'],1
utilmy/zarchive/util.py:str_split2,str_split2,function,1,3,3,28,9.33,0,0,"['delimiters', 'string', 'maxsplit=0)', 'delimiters))regexPattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, '0):  #Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1749,[],['x.decode'],1
utilmy/zarchive/util.py:str_split_pattern,str_split_pattern,function,1,3,3,28,9.33,0,0,"['sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1754,[],['x.decode'],1
utilmy/zarchive/util.py:pd_str_isascii,pd_str_isascii,function,1,3,3,28,9.33,0,0,['x'],[None],[None],1762,[],['x.decode'],1
utilmy/zarchive/util.py:str_to_utf8,str_to_utf8,function,2,2,2,23,11.5,0,0,['x'],[None],[None],1768,"['  """""" Do it before saving/output to external printer """"""\n']",['x.encode'],1
utilmy/zarchive/util.py:str_to_unicode,str_to_unicode,function,3,14,11,78,5.57,0,2,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",1773,"[""  ''' Do it First after Loading some text '''\n""]","['isinstance', 'str']",2
utilmy/zarchive/util.py:np_minimize,np_minimize,function,12,41,37,379,9.24,1,0,"['fun_obj', 'x0', 'argext', '0']","[None, None, None, None]","[None, '[0.0]', '(0', None]",1846,[],"['penalty', 'enumerate', 'max', 'loss', 'fun_obj', 'np_minimizeDE']",6
utilmy/zarchive/util.py:np_minimizeDE,np_minimizeDE,function,16,51,41,418,8.2,1,2,"['fun_obj', 'bounds', 'name1', 'maxiter', 'popsize', 'solver']","[None, None, None, None, None, None]","[None, None, None, '10', '5', 'None']",1859,[],"['range', 'next', 'print', 'save', 'name1+date_now', 'np.mod', 'np.abs']",7
utilmy/zarchive/util.py:np_remove_NA_INF_2d,np_remove_NA_INF_2d,function,9,22,19,116,5.27,2,1,['X'],[None],[None],1876,[],"['np.shape', 'range', 'np.isnan', 'np.isinf']",4
utilmy/zarchive/util.py:np_addcolumn,np_addcolumn,function,8,11,11,86,7.82,0,0,"['arr', 'nbcol']","[None, None]","[None, None]",1883,[],"['np.shape', 'np.zeros', 'np.column_stack']",3
utilmy/zarchive/util.py:np_addrow,np_addrow,function,9,20,19,139,6.95,0,1,"['arr', 'nbrow']","[None, None]","[None, None]",1889,[],"['np.shape', 'len', 'np.zeros', 'np.row_stack', 'np.append']",5
utilmy/zarchive/util.py:np_int_tostr,np_int_tostr,function,3,17,12,69,4.06,0,1,['i'],[None],[None],1898,[],['str'],1
utilmy/zarchive/util.py:np_dictordered_create,np_dictordered_create,function,5,6,6,52,8.67,0,0,[],[],[],1904,[],['OrderedDict'],1
utilmy/zarchive/util.py:np_list_unique,np_list_unique,function,5,8,8,46,5.75,0,0,['seq'],[None],[None],1908,[],"['Set', 'list']",2
utilmy/zarchive/util.py:np_list_tofreqdict,np_list_tofreqdict,function,10,39,23,162,4.15,2,1,"['l1', 'wweight']","[None, None]","[None, '[]']",1914,[],"['dict', 'len', 'enumerate']",3
utilmy/zarchive/util.py:np_list_flatten,np_list_flatten,function,11,25,19,114,4.56,2,1,['seq'],[None],[None],1931,[],"['type', 'flatten', 'l.append']",3
utilmy/zarchive/util.py:np_dict_tolist,np_dict_tolist,function,5,22,15,100,4.55,2,1,"['dd', 'withkey']","[None, None]","[None, '0']",1942,[],['list'],1
utilmy/zarchive/util.py:np_dict_tostr_val,np_dict_tostr_val,function,1,9,9,52,5.78,0,0,['dd'],[None],[None],1948,[],"['str', 'list']",2
utilmy/zarchive/util.py:np_dict_tostr_key,np_dict_tostr_key,function,1,8,8,52,6.5,0,0,['dd'],[None],[None],1951,[],"['str', 'list']",2
utilmy/zarchive/util.py:np_removelist,np_removelist,function,6,15,15,71,4.73,1,1,"['x0', 'xremove']","[None, None]","[None, '[]']",1956,[],"['np_findfirst', 'xnew.append']",2
utilmy/zarchive/util.py:np_transform2d_int_1d,np_transform2d_int_1d,function,19,31,28,227,7.32,2,0,"['m2d', 'onlyhalf']","[None, None]","[None, 'False']",1962,[],"['np.shape', 'np.zeros', 'range', 'np.abs', 'np_sortbycol']",5
utilmy/zarchive/util.py:np_mergelist,np_mergelist,function,5,10,10,55,5.5,1,0,"['x0', 'x1']","[None, None]","[None, None]",1974,[],"['list', 'xnew.append']",2
utilmy/zarchive/util.py:np_enumerate2,np_enumerate2,function,6,14,14,83,5.93,1,0,['vec_1d'],[None],[None],1980,[],"['np.empty', 'enumerate']",2
utilmy/zarchive/util.py:np_pivottable_count,np_pivottable_count,function,12,24,23,170,7.08,1,0,['mylist'],[None],[None],1986,[],"['np_dict_tolist', 'sorted', 'int']",3
utilmy/zarchive/util.py:np_nan_helper,np_nan_helper,function,2,5,5,40,8.0,0,0,['y'],[None],[None],1994,"['    """""" Input:  - y, 1d numpy array with possible NaNs\n', '        Output - nans, logical indices of NaNs - index, a function, with signature indices= index(logical_indices),\n', ""              to convert logical indices of NaNs to 'equivalent' indices\n"", '    """"""\n']","['np.isnan', 'z.nonzero']",2
utilmy/zarchive/util.py:np_interpolate_nan,np_interpolate_nan,function,7,9,9,76,8.44,0,0,['y'],[None],[None],2001,[],"['np_nan_helper', 'np.interp', 'x']",3
utilmy/zarchive/util.py:np_and1,np_and1,function,8,55,22,356,6.47,0,6,"['x', 'y', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']","[None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None', 'None', 'None']",2006,[],[],0
utilmy/zarchive/util.py:np_sortcol,np_sortcol,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2014,"[' """""" df.sort([\'A\', \'B\'], ascending=[1, 0])  """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/util.py:np_sort,np_sort,function,7,19,12,184,9.68,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2020,[],"['pd.DataFrame', 'df.sort_values', 'np_sort']",3
utilmy/zarchive/util.py:np_ma,np_ma,function,2,3,3,45,15.0,0,0,"['vv', 'n']","[None, None]","[None, None]",2026,"[""  '''Moving average '''\n""]","['np.convolve', 'np.ones']",2
utilmy/zarchive/util.py:np_cleanmatrix,np_cleanmatrix,function,11,22,20,124,5.64,2,1,['m'],[None],[None],2032,[],"['np.nan_to_num', 'np.shape', 'range', 'abs']",4
utilmy/zarchive/util.py:np_torecarray,np_torecarray,function,2,6,6,105,17.5,0,0,"['arr', 'colname']","[None, None]","[None, None]",2040,[],['np.shape'],1
utilmy/zarchive/util.py:np_sortbycolumn,np_sortbycolumn,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",2043,[],"['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/util.py:np_sortbycol,np_sortbycol,function,8,30,20,257,8.57,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",2048,[],"['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/util.py:min_kpos,min_kpos,function,2,3,3,36,12.0,0,0,"['arr', 'kth']","[None, None]","[None, None]",2059,"[""   ''' return kth mininimun '''\n""]",['np.partition'],1
utilmy/zarchive/util.py:max_kpos,max_kpos,function,3,5,5,53,10.6,0,0,"['arr', 'kth']","[None, None]","[None, None]",2063,"[""   ''' return kth mininimun '''\n""]","['len', 'np.partition']",2
utilmy/zarchive/util.py:np_findfirst,np_findfirst,function,5,11,10,54,4.91,1,1,"['item', 'vec']","[None, None]","[None, None]",2070,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/util.py:np_find,np_find,function,5,11,10,54,4.91,1,1,"['item', 'vec']","[None, None]","[None, None]",2077,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/util.py:find,find,function,14,54,32,291,5.39,2,4,"['item', 'vec']","[None, None]","[None, None]",2084,"['    """"""return the index of the first occurence of item in vec""""""\n']","['range', 'findnone', 'findx', 'type', 'vec.index', 'len', 'finds']",7
utilmy/zarchive/util.py:findnone,findnone,function,4,11,10,54,4.91,1,1,['vec'],[None],[None],2090,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/util.py:findx,findx,function,6,27,18,119,4.41,0,2,"['item', 'vec']","[None, None]","[None, None]",2096,"['    """"""return the index of the first occurence of item in vec""""""\n']","['type', 'vec.index', 'len']",3
utilmy/zarchive/util.py:finds,finds,function,12,34,23,155,4.56,2,3,"['itemlist', 'vec']","[None, None]","[None, None]",2107,"['  """"""return the index of the first occurence of item in vec""""""\n']","['range', 'idlist.append']",2
utilmy/zarchive/util.py:findhigher,findhigher,function,5,13,12,50,3.85,1,1,"['x', 'vec']","[None, None]","[None, None]",2118,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/util.py:findlower,findlower,function,5,12,11,50,4.17,1,1,"['x', 'vec']","[None, None]","[None, None]",2124,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/util.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],2132,[],['min'],1
utilmy/zarchive/util.py:np_find_maxpos,np_find_maxpos,function,17,45,34,266,5.91,1,3,['values'],[None],[None],2136,[],"['max', 'np_find_maxpos_2nd', 'float', 'enumerate']",4
utilmy/zarchive/util.py:np_find_maxpos_2nd,np_find_maxpos_2nd,function,13,37,28,138,3.73,1,3,['numbers'],[None],[None],2140,[],"['float', 'enumerate']",2
utilmy/zarchive/util.py:np_findlocalmax2,np_findlocalmax2,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",2152,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/util.py:np_findlocalmin2,np_findlocalmin2,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",2186,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/util.py:np_findlocalmax,np_findlocalmax,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",2220,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/util.py:np_findlocalmin,np_findlocalmin,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",2234,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/util.py:np_stack,np_stack,function,12,53,25,323,6.09,0,7,"['v1', 'v2', 'v3', 'v4', 'v5']","[None, None, None, None, None]","[None, 'None', 'None', 'None', 'None']",2250,[],"['np.shape', 'np.row_stack', 'np.column_stack']",3
utilmy/zarchive/util.py:np_uniquerows,np_uniquerows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],2265,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/util.py:np_remove_zeros,np_remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",2270,[],[],0
utilmy/zarchive/util.py:np_sort,np_sort,function,7,19,12,184,9.68,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2273,"['    """"""\n', '    Creates a cross-tab or pivot table from a normalised input table. Use this\n', ""    function to 'denormalize' a table of normalized records.\n"", '\n', '    * The table argument can be a list of dictionaries or a Table object.\n', '    (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/334621)\n', '    * The left argument is a tuple of headings which are displayed down the\n', '    left side of the new table.\n', '    * The top argument is a tuple of headings which are displayed across the\n', '    top of the new table.\n', '    Tuples are used so that multiple element headings and columns can be used.\n', '\n', '    E.g. To transform the list (listOfDicts):\n', '\n', '    Name,   Year,  Value\n', '    -----------------------\n', ""    'Simon', 2004, 32\n"", ""    'Simon', 2005, 128\n"", ""    'Russel', 2004, 64\n"", ""    'Eric', 2004, 52\n"", ""    'Russel', 2005, 32\n"", '\n', '    into the new list:\n', '\n', ""    'Name',   2004, 2005\n"", '    ------------------------\n', ""    'Simon',  32,     128\n"", ""    'Russel',  64,     32\n"", ""    'Eric',   52,     NA\n"", '\n', '    you would call pivot with the arguments:\n', '\n', ""    newList = pivot(listOfDicts, ('Name',), ('Year',), 'Value')\n"", '\n', '    """"""\n']","['pd.DataFrame', 'df.sort_values', 'np_sort']",3
utilmy/zarchive/util.py:np_memory_array_adress,np_memory_array_adress,function,2,2,2,38,19.0,0,0,['x'],[None],[None],2276,[],[],0
utilmy/zarchive/util.py:np_pivotable_create,np_pivotable_create,function,28,99,61,699,7.06,4,5,"['table', 'left', 'top', 'value']","[None, None, None, None]","[None, None, None, None]",2283,"['    """"""\n', '    Creates a cross-tab or pivot table from a normalised input table. Use this\n', ""    function to 'denormalize' a table of normalized records.\n"", '\n', '    * The table argument can be a list of dictionaries or a Table object.\n', '    (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/334621)\n', '    * The left argument is a tuple of headings which are displayed down the\n', '    left side of the new table.\n', '    * The top argument is a tuple of headings which are displayed across the\n', '    top of the new table.\n', '    Tuples are used so that multiple element headings and columns can be used.\n', '\n', '    E.g. To transform the list (listOfDicts):\n', '\n', '    Name,   Year,  Value\n', '    -----------------------\n', ""    'Simon', 2004, 32\n"", ""    'Simon', 2005, 128\n"", ""    'Russel', 2004, 64\n"", ""    'Eric', 2004, 52\n"", ""    'Russel', 2005, 32\n"", '\n', '    into the new list:\n', '\n', ""    'Name',   2004, 2005\n"", '    ------------------------\n', ""    'Simon',  32,     128\n"", ""    'Russel',  64,     32\n"", ""    'Eric',   52,     NA\n"", '\n', '    you would call pivot with the arguments:\n', '\n', ""    newList = pivot(listOfDicts, ('Name',), ('Year',), 'Value')\n"", '\n', '    """"""\n']","['tuple', 'ysort.append', 'xsort.append', 'len', 'list', 'xsort.sort', 'headings.extend', 'sortedkeys.sort', 'row.extend', 't.append']",10
utilmy/zarchive/util.py:pd_info,pd_info,function,13,25,24,255,10.2,1,2,"['df', 'doreturn']","[None, None]","[None, '1']",2368,[],"['df.info', 'print', 'type', 'pd_info_memsize', 'pd_info', 'df.memory_usage']",6
utilmy/zarchive/util.py:pd_info_memsize,pd_info_memsize,function,5,6,6,84,14.0,0,1,"['df', 'memusage']","[None, None]","[None, '0']",2375,[],"['df.info', 'pd_info', 'df.memory_usage']",3
utilmy/zarchive/util.py:pd_row_findlast,pd_row_findlast,function,7,13,13,57,4.38,1,1,"['df', 'colid', 'emptyrowid']","[None, None, None]","[None, '0', 'None']",2382,[],['df.iterrows'],1
utilmy/zarchive/util.py:pd_row_select,pd_row_select,function,11,100,54,863,8.63,1,3,"['df', '**conditions']","[None, None]","[None, None]",2388,"[""    '''Select rows from a df according to conditions\n"", '    pdselect(data, a=2, b__lt=3) __gt __ge __lte  __in  __not_in\n', ""    will select all rows where 'a' is 2 and 'b' is less than 3\n"", ""    '''\n""]","['type', 'pd.DataFrame', 'list', 'c.endswith', 'np.in1d', 'ValueError']",6
utilmy/zarchive/util.py:pd_csv_randomread,pd_csv_randomread,function,11,41,37,266,6.49,0,1,"['filename', 'nsample', 'filemaxline', 'dtype']","[None, None, None, None]","[None, '10000', '-1', 'None']",2432,[],"['sum', 'open', 'np.sort', 'pd.read_csv']",4
utilmy/zarchive/util.py:pd_array_todataframe,pd_array_todataframe,function,14,46,33,313,6.8,0,2,"['array', 'colname', 'index1', 'dotranspose']","[None, None, None, None]","[None, 'None', 'None', 'False']",2442,[],"['np.shape', 'len', 'pd.DataFrame', 'np.array']",4
utilmy/zarchive/util.py:pd_dataframe_toarray,pd_dataframe_toarray,function,10,10,10,103,10.3,0,0,['df'],[None],[None],2452,[],['df.reset_index'],1
utilmy/zarchive/util.py:pd_createdf,pd_createdf,function,2,4,4,55,13.75,0,0,"['array1', 'col1', 'idx1']","[None, None, None]","[None, 'None', 'None']",2458,[],['pd.DataFrame'],1
utilmy/zarchive/util.py:pd_create_colmapdict_nametoint,pd_create_colmapdict_nametoint,function,9,12,12,77,6.42,1,0,['df'],[None],[None],2461,"[""  ''' 'close' ---> 5    '''\n""]",['enumerate'],1
utilmy/zarchive/util.py:pd_extract_col_idx_val,pd_extract_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],2471,[],[],0
utilmy/zarchive/util.py:pd_extract_col_uniquevalue_tocsv,pd_extract_col_uniquevalue_tocsv,function,5,10,9,101,10.1,0,0,"['df', 'colname', 'csvfile']","[None, None, None]","[None, ""''"", ""''""]",2475,"["" ''' Write one column into a file   '''\n""]","['np.array', 'pd.DataFrame', 'print']",3
utilmy/zarchive/util.py:pd_split_col_idx_val,pd_split_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],2484,[],[],0
utilmy/zarchive/util.py:pd_splitdf_inlist,pd_splitdf_inlist,function,15,34,26,254,7.47,3,2,"['df', 'colid', 'type1']","[None, None, None]","[None, None, '""dict""']",2487,"[""    ''' Split df into dictionnary of dict/list '''\n""]","['list', 'l1.append']",2
utilmy/zarchive/util.py:pd_find,pd_find,function,38,140,82,994,7.1,5,8,"['df', 'regex_pattern', 'col_restrict', 'isnumeric', 'doreturnposition']","[None, None, None, None, None]","[None, ""'*'"", '[]', 'False', 'False']",2502,"["" ''' Find string / numeric values inside df columns, return position where found\n"", ""     col_restrict : restrict to these columns '''\n""]","['str', 'print', 'enumerate', 'np.column_stack', 'len', 'gc.collect', 'np_dictordered_create', 'range', 'np.array']",9
utilmy/zarchive/util.py:pd_dtypes_totype2,pd_dtypes_totype2,function,6,9,9,58,6.44,1,0,"['df', 'columns', 'targetype']","[None, None, None]","[None, '[]', ""'category'""]",2548,[],[],0
utilmy/zarchive/util.py:pd_dtypes,pd_dtypes,function,7,12,11,91,7.58,1,0,"['df', 'columns', 'targetype']","[None, None, None]","[None, '[]', ""'category'""]",2553,[],['pd_dtypes'],1
utilmy/zarchive/util.py:pd_df_todict2,pd_df_todict2,function,16,31,27,247,7.97,1,2,"['df1', 'colkey', 'excludekey', 'onlyfirstelt']","[None, None, None, None]","[None, ""'table'"", ""['']"", ' True']",2568,[],"['df.drop_duplicates', 'range', 'len', 'dict0.setdefault']",4
utilmy/zarchive/util.py:pd_df_todict,pd_df_todict,function,17,35,31,306,8.74,1,2,"['df1', 'colkey', 'excludekey', 'onlyfirstelt']","[None, None, None, None]","[None, ""'table'"", ""['']"", ' True']",2581,[],"['df.drop_duplicates', 'range', 'len', 'dict0.setdefault', 'pd_df_todict']",5
utilmy/zarchive/util.py:pd_col_addfrom_dfmap,pd_col_addfrom_dfmap,function,12,44,34,229,5.2,0,1,"['df', 'dfmap', 'colkey', 'colval', 'df_colused', 'df_colnew', 'exceptval', 'inplace']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, '-1', ' True']",2594,"[""  ''' Add new columns based on df_map:  In Place Modification of df\n"", '    df:     Dataframe of transactions.\n', '    dfmap:  FSMaster Dataframe\n', '      colkey: colum used for dict key.  machine_code\n', '      colval: colum used for dict val.  adress\n', '      \n', '    df_colused  :     ""machine_code""\n', ""    exception val:  -1 or ''\n"", ""  '''\n""]","['pd_df_todict', 'map_dict_fun', 'df.apply']",3
utilmy/zarchive/util.py:pd_applyfun_col,pd_applyfun_col,function,5,11,9,107,9.73,0,1,"['df', 'newcol', 'ff', 'use_colname']","[None, None, None, None]","[None, None, None, '""all/[colname]""']",2652,"[""   ''' use all Columns to compute values '''\n""]",['ff'],1
utilmy/zarchive/util.py:pd_date_intersection,pd_date_intersection,function,7,18,15,157,8.72,1,0,['qlist'],[None],[None],2669,[],"['set', 'set.intersection', 'list', 'sorted']",4
utilmy/zarchive/util.py:pd_is_categorical,pd_is_categorical,function,2,12,10,108,9.0,0,1,['z'],[None],[None],2677,[],['isinstance'],1
utilmy/zarchive/util.py:pd_str_encoding_change,pd_str_encoding_change,function,6,8,8,76,9.5,1,0,"['df', 'cols', 'fromenc', 'toenc']","[None, None, None, None]","[None, None, ""'iso-8859-1'"", ""'utf-8'""]",2684,[],[],0
utilmy/zarchive/util.py:pd_str_unicode_tostr,pd_str_unicode_tostr,function,2,4,4,60,15.0,0,0,"['df', 'targetype']","[None, None]","[None, 'str']",2690,"["" '''\n"", ' https://www.azavea.com/blog/2014/03/24/solving-unicode-problems-in-python-2-7/\n', ' Nearly every Unicode problem can be solved by the proper application of these tools;\n', ' they will help you build an airlock to keep the inside of your code nice and clean:\n', '\n', 'encode(): Gets you from Unicode -> bytes\n', 'decode(): Gets you from bytes -> Unicode\n', 'codecs.open(encoding=utf-8): Read and write files directly to/from Unicode (you can use any encoding,\n', ' not just utf-8, but utf-8 is most common).\n', 'u: Makes your string literals into Unicode objects rather than byte sequences.\n', 'Warning: Dont use encode() on bytes or decode() on Unicode objects\n', '\n', '>>> uni_greeting % utf8_name\n', 'Traceback (most recent call last):\n', ' File ""<stdin>"", line 1, in <module>\n', ""UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 3: ordinal not in range(128)\n"", '# Solution:\n', "">>> uni_greeting % utf8_name.decode('utf-8')\n"", ""u'Hi, my name is Josxe9.'\n"", '\n', "" '''\n""]",['pd_dtypes_type1_totype2'],1
utilmy/zarchive/util.py:pd_dtypes_type1_totype2,pd_dtypes_type1_totype2,function,7,13,12,100,7.69,1,1,"['df', 'fromtype', 'targetype']","[None, None, None]","[None, 'str', 'str']",2714,[],['isinstance'],1
utilmy/zarchive/util.py:pd_resetindex,pd_resetindex,function,3,4,4,50,12.5,0,0,['df'],[None],[None],2723,[],['list'],1
utilmy/zarchive/util.py:pd_insertdatecol,pd_insertdatecol,function,8,11,11,192,17.45,0,0,"['df_insider', 'format1=""%Y-%m-%d %H']","[None, '']","[None, '""%Y-%m-%d %H:%M:%S:%f""']",2727,[],"['pd_addcol', 'date_nowtime']",2
utilmy/zarchive/util.py:pd_replacevalues,pd_replacevalues,function,11,14,14,101,7.21,1,0,"['df', 'matrix']","[None, None]","[None, None]",2733,"["" ''' Matrix replaces df.values  '''\n""]",['np.shape'],1
utilmy/zarchive/util.py:pd_removerow,pd_removerow,function,2,2,2,29,14.5,0,0,"['df', 'row_list_index', '45]']","[None, None, None]","[None, '[23', None]",2742,[],['df.drop'],1
utilmy/zarchive/util.py:pd_removecol,pd_removecol,function,2,3,3,28,9.33,0,0,"['df1', 'name1']","[None, None]","[None, None]",2745,[],['df1.drop'],1
utilmy/zarchive/util.py:pd_insertrow,pd_insertrow,function,6,10,10,102,10.2,0,0,"['df', 'rowval', 'index1', 'isreset']","[None, None, None, None]","[None, None, 'None', '1']",2749,[],"['pd_array_todataframe', 'df.append']",2
utilmy/zarchive/util.py:pd_h5_cleanbeforesave,pd_h5_cleanbeforesave,function,5,12,11,91,7.58,0,0,['df'],[None],[None],2757,"[""   '''Clean Column type before Saving in HDFS: Unicode, Datetime  '''\n""]","['pd_resetindex', 'pd_str_unicode_tostr']",2
utilmy/zarchive/util.py:pd_h5_addtable,pd_h5_addtable,function,5,18,17,148,8.22,0,1,"['df', 'tablename', ""dbfile='F""]","[None, None, '']","[None, None, ""'F:\\temp_pandas.h5'""]",2773,[],"['pd.HDFStore', 'find', 'list', 'print', 'store.append', 'store.close']",6
utilmy/zarchive/util.py:pd_h5_tableinfo,pd_h5_tableinfo,function,4,4,4,65,16.25,0,0,"['filenameh5', 'table']","[None, None]","[None, None]",2782,[],"['pd.HDFStore', 'store.get_storer']",2
utilmy/zarchive/util.py:pd_h5_dumpinfo,pd_h5_dumpinfo,function,12,23,23,304,13.22,1,0,"[""dbfile='E""]",[''],"[""'E:\\_data\\stock\\intraday_google.h5'""]",2787,[],"['pd.HDFStore', 'list', 'pd.read_hdf', 'extract.append', 'datetime_tostring', 'errsym.append', 'np.array']",7
utilmy/zarchive/util.py:pd_h5_save,pd_h5_save,function,3,6,6,64,10.67,0,0,"['df', ""filenameh5='E"", 'key']","[None, '', None]","[None, ""'E:/_data/_data_outlier.h5'"", ""'data'""]",2800,"["" ''' File is release after saving it'''\n""]","['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zarchive/util.py:pd_h5_load,pd_h5_load,function,4,22,16,185,8.41,0,2,"[""filenameh5='E"", 'table_id', 'exportype', 'rowstart', 'rowend', 'cols']","['', None, None, None, None, None]","[""'E:/_data/_data_outlier.h5'"", ""'data'"", '""pandas""', '-1', '-1', '[]']",2805,[],['pd.read_hdf'],1
utilmy/zarchive/util.py:pd_h5_fromcsv_tohdfs,pd_h5_fromcsv_tohdfs,function,30,78,65,670,8.59,3,2,"['dircsv', 'filepattern', 'tofilehdfs', 'tablename', 'col_category', 'dtype0', 'encoding', 'chunksize', 'mode', 'format', 'complib']","[None, None, None, None, None, None, None, None, None, None, None]","[""'dir1/dir2/'"", ""'*.csv'"", ""'file1.h5'"", ""'df'"", '[]', 'None', ""'utf-8'"", ' 2000000', ""'a'"", ""'table'"", 'None']",2811,[],"['os_file_listall', 'pd.HDFStore', 'enumerate', 'pd.read_csv', 'print', 'store.append', 'store.close', 'os_file_exist']",8
utilmy/zarchive/util.py:pd_np_toh5file,pd_np_toh5file,function,2,8,8,76,9.5,0,0,"['numpyarr', 'fileout', 'table1']","[None, None, None]","[None, '""file.h5""', ""'data'""]",2848,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zarchive/util.py:date_allinfo,date_allinfo,function,0,0,0,0,0.0,0,0,[],[],[],2856,"[""   '''\n"", '\n', '   https://aboutsimon.com/blog/2016/08/04/datetime-vs-Arrow-vs-Pendulum-vs-Delorean-vs-udatetime.html\n', '\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/util.py:date_convert,date_convert,function,14,53,37,303,5.72,1,1,"['t1', 'fromtype', 'totype']","[None, None, None]","[None, None, None]",2865,[],"['len', 'isinstance', '_dateconvert_from', 'tlist.append']",4
utilmy/zarchive/util.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],2889,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/util.py:date_remove_bdays,date_remove_bdays,function,16,41,28,351,8.56,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2899,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/util.py:date_add_bdays,date_add_bdays,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2913,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/util.py:datenumpy_todatetime,datenumpy_todatetime,function,11,36,22,384,10.67,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",2927,[],['type'],1
utilmy/zarchive/util.py:datetime_tonumpydate,datetime_tonumpydate,function,2,2,2,22,11.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",2943,[],['np.datetime64'],1
utilmy/zarchive/util.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",2947,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/util.py:datetime_toint,datetime_toint,function,6,15,13,155,10.33,1,1,['datelist1'],[None],[None],2955,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/util.py:date_holiday,date_holiday,function,0,0,0,0,0.0,0,0,[],[],[],2962,"[""   '''\n"", '   https://jakevdp.github.io/blog/2015/07/23/learning-seattles-work-habits-from-bicycle-counts/\n', '\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'cal = USFederalHolidayCalendar()\n', ""holidays = cal.holidays('2012', '2016', return_name=True)\n"", 'holidays.head()\n', '\n', 'holidays_all = pd.concat([holidays, ""Day Before "" + holidays.shift(-1, \'D\'),  ""Day After "" + holidays.shift(1, \'D\')])\n', 'holidays_all = holidays_all.sort_index()\n', 'holidays_all.head()\n', '\n', 'from pandas.tseries.offsets import CustomBusinessDay\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'bday_us = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n', 'dateref[-1] - bday_us- bday_us\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/util.py:date_add_bday,date_add_bday,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",2982,"["" ''' str / stamp /  '''\n""]","['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/util.py:dateint_todatetime,dateint_todatetime,function,6,15,13,135,9.0,1,1,['datelist1'],[None],[None],2995,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/util.py:date_diffinday,date_diffinday,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",3003,[],['dateint_todatetime'],1
utilmy/zarchive/util.py:date_diffinyear,date_diffinyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",3007,[],['date_as_float'],1
utilmy/zarchive/util.py:date_diffinbday,date_diffinbday,function,7,11,9,112,10.18,0,0,"['intd2', 'intd1']","[None, None]","[None, None]",3010,[],"['dateint_todatetime', 'd1.date', 'd2.date', 'np.busday_count']",4
utilmy/zarchive/util.py:date_gencalendar,date_gencalendar,function,9,13,11,233,17.92,0,0,"['start', 'end', 'country']","[None, None, None]","[""'2010-01-01'"", ""'2010-01-15'"", ""'us'""]",3018,[],"['CustomBusinessDay', 'np.arrray']",2
utilmy/zarchive/util.py:date_finddateid,date_finddateid,function,5,75,20,437,5.83,0,10,"['date1', 'dateref']","[None, None]","[None, None]",3024,[],['np_findfirst'],1
utilmy/zarchive/util.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],3038,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/util.py:date_now,date_now,function,15,45,31,396,8.8,0,2,['i'],[None],['0'],3044,[],"['datetime.now', 'date_add_bdays', 'date_remove_bdays', 'str', 'date_nowtime', 'datetime.today', 'd.strftime']",7
utilmy/zarchive/util.py:date_nowtime,date_nowtime,function,8,23,18,205,8.91,0,1,"['type1', 'format1= ""%Y-%m-%d %H']","[None, '']","[""'str'"", ' ""%Y-%m-%d %H:%M:%S:%f""']",3051,"["" ''' str / stamp /  '''\n""]","['datetime.today', 'd.strftime']",2
utilmy/zarchive/util.py:date_tofloat,date_tofloat,function,11,28,23,273,9.75,0,1,['dt'],[None],[None],3060,[],"['datetime.datetime', 'isleap', 'timedelta']",3
utilmy/zarchive/util.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",3068,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/util.py:np_numexpr_vec_calc,np_numexpr_vec_calc,function,13,28,22,214,7.64,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",3081,"["" ''' New= xx*xx  over very large series\n"", ' #numexpr_vect_calc(filename, 0, imax=16384*4096, ""xx*xx"", \'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5\'  ):\n', ""'''\n""]","['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/util.py:np_numexpr_tohdfs,np_numexpr_tohdfs,function,10,28,22,248,8.86,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",3095,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/util.py:np_comoment,np_comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",3111,[],['ne.evaluate'],1
utilmy/zarchive/util.py:np_acf,np_acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],3117,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/util.py:plot_XY,plot_XY,function,25,83,60,688,8.29,0,3,"['xx', 'yy', 'zcolor', 'tsize', 'title1', 'xlabel', 'ylabel', 'figsize', '6']","[None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', ""''"", ""''"", ""''"", '(8', None]",3133,[],"['isinstance', 'np.array', 'np.abs', 'plt.get_cmap', 'np.min', 'plt.subplots', 'fig.set_size_inches', 'fig.set_dpi', 'fig.tight_layout', 'ax1.scatter', 'ax1.set_xlabel', 'ax1.set_ylabel', 'ax1.set_title', 'ax1.grid', 'plt.savefig', 'plt.clf', 'plt.show']",17
utilmy/zarchive/util.py:plot_heatmap,plot_heatmap,function,15,26,25,364,14.0,0,1,"['frame', 'ax', 'cmap', 'vmin', 'vmax', 'interpolation']","[None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', ""'nearest'""]",3173,[],"['plt.gca', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_yticks', 'ax.set_yticklabels', 'ax.grid', 'ax.set_aspect', 'ax.imshow']",8
utilmy/zarchive/util.py:np_map_dict_to_bq_schema,np_map_dict_to_bq_schema,function,13,59,31,720,12.2,3,3,"['source_dict', 'schema', 'dest_dict']","[None, None, None]","[None, None, None]",3190,"[""    '''\n"", '     new_dict = {}\n', '     map_dict_to_bq_schema (my_dict, schema, new_dict)\n', '\n', '     new_dict = {}\n', '     map_dict_to_bq_schema (my_dict, schema, new_dict)\n', '\n', '    :param source_dict:\n', '    :param schema:\n', '    :param dest_dict:\n', '    :return:\n', ""    '''\n""]","['np_map_dict_to_bq_schema', 'format_value_bq']",2
utilmy/zarchive/util.py:googledrive_get,googledrive_get,function,0,1,1,4,4.0,0,0,[],[],[],3235,"[""   '''\n"", '   https://github.com/ctberthiaume/gdcp\n', '   ... I am using this now to transfer thousands of mp3 files from a ubuntu vps to google drive.\n', '\n', '\n', 'http://olivermarshall.net/how-to-upload-a-file-to-google-drive-from-the-command-line/\n', 'https://github.com/prasmussen/gdrive  : Super Complete\n', '\n', 'gdrive [global] upload [options] <path>\n', '\n', 'global:\n', '  -c, --config <configDir>         Application path, default: /Users/<user>/.gdrive\n', '  --refresh-token <refreshToken>   Oauth refresh token used to get access token (for advanced users)\n', '  --access-token <accessToken>     Oauth access token, only recommended for short-lived requests because of short lifetime (for advanced users)\n', '\n', 'options:\n', '  -r, --recursive           Upload directory recursively\n', '  -p, --parent <parent>     Parent id, used to upload file to a specific directory, can be specified multiple times to give many parents\n', '  --name <name>             Filename\n', '  --no-progress             Hide progress\n', '  --mime <mime>             Force mime type\n', '  --share                   Share file\n', '  --delete                  Delete local file when upload is successful\n', '  --chunksize <chunksize>   Set chunk size in bytes, default: 8388608\n', '\n', '   :return:\n', ""   '''\n""]",[],0
utilmy/zarchive/util.py:googledrive_put,googledrive_put,function,0,1,1,4,4.0,0,0,[],[],[],3265,"[""  '''\n"", '  100 GB: 2USD,  1TB: 10USD\n', '  https://gsuite.google.com/intl/en/pricing.html\n', '\n', '  :return:\n', ""  '''\n""]",[],0
utilmy/zarchive/util.py:googledrive_list,googledrive_list,function,0,1,1,4,4.0,0,0,[],[],[],3275,[],[],0
utilmy/zarchive/util.py:os_processify_fun,os_processify_fun,function,32,78,63,713,9.14,0,1,['func'],[None],[None],3280,"[""    '''Decorator to run a function as a process.\n"", '    Be sure that every argument and the return value is *pickable*.\n', '    The created process is joined, so the code does not  run in parallel.\n', '    @processify\n', '\n', '    def test():\n', '      return os.getpid()\n', '\n', '    @processify\n', '    def test_deadlock():\n', '      return range(30000)\n', '\n', '   @processify\n', '   def test_exception():\n', ""     raise RuntimeError('xyz')\n"", '\n', '   def test():\n', '     print os.getpid()\n', '     print test_function()\n', '     print len(test_deadlock())\n', '     test_exception()\n', '\n', ""   if __name__ == '__main__':\n"", '     test()\n', '\n', ""    '''\n""]","['process_func', 'func', 'sys.exc_info', 'q.put', 'setattr', 'wrapper', 'Queue', 'Process', 'list', 'p.start', 'q.get', 'ex_type']",12
utilmy/zarchive/util.py:ztest_processify,ztest_processify,function,2,2,2,17,8.5,0,0,[],[],[],3347,[],['os.getpid'],1
utilmy/zarchive/util.py:date_getspecificdate,date_getspecificdate,function,21,194,56,1312,6.76,8,19,"['datelist', 'datetype1', 'outputype1', 'includelastdate', 'includefirstdate', '']","[None, None, None, None, None, None]","[None, '""yearend""', '""intdate""', 'True', 'False', None]",3353,[],"['isint', 'dateint_todatetime', 'enumerate', 'vec2.append', 'np.mod', 'np.array']",6
utilmy/zarchive/util.py:py_exception_print,py_exception_print,function,16,27,26,281,10.41,0,0,[],[],[],3413,[],"['sys.exc_info', 'linecache.checkcache', 'linecache.getline', 'print', 'line.strip']",5
utilmy/zarchive/util.py:py_log_write,py_log_write,function,13,29,26,365,12.59,0,0,"['LOGFILE', 'prefix']","[None, None]","[None, None]",3424,[],"['print', 'arrow.utcnow', 'str', 'open']",4
utilmy/zarchive/util.py:testclass,testclass,class,21,51,42,434,8.51,0,3,[],[],[],148,[],[],0
utilmy/zarchive/util.py:FundingRecord,FundingRecord,class,14,59,48,394,6.68,0,0,[],[],[],1582,[],[],0
utilmy/zarchive/util.py:testclass:__init__,testclass:__init__,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",149,[],[],0
utilmy/zarchive/util.py:testclass:z_autotest,testclass:z_autotest,method,19,44,38,387,8.8,0,3,['self'],[None],[None],152,[],"['io.StringIO', 'f', 'self.redirect_internalshell_stdio', 'getopenfilename', '_', 'getcwd', 'self.close']",7
utilmy/zarchive/util.py:FundingRecord:parse,FundingRecord:parse,method,7,35,26,223,6.37,0,0,"['klass', 'row']","[None, None]","[None, None]",1585,[],"['list', 'int', 'datetime.strptime', 'klass']",4
utilmy/zarchive/util.py:FundingRecord:__str__,FundingRecord:__str__,method,6,18,18,118,6.56,0,0,['self'],[None],[None],1592,[],[],0
utilmy/zarchive/utilgeo.py:df_to_geojson,df_to_geojson,function,10,24,21,329,13.71,2,0,"['df', 'col_properties', 'lat', 'lon']","[None, None, None, None]","[None, None, ""'latitude'"", ""'longitude'""]",24,[],['df.iterrows'],1
utilmy/zarchive/util_aws.py:aws_credentials,aws_credentials,function,3,7,7,126,18.0,0,0,['account'],[None],['None'],41,"['    """"""\n', '    Return a tuple of AWS credentials (access key id and secret access key) for\n', '    the given account.\n', '    """"""\n']",['INIConfig'],1
utilmy/zarchive/util_aws.py:aws_ec2_get_instanceid,aws_ec2_get_instanceid,function,4,7,6,110,15.71,0,1,"['con', 'ip_address']","[None, None]","[None, None]",283,[],['con.get_all_instances'],1
utilmy/zarchive/util_aws.py:aws_ec2_allocate_elastic_ip,aws_ec2_allocate_elastic_ip,function,7,31,23,358,11.55,0,1,"['con', 'instance_id', 'elastic_ip', 'region']","[None, None, None, None]","[None, '""""', ""''"", '""ap-northeast-2""']",288,[],"['con.allocate_address', 'con.associate_address']",2
utilmy/zarchive/util_aws.py:aws_ec2_printinfo,aws_ec2_printinfo,function,5,17,12,93,5.47,0,3,"['instance', 'ipadress', 'instance_id']","[None, None, None]","['None', '""""', '""""']",300,"[""   '''   Idenfiy instnance of\n"", '   :param instance: \n', '     ipadress\n', '   :param instance_id: \n', '   :return: return info on the instance : ip, ip_adress,  \n', ""   '''\n""]","['print', 'pprint']",2
utilmy/zarchive/util_aws.py:aws_ec2_spot_start,aws_ec2_spot_start,function,26,96,89,1014,10.56,1,1,"['con', 'region', 'key_name', 'inst_type', 'ami_id', 'pricemax', 'elastic_ip', 'pars= {""security_group""', '""disk_size""', '""disk_type""', '""volume_type""']","[None, None, None, None, None, None, None, '', ' 25', ' ""ssd""', ' ""gp2""}']","[None, None, '""ecsInstanceRole""', '""cx2.2""', '""""', '0.15', ""''"", ' {""security_group"": [""""]', None, None, None]",320,"[""    '''\n"", '   :param con:   Connector to Boto\n', '   :param region: AWS region (us-east-1,..) \n', '   :param key_name: AWS  SSH Key Name  (in EC2 webspage )\n', '   :param security_group: AWS security group id\n', '   :param inst_type:  AWS EC2 instance type (t1.micro, m1.small ...)\n', '   :param ami_id:  AWS AMI ID\n', '   :param pars: Disk Size, Volume type (General Purpose SSD - gp2, Magnetic etc)\n', '   :param pricemax: minmum spot instance bid price\n', ""    '''\n""]","['dict2', 'BlockDeviceMapping', 'EBSBlockDeviceType', 'int', 'print', 'con.request_spot_instances', 'con.get_all_spot_instance_requests', 'con.get_all_instances', 'aws_ec2_allocate_elastic_ip', 'aws_ec2_printinfo', 'sleep']",11
utilmy/zarchive/util_aws.py:aws_ec2_get_id,aws_ec2_get_id,function,4,11,9,69,6.27,0,2,"['ipadress', 'instance_id']","[None, None]","[""''"", ""''""]",368,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_spot_stop,aws_ec2_spot_stop,function,5,39,33,281,7.21,0,1,"['con', 'ipadress', 'instance_id']","[None, None, None]","[None, '""""', '""""']",379,"[""   '''\n"", '   :param con: connector \n', '   :param ipadress:   of the instance  to Identify the instance.\n', '   :param instance_id:  OR use instance ID....\n', '   :return: \n', ""   '''\n""]","['aws_ec2_get_instanceid', 'str', 'con.terminate_instances']",3
utilmy/zarchive/util_aws.py:aws_ec2_res_start,aws_ec2_res_start,function,26,97,90,972,10.02,1,1,"['con', 'region', 'key_name', 'ami_id', 'inst_type', 'min_count ', 'max_count ', 'pars= {""security_group""', '""disk_size""', '""disk_type""', '""volume_type""']","[None, None, None, None, None, None, None, '', ' 25', ' ""ssd""', ' ""gp2""}']","[None, None, None, None, '""cx2.2""', '1', '1', ' {""security_group"": [""""]', None, None, None]",405,"[""    '''  \n"", '        normal instance start\n', '        :param con:   Connector to Boto\n', '        :param region: AWS region (us-east-1,..) \n', '        :param key_name: AWS  SSH Key Name\n', '        :param security_group: AWS security group id\n', '        :param inst_type:  AWS EC2 instance type (t1.micro, m1.small ...)\n', '        :param ami_id:  AWS AMI ID\n', '        :param min_count: Minumum number of instances\n', '        :param max_count : Maximum number of instances\n', '        :param pars: Disk Size, Volume type (General Purpose SSD - gp2, Magnetic etc)\n', '        :return \n', ""    '''\n""]","['dict2', 'BlockDeviceMapping', 'EBSBlockDeviceType', 'int', 'print', 'con.run_instances', 'con.get_all_instances', 'aws_ec2_printinfo', 'sleep']",9
utilmy/zarchive/util_aws.py:aws_ec2_res_stop,aws_ec2_res_stop,function,7,44,37,309,7.02,0,1,"['con', 'ipadress', 'instance_id']","[None, None, None]","[None, '""""', '""""']",450,"[""   '''\n"", '   :param con: connector \n', '   :param ipadress:     Of the instance  to Identify the instance.\n', '   :param instance_id:  OR use instance ID....\n', '   :return: \n', ""   '''\n""]","['aws_ec2_get_instanceid', 'con.stop_instances', 'str']",3
utilmy/zarchive/util_aws.py:aws_accesskey_get,aws_accesskey_get,function,6,19,16,193,10.16,0,1,"['access', 'key']","[None, None]","[""''"", ""''""]",483,[],['print'],1
utilmy/zarchive/util_aws.py:aws_conn_do,aws_conn_do,function,2,3,3,39,13.0,0,0,"['action', 'region']","[None, None]","[""''"", '""ap-northeast-2""']",492,[],['aws_conn_create'],1
utilmy/zarchive/util_aws.py:aws_conn_getallregions,aws_conn_getallregions,function,2,2,2,28,14.0,0,0,['conn'],[None],['None'],497,[],['conn.get_all_regions'],1
utilmy/zarchive/util_aws.py:aws_conn_create,aws_conn_create,function,21,36,34,282,7.83,1,2,"['region', 'access', 'key']","[None, None, None]","['""ap-northeast-2""', ""''"", ""''""]",500,[],"['aws_accesskey_get', 'EC2Connection', 'aws_conn_getallregions', 'conn=EC2Connection', 'print']",5
utilmy/zarchive/util_aws.py:aws_conn_getinfo,aws_conn_getinfo,function,1,2,2,23,11.5,0,0,['conn'],[None],[None],513,[],['print'],1
utilmy/zarchive/util_aws.py:aws_s3_url_split,aws_s3_url_split,function,4,5,5,52,10.4,0,0,['url'],[None],[None],543,"[""  '''Split into Bucket, url '''\n""]",['url.split'],1
utilmy/zarchive/util_aws.py:aws_s3_getbucketconn,aws_s3_getbucketconn,function,13,17,16,221,13.0,0,0,['s3dir'],[None],[None],548,[],"['aws_s3_url_split', 'aws_accesskey_get', 'boto.connect_s3', 'conn.get_bucket']",4
utilmy/zarchive/util_aws.py:aws_s3_puto_s3,aws_s3_puto_s3,function,35,114,102,1162,10.19,3,2,"['fromdir_file', 'todir']","[None, None]","[""'dir/file.zip'"", ""'bucket/folder1/folder2'""]",556,"["" ''' Copy File or Folder to S3 '''\n""]","['aws_s3_getbucketconn', 'aws_s3_url_split', 'fromdir_file.find', 'util.os_file_getname', 'os.walk', 'uploadFileNames.extend', 'percent_cb', 'print', 'bucket.initiate_multipart_upload', 'open', 'mp.upload_part_from_file', 'mp.complete_upload', 'k.set_contents_from_filename']",13
utilmy/zarchive/util_aws.py:aws_s3_getfrom_s3,aws_s3_getfrom_s3,function,21,44,44,435,9.89,1,1,"['froms3dir', 'todir', 'bucket_name']","[None, None, None]","[""'task01/'"", ""''"", ""'zdisk'""]",600,"["" ''' Get from S3 file/folder  '''\n""]","['aws_s3_url_split', 'aws_s3_getbucketconn', 'bucket.list', 'str', 'util.os_file_getname', 'util.os_file_getpath', 'os.makedirs', 'l.get_contents_to_filename']",8
utilmy/zarchive/util_aws.py:aws_s3_folder_printtall,aws_s3_folder_printtall,function,12,19,18,234,12.32,1,0,['bucket_name'],[None],"[""'zdisk'""]",620,[],"['aws_accesskey_get', 'boto.connect_s3', 'conn.create_bucket', 'bucket.list']",4
utilmy/zarchive/util_aws.py:aws_s3_file_read,aws_s3_file_read,function,10,14,13,186,13.29,0,0,"['bucket1', 'filepath', 'isbinary']","[None, None, None]","[None, None, '1']",630,"[""  ''' s3_client = boto3.client('s3')\n"", '    #Download private key file from secure S3 bucket\n', ""  s3_client.download_file('s3-key-bucket','keys/keyname.pem', '/tmp/keyname.pem')\n"", ""  '''\n""]","['S3Connection', 'conn.get_object']",2
utilmy/zarchive/util_aws.py:aws_ec2_cmd_ssh,aws_ec2_cmd_ssh,function,23,82,72,560,6.83,1,4,"['cmdlist', 'host', 'doreturn', 'ssh', 'username', 'keyfilepath']","[None, None, None, None, None, None]","['  [""ls "" ]', ""'ip'"", '0', 'None', ""'ubuntu'"", ""''""]",642,"[""    ''' SSH Linux terminal Command\n"", '     https://www.siteground.com/tutorials/ssh/ssh_deleting.htm\n', '\n', '     rm -rf foldername/\n', '\n', '\n', '    fuser 8888/tcp     Check if Jupyter is running\n', '    ps -ef | grep python     :List of  PID Python process\n', '    kill -9 PID_number     (i.e. the pid returned)\n', '    top     : CPU usage\n', '\n', '      Run nohup python bgservice.py & to get the script to ignore the hangup signal and keep running.\n', '      Output will be put in nohup.out.\n', '        ""aws s3 cp s3://s3-bucket/scripts/HelloWorld.sh /home/ec2-user/HelloWorld.sh"",\n', '        ""chmod 700 /home/ec2-user/HelloWorld.sh"",\n', '        ""/home/ec2-user/HelloWorld.sh""\n', '\n', '    https://aws.amazon.com/blogs/compute/scheduling-ssh-jobs-using-aws-lambda/\n', ""   '''\n""]","['len', 'aws_ec2_create_con', 'print', 'isinstance', 'ssh.exec_command', 'stdout.read', 'stderr.read', 'readall.append', 'ssh.close']",9
utilmy/zarchive/util_aws.py:aws_ec2_python_script,aws_ec2_python_script,function,5,20,18,195,9.75,0,0,"['script_path', 'args1', 'host']","[None, None, None]","[None, None, None]",682,[],['aws_ec2_cmd_ssh'],1
utilmy/zarchive/util_aws.py:aws_ec2_create_con,aws_ec2_create_con,function,36,121,93,1016,8.4,1,9,"['contype', 'host', 'port', 'username', 'keyfilepath', 'password', 'keyfiletype', 'isprint']","[None, None, None, None, None, None, None, None]","[""'sftp/ssh'"", ""'ip'"", '22', ""'ubuntu'"", ""''"", ""''"", ""'RSA'"", '1']",687,"['    """""" Transfert File  host = \'52.79.79.1\'\n', ""        keyfilepath = 'D:/_devs/aws/keypairs/ec2_instanc'\n"", '\n', '# List files in the default directory on the remote computer.\n', ""dirlist = sftp.listdir('.')\n"", ""sftp.get('remote_file.txt', 'downloaded_file.txt')\n"", ""sftp.put('testfile.txt', 'remote_testfile.txt')\n"", '\n', 'http://docs.paramiko.org/en/2.1/api/sftp.html\n', '    """"""\n']","['paramiko.Transport', 'transport.add_server_key', 'transport.connect', 'print', 'sftp.listdir', 'paramiko.SSHClient', 'ssh.set_missing_host_key_policy', 'ssh.connect', 'ssh.exec_command', 'stdin.flush', 'stdout.read', 'sftp.close', 'transport.close', 'ssh.close']",14
utilmy/zarchive/util_aws.py:ztest_01,ztest_01,function,0,1,1,4,4.0,0,0,[],[],[],1069,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh,aws_ec2_ssh,class,132,332,236,4141,12.47,9,10,[],[],[],54,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh:__init__,aws_ec2_ssh:__init__,method,24,61,49,779,12.77,0,4,"['self', 'hostname', 'username', 'key_file', 'password']","[None, None, None, None, None]","[None, None, ""'ubuntu'"", 'None', 'None']",70,[],"['socket.socket', 'paramiko.Transport', 'isinstance', 'key_file=open', 'key_file.seek', 'Exception', 'print']",7
utilmy/zarchive/util_aws.py:aws_ec2_ssh:command,aws_ec2_ssh:command,method,12,19,17,242,12.74,1,0,"['self', 'cmd']","[None, None]","[None, None]",111,[],"['chan.get_pty', 'chan.invoke_shell', 'chan.settimeout', 'chan.send', 'cmd.split']",5
utilmy/zarchive/util_aws.py:aws_ec2_ssh:put,aws_ec2_ssh:put,method,17,33,29,648,19.64,2,2,"['self', 'localfile', 'remotefile']","[None, None, None]","[None, None, None]",131,[],"['put_all', 'os.chdir', 'os.walk', 'print', 'self.put']",5
utilmy/zarchive/util_aws.py:aws_ec2_ssh:put_all,aws_ec2_ssh:put_all,method,15,30,26,573,19.1,2,2,"['self', 'localpath', 'remotepath']","[None, None, None]","[None, None, None]",135,[],"['os.chdir', 'os.walk', 'print', 'self.put']",4
utilmy/zarchive/util_aws.py:aws_ec2_ssh:get,aws_ec2_ssh:get,method,1,1,1,35,35.0,0,0,"['self', 'remotefile', 'localfile']","[None, None, None]","[None, None, None]",151,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh:sftp_walk,aws_ec2_ssh:sftp_walk,method,18,31,25,347,11.19,3,1,"['self', 'remotepath']","[None, None]","[None, None]",155,[],"['S_ISDIR', 'folders.append', 'files.append', 'self.sftp_walk']",4
utilmy/zarchive/util_aws.py:aws_ec2_ssh:get_all,aws_ec2_ssh:get_all,method,15,38,30,599,15.76,2,2,"['self', 'remotepath', 'localpath']","[None, None, None]","[None, None, None]",175,[],"['os.mkdir', 'self.sftp_walk', 'print', 'self.get']",4
utilmy/zarchive/util_aws.py:aws_ec2_ssh:write_command,aws_ec2_ssh:write_command,method,2,2,2,74,37.0,0,0,"['self', 'text', 'remotefile']","[None, None, None]","[None, None, None]",199,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh:python_script,aws_ec2_ssh:python_script,method,5,12,10,119,9.92,0,0,"['self', 'script_path', 'args1']","[None, None, None]","[None, None, None]",206,[],['self.cmd2'],1
utilmy/zarchive/util_aws.py:aws_ec2_ssh:command_list,aws_ec2_ssh:command_list,method,5,13,13,119,9.15,1,0,"['self', 'cmdlist']","[None, None]","[None, None]",212,[],"['print', 'self.command']",2
utilmy/zarchive/util_aws.py:aws_ec2_ssh:listdir,aws_ec2_ssh:listdir,method,2,2,2,34,17.0,0,0,"['self', 'remotedir']","[None, None]","[None, None]",219,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh:jupyter_kill,aws_ec2_ssh:jupyter_kill,method,3,10,10,136,13.6,0,0,['self'],[None],[None],222,[],['aws_ec2_cmd_ssh'],1
utilmy/zarchive/util_aws.py:aws_ec2_ssh:jupyter_start,aws_ec2_ssh:jupyter_start,method,0,1,1,4,4.0,0,0,['self'],[None],[None],226,[],[],0
utilmy/zarchive/util_aws.py:aws_ec2_ssh:cmd2,aws_ec2_ssh:cmd2,method,2,5,5,63,12.6,0,0,"['self', 'cmd1']","[None, None]","[None, None]",229,[],['aws_ec2_cmd_ssh'],1
utilmy/zarchive/util_aws.py:aws_ec2_ssh:_help_ssh,aws_ec2_ssh:_help_ssh,method,18,29,29,132,4.55,0,1,['self'],[None],[None],232,[],[],0
utilmy/zarchive/util_min.py:os_wait_cpu,os_wait_cpu,function,12,31,27,286,9.23,1,0,"['priority', 'cpu_min']","[None, None]","['300', '50']",23,[],"['psutil.cpu_percent', 'print', 'arrow.utcnow', 'sleep']",4
utilmy/zarchive/util_min.py:isexist,isexist,function,3,11,10,58,5.27,0,0,['a'],[None],[None],48,[],['print'],1
utilmy/zarchive/util_min.py:isfloat,isfloat,function,5,15,13,67,4.47,0,1,['x'],[None],[None],54,[],['float'],1
utilmy/zarchive/util_min.py:isint,isint,function,6,14,13,80,5.71,0,1,"['x)', '( int', 'np.int8', 'np.int16', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, None, None, '']","[None, None, None, None, None, None, None]",61,[],['txt.find'],1
utilmy/zarchive/util_min.py:a_isanaconda,a_isanaconda,function,6,14,13,80,5.71,0,1,[],[],[],63,[],['txt.find'],1
utilmy/zarchive/util_min.py:os_zip_checkintegrity,os_zip_checkintegrity,function,9,33,31,185,5.61,0,1,['filezip1'],[None],[None],72,[],"['zipfile.ZipFile', 'zip_file.testzip', 'print']",3
utilmy/zarchive/util_min.py:os_zipfile,os_zipfile,function,23,43,37,397,9.23,2,2,"['folderin', 'folderzipname', 'iscompress']","[None, None, None]","[None, None, 'True']",83,[],"['zipfile.ZipFile', 'os.walk', 'zf.write', 'zf.close', 'os_zip_checkintegrity', 'print']",6
utilmy/zarchive/util_min.py:os_zipfolder,os_zipfolder,function,15,35,29,346,9.89,0,3,"['dir_tozip', 'zipname', 'dir_prefix', 'iscompress']","[None, None, None, None]","[""'/zdisks3/output'"", ""'/zdisk3/output.zip'"", 'None', 'True']",99,"["" '''\n"", "" shutil.make_archive('/zdisks3/results/output', 'zip',\n"", ""                     root_dir=/zdisks3/results/',\n"", ""                     base_dir='output')\n"", '\n', "" os_zipfolder('zdisk/test/aapackage', 'zdisk/test/aapackage.zip', 'zdisk/test')'''\n""]","['dir_tozip.split', 'shutil.make_archive', 'os_zip_checkintegrity', 'print']",4
utilmy/zarchive/util_min.py:os_zipextractall,os_zipextractall,function,23,59,48,538,9.12,1,3,"['filezip_or_dir', 'tofolderextract', 'isprint']","[None, None, None]","['""folder1/*.zip""', ""'zdisk/test'"", '1']",148,"[""   '''os_zipextractall( 'aapackage.zip','zdisk/test/'      )  '''\n""]","['filezip_or_dir.find', 'os_file_listall', 'os_file_getname', 'zipfile.ZipFile', 'zip_ref.extractall', 'zip_ref.close', 'print']",7
utilmy/zarchive/util_min.py:os_folder_copy,os_folder_copy,function,17,36,35,345,9.58,0,1,"['src', 'dst', 'symlinks', 'pattern1', 'fun_file_toignore']","[None, None, None, None, None]","[None, None, 'False', '""*.py""', 'None']",178,"[""   '''\n"", '       callable(src, names) -> ignored_names\n', ""       'src' parameter, which is the directory being visited by copytree(), and\n"", ""       'names' which is the list of `src` contents, as returned by os.listdir():\n"", '\n', '    Since copytree() is called recursively, the callable will be called once for each directory that is copied.\n', '    It returns a  list of names relative to the `src` directory that should not be copied.\n', ""   '''\n""]","['fun_file_toignore', 'fnmatch.filter', 'shutil.copytree', 'shutil.copy']",4
utilmy/zarchive/util_min.py:os_folder_create,os_folder_create,function,4,7,7,85,12.14,0,1,['directory'],[None],[None],200,[],"['os.getcwd', 'os.makedirs', 'os.chdir']",3
utilmy/zarchive/util_min.py:os_folder_robocopy,os_folder_robocopy,function,3,15,15,166,11.07,0,1,"['from_folder', 'to_folder', ""my_log='H""]","[None, None, '']","[""''"", ""''"", ""'H:/robocopy_log.txt'""]",205,"['    """"""\n', '    Copy files to working directory\n', '    robocopy <Source> <Destination> [<File>[ ...]] [<Options>]\n', '    We want to copy the files to a fast SSD drive\n', '    """"""\n']",['print'],1
utilmy/zarchive/util_min.py:os_file_replacestring1,os_file_replacestring1,function,11,25,24,238,9.52,1,0,"['findStr', 'repStr', 'filePath']","[None, None, None]","[None, None, None]",216,[],"['fileinput.FileInput', 'line.replace', 'file1.close', 'print']",4
utilmy/zarchive/util_min.py:os_file_replacestring2,os_file_replacestring2,function,6,14,13,161,11.5,1,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",227,"['  \'\'\' #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",    pattern=""*.html"", dirlevel=5  )\n', ""  '''\n""]","['os_file_listall', 'os_file_replacestring1']",2
utilmy/zarchive/util_min.py:os_file_getname,os_file_getname,function,8,9,8,75,8.33,0,0,['path'],[None],[None],234,[],"['ntpath.split', 'ntpath.basename']",2
utilmy/zarchive/util_min.py:os_file_getpath,os_file_getpath,function,7,7,7,52,7.43,0,0,['path'],[None],[None],239,[],['ntpath.split'],1
utilmy/zarchive/util_min.py:os_file_gettext,os_file_gettext,function,4,7,7,56,8.0,0,0,['file1'],[None],[None],244,[],"['open', 'f.read']",2
utilmy/zarchive/util_min.py:os_file_listall,os_file_listall,function,28,79,46,902,11.42,4,3,"['dir1', 'pattern', 'dirlevel', 'onlyfolder']","[None, None, None, None]","[None, '""*.*""', '1', '0']",250,"[""  '''\n"", '   # DIRCWD=r""D:\\_devs\\Python01\\project""\n', '   # aa= listallfile(DIRCWD, ""*.*"", 2)\n', '   # aa[0][30];   aa[2][30]\n', '\n', '   :param dir1:\n', '   :param pattern:\n', '   :param dirlevel:\n', '   :param onlyfolder:\n', '   :return:\n', ""  '''\n""]","['dir1.rstrip', 'dir1.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 'np.array']",7
utilmy/zarchive/util_min.py:os_file_rename,os_file_rename,function,32,56,48,642,11.46,2,1,"['some_dir', 'pattern', 'pattern2', 'dirlevel']","[None, None, None, None]","[None, '""*.*""', '""""', '1']",287,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 're.sub', 'os.rename', 'np.array']",9
utilmy/zarchive/util_min.py:os_print_tofile,os_print_tofile,function,1,2,2,7,3.5,0,0,"['vv', 'file1', ""mode1='a')"", 'mode1) as text_file']","[None, None, '', '  text_file.write(str(vv))) :']","[None, None, ""'a'):  # print into a file='afile1"", None]",309,"[""    '''\n"", '    Here is a list of the different modes of opening a file:\n', 'r\n', 'Opens a file for reading only. The file pointer is placed at the beginning of the file. This is the default mode.\n', '\n', 'rb\n', '\n', 'Opens a file for reading only in binary format. The file pointer is placed at the beginning of the file. This is the default mode.\n', 'r+\n', '\n', 'Opens a file for both reading and writing. The file pointer will be at the beginning of the file.\n', 'rb+\n', '\n', 'Opens a file for both reading and writing in binary format. The file pointer will be at the beginning of the file.\n', 'w\n', '\n', 'Opens a file for writing only. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'wb\n', '\n', 'Opens a file for writing only in binary format. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'w+\n', '\n', 'Opens a file for both writing and reading. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'wb+\n', '\n', 'Opens a file for both writing and reading in binary format. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'a\n', '\n', 'Opens a file for appending. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'ab\n', '\n', 'Opens a file for appending in binary format. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'a+\n', '\n', 'Opens a file for both appending and reading. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'ab+\n', '\n', 'Opens a file for both appending and reading in binary format. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'To open a text file, use:\n', 'fh = open(""hello.txt"", ""r"")\n', '\n', 'To read a text file, use:\n', 'print fh.read()\n', '\n', 'To read one line at a time, use:\n', 'print fh.readline()\n', '\n', 'To read a list of lines use:\n', 'print fh.readlines()\n', '\n', 'To write to a file, use:\n', 'fh = open(""hello.txt"", ""w"")\n', 'lines_of_text = [""a line of text"", ""another line of text"", ""a third line""]\n', 'fh.writelines(lines_of_text)\n', 'fh.close()\n', '\n', 'To append to file, use:\n', 'fh = open(""Hello.txt"", ""a"")\n', 'fh.close()\n', '\n', ""    '''\n""]",[],0
utilmy/zarchive/util_min.py:a_get_pythonversion,a_get_pythonversion,function,1,2,2,7,3.5,0,0,[],[],[],374,[],[],0
utilmy/zarchive/util_min.py:os_path_norm,os_path_norm,function,8,20,18,174,8.7,0,1,['pth)'],[' #Normalize path for Python directory)'],['=2:'],377,"['    \'\'\' #r""D:\\_devs\\Python01\\project\\03-Connect_Java_CPP_Excel\\PyBindGen\\examples"" \'\'\'\n']","['pth.find', 'b.lstrip']",2
utilmy/zarchive/util_min.py:os_path_change,os_path_change,function,4,4,4,34,8.5,0,0,['path1)'],[' path1'],[' os_path_norm(path1); os.chdir(path1)    #Change Working directory path): return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],389,[],"['open', 'fh.read']",2
utilmy/zarchive/util_min.py:os_path_current,os_path_current,function,4,4,4,34,8.5,0,0,[')'],[' return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],391,[],"['open', 'fh.read']",2
utilmy/zarchive/util_min.py:os_file_exist,os_file_exist,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],393,[],"['open', 'fh.read']",2
utilmy/zarchive/util_min.py:os_file_size,os_file_size,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.getsize(file1)file1):'],[None],395,[],"['open', 'fh.read']",2
utilmy/zarchive/util_min.py:os_file_read,os_file_read,function,4,4,4,34,8.5,0,0,['file1'],[None],[None],397,[],"['open', 'fh.read']",2
utilmy/zarchive/util_min.py:os_file_mergeall,os_file_mergeall,function,10,20,20,185,9.25,1,0,"['nfile', 'dir1', 'pattern1', 'deepness']","[None, None, None, None]","[None, None, None, '2']",401,[],"['os_file_listall', 'open', 'os_file_gettext', 'nfile1.write', 'nfile1.close']",5
utilmy/zarchive/util_min.py:os_path_append,os_path_append,function,4,19,11,121,6.37,0,3,"['p1', 'p2', 'p3', 'p4']","[None, None, None, None]","[None, 'None', 'None', 'None']",412,[],[],0
utilmy/zarchive/util_min.py:os_split_dir_file,os_split_dir_file,function,6,15,15,112,7.47,0,1,['dirfile'],[None],[None],421,[],"['dirfile.split', 'len']",2
utilmy/zarchive/util_min.py:py_importfromfile,py_importfromfile,function,12,21,19,251,11.95,0,1,"['modulename', 'dir1']","[None, None]","[None, None]",430,[],"['a_get_pythonversion', 'SourceFileLoader', 'foo.MyClass', 'imp.load_source']",4
utilmy/zarchive/util_min.py:py_memorysize,py_memorysize,function,16,56,38,320,5.71,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",442,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'o.iteritems']",7
utilmy/zarchive/util_min.py:save,save,function,2,4,4,64,16.0,0,0,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",470,[],['py_save_obj'],1
utilmy/zarchive/util_min.py:load,load,function,2,3,3,60,20.0,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",473,[],['py_load_obj'],1
utilmy/zarchive/util_min.py:save_test,save_test,function,6,11,11,124,11.27,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",476,[],"['py_load_obj', 'print', 'str', 'gc.collect']",4
utilmy/zarchive/util_min.py:py_save_obj,py_save_obj,function,17,36,35,308,8.56,0,1,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",482,[],"['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.dump']",5
utilmy/zarchive/util_min.py:py_load_obj,py_load_obj,function,16,30,28,265,8.83,0,1,"['folder', 'isabsolutpath', 'encoding1']","[None, None, None]","[""'/folder1/keyname'"", '0', ""'utf-8'""]",495,"[""    '''def load_obj(name, encoding1='utf-8' ):\n"", ""         with open('D:/_devs/Python01/aaserialize/' + name + '.pkl', 'rb') as f:\n"", '            return pickle.load(f, encoding=encoding1)\n', ""    '''\n""]","['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.load']",5
utilmy/zarchive/util_min.py:z_key_splitinto_dir_name,z_key_splitinto_dir_name,function,6,15,15,112,7.47,0,1,['keyname'],[None],[None],511,[],"['keyname.split', 'len']",2
utilmy/zarchive/util_ml.py:create_weight_variable,create_weight_variable,function,5,7,6,129,18.43,0,0,"['name', 'shape']","[None, None]","[None, None]",27,[],['tf.Variable'],1
utilmy/zarchive/util_ml.py:create_bias_variable,create_bias_variable,function,4,6,6,112,18.67,0,0,"['name', 'shape']","[None, None]","[None, None]",33,[],"['tf.constant_initializer', 'tf.Variable']",2
utilmy/zarchive/util_ml.py:create_adam_optimizer,create_adam_optimizer,function,2,3,3,70,23.33,0,0,"['learning_rate', 'momentum']","[None, None]","[None, None]",38,[],[],0
utilmy/zarchive/util_ml.py:tf_check,tf_check,function,32,91,51,915,10.05,0,0,[],[],[],44,[],"['print', 'tf.constant', 'tf.matmul', 'tf.Session', 'sess.run']",5
utilmy/zarchive/util_ml.py:parse_args,parse_args,function,11,26,24,196,7.54,1,1,"['ppa', 'args']","[None, None]","['None', ' {}']",75,[],"['argparse.ArgumentParser', 'args.items', 'ppa.add_argument', 'type=type', 'ppa.parse_args', 'parse_args2']",6
utilmy/zarchive/util_ml.py:parse_args2,parse_args2,function,5,133,98,1435,10.79,0,1,['ppa'],[None],['None'],86,[],"['argparse.ArgumentParser', 'e:print', 'ppa.add_argument']",3
utilmy/zarchive/util_ml.py:tf_global_variables_initializer,tf_global_variables_initializer,function,27,65,46,866,13.32,3,1,['sess'],[None],['None'],124,"['    """"""Initializes all uninitialized variables in correct order. Initializers\n', ""    are only run for uninitialized variables, so it's safe to run this multiple times.\n"", '    Args:   sess: session to use. Use default session if None.\n', '    """"""\n']","['make_initializer', 'f', 'tf.assign', 'make_noop', 'tf.no_op', 'make_safe_initializer', 'tf.cond', 'tf.get_default_session', 'tf.get_default_graph', 'tf.global_variables', 'g.get_operation_by_name', 'sess.run']",12
utilmy/zarchive/util_ml.py:visualize_result,visualize_result,function,21,142,111,1132,7.97,2,0,[],[],[],234,[],"['range', 'enumerate', 'pd.read_csv', 'plt.plot', 'train_loss.tolist', 'plt.legend', 'plt.xlabel', 'plt.ylabel', 'plt.show']",9
utilmy/zarchive/util_ml.py:TextLoader,TextLoader,class,65,159,120,2143,13.48,0,1,[],[],[],167,[],[],0
utilmy/zarchive/util_ml.py:TextLoader:__init__,TextLoader:__init__,method,15,34,31,491,14.44,0,1,"['self', 'data_dir', 'batch_size', 'seq_length']","[None, None, None, None]","[None, None, None, None]",168,[],"['print', 'self.preprocess', 'self.load_preprocessed', 'self.create_batches', 'self.reset_batch_pointer']",5
utilmy/zarchive/util_ml.py:TextLoader:preprocess,TextLoader:preprocess,method,17,34,31,404,11.88,0,0,"['self', 'input_file', 'vocab_file', 'tensor_file']","[None, None, None, None]","[None, None, None, None]",186,[],"['codecs.open', 'f.read', 'collections.Counter', 'sorted', 'list', 'len', 'dict', 'range', 'open', 'pickle.dump', 'np.array', 'np.save']",12
utilmy/zarchive/util_ml.py:TextLoader:load_preprocessed,TextLoader:load_preprocessed,method,10,19,19,245,12.89,0,0,"['self', 'vocab_file', 'tensor_file']","[None, None, None]","[None, None, None]",199,[],"['open', 'pickle.load', 'len', 'dict', 'range', 'np.load']",6
utilmy/zarchive/util_ml.py:TextLoader:create_batches,TextLoader:create_batches,method,20,40,33,665,16.62,0,0,['self'],[None],[None],207,[],"['np.copy', 'np.split', 'int', 'zip']",4
utilmy/zarchive/util_ml.py:TextLoader:next_batch,TextLoader:next_batch,method,6,10,8,87,8.7,0,0,['self'],[None],[None],223,[],[],0
utilmy/zarchive/util_ml.py:TextLoader:reset_batch_pointer,TextLoader:reset_batch_pointer,method,1,2,2,14,7.0,0,0,['self'],[None],[None],228,[],[],0
utilmy/zarchive/util_sql.py:sql_create_dbengine,sql_create_dbengine,function,4,45,26,358,7.96,0,1,"['type1', 'dbname', 'login', 'password', 'url', 'port']","[None, None, None, None, None, None]","[""''"", ""''"", ""''"", ""''"", ""'localhost'"", '5432']",43,"[""   ''' Return SQL Alchemy Connector\n"", '\n', '# psycopg2\n', ""engine = create_engine('postgresql+psycopg2://scott:tiger@localhost/mydatabase')\n"", '\n', '# MySQL-connector-python  Official one\n', ""engine = create_engine('mysql+mysqlconnector://scott:tiger@localhost/foo')\n"", 'conda install -c anaconda mysql-connector-python=2.0.4\n', ""engine = create_engine('postgresql://%s:%s@localhost:5432/%s' %(myusername, mypassword, mydatabase))\n"", '\n', ""engine = create_engine('sqlite:///  folder/foo.db')\n"", '\n', ""   '''\n""]","['sql.create_engine', 'str']",2
utilmy/zarchive/util_sql.py:sql_query,sql_query,function,6,22,18,155,7.05,0,2,"['sqlr', 'dbengine', 'output', ""dburl='sqlite""]","[None, None, None, '']","[""'SELECT ticker,shortratio,sector1_id, FROM stockfundamental'"", 'None', ""'df'"", ""'sqlite:///aaserialize/store/finviz.db'""]",69,"["" '''\n"", "" :param sqlr:       'SELECT ticker,shortratio,sector1_id, FROM stockfundamental'\n"", ' :param output:     df   /   file1.csv\n', "" :param dburl:      'sqlite:///aaserialize/store/finviz.db'\n"", "" :param dbengine:   dbengine = sql.create_engine('postgresql+psycopg2://postgres:postgres@localhost/coke')\n"", ' :return:\n', "" '''\n""]","['sql.create_engine', 'pd.read_sql_query', 'output.find', 'df.to_csv']",4
utilmy/zarchive/util_sql.py:sql_get_dbschema,sql_get_dbschema,function,16,37,32,318,8.59,2,2,"[""dburl='sqlite"", 'dbengine', 'isprint']","['', None, None]","[""'sqlite:///aapackage/store/yahoo.db'"", 'None', '0']",83,[],"['sql.create_engine', 'sql.inspect', 'inspector.get_table_names', 'inspector.get_columns', 'l1.append', 'print', 'np.array']",7
utilmy/zarchive/util_sql.py:sql_delete_table,sql_delete_table,function,1,8,8,89,11.12,0,0,"['name', 'dbengine']","[None, None]","[None, None]",96,[],[],0
utilmy/zarchive/util_sql.py:sql_insert_excel,sql_insert_excel,function,50,131,97,992,7.57,5,2,"['file1', 'dbengine', 'dbtype']","[None, None, None]","[""'.xls'"", 'None', ""''""]",103,"["" ''' http://flask-excel.readthedocs.io/en/latest/\n"", ' https://pythonhosted.org/pyexcel/tutorial_data_conversion.html#import-excel-sheet-into-a-database-table\n', ' from sqlalchemy import create_engine\n', 'from sqlalchemy.ext.declarative import declarative_base\n', 'from sqlalchemy import Column , Integer, String, Float, Date\n', 'from sqlalchemy.orm import sessionmaker\n', 'engine = create_engine(""sqlite:///birth.db"")\n', 'Base = declarative_base()\n', 'Session = sessionmaker(bind=engine)\n', '\n', 'class BirthRegister(Base):\n', ""...     __tablename__='birth'\n"", '...     id=Column(Integer, primary_key=True)\n', '...     name=Column(String)\n', '...     weight=Column(Float)\n', '...     birth=Column(Date)\n', '\n', 'Base.metadata.create_all(engine)\n', '\n', 'https://www.digitalocean.com/community/tutorials/how-to-use-celery-with-rabbitmq-to-queue-tasks-on-an-ubuntu-vps\n', 'import os\n', 'import pyexcel\n', 'import datetime\n', '\n', 'from sqlalchemy import create_engine\n', 'from sqlalchemy.ext.declarative import declarative_base\n', 'from sqlalchemy import Column, Integer, String, Float, Date\n', 'from sqlalchemy.orm import sessionmaker\n', '\n', '\n', 'engine = create_engine(""sqlite:///birth.db"")\n', 'Base = declarative_base()\n', 'Session = sessionmaker(bind=engine)\n', '\n', '\n', '# here is the destination table\n', 'class BirthRegister(Base):\n', ""    __tablename__ = 'birth'\n"", '    id = Column(Integer, primary_key=True)\n', '    name = Column(String)\n', '    weight = Column(Float)\n', '    birth = Column(Date)\n', '\n', '\n', 'Base.metadata.create_all(engine)\n', '\n', '\n', '# create fixture\n', 'data = [\n', '    [""name"", ""weight"", ""birth""],\n', '    [""Adam"", 3.4, datetime.date(2015, 2, 3)],\n', '    [""Smith"", 4.2, datetime.date(2014, 11, 12)]\n', ']\n', 'pyexcel.save_as(array=data,\n', '                dest_file_name=""birth.xls"")\n', '\n', '# import the xls file\n', 'session = Session()  # obtain a sql session\n', 'pyexcel.save_as(file_name=""birth.xls"",\n', '                name_columns_by_row=0,\n', '                dest_session=session,\n', '                dest_table=BirthRegister)\n', '\n', '# verify results\n', 'sheet = pyexcel.get_sheet(session=session, table=BirthRegister)\n', 'print(sheet)\n', '\n', 'session.close()\n', ""os.unlink('birth.db')\n"", 'os.unlink(""birth.xls"")\n', '\n', ' This code uses the openpyxl package for playing around with excel using Python code\n', ' to convert complete excel workbook (all sheets) to an SQLite database\n', ' The code assumes that the first row of every sheet is the column name\n', ' Every sheet is stored in a separate table\n', ' The sheet name is assigned as the table name for every sheet\n', "" '''\n""]","['slugify', 'text.strip', 're.sub', 'load_workbook', 'wb.get_sheet_names', 'str', 'columns.append', 'dbengine.execute', 'enumerate', 'tuprow.append', 'tup.append', 'VALUES', 'dbengine.executemany', 'dbengine.commit', 'dbengine.close']",15
utilmy/zarchive/util_sql.py:sql_insert_df,sql_insert_df,function,22,59,51,481,8.15,1,2,"['df', 'dbtable', 'dbengine', 'col_drop', 'verbose']","[None, None, None, None, None]","[None, None, None, ""['id']"", '1']",226,[],"['df.drop', 'df.to_dict', 'print', 'sql.Table', 'Session', 'dbengine.execute', 'session.commit', 'session.close']",8
utilmy/zarchive/util_sql.py:sql_insert_csv,sql_insert_csv,function,35,159,130,1364,8.58,3,3,"['csvfile', 'dbtable', 'dbengine', 'col_drop']","[None, None, None, None]","[None, None, None, '[]']",256,[],"['datetime.now', 'pd.read_csv', 'df.rename', 'c.replace', 'df.drop', 'df.to_dict', 'sql.Table', 'Session', 'dbengine.execute', 'session.commit', 'session.close', 'print', 'sql_insert_csv2', 'os.listdir', 'i.endswith', 'i.startswith', 'df.to_sql']",17
utilmy/zarchive/util_sql.py:sql_insert_csv2,sql_insert_csv2,function,11,58,54,469,8.09,1,2,"['csvfile', 'dbtable', 'columns', 'dbengine', 'nrows']","[None, None, None, None, None]","[""''"", ""''"", '[]', 'None', ' 10000']",328,"['    """"""\n', '    Upload data to a temporary table first using PANDAs to identify optimal data-types for columns\n', '    PANDAS is not speed-efficient as it uses INSERT commands rather than COPY e.g. it took COPY 16mins average\n', '    to get a 15GB CSV into the database (door-to-door) whereas pandas.to_sql took 50mins\n', '    """"""\n']","['os.listdir', 'i.endswith', 'i.startswith', 'print', 'pd.read_csv', 'df.to_sql']",6
utilmy/zarchive/util_sql.py:sql_postgres_create_table,sql_postgres_create_table,function,20,108,73,890,8.24,0,3,"['mytable', 'database', 'username', 'password']","[None, None, None, None]","[""''"", ""''"", ""''"", ""''""]",361,"['    """""" Create table copying the structure of the temp table created using pandas  Timer to benchmark """"""\n']","['psycopg2.connect', 'con.cursor', 'print', 'sys.exit', 'cur.execute', 'open', 'cur.copy_expert', 'con.close']",8
utilmy/zarchive/util_sql.py:sql_postgres_pivot,sql_postgres_pivot,function,0,1,1,4,4.0,0,0,[],[],[],447,"[""   '''\n"", 'Enabling the Crosstab Function\n', 'As we previously mentioned, the crosstab function is part of a PostgreSQL extension called tablefunc. To call the crosstab function,\n', 'you must first enable the tablefunc extension by executing the following SQL command:\n', 'CREATE extension tablefunc;\n', '\n', 'SELECT *\n', ""FROM crosstab( 'select student, subject, evaluation_result from evaluations order by 1,2')\n"", 'AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '\n', '##### Correct Even iF there are missing values :\n', 'http://www.vertabelo.com/blog/technical-articles/creating-pivot-tables-in-postgresql-using-the-crosstab-function\n', '\n', 'SELECT *\n', ""FROM crosstab( 'select student, subject, evaluation_result from evaluations\n"", ""                where extract (month from evaluation_day) = 7 order by 1,2',\n"", ""                'select name from subject order by 1')\n"", '     AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/util_sql.py:sql_mysql_insert_excel,sql_mysql_insert_excel,function,30,73,69,712,9.75,1,0,[],[],[],473,[],"['xlrd.open_workbook', 'list.sheet_by_index', 'database.cursor', 'range', 'sheet.cell', 'cursor.execute', 'cursor.close', 'database.commit', 'database.close', 'print', 'str', 'rows=str']",12
utilmy/zarchive/util_sql.py:sql_pivotable,sql_pivotable,function,1,3,3,10,3.33,0,0,"['dbcon', 'ss']","[None, None]","[None, ""'select  '""]",506,"[""  '''\n"", '\n', ' 1) get the category\n', '\n', ' 2) Build the Pivot From category\n', '  SELECT *\n', ""  FROM crosstab( 'select student, subject, evaluation_result from evaluations\n"", ""                where extract (month from evaluation_day) = 7 order by 1,2',\n"", ""                'select name from subject order by 1')\n"", '   AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '  https://www.amazon.com/PostgreSQL-High-Performance-Gregory-Smith/dp/184951030X/ref=as_li_ss_tl?s=books&ie=UTF8&qid=1458352081&sr=1-6&keywords=postgres&linkCode=sl1&tag=postgres-bottom-20&linkId=c981783121cbd5542dc2b44a2297df57\n', '\n', '\n', 'http://blog.brakmic.com/data-science-for-losers-part-2/\n', '\n', 'Here we instruct Pandas to merge two tables by using certain primary keys from both when combining their rows into a new table. The parameter how instructs Pandas to use the inner-join which means it will only combine such rows which belong to both of the tables. Therefore well not receive any NaN-rows. But in some cases this could be desirable. Then use the alternative options like left, right or outer.\n', '\n', 'Pivots with Tables from SQLAlchemy\n', '\n', 'And of course its possible to generate the same pivot tables with data that came from SQLAlchemy.\n', 'Theyre nothing else but DataFrames all the way down. OK, not absolutely all the way down,\n', 'because there are also Series and NumPy arrays etc.,\n', 'but this is a little bit too much of knowledge for Losers like us. Maybe in some later articles.\n', '\n', '\n', ' :return:\n', ""  '''\n""]",[],0
utilmy/zarchive/util_web.py:web_restapi_toresp,web_restapi_toresp,function,12,19,18,168,8.84,0,1,['apiurl1'],[None],[None],59,[],"['requests.get', 'ApiError']",2
utilmy/zarchive/util_web.py:web_getrawhtml,web_getrawhtml,function,13,20,20,176,8.8,0,1,['url1'],[None],[None],66,[],"['requests.get', 'ApiError']",2
utilmy/zarchive/util_web.py:web_importio_todataframe,web_importio_todataframe,function,41,77,59,641,8.32,4,4,"['apiurl1', 'isurl']","[None, None]","[None, '1']",74,[],"['requests.get', 'ApiError', 'resp.json', 'list', 'colname.append', 'str', 'np.array', 'colmax=len', 'np.empty', 'pd_createdf', 'np.arange', 'len']",12
utilmy/zarchive/util_web.py:web_getjson_fromurl,web_getjson_fromurl,function,10,11,10,138,12.55,0,0,['url'],[None],[None],101,[],"['urllib3.connection_from_url', 'http.urlopen', 'print', 'json.loads']",4
utilmy/zarchive/util_web.py:web_gettext_fromurl,web_gettext_fromurl,function,9,18,17,203,11.28,0,0,"['url', 'htmltag']","[None, None]","[None, ""'p'""]",116,[],"['urllib3.connection_from_url', 'http.urlopen', 'BeautifulSoup', 'soup.find_all']",4
utilmy/zarchive/util_web.py:web_gettext_fromhtml,web_gettext_fromhtml,function,8,20,19,176,8.8,0,0,"['file1', 'htmltag']","[None, None]","[None, ""'p'""]",124,[],"['open', 'BeautifulSoup', 'soup.find_all']",3
utilmy/zarchive/util_web.py:web_getlink_fromurl,web_getlink_fromurl,function,14,20,20,248,12.4,1,0,['url'],[None],[None],183,[],"['urllib3.connection_from_url', 'http.urlopen', 'BeautifulSoup', 'soup.prettify', 'soup.findAll', 'links.append', 'set']",7
utilmy/zarchive/util_web.py:web_send_email,web_send_email,function,33,126,77,1266,10.05,0,0,"['FROM', 'recipient', 'subject', 'body', 'login1', 'pss1', 'server1', 'port1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, '""mizenjapan@gmail.com""', '""sophieelise237""', '""smtp.gmail.com""', '465']",195,"['    \'\'\'  # send_email(""Kevin"", ""brookm291@gmail.com"", ""JapaneseText:"" , ""txt"") \'\'\'\n']","['MIMEMultipart', 'msg.set_charset', 'MIMEText', 'msg.attach', 'smtplib.SMTP_SSL', 'server_ssl.ehlo', 'login', 'server_ssl.login', 'server_ssl.sendmail', 'msg.as_string', 'server_ssl.close', 'print', 'web_send_email_tls', 'smtplib.SMTP', 'mailserver.ehlo', 'mailserver.starttls', 'mailserver.login', 'mailserver.sendmail', 'mailserver.quit']",19
utilmy/zarchive/util_web.py:web_send_email_tls,web_send_email_tls,function,25,56,51,568,10.14,0,0,"['FROM', 'recipient', 'subject', 'body', 'login1', 'pss1', 'server1', 'port1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, '""mizenjapan@gmail.com""', '""sophieelise237""', '""smtp.gmail.com""', '465']",220,[],"['MIMEMultipart', 'msg.set_charset', 'MIMEText', 'msg.attach', 'smtplib.SMTP', 'mailserver.ehlo', 'mailserver.starttls', 'mailserver.login', 'mailserver.sendmail', 'msg.as_string', 'mailserver.quit', 'print']",12
utilmy/zarchive/util_web.py:web_sendurl,web_sendurl,function,3,10,10,95,9.5,0,0,['url1'],[None],[None],256,[],"['web_gettext_fromurl', 'send_email']",2
utilmy/zarchive/_HELP.py:os_compileVSsolution,os_compileVSsolution,function,6,32,21,239,7.47,0,4,"['dir1', 'flags1', 'type1', 'compilerdir']","[None, None, None, None]","[None, '""""', '""devenv""', '""""']",744,[],['os.system'],1
utilmy/zarchive/_HELP.py:os_VS_build,os_VS_build,function,16,62,54,614,9.9,1,2,"['self', 'lib_to_build']","[None, None]","[None, None]",773,[],"['print', 'subprocess.Popen', 'process.poll', 'process.communicate']",4
utilmy/zarchive/_HELP.py:set_rc_version,set_rc_version,function,12,37,34,502,13.57,0,0,"['rcfile', 'target_version']","[None, None]","[None, None]",810,[],"['open', 'f.seek', 'f.write', 'f.truncate']",4
utilmy/zarchive/_HELP.py:os_VS_start,os_VS_start,function,18,56,52,881,15.73,0,2,"['self', 'version']","[None, None]","[None, None]",847,[],"['os.getenv', 'Exception', 'default.append', 'libs.append']",4
utilmy/zarchive/_HELP.py:fun_cython,fun_cython,function,5,10,9,34,3.4,1,0,['a'],[None],[None],890,[],['xrange'],1
utilmy/zarchive/_HELP.py:fun_python,fun_python,function,5,10,9,34,3.4,1,0,['a'],[None],[None],897,[],['xrange'],1
utilmy/zarchive/_HELP.py:LookupTable,LookupTable,class,4,7,7,94,13.43,0,0,[],[],[],207,[],[],0
utilmy/zarchive/py2to3/allmodule.py:pprint,pprint,function,10,32,23,378,11.81,0,1,"['table1', 'tablefmt']","[None, None]","[None, '""simple""']",34,"[' """"""To print nice column headers, supply the second argument (`headers`):\n', '      - `headers` can be an explicit list of column headers\n', '      - if `headers=""firstrow""`, then the first row of data is used\n', '      - if `headers=""keys""`, then dictionary keys or column indices are used\n', '    print(tabulate([[1, 2.34], [-56, ""8.999""], [""2"", ""10001""]]))\n', '  """"""\n']","['isinstance', 'tabulate', 'pprint2', 'pprint.PrettyPrinter', 'pp.pprint']",5
utilmy/zarchive/py2to3/allmodule.py:pprint2,pprint2,function,5,5,5,59,11.8,0,0,['x'],[None],[None],51,"[""  '''import pprint\n"", ""     stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']\n"", 'stuff.insert(0, stuff[:])\n', 'pp = pprint.PrettyPrinter(indent=4)\n', 'pp.pprint(ALLDB)\n', ""  '''\n""]","['pprint.PrettyPrinter', 'pp.pprint']",2
utilmy/zarchive/py2to3/allmodule.py:str_convert_beforeprint,str_convert_beforeprint,function,2,2,2,23,11.5,0,0,['x'],[None],[None],64,"[""  ''' #Before writing/output to printer put in utf-8 '''\n""]",['x.encode'],1
utilmy/zarchive/py2to3/allmodule.py:str_to_utf8,str_to_utf8,function,2,2,2,23,11.5,0,0,['x'],[None],[None],69,"[""  ''' #Before writing/output to printer put in utf-8 '''\n""]",['x.encode'],1
utilmy/zarchive/py2to3/allmodule.py:str_to_unicode,str_to_unicode,function,4,16,12,98,6.12,0,2,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",74,"[""  ''' #After Loading Text from CSV ---> Immediately in unicode '''\n""]","['isinstance', 'unicode']",2
utilmy/zarchive/py2to3/coke_functions.py:date_diffsecond,date_diffsecond,function,4,8,7,71,8.88,0,0,"['str_t1', 'str_t0', ""fmt='YYYY-MM-DD HH""]","[None, None, '']","[None, None, ""'YYYY-MM-DD HH:mm:SS'""]",8,[],"['arrow.get', 'dd.total_seconds']",2
utilmy/zarchive/py2to3/coke_functions.py:date_diffstart,date_diffstart,function,4,9,8,31,3.44,1,0,"['t) ', 'str_t0=t0)t) ', 'str_t0=t)dd) ']","[' return date_diffsecond(str_t1', '', '']","['t', 't0)t) :   return date_diffsecond(str_t1=t1', 't)dd) :']",13,[],['dd.items'],1
utilmy/zarchive/py2to3/coke_functions.py:date_diffend,date_diffend,function,4,9,8,31,3.44,1,0,"['t) ', 'str_t0=t)dd) ']","['   return date_diffsecond(str_t1', '']","['t1', 't)dd) :']",14,[],['dd.items'],1
utilmy/zarchive/py2to3/coke_functions.py:np_dict_tolist,np_dict_tolist,function,4,9,8,31,3.44,1,0,['dd'],[None],[None],17,[],['dd.items'],1
utilmy/zarchive/py2to3/coke_functions.py:np_dict_tostr_val,np_dict_tostr_val,function,1,9,9,46,5.11,0,0,['dd'],[None],[None],20,[],"['str', 'dd.items']",2
utilmy/zarchive/py2to3/coke_functions.py:np_dict_tostr_key,np_dict_tostr_key,function,1,8,8,46,5.75,0,0,['dd'],[None],[None],23,[],"['str', 'dd.items']",2
utilmy/zarchive/py2to3/coke_functions.py:day,day,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['    return int(s[8:10])s):  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",31,[],['arrow.get'],1
utilmy/zarchive/py2to3/coke_functions.py:month,month,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",32,[],['arrow.get'],1
utilmy/zarchive/py2to3/coke_functions.py:year,year,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['   return int(s[0:4])s):   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",33,[],['arrow.get'],1
utilmy/zarchive/py2to3/coke_functions.py:hour,hour,function,9,16,15,117,7.31,0,0,"['s)', 'fmt', 'i0', 'i1=10)']","['   return int(s[11:13])cache_weekday', None, None, '']","[' {}s', ""'YYYY-MM-DD'"", '0', '10):']",34,[],['arrow.get'],1
utilmy/zarchive/py2to3/coke_functions.py:weekday,weekday,function,9,16,15,117,7.31,0,0,"['s', 'fmt', 'i0', 'i1']","[None, None, None, None]","[None, ""'YYYY-MM-DD'"", '0', '10']",38,[],['arrow.get'],1
utilmy/zarchive/py2to3/coke_functions.py:season,season,function,4,15,13,47,3.13,0,1,['d'],[None],[None],48,[],['int'],1
utilmy/zarchive/py2to3/coke_functions.py:daytime,daytime,function,7,42,23,123,2.93,0,1,['d'],[None],[None],53,[],['int'],1
utilmy/zarchive/py2to3/coke_functions.py:pd_date_splitall,pd_date_splitall,function,11,22,17,255,11.59,0,0,"['df', 'coldate']","[None, None]","[None, ""'purchased_at'""]",62,[],['copy.deepcopy'],1
utilmy/zarchive/py2to3/datanalysis.py:pd_filter_column,pd_filter_column,function,12,25,22,218,8.72,1,2,"['df_client_product', 'filter_val', 'iscol']","[None, None, None]","[None, '[]', '1']",52,"[""   '''\n"", '   # Remove Columns where Index Value is not in the filter_value\n', ""   # filter1= X_client['client_id'].values\n"", '   :param df_client_product:\n', '   :param filter_val:\n', '   :param iscol:\n', '   :return:\n', ""   '''\n""]",['col_delete1.append'],1
utilmy/zarchive/py2to3/datanalysis.py:pd_missing_show,pd_missing_show,function,0,1,1,4,4.0,0,0,[],[],[],69,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:pd_validation_struct,pd_validation_struct,function,0,1,1,4,4.0,0,0,[],[],[],98,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:pd_checkpoint,pd_checkpoint,function,0,1,1,4,4.0,0,0,[],[],[],108,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:xl_setstyle,xl_setstyle,function,32,63,47,610,9.68,2,0,['file1'],[None],[None],167,"["" '''\n"", '   http://openpyxl.readthedocs.io/en/default/styles.html#cell-styles-and-named-styles\n', '  import openpyxl.styles.builtins  as bi\n', '  import openpyxl.styles.builtins\n', '\n', ""  col = ws.column_dimensions['A']\n"", '  col.font = Font(bold=True)\n', '\n', ""  for cell in ws['A'] + ws[1]:\n"", ""    cell.style = 'data01'\n"", '\n', '  bd = Side(style=\'thick\', color=""000000"")\n', '  highlight.border = BORDER_NONE\n', '  from openpyxl.styles import\n', "" '''\n""]","['load_workbook', 'print', 'named_styles.NamedStyle', 'Font', 'wb.get_sheet_names', 'wb.get_sheet_by_name', 'xrange', 'wb.save']",8
utilmy/zarchive/py2to3/datanalysis.py:xl_val,xl_val,function,7,14,13,107,7.64,0,0,"['ws', 'colj', 'rowi']","[None, None, None]","[None, None, None]",207,[],"['ws[gcol', 'str']",2
utilmy/zarchive/py2to3/datanalysis.py:isnull,isnull,function,3,5,5,20,4.0,0,0,['x'],[None],[None],214,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:xl_get_rowcol,xl_get_rowcol,function,8,44,37,222,5.05,1,1,"['ws', 'i0', 'j0', 'imax', 'jmax']","[None, None, None, None, None]","[None, None, None, None, None]",217,[],"['xrange', 'isnull', 'rmat.append']",3
utilmy/zarchive/py2to3/datanalysis.py:pd_stack_dflist,pd_stack_dflist,function,8,29,24,155,5.34,1,1,['df_list'],[None],[None],227,[],"['enumerate', 'df0.append', 'print']",3
utilmy/zarchive/py2to3/datanalysis.py:xl_getschema,xl_getschema,function,73,258,174,1953,7.57,4,8,"['dirxl', 'filepattern', 'dirlevel', 'outfile']","[None, None, None, None]","['""""', ""'*.xlsx'"", '1', ""'.xlsx'""]",237,"["" '''Take All excel in a folder and provide Table, Column Schema, type into master file\n"", "" '''\n""]","['xl_is_data_block_start', 'isnull', 'xl_find_start_block', 'xrange', '_xl_getschema', 'util.os_file_getname', 'load_workbook', 'print', 'wb.get_sheet_names', 'wb.get_sheet_by_name', 'gcol', 'str', 'np.array', 'unicode', 'np.column_stack', 'df_list.append', 'pd_stack_dflist', 'util.os_file_listall', 'enumerate', 'df0.append', 'util.pd_toexcel']",21
utilmy/zarchive/py2to3/datanalysis.py:str_to_unicode,str_to_unicode,function,4,16,12,99,6.19,0,2,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",318,[],"['isinstance', 'unicode']",2
utilmy/zarchive/py2to3/datanalysis.py:csv_dtypes_getdict,csv_dtypes_getdict,function,6,20,16,122,6.1,0,1,"['df', 'csvfile']","[None, None]","['None', 'None']",327,[],['pd.read_csv'],1
utilmy/zarchive/py2to3/datanalysis.py:csv_fast_processing,csv_fast_processing,function,0,0,0,0,0.0,0,0,[],[],[],334,"[""   '''\n"", '   http://word.bitly.com/post/74069870671/optimizing-text-processing\n', '\n', 'import sys\n', 'from collections import defaultdict\n', 'OUT_FILES = defaultdict(dict)\n', '\n', 'open_outfiles()  # open all files I could possibly need\n', '\n', 'for line in sys.stdin:\n', '    # 1. parse line for account_id and metric_type\n', ""    key = line.split(',')\n"", '    account_id = key[ACCOUNT_ID_INDEX][1:] # strip leading quote\n', '\n', '    # 2. write to appropriate file for account_id and metric_type\n', '    OUT_FILES[account_id][key[METRIC_TYPE_INDEX]].write(line)\n', '\n', '   close_outfiles()  # close all the files we opened\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/py2to3/datanalysis.py:csv_col_schema_toexcel,csv_col_schema_toexcel,function,87,292,206,2613,8.95,3,8,"['dircsv', 'filepattern', 'outfile', 'returntable', 'maxrow', 'maxcol_pertable', 'maxstrlen']","[None, None, None, None, None, None, None]","['""""', ""'*.csv'"", ""'.xlsx'"", '1', '5000000', '90', ""'U80'""]",356,"["" '''Take All csv in a folder and provide Table, Column Schema, type\n"", ' str(df[col].dtype)  USE str always, otherwise BIG Issue\n', '\n', 'METHOD FOR Unicode / ASCII issue\n', ""1. Decode early:  Decode to <type 'unicode'> ASAP\n"", ""    df['PREF_NAME']=       df['PREF_NAME'].apply(to_unicode)\n"", '2. Unicode everywhere\n', ""3. Encode late :f = open('/tmp/ivan_out.txt','w')\n"", ""                f.write(ivan_uni.encode('utf-8'))\n"", "" '''\n""]","['util.os_file_listall', 'len', 'np.array', 'enumerate', 'pd.read_csv', 'str', 'util.pd_toexcel', 'df.apply', 'np.zeros', 'xrange', 'float', 'gc.collect', 'pd.DataFrame', 'util.save', 'outfile.replace', 'print']",16
utilmy/zarchive/py2to3/datanalysis.py:csv_col_get_dict_categoryfreq,csv_col_get_dict_categoryfreq,function,39,81,63,551,6.8,4,4,"['dircsv', 'filepattern', 'category_cols', 'maxline', 'fileencoding']","[None, None, None, None, None]","[None, '""*.csv""', '[]', '-1', '""utf-8""']",447,"[""  ''' Find Category Freq in large CSV Transaction Column   '''\n""]","['datetime.now', 'defaultdict', 'util.os_file_listall', 'enumerate', 'line.split']",5
utilmy/zarchive/py2to3/datanalysis.py:csv_row_reduce_line,csv_row_reduce_line,function,23,82,62,474,5.78,1,5,"['fromfile', 'tofile', 'condfilter', 'catval_tokeep', 'maxline']","[None, None, None, None, None]","[None, None, None, None, '-1']",472,"[""  ''' Reduce Data Row by filtering on some Category\n"", '    file_category=  in1+ ""offers.csv""\n', '    ncol= 8\n', '    catval_tokeep=[ {} for i in xrange(0, ncol)]\n', '    for i, line in enumerate(open(file_category)):\n', '      ll=  line.split("","")\n', '      catval_tokeep[3][  ll[1] ]  = 1  # Offer_file_col1 --> Transact_file_col_4\n', '      catval_tokeep[4][  ll[3] ] =  1  # Offer_file_col3 --> Transact_file_col_4\n', '\n', '  def condfilter(colk, catval_tokeep) :\n', '    if colk[3] in catval_tokeep[3] or colk[4] in catval_tokeep[4]: return True\n', '    else: return False\n', ""  '''\n""]","['datetime.now', 'open', 'f.next', 'outfile.write', 'enumerate', 'line.split', 'condfilter']",7
utilmy/zarchive/py2to3/datanalysis.py:csv_analysis,csv_analysis,function,0,0,0,0,0.0,0,0,[],[],[],511,"[""   '''\n"", '   https://csvkit.readthedocs.io/en/540/tutorial/1_getting_started.html\n', '\n', '   sudo pip install csvkit\n', '\n', '   :return:\n', ""   '''\n""]",[],0
utilmy/zarchive/py2to3/datanalysis.py:csv_row_reduce_line_manual,csv_row_reduce_line_manual,function,26,79,53,495,6.27,2,4,"['file_category', 'file_transact', 'file_reduced']","[None, None, None]","[None, None, None]",520,"[""  ''' Reduce Data by filtering on some Category '''\n""]","['datetime.now', 'enumerate', 'line.split', 'open', 'outfile.write']",5
utilmy/zarchive/py2to3/datanalysis.py:csv_row_mapreduce,csv_row_mapreduce,function,19,29,26,278,9.59,2,0,"['dircsv', 'outfile', 'type_mapreduce', 'chunk']","[None, None, None, None]","['""""', '""""', ""'sum'"", ' 5000000']",549,"["" '''Take All csv in a folder and provide Table, Column Schema'''\n""]","['util.os_file_listall', 'pd.DataFrame', 'enumerate', 'xrange', 'pd.read_csv']",5
utilmy/zarchive/py2to3/datanalysis.py:csv_pivotable,csv_pivotable,function,13,57,38,576,10.11,1,4,"['dircsv', 'filepattern', 'fileh5', 'leftX', 'topY', 'centerZ', 'mapreduce', 'chunksize', 'tablename']","[None, None, None, None, None, None, None, None, None]","['""""', ""'*.csv'"", ""'.h5'"", ""'col0'"", ""'col2'"", ""'coli'"", ""'sum'"", ' 500000', ""'df'""]",565,"["" ''' return df Pivot Table from series of csv file (transfer to d5 temporary)\n"", '\n', 'Edit: you can groupby/sum from the store iteratively since this ""map-reduces"" over the chunks:\n', '\n', 'reduce(lambda x, y: x.add(y, fill_value=0),\n', ""       (df.groupby().sum() for df in store.select('df', chunksize=50000)))\n"", '\n', "" '''\n""]","['util.pd_h5_fromcsv_tohdfs', 'pd.HDFStore', 'store.select', 'pd.concat']",4
utilmy/zarchive/py2to3/datanalysis.py:csv_bigcompute,csv_bigcompute,function,0,1,1,4,4.0,0,0,[],[],[],594,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:db_getdata,db_getdata,function,0,1,1,4,4.0,0,0,[],[],[],601,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:db_sql,db_sql,function,0,1,1,4,4.0,0,0,[],[],[],604,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:db_meta_add,db_meta_add,function,26,85,61,762,8.96,1,4,"['metadb', 'dbname', 'new_table', '[]']","[None, None, None, None]","[None, None, ""(''"", None]",607,"[""   ''' Create Meta database to store infos on the tables : csv, zip, HFS, Postgres\n"", ""ALL_DB['japancoupon']= {}\n"", ""ALL_DB['japancoupon']['schema']=    df_schema\n"", ""ALL_DB['japancoupon']['df_table_uri']= df_schema_dictionnary\n"", ""ALL_DB['japancoupon']['df_table_columns']= df_schema_dict\n"", '        DBname, db_schema, db_table_uri, db_table_columns(dict_table->colum_list),\n', ""   '''\n""]","['pd_df_todict', 'df.drop_duplicates', 'xrange', 'dict0.setdefault']",4
utilmy/zarchive/py2to3/datanalysis.py:db_meta_find,db_meta_find,function,24,86,67,605,7.03,3,4,"['ALLDB', 'query', 'filter_db', 'filter_table', 'filter_column']","[None, None, None, None, None]","[None, ""''"", '[]', '[]', '[]']",644,"[""  ''' Find string in all the meta table name, column\n"", ""  db_meta_find(ALLDB, query='bottler', filter_db=['cokeon'],   filter_table=['table'], filter_column=['table'] )\n"", '  dbname: should be exact name\n', '  fitler_table: partial match is ok\n', '  fitler_column : partial name is ok\n', '  return   (dbname, meta_table_name,  meta_table_filtered_by_row_containing query)\n', ""  '''\n""]","['ALLDB.items', 'len', 'dbi.items', 'isinstance', 'util.str_match_fuzzy', 'list', 'util.find_fuzzy', 'util.pd_find', 'rs.append']",9
utilmy/zarchive/py2to3/datanalysis.py:col_study_getcategorydict_freq,col_study_getcategorydict_freq,function,17,26,25,402,15.46,1,0,['catedict'],[None],[None],675,"[""  ''' Generate Frequency of category : Id, Freq, Freqin%, CumSum%, ZScore\n"", '      given a dictionnary of category parsed previously\n', ""  '''\n""]","['catedict.items', 'util.pd_array_todataframe', 'df.sort_values', 'np.arange', 'catlist.append']",5
utilmy/zarchive/py2to3/datanalysis.py:col_feature_importance,col_feature_importance,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",690,"[""   ''' random forest for column importance '''\n""]",[],0
utilmy/zarchive/py2to3/datanalysis.py:col_study_distribution_show,col_study_distribution_show,function,22,96,71,982,10.23,3,3,"['df', 'col_include', 'col_exclude', ""pars={'binsize'""]","[None, None, None, '']","[None, 'None', 'None', ""{'binsize':20}""]",694,"["" '''  Perfom Full Study of the pandas columns'''\n""]","['np.count_nonzero', 'sorted', 'print', 'len', 'np.max', 'np.min', 'np.median', 'np.mean', 'np.std', 'plot_Y', 'plt.title', 'plt.plot', 'plt.hist', 'plt.show', 'plt.figure', 'np.percentile', 'range']",17
utilmy/zarchive/py2to3/datanalysis.py:col_study_summary,col_study_summary,function,18,57,53,604,10.6,1,3,"['Xmat', '0.0]', 'Xcolname', ""'col2']"", 'Xcolselect', '9]', 'isprint']","[None, None, None, None, None, None, None]","['[0.0', None, ""['col1'"", None, '[9', None, '0']",724,[],"['np.arange', 'len', 'print', 'np.min', 'np.max', 'np.median', 'np.mean', 'np.std', 'colanalysis.append', 'pd.DataFrame', 'np.shape']",11
utilmy/zarchive/py2to3/datanalysis.py:col_pair_plot,col_pair_plot,function,14,34,32,261,7.68,1,1,"['dfX', 'Xcolname_selectlist', 'dfY', 'Ycolname']","[None, None, None, None]","[None, 'None', 'None', 'None']",741,[],"['str', 'plt.scatter', 'plt.autoscale', 'plt.title', 'plt.show']",5
utilmy/zarchive/py2to3/datanalysis.py:col_pair_correl,col_pair_correl,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",755,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:col_pair_interaction,col_pair_interaction,function,0,1,1,4,4.0,0,0,"['Xcol', 'Ytarget']","[None, None]","[None, None]",758,"[""   ''' random forest for pairwise interaction '''\n""]",[],0
utilmy/zarchive/py2to3/datanalysis.py:plot_col_pair,plot_col_pair,function,1,4,4,66,16.5,0,0,"['dfX', 'Xcolname_selectlist', 'dfY', 'Ycolname']","[None, None, None, None]","[None, 'None', 'None', 'None']",762,[],['col_pair_plot'],1
utilmy/zarchive/py2to3/datanalysis.py:tf_transform_catlabel_toint,tf_transform_catlabel_toint,function,13,18,18,219,12.17,1,0,['Xmat'],[None],[None],768,"[""   '''\n"", '     # [""paris"", ""paris"", ""tokyo"", ""amsterdam""]  --> 2 ,5,6\n', '     # np.array(le.inverse_transform([2, 2, 1]))\n', '     le = preprocessing.LabelEncoder()\n', '     le.fit([""paris"", ""paris"", ""tokyo"", ""amsterdam""])\n', 'LabelEncoder()\n', 'list(le.classes_)\n', ""['amsterdam', 'paris', 'tokyo']\n"", 'le.transform([""tokyo"", ""tokyo"", ""paris""])\n', 'array([2, 2, 1]...)\n', 'list(le.inverse_transform([2, 2, 1]))\n', ""['tokyo', 'tokyo', 'paris']\n"", ""   '''\n""]","['xrange', 'le.get_params']",2
utilmy/zarchive/py2to3/datanalysis.py:tf_transform_pca,tf_transform_pca,function,3,4,4,78,19.5,0,0,"['Xmat', 'dimpca', 'whiten']","[None, None, None]","[None, '2', 'True']",793,"[""   '''Project ndim data into dimpca sub-space  '''\n""]","['pca=PCA', 'pca.transform']",2
utilmy/zarchive/py2to3/datanalysis.py:plot_distance_heatmap,plot_distance_heatmap,function,19,30,29,363,12.1,0,0,"['Xmat_dist', 'Xcolname']","[None, None]","[None, None]",802,[],"['pd.DataFrame', 'plt.figure', 'fig.add_subplot', 'ax.imshow', 'pyplot.get_cmap', 'ax.set_xlabel', 'ax.set_ylabel', 'ax.set_title', 'plt.colorbar']",9
utilmy/zarchive/py2to3/datanalysis.py:plot_cluster_2D,plot_cluster_2D,function,10,20,20,238,11.9,1,0,"['X_2dim', 'target_class', 'target_names']","[None, None, None]","[None, None, None]",817,"[""   ''' Plot 2d of Clustering Class,\n"", '       X2d: Nbsample x 2 dim  (projection on 2D sub-space)\n', ""   '''\n""]","['target_ids=xrange', 'len', 'pl.figure', 'zip', 'pl.scatter', 'pl.legend', 'pl.show']",7
utilmy/zarchive/py2to3/datanalysis.py:plot_cluster_tsne,plot_cluster_tsne,function,23,53,46,590,11.13,0,3,"['Xmat', 'Xcluster_label', 'metric', 'perplexity', 'ncomponent', 'savefile', 'isprecompute', 'returnval']","[None, None, None, None, None, None, None, None]","[None, 'None', ""'euclidean'"", '50', '2', ""''"", 'False', 'True']",829,"["" '''Plot High dimemnsionnal State using TSNE method\n"", ""   'euclidean, 'minkowski', 'cityblock', 'seuclidean', 'sqeuclidean, 'cosine, 'correlation, 'hamming, 'jaccard, 'chebyshev,\n"", ""   'canberra, 'braycurtis, 'mahalanobis', VI=None) 'yule, 'matching, 'dice, 'kulsinski, 'rogerstanimoto, 'russellrao, 'sokalmichener, 'sokalsneath,\n"", '\n', '   Xtsne= da.plot_cluster_tsne(Xtrain_dist, Xcluster_label=None, perplexity=40, ncomponent=2, isprecompute=True)\n', '\n', '   Xtrain_dist= sci.spatial.distance.squareform(sci.spatial.distance.pdist(Xtrain_d,\n', ""               metric='cityblock', p=2, w=None, V=None, VI=None))\n"", ""   '''\n""]","['np.set_printoptions', 'model.fit_transform', 'np.arange', 'plot_XY']",4
utilmy/zarchive/py2to3/datanalysis.py:plot_cluster_pca,plot_cluster_pca,function,22,51,44,480,9.41,0,3,"['Xmat', 'Xcluster_label', 'metric', 'dimpca', 'whiten', 'isprecompute', 'savefile', 'doreturn']","[None, None, None, None, None, None, None, None]","[None, 'None', ""'euclidean'"", '2', 'True', 'False', ""''"", '1']",857,[],"['PCA', 'model.fit_transform', 'np.zeros', 'plot_XY']",4
utilmy/zarchive/py2to3/datanalysis.py:plot_cluster_hiearchy,plot_cluster_hiearchy,function,29,84,76,941,11.2,1,3,"['Xmat_dist', 'p', 'truncate_mode', 'color_threshold', 'get_leaves', 'orientation', 'labels', 'count_sort', 'distance_sort', 'show_leaf_counts', 'no_plot', 'no_labels', 'leaf_font_size', 'leaf_rotation', 'leaf_label_func', 'show_contracted', 'link_color_func', 'ax', 'above_threshold_color']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]","[None, '30', 'None', 'None', 'True', ""'top'"", 'None', 'False', 'False', 'True', 'False', 'False', 'None', 'None', 'None', 'False', 'None', 'None', ""'b'""]",874,[],"['dendrogram', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'zip', 'sum', 'plt.plot', 'plt.annotate', 'plt.axhline']",9
utilmy/zarchive/py2to3/datanalysis.py:plot_distribution_density,plot_distribution_density,function,28,58,52,631,10.88,0,0,"['Xsample', 'kernel', 'N', 'bandwith']","[None, None, None, None]","[None, ""'gaussian'"", '10', '1 / 10.0']",902,[],"['plt.subplots', 'len', 'np.min', 'np.max', 'np.linspace', 'np.ones_like', 'np.ones', 'ax.hist', 'kde.score_samples', 'np.log', 'ax.plot', 'np.exp', 'ax.set_xlim', 'plt.show']",14
utilmy/zarchive/py2to3/datanalysis.py:plot_Y,plot_Y,function,4,7,7,88,12.57,0,0,"['Yval', 'typeplot', 'tsize', 'labels', 'title', 'xlabel', 'ylabel', 'zcolor_label', 'figsize', '6']","[None, None, None, None, None, None, None, None, None, None]","[None, ""'.b'"", 'None', 'None', ""''"", ""''"", ""''"", ""''"", '(8', None]",944,[],"['plt.figure', 'plt.title', 'plt.plot', 'plt.show']",4
utilmy/zarchive/py2to3/datanalysis.py:plot_XY,plot_XY,function,72,197,147,1805,9.16,0,7,"['xx', 'yy', 'zcolor', 'tsize', 'labels', 'title', 'xlabel', 'ylabel', 'zcolor_label', 'figsize', '6']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', ""''"", ""''"", ""''"", ""''"", '(8', None]",950,"[""  '''\n"", '      labels= numpy array, ---> Generate HTML File with the labels interactives\n', '      Color: Plasma\n', ""  '''\n""]","['isinstance', 'np.array', 'np.abs', 'plt.get_cmap', 'np.min', 'plt.subplots', 'fig.set_size_inches', 'fig.set_dpi', 'fig.tight_layout', 'ax1.scatter', 'ax1.set_xlabel', 'ax1.set_ylabel', 'ax1.set_title', 'ax1.grid', 'np.max', 'scatter.set_clim', 'fig.colorbar', 'cb.set_label', 'list', 'mpld3.save_html', 'plt.show', 'util.os_folder_create', 'plt.savefig', 'plot_XY_plotly', 'go.Scatter', 'py.iplot', 'py.plot', 'plot_XY_seaborn', 'sns.set_context', 'sns.set_color_codes', 'sns.color_palette', 'np.unique', 'plt.scatter', 'plt.gca', 'plt.title']",35
utilmy/zarchive/py2to3/datanalysis.py:plot_XY_plotly,plot_XY_plotly,function,15,31,26,261,8.42,0,1,"['xx', 'yy', 'towhere']","[None, None, None]","[None, None, ""'url'""]",1016,"[""  ''' Create Interactive Plotly   '''\n""]","['go.Scatter', 'py.iplot', 'py.plot']",3
utilmy/zarchive/py2to3/datanalysis.py:plot_XY_seaborn,plot_XY_seaborn,function,14,44,42,400,9.09,0,1,"['X', 'Y', 'Zcolor']","[None, None, None]","[None, None, 'None']",1038,[],"['sns.set_context', 'sns.set_color_codes', 'sns.color_palette', 'np.unique', 'plt.scatter', 'plt.gca', 'plt.title']",7
utilmy/zarchive/py2to3/datanalysis.py:optim_is_pareto_efficient,optim_is_pareto_efficient,function,15,35,31,304,8.69,1,2,"['Xmat_cost', 'epsilon', 'ret_boolean']","[None, None, None]","[None, ' 0.01', '1']",1080,"['    """""" Calculate Pareto Frontier of Multi-criteria Optimization program\n', '    c1, c2  has to be minimized : -Sharpe, -Perf, +Drawdown\n', '    :param Xmat_cost: An (n_points, k_costs) array\n', '    :return: A (n_points, ) boolean array, indicating whether each point is Pareto efficient\n', '    """"""\n']","['np.ones', 'enumerate', 'np.any']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_model_auto_tpot,sk_model_auto_tpot,function,21,41,36,560,13.66,0,1,"['Xmat', 'y', 'outfolder', 'model_type', 'train_size', 'generation', 'population_size', 'verbosity']","[None, None, None, None, None, None, None, None]","[None, None, ""'aaserialize/'"", ""'regressor/classifier'"", '0.5', '1', '5', '2']",1098,"[""  ''' Automatic training of Xmat--->Y, Generate SKlearn code in outfile\n"", '      Very Slow Process, use lower number of Sample\n', '  :param Xmat:\n', '  :param y:\n', '  :param outfolder:\n', '  :param model_type:\n', '  :param train_size:\n', '  :param generation: \n', '  :param population_size:\n', '  :param verbosity:\n', '  :return:\n', ""  '''\n""]","['train_test_split', 'TPOTRegressor', 'TPOTClassifier', 'tpot.fit', 'print', 'str', 'tpot.export']",7
utilmy/zarchive/py2to3/datanalysis.py:sk_params_search_best,sk_params_search_best,function,30,61,51,826,13.54,0,3,"['Xmat', 'Ytarget', 'model1', ""param_grid={'alpha'"", '1', '5) }', 'method', ""param_search= {'scoretype'"", ""'cv'"", ""'population_size'"", ""'generations_number'""]","[None, None, None, '', None, None, None, '', '5', '5', '3 }']","[None, None, None, ""{'alpha':  np.linspace(0"", None, None, ""'gridsearch'"", "" {'scoretype':'r2'"", None, None, None]",1126,"[""  '''\n"", '   genetic: population_size=5, ngene_mutation_prob=0.10,,gene_crossover_prob=0.5, tournament_size=3,  generations_number=3\n', '\n', '  :param Xmat:\n', '  :param Ytarget:\n', '  :param model1:\n', '  :param param_grid:\n', '  :param method:\n', '  :param param_search:\n', '  :return:\n', ""  '''\n""]","['make_scorer', 'GridSearchCV', 'grid.fit', 'EvolutionaryAlgorithmSearchCV', 'cv=StratifiedKFold', 'cv.fit']",6
utilmy/zarchive/py2to3/datanalysis.py:sk_distribution_kernel_bestbandwidth,sk_distribution_kernel_bestbandwidth,function,8,17,17,176,10.35,0,0,['kde'],[None],[None],1193,"["" '''Find best Bandwidht for a  given kernel\n"", '  :param kde:\n', '  :return:\n', "" '''\n""]","['GridSearchCV', 'np.linspace', 'grid.fit']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_distribution_kernel_sample,sk_distribution_kernel_sample,function,15,31,29,212,6.84,1,0,"['kde', 'n']","[None, None]","['None', '1']",1204,"["" ''' \n"", '  kde = sm.nonparametric.KDEUnivariate(np.array(Y[Y_cluster==0],dtype=np.float64))\n', '  kde = sm.nonparametric.KDEMultivariate()  # ... you already did this\n', "" '''\n""]","['np.zeros', 'func', 'kde.cdf', 'xrange', 'brentq']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_correl_rank,sk_correl_rank,function,16,38,31,291,7.66,2,0,"['correl', '0]', '[0', '1]]']","[None, None, None, None]","['[[1', None, None, None]",1222,"[' """""" Correl Ranking:  Col i, Col j, Correl_i_j, Abs_Correl_i_j    """"""\n']","['np.shape', 'np.zeros', 'xrange', 'abs', 'util.sortcol']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_error_r2,sk_error_r2,function,8,19,16,175,9.21,0,1,"['Ypred', 'y_true', 'sample_weight', 'multioutput']","[None, None, None, None]","[None, None, 'None', 'None']",1237,[],"['r2_score', 'np.sign']",2
utilmy/zarchive/py2to3/datanalysis.py:sk_error_rmse,sk_error_rmse,function,6,10,10,100,10.0,0,0,"['Ypred', 'Ytrue']","[None, None]","[None, None]",1244,[],"['np.sqrt', 'len', 'np.std']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_cluster_distance_pair,sk_cluster_distance_pair,function,5,16,14,195,12.19,0,2,"['Xmat', 'metric']","[None, None]","[None, ""'jaccard'""]",1248,"[""   '''\n"", ""    'euclidean, 'minkowski', 'cityblock', 'seuclidean', 'sqeuclidean, 'cosine, 'correlation, 'hamming, 'jaccard, 'chebyshev, 'canberra, 'braycurtis, 'mahalanobis', VI=None) 'yule, 'matching, 'dice, 'kulsinski, 'rogerstanimoto, 'russellrao, 'sokalmichener, 'sokalsneath,\n"", '\n', ""    'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance,\n"", "" 'canberra': hdbscan.dist_metrics.CanberraDistance,\n"", "" 'chebyshev': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'cityblock': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'dice': hdbscan.dist_metrics.DiceDistance,\n"", "" 'euclidean': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'hamming': hdbscan.dist_metrics.HammingDistance,\n"", "" 'haversine': hdbscan.dist_metrics.HaversineDistance,\n"", "" 'infinity': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'jaccard': hdbscan.dist_metrics.JaccardDistance,\n"", "" 'kulsinski': hdbscan.dist_metrics.KulsinskiDistance,\n"", "" 'l1': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'l2': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance,\n"", "" 'manhattan': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'matching': hdbscan.dist_metrics.MatchingDistance,\n"", "" 'minkowski': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'p': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'pyfunc': hdbscan.dist_metrics.PyFuncDistance,\n"", "" 'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance,\n"", "" 'russellrao': hdbscan.dist_metrics.RussellRaoDistance,\n"", "" 'seuclidean': hdbscan.dist_metrics.SEuclideanDistance,\n"", "" 'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance,\n"", "" 'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance,\n"", "" 'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance}\n"", '   #Visualize discretization scheme\n', '\n', '   Xtrain_dist= sci.spatial.distance.squareform(sci.spatial.distance.pdist(Xtrain_d,\n', ""             metric='cityblock', p=2, w=None, V=None, VI=None))\n"", '\n', ""   Xtsne= da.plot_cluster_tsne(Xtrain_dist, metric='', perplexity=40, ncomponent=2, isprecompute=True)\n"", '\n', ""   '''\n""]",['fast.distance_jaccard_X'],1
utilmy/zarchive/py2to3/datanalysis.py:sk_cluster,sk_cluster,function,52,174,123,1637,9.41,2,11,"['Xmat', 'metric']","[None, None]","[None, ""'jaccard'""]",1290,[],"['fast.distance_jaccard_X', 'sk_cluster', 'hdbscan.HDBSCAN', 'print', 'len', 'np.std', 'np.mean', 'Xmat.reshape', 'k_means', 'KMeans', 'kmeans.fit', 'range', 'plt.plot', 'plt.show', 'sk_cluster_algo_custom', 'algorithm']",16
utilmy/zarchive/py2to3/datanalysis.py:sk_cluster_algo_custom,sk_cluster_algo_custom,function,9,17,15,172,10.12,0,1,"['Xmat', 'algorithm', 'args', 'kwds', 'returnval']","[None, None, None, None, None]","[None, None, None, None, '1']",1353,"[""    ''' Plot the cLuster using specific Algo\n"", '    distance_matrix = pairwise_distances(blobs)\n', ""    clusterer = hdbscan.HDBSCAN(metric='precomputed')\n"", '    clusterer.fit(distance_matrix)\n', '    clusterer.labels_\n', '\n', ""    {'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance,\n"", "" 'canberra': hdbscan.dist_metrics.CanberraDistance,\n"", "" 'chebyshev': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'cityblock': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'dice': hdbscan.dist_metrics.DiceDistance,\n"", "" 'euclidean': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'hamming': hdbscan.dist_metrics.HammingDistance,\n"", "" 'haversine': hdbscan.dist_metrics.HaversineDistance,\n"", "" 'infinity': hdbscan.dist_metrics.ChebyshevDistance,\n"", "" 'jaccard': hdbscan.dist_metrics.JaccardDistance,\n"", "" 'kulsinski': hdbscan.dist_metrics.KulsinskiDistance,\n"", "" 'l1': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'l2': hdbscan.dist_metrics.EuclideanDistance,\n"", "" 'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance,\n"", "" 'manhattan': hdbscan.dist_metrics.ManhattanDistance,\n"", "" 'matching': hdbscan.dist_metrics.MatchingDistance,\n"", "" 'minkowski': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'p': hdbscan.dist_metrics.MinkowskiDistance,\n"", "" 'pyfunc': hdbscan.dist_metrics.PyFuncDistance,\n"", "" 'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance,\n"", "" 'russellrao': hdbscan.dist_metrics.RussellRaoDistance,\n"", "" 'seuclidean': hdbscan.dist_metrics.SEuclideanDistance,\n"", "" 'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance,\n"", "" 'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance,\n"", "" 'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance}\n"", '\n', ""    '''\n""]","['algorithm', 'print', 'len']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_optim_de,sk_optim_de,function,37,127,96,1179,9.28,1,4,"['obj_fun', 'bounds', 'maxiter', 'name1', 'solver1', 'isreset', 'popsize']","[None, None, None, None, None, None, None]","[None, None, '1', ""''"", 'None', '1', '15']",1426,"[""    ''' Optimization and Save Data into file'''\n""]","['print', 'load_obj', 'int', 'copy.deepcopy', 'xrange', 'next', 'util.save_obj', 'util.date_now', 'util.np_int_tostr', 'np.mod', 'np.abs']",11
utilmy/zarchive/py2to3/datanalysis.py:sk_feature_importance,sk_feature_importance,function,9,20,20,228,11.4,1,1,"['clfrf', 'feature_name']","[None, None]","[None, None]",1529,[],"['np.argsort', 'range', 'len', 'str']",4
utilmy/zarchive/py2to3/datanalysis.py:sk_showconfusion,sk_showconfusion,function,11,22,21,244,11.09,0,1,"['clfrf', 'X_train', 'Y_train', 'isprint']","[None, None, None, None]","[None, None, None, 'True']",1537,[],"['clfrf.predict', 'cm.astype', 'cm.sum', 'print']",4
utilmy/zarchive/py2to3/datanalysis.py:sk_tree,sk_tree,function,13,33,32,445,13.48,0,1,"['Xtrain', 'Ytrain', 'nbtree', 'maxdepth', 'isprint1', 'njobs']","[None, None, None, None, None, None]","[None, None, None, None, '1', '1']",1546,[],"['clfrf.fit', 'clfrf.predict', 'cm.astype', 'cm.sum', 'print']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_gen_ensemble_weight,sk_gen_ensemble_weight,function,14,29,27,213,7.34,1,0,"['vv', 'acclevel', 'maxlevel']","[None, None, None]","[None, None, '0.88']",1558,[],"['min', 'np.empty', 'range', 'estww.append', 'np.log', 'np.array']",6
utilmy/zarchive/py2to3/datanalysis.py:sk_votingpredict,sk_votingpredict,function,19,33,28,267,8.09,2,1,"['estimators', 'voting', 'ww', 'X_test']","[None, None, None, None]","[None, None, None, None]",1572,[],"['np.zeros', 'enumerate', 'clf.predict_proba', 'range', 'len']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_tree_get_ifthen,sk_tree_get_ifthen,function,26,91,64,774,8.51,2,3,"['tree', 'feature_names', 'target_names', 'spacer_base']","[None, None, None, None]","[None, None, None, '"" ""']",1587,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['recurse', 'print', 'str', 'zip', 'int']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_model_template1,sk_model_template1,class,39,143,86,1191,8.33,0,3,[],[],[],1473,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:sk_stateRule,sk_stateRule,class,38,138,104,1118,8.1,0,5,[],[],[],1658,[],[],0
utilmy/zarchive/py2to3/datanalysis.py:sk_model_template1:__init__,sk_model_template1:__init__,method,10,13,13,166,12.77,0,0,"['self', 'alpha', 'low_y_cut', 'high_y_cut', 'ww0']","[None, None, None, None, None]","[None, '0.5', '-0.09', '0.09', '0.95']",1474,[],['Ridge'],1
utilmy/zarchive/py2to3/datanalysis.py:sk_model_template1:fit,sk_model_template1:fit,method,17,46,40,465,10.11,0,1,"['self', 'X', 'Y']","[None, None, None]","[None, None, 'None']",1480,[],"['len', 'print', 'np.median']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_model_template1:predict,sk_model_template1:predict,method,10,27,21,166,6.15,0,1,"['self', 'X', 'y', 'ymedian']","[None, None, None, None]","[None, None, 'None', 'None']",1498,[],['Y.clip'],1
utilmy/zarchive/py2to3/datanalysis.py:sk_model_template1:score,sk_model_template1:score,method,14,32,27,216,6.75,0,1,"['self', 'X', 'Ytrue', 'ymedian']","[None, None, None, None]","[None, None, 'None', 'None']",1509,[],"['Y.clip', 'r2_score']",2
utilmy/zarchive/py2to3/datanalysis.py:sk_stateRule:__init__,sk_stateRule:__init__,method,8,44,37,371,8.43,0,1,"['self', 'state', 'trigger', 'colname']","[None, None, None, None]","[None, None, None, '[]']",1661,[],"['np.empty', 'np.shape', 'len', 'xrange', 'util.np_torecarray']",5
utilmy/zarchive/py2to3/datanalysis.py:sk_stateRule:addrule,sk_stateRule:addrule,method,20,47,42,381,8.11,0,2,"['self', 'rulefun', 'name', 'desc']","[None, None, None, None]","[None, None, ""''"", ""''""]",1673,[],"['util.findnone', 'util.find', 'print', 'util.np_addcolumn', 'rulefun', 'copy.deepcopy']",6
utilmy/zarchive/py2to3/datanalysis.py:sk_stateRule:eval,sk_stateRule:eval,method,9,29,24,231,7.97,0,2,"['self', 'idrule', 't', 'ktrig']","[None, None, None, None]","[None, None, None, '0']",1691,[],"['isinstance', 'util.find', 'print']",3
utilmy/zarchive/py2to3/datanalysis.py:sk_stateRule:help,sk_stateRule:help,method,0,0,0,0,0.0,0,0,[],[],[],1699,"[""    '''\n"", 's1= np.arange(5000).reshape((1000, 5))\n', 'trig1= np.ones((1,5))\n', ""state1= sk_stateRule(aa, trig1, ['drawdown','ma100d','ret10d','state_1','state_2'] )\n"", '\n', 'def fun1(s, tr,t):\n', '  return  s.drawdown[t] < tr.drawdown[0] and  s.drawdown[t] < tr.drawdown[0]\n', '\n', 'def fun2(s, tr,t):\n', ' return  s.drawdown[t] > tr.drawdown[0] and  s.drawdown[t] < tr.drawdown[0]\n', '\n', ""state1.addrule(fun1, 'rule6')\n"", ""state1.addrule(fun2, 'rule5')\n"", '\n', 'state1.eval(idrule=0,t=5)\n', '\n', 'state1.eval(idrule=1,t=5)\n', '\n', ""state1.eval(idrule='rule5',t=6)\n"", '\n', ""util.save_obj(state1, 'state1')\n"", '\n', 'np.shape(aa2)\n', '\n', ""aa2= util.np_torecarray(aa,  ['drawdown','a2','a3','a4','a5'])\n"", '\n', 'util.find(5.0, aa2[0])\n', '\n', 'recordarr = np.rec.array([(1,2.,7),(2,3.,5)],\n', ""                   dtype=[('col1', 'f8'),('col2', 'f8'), ('col3', 'f8')])\n"", 'recordarr.col3[0]\n', '\n', 'state1= stateRule(np.ones((100,10)), np.ones((1,10)))\n', '\n', 'col= aa2.a2\n', '\n', ""'''\n""]",[],0
utilmy/zarchive/py2to3/excel.py:get_workbook_name,get_workbook_name,function,3,5,5,48,9.6,0,0,[],[],[],9,"['    """"""Writes the name of the Workbook into Range(""D3"") of Sheet 1""""""\n']","['Workbook.caller', 'Range']",2
utilmy/zarchive/py2to3/excel.py:double_sum,double_sum,function,1,4,4,13,3.25,0,0,"['x', 'y']","[None, None]","[None, None]",16,"['    """"""Returns twice the sum of the two arguments""""""\n']",[],0
utilmy/zarchive/py2to3/excel.py:add_one,add_one,function,5,11,9,40,3.64,2,0,['data'],[None],[None],23,"['    """"""Adds 1 to every cell in Range""""""\n']",[],0
utilmy/zarchive/py2to3/excel.py:matrix_mult,matrix_mult,function,2,2,2,14,7.0,0,0,"['x', 'y']","[None, None]","[None, None]",31,"['    """"""Alternative implementation of Excel\'s MMULT, requires NumPy""""""\n']",['x.dot'],1
utilmy/zarchive/py2to3/excel.py:npdot,npdot,function,0,0,0,0,0.0,0,0,[],[],[],43,[],[],0
utilmy/zarchive/py2to3/fast.py:day,day,function,9,15,14,125,8.33,0,0,['s)'],['    return int(s[8:10])s):  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],130,[],['arrow.get'],1
utilmy/zarchive/py2to3/fast.py:month,month,function,9,15,14,125,8.33,0,0,['s)'],['  return int(s[5:7])s):   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],131,[],['arrow.get'],1
utilmy/zarchive/py2to3/fast.py:year,year,function,9,15,14,125,8.33,0,0,['s)'],['   return int(s[0:4])s):   return int(s[11:13])cache_weekday'],[' {}s):'],132,[],['arrow.get'],1
utilmy/zarchive/py2to3/fast.py:hour,hour,function,9,15,14,125,8.33,0,0,['s)'],['   return int(s[11:13])cache_weekday'],[' {}s):'],133,[],['arrow.get'],1
utilmy/zarchive/py2to3/fast.py:weekday,weekday,function,9,15,14,125,8.33,0,0,['s'],[None],[None],139,[],['arrow.get'],1
utilmy/zarchive/py2to3/fast.py:season,season,function,4,15,13,47,3.13,0,1,['d'],[None],[None],148,[],['int'],1
utilmy/zarchive/py2to3/fast.py:daytime,daytime,function,5,40,23,123,3.08,0,1,['d'],[None],[None],154,[],['int'],1
utilmy/zarchive/py2to3/fast.py:fastStrptime,fastStrptime,function,8,46,35,288,6.26,0,2,"['val', 'format']","[None, None]","[None, None]",164,[],"['len', 'int', 'datetime.datetime']",3
utilmy/zarchive/py2to3/fast.py:drawdown_calc_fast,drawdown_calc_fast,function,36,80,63,618,7.72,1,3,['price'],[None],[None],190,[],"['len', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/fast.py:std,std,function,6,12,12,61,5.08,0,0,['x'],[None],[None],225,"['    """"""Std Deviation 1D array""""""\n']","['x.sum', 'sqrt']",2
utilmy/zarchive/py2to3/fast.py:mean,mean,function,2,3,3,24,8.0,0,0,['x'],[None],[None],236,"['    """"""Mean  """"""\n']",['x.sum'],1
utilmy/zarchive/py2to3/fast.py:_compute_overlaps,_compute_overlaps,function,13,27,20,108,4.0,1,0,"['u', 'v']","[None, None]","[None, None]",249,[],['xrange'],1
utilmy/zarchive/py2to3/fast.py:distance_jaccard2,distance_jaccard2,function,5,11,11,55,5.0,0,0,"['u', 'v']","[None, None]","[None, None]",260,[],"['_compute_overlaps', 'float']",2
utilmy/zarchive/py2to3/fast.py:distance_jaccard,distance_jaccard,function,5,11,11,55,5.0,0,0,"['u', 'v']","[None, None]","[None, None]",266,[],"['_compute_overlaps', 'float']",2
utilmy/zarchive/py2to3/fast.py:distance_jaccard_X,distance_jaccard_X,function,13,21,19,163,7.76,2,0,['X'],[None],[None],277,[],"['np.zeros', 'xrange', 'distance_jaccard']",3
utilmy/zarchive/py2to3/fast.py:cosine,cosine,function,11,43,26,262,6.09,0,2,"['u', 'v']","[None, None]","[None, None]",292,[],['np.sqrt'],1
utilmy/zarchive/py2to3/fast.py:rmse,rmse,function,1,7,6,31,4.43,0,0,"['y', 'yhat']","[None, None]","[None, None]",321,"['    """""" Calculate and return Root Mean Squared Error (RMSE)\n', '    Returns: float: Root Mean Squared Error\n', '    """"""\n']",[],0
utilmy/zarchive/py2to3/fast.py:cross,cross,function,17,31,25,211,6.81,0,0,"['vec1', 'vec2']","[None, None]","[None, None]",329,"['    """""" Calculate the dot product of two 3d vectors. """"""\n']","['double', 'np.zeros']",2
utilmy/zarchive/py2to3/fast.py:norm,norm,function,4,8,8,61,7.62,1,0,['vec'],[None],[None],341,"['    """""" Calculate the norm of a 3d vector. """"""\n']","['sqrt', 'range']",2
utilmy/zarchive/py2to3/fast.py:log_exp_sum2,log_exp_sum2,function,0,1,1,5,5.0,0,0,"['a', 'b']","[None, None]","[None, None]",242,[],[],0
utilmy/zarchive/py2to3/fast_parallel.py:task_summary,task_summary,function,4,17,17,142,8.35,1,0,['tasks'],[None],[None],76,[],"['print', 'enumerate', 't.get']",3
utilmy/zarchive/py2to3/fast_parallel.py:task_progress,task_progress,function,8,26,23,161,6.19,1,1,['tasks'],[None],[None],83,"[""  ''' Monitor progress '''\n""]","['np.mean', 'print']",2
utilmy/zarchive/py2to3/fast_parallel.py:task_find_best,task_find_best,function,3,11,11,80,7.27,0,0,"['tasks', 'n_top']","[None, None]","[None, '5']",94,"['    """"""Compute the best score of tasks_folder""""""\n']","['t.ready', 'sorted']",2
utilmy/zarchive/py2to3/fast_parallel.py:task_parallel_job_01,task_parallel_job_01,function,19,33,32,336,10.18,0,0,"['name', 'param', 'datadict']","[None, None, None]","[None, None, None]",101,"[""   ''' Sample task run in Parallel '''\n""]","['os.chdir', 'util.a_run_ipython', 'str']",3
utilmy/zarchive/py2to3/filelock.py:FileLock,FileLock,class,41,133,94,1246,9.37,2,6,[],[],[],36,[],[],0
utilmy/zarchive/py2to3/filelock.py:FileLock:__init__,FileLock:__init__,method,11,27,23,279,10.33,1,1,"['self', 'protected_file_path', 'timeout', 'delay', 'lock_file_contents']","[None, None, None, None, None]","[None, None, 'None', '1', 'None']",53,"['        """""" Prepare the file locker. Specify the file to lock and optionally\n', '            the maximum timeout and the delay between each attempt to lock.\n', '        """"""\n']",[],0
utilmy/zarchive/py2to3/filelock.py:FileLock:locked,FileLock:locked,method,2,2,2,20,10.0,0,0,['self'],[None],[None],67,"['        """"""\n', '        Returns True iff the file is owned by THIS FileLock instance.\n', '        (Even if this returns false, the file could be owned by another FileLock instance, possibly in a different thread or process).\n', '        """"""\n']",[],0
utilmy/zarchive/py2to3/filelock.py:FileLock:available,FileLock:available,method,2,3,3,38,12.67,0,0,['self'],[None],[None],74,"['        """"""\n', '        Returns True iff the file is currently available to be locked.\n', '        """"""\n']",[],0
utilmy/zarchive/py2to3/filelock.py:FileLock:acquire,FileLock:acquire,method,18,55,48,410,7.45,1,3,"['self', 'blocking']","[None, None]","[None, 'True']",80,"['        """""" Acquire the lock, if possible. If the lock is in use, and `blocking` is False, return False.\n', '            Otherwise, check again every `self.delay` seconds until it either gets the lock or\n', '            exceeds `timeout` number of seconds, in which case it raises an exception.\n', '        """"""\n']","['time.time', 'os.open', 'os.fdopen', 'f.write', 'FileLock.FileLockException', 'time.sleep']",6
utilmy/zarchive/py2to3/filelock.py:FileLock:release,FileLock:release,method,2,3,3,45,15.0,0,0,['self'],[None],[None],106,"['        """""" Get rid of the lock by deleting the lockfile.\n', '            When working in a `with` statement, this gets automatically\n', '            called at the end.\n', '        """"""\n']",['os.unlink'],1
utilmy/zarchive/py2to3/filelock.py:FileLock:__enter__,FileLock:__enter__,method,2,3,3,25,8.33,0,0,['self'],[None],[None],115,"['        """""" Activated when used in the with statement.\n', '            Should automatically acquire a lock to be used in the with block.\n', '        """"""\n']",['self.acquire'],1
utilmy/zarchive/py2to3/filelock.py:FileLock:__exit__,FileLock:__exit__,method,1,1,1,14,14.0,0,0,"['self', 'type', 'value', 'traceback']","[None, None, None, None]","[None, None, None, None]",123,"['        """""" Activated at the end of the with statement.\n', ""            It automatically releases the lock if it isn't locked.\n"", '        """"""\n']",['self.release'],1
utilmy/zarchive/py2to3/filelock.py:FileLock:__del__,FileLock:__del__,method,2,3,3,32,10.67,0,1,['self'],[None],[None],130,"['        """""" Make sure this ``FileLock`` instance doesn\'t leave a .lock file\n', '            lying around.\n', '        """"""\n']",['self.release'],1
utilmy/zarchive/py2to3/filelock.py:FileLock:purge,FileLock:purge,method,3,7,6,70,10.0,0,1,['self'],[None],[None],137,"['        """"""\n', '        For debug purposes only.  Removes the lock file from the hard disk.\n', '        """"""\n']",['self.release'],1
utilmy/zarchive/py2to3/function_custom.py:mapping_calc_risk_elvis_v03,mapping_calc_risk_elvis_v03,function,4,9,9,63,7.0,0,0,"['ss', 'tr', 't', 'riskout']","[None, None, None, None]","[None, None, None, None]",18,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",['mapping_calc_risk_v01'],1
utilmy/zarchive/py2to3/function_custom.py:mapping_calc_risk_v02,mapping_calc_risk_v02,function,18,190,75,704,3.71,0,2,"['ss', 'tr', 't', 'risk0']","[None, None, None, None]","[None, None, None, None]",31,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",[],0
utilmy/zarchive/py2to3/function_custom.py:mapping_calc_risk_v01,mapping_calc_risk_v01,function,19,130,56,532,4.09,0,2,"['ss', 'tr', 't', 'risk0']","[None, None, None, None]","[None, None, None, None]",72,"[""     ''' ss: state,  tr:trigger level,  risk0: previous risk value '''\n""]",[],0
utilmy/zarchive/py2to3/function_custom.py:mapping_risk_ww_v01,mapping_risk_ww_v01,function,12,56,29,245,4.38,0,1,"['risk', 'wwmat', 'ww2']","[None, None, None]","[None, None, None]",98,[],"['np.sum', 'np.array']",2
utilmy/zarchive/py2to3/function_custom.py:mapping_calc_risk_v00,mapping_calc_risk_v00,function,16,68,45,286,4.21,0,1,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",107,[],[],0
utilmy/zarchive/py2to3/function_custom.py:getweight,getweight,function,7,13,12,70,5.38,0,1,"['ww', 'size', '3']","[None, None, None]","[None, '(9', None]",133,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/py2to3/function_custom.py:fun_obj,fun_obj,function,6,11,11,120,10.91,0,0,"['vv', 'ext']","[None, None]","[None, None]",139,[],"['pf.folio_volta', 'int', 'pf.volhisto_fromprice', 'len']",4
utilmy/zarchive/py2to3/geospatial.py:coordinates_box,coordinates_box,class,1,2,2,16,8.0,0,0,[],[],[],33,[],[],0
utilmy/zarchive/py2to3/kagglegym.py:r_score,r_score,function,4,15,12,146,9.73,0,1,"['y_true', 'y_pred', 'sample_weight', 'multioutput']","[None, None, None, None]","[None, None, 'None', 'None']",77,[],['r2_score'],1
utilmy/zarchive/py2to3/kagglegym.py:make,make,function,2,2,2,19,9.5,0,0,[],[],[],175,[],['Environment'],1
utilmy/zarchive/py2to3/kagglegym.py:Observation,Observation,class,7,11,11,99,9.0,0,0,[],[],[],86,[],[],0
utilmy/zarchive/py2to3/kagglegym.py:Environment,Environment,class,49,148,101,1719,11.61,0,1,[],[],[],93,[],[],0
utilmy/zarchive/py2to3/kagglegym.py:Observation:__init__,Observation:__init__,method,6,6,6,58,9.67,0,0,"['self', 'train', 'target', 'features']","[None, None, None, None]","[None, None, None, None]",87,[],[],0
utilmy/zarchive/py2to3/kagglegym.py:Environment:__init__,Environment:__init__,method,21,37,35,452,12.22,0,0,['self'],[None],[None],94,[],"['pd.HDFStore', 'hfdata.get', 'len', 'int']",4
utilmy/zarchive/py2to3/kagglegym.py:Environment:reset,Environment:reset,method,16,36,34,403,11.19,0,0,['self'],[None],[None],115,[],"['int', 'Observation']",2
utilmy/zarchive/py2to3/kagglegym.py:Environment:step,Environment:step,method,29,64,52,765,11.95,0,1,"['self', 'target']","[None, None]","[None, None]",135,[],"['r_score', 'Observation']",2
utilmy/zarchive/py2to3/kagglegym.py:Environment:__str__,Environment:__str__,method,1,2,2,21,10.5,0,0,['self'],[None],[None],171,[],[],0
utilmy/zarchive/py2to3/linux.py:load_session,load_session,function,4,7,7,86,12.29,0,0,['name'],[None],"[""'test_20160815'""]",100,[],['dill.load_session'],1
utilmy/zarchive/py2to3/linux.py:save_session,save_session,function,6,9,9,107,11.89,0,0,['name'],[None],"[""''""]",106,[],"['date_now', 'dill.dump_session']",2
utilmy/zarchive/py2to3/linux.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],121,[],['float'],1
utilmy/zarchive/py2to3/linux.py:isint,isint,function,6,15,14,80,5.33,0,1,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, None, '']","[None, None, None, None, None, None]",129,[],['txt.find'],1
utilmy/zarchive/py2to3/linux.py:aa_isanaconda,aa_isanaconda,function,6,15,14,80,5.33,0,1,[],[],[],132,[],['txt.find'],1
utilmy/zarchive/py2to3/linux.py:aa_cleanmemory,aa_cleanmemory,function,3,3,3,21,7.0,0,0,[],[],[],147,[],['gc.collect'],1
utilmy/zarchive/py2to3/linux.py:aa_getmodule_doc,aa_getmodule_doc,function,8,13,13,110,8.46,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",150,[],"['ca.getmodule_doc', 'np.isnan', 'z.nonzero']",3
utilmy/zarchive/py2to3/linux.py:np_interpolate_nan,np_interpolate_nan,function,7,9,9,78,8.67,0,0,['y'],[None],[None],1176,[],"['__np_nan_helper', 'np.interp', 'x']",3
utilmy/zarchive/py2to3/linux.py:and1,and1,function,8,55,22,356,6.47,0,6,"['x', 'y', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']","[None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None', 'None', 'None']",1182,[],[],0
utilmy/zarchive/py2to3/linux.py:sortcol,sortcol,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",1192,"[' """""" df.sort([\'A\', \'B\'], ascending=[1, 0])  """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/py2to3/linux.py:sort,sort,function,7,20,12,181,9.05,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",1198,[],"['pd.DataFrame', 'df.sort_values', 'sort']",3
utilmy/zarchive/py2to3/linux.py:np_ma,np_ma,function,2,3,3,45,15.0,0,0,"['vv', 'n']","[None, None]","[None, None]",1205,"[""  '''Moving average '''\n""]","['np.convolve', 'np.ones']",2
utilmy/zarchive/py2to3/linux.py:np_cleanmatrix,np_cleanmatrix,function,11,22,20,124,5.64,2,1,['m'],[None],[None],1211,[],"['np.nan_to_num', 'np.shape', 'range', 'abs']",4
utilmy/zarchive/py2to3/linux.py:np_sortbycolumn,np_sortbycolumn,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1222,[],"['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/py2to3/linux.py:np_sortbycol,np_sortbycol,function,8,30,20,257,8.57,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1227,[],"['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/py2to3/linux.py:np_findfirst,np_findfirst,function,5,11,10,55,5.0,1,1,"['item', 'vec']","[None, None]","[None, None]",1238,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/py2to3/linux.py:np_find,np_find,function,6,24,13,133,5.54,2,2,"['item', 'vec']","[None, None]","[None, None]",1244,[],"['xrange', 'np_find']",2
utilmy/zarchive/py2to3/linux.py:find,find,function,12,42,30,219,5.21,1,3,"['item', 'vec']","[None, None]","[None, None]",1250,"['    """"""return the index of the first occurence of item in vec""""""\n']","['xrange', 'findx', 'type', 'vec.index', 'len', 'finds']",6
utilmy/zarchive/py2to3/linux.py:findx,findx,function,6,27,18,119,4.41,0,2,"['item', 'vec']","[None, None]","[None, None]",1257,"['    """"""return the index of the first occurence of item in vec""""""\n']","['type', 'vec.index', 'len']",3
utilmy/zarchive/py2to3/linux.py:finds,finds,function,12,34,23,156,4.59,2,3,"['itemlist', 'vec']","[None, None]","[None, None]",1268,"['  """"""return the index of the first occurence of item in vec""""""\n']","['xrange', 'idlist.append']",2
utilmy/zarchive/py2to3/linux.py:findhigher,findhigher,function,5,13,12,51,3.92,1,1,"['x', 'vec']","[None, None]","[None, None]",1280,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/py2to3/linux.py:findlower,findlower,function,5,12,11,51,4.25,1,1,"['x', 'vec']","[None, None]","[None, None]",1287,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/py2to3/linux.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],1297,[],['min'],1
utilmy/zarchive/py2to3/linux.py:np_find_maxpos,np_find_maxpos,function,17,45,34,266,5.91,1,3,['values'],[None],[None],1301,[],"['max', 'np_find_maxpos_2nd', 'float', 'enumerate']",4
utilmy/zarchive/py2to3/linux.py:np_find_maxpos_2nd,np_find_maxpos_2nd,function,13,37,28,138,3.73,1,3,['numbers'],[None],[None],1306,[],"['float', 'enumerate']",2
utilmy/zarchive/py2to3/linux.py:np_findlocalmax2,np_findlocalmax2,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",1320,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/py2to3/linux.py:np_findlocalmin2,np_findlocalmin2,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",1355,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/py2to3/linux.py:np_findlocalmax,np_findlocalmax,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",1392,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/py2to3/linux.py:np_findlocalmin,np_findlocalmin,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",1407,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/py2to3/linux.py:np_stack,np_stack,function,12,53,25,323,6.09,0,7,"['v1', 'v2', 'v3', 'v4', 'v5']","[None, None, None, None, None]","[None, 'None', 'None', 'None', 'None']",1428,[],"['np.shape', 'np.row_stack', 'np.column_stack']",3
utilmy/zarchive/py2to3/linux.py:np_uniquerows,np_uniquerows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],1443,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/py2to3/linux.py:np_remove_zeros,np_remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",1448,[],[],0
utilmy/zarchive/py2to3/linux.py:np_sort,np_sort,function,8,30,20,257,8.57,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",1451,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/py2to3/linux.py:np_memory_array_adress,np_memory_array_adress,function,2,2,2,38,19.0,0,0,['x'],[None],[None],1454,[],[],0
utilmy/zarchive/py2to3/linux.py:sk_featureimportance,sk_featureimportance,function,9,21,21,228,10.86,1,1,"['clfrf', 'feature_name']","[None, None]","[None, None]",1463,[],"['np.argsort', 'range', 'len', 'str']",4
utilmy/zarchive/py2to3/linux.py:sk_showconfusion,sk_showconfusion,function,11,22,21,244,11.09,0,1,"['clfrf', 'X_train', 'Y_train', 'isprint']","[None, None, None, None]","[None, None, None, 'True']",1471,[],"['clfrf.predict', 'cm.astype', 'cm.sum', 'print']",4
utilmy/zarchive/py2to3/linux.py:sk_tree,sk_tree,function,13,34,32,430,12.65,0,1,"['Xtrain', 'Ytrain', 'nbtree', 'maxdepth', 'print1']","[None, None, None, None, None]","[None, None, None, None, None]",1479,[],"['clfrf.fit', 'clfrf.predict', 'cm.astype', 'cm.sum', 'print']",5
utilmy/zarchive/py2to3/linux.py:sk_gen_ensemble_weight,sk_gen_ensemble_weight,function,14,30,28,213,7.1,1,0,"['vv', 'acclevel', 'maxlevel']","[None, None, None]","[None, None, '0.88']",1492,[],"['min', 'np.empty', 'range', 'estww.append', 'np.log', 'np.array']",6
utilmy/zarchive/py2to3/linux.py:sk_votingpredict,sk_votingpredict,function,19,33,28,267,8.09,2,1,"['estimators', 'voting', 'ww', 'X_test']","[None, None, None, None]","[None, None, None, None]",1506,[],"['np.zeros', 'enumerate', 'clf.predict_proba', 'range', 'len']",5
utilmy/zarchive/py2to3/linux.py:sk_tree_get_ifthen,sk_tree_get_ifthen,function,26,89,62,768,8.63,2,3,"['tree', 'feature_names', 'target_names', 'spacer_base']","[None, None, None, None]","[None, None, None, '"" ""']",1524,"['    """"""Produce psuedo-code for decision tree.\n', '    tree -- scikit-leant DescisionTree.\n', '    feature_names -- list of feature names.\n', '    target_names -- list of target (output) names.\n', '    spacer_base -- used for spacing code (default: ""    "").\n', '    """"""\n']","['recurse', 'print', 'str', 'zip', 'int']",5
utilmy/zarchive/py2to3/linux.py:pd_array_todataframe,pd_array_todataframe,function,13,45,29,277,6.16,0,2,"['price', 'symbols', 'date1', 'dotranspose']","[None, None, None, None]","[None, 'None', 'None', 'False']",1562,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/py2to3/linux.py:pd_date_intersection,pd_date_intersection,function,7,18,15,157,8.72,1,0,['qlist'],[None],[None],1574,[],"['set', 'set.intersection', 'list', 'sorted']",4
utilmy/zarchive/py2to3/linux.py:pd_resetindex,pd_resetindex,function,3,4,4,50,12.5,0,0,['df'],[None],[None],1585,[],['list'],1
utilmy/zarchive/py2to3/linux.py:pd_create_colmap_nametoid,pd_create_colmap_nametoid,function,9,12,12,77,6.42,1,0,['df'],[None],[None],1591,"[""  ''' 'close' ---> 5    '''\n""]",['enumerate'],1
utilmy/zarchive/py2to3/linux.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],1599,[],[],0
utilmy/zarchive/py2to3/linux.py:pd_changeencoding,pd_changeencoding,function,6,8,8,89,11.12,1,0,"['data', 'cols']","[None, None]","[None, None]",1606,[],[],0
utilmy/zarchive/py2to3/linux.py:pd_createdf,pd_createdf,function,2,4,4,53,13.25,0,0,"['val1', 'col1', 'idx1']","[None, None, None]","[None, 'None', 'None']",1613,[],['pd.DataFrame'],1
utilmy/zarchive/py2to3/linux.py:pd_insertcolumn,pd_insertcolumn,function,12,29,27,179,6.17,1,1,"['df', 'colname', 'vec']","[None, None, None]","[None, None, None]",1618,"["" ''' Vec and Colname must be aligned '''\n""]","['len', 'np.shape', 'range', 'df.insert']",4
utilmy/zarchive/py2to3/linux.py:pd_insertrows,pd_insertrows,function,17,31,30,237,7.65,1,1,"['df', 'rowval', 'index1']","[None, None, None]","[None, None, 'None']",1632,[],"['np.shape', 'np.arange', 'pd.DataFrame', 'range', 'df.append']",5
utilmy/zarchive/py2to3/linux.py:pd_replacevalues,pd_replacevalues,function,11,14,14,101,7.21,1,0,"['df', 'matrix']","[None, None]","[None, None]",1645,"["" ''' Matrix replaces df.values  '''\n""]",['np.shape'],1
utilmy/zarchive/py2to3/linux.py:pd_storeadddf,pd_storeadddf,function,6,15,15,113,7.53,0,1,"['df', 'dfname', ""dbfile='F""]","[None, None, '']","[None, None, ""'F:\\temp_pandas.h5'""]",1655,[],"['pd.HDFStore', 'find', 'store.keys', 'store.append', 'store.close']",5
utilmy/zarchive/py2to3/linux.py:pd_storedumpinfo,pd_storedumpinfo,function,13,29,24,298,10.28,1,0,"[""dbfile='E""]",[''],"[""'E:\\_data\\stock\\intraday_google.h5'""]",1663,[],"['pd.HDFStore', 'store.keys', 'pd.read_hdf', 'extract.append', 'datetime_tostring', 'errsym.append', 'np.array']",7
utilmy/zarchive/py2to3/linux.py:pd_remove_row,pd_remove_row,function,2,2,2,29,14.5,0,0,"['df', 'row_list_index', '45]']","[None, None, None]","[None, '[23', None]",1677,[],['df.drop'],1
utilmy/zarchive/py2to3/linux.py:pd_extract_col_idx_val,pd_extract_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],1680,[],[],0
utilmy/zarchive/py2to3/linux.py:pd_split_col_idx_val,pd_split_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],1684,[],[],0
utilmy/zarchive/py2to3/linux.py:pd_addcolumn,pd_addcolumn,function,10,23,19,190,8.26,1,1,"['df1', 'name1']","[None, None]","[None, ""'new'""]",1688,[],"['len', 'type', 'pd.Series']",3
utilmy/zarchive/py2to3/linux.py:pd_removecolumn,pd_removecolumn,function,2,3,3,23,7.67,0,0,"['df1', 'name1']","[None, None]","[None, None]",1697,[],['df1.drop'],1
utilmy/zarchive/py2to3/linux.py:pd_save_vectopanda,pd_save_vectopanda,function,9,22,19,182,8.27,1,0,"['vv', 'filenameh5)', 'pdf); store.close()filenameh5', ""store_id='data')"", 'store_id)    #from filereturn pdf.values   #to numpy vectorfilein1', 'filename', ""tablen='data')""]","[None, ""  # 'E:\\_data\\_data_outlier.h5'filenameh5)vv); store.append('data'"", None, '', None, None, '']","[None, None, None, ""'data'):  # 'E:\\_data\\_data_outlier.h5'filenameh5"", None, None, ""'data'):""]",1701,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/py2to3/linux.py:pd_load_panda2vec,pd_load_panda2vec,function,9,22,19,182,8.27,1,0,"['filenameh5', ""store_id='data')"", 'store_id)    #from filereturn pdf.values   #to numpy vectorfilein1', 'filename', ""tablen='data')""]","[None, '', None, None, '']","[None, ""'data'):  # 'E:\\_data\\_data_outlier.h5'filenameh5"", None, None, ""'data'):""]",1706,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/py2to3/linux.py:pd_csv_topanda,pd_csv_topanda,function,9,22,19,182,8.27,1,0,"['filein1', 'filename', 'tablen']","[None, None, None]","[None, None, ""'data'""]",1711,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/py2to3/linux.py:pd_getpanda_tonumpy,pd_getpanda_tonumpy,function,6,10,10,92,9.2,0,0,"['filename', 'nsize', 'tablen']","[None, None, None]","[None, None, ""'data'""]",1723,[],['pd.read_hdf'],1
utilmy/zarchive/py2to3/linux.py:pd_getrandom_tonumpy,pd_getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample', 'tablen']","[None, None, None, None]","[None, None, None, ""'data'""]",1728,[],['pd.read_hdf'],1
utilmy/zarchive/py2to3/linux.py:sk_cluster_kmeans,sk_cluster_kmeans,function,21,38,37,375,9.87,1,1,"['x', 'nbcluster', 'isplot']","[None, None, None]","[None, '5', 'True']",1861,[],"['np.std', 'kmeans.fit', 'range', 'plt.plot', 'plt.show']",5
utilmy/zarchive/py2to3/linux.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],1885,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/py2to3/linux.py:date_remove_bdays,date_remove_bdays,function,16,41,28,351,8.56,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",1896,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/py2to3/linux.py:date_add_bdays,date_add_bdays,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",1914,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/py2to3/linux.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",1929,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:datetime_toint,datetime_toint,function,6,15,13,155,10.33,1,1,['datelist1'],[None],[None],1938,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:dateint_todatetime,dateint_todatetime,function,6,15,13,135,9.0,1,1,['datelist1'],[None],[None],1946,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:date_diffindays,date_diffindays,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",1955,[],['dateint_todatetime'],1
utilmy/zarchive/py2to3/linux.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",1960,[],['util.np_findfirst'],1
utilmy/zarchive/py2to3/linux.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],1974,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:date_now,date_now,function,10,18,16,130,7.22,0,1,['i'],[None],['0'],1981,[],"['datetime.now', 'date_add_bdays', 'date_remove_bdays', 'str']",4
utilmy/zarchive/py2to3/linux.py:date_as_float,date_as_float,function,11,28,23,273,9.75,0,1,['dt'],[None],[None],1989,[],"['datetime.datetime', 'isleap', 'timedelta']",3
utilmy/zarchive/py2to3/linux.py:datediff_inyear,datediff_inyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",2001,[],['date_as_float'],1
utilmy/zarchive/py2to3/linux.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",2005,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/py2to3/linux.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],1885,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/py2to3/linux.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",1929,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],1974,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py2to3/linux.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",2048,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/py2to3/linux.py:numexpr_topanda,numexpr_topanda,function,10,28,22,248,8.86,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",2060,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/py2to3/linux.py:textvect_topanda,textvect_topanda,function,2,8,8,70,8.75,0,0,"['vv', 'fileout']","[None, None]","[None, '""""']",2070,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zarchive/py2to3/linux.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",2093,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/linux.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],2101,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/py2to3/linux.py:plotsave,plotsave,function,7,16,16,199,12.44,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",2124,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/py2to3/linux.py:plotshow,plotshow,function,4,9,9,101,11.22,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",2135,[],"['plt.scatter', 'plt.autoscale', 'plt.title', 'plt.show']",4
utilmy/zarchive/py2to3/linux.py:compileVSsolution,compileVSsolution,function,5,33,19,239,7.24,0,4,"['dir1', 'flags1', 'type1', 'compilerdir']","[None, None, None, None]","[None, '""""', '""devenv""', '""""']",2568,[],['os.system'],1
utilmy/zarchive/py2to3/linux.py:VS_start,VS_start,function,18,56,52,881,15.73,0,2,"['self', 'version']","[None, None]","[None, None]",2597,[],"['os.getenv', 'Exception', 'default.append', 'libs.append']",4
utilmy/zarchive/py2to3/linux.py:VS_build,VS_build,function,16,62,54,614,9.9,1,2,"['self', 'lib_to_build']","[None, None]","[None, None]",2632,[],"['print', 'subprocess.Popen', 'process.poll', 'process.communicate']",4
utilmy/zarchive/py2to3/linux.py:set_rc_version,set_rc_version,function,12,43,39,500,11.63,0,0,"['rcfile', 'target_version']","[None, None]","[None, None]",2666,[],"['open', 'f.read', 're.compile', 're.sub', 'f.seek', 'f.write', 'f.truncate']",7
utilmy/zarchive/py2to3/multiprocessfunc.py:multigbm_paralell_func,multigbm_paralell_func,function,34,117,81,913,7.8,1,4,"['nbsimul', 'ww', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price', 'type1', 'strike', 'cp']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, '0', '0', '1']",20,[],"['np.zeros', 'range', 'np.dot', 'np.multiply', 'np.exp', 'np.cumprod', 'np.maximum', 'sum', 'sum1/float']",9
utilmy/zarchive/py2to3/multiprocessfunc.py:func,func,function,6,10,10,56,5.6,1,0,"['val', 'lock']","[None, None]","[None, None]",73,[],"['range', 'time.sleep']",2
utilmy/zarchive/py2to3/multiprocessfunc.py:multigbm_processfast7,multigbm_processfast7,function,24,48,44,419,8.73,3,0,"['nbsimul', 's0', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",150,[],"['range', 'np.dot', 'bm_generator', 'np.exp', 'sum', 'sum1/float']",6
utilmy/zarchive/py2to3/multiprocessfunc.py:bm_generator,bm_generator,function,5,9,8,43,4.78,0,1,"['bm', 'dt', 'n', 'type1']","[None, None, None, None]","[None, None, None, None]",177,[],[],0
utilmy/zarchive/py2to3/multiprocessfunc.py:merge,merge,function,6,20,17,106,5.3,1,1,['d2'],[None],[None],211,[],"['time.sleep', 'd2.keys']",2
utilmy/zarchive/py2to3/multiprocessfunc.py:integratenp2,integratenp2,function,10,29,25,184,6.34,1,0,"['its', 'nchunk']","[None, None]","[None, None]",222,[],"['range', 'ne.evaluate']",2
utilmy/zarchive/py2to3/multiprocessfunc.py:integratenp,integratenp,function,27,77,47,454,5.9,2,0,"['its', 'nchunk']","[None, None]","[None, None]",234,[],"['range', 'ne.evaluate', 'integratenp', 'np.sum', 'float']",5
utilmy/zarchive/py2to3/multiprocessfunc.py:integratene,integratene,function,12,44,38,275,6.25,1,0,['its'],[None],[None],247,[],"['range', 'ne.evaluate', 'float']",3
utilmy/zarchive/py2to3/multiprocessfunc.py:parzen_estimation,parzen_estimation,function,7,30,26,185,6.17,2,1,"['x_samples', 'point_x', 'h']","[None, None, None]","[None, None, None]",268,[],"['np.abs', 'len']",2
utilmy/zarchive/py2to3/multiprocessfunc.py:init2,init2,function,2,4,4,13,3.25,0,0,['d'],[None],[None],282,[],[],0
utilmy/zarchive/py2to3/multiprocessfunc.py:init_global1,init_global1,function,2,2,2,37,18.5,0,0,"['l', 'r']","[None, None]","[None, None]",286,[],[],0
utilmy/zarchive/py2to3/multiprocessfunc.py:np_sin,np_sin,function,2,2,2,19,9.5,0,0,['value'],[None],[None],291,[],['np.sin'],1
utilmy/zarchive/py2to3/multiprocessfunc.py:ne_sin,ne_sin,function,2,2,2,27,13.5,0,0,['x'],[None],[None],294,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/multiprocessfunc.py:res_shared2,res_shared2,function,4,16,14,94,5.88,0,0,[],[],[],297,[],['float'],1
utilmy/zarchive/py2to3/multiprocessfunc.py:list_append,list_append,function,3,4,4,54,13.5,1,0,"['count', 'id', 'out_list']","[None, None, None]","[None, None, None]",261,"['\t""""""Creates an empty list and then appends a random number to the list \'count\' number of times. A CPU-heavy operation!""""""\n']",['range'],1
utilmy/zarchive/py2to3/portfolio.py:data_jpsector,data_jpsector,function,3,4,4,47,11.75,0,0,[],[],[],37,[],['util.load_obj'],1
utilmy/zarchive/py2to3/portfolio.py:date_earningquater,date_earningquater,function,9,103,42,604,5.86,0,5,['t1'],[None],[None],47,[],['datetime.datetime'],1
utilmy/zarchive/py2to3/portfolio.py:date_is_3rdfriday,date_is_3rdfriday,function,4,14,13,67,4.79,0,0,['s'],[None],[None],66,[],"['datetime.strptime', 'd.weekday']",2
utilmy/zarchive/py2to3/portfolio.py:date_option_expiry,date_option_expiry,function,10,50,33,354,7.08,0,2,['date'],[None],[None],71,[],['datetime.datetime'],1
utilmy/zarchive/py2to3/portfolio.py:date_find_kday_fromintradaydate,date_find_kday_fromintradaydate,function,2,3,3,68,22.67,0,0,"['kintraday', 'intradaydate', 'dailydate']","[None, None, None]","[None, None, None]",88,[],['util.np_find'],1
utilmy/zarchive/py2to3/portfolio.py:date_find_kintraday_fromdate,date_find_kintraday_fromdate,function,4,10,10,88,8.8,0,0,"['d1', 'intradaydate1', 'h1', 'm1']","[None, None, None, None]","[None, None, '9', '30']",92,[],"['datetime.datetime', 'util.np_find']",2
utilmy/zarchive/py2to3/portfolio.py:date_find_intradateid,date_find_intradateid,function,8,13,13,96,7.38,1,0,"['datetimelist', 'stringdate']","[None, None]","[None, ""['20160420223000']""]",99,[],"['datestring_todatetime', 'util.np_find', 'str']",3
utilmy/zarchive/py2to3/portfolio.py:datetime_convertzone1_tozone2,datetime_convertzone1_tozone2,function,16,29,25,343,11.83,1,1,"['tt', 'fromzone', 'tozone']","[None, None, None]","[None, ""'Japan'"", ""'US/Eastern'""]",110,[],"['pytz.timezone', 'type', 'tz.localize', 't2.append']",4
utilmy/zarchive/py2to3/portfolio.py:date_extract_dailyopenclosetime,date_extract_dailyopenclosetime,function,23,51,35,431,8.45,2,3,"['spdateref1', 'market']","[None, None]","[None, ""'us'""]",127,[],"['enumerate', 'spdailyopendate.append', 'np.array', 'spdailyclosedate.append']",4
utilmy/zarchive/py2to3/portfolio.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",147,[],['util.np_findfirst'],1
utilmy/zarchive/py2to3/portfolio.py:date_alignfromdateref,date_alignfromdateref,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",162,[],"['range', 'np.float', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:_date_align,_date_align,function,16,42,33,256,6.1,2,2,"['dateref', 'datei', 'tmax', 'closei']","[None, None, None, None]","[None, None, None, None]",187,[],"['np.zeros', 'range', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:date_align,date_align,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",201,"["" ''' #Aligne the price with the same dates date\tyear\tmonth\tday\td\topen\tclose\thigh\tlow\tvolume\taclose '''\n""]","['range', 'np.float', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:min_withposition,min_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],249,[],['min'],1
utilmy/zarchive/py2to3/portfolio.py:max_withposition,max_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],253,[],['max'],1
utilmy/zarchive/py2to3/portfolio.py:_reshape,_reshape,function,2,14,12,68,4.86,0,1,['x'],[None],[None],259,[],"['len', 'np.reshape', 'np.size']",3
utilmy/zarchive/py2to3/portfolio.py:_notnone,_notnone,function,39,211,114,1769,8.38,1,11,"['x)', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5)', 'label', ""'Time'"", ""'Y')"", 'legendloc', 'dpi', 'isband=0) ']","['  return not x is Noneasset', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None, ""('title'"", None, None, '""upper left""', '150', '0) :']",263,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend']",23
utilmy/zarchive/py2to3/portfolio.py:plot_price,plot_price,function,69,272,170,2746,10.1,2,11,"['asset', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None]",267,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend', 'plot_priceintraday', 'np.loadtxt', 'np.unique', 'xdays.append', 'np.hstack', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick']",35
utilmy/zarchive/py2to3/portfolio.py:plot_priceintraday,plot_priceintraday,function,32,59,57,947,16.05,1,0,['data'],[None],[None],346,[],"['np.loadtxt', 'np.unique', 'np.arange', 'xdays.append', 'np.hstack', 'plt.figure', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plt.show']",14
utilmy/zarchive/py2to3/portfolio.py:plot_check,plot_check,function,8,19,19,257,13.53,0,0,"['close', 'tt0i', 'tt1i', 'dateref', 'sym', 'tickperday']","[None, None, None, None, None, None]","[None, '20140102', '20160815', '[]', '[]', '120']",388,[],"['util.find', 'getret_fromquotes', 'price_normalize100', 'plot_price']",4
utilmy/zarchive/py2to3/portfolio.py:plot_pricedate,plot_pricedate,function,18,61,49,534,8.75,1,4,"['date1', 'sym1', 'asset1', 'sym2', 'bsk1', 'verticaldate', 'savename1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None', ""''"", '(10', None]",398,[],"['type', 'datestring_todatetime', 'np.row_stack', 'np.concatenate', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'np.arange', 'int', 'len', 'ax.savefig']",11
utilmy/zarchive/py2to3/portfolio.py:generate_sepvertical,generate_sepvertical,function,9,13,12,149,11.46,0,1,"['asset1', 'tt', 'tmax', 'start', 'datebar']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",480,[],"['np.zeros', 'datestring_todatetime']",2
utilmy/zarchive/py2to3/portfolio.py:save_asset_tofile,save_asset_tofile,function,31,129,87,978,7.58,5,9,"['file1', 'asset1', 'asset2', 'asset3', 'date1', 'title1']","[None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None']",495,[],"['np.shape', 'len', 'np.reshape', 'print', 'np.zeros', 'range', 'int', 'np.row_stack', 'np.savetxt']",9
utilmy/zarchive/py2to3/portfolio.py:load_asset_fromfile,load_asset_fromfile,function,1,4,4,51,12.75,0,0,['file1'],[None],[None],534,[],[],0
utilmy/zarchive/py2to3/portfolio.py:array_todataframe,array_todataframe,function,11,41,27,259,6.32,0,2,"['price', 'symbols', 'date1']","[None, None, None]","[None, 'None', 'None']",538,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/py2to3/portfolio.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],549,[],[],0
utilmy/zarchive/py2to3/portfolio.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],558,[],['float'],1
utilmy/zarchive/py2to3/portfolio.py:isint,isint,function,32,105,61,1036,9.87,0,8,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) )Xmat', 'type1', 'type2=""correl"") ']","[' return isinstance(x', None, None, None, None, None, None, '']","[None, None, None, None, None, None, '""robust""', '""correl"") :']",566,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/py2to3/portfolio.py:correlation_mat,correlation_mat,function,32,105,61,1036,9.87,0,8,"['Xmat', 'type1', 'type2']","[None, None, None]","[None, '""robust""', '""correl""']",573,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/py2to3/portfolio.py:correl_reducebytrigger,correl_reducebytrigger,function,9,22,18,128,5.82,2,1,"['correl2', 'trigger']","[None, None]","[None, None]",621,"[""  ''' Put Zero below trigger  '''\n""]","['correl2.copy', 'range', 'abs']",3
utilmy/zarchive/py2to3/portfolio.py:sk_cov_fromcorrel,sk_cov_fromcorrel,function,8,14,13,115,8.21,0,0,"['correl', 'ret_close1']","[None, None]","[None, None]",633,[],"['volhisto_fromret', 'np.diag', 'np.dot']",3
utilmy/zarchive/py2to3/portfolio.py:cointegration,cointegration,function,18,47,37,385,8.19,0,0,"['x', 'y']","[None, None]","[None, None]",639,"['  """""" Output :\n', '    coint_t :t-statistic of unit-root test on residuals\n', ""    pvalue :   MacKinnon's approximate p-value based on MacKinnon (1994)\n"", '    crit_value : Critical values for the test statistic at the 1 %, 5 %, and 10 %  Signifiance levels.\n', '\n', '    The Null hypothesis is that there is no cointegration, the alt hypothesis is that there is cointegrating relationship. \n', '    If the pvalue is small, below a critical size:  Reject Null Hypothesis -->  Cointegration\n', '           pvalue is high --> No Cointegration    \n', '    \n', '    Significance level, also denoted as alpha or , is the probability of rejecting  the null hypothesis when it is true.\n', '    Probability of incorrectly rejecting a true null hypothesis\n', '\n', '    P=0.05  , At least 23% (and typically close to 50%)\n', '    P=0.01  , At least 7% (and typically close to 15%\n', '\n', '    (-2.9607012342275936,\n', '    0.038730981052330332, 0,\n', '    249,\n', ""    {'1%': -3.4568881317725864,\n"", ""       '10%': -2.5729936189738876,\n"", ""     '5%': -2.8732185133016057},\n"", '      601.96849256295991)\n', '        It can be seen that the calculated test statistic of -2.96 is smaller than the 5% critical value of -2.87, \n', ""        which means that we can reject the null hypothesis that  there isn't a cointegrating relationship at the 5% level.\n"", '  """"""\n']",['np.zeros'],1
utilmy/zarchive/py2to3/portfolio.py:causality_y1_y2,causality_y1_y2,function,10,14,13,153,10.93,0,0,"['price2', 'price1', 'maxlag']","[None, None, None]","[None, None, None]",677,[],[],0
utilmy/zarchive/py2to3/portfolio.py:reg_slope,reg_slope,function,16,24,24,261,10.88,1,0,"['close', 'dateref', 'tlag', 'type1']","[None, None, None, None]","[None, None, None, ""'elasticv'""]",685,[],"['np.ones', 'xrange', 'regression', 'np.arange']",4
utilmy/zarchive/py2to3/portfolio.py:rolling_cointegration,rolling_cointegration,function,13,29,26,280,9.66,0,0,"['x', 'y']","[None, None]","[None, None]",700,[],"['rolling_coint', 'pd.expanding_apply']",2
utilmy/zarchive/py2to3/portfolio.py:regression,regression,function,13,67,32,589,8.79,0,5,"['yreturn', 'xreturn', 'type1']","[None, None, None]","[None, None, '""elasticv""']",719,"["" '''Y = X* reg.coef_  +  reg.intercept_, r2 '''\n""]","['len', 'yreturn.ravel', 'xreturn.reshape', 'reg.fit', 'F', 'reg.score']",6
utilmy/zarchive/py2to3/portfolio.py:regression_fixedsymbolstock,regression_fixedsymbolstock,function,30,59,54,591,10.02,1,1,"['sym', 'ret_close2', 'tsstart', 'tsample', 'ret_spy', 'spyclose', 'regonly']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, 'True']",756,"["" ''' Price, Weight, R2, Error  '''\n""]","['len', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max']",7
utilmy/zarchive/py2to3/portfolio.py:regression_getpricefromww,regression_getpricefromww,function,20,38,30,298,7.84,3,0,"['spyclose', 'ww01', 'regasset01', 'ret_close2', 'tstart', 'tlag']","[None, None, None, None, None, None]","[None, None, None, None, None, '1']",779,[],"['np.copy', 'np.zeros', 'range', 'len']",4
utilmy/zarchive/py2to3/portfolio.py:regression_allstocks_vs_riskfactors,regression_allstocks_vs_riskfactors,function,65,137,113,1351,9.86,2,1,"['symstock', 'pricestock', 'symriskfac', 'priceriskfac', 'nlaglist']","[None, None, None, None, None]","[None, None, None, None, None]",800,"["" '''Make Regression on all stocks ''' \n""]","['np.shape', 'print', 'np.arange', 'np.empty', 'len', 'enumerate', 'getlogret_fromquotes', 'range', 'np.reshape', 'regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",13
utilmy/zarchive/py2to3/portfolio.py:getdiff_fromquotes,getdiff_fromquotes,function,4,6,6,73,12.17,0,0,"['close', 'timelag']","[None, None]","[None, None]",897,[],['np.shape'],1
utilmy/zarchive/py2to3/portfolio.py:getret_fromquotes,getret_fromquotes,function,7,23,17,159,6.91,0,1,"['close', 'timelag']","[None, None]","[None, '1']",901,[],"['np.shape', 'len']",2
utilmy/zarchive/py2to3/portfolio.py:getlogret_fromquotes,getlogret_fromquotes,function,4,7,7,81,11.57,0,0,"['close', 'timelag']","[None, None]","[None, '1']",912,[],"['np.shape', 'np.log']",2
utilmy/zarchive/py2to3/portfolio.py:getprice_fromret,getprice_fromret,function,12,23,21,190,8.26,2,0,"['ret', 'normprice']","[None, None]","[None, '100']",917,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio.py:price_normalize100,price_normalize100,function,16,43,36,292,6.79,1,1,"['ret', 'normprice']","[None, None]","[None, '100']",929,[],"['np.shape', 'len', 'np.reshape', 'np.zeros', 'range', 'np.cumprod']",6
utilmy/zarchive/py2to3/portfolio.py:price_normalize_1d,price_normalize_1d,function,8,22,19,147,6.68,0,0,"['ret', 'normprice', 'dtype1']","[None, None, None]","[None, '100', ' np.float32']",949,[],"['np.empty', 'np.cumprod']",2
utilmy/zarchive/py2to3/portfolio.py:norm_fast,norm_fast,function,7,8,8,85,10.62,0,0,"['y', 'ny']","[None, None]","[None, None]",958,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/portfolio.py:correl_fast,correl_fast,function,8,13,13,116,8.92,0,0,"['xn', 'y', 'nx']","[None, None, None]","[None, None, None]",966,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/portfolio.py:volhisto_fromret,volhisto_fromret,function,2,14,11,168,12.0,0,1,"['retbsk', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",974,[],"['len', 'np.std']",2
utilmy/zarchive/py2to3/portfolio.py:volhisto_fromprice,volhisto_fromprice,function,6,25,17,245,9.8,0,1,"['price', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",981,[],"['len', 'np.shape', 'np.std']",3
utilmy/zarchive/py2to3/portfolio.py:volhistorolling_fromprice,volhistorolling_fromprice,function,16,42,30,318,7.57,2,1,"['price', 'volrange']","[None, None]","[None, None]",990,[],"['np.shape', 'len', 'np.zeros', 'xrange', 'volhisto_fromprice']",5
utilmy/zarchive/py2to3/portfolio.py:rsk_calc_all_TA,rsk_calc_all_TA,function,51,223,105,1352,6.06,0,10,['df'],[None],"[""'panda_dataframe'""]",1009,"[""  '''Add All TA RMI, RSI To the '''\n""]","['ta.MA', 'ta.distance', 'ta.RET', 'ta.RMI', 'ta.STDDEV', 'ta.nbday_low', 'ta.nbday_high', 'ta.RSI', 'ta.qearning_dist', 'ta.optionexpiry_dist', 'linearreg2', 'np.array', 'np.sum', 'util.np_findlocalmin2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",18
utilmy/zarchive/py2to3/portfolio.py:ta_highbandtrend1,ta_highbandtrend1,function,42,170,75,910,5.35,0,11,"['close2', 'type1']","[None, None]","[None, '0']",1091,[],"['linearreg', 'np.array', 'np.sum', 'util.np_findlocalmax2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",8
utilmy/zarchive/py2to3/portfolio.py:pd_transform_asset,pd_transform_asset,function,11,35,27,409,11.69,0,1,"['q0', 'q1', 'type1']","[None, None, None]","[None, None, '""spread""']",1140,[],"['util.pd_date_intersection', 'util.pd_array_todataframe', 'util.pd_insertcol']",3
utilmy/zarchive/py2to3/portfolio.py:calcbasket_table,calcbasket_table,function,25,59,53,477,8.08,1,2,"['wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps']","[None, None, None, None, None, None]","[None, None, '""table""', '""constant""', '1', ' 0.000']",1154,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.mod', 'np.sum']",6
utilmy/zarchive/py2to3/portfolio.py:folio_createvolta_asset,folio_createvolta_asset,function,10,19,19,159,8.37,1,0,"['close', 'vol', 'volrange', 'lev']","[None, None, None, None]","[None, '0.12', '120', '1.0']",1181,[],"['np.zeros_like', 'np.shape', 'xrange', 'folio_volta']",4
utilmy/zarchive/py2to3/portfolio.py:folio_lowcorrelation,folio_lowcorrelation,function,145,431,300,3894,9.03,8,7,"['sym01', 'nstock', 'periodlist', 'dateref', 'close1', 'kbenchmark', 'badlist', 'costbppa', 'showgraph']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, '0.02', 'True']",1189,[],"['ww_selection', 'np.corrcoef', 'np.nan_to_num', 'np.zeros', 'range', 'util.np_sortbycol', 'int', 'np.std', 'np.isnan', 'util.find', 'np.sum', 'stk_select.append', 'volhisto_fromret', 'sum', '1/len', 'getret_fromquotes', 'len', 'np.empty', 'np.ones', 'enumerate', 'calcbasket_table', 'price_normalize100', 'np.column_stack', 'np.zeros_like', 'np.array', 'np.concatenate', 'print', 'str', 'plot_price', 'sym01[int', 'volhisto_fromprice', 'xrange', 'folio_inverseetf']",33
utilmy/zarchive/py2to3/portfolio.py:folio_leverageetf,folio_leverageetf,function,8,23,20,156,6.78,1,0,"['price', 'lev', 'costpa']","[None, None, None]","[None, '1.0', '0.0']",1327,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:folio_inverseetf,folio_inverseetf,function,8,18,18,151,8.39,1,0,"['price', 'costpa']","[None, None]","[None, '0.0']",1336,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:folio_longshort_unit,folio_longshort_unit,function,59,240,112,1594,6.64,2,7,"['long1', 'short1', 'ww', '-1]', 'costpa', 'tlag', 'istable', 'wwschedule']","[None, None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1', '[]']",1345,[],"['len', 'np.zeros', 'xrange', 'np.mod', 'folio_longshort_unitfixed']",5
utilmy/zarchive/py2to3/portfolio.py:folio_longshort_unitfixed,folio_longshort_unitfixed,function,43,111,73,719,6.48,1,3,"['long1', 'short1', 'nn', '-1]', 'costpa', 'tlag', 'istable']","[None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1']",1386,[],"['len', 'np.zeros', 'xrange', 'np.mod']",4
utilmy/zarchive/py2to3/portfolio.py:folio_longshort_pct,folio_longshort_pct,function,8,21,20,189,9.0,1,0,"['long1', 'short1', 'ww', '-1]', 'costpa']","[None, None, None, None, None]","[None, None, '[1', None, '0.0']",1424,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio.py:folio_histogram,folio_histogram,function,13,75,41,914,12.19,0,0,['close'],[None],[None],1432,[],"['getret_fromquotes', 'plt.subplots', 'np.ones_like', 'ax2.hist', 'ax2.set_title', 'ax2.set_xlabel', 'ax2.set_ylabel', 'ax2.axvline', 'plt.show', 'print']",10
utilmy/zarchive/py2to3/portfolio.py:folio_voltarget,folio_voltarget,function,2,6,6,61,10.17,0,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1460,[],['folio_volta'],1
utilmy/zarchive/py2to3/portfolio.py:folio_volta,folio_volta,function,54,197,112,1663,8.44,2,8,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1464,[],"['folio_volta', 'len', 'np.shape', 'np.zeros', 'range', 'np.std', 'util.findhigher', 'max', 'min', 'folio_volta2', 'np.abs']",11
utilmy/zarchive/py2to3/portfolio.py:folio_volta2,folio_volta2,function,29,61,54,514,8.43,1,2,"['bsk', 'riskind', 'par', 'targetvol', 'volrange', 'cap', 'floor', 'costbp']","[None, None, None, None, None, None, None, None]","[None, None, None, '0.11', ' 90', '1.5', '0.0', '0.0005']",1503,[],"['np.shape', 'np.zeros', 'range', 'np.std', 'max', 'min', 'np.abs']",7
utilmy/zarchive/py2to3/portfolio.py:folio_fixedunitprice,folio_fixedunitprice,function,13,36,33,221,6.14,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1528,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio.py:folio_fixedweightprice,folio_fixedweightprice,function,13,36,33,225,6.25,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1542,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio.py:folio_fixedweightret,folio_fixedweightret,function,13,31,28,193,6.23,2,0,"['ret', 'fixedww']","[None, None]","[None, None]",1554,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio.py:folio_cost_turnover,folio_cost_turnover,function,26,88,71,825,9.38,1,1,"['wwall', 'bsk', 'dateref', 'costbp']","[None, None, None, None]","[None, None, None, None]",1567,[],"['len', 'np.zeros', 'xrange', 'np.sum', 'plot_price', 'date1=dateint_tostring']",6
utilmy/zarchive/py2to3/portfolio.py:folio_riskpa,folio_riskpa,function,20,52,40,422,8.12,2,0,"['ret', 'targetvol', 'volrange', 'cap']","[None, None, None, None]","[None, '0.1', '90', '1.0']",1597,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.sum', 'np.std', 'min', 'list']",8
utilmy/zarchive/py2to3/portfolio.py:folio_perfreport_schedule,folio_perfreport_schedule,function,14,20,19,189,9.45,1,0,"['sym', 'dateref', 'close', 'wwind', 't0', 'scheduleperiod']","[None, None, None, None, None, None]","[None, None, None, None, None, '""1monthend""']",1911,[],"['np.shape', 'generate_schedule', 'np.zeros', 'enumerate']",4
utilmy/zarchive/py2to3/portfolio.py:folio_concenfactor2,folio_concenfactor2,function,7,12,12,103,8.58,0,0,"['ww', 'masset']","[None, None]","[None, '12']",2211,[],"['getweight', 'np.sum', 'np.mean']",3
utilmy/zarchive/py2to3/portfolio.py:calcbasket_objext,calcbasket_objext,function,50,203,96,1094,5.39,1,7,"['RETURN', 'TMAX', 'riskind_i', 'wwmat', 'wwasset0', 'ww0', 'nbrange', 'criteria']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",2229,[],"['xrange', 'np.sum', 'math.sqrt']",3
utilmy/zarchive/py2to3/portfolio.py:calc_ranktable,calc_ranktable,function,20,44,41,351,7.98,1,0,"['close2', 'symjp1', 'nlag', 'refindex', 'funeval', 'funargs']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",3639,[],"['np.zeros', 'getlogret_fromquotes', 'enumerate', 'funeval', 'util.np_sortbycolumn']",5
utilmy/zarchive/py2to3/portfolio.py:similarity_correl,similarity_correl,function,7,10,9,88,8.8,0,0,"['ret_close2', 'funargs']","[None, None]","[None, None]",3659,[],['correlation_mat'],1
utilmy/zarchive/py2to3/portfolio.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3714,[],['np_distance_l1'],1
utilmy/zarchive/py2to3/portfolio.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3720,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/py2to3/portfolio.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3714,[],['np_distance_l1'],1
utilmy/zarchive/py2to3/portfolio.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3720,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/py2to3/portfolio.py:get,get,function,11,44,26,436,9.91,0,1,"['close', 'timelag']","[None, None]","[None, None]",4085,"['    """"""Return dataframe of requested dataset from Quandl.\n', '    :param dataset: str or list, depending on single dataset usage or multiset usage\n', '            Dataset codes are available on the Quandl website\n', '    :param str api_key: Downloads are limited to 50 unless api_key is specified\n', '    :param str start_date, end_date: Optional datefilers, otherwise entire dataset is returned\n', '    :param str collapse: Options are daily, weekly, monthly, quarterly, annual\n', '    :param str transform: options are diff, rdiff, cumul, and normalize\n', '    :param int rows: Number of rows which will be returned\n', '    :param str order: options are asc, desc. Default: `asc`\n', '    :param str returns: specify what format you wish your dataset returned as,\n', '        either `numpy` for a numpy ndarray or `pandas`. Default: `pandas`\n', '    :returns: :class:`pandas.DataFrame` or :class:`numpy.ndarray`\n', '    Any other `kwargs` passed to `get` are sent as field/value params to Quandl\n', '    with no interference.\n', '\n', ""'''\n"", '\n', '\n', '\n', '#--------------------Import data from Yahoo --------------------------------------------------\n', 'def imp_yahoo_getquotes(symbols, start=""20150101"", end=""20160101"", type1=1):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', '# symbols = np.array(symbol1)\n', ' quotes= []; errorlist=[]; correctlist=[]\n', ' for i, symbol in enumerate(symbols) :\n', '   # if np.mod(i,400) ==0 and i != 0 :\n', ""     # print('Waiting 30s'); time.sleep(30)\n"", '   try:   \n', '     array1= quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '     df= pd.DataFrame.from_records(array1)\n', '     quotes.append(df)\n', '     correctlist.append(symbol)\n', '   except :\n', '       errorlist.append(symbol)\n', ""       print('Err: '+symbol)\n"", ' #quotes = [quotes_historical_yahoo(symbol, d1, d2, asobject=True)  for symbol in symbols]\n', ' #print(errorlist) \n', ' if type1==1 :  return quotes, correctlist\n', ' else: return quotes, correctlist, errorlist  \n', '\n', '              \n', '#Find error in Ticker import\n', 'def imp_yahoo_geterrorticker(symbols, start=""20150101"", end=""20160101""):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', ' errorlist= []\n', ' for symbol in symbols :\n', '   try :  \n', '     quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '   except :\n', '     errorlist.append(symbol)\n', '     print(symbol)       \n', ' return errorlist\n', ' \n', ""'''\n"", ""symbols0= ['KHC', 'PYPL', 'HPE', 'BXLT', 'SYF', 'WLTW', 'CFG', 'BF-B', 'WRK']\n"", '\n', '#Show list of ticker in error\n', 'import_errorticker(symbols0,""20110101"",""20150601""  )\n', ""'''\n"", '\n', '\n', 'def imp_yahoo_financials_url(ticker_symbol, statement=""is"", quarterly=False):\n', '    if statement == ""is"" or statement == ""bs"" or statement == ""cf"":\n', '        url = ""https://finance.yahoo.com/q/"" + statement + ""?s="" + ticker_symbol\n', '        if not quarterly:\n', '            url += ""&annual""; return BeautifulSoup(requests.get(url).text, ""html.parser"")\n', '    return sys.exit(""Invalid financial statement code \'"" + statement + ""\' passed."")\n', '\n', 'def imp_yahoo_periodic_figure(soup, yahoo_figure):\n', '    values = []; pattern = re.compile(yahoo_figure)\n', '\n', '    title = soup.find(""strong"", text=pattern)    # works for the figures printed in bold\n', '    if title:  row = title.parent.parent\n', '    else:\n', '        title = soup.find(""td"", text=pattern)    # works for any other available figure\n', '        if title:  row = title.parent\n', '        else:      sys.exit(""Invalid figure \'"" + yahoo_figure + ""\' passed."")\n', '\n', '    cells = row.find_all(""td"")[1:]    # exclude the <td> with figure name\n', '    for cell in cells:\n', '        if cell.text.strip() != yahoo_figure:    # needed because some figures are indented\n', '            str_value = cell.text.strip().replace("","", """").replace(""("", ""-"").replace("")"", """")\n', '            if str_value == ""-"": str_value = 0\n', '            value = int(str_value) * 1000\n', '            values.append(value)\n', '\n', '    return values\n', '    \n', '# print(imp_yahoo_periodic(imp_yahoo_financials_url(""AAPL"", ""is""), ""Income Tax Expense""))\n', '\n', ' \n', '\n', '#--------------------Import Quotes Google  ------------------------------------------\n', 'import requests.packages.urllib3\n', 'requests.packages.urllib3.disable_warnings()\n', 'import urllib, os\n', '\n', ""dirstockcsv= 'E:\\_data\\stock\\csv'\n"", '\n', 'def imp_googleIntradayQuote(symbol, freqsec=300, nday=5):\n', ""    ''' Intraday quotes from google. Specify interval seconds and number of days\n"", '    http://www.google.com/finance/getprices?q=7261&i=300&p=3d&f=d,o,h,l,c,v\n', ""    '''\n"", '    url =""http://www.google.com/finance/getprices?q={0}"".format(symbol)\n', '    url +=""&i={0}&p={1}d&f=d,o,h,l,c,v"".format(freqsec, nday)\n', '    try :      \n', '       resp= requests.post(url)\n', '       csv= resp.text\n', '       csv= csv.splitlines()\n', '    except :\n', ""       print('Err Intaday '+symbol)\n"", '\n', '    if len(csv) < 9 :\n', ""      print 'Using Daily',\n"", '\n', ""      url='http://www.google.com/finance/historical?q='+symbol+'&i='+str(freqsec)+'&p=3d&f=d,o,h,l,c,v&output=csv'\n"", '      csv = urllib.urlopen(url).readlines()\n', '      csv.reverse()\n', '      q=[]\n', '      for bar in xrange(0,len(csv)-1):\n', ""        ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '        if isfloat(open_) and isfloat(high) :\n', '          open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""          dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '          q.append([dt,open_,high,low,close,volume])\n', ""      df= util.pd_array_todataframe(q, ['date','open','high','low','close','volume'])\n"", '      return df\n', '\n', '\n', '    # print(csv)\n', '    qq=[]\n', '    for bar in xrange(7,len(csv)):\n', ""      if csv[bar].count(',')!=5: continue\n"", ""      offset,close,high,low,open_,volume = csv[bar].split(',')\n"", '      \n', ""      if offset[0]=='a':\n"", '        day = float(offset[1:])\n', '        offset = 0\n', '      else:\n', '        offset = float(offset)\n', '      open_, high, low, close = [float(x) for x in [open_,high,low,close]]\n', '      dt = datetime.datetime.fromtimestamp(day + (freqsec * offset))\n', '      #print (dt,open_,high,low,close,volume)\n', '      qq.append([dt,open_,high,low,close,volume])\n', ""    df= util.pd_array_todataframe(qq, ['date','open','high','low','close','volume'])\n"", '    return df\n', '\n', ""def imp_googleIntradayQuoteSave(symbols=['NKE'], freqsec=300, nday=2000, dircsv='', dbname=''):\n"", "" ''' Save Under various format: csv / db / output in Dataframe '''\n"", ' if isinstance(symbols, str) : symbols= [symbols]\n', ' symout,qlist, sym_error= [], [], []\n', ' for sym in symbols:\n', '   try :\n', '    q = imp_googleIntradayQuote(sym, freqsec, nday)  #interval, timeframe\n', '    print sym,\n', ""    sym= sym.replace(':', '_')\n"", '\n', ""    if dircsv != '' :\n"", '      if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""      start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""      file1= dircsv+ '\\\\' + sym + '_' + str(start1) + '_' + str(freqsec) + '_' + str(nday) + '.csv'\n"", '\n', ""      q= util.pd_addcol(q, 'symbol'); q['symbol']= sym\n"", '      q.to_csv(file1, index=False)\n', '\n', ""    elif dbname != '' :\n"", '      import sqlalchemy as sql\n', '      dbcon= sql.create_engine(dbname)\n', '      if interv_sec== 300 : # 5mins\n', ""        q.to_sql('q5min', dbcon)\n"", '\n', '    else :\n', '      qlist.append(q);   symout.append(sym)\n', '   except:\n', ""      print('Error:'+sym, )\n"", '      sym_error.append(sym)\n', '\n', ' return qlist, symout, sym_error\n', '\n', ""def imp_googleQuote(symbol, start_date='20160101', end_date= '20160101') : # datetime.date.today().isoformat()):\n"", ""    ''' Daily quotes from google. Date format='yyyymmdd' '''\n"", '    symbol = symbol.upper()\n', '    start = datetime.date(int(start_date[0:4]),int(start_date[4:6]),int(start_date[6:8]))\n', '    end =   datetime.date(int(end_date[0:4]),int(end_date[4:6]),int(end_date[6:8]))\n', '    url =""http://www.google.com/finance/historical?q={0}"".format(symbol)\n', '    url +=""&startdate={0}&enddate={1}&output=csv"".format( start.strftime(\'%b %d, %Y\'),end.strftime(\'%b %d, %Y\'))\n', '    csv = urllib.urlopen(url).readlines()\n', '    csv.reverse()\n', '    # print(url)\n', '    q=[]\n', '    for bar in xrange(0,len(csv)-1):\n', ""      ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '      if isfloat(open_) and isfloat(high) :\n', '        open_,high,low,close = [float(x) for x in [open_, high, low, close]  ]\n', ""        dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '        q.append([dt,open_,high,low,close,volume])\n', '    return  pd.DataFrame(np.array(q), columns= [""date"",""open"",""high"",""low"",""Close"",""volume""])\n', '\n', '\n', 'def imp_googleQuoteSave(symbols, date1, date2, dircsv):\n', ' if isinstance(symbols, str) : symbols= [symbols]\n', ' for sym in symbols:\n', '   try :\n', '      q = imp_googleQuote(sym, date1, date2)   #interval, timeframe\n', ""   except: print('Error:'+symbol)\n"", '\n', ""   sym= sym.replace(':', '_')\n"", '\n', ""   if dircsv != '' :\n"", '     if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""     start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""     file1= dircsv+ '\\\\'+ name1+'_'+ start1 +'_'+ str(date2) +'.csv'\n"", '     q.to_csv(file1)\n', '\n', ""   if dbname != '' :\n"", '     import sqlalchemy as sql\n', '     dbcon= sql.create_engine(dbname)\n', '     if interv_sec== 300 : # 5mins\n', ""       q.to_sql('q5min', dbcon)\n"", '\n', '\n', '\n', ""def imp_csv_dbupdate(indir='E:/_data/stock/intraday/intraday_google_usetf2.h5',\n"", ""                     outdir='E:/_data/stock/intraday/q5min/us/etf/', filelist=[], intype='csv',\n"", ""                     refcols=['date', 'open', 'high', 'low', 'close', 'volume', 'symbol']) :\n"", '\n', '  for file1 in filelist :\n', ""    sym=  file1[:file1.find('_')]  #Clean Up name\n"", '    print sym,\n', ""    outfile= outdir+'/'+sym+'.csv'\n"", '    if os.path.isfile(outfile) :\n', ""      df0= imp_csv_toext(file1=outfile, fromzone='Japan', tozone='UTC', header=0, cols=refcols)\n"", '    else :\n', '      df0= None\n', '\n', ""    if intype== 'hdfs':\n"", '      df1= imp_hdfs_getquote(indir, sym)\n', '      if isinstance(df1, float) : df1= None\n', '\n', ""    if intype=='csv' :\n"", ""      infile= indir+'/'+ file1   #csv\n"", ""      df1= imp_csv_toext(file1=infile, header=0, cols=refcols, fromzone='Japan', tozone='UTC')\n"", '\n', '    if df1 is not None :\n', '       if df0 is not None  : df1= imp_pd_merge(df1[refcols], df0[refcols])\n', '       # return outfile, df1\n', '       df1[refcols].to_csv(outfile, index=False)\n', '\n', '\n', '#####################################################################################\n', 'def imp_numpy_close_fromdb(dbname=\'/aaserialize/store/yahoo.db\', table1=\'\', symlist=[], t0=20010101, t1=20010101, priceid=""close"", batchsize= 400, maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from DB SQL"")\n', ' import data.hist_data_storage as yhh\n', ' dstore= yhh.dailyDataStore(dbname)\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', '\n', "" dateref0= dstore.get_histo(['SPY'], table1='daily_us_etf', start1=str(t0), end1=str(t1),  split_df=0).date.values\n"", ' \n', ' k=0; symfull=[];   i=0\n', ' nsym= len(symlist); nbatch= int(nsym / batchsize)+1\n', ' for j in xrange(0, nbatch) : \n', '      qlist, sym= dstore.get_histo(symlist[i:min(nsym,i+batchsize)], table1=table1, start1=str(t0), end1=str(t1),  split_df=1)\n', '\n', '      #print(""batch: ""+str(j), len(qlist), len(qlist[0].index) )\n', '      #for k,q in enumerate(qlist) :print sym[k], len(q.index)\n', '      i= i + batchsize\n', '      symfull= np.concatenate((symfull,sym))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)\n', '      print(""batch: ""+str(j), len(sym),dateref[0],dateref[-1] )\n', '      qlist=None; sym=None\n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[k:k+masset,0:tmax] = close\n', '      k=k+ masset\n', '\n', ' maxasset= k\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', 'def imp_numpy_close_fromhdfs(dbfile, symlist=[], t0=20010101, t1=20010101, priceid=""close"", maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from Pandas"")\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', ' store = pd.HDFStore(dbfile)\n', ' \n', "" df= store.select('SPY')\n"", ' df= df[(df.date >= t0) & (df.date <= t1 )]\n', ' dateref0= df.date.values\n', ' \n', ' k=0; symfull=[]; qlist=[]; sym=[]; tmax= 2000\n', ' for j, symbol in enumerate(store.keys()):\n', '  symbol=  symbol[1:]\n', '\n', '  if len(symlist)==0  or  util.find(symbol,symlist) > -1 : \n', '   #print symbol, util.find(symbol,symlist) \n', '   df= store.select(symbol) \n', '   if t0 !=t1 :     df= df[(df.date >= t0) & (df.date <= t1 )]\n', '   \n', '   qlist.append(df);   sym.append(symbol)\n', '   if np.mod(j+1, 401) == 0 :\n', '      print(""batch: ""+str(j))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)   \n', '      print len(sym),dateref[0],dateref[-1] \n', '      symfull= symfull+sym\n', '      qlist=[]; sym=[]\n', ' \n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[(k):(k+masset),0:tmax] = close\n', '      k=k+ masset   \n', '     \n', ' if len(qlist) > 0:\n', '  # return qlist, qlist[0] ,  qlist[1] \n', '   close,dateref= date_align(qlist,type1=priceid)   \n', '   print len(sym),dateref[0],dateref[-1] \n', '   symfull= symfull+sym\n', '   masset,tmax= np.shape(close);\n', '   close2[(k):(k+masset),0:tmax] = close\n', ' \n', ' maxasset= k+masset\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', '\n', ""def imp_sql_getquotes(stocklist01, dbname='sqlite:///aaserialize/store/yahoo.db', start1=20150101, end1=20160616, table1='daily_us_stock'):\n"", '    import data.hist_data_storage as yhh\n', '    dstore = yhh.dailyDataStore(dbname)\n', '    qlist, sym= dstore.get_histo(stocklist01, table1=table1,  start1=start1, end1=end1, split_df=1)\n', '    return qlist, sym\n', '\n', ""def imp_txt_getquotes(stocklist01, filedir='E:/_data/stock/daily/20160610/jp', startdate=20150101, endate=20160616):\n"", ' liststockfile= util.listallfile(filedir, ""*.txt"", dirlevel=5)\n', ' #print liststockfile\n', ' if len(np.shape(liststockfile)) > 1 :\n', '  liststockname=[ x.split(""."")[0] for x in liststockfile[:,0] ]\n', '#  for k in range(0, np.shape(liststockfile)[0]):  liststockname.append( (liststockfile[k,0])[0:4])   \n', '   \n', ' else: \n', '  stk0= liststockfile[0]; #stk2= liststockfile[2]\n', '#  liststockname=[ x[0:4] for x in stk0 ]\n', '  liststockname=[ x for x in stk0 ]\n', '\n', '#  liststockname=[]\n', '#  for k in range(0, len(stk0)):  liststockname.append( (stk0[k])[0:4])\n', ' \n', ' quotes=[]\n', ' print liststockname\n', ' for sym in stocklist01:\n', '   kstock= util.np_findfirst(sym, liststockname)\n', '   if kstock == -1 :\n', ""     print('Not Found '+sym)\n"", '   else :\n', '     df= pd.read_csv(liststockfile[kstock][2])\n', ""     df.columns = ['date', 'open', 'high','low','close', 'volume', 'openint']  #Change Column Name\n"", '     df2= df[(df.date > startdate  )& ( df.date   < endate )] # Filter by date\n', '     quotes.append(df2)\n', '  \n', ' return quotes \n', '\n', '\n', 'def imp_csv_getname(name1, date1, inter, tframe):\n', "" file1= dirstockcsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", ' return file1\n', '\n', '\n', ""def imp_csv_toext(file1='SPY.csv', outputfile='.h5', fromzone='Japan', tozone='UTC', header=None,\n"", ""                  cols=['date', 'time','open','high','low','close','volume', 'symbol'], coldate=[0]):\n"", ""  ''' cols: column name,  coldate: position of date column   '''\n"", '  from dateutil import parser\n', '\n', '  if os.path.getsize(file1)> 500 :\n', ""   df = pd.read_csv(file1,sep=',',header=header)  # date_parser=dateparse)  # parse_dates={'date': [] },\n"", '   df.date= [ parser.parse(x) for x in  df.date]\n', '\n', ""   #if util.find('symbol', df.columns.values) < 0 :\n"", ""     #df= util.pd_addcol(df, 'symbol')\n"", ""     #df['symbol']= sym\n"", '\n', ""   type1= outputfile[outputfile.find('.'):]\n"", '\n', ""   if outputfile=='':\n"", '     # df.columns = [  x.lower() for x in df.columns.values ]\n', ""     # df.columns = ['date', 'symbol','open','high','low','close','volume']\n"", '     df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""     df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""     df.columns = ['date', 'open','high','low','close','volume', 'symbol']\n"", '     return df[cols]\n', '\n', ""   if type1=='csv' :\n"", ""     df[cols].to_csv(outputfile , index=False)  # , compression='gzip' )\n"", '\n', ""   if type1== 'h5' :\n"", ""      # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '      dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '      # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '      # df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '      # df.date= [x.to_datetime() for x in  df.date]\n', '\n', '      df.drop(df.columns[[0]], axis=1, inplace=True)\n', '      print filenameh5\n', ""      if util.find('symbol', df.columns.values) < 0 :\n"", ""         df= util.pd_addcol(df, 'symbol'); df['symbol']= dfname\n"", '      store = pd.HDFStore(outputfile); store.append(dfname, df);  store.close()\n', '\n', '\n', '\n', ""def imp_hdfs_db_updatefromcsv(dircsv, filepd=r'E:\\_data\\stock\\intraday_google.h5', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= filepd + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2, name1, fromtimezone, tozone)\n', '\n', ""def imp_hdfs_db_dumpinfo(dbfile='E:\\_data\\stock\\intraday_google.h5'):\n"", '  store = pd.HDFStore(dbfile)\n', '  extract=[]; errsym=[]\n', '  for symbol in store.keys():\n', '     try:\n', '       df= pd.read_hdf(dbfile, symbol)\n', ""       t0= df['date'].values[0]\n"", ""       t1= df['date'].values[-1]\n"", '\n', '       extract.append([symbol[1:], df.shape[1],   df.shape[0], t0, t1 ])\n', '\n', '     except: errsym.append(symbol)\n', '  return np.array(extract), errsym\n', '\n', 'def imp_hdfs_mergedb(filepdfrom, filepdto) :\n', '  store0 = pd.HDFStore(filepdfrom)\n', '  store1 = pd.HDFStore(filepdto)\n', '\n', '  for symbol in store0.keys():\n', '    qq= imp_hdfs_getquote(filepdfrom, symbol)\n', '    store1.append(symbol, qq)\n', '\n', '    qq= imp_hdfs_getquote(filepdto, symbol)\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    print(symbol)\n', '  store0.close(); store1.close()\n', '\n', ""def imp_hdfs_storecopy(hdfs1='F:/usstock8.h5', hdfs2='F:/usstock8.h5'):\n"", ' store = pd.HDFStore(hdfs1);  store2 = pd.HDFStore(hdfs2)\n', ' for symbol in store.keys() :\n', '   df= imp_hdfs_getquote(hdfs1, symbol)\n', '   symbol= symbol[1:].replace(""-"",""_"")\n', '   store2.append(symbol, df, data_columns=True)\n', ' store.close(); store2.close()\n', '\n', 'def imp_hdfs_getquote(filenameh5, dfname=""data""):\n', '  try: return  pd.read_hdf(filenameh5, dfname)\n', '  except: return -1.0;\n', '\n', ""def imp_hdfs_getListquote(symbols, close1='close', start='12/18/2015 00:00:00+00:00',\n"", ""                          end='3/1/2016 00:00:00+00:00', freq='0d0h10min', filepd= 'E:\\_data\\stock\\intraday_google.h5',\n"", ""                          tozone='Japan', fillna=True, interpo=True):\n"", '\n', ' datefilter= pd.date_range(start=start, end=end, freq= freq,tz=tozone).values\n', '\n', ' errorsym=[]; quotes=[]; correctsym=[]\n', ' for symbol in symbols:  # Issue Not same size\n', '   qq= imp_hdfs_getquote(filepd, symbol)\n', '\n', '   if type(qq)==np.float :  # Error qq=-1\n', '        errorsym.append(symbol)\n', '   else:\n', ""       qq.columns = ['date', 'symbol','open','high','low','close','volume']\n"", ""       qq= qq[qq['date'].isin(datefilter)]   #Only date in the range\n"", ""       #qq= qq.drop_duplicates(cols='date', take_last=True)\n"", ""       #  qq= qq.sort('date', asc=True)\n"", '\n', '       #print qq.date.values[0]\n', ""       if fillna : qq= qq.fillna(method='backfill')\n"", '       if interpo : qq= qq.interpolate()\n', '       quotes.append(qq)\n', '       correctsym.append(symbol)\n', '\n', ' datefilter= datenumpy_todatetime(datefilter)\n', ' return quotes,datefilter, correctsym,   errorsym\n', '\n', '\n', ""def imp_hdfs_removeDuplicate(filepd='E:\\_data\\stock\\intraday_google.h5') :\n"", '  #-------Clean by removing duplicate-------------------------------------------------\n', '  store = pd.HDFStore(filepd)\n', '  for symbol in store.keys():\n', '    #qq= imp_hdfs_getquote(filepd, symbol);\n', '    qq= store.select(symbol[1:])\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    qq.index = list(np.arange(0,len(qq.index)))\n', '\n', '    store.remove(symbol); store.append(symbol, qq);\n', '  store.close()\n', '\n', '\n', '\n', ""def imp_pd_tohdfs(sym, qqlist, filenameh5, fromzone='Japan', tozone='UTC') :\n"", ""  ''' df list to HDFS '''\n"", '  store = pd.HDFStore(filenameh5);\n', '  for k, df2 in enumerate(qqlist) :\n', '    df= copy.deepcopy(df2)\n', ""    df['date']= datetime_toint(df.date.values)\n"", '\n', ""    symbol= sym[k].replace('-','_')\n"", '    qq= imp_hdfs_getquote(filenameh5, symbol)\n', '    # print symbol, type(qq)\n', '    if type(qq) ==  float or  type(qq) ==  int  :\n', '      store.append(symbol, df)  # , data_columns=True\n', '      # print(symbol + str(df.date.values[-1]))\n', '    else :\n', '      qq= pd.concat([qq, df], ignore_index=True)\n', ""      qq= qq.drop_duplicates(subset='date', keep='last')\n"", ""      qq= qq.sort('date', ascending=1)\n"", '      store.append(symbol, qq)  #Too much space , data_columns=True\n', '      print(symbol + str(qq.date.values[-1]))\n', '\n', '  store.close()\n', '\n', 'def imp_pd_merge(df1, df2) :\n', '  df= pd.concat([df1, df2], axis=0)\n', ""  df= df.drop_duplicates(subset='date', keep='last')\n"", ""  df= df.sort_values(by=['date'], ascending=1)\n"", '  df.index = list(np.arange(0,len(df.index)))\n', '  return df\n', '\n', 'def imp_pd_checkquote(quotes) :\n', ""   for c in quotes: print np.shape(c), c['date'].values[0], c['date'].values[-1]\n"", '\n', 'def imp_pd_getclose(df, datefilter=None):\n', ' if datefilter is  not None :\n', ""    df= df[df['date'].isin(datefilter)]   #Only date in the range\n"", "" df= df.sort('date')\n"", "" close= df.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", ' \n', ' close= np.array(close.values[1:,1:]).astype(np.float)            #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close\n', '\n', 'def imp_pd_cashyield(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  100 * np.cumprod( (1 + np.ones(len(vv)) * 0.005/365.0 ))\n', '     qbond[id1]= pbond\n', '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_yield_tobond(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  1/ np.power(1+ vv*0.01,duration) *100\n', '     qbond[id1]= pbond\n', ""#     print 'ok'\n"", '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_errordate(quotes, dateref):\n', "" ''' Show Symbol in Error when importing '''\n"", ' for i, stock in enumerate(quotes) :\n', '   print(i, symbols1[i],  datetime_tostring(stock[0][0]))\n', ' print(""\\n\\n"")\n', '\n', ' for i, stock in enumerate(quotes) :\n', '   date1= datetime_toint(stock[0][0])\n', '   if date1 != dateref : print(i, symbols1[i],  str(date1))\n', '\n', 'def imp_pd_fxtoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', 'def imp_pd_fxinversetoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(1.0 / q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', ""def imp_pd_filterbydate(df, dtref=None, start='2016-06-06 00:00:00', end='2016-06-14 00:00:00', freq='0d0h05min', timezone='Japan'):\n"", "" ''' df: DateSeries or TimeSeries of Quotes   '''\n"", '\n', ' if type(df) in {pd.core.frame.DataFrame} :  #Data frame version\n', '   if type(dtref)== str:\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', ""   return df[df['date'].isin(dtref)]\n"", ' else :\n', '   if type(dtref)== str:  #Date version\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', '   return df[df.isin(dtref)].values\n', '\n', 'def imp_pd_cleanquote(q):\n', ' col= q.columns.values\n', "" if isinstance(q['date'].values[0] , str) :\n"", ""   q['date']= datetime_todate(datestring_todatetime(q['date'].values))\n"", '\n', ' for kid in col:\n', ""   if kid not in ['date', 'day','month','year'] :\n"", ""      q[kid]= pd.to_numeric(q[kid], errors='coerce').values  #Put NA on string\n"", '\n', "" q= q.fillna(method='pad')\n"", ' return q\n', '\n', 'def imp_pd_divide(q1, q2, funapply):\n', "" close, dateref= date_align([q1,q2], type1='close')\n"", ' m,tt= np.shape(close)\n', '\n', ' q3= util.pd_createdf( np.zeros((tt,len(q1.columns))) ,q1.columns, dateref)\n', "" q3['date']= dateref\n"", "" q3['close']= (close[0,:] / close[1,:])\n"", '\n', ' for kid in q1.columns :\n', ""   if kid not in ['close', 'volume','date','day','month', 'year'] :\n"", '     close, _= date_align([q1,q2], type1=kid)\n', '     q3[kid]= (close[0,:] / close[1,:])\n', ' return q3\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""def imp_quote_csvdir_tofile(dircsv='', outdir1='E:/_data/stock/', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= outdir + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2,  header=True, fromzone=fromtimezone, tozone=tozone)\n', ""'''\n"", '\n', '\n', ""'''\n"", ""close1='Close' ; start='12/18/2015 00:00:00';\n"", ""end='3/1/2016 00:00:00'; freq='1d0h00min';\n"", ""filepd= 'E:\\_data\\stock\\intraday_google.h5'\n"", '\n', 'datefilter= pd.date_range(start=start, end=end,   freq= freq).values\n', '\n', 'symbols, names = np.array(list(symbol_dict.items())).T\n', 'i=0; vv=[]\n', 'for symbol in symbols:  # Issue Not same size\n', '   qq= quote_frompanda(filepd, symbol); i+=1\n', '   if isfloat(qq) :  vv.append(symbol)\n', '   else:\n', ""     if i==1: close = qq[['Datetime']]  #new dataframe    \n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', '     if not tmp.isnull().values.all():\n', ""      close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""      close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', ""close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", ""close= close.sort('Datetime')\n"", ""close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", 'close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', 'close= close[(np.abs(stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', ""'''\n"", 'from datetime import datetime\n', 'from dateutil import tz\n', '\n', ""from_zone = tz.gettz('Japan'); to_zone = tz.gettz('UTC')\n"", '\n', ""date1 = datetime.strptime('2011-01-21 09:00:00', '%Y-%m-%d %H:%M:%S')\n"", 'date1 = date1.replace(tzinfo=from_zone)\n', 'dateutc = date1.astimezone(to_zone)\n', 'date1, dateutc\n', '\n', ""Suppose you have a column 'datetime' with your string, then:\n"", ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\n"", ' combine multiple columns into a single datetime column,\n', ""this merges a 'date' and a 'time' column into a single 'datetime' column:\n"", '\n', ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)\n"", ""'''\n"", '\n', '\n', '#date1 = ""20160302""; inter= 60; tframe=80; name1= ""spy""\n', '#googleIntradayQuoteSave(name1, inter, tframe)\n', '\n', '\n', '\n', 'def ta_mar(close,t,m):  return  100*( np.mean(close[(t-m):(t+1)], axis=0) / close[t] )\n', 'def ta_ma(close,t,m):  return   np.mean(close[(t-m):(t+1)], axis=0)\n', '\n', '\n', '############################################################################\n', '#---------------------Calculate the Statistics         --------------------  \n', 'def calc_statestock(close2, dateref, symfull):\n', ' def sort(x,col,asc): return   util.sortcol(x,col,asc)\n', ' def perf(close,t0,t1):  return  100*( close[:,t1] / close[:,t0] -1)\n', ' def and2(tuple1):  return np.logical_and.reduce(tuple1)\n', ' def mar(close,t,m):  return  100*( np.mean(close[:,(t-m):(t+1)], axis=1) / close[:,t] )\n', ' def ma(close,t,m):  return   np.mean(close[:,(t-m):(t+1)], axis=1)\n', '\n', '\n', ' # a= ma(close2, tmax, 5) / ma(close2, tmax, 50)  \n', '\n', '\n', ' def dd(t) :\n', '  x= util.find(t,dateref)  # 607\n', ""  if x==-1 : print 'Error date not found in dateref '+str(t) ; return np.nan\n"", '  else :  return x\n', '\n', ' def gap(close,t0,t1,lag):   \n', '  ret= getret_fromquotes(close[:,t0:t1],lag)\n', '  rmin= 100*np.amin(ret,axis=1)\n', '  return rmin\n', ' \n', ' #--------------------Size----------------------------------------- \n', ' masset= len(symfull)\n', ' ttmax= util.find(0,close2[0,:])\n', ' if ttmax==-1 : ttmax= np.shape(close2)[1]\n', ' close2= close2[0:masset,0:ttmax]\n', ' m, tmax= masset, ttmax-1\n', ' \n', ' #correl\n', ' #close3= np.array(close2[:,0:ttmax],dtype=np.float16)\n', ' #close2ret= getret_fromquotes(close3)\n', ' #close2ret= np.nan_to_num(close2ret)\n', ' #close2ret= util.np_cleanmatrix(close2ret);  del close3\n', '\n', '##################################################################################\n', '#1: 1d,2:5d,3:10d,4:15d,5:20d,11:50d,12:60d,13:90d,15:1y\n', '#16: YTD,17:From Feb,21: 2015Ret,45: Price,50,51: Min,52,53: Max\n', ' print(""Calcul the Stats "" + str(dateref[-1]))\n', ' stat= np.zeros((2600,200),dtype=np.float16)\n', '\n', ' k=0\n', ' stat[k:(k+m),0]= np.arange(k,k+m)\n', ' stat[k:(k+m),1]=  perf(close2,tmax-1,tmax)  \n', ' stat[k:(k+m),2]=  perf(close2,tmax-5,tmax)  \n', ' stat[k:(k+m),3]=  perf(close2,tmax-10,tmax)  \n', ' stat[k:(k+m),4]=  perf(close2,tmax-15,tmax)  \n', ' stat[k:(k+m),5]=  perf(close2,tmax-20,tmax)  \n', '# stat[k:(k+m),6]=  perf(close2,tmax-25,tmax)  \n', ' stat[k:(k+m),7]=  perf(close2,tmax-30,tmax)  \n', '# stat[k:(k+m),8]=  perf(close2,tmax-35,tmax)  \n', ' stat[k:(k+m),9]=  perf(close2,tmax-40,tmax)  \n', '# stat[k:(k+m),10]=  perf(close2,tmax-45,tmax)  \n', ' stat[k:(k+m),11]=  perf(close2,tmax-50,tmax)  \n', ' stat[k:(k+m),12]=  perf(close2,tmax-60,tmax)  \n', ' stat[k:(k+m),13]=  perf(close2,tmax-90,tmax)  \n', ' stat[k:(k+m),14]=  perf(close2,tmax-120,tmax)  \n', ' stat[k:(k+m),15]=  perf(close2,tmax-250,tmax)  \n', '\n', '\n', '# stat[k:(k+m),16]=  perf(close2, dd(20160105),tmax)   #1Jan 2016\n', '# stat[k:(k+m),17]=  perf(close2, dd(20160222),tmax)   # 22 Feb 2016\n', '# stat[k:(k+m),18]=  perf(close2,dd(20160105),dd(20160222))   # Crash DrawDown\n', ' # stat[k:(k+m),19]=  perf(close2,624,tmax)   #  24 June 2016\n', ' # stat[k:(k+m),20]=  perf(close2,623,625)   #  Crash 24 June 2016\n', ' # stat[k:(k+m),21]=  perf(close2,dd(20151230)-250,dd(20151230))    #2015 Return\n', '\n', ' stat[k:(k+m),22]= gap(close2,tmax-80,tmax,1) #Max 1 days Gap\n', ' stat[k:(k+m),23]= gap(close2,tmax-80,tmax,5) #Max 5 days Gap\n', ' stat[k:(k+m),24]= perf(close2,tmax-2,tmax)  \n', ' stat[k:(k+m),25]= perf(close2,tmax-3,tmax)  \n', ' stat[k:(k+m),26]= perf(close2,tmax-4,tmax)  \n', '\n', ' stat[k:(k+m),27]= perf(close2,tmax-2,tmax-1)   \n', ' stat[k:(k+m),28]= perf(close2,tmax-3,tmax-2)   \n', ' stat[k:(k+m),29]= perf(close2,tmax-4,tmax-3)   \n', ' stat[k:(k+m),30]= perf(close2,tmax-5,tmax-4)\n', ' \n', ' stat[k:(k+m),120]= mar(close2, tmax, 20) \n', ' stat[k:(k+m),121]= mar(close2, tmax, 50) \n', ' stat[k:(k+m),122]= 100*ma(close2, tmax, 5) / ma(close2, tmax, 50)  #OverSold /OverBought\n', ' stat[k:(k+m),123]= mar(close2, tmax, 100)  \n', ' stat[k:(k+m),124]= mar(close2, tmax, 10) \n', '# stat[k:(k+m),35]= 0 \n', '# stat[k:(k+m),36]= 0 \n', '# stat[k:(k+m),37]= 0 \n', '# stat[k:(k+m),38]= 0 \n', '# stat[k:(k+m),39]= 0 \n', '\n', ' # stat[k:(k+m),30]= volume / AvgVol3M\n', ' # stat[k:(k+m),30]= Nbday_to_Earnings\n', ' #Volume/3M AvgVolume\n', ' # stat[k:(k+m),26]=  volume(volume2,tmax-120,tmax)  \n', '\n', ' #==============================================================================\n', ' #-------------- Data Fundamental    -------------------------------------------\n', "" df= util.sql_query(sqlr='SELECT ticker,shortratio,sector1_id, sector2_id, marketcap   FROM stockfundamental ', dburl='/aaserialize/store/finviz.db')\n"", ' npdf= df.values; del df\n', ' npdf0= npdf[:,0]  \n', ' for i in range(0,m):  \n', '   try :\n', '     kid= util.find(symfull[i], npdf0)\n', '     if kid != -1 :\n', '      stat[i,150]=  float(npdf[kid, 1])   # short ratio\n', '      stat[i,151]=  float(npdf[kid, 2])   # sector 1      \n', '      stat[i,152]=  float(npdf[kid, 3])   # sector 2     \n', '      stat[i,153]=  float(npdf[kid, 4] / 100000000.0)   # market Cap    \n', '   except : pass\n', ' del npdf, npdf0\n', '\n', '\n', '#==============================================================================\n', ' ################ Volatility\n', ' stat[k:(k+m),40]= volhisto_fromprice(close2,tmax,20,axis=1)* 100\n', ' stat[k:(k+m),41]= volhisto_fromprice(close2,tmax,60,axis=1)* 100\n', ' stat[k:(k+m),42]= volhisto_fromprice(close2,tmax,252,axis=1)* 100\n', '# stat[k:(k+m),43]= stat[k:(k+m),12] / stat[k:(k+m),41] #Sharpe 3Month\n', '# stat[k:(k+m),44]= stat[k:(k+m),15] / stat[k:(k+m),42] #Sharpe 1Year\n', '\n', ' stat[k:(k+m),45]= close2[:,tmax] #Last Close\n', '\n', '# stat[k:(k+m),46]= 0 \n', '# stat[k:(k+m),47]= 0 \n', '# stat[k:(k+m),48]= 0 \n', '# stat[k:(k+m),49]= 0 \n', '\n', '\n', ' ###############  Technical Indicator\n', ' #Min of last 6 months, Max of last 6months\n', ' for i in range(0,m):\n', '  pp0= stat[i,45]\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-120):tmax])\n', '  stat[i,50]= kmin+(tmax-120);  stat[i,51]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-120):tmax])\n', '  stat[i,52]= kmax+(tmax-120);  stat[i,53]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-10):tmax])\n', '  stat[i,66]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-10):tmax])\n', '  stat[i,67]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-5):tmax])\n', '  stat[i,68]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-5):tmax])\n', '  stat[i,69]= 100*pp0 / pmax\n', '\n', ' del kmax,pmax,i,k  \n', '\n', '\n', ' #Regression from Min Price Time\n', ' for i in range(0,m):\n', '  t0= int(stat[i,50])\n', '  try :\n', '    res= regression(close2[i,t0:tmax ]  ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,54]=  res[2]  #R2\n', '    stat[i,55]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from Max Price Time\n', ' for i in range(0,m):  \n', '  t0= stat[i,52]\n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,56]=  res[2]  #R2\n', '    stat[i,57]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from 5 days ago\n', ' t0= tmax-5\n', ' for i in range(0,m): \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,58]=  res[2]  #R2\n', '    stat[i,59]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', '#Regression from 10 days ago\n', ' t0= tmax-10\n', ' for i in range(0,m):  \n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,60]=  res[2]  #R2\n', '    stat[i,61]=  res[0][0]  #Slope\n', '   except : pass\n', '\n', "" '''\n"", '#Regression from 1 month\n', ' t0= tmax-20   \n', ' for i in range(0,m):\n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,62]=  res[2]  #R2\n', '    stat[i,63]=  res[0][0]  #Slope\n', '   except : pass\n', "" '''\n"", '\n', "" '''\n"", '#Regression from 2 months ago\n', ' t0= tmax-40\n', ' for i in range(0,m):  \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,64]=  res[2]  #R2\n', '    stat[i,65]=  res[0][0]  #Slope\n', '  except : pass\n', "" '''\n"", '\n', '#Nb of Positive days last 5d\n', ' for i in range(0,m):  stat[i,66]=  np_countretsign(close2[i,(tmax-5):tmax])  \n', '\n', '#Nb of Positive days last 10d\n', ' for i in range(0,m):  stat[i,67]=  np_countretsign(close2[i,(tmax-10):tmax])  \n', '\n', '#Nb of Positive days last 20d\n', '# for i in range(0,m):  stat[i,68]=  np_countretsign(close2[i,(tmax-20):tmax])  \n', '\n', '\n', '#Regression from Max Values,200days\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,70]=  res[2]  #R2\n', '    stat[i,71]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmax\n', '\n', '\n', '#Regression from Min Values,200days \n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,72]=  res[2]  #R2\n', '    stat[i,73]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmin\n', '\n', '\n', '#Regression from Max Values,100days\n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,74]=  res[2]  #R2\n', '    stat[i,75]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmax\n', '\n', '\n', '#Regression from Min Values,100days \n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,76]=  res[2]  #R2\n', '    stat[i,77]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmin\n', '\n', '\n', '\n', '# Upside Trend with Higher Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '   vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '   vmax= util.sort(vmax,0,asc=0)\n', '   stat[i,80]=  -1\n', '   if len(vmax) > 1 :\n', '    ss=0\n', '    for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '    if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,80]=  ss  \n', '        stat[i,81]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Upside Trend with Higher High detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '    vmax= util.sort(vmax,0,asc=0)\n', '    stat[i,82]=  -1\n', '    if len(vmax) > 1 :\n', '      ss=0\n', '      for k in range(0,len(vmax)-1):\n', '        if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher high\n', '        else : break;\n', '      if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,82]=  ss  \n', '        stat[i,83]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Downside Trend with lower Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,84]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,84]=  ss  \n', '        stat[i,85]=  vmax[0,0] + t0\n', '\n', '\n', '# Downside Trend  with lower highs detection\n', ' t0= tmax-20*6\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,80]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,86]=  ss    #Nb  of lower high consecutive\n', '        stat[i,87]=  vmax[0,0] + t0\n', '\n', "" print('Higher/Lower Band Support')\n"", '#-----higher band Support / Lower Band Support 120days-------------------------------\n', ' t0= tmax-120\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,90]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,91]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,92]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '    # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1]) \n', '    # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 200days-------------------------------\n', ' t0= tmax-200\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,93]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,94]= 100.0 * stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,95]= 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 300days-------------------------------------\n', ' t0= tmax-300\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,96]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,97]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,98]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', ""  '''\n"", '  # -----higher band Support / Lower Band Support 60days-------------------------------\n', '  t0 = tmax - 60\n', '  for i in range(0, m):\n', '      try:\n', '          res1 = ta_highbandtrend1(close2[i, t0:tmax])\n', '          pmax = (res1.x[0] * (tmax - t0) + res1.x[1])\n', '          stat[i, 99] = 100.0 * stat[i, 45] / pmax  # Higher Band\n', '\n', '          res2 = ta_lowbandtrend1(close2[i, t0:tmax])\n', '          pmin = (res2.x[0] * (tmax - t0) + res2.x[1])\n', '          stat[i, 100] = 100.0 * stat[i, 45] / pmin  # LowerBand\n', '\n', '          stat[i, 101] = 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)  # Price inside Range\n', '\n', '          # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1])\n', '          # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '      except:\n', '          pass\n', ""  '''\n"", '\n', '  #-----Technical Indicator------------------------------------------------\n', '# for i in range(0,m): \n', '#  try :\n', '#   res2=0\n', '   # df= pd.read_hdf(dbfile, symfull[i])\n', '   # stat[i,110]= ta.RMI(close2[i,:])\n', '   # stat[i,111]= 100*close2[i,:] / ta.MA(close2[i,:],20)\n', '   # stat[i,112]= 100*close2[i,:] / ta.MA(close2[i,:],50)   \n', '#  except: pass\n', '\n', '\n', ' return np.array(stat, dtype=np.float16) \n', '\n', '\n', ""'''  \n"", 'i=1964  \n', 'stat= s1\n', 'stat[i, 91]  \n', '\n', 'tt= np.arange(t0, tmax)\n', 'plot_price(close2[i,t0:tmax], (res2.x[0] * (tt-t0) + res2.x[1]) )\n', ""'''\n"", '\n', '  \n', '#------------------- Stock Monitoring Tools ------------------------------------------------\n', ""def monitor_addrecommend(string1, dbname='stock_recommend') :\n"", ' ss= string1.replace(""("","" "").replace(\')\',\' \').replace(\':\',\' \')\n', "" ss= ss.replace('\\t', ' ').replace('\\n', ' ')\n"", ' sl1= ss.split("" "")\n', ' print sl1\n', ' aux= [datestring_toint(util.date_now())]\n', ' symfull= copy.deepcopy(a_us_all)\n', ' for x in sl1:\n', '   if len(x) < 5 :\n', '    if util.find(x,symfull) > 0 :   aux.append(x)\n', '\n', ' if len(aux) >  1 :\n', '  stock_recommend= util.load_obj(dbname)\n', '  stock_recommend.append(aux)\n', '  util.save_obj(stock_recommend,dbname)\n', '  print aux\n', ' return stock_recommend\n', '\n', '\n', '\n', '#################### Finviz  ###############################################################\n', 'from bs4 import BeautifulSoup\n', 'import csv,datetime, requests\n', 'def imp_finviz():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Overview Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=111&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(111) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 10].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 10\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockoverview.csv', 'wb') as csvfile:\n"", ""    overview = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    overview.writeheader()\n', '\n', '    for stock in alldata:\n', '        overview.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10] })\n', '\n', ' print ""Finviz Overview Completed""\n', ' return overview\n', ' \n', '\n', 'def imp_finviz_news():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Performance Start""\n', ' url = ""http://www.finviz.com/quote.ashx?t=intc""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', ' titleslist = soup.find_all(\'a\',{""class"" : ""tab-link-news""})\n', ' return titleslist\n', '\n', '\n', 'def imp_finviz_financials():\n', ' import datetime\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=161&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(161) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 17].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 16].text,stockdata[datalength - 15].text,stockdata[datalength - 14].text,stockdata[datalength - 13].text,stockdata[datalength - 12].text,stockdata[datalength - 11].text,stockdata[datalength - 10].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 17\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockfinancial.csv', 'wb') as csvfile:\n"", ""    financial = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    financial.writeheader()\n', '\n', '    for stock in alldata:\n', '        financial.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10],titlesarray[11] : stock[11],titlesarray[12] : stock[12],titlesarray[13] : stock[13],titlesarray[14] : stock[14],titlesarray[15] : stock[15],titlesarray[16] : stock[16],titlesarray[17] : stock[17] })\n', '\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Completed""\n', '\n', '\n', '\n', 'def get_price2book( symbol ):\n', '   from bs4 import BeautifulSoup as bs\n', '   import urllib as u\n', '   try:\n', ""    \turl = r'http://finviz.com/quote.ashx?t={}'.format(symbol.lower())\n"", '        html = u.request.urlopen(url).read()\n', ""        soup = bs(html, 'lxml')\n"", '        # Change the text below to get a diff metric\n', ""        pb =  soup.find(text = r'P/B')\n"", ""        pb_ = pb.find_next(class_='snapshot-td2').text\n"", ""        print( '{} price to book = {}'.format(symbol, pb_) )\n"", '        return pb_\n', '   except Exception as e:\n', '        print(e)\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ' try:\n', '   q = imp_googleQuote(name1, date1, date2)  #interval, timeframe\n', ""   name1= name1.replace(':','_')\n"", ""   file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(date2) +'.csv'\n"", '   q.write_csv(file1)\n', ' except: print\n', ""'''\n"", '\n', '\n', ""'''\n"", 'def imp_googleQuoteList(symbols, freqsec=300, nday=1, intraday1=True) :\n', ' qlist=[]; sym=[]\n', ' if intraday1:\n', '  for symbol in symbols:\n', '     #try :\n', '        q = imp_googleIntradayQuote(symbol, freqsec, nday)  #interval, timeframe\n', '        qlist.append(q)\n', '        sym.append(symbol)\n', ""     #except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       q = imp_googleQuote(name1, freqsec, num_days)  #interval, timeframe\n', '     except: print(symbol)\n', '\n', ' return qlist, sym\n', ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''        \n"", ""stock_list = ['XOM','AMZN','AAPL','SWKS']\n"", 'p2b_series = pd.Series( index=stock_list )\n', '\n', 'for sym in stock_list:\tp2b_series[sym] = get_price2book(sym)\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", "" # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", ' from dateutil.parser import parse\n', ' if os.path.getsize(file1)> 500 :\n', '  from_zone = tz.gettz(fromzone); tozone = tz.gettz(tozone)\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%m-%d-%Y %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', '  dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '\n', '  # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '  print file1\n', ""  #df = pd.read_csv(file1,sep=',',header=None, parse_dates={'date': [1]}, date_parser=dateparse)\n"", '\n', ""  df = pd.read_csv(file1,sep=',',header=0)\n"", '  #df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '  #df.date= [x.to_datetime() for x in  df.date]\n', '\n', '\n', '  df.drop(df.columns[[0]], axis=1, inplace=True)\n', ""  df= util.pd_addcol(df, 'symbol')\n"", ""  df['symbol']= dfname\n"", '\n', '  print filenameh5\n', ""  df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", ""  df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", '\n', '  # store = pd.HDFStore(filenameh5);\n', '  # store.append(dfname, df);  store.close()\n', ""'''\n"", '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dropcol=[], type1='csv', hasheader=True, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", ' if os.path.getsize(file1)> 500 :\n', '   header= 0 if hasheader else None\n', ""   df = pd.read_csv(file1, sep=',',header=0)\n"", '\n', '   df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""   df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""   df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", '\n', ""   if type1=='csv' :\n"", ""     df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""     if i==1: close = qq[['Datetime']]  #new dataframe\n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', ""     close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""     close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', "" close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", "" close= close.sort('Datetime')\n"", "" close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", '\n', ' close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", 'class Quote(object):\n', ""  DATE_FMT = '%Y-%m-%d';  TIME_FMT = '%H:%M:%S'\n"", '\n', '  def __init__(self):\n', ""    self.symbol = '';    self.exchn=''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', '\n', '  def append(self,dt,open_,high,low,close,volume):\n', '    self.date.append(dt.date())\n', '    self.time.append(dt.time())\n', '    self.open_.append(float(open_))\n', '    self.high.append(float(high))\n', '    self.low.append(float(low))\n', '    self.close.append(float(close))\n', '    self.volume.append(int(volume))\n', '\n', '  def to_csv(self):\n', '    return \'\'.join([""{0},{1},{2},{3:.2f},{4:.2f},{5:.2f},{6:.2f},{7}\\n"".format(self.symbol,\n', ""              self.date[bar].strftime('%Y-%m-%d'),self.time[bar].strftime('%H:%M:%S'),\n"", '              self.open_[bar],self.high[bar],self.low[bar],self.close[bar],self.volume[bar])\n', '              for bar in xrange(len(self.close))])\n', '\n', '  def write_csv(self,filename):\n', ""    with open(filename,'w') as f:\n"", '      txt= self.to_csv()\n', '      f.write(txt)\n', '\n', '  def read_csv(self,filename):\n', ""    self.symbol = ''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', ""    for line in open(filename,'r'):\n"", ""      symbol,ds,ts,open_,high,low,close,volume = line.rstrip().split(',')\n"", '      self.symbol = symbol\n', ""      dt = datetime.datetime.strptime(ds+' '+ts,self.DATE_FMT+' '+self.TIME_FMT)\n"", '      self.append(dt,open_,high,low,close,volume)\n', '    return True\n', '\n', '  def __repr__(self):\n', '    return self.to_csv()\n', ""'''\n"", '\n', ' \n', '\n', ""'''\n"", ""def imp_googleIntradayQuoteSave2(name1, date1, inter, tframe, dircsv='', dbname=''):\n"", ' q = imp_googleIntradayQuote(name1, inter, tframe)  #interval, timeframe\n', "" name1= name1.replace(':','_')\n"", '\n', "" if dircsv != '' :\n"", ""    file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", '    q.to_csv(file1)\n', '\n', "" if dbname != '' :\n"", '    import sqlalchemy as sql\n', '    dbcon= sql.create_engine(dbname)\n', '    if inter== 300 : # 5mins\n', ""      q.to_sql('q5min', dbcon)\n"", '\n', '\n', ""def imp_googleQuoteList_save(symbols, date1, date2, inter=23400, tframe=2000, dircsv='', intraday1=True) :\n"", ' if intraday1:\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleIntradayQuoteSave(symbol, date1, inter, tframe, dircsv)\n', ""     except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleQuoteSave(symbol, date1, date2, dircsv)\n', '     except: print(symbol)\n', ""'''\n"", '\n']","['np.shape', 'getret_fromquotes', 'len', 'getlogret_fromquotes', 'np.log', 'getprice_fromret']",6
utilmy/zarchive/py2to3/portfolio.py:index,index,class,103,300,221,3009,10.03,1,3,[],[],[],1625,[],[],0
utilmy/zarchive/py2to3/portfolio.py:folioCalc,folioCalc,class,125,509,332,4736,9.3,2,17,[],[],[],1924,[],[],0
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator,folioRiskIndicator,class,89,306,215,3180,10.39,1,9,[],[],[],2099,[],[],0
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF,folioOptimizationF,class,280,1291,671,10994,8.52,6,39,[],[],[],2277,[],[],0
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity,searchSimilarity,class,173,497,328,4550,9.15,8,17,[],[],[],3724,[],[],0
utilmy/zarchive/py2to3/portfolio.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1626,[],['date_generatedatetime'],1
utilmy/zarchive/py2to3/portfolio.py:index:close,index:close,method,0,1,1,4,4.0,0,0,['self'],[None],[None],1631,[],[],0
utilmy/zarchive/py2to3/portfolio.py:index:updatehisto,index:updatehisto,method,2,12,11,62,5.17,0,0,['self)'],['  #Download Quotespassself) :'],[None],1634,[],['print'],1
utilmy/zarchive/py2to3/portfolio.py:index:help,index:help,method,2,12,11,62,5.17,0,0,['self'],[None],[None],1638,[],['print'],1
utilmy/zarchive/py2to3/portfolio.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]",['date_generatedatetime'],1
utilmy/zarchive/py2to3/portfolio.py:index:calc_baskettable_pct,index:calc_baskettable_pct,method,37,95,77,782,8.23,1,2,"['self', 'type1', 'showdetail']","[None, None, None]","[None, '""table""', '0']",1703,"[""      '''   Calc Basket Values from Input data '''\n""]","['np.zeros', 'np.sum', 'self._udpate_wwindpct', 'range', 'np.mod', 'self._wwpct_rebal']",6
utilmy/zarchive/py2to3/portfolio.py:index:_wwpct_rebal,index:_wwpct_rebal,method,3,4,3,41,10.25,0,0,"['self', 'wwpct_actual', 't', 'trebal)', '']","[None, None, None, '  # BskUnit', ']np.abs(wwpct_actual/wwpct_th  -1 )) > self.rebal_trigger:']","[None, None, None, ' 1.0  !!!wwpct_th = self.wwasset[trebal', None]",1730,[],[],0
utilmy/zarchive/py2to3/portfolio.py:index:_udpate_wwindpct,index:_udpate_wwindpct,method,11,25,17,224,8.96,0,0,"['self', 't', 'bskt', 'hedgecost', 'wwpct_actual', 'wwpct_th']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",1740,[],[],0
utilmy/zarchive/py2to3/portfolio.py:index:calc_baskettable_unit,index:calc_baskettable_unit,method,0,0,0,0,0.0,0,0,[],[],[],1749,"[""    '''   t           --->  t+1                 ---->   t+2\n"", '            wwactual:    B[t]    -->   B[t+1]   using  w[t+1], B[t] /   S[t]\n', '            wwnew   :    B[t+1]  -->   B[t+2]   using  w[t+2], B[t+1] /   S[t+1]\n', ""    '''\n""]",[],0
utilmy/zarchive/py2to3/portfolio.py:folioCalc:__init__,folioCalc:__init__,method,21,39,37,356,9.13,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1925,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioCalc:set_symclose,folioCalc:set_symclose,method,17,34,33,312,9.18,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1938,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioCalc:setcriteria,folioCalc:setcriteria,method,41,76,71,1046,13.76,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",1947,"[""        ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '            wwtype:     constant / regime /regimExtra\n', '            initperiod: NbOfDays_initial_Risk_Monitoring\n', '            riskid:     spprice/spperf/multi\n', ""        '''\n""]","['np.array', 'len']",2
utilmy/zarchive/py2to3/portfolio.py:folioCalc:_weightcalc_generic,folioCalc:_weightcalc_generic,method,5,35,23,396,11.31,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",1997,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/py2to3/portfolio.py:folioCalc:_weightcalc_regime,folioCalc:_weightcalc_regime,method,10,37,32,272,7.35,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2008,[],"['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/py2to3/portfolio.py:folioCalc:_regimecalc,folioCalc:_regimecalc,method,3,7,6,83,11.86,0,0,"['self', 't', 'wwextra)', 't - 1]self.riskind[0', 't - 1] / self.riskind[0', 't - 1 - self.nbrange] - 1if self.riskid == ""multi""']","[None, None, '  # Risk Indicatorif self.riskid ', None, None, '']","[None, None, '= ""spprice"":   return self.riskind[0', None, None, '= ""multi"":']",2018,[],['self._mapping_calc_risk'],1
utilmy/zarchive/py2to3/portfolio.py:folioCalc:_weightcalc_constant,folioCalc:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2027,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio.py:folioCalc:getweight,folioCalc:getweight,method,5,12,9,126,10.5,0,0,['self'],[None],[None],2031,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/py2to3/portfolio.py:folioCalc:calc_baskettable,folioCalc:calc_baskettable,method,33,111,83,811,7.31,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', '0.000', '0']",2038,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/py2to3/portfolio.py:folioCalc:plot,folioCalc:plot,method,10,29,26,295,10.17,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2066,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/py2to3/portfolio.py:folioCalc:multiperiod_ww,folioCalc:multiperiod_ww,method,15,36,29,240,6.67,1,1,"['self', 't']","[None, None]","[None, None]",2077,[],['xrange'],1
utilmy/zarchive/py2to3/portfolio.py:folioCalc:help,folioCalc:help,method,1,2,2,13,6.5,0,0,['self'],[None],[None],2090,[],['print'],1
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:__init__,folioRiskIndicator:__init__,method,23,40,38,356,8.9,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:set_symclose,folioRiskIndicator:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2114,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:setcriteria,folioRiskIndicator:setcriteria,method,34,81,70,1006,12.42,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2124,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'np.zeros']",3
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:calcrisk,folioRiskIndicator:calcrisk,method,13,18,17,220,12.22,1,0,"['self', 'wwvec', 'initval']","[None, None, None]","[None, '[]', '1']",2172,[],"['xrange', 'self._weightcalc_generic', 'np.column_stack']",3
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:_weightcalc_generic,folioRiskIndicator:_weightcalc_generic,method,4,34,24,327,9.62,0,3,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2184,[],"['self._weightcalc_regime', 'print']",2
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:_weightcalc_regime,folioRiskIndicator:_weightcalc_regime,method,3,11,11,68,6.18,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2193,[],['self._regimecalc'],1
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:_regimecalc,folioRiskIndicator:_regimecalc,method,7,18,17,216,12.0,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )self.riskind', 'wwextra', 't', 'self.riskind_out)self', 'maxiter', 'name1', 'isreset', 'popsize=15) ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, None, None, None, None, None, None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, None, None, None, None, '1', ""''"", '1', '15) :']",2198,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio.py:folioRiskIndicator:calc_optimal_weight,folioRiskIndicator:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2204,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:__init__,folioOptimizationF:__init__,method,23,39,37,340,8.72,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1659,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:set_symclose,folioOptimizationF:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2114,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:setcriteria,folioOptimizationF:setcriteria,method,44,128,103,1669,13.04,0,2,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2124,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'print', 'list']",4
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:calcbasket_obj2,folioOptimizationF:calcbasket_obj2,method,23,76,63,756,9.95,0,1,"['self', 'wwvec']","[None, None]","[None, None]",2362,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float']",6
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:calcbasket_obj,folioOptimizationF:calcbasket_obj,method,55,157,118,1494,9.52,1,4,"['self', 'wwvec']","[None, None]","[None, None]",2388,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float', 'calcbasket_obj', 'concenfactor=folio_concenfactor2', 'np.zeros', 'xrange', 'np.mod', 'self._weightcalc_generic', 'self._loss_obj', 'self._objective_criteria']",14
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_loss_obj,folioOptimizationF:_loss_obj,method,4,6,6,68,11.33,0,0,"['self', 'ww2', 'wwpenalty']","[None, None, None]","[None, None, None]",2413,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_weightcalc_generic,folioOptimizationF:_weightcalc_generic,method,5,40,26,394,9.85,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2184,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_weightcalc_regime,folioOptimizationF:_weightcalc_regime,method,8,32,28,239,7.47,0,0,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2193,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']","['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_regimecalc,folioOptimizationF:_regimecalc,method,4,7,7,83,11.86,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )if self.riskid== ""multi""   ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, '= ""multi""   :']",2198,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']",['self._mapping_calc_risk'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_weightcalc_constant,folioOptimizationF:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2452,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:calc_optimal_weight,folioOptimizationF:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2204,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:getweight,folioOptimizationF:getweight,method,6,11,9,126,11.45,0,0,['self'],[None],[None],2461,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:calc_baskettable,folioOptimizationF:calc_baskettable,method,36,86,72,827,9.62,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', ' 0.000', '0']",2469,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:plot,folioOptimizationF:plot,method,11,31,30,294,9.48,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2498,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_objective_criteria,folioOptimizationF:_objective_criteria,method,31,147,78,1105,7.52,2,7,"['self', 'bsk']","[None, None]","[None, None]",2510,[],"['np.std', 'np.sum', 'range', 'np.arange']",4
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:multiperiod_ww,folioOptimizationF:multiperiod_ww,method,18,29,27,238,8.21,1,1,"['self', 't']","[None, None]","[None, None]",2557,[],['xrange'],1
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:help,folioOptimizationF:help,method,50,152,103,1472,9.68,1,6,['self'],[None],[None],2569,[],"['print', 'util.load_obj', 'int', 'copy.deepcopy', 'xrange', 'next', 'util.save_obj', 'np.mod', 'np.abs', 'np.reshape', 'np.sum']",11
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:mapping_risk_ww,folioOptimizationF:mapping_risk_ww,method,12,56,29,245,4.38,0,1,"['self', 'risk', 'wwmat', 'ww2']","[None, None, None, None]","[None, None, None, 'self.wwasset0']",2628,[],"['np.sum', 'np.array']",2
utilmy/zarchive/py2to3/portfolio.py:folioOptimizationF:_mapping_calc_risk,folioOptimizationF:_mapping_calc_risk,method,27,201,76,831,4.13,0,3,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",2640,[],[],0
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:__init__,searchSimilarity:__init__,method,15,18,17,193,10.72,0,0,"['self', ""filejpstock=r'E"", 'sym01', 'symname', 'startdate', 'enddate', 'pricetype']","[None, '', None, None, None, None, None]","[None, ""r'E:/_data/stock/daily/20160616/jp'"", ""['7203']"", ""['Toyota']"", ' 20150101', '20160601', '""close""']",3725,[],[],0
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:load_quotes_fromdb,searchSimilarity:load_quotes_fromdb,method,15,35,33,355,10.14,0,1,"['self', 'picklefile']","[None, None]","[None, ""''""]",3730,[],"['util.load_obj', 'imp_txt_getquotes', 'date_align', 'util.a_cleanmemory']",4
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:__generate_return__,searchSimilarity:__generate_return__,method,4,4,4,64,16.0,0,0,"['self', 'nlag']","[None, None]","[None, None]",3741,[],['getret_fromquotes'],1
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:__overweight__,searchSimilarity:__overweight__,method,17,62,41,412,6.65,2,4,"['self', 'px']","[None, None]","[None, None]",3745,[],"['len', 'np.ones', 'util.np_findlocalmax', 'type', 'np.abs', 'wwerr[max', 'util.np_findlocalmin']",7
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:set_searchcriteria,searchSimilarity:set_searchcriteria,method,34,79,63,793,10.04,0,5,"['self', 'name1', 'date1', 'date2', 'nlag', 'searchperiodstart', 'typesearch', '']","[None, None, None, None, None, None, None, None]","[None, ""'7203'"", '20160301', '20160601', '1', '20120101', '""pattern2""', None]",3765,[],"['getret_fromquotes', 'date_finddateid', 'max', 'util.np_findfirst', 'print', 'price_normalize_1d', 'len', 'self.__overweight__']",8
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:launch_search,searchSimilarity:launch_search,method,53,107,81,908,8.49,3,3,['self'],[None],[None],3794,[],"['len', 'np.zeros', 'range', 'price_normalize_1d', 'np_similarity', 'util.np_sortbycolumn', 'enumerate']",7
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:show_comparison_graph,searchSimilarity:show_comparison_graph,method,33,72,63,682,9.47,1,3,"['self', 'maxresult', 'show_only_different_time', 'fromid', 'fromend', 'filenameout']","[None, None, None, None, None, None]","[None, '20', 'True', '0', ' 0', ""''""]",3828,[],"['np.shape', 'range', 'int', 'print', 'price_normalize_1d', 'str', 'plot_price']",7
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:staticmethod,searchSimilarity:staticmethod,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",3857,[],[],0
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:get_rankresult,searchSimilarity:get_rankresult,method,24,63,53,496,7.87,2,1,"['self', 'filetosave']","[None, None]","[None, ""''""]",3861,[],"['len', 'np.savetxt', 'np.shape', 'np.array', 'np.empty', 'range', 'int', 'str']",8
utilmy/zarchive/py2to3/portfolio.py:searchSimilarity:export_results,searchSimilarity:export_results,method,0,0,0,0,0.0,0,0,[],[],[],3883,"[""'''\n"", '#####################################################################################\n', '#---------Run over all the indexes, with time lag -----------------------------------\n', 'def np_similarity(x,y, wwerr=[], type1=0):\n', '  if type1==2 : return np_distance_l1(x,y, wwerr)\n', '  if type1==1: return sci.spatial.distance.correlation(x, y)  \n', '  if type1==0 : return 1-np.corrcoef(x,y)[0,1]\n', '\n', 'def np_distance_l1(x,y, wwerr) :\n', ' return np.sum(wwerr * np.abs(x-y))  \n', '  \n', '#---------------------  Universe Load         ---------------------------------------\n', ""filejpstock= r'E:/_data/stock/daily/20160616/jp'\n"", 'sym01= nk400list\n', '\n', 'quotes= imp_txt_getquotes(sym01, filejpstock, startdate=20090101, endate=20160616)\n', 'open1, dateref= date_align(quotes, type1=""close"")    #Get the data and align dates\n', 'del quotes; util.a_cleanmemory()\n', '\n', ""#util.save_obj(open1, 'close_nk400_2009_2016')\n"", ""#util.save_obj(dateref, 'dateref_nk400_2009_2016')\n"", '\n', ""open1= util.load_obj('close_nk400_2009_2016')\n"", ""dateref= util.load_obj( 'dateref_nk400_2009_2016')\n"", '\n', 'nlag=1\n', 'ret_open1 =  getdailyret_fromquotes(open1,nlag)\n', 'del open1\n', '\n', '#--------------------  Search Asset Input     ---------------------------------------\n', ""name1= '7203' \n"", 'date1= 20160328\n', 'date2= 20160531\n', 'twindow= util.np_findfirst(date2, dateref) - util.np_findfirst(date1, dateref) \n', '\n', '\n', 'tstartx= util.np_findfirst(date1, dateref)          # Date Index\n', 'stockx= util.np_findfirst(name1, sym01)\n', 'retx= ret_open1[stockx, tstartx:(tstartx+twindow-1)]    # Recent Period\n', 'px= price_normalize_1d(retx)\n', 'nx= len(px)\n', '\n', '\n', '#----OverWeight for Local Min, Local Max         -----------------------------------\n', 'wwerr= np.ones(nx, dtype=np.float16)\n', 'vvmax= util.np_findlocalmax(px); xprev=0\n', 'for x in vvmax:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', 'vvmin= util.np_findlocalmin(px); xprev=0\n', 'for x in vvmin:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', '\n', '#--------------------  Search the Pattern       -------------------------------------\n', 'tmaxx= len(dateref)-1\n', 'similar_list= np.zeros((nstock*(tmaxx-twindow)+1, 3), np.float16)\n', 'i=0\n', 'for iy in range(0, nstock) :\n', ' for t in range(0, tmaxx-twindow):\n', '   if iy == stockx and t > tstartx : \n', '     pass\n', '   else :\n', '    rety= ret_open1[iy, t:(t+twindow-1)]\n', '    py=   price_normalize_1d(rety)\n', '    ss= np_similarity(px, py, wwerr=wwerr, type1=2)\n', '    i+=1\n', '    similar_list[i,0]= iy\n', '    similar_list[i,1]= t\n', '    similar_list[i,2]= ss\n', '\n', '\n', ' #-------------------Clean the table -------------------------------------------------\n', 'rank= util.np_sortbycolumn(similar_list,2, asc=True)\n', 'for i,x in enumerate(rank) :\n', '  if rank[i,2]==0.0 : rank[i,2]= 1000         # Empty cell\n', '  if rank[i,1]> tstartx-3 : rank[i,2]= 100    # Start Element\n', 'rank= util.np_sortbycolumn(rank,2, asc=True)  \n', '\n', '\n', ' #----- Show Similar Stocks ---------------------------------------------------------\n', 'show_only_different_time= True\n', '\n', 'for i in range(0,10) :\n', ' tstarti= rank[i,1]\n', ' stocki= int(rank[i,0])\n', ' \n', ' if show_only_different_time and tstarti < tstartx-1  :\n', '   py= price_normalize100(ret_open1[stocki, tstarti:(tstarti+twindow-1)]) \n', '\n', '   namei= sym01[stocki]\n', '   namefulli= nk400name[util.np_findfirst(namei, nk400list)]\n', '\n', '   tit= namei+ "" "" +namefulli+ "" "" + str(dateref[tstarti])          \n', ""   plot_price(px-100, py-100, label=('Similar '+tit, 'Time','% Var') )\n"", '\n', '\n', 'kix= util.np_findfirst(name1, statsjp[:,0, ilag])\n', 'stocklist01[390]\n', '\n', '\n', 'stocklist01[157] , nk400name[157] ,  dateref1adj[86]     \n', 'plot_price(price_normalize100(ret_open1[157, 86:86+twindow-1])-100,px-100   )\n', ""'''    \n""]",[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:data_jpsector,data_jpsector,function,3,4,4,47,11.75,0,0,[],[],[],30,[],['util.load_obj'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_earningquater,date_earningquater,function,9,103,42,604,5.86,0,5,['t1'],[None],[None],40,[],['datetime.datetime'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_is_3rdfriday,date_is_3rdfriday,function,4,14,13,67,4.79,0,0,['s'],[None],[None],59,[],"['datetime.strptime', 'd.weekday']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:date_option_expiry,date_option_expiry,function,10,50,33,354,7.08,0,2,['date'],[None],[None],64,[],['datetime.datetime'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_find_kday_fromintradaydate,date_find_kday_fromintradaydate,function,2,3,3,68,22.67,0,0,"['kintraday', 'intradaydate', 'dailydate']","[None, None, None]","[None, None, None]",81,[],['util.np_find'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_find_kintraday_fromdate,date_find_kintraday_fromdate,function,4,10,10,88,8.8,0,0,"['d1', 'intradaydate1', 'h1', 'm1']","[None, None, None, None]","[None, None, '9', '30']",85,[],"['datetime.datetime', 'util.np_find']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:date_find_intradateid,date_find_intradateid,function,8,13,13,96,7.38,1,0,"['datetimelist', 'stringdate']","[None, None]","[None, ""['20160420223000']""]",92,[],"['datestring_todatetime', 'util.np_find', 'str']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_convertzone1_tozone2,datetime_convertzone1_tozone2,function,16,29,25,343,11.83,1,1,"['tt', 'fromzone', 'tozone']","[None, None, None]","[None, ""'Japan'"", ""'US/Eastern'""]",103,[],"['pytz.timezone', 'type', 'tz.localize', 't2.append']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:date_extract_dailyopenclosetime,date_extract_dailyopenclosetime,function,23,51,35,431,8.45,2,3,"['spdateref1', 'market']","[None, None]","[None, ""'us'""]",120,[],"['enumerate', 'spdailyopendate.append', 'np.array', 'spdailyclosedate.append']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_tostring,datetime_tostring,function,6,34,22,269,7.91,1,3,['tt'],[None],[None],138,[],"['isinstance', 'tt.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",149,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_todate,datetime_todate,function,6,40,25,319,7.97,1,3,['tt'],[None],[None],158,[],"['isinstance', 'datetime.date', 'pd.to_datetime', 'date2.append']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_toint,datetime_toint,function,12,37,28,424,11.46,2,2,['datelist1'],[None],[None],169,[],"['isinstance', 'int', 'date2.append', 'datetime_tointhour', 'yy2.append', 'np.array']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_tointhour,datetime_tointhour,function,7,20,19,234,11.7,1,1,['datelist1'],[None],[None],177,[],"['isinstance', 'int', 'yy2.append', 'np.array']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:dateint_tostring,dateint_tostring,function,7,15,14,183,12.2,1,1,"['datelist1', 'format1']","[None, None]","[None, ""'%b-%y'""]",185,[],"['isinstance', 'dateint_todatetime', 'date2.append', 'np.array']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:dateint_todatetime,dateint_todatetime,function,6,14,12,126,9.0,1,1,['datelist1'],[None],[None],207,[],"['isint', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:datenumpy_todatetime,datenumpy_todatetime,function,9,48,26,381,7.94,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",218,[],['type'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:datetime_tonumpypdate,datetime_tonumpypdate,function,2,2,2,22,11.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",232,[],['np.datetime64'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_diffindays,date_diffindays,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",237,[],['dateint_todatetime'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",242,[],['util.np_findfirst'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],256,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:date_as_float,date_as_float,function,12,32,26,311,9.72,0,2,['dt'],[None],[None],263,[],"['isint', 'dateint_todatetime', 'datetime.datetime', 'isleap', 'timedelta']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:date_todatetime,date_todatetime,function,1,9,9,58,6.44,0,0,['tlist'],[None],[None],277,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:date_removetimezone,date_removetimezone,function,1,6,6,63,10.5,0,0,['datelist'],[None],[None],281,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:datediff_inyear,datediff_inyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",285,[],['date_as_float'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",289,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:date_add_bdays,date_add_bdays,function,12,37,30,369,9.97,1,2,"['from_date', 'add_days']","[None, None]","[None, None]",298,[],"['type', 'dateint_todatetime', 'datestring_todatetime', 'datetime.timedelta', 'current_date.weekday']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:date_getspecificdate,date_getspecificdate,function,21,203,58,1312,6.46,8,19,"['datelist', 'datetype1', 'outputype1', 'includelastdate', 'includefirstdate', '']","[None, None, None, None, None, None]","[None, '""yearend""', '""intdate""', 'True', 'False', None]",312,[],"['isint', 'dateint_todatetime', 'enumerate', 'vec2.append', 'np.mod', 'np.array']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:date_alignfromdateref,date_alignfromdateref,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",373,[],"['range', 'np.float', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:_date_align,_date_align,function,16,42,33,256,6.1,2,2,"['dateref', 'datei', 'tmax', 'closei']","[None, None, None, None]","[None, None, None, None]",398,[],"['np.zeros', 'range', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:date_align,date_align,function,13,31,27,206,6.65,1,1,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",412,"["" ''' #Aligne the price with the same dates date\tyear\tmonth\tday\td\topen\tclose\thigh\tlow\tvolume\taclose '''\n""]","['range', 'np.float', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:min_withposition,min_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],459,[],['min'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:max_withposition,max_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],463,[],['max'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:_reshape,_reshape,function,2,14,12,68,4.86,0,1,['x'],[None],[None],469,[],"['len', 'np.reshape', 'np.size']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:_notnone,_notnone,function,39,211,114,1769,8.38,1,11,"['x)', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5)', 'label', ""'Time'"", ""'Y')"", 'legendloc', 'dpi', 'isband=0) ']","['  return not x is Noneasset', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None, ""('title'"", None, None, '""upper left""', '150', '0) :']",473,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend']",23
utilmy/zarchive/py2to3/portfolio_withdate.py:plot_price,plot_price,function,69,272,170,2746,10.1,2,11,"['asset', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None]",477,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend', 'plot_priceintraday', 'np.loadtxt', 'np.unique', 'xdays.append', 'np.hstack', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick']",35
utilmy/zarchive/py2to3/portfolio_withdate.py:plot_priceintraday,plot_priceintraday,function,32,59,57,947,16.05,1,0,['data'],[None],[None],556,[],"['np.loadtxt', 'np.unique', 'np.arange', 'xdays.append', 'np.hstack', 'plt.figure', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plt.show']",14
utilmy/zarchive/py2to3/portfolio_withdate.py:plot_check,plot_check,function,8,19,19,257,13.53,0,0,"['close', 'tt0i', 'tt1i', 'dateref', 'sym', 'tickperday']","[None, None, None, None, None, None]","[None, '20140102', '20160815', '[]', '[]', '120']",598,[],"['util.find', 'getret_fromquotes', 'price_normalize100', 'plot_price']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:plot_pricedate,plot_pricedate,function,18,61,49,534,8.75,1,4,"['date1', 'sym1', 'asset1', 'sym2', 'bsk1', 'verticaldate', 'savename1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None', ""''"", '(10', None]",608,[],"['type', 'datestring_todatetime', 'np.row_stack', 'np.concatenate', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'np.arange', 'int', 'len', 'ax.savefig']",11
utilmy/zarchive/py2to3/portfolio_withdate.py:generate_sepvertical,generate_sepvertical,function,9,13,12,149,11.46,0,1,"['asset1', 'tt', 'tmax', 'start', 'datebar']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",690,[],"['np.zeros', 'datestring_todatetime']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:save_asset_tofile,save_asset_tofile,function,31,129,87,978,7.58,5,9,"['file1', 'asset1', 'asset2', 'asset3', 'date1', 'title1']","[None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None']",705,[],"['np.shape', 'len', 'np.reshape', 'print', 'np.zeros', 'range', 'int', 'np.row_stack', 'np.savetxt']",9
utilmy/zarchive/py2to3/portfolio_withdate.py:load_asset_fromfile,load_asset_fromfile,function,1,4,4,51,12.75,0,0,['file1'],[None],[None],744,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:array_todataframe,array_todataframe,function,11,41,27,259,6.32,0,2,"['price', 'symbols', 'date1']","[None, None, None]","[None, 'None', 'None']",748,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:pd_dataframe_toarray,pd_dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],759,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],768,[],['float'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:isint,isint,function,32,105,61,1036,9.87,0,8,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) )Xmat', 'type1', 'type2=""correl"") ']","[' return isinstance(x', None, None, None, None, None, None, '']","[None, None, None, None, None, None, '""robust""', '""correl"") :']",776,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:correlation_mat,correlation_mat,function,32,105,61,1036,9.87,0,8,"['Xmat', 'type1', 'type2']","[None, None, None]","[None, '""robust""', '""correl""']",783,[],"['Xmat.copy', 'x.mean', 'x.std', 'np.corrcoef', 'MinCovDet', 'OAS', 'correl_inv.copy', 'np.sqrt']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:correl_reducebytrigger,correl_reducebytrigger,function,9,22,18,128,5.82,2,1,"['correl2', 'trigger']","[None, None]","[None, None]",831,"[""  ''' Put Zero below trigger  '''\n""]","['correl2.copy', 'range', 'abs']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:sk_cov_fromcorrel,sk_cov_fromcorrel,function,8,14,13,115,8.21,0,0,"['correl', 'ret_close1']","[None, None]","[None, None]",843,[],"['volhisto_fromret', 'np.diag', 'np.dot']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:cointegration,cointegration,function,18,47,37,385,8.19,0,0,"['x', 'y']","[None, None]","[None, None]",849,"['  """""" Output :\n', '    coint_t :t-statistic of unit-root test on residuals\n', ""    pvalue :   MacKinnon's approximate p-value based on MacKinnon (1994)\n"", '    crit_value : Critical values for the test statistic at the 1 %, 5 %, and 10 %  Signifiance levels.\n', '\n', '    The Null hypothesis is that there is no cointegration, the alt hypothesis is that there is cointegrating relationship. \n', '    If the pvalue is small, below a critical size:  Reject Null Hypothesis -->  Cointegration\n', '           pvalue is high --> No Cointegration    \n', '    \n', '    Significance level, also denoted as alpha or , is the probability of rejecting  the null hypothesis when it is true.\n', '    Probability of incorrectly rejecting a true null hypothesis\n', '\n', '    P=0.05  , At least 23% (and typically close to 50%)\n', '    P=0.01  , At least 7% (and typically close to 15%\n', '\n', '    (-2.9607012342275936,\n', '    0.038730981052330332, 0,\n', '    249,\n', ""    {'1%': -3.4568881317725864,\n"", ""       '10%': -2.5729936189738876,\n"", ""     '5%': -2.8732185133016057},\n"", '      601.96849256295991)\n', '        It can be seen that the calculated test statistic of -2.96 is smaller than the 5% critical value of -2.87, \n', ""        which means that we can reject the null hypothesis that  there isn't a cointegrating relationship at the 5% level.\n"", '  """"""\n']",['np.zeros'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:causality_y1_y2,causality_y1_y2,function,10,14,13,153,10.93,0,0,"['price2', 'price1', 'maxlag']","[None, None, None]","[None, None, None]",887,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:reg_slope,reg_slope,function,16,24,24,261,10.88,1,0,"['close', 'dateref', 'tlag', 'type1']","[None, None, None, None]","[None, None, None, ""'elasticv'""]",895,[],"['np.ones', 'xrange', 'regression', 'np.arange']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:rolling_cointegration,rolling_cointegration,function,13,29,26,280,9.66,0,0,"['x', 'y']","[None, None]","[None, None]",910,[],"['rolling_coint', 'pd.expanding_apply']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:regression,regression,function,13,67,32,589,8.79,0,5,"['yreturn', 'xreturn', 'type1']","[None, None, None]","[None, None, '""elasticv""']",929,"["" '''Y = X* reg.coef_  +  reg.intercept_, r2 '''\n""]","['len', 'yreturn.ravel', 'xreturn.reshape', 'reg.fit', 'F', 'reg.score']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:regression_fixedsymbolstock,regression_fixedsymbolstock,function,30,59,54,591,10.02,1,1,"['sym', 'ret_close2', 'tsstart', 'tsample', 'ret_spy', 'spyclose', 'regonly']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, 'True']",966,"["" ''' Price, Weight, R2, Error  '''\n""]","['len', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:regression_getpricefromww,regression_getpricefromww,function,20,38,30,298,7.84,3,0,"['spyclose', 'ww01', 'regasset01', 'ret_close2', 'tstart', 'tlag']","[None, None, None, None, None, None]","[None, None, None, None, None, '1']",989,[],"['np.copy', 'np.zeros', 'range', 'len']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:regression_allstocks_vs_riskfactors,regression_allstocks_vs_riskfactors,function,65,137,113,1351,9.86,2,1,"['symstock', 'pricestock', 'symriskfac', 'priceriskfac', 'nlaglist']","[None, None, None, None, None]","[None, None, None, None, None]",1010,"["" '''Make Regression on all stocks ''' \n""]","['np.shape', 'print', 'np.arange', 'np.empty', 'len', 'enumerate', 'getlogret_fromquotes', 'range', 'np.reshape', 'regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",13
utilmy/zarchive/py2to3/portfolio_withdate.py:getdiff_fromquotes,getdiff_fromquotes,function,4,6,6,73,12.17,0,0,"['close', 'timelag']","[None, None]","[None, None]",1107,[],['np.shape'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:getret_fromquotes,getret_fromquotes,function,7,23,17,159,6.91,0,1,"['close', 'timelag']","[None, None]","[None, '1']",1111,[],"['np.shape', 'len']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:getlogret_fromquotes,getlogret_fromquotes,function,4,7,7,81,11.57,0,0,"['close', 'timelag']","[None, None]","[None, '1']",1122,[],"['np.shape', 'np.log']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:getprice_fromret,getprice_fromret,function,12,23,21,190,8.26,2,0,"['ret', 'normprice']","[None, None]","[None, '100']",1127,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:price_normalize100,price_normalize100,function,16,43,36,292,6.79,1,1,"['ret', 'normprice']","[None, None]","[None, '100']",1139,[],"['np.shape', 'len', 'np.reshape', 'np.zeros', 'range', 'np.cumprod']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:price_normalize_1d,price_normalize_1d,function,8,22,19,147,6.68,0,0,"['ret', 'normprice', 'dtype1']","[None, None, None]","[None, '100', ' np.float32']",1159,[],"['np.empty', 'np.cumprod']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:norm_fast,norm_fast,function,7,8,8,85,10.62,0,0,"['y', 'ny']","[None, None]","[None, None]",1168,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:correl_fast,correl_fast,function,8,13,13,116,8.92,0,0,"['xn', 'y', 'nx']","[None, None, None]","[None, None, None]",1176,[],['ne.evaluate'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:volhisto_fromret,volhisto_fromret,function,2,14,11,168,12.0,0,1,"['retbsk', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1184,[],"['len', 'np.std']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:volhisto_fromprice,volhisto_fromprice,function,6,25,17,245,9.8,0,1,"['price', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1191,[],"['len', 'np.shape', 'np.std']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:volhistorolling_fromprice,volhistorolling_fromprice,function,16,42,30,318,7.57,2,1,"['price', 'volrange']","[None, None]","[None, None]",1200,[],"['np.shape', 'len', 'np.zeros', 'xrange', 'volhisto_fromprice']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:rsk_calc_all_TA,rsk_calc_all_TA,function,51,223,105,1352,6.06,0,10,['df'],[None],"[""'panda_dataframe'""]",1219,"[""  '''Add All TA RMI, RSI To the '''\n""]","['ta.MA', 'ta.distance', 'ta.RET', 'ta.RMI', 'ta.STDDEV', 'ta.nbday_low', 'ta.nbday_high', 'ta.RSI', 'ta.qearning_dist', 'ta.optionexpiry_dist', 'linearreg2', 'np.array', 'np.sum', 'util.np_findlocalmin2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",18
utilmy/zarchive/py2to3/portfolio_withdate.py:ta_highbandtrend1,ta_highbandtrend1,function,42,170,75,910,5.35,0,11,"['close2', 'type1']","[None, None]","[None, '0']",1301,[],"['linearreg', 'np.array', 'np.sum', 'util.np_findlocalmax2', 'len', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:pd_transform_asset,pd_transform_asset,function,11,35,27,409,11.69,0,1,"['q0', 'q1', 'type1']","[None, None, None]","[None, None, '""spread""']",1350,[],"['util.pd_date_intersection', 'util.pd_array_todataframe', 'util.pd_insertcol']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:calcbasket_table,calcbasket_table,function,25,59,53,477,8.08,1,2,"['wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps']","[None, None, None, None, None, None]","[None, None, '""table""', '""constant""', '1', ' 0.000']",1364,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.mod', 'np.sum']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_createvolta_asset,folio_createvolta_asset,function,10,19,19,159,8.37,1,0,"['close', 'vol', 'volrange', 'lev']","[None, None, None, None]","[None, '0.12', '120', '1.0']",1391,[],"['np.zeros_like', 'np.shape', 'xrange', 'folio_volta']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_lowcorrelation,folio_lowcorrelation,function,145,431,300,3894,9.03,8,7,"['sym01', 'nstock', 'periodlist', 'dateref', 'close1', 'kbenchmark', 'badlist', 'costbppa', 'showgraph']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, '0.02', 'True']",1399,[],"['ww_selection', 'np.corrcoef', 'np.nan_to_num', 'np.zeros', 'range', 'util.np_sortbycol', 'int', 'np.std', 'np.isnan', 'util.find', 'np.sum', 'stk_select.append', 'volhisto_fromret', 'sum', '1/len', 'getret_fromquotes', 'len', 'np.empty', 'np.ones', 'enumerate', 'calcbasket_table', 'price_normalize100', 'np.column_stack', 'np.zeros_like', 'np.array', 'np.concatenate', 'print', 'str', 'plot_price', 'sym01[int', 'volhisto_fromprice', 'xrange', 'folio_inverseetf']",33
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_leverageetf,folio_leverageetf,function,8,23,20,156,6.78,1,0,"['price', 'lev', 'costpa']","[None, None, None]","[None, '1.0', '0.0']",1537,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_inverseetf,folio_inverseetf,function,8,18,18,151,8.39,1,0,"['price', 'costpa']","[None, None]","[None, '0.0']",1546,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_longshort_unit,folio_longshort_unit,function,59,240,112,1594,6.64,2,7,"['long1', 'short1', 'ww', '-1]', 'costpa', 'tlag', 'istable', 'wwschedule']","[None, None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1', '[]']",1555,[],"['len', 'np.zeros', 'xrange', 'np.mod', 'folio_longshort_unitfixed']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_longshort_unitfixed,folio_longshort_unitfixed,function,43,111,73,719,6.48,1,3,"['long1', 'short1', 'nn', '-1]', 'costpa', 'tlag', 'istable']","[None, None, None, None, None, None, None]","[None, None, '[1', None, '0.0', '1', '1']",1596,[],"['len', 'np.zeros', 'xrange', 'np.mod']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_longshort_pct,folio_longshort_pct,function,8,21,20,189,9.0,1,0,"['long1', 'short1', 'ww', '-1]', 'costpa']","[None, None, None, None, None]","[None, None, '[1', None, '0.0']",1634,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_histogram,folio_histogram,function,13,75,41,914,12.19,0,0,['close'],[None],[None],1642,[],"['getret_fromquotes', 'plt.subplots', 'np.ones_like', 'ax2.hist', 'ax2.set_title', 'ax2.set_xlabel', 'ax2.set_ylabel', 'ax2.axvline', 'plt.show', 'print']",10
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_voltarget,folio_voltarget,function,2,6,6,61,10.17,0,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1670,[],['folio_volta'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_volta,folio_volta,function,54,197,112,1663,8.44,2,8,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1674,[],"['folio_volta', 'len', 'np.shape', 'np.zeros', 'range', 'np.std', 'util.findhigher', 'max', 'min', 'folio_volta2', 'np.abs']",11
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_volta2,folio_volta2,function,29,61,54,514,8.43,1,2,"['bsk', 'riskind', 'par', 'targetvol', 'volrange', 'cap', 'floor', 'costbp']","[None, None, None, None, None, None, None, None]","[None, None, None, '0.11', ' 90', '1.5', '0.0', '0.0005']",1713,[],"['np.shape', 'np.zeros', 'range', 'np.std', 'max', 'min', 'np.abs']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_fixedunitprice,folio_fixedunitprice,function,13,36,33,221,6.14,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1738,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_fixedweightprice,folio_fixedweightprice,function,13,36,33,225,6.25,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1752,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_fixedweightret,folio_fixedweightret,function,13,31,28,193,6.23,2,0,"['ret', 'fixedww']","[None, None]","[None, None]",1764,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_cost_turnover,folio_cost_turnover,function,26,88,71,825,9.38,1,1,"['wwall', 'bsk', 'dateref', 'costbp']","[None, None, None, None]","[None, None, None, None]",1777,[],"['len', 'np.zeros', 'xrange', 'np.sum', 'plot_price', 'date1=dateint_tostring']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_riskpa,folio_riskpa,function,20,52,40,422,8.12,2,0,"['ret', 'targetvol', 'volrange', 'cap']","[None, None, None, None]","[None, '0.1', '90', '1.0']",1807,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.sum', 'np.std', 'min', 'list']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_perfreport_schedule,folio_perfreport_schedule,function,14,20,19,189,9.45,1,0,"['sym', 'dateref', 'close', 'wwind', 't0', 'scheduleperiod']","[None, None, None, None, None, None]","[None, None, None, None, None, '""1monthend""']",2121,[],"['np.shape', 'generate_schedule', 'np.zeros', 'enumerate']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folio_concenfactor2,folio_concenfactor2,function,7,12,12,103,8.58,0,0,"['ww', 'masset']","[None, None]","[None, '12']",2421,[],"['getweight', 'np.sum', 'np.mean']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:calcbasket_objext,calcbasket_objext,function,50,203,96,1094,5.39,1,7,"['RETURN', 'TMAX', 'riskind_i', 'wwmat', 'wwasset0', 'ww0', 'nbrange', 'criteria']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",2439,[],"['xrange', 'np.sum', 'math.sqrt']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:calc_ranktable,calc_ranktable,function,20,44,41,351,7.98,1,0,"['close2', 'symjp1', 'nlag', 'refindex', 'funeval', 'funargs']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",3849,[],"['np.zeros', 'getlogret_fromquotes', 'enumerate', 'funeval', 'util.np_sortbycolumn']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:similarity_correl,similarity_correl,function,7,10,9,88,8.8,0,0,"['ret_close2', 'funargs']","[None, None]","[None, None]",3869,[],['correlation_mat'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3924,[],['np_distance_l1'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3930,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3924,[],['np_distance_l1'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:np_distance_l1,np_distance_l1,function,2,3,3,31,10.33,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3930,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:get,get,function,11,44,26,436,9.91,0,1,"['close', 'timelag']","[None, None]","[None, None]",4293,"['    """"""Return dataframe of requested dataset from Quandl.\n', '    :param dataset: str or list, depending on single dataset usage or multiset usage\n', '            Dataset codes are available on the Quandl website\n', '    :param str api_key: Downloads are limited to 50 unless api_key is specified\n', '    :param str start_date, end_date: Optional datefilers, otherwise entire dataset is returned\n', '    :param str collapse: Options are daily, weekly, monthly, quarterly, annual\n', '    :param str transform: options are diff, rdiff, cumul, and normalize\n', '    :param int rows: Number of rows which will be returned\n', '    :param str order: options are asc, desc. Default: `asc`\n', '    :param str returns: specify what format you wish your dataset returned as,\n', '        either `numpy` for a numpy ndarray or `pandas`. Default: `pandas`\n', '    :returns: :class:`pandas.DataFrame` or :class:`numpy.ndarray`\n', '    Any other `kwargs` passed to `get` are sent as field/value params to Quandl\n', '    with no interference.\n', '\n', ""'''\n"", '\n', '\n', '\n', '#--------------------Import data from Yahoo --------------------------------------------------\n', 'def imp_yahoo_getquotes(symbols, start=""20150101"", end=""20160101"", type1=1):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', '# symbols = np.array(symbol1)\n', ' quotes= []; errorlist=[]; correctlist=[]\n', ' for i, symbol in enumerate(symbols) :\n', '   # if np.mod(i,400) ==0 and i != 0 :\n', ""     # print('Waiting 30s'); time.sleep(30)\n"", '   try:   \n', '     array1= quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '     df= pd.DataFrame.from_records(array1)\n', '     quotes.append(df)\n', '     correctlist.append(symbol)\n', '   except :\n', '       errorlist.append(symbol)\n', ""       print('Err: '+symbol)\n"", ' #quotes = [quotes_historical_yahoo(symbol, d1, d2, asobject=True)  for symbol in symbols]\n', ' #print(errorlist) \n', ' if type1==1 :  return quotes, correctlist\n', ' else: return quotes, correctlist, errorlist  \n', '\n', '              \n', '#Find error in Ticker import\n', 'def imp_yahoo_geterrorticker(symbols, start=""20150101"", end=""20160101""):\n', ' d1 = datetime.datetime(int(start[0:4]), int(start[4:6]), int(start[6:8]))\n', ' d2 = datetime.datetime(int(end[0:4]), int(end[4:6]), int(end[6:8]))\n', ' errorlist= []\n', ' for symbol in symbols :\n', '   try :  \n', '     quotes_historical_yahoo_ochl(symbol, d1, d2, asobject=True)\n', '   except :\n', '     errorlist.append(symbol)\n', '     print(symbol)       \n', ' return errorlist\n', ' \n', ""'''\n"", ""symbols0= ['KHC', 'PYPL', 'HPE', 'BXLT', 'SYF', 'WLTW', 'CFG', 'BF-B', 'WRK']\n"", '\n', '#Show list of ticker in error\n', 'import_errorticker(symbols0,""20110101"",""20150601""  )\n', ""'''\n"", '\n', '\n', 'def imp_yahoo_financials_url(ticker_symbol, statement=""is"", quarterly=False):\n', '    if statement == ""is"" or statement == ""bs"" or statement == ""cf"":\n', '        url = ""https://finance.yahoo.com/q/"" + statement + ""?s="" + ticker_symbol\n', '        if not quarterly:\n', '            url += ""&annual""; return BeautifulSoup(requests.get(url).text, ""html.parser"")\n', '    return sys.exit(""Invalid financial statement code \'"" + statement + ""\' passed."")\n', '\n', 'def imp_yahoo_periodic_figure(soup, yahoo_figure):\n', '    values = []; pattern = re.compile(yahoo_figure)\n', '\n', '    title = soup.find(""strong"", text=pattern)    # works for the figures printed in bold\n', '    if title:  row = title.parent.parent\n', '    else:\n', '        title = soup.find(""td"", text=pattern)    # works for any other available figure\n', '        if title:  row = title.parent\n', '        else:      sys.exit(""Invalid figure \'"" + yahoo_figure + ""\' passed."")\n', '\n', '    cells = row.find_all(""td"")[1:]    # exclude the <td> with figure name\n', '    for cell in cells:\n', '        if cell.text.strip() != yahoo_figure:    # needed because some figures are indented\n', '            str_value = cell.text.strip().replace("","", """").replace(""("", ""-"").replace("")"", """")\n', '            if str_value == ""-"": str_value = 0\n', '            value = int(str_value) * 1000\n', '            values.append(value)\n', '\n', '    return values\n', '    \n', '# print(imp_yahoo_periodic(imp_yahoo_financials_url(""AAPL"", ""is""), ""Income Tax Expense""))\n', '\n', ' \n', '\n', '#--------------------Import Quotes Google  ------------------------------------------\n', 'import requests.packages.urllib3\n', 'requests.packages.urllib3.disable_warnings()\n', 'import urllib, os\n', '\n', ""dirstockcsv= 'E:\\_data\\stock\\csv'\n"", '\n', 'def imp_googleIntradayQuote(symbol, freqsec=300, nday=5):\n', ""    ''' Intraday quotes from google. Specify interval seconds and number of days\n"", '    http://www.google.com/finance/getprices?q=7261&i=300&p=3d&f=d,o,h,l,c,v\n', ""    '''\n"", '    url =""http://www.google.com/finance/getprices?q={0}"".format(symbol)\n', '    url +=""&i={0}&p={1}d&f=d,o,h,l,c,v"".format(freqsec, nday)\n', '    try :      \n', '       resp= requests.post(url)\n', '       csv= resp.text\n', '       csv= csv.splitlines()\n', '    except :\n', ""       print('Err Intaday '+symbol)\n"", '\n', '    if len(csv) < 9 :\n', ""      print 'Using Daily',\n"", '\n', ""      url='http://www.google.com/finance/historical?q='+symbol+'&i='+str(freqsec)+'&p=3d&f=d,o,h,l,c,v&output=csv'\n"", '      csv = urllib.urlopen(url).readlines()\n', '      csv.reverse()\n', '      q=[]\n', '      for bar in xrange(0,len(csv)-1):\n', ""        ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '        if isfloat(open_) and isfloat(high) :\n', '          open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""          dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '          q.append([dt,open_,high,low,close,volume])\n', ""      df= util.pd_array_todataframe(q, ['date','open','high','low','close','volume'])\n"", '      return df\n', '\n', '\n', '    # print(csv)\n', '    qq=[]\n', '    for bar in xrange(7,len(csv)):\n', ""      if csv[bar].count(',')!=5: continue\n"", ""      offset,close,high,low,open_,volume = csv[bar].split(',')\n"", '      \n', ""      if offset[0]=='a':\n"", '        day = float(offset[1:])\n', '        offset = 0\n', '      else:\n', '        offset = float(offset)\n', '      open_, high, low, close = [float(x) for x in [open_,high,low,close]]\n', '      dt = datetime.datetime.fromtimestamp(day + (freqsec * offset))\n', '      #print (dt,open_,high,low,close,volume)\n', '      qq.append([dt,open_,high,low,close,volume])\n', ""    df= util.pd_array_todataframe(qq, ['date','open','high','low','close','volume'])\n"", '    return df\n', '\n', ""def imp_googleIntradayQuoteSave(symbols=['NKE'], freqsec=300, nday=2000, dircsv='', dbname=''):\n"", "" ''' Save Under various format: csv / db / output in Dataframe '''\n"", ' if isinstance(symbols, str) : symbols= [symbols]\n', ' symout,qlist, sym_error= [], [], []\n', ' for sym in symbols:\n', '   try :\n', '    q = imp_googleIntradayQuote(sym, freqsec, nday)  #interval, timeframe\n', '    print sym,\n', ""    sym= sym.replace(':', '_')\n"", '\n', ""    if dircsv != '' :\n"", '      if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""      start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""      file1= dircsv+ '\\\\' + sym + '_' + str(start1) + '_' + str(freqsec) + '_' + str(nday) + '.csv'\n"", '\n', ""      q= util.pd_addcol(q, 'symbol'); q['symbol']= sym\n"", '      q.to_csv(file1, index=False)\n', '\n', ""    elif dbname != '' :\n"", '      import sqlalchemy as sql\n', '      dbcon= sql.create_engine(dbname)\n', '      if interv_sec== 300 : # 5mins\n', ""        q.to_sql('q5min', dbcon)\n"", '\n', '    else :\n', '      qlist.append(q);   symout.append(sym)\n', '   except:\n', ""      print('Error:'+sym, )\n"", '      sym_error.append(sym)\n', '\n', ' return qlist, symout, sym_error\n', '\n', ""def imp_googleQuote(symbol, start_date='20160101', end_date= '20160101') : # datetime.date.today().isoformat()):\n"", ""    ''' Daily quotes from google. Date format='yyyymmdd' '''\n"", '    symbol = symbol.upper()\n', '    start = datetime.date(int(start_date[0:4]),int(start_date[4:6]),int(start_date[6:8]))\n', '    end =   datetime.date(int(end_date[0:4]),int(end_date[4:6]),int(end_date[6:8]))\n', '    url =""http://www.google.com/finance/historical?q={0}"".format(self.symbol)\n', '    url +=""&startdate={0}&enddate={1}&output=csv"".format( start.strftime(\'%b %d, %Y\'),end.strftime(\'%b %d, %Y\'))\n', '    csv = urllib.urlopen(url).readlines()\n', '    csv.reverse()\n', '    # print(url)\n', '    q=[]\n', '    for bar in xrange(0,len(csv)-1):\n', ""      ds,open_,high,low,close,volume = csv[bar].rstrip().split(',')\n"", '      if isfloat(open_) and isfloat(high) :\n', '        open_,high,low,close = [float(x) for x in [open_,high,low,close]]\n', ""        dt = datetime.datetime.strptime(ds,'%d-%b-%y')\n"", '        q.append([dt,open_,high,low,close,volume])\n', '    return q\n', '\n', 'def imp_googleQuoteSave(symbols, date1, date2, dircsv):\n', ' if isinstance(symbols, str) : symbols= [symbols]\n', ' for sym in symbols:\n', '   try :\n', '      q = imp_googleQuote(sym, date1, date2)   #interval, timeframe\n', ""   except: print('Error:'+symbol)\n"", '\n', ""   sym= sym.replace(':', '_')\n"", '\n', ""   if dircsv != '' :\n"", '     if not os.path.isdir(dircsv) :  os.makedirs(dircsv)\n', ""     start1= util.datetime_toint(util.datenumpy_todatetime(q['date'].values[0]))\n"", ""     file1= dircsv+ '\\\\'+ name1+'_'+ start1 +'_'+ str(date2) +'.csv'\n"", '     q.to_csv(file1)\n', '\n', ""   if dbname != '' :\n"", '     import sqlalchemy as sql\n', '     dbcon= sql.create_engine(dbname)\n', '     if interv_sec== 300 : # 5mins\n', ""       q.to_sql('q5min', dbcon)\n"", '\n', '\n', '\n', ""def imp_csv_dbupdate(indir='E:/_data/stock/intraday/intraday_google_usetf2.h5',\n"", ""                     outdir='E:/_data/stock/intraday/q5min/us/etf/', filelist=[], intype='csv',\n"", ""                     refcols=['date', 'open', 'high', 'low', 'close', 'volume', 'symbol']) :\n"", '\n', '  for file1 in filelist :\n', ""    sym=  file1[:file1.find('_')]  #Clean Up name\n"", '    print sym,\n', ""    outfile= outdir+'/'+sym+'.csv'\n"", '    if os.path.isfile(outfile) :\n', ""      df0= imp_csv_toext(file1=outfile, fromzone='Japan', tozone='UTC', header=0, cols=refcols)\n"", '    else :\n', '      df0= None\n', '\n', ""    if intype== 'hdfs':\n"", '      df1= imp_hdfs_getquote(indir, sym)\n', '      if isinstance(df1, float) : df1= None\n', '\n', ""    if intype=='csv' :\n"", ""      infile= indir+'/'+ file1   #csv\n"", ""      df1= imp_csv_toext(file1=infile, header=0, cols=refcols, fromzone='Japan', tozone='UTC')\n"", '\n', '    if df1 is not None :\n', '       if df0 is not None  : df1= imp_pd_merge(df1[refcols], df0[refcols])\n', '       # return outfile, df1\n', '       df1[refcols].to_csv(outfile, index=False)\n', '\n', '\n', '#####################################################################################\n', 'def imp_numpy_close_fromdb(dbname=\'/aaserialize/store/yahoo.db\', table1=\'\', symlist=[], t0=20010101, t1=20010101, priceid=""close"", batchsize= 400, maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from DB SQL"")\n', ' import data.hist_data_storage as yhh\n', ' dstore= yhh.dailyDataStore(dbname)\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', '\n', "" dateref0= dstore.get_histo(['SPY'], table1='daily_us_etf', start1=str(t0), end1=str(t1),  split_df=0).date.values\n"", ' \n', ' k=0; symfull=[];   i=0\n', ' nsym= len(symlist); nbatch= int(nsym / batchsize)+1\n', ' for j in xrange(0, nbatch) : \n', '      qlist, sym= dstore.get_histo(symlist[i:min(nsym,i+batchsize)], table1=table1, start1=str(t0), end1=str(t1),  split_df=1)\n', '\n', '      #print(""batch: ""+str(j), len(qlist), len(qlist[0].index) )\n', '      #for k,q in enumerate(qlist) :print sym[k], len(q.index)\n', '      i= i + batchsize\n', '      symfull= np.concatenate((symfull,sym))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)\n', '      print(""batch: ""+str(j), len(sym),dateref[0],dateref[-1] )\n', '      qlist=None; sym=None\n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[k:k+masset,0:tmax] = close\n', '      k=k+ masset\n', '\n', ' maxasset= k\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', 'def imp_numpy_close_fromhdfs(dbfile, symlist=[], t0=20010101, t1=20010101, priceid=""close"", maxasset=2600, tmax2=2000) :\n', ' print(""Get Numpy Matrix Close from Pandas"")\n', ' close2= np.zeros((maxasset,tmax2),dtype=np.float16)\n', ' store = pd.HDFStore(dbfile)\n', ' \n', "" df= store.select('SPY')\n"", ' df= df[(df.date >= t0) & (df.date <= t1 )]\n', ' dateref0= df.date.values\n', ' \n', ' k=0; symfull=[]; qlist=[]; sym=[]; tmax= 2000\n', ' for j, symbol in enumerate(store.keys()):\n', '  symbol=  symbol[1:]\n', '\n', '  if len(symlist)==0  or  util.find(symbol,symlist) > -1 : \n', '   #print symbol, util.find(symbol,symlist) \n', '   df= store.select(symbol) \n', '   if t0 !=t1 :     df= df[(df.date >= t0) & (df.date <= t1 )]\n', '   \n', '   qlist.append(df);   sym.append(symbol)\n', '   if np.mod(j+1, 401) == 0 :\n', '      print(""batch: ""+str(j))\n', '      close,dateref= date_align(qlist, dateref= dateref0, type1=priceid)   \n', '      print len(sym),dateref[0],dateref[-1] \n', '      symfull= symfull+sym\n', '      qlist=[]; sym=[]\n', ' \n', '      masset,tmax= np.shape(close)\n', '      if tmax2 < tmax: print(""Error tmax2 < tmax, wrong dates""); break\n', '      close2[(k):(k+masset),0:tmax] = close\n', '      k=k+ masset   \n', '     \n', ' if len(qlist) > 0:\n', '  # return qlist, qlist[0] ,  qlist[1] \n', '   close,dateref= date_align(qlist,type1=priceid)   \n', '   print len(sym),dateref[0],dateref[-1] \n', '   symfull= symfull+sym\n', '   masset,tmax= np.shape(close);\n', '   close2[(k):(k+masset),0:tmax] = close\n', ' \n', ' maxasset= k+masset\n', ' tmaxx= util.find(0.0, close2[0,:])\n', ' for k in xrange(0,maxasset):\n', '   if close2[k,tmaxx-1] == 0.0 : close2[k,tmaxx-1]=   close2[k,tmaxx-2]\n', ' \n', ' return close2[0:maxasset,0:tmaxx], symfull, dateref\n', '\n', '\n', ""def imp_sql_getquotes(stocklist01, dbname='sqlite:///aaserialize/store/yahoo.db', start1=20150101, end1=20160616, table1='daily_us_stock'):\n"", '    import data.hist_data_storage as yhh\n', '    dstore = yhh.dailyDataStore(dbname)\n', '    qlist, sym= dstore.get_histo(stocklist01, table1=table1,  start1=start1, end1=end1, split_df=1)\n', '    return qlist, sym\n', '\n', ""def imp_txt_getquotes(stocklist01, filedir='E:/_data/stock/daily/20160610/jp', startdate=20150101, endate=20160616):\n"", ' liststockfile= util.listallfile(filedir, ""*.txt"", dirlevel=5)\n', ' #print liststockfile\n', ' if len(np.shape(liststockfile)) > 1 :\n', '  liststockname=[ x.split(""."")[0] for x in liststockfile[:,0] ]\n', '#  for k in range(0, np.shape(liststockfile)[0]):  liststockname.append( (liststockfile[k,0])[0:4])   \n', '   \n', ' else: \n', '  stk0= liststockfile[0]; #stk2= liststockfile[2]\n', '#  liststockname=[ x[0:4] for x in stk0 ]\n', '  liststockname=[ x for x in stk0 ]\n', '\n', '#  liststockname=[]\n', '#  for k in range(0, len(stk0)):  liststockname.append( (stk0[k])[0:4])\n', ' \n', ' quotes=[]\n', ' print liststockname\n', ' for sym in stocklist01:\n', '   kstock= util.np_findfirst(sym, liststockname)\n', '   if kstock == -1 :\n', ""     print('Not Found '+sym)\n"", '   else :\n', '     df= pd.read_csv(liststockfile[kstock][2])\n', ""     df.columns = ['date', 'open', 'high','low','close', 'volume', 'openint']  #Change Column Name\n"", '     df2= df[(df.date > startdate  )& ( df.date   < endate )] # Filter by date\n', '     quotes.append(df2)\n', '  \n', ' return quotes \n', '\n', '\n', 'def imp_csv_getname(name1, date1, inter, tframe):\n', "" file1= dirstockcsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", ' return file1\n', '\n', '\n', 'from dateutil import tz\n', ""def imp_csv_toext(file1='SPY.csv', outputfile='.h5', fromzone='Japan', tozone='UTC', header=None,\n"", ""                  cols=['date', 'time','open','high','low','close','volume', 'symbol'], coldate=[0]):\n"", ""  ''' cols: column name,  coldate: position of date column   '''\n"", '  from dateutil import parser\n', '\n', '  if os.path.getsize(file1)> 500 :\n', ""   df = pd.read_csv(file1,sep=',',header=header)  # date_parser=dateparse)  # parse_dates={'date': [] },\n"", '   df.date= [ parser.parse(x) for x in  df.date]\n', '\n', ""   #if util.find('symbol', df.columns.values) < 0 :\n"", ""     #df= util.pd_addcol(df, 'symbol')\n"", ""     #df['symbol']= sym\n"", '\n', ""   type1= outputfile[outputfile.find('.'):]\n"", '\n', ""   if outputfile=='':\n"", '     # df.columns = [  x.lower() for x in df.columns.values ]\n', ""     # df.columns = ['date', 'symbol','open','high','low','close','volume']\n"", '     df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""     df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""     df.columns = ['date', 'open','high','low','close','volume', 'symbol']\n"", '     return df[cols]\n', '\n', ""   if type1=='csv' :\n"", ""     df[cols].to_csv(outputfile , index=False)  # , compression='gzip' )\n"", '\n', ""   if type1== 'h5' :\n"", ""      # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '      dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '      # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '      # df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '      # df.date= [x.to_datetime() for x in  df.date]\n', '\n', '      df.drop(df.columns[[0]], axis=1, inplace=True)\n', '      print filenameh5\n', ""      if util.find('symbol', df.columns.values) < 0 :\n"", ""         df= util.pd_addcol(df, 'symbol'); df['symbol']= dfname\n"", '      store = pd.HDFStore(outputfile); store.append(dfname, df);  store.close()\n', '\n', '\n', '\n', ""def imp_hdfs_db_updatefromcsv(dircsv, filepd=r'E:\\_data\\stock\\intraday_google.h5', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= filepd + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2, name1, fromtimezone, tozone)\n', '\n', ""def imp_hdfs_db_dumpinfo(dbfile='E:\\_data\\stock\\intraday_google.h5'):\n"", '  store = pd.HDFStore(dbfile)\n', '  extract=[]; errsym=[]\n', '  for symbol in store.keys():\n', '     try:\n', '       df= pd.read_hdf(dbfile, symbol)\n', ""       t0= df['date'].values[0]\n"", ""       t1= df['date'].values[-1]\n"", '\n', '       extract.append([symbol[1:], df.shape[1],   df.shape[0], t0, t1 ])\n', '\n', '     except: errsym.append(symbol)\n', '  return np.array(extract), errsym\n', '\n', 'def imp_hdfs_mergedb(filepdfrom, filepdto) :\n', '  store0 = pd.HDFStore(filepdfrom)\n', '  store1 = pd.HDFStore(filepdto)\n', '\n', '  for symbol in store0.keys():\n', '    qq= imp_hdfs_getquote(filepdfrom, symbol)\n', '    store1.append(symbol, qq)\n', '\n', '    qq= imp_hdfs_getquote(filepdto, symbol)\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    print(symbol)\n', '  store0.close(); store1.close()\n', '\n', ""def imp_hdfs_storecopy(hdfs1='F:/usstock8.h5', hdfs2='F:/usstock8.h5'):\n"", ' store = pd.HDFStore(hdfs1);  store2 = pd.HDFStore(hdfs2)\n', ' for symbol in store.keys() :\n', '   df= imp_hdfs_getquote(hdfs1, symbol)\n', '   symbol= symbol[1:].replace(""-"",""_"")\n', '   store2.append(symbol, df, data_columns=True)\n', ' store.close(); store2.close()\n', '\n', 'def imp_hdfs_getquote(filenameh5, dfname=""data""):\n', '  try: return  pd.read_hdf(filenameh5, dfname)\n', '  except: return -1.0;\n', '\n', ""def imp_hdfs_getListquote(symbols, close1='close', start='12/18/2015 00:00:00+00:00',\n"", ""                          end='3/1/2016 00:00:00+00:00', freq='0d0h10min', filepd= 'E:\\_data\\stock\\intraday_google.h5',\n"", ""                          tozone='Japan', fillna=True, interpo=True):\n"", '\n', ' datefilter= pd.date_range(start=start, end=end, freq= freq,tz=tozone).values\n', '\n', ' errorsym=[]; quotes=[]; correctsym=[]\n', ' for symbol in symbols:  # Issue Not same size\n', '   qq= imp_hdfs_getquote(filepd, symbol)\n', '\n', '   if type(qq)==np.float :  # Error qq=-1\n', '        errorsym.append(symbol)\n', '   else:\n', ""       qq.columns = ['date', 'symbol','open','high','low','close','volume']\n"", ""       qq= qq[qq['date'].isin(datefilter)]   #Only date in the range\n"", ""       #qq= qq.drop_duplicates(cols='date', take_last=True)\n"", ""       #  qq= qq.sort('date', asc=True)\n"", '\n', '       #print qq.date.values[0]\n', ""       if fillna : qq= qq.fillna(method='backfill')\n"", '       if interpo : qq= qq.interpolate()\n', '       quotes.append(qq)\n', '       correctsym.append(symbol)\n', '\n', ' datefilter= datenumpy_todatetime(datefilter)\n', ' return quotes,datefilter, correctsym,   errorsym\n', '\n', '\n', ""def imp_hdfs_removeDuplicate(filepd='E:\\_data\\stock\\intraday_google.h5') :\n"", '  #-------Clean by removing duplicate-------------------------------------------------\n', '  store = pd.HDFStore(filepd)\n', '  for symbol in store.keys():\n', '    #qq= imp_hdfs_getquote(filepd, symbol);\n', '    qq= store.select(symbol[1:])\n', ""    qq= qq.drop_duplicates(subset='date', take_last=True)\n"", ""    qq= qq.sort('date', ascending=1)\n"", '    qq.index = list(np.arange(0,len(qq.index)))\n', '\n', '    store.remove(symbol); store.append(symbol, qq);\n', '  store.close()\n', '\n', '\n', '\n', ""def imp_pd_tohdfs(sym, qqlist, filenameh5, fromzone='Japan', tozone='UTC') :\n"", ""  ''' df list to HDFS '''\n"", '  store = pd.HDFStore(filenameh5);\n', '  for k, df2 in enumerate(qqlist) :\n', '    df= copy.deepcopy(df2)\n', ""    df['date']= datetime_toint(df.date.values)\n"", '\n', ""    symbol= sym[k].replace('-','_')\n"", '    qq= imp_hdfs_getquote(filenameh5, symbol)\n', '    # print symbol, type(qq)\n', '    if type(qq) ==  float or  type(qq) ==  int  :\n', '      store.append(symbol, df)  # , data_columns=True\n', '      # print(symbol + str(df.date.values[-1]))\n', '    else :\n', '      qq= pd.concat([qq, df], ignore_index=True)\n', ""      qq= qq.drop_duplicates(subset='date', keep='last')\n"", ""      qq= qq.sort('date', ascending=1)\n"", '      store.append(symbol, qq)  #Too much space , data_columns=True\n', '      print(symbol + str(qq.date.values[-1]))\n', '\n', '  store.close()\n', '\n', 'def imp_pd_merge(df1, df2) :\n', '  df= pd.concat([df1, df2], axis=0)\n', ""  df= df.drop_duplicates(subset='date', keep='last')\n"", ""  df= df.sort_values(by=['date'], ascending=1)\n"", '  df.index = list(np.arange(0,len(df.index)))\n', '  return df\n', '\n', 'def imp_pd_checkquote(quotes) :\n', ""   for c in quotes: print np.shape(c), c['date'].values[0], c['date'].values[-1]\n"", '\n', 'def imp_pd_getclose(df, datefilter=None):\n', ' if datefilter is  not None :\n', ""    df= df[df['date'].isin(datefilter)]   #Only date in the range\n"", "" df= df.sort('date')\n"", "" close= df.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", ' \n', ' close= np.array(close.values[1:,1:]).astype(np.float)            #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close\n', '\n', 'def imp_pd_cashyield(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  100 * np.cumprod( (1 + np.ones(len(vv)) * 0.005/365.0 ))\n', '     qbond[id1]= pbond\n', '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_yield_tobond(q, duration=10):\n', ' qbond= copy.deepcopy(q)\n', "" for id1 in ['close','open','high','low','aclose'] :\n"", '   try:\n', '     vv= q[id1].values\n', '     pbond=  1/ np.power(1+ vv*0.01,duration) *100\n', '     qbond[id1]= pbond\n', ""#     print 'ok'\n"", '   except: pass\n', ' return qbond\n', '\n', 'def imp_pd_errordate(quotes, dateref):\n', "" ''' Show Symbol in Error when importing '''\n"", ' for i, stock in enumerate(quotes) :\n', '   print(i, symbols1[i],  datetime_tostring(stock[0][0]))\n', ' print(""\\n\\n"")\n', '\n', ' for i, stock in enumerate(quotes) :\n', '   date1= datetime_toint(stock[0][0])\n', '   if date1 != dateref : print(i, symbols1[i],  str(date1))\n', '\n', 'def imp_pd_fxtoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', 'def imp_pd_fxinversetoprice(q):\n', ' dfprice= copy.deepcopy(q)\n', "" for kid in ['close','open','high','low'] :\n"", '   qret= getret_fromquotes(1.0 / q[kid].values,1)\n', '   qprice= price_normalize100(qret)\n', '   dfprice[kid]= qprice.T\n', ' return dfprice\n', '\n', ""def imp_pd_filterbydate(df, dtref=None, start='2016-06-06 00:00:00', end='2016-06-14 00:00:00', freq='0d0h05min', timezone='Japan'):\n"", "" ''' df: DateSeries or TimeSeries of Quotes   '''\n"", '\n', ' if type(df) in {pd.core.frame.DataFrame} :  #Data frame version\n', '   if type(dtref)== str:\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', ""   return df[df['date'].isin(dtref)]\n"", ' else :\n', '   if type(dtref)== str:  #Date version\n', '      dtref= pd.date_range(start=start, end=end, freq= freq,tz=timezone).values\n', '\n', '   return df[df.isin(dtref)].values\n', '\n', 'def imp_pd_cleanquote(q):\n', ' col= q.columns.values\n', "" if isinstance(q['date'].values[0] , str) :\n"", ""   q['date']= datetime_todate(datestring_todatetime(q['date'].values))\n"", '\n', ' for kid in col:\n', ""   if kid not in ['date', 'day','month','year'] :\n"", ""      q[kid]= pd.to_numeric(q[kid], errors='coerce').values  #Put NA on string\n"", '\n', "" q= q.fillna(method='pad')\n"", ' return q\n', '\n', 'def imp_pd_divide(q1, q2, funapply):\n', "" close, dateref= date_align([q1,q2], type1='close')\n"", ' m,tt= np.shape(close)\n', '\n', ' q3= util.pd_createdf( np.zeros((tt,len(q1.columns))) ,q1.columns, dateref)\n', "" q3['date']= dateref\n"", "" q3['close']= (close[0,:] / close[1,:])\n"", '\n', ' for kid in q1.columns :\n', ""   if kid not in ['close', 'volume','date','day','month', 'year'] :\n"", '     close, _= date_align([q1,q2], type1=kid)\n', '     q3[kid]= (close[0,:] / close[1,:])\n', ' return q3\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""def imp_quote_csvdir_tofile(dircsv='', outdir1='E:/_data/stock/', fromtimezone='Japan', tozone='UTC'):\n"", ' lfile= util.os_file_listall(dircsv, pattern=""*.csv"", dirlevel=0)\n', ' for x in lfile:\n', '   name1= (x[0]).split(""_"")[0] #get Ticker name, splitting by _\n', ""   if util.str_isfloat(name1):  name1= 'jp'+name1  #Japanese Stocks case\n"", '   file1 = x[2];  print(name1)\n', '   if os.path.getsize(file1)> 500:\n', ""      filepd2= outdir + '/' +name1 +'.csv'\n"", '      imp_csv_toext(file1, filepd2,  header=True, fromzone=fromtimezone, tozone=tozone)\n', ""'''\n"", '\n', '\n', ""'''\n"", ""close1='Close' ; start='12/18/2015 00:00:00';\n"", ""end='3/1/2016 00:00:00'; freq='1d0h00min';\n"", ""filepd= 'E:\\_data\\stock\\intraday_google.h5'\n"", '\n', 'datefilter= pd.date_range(start=start, end=end,   freq= freq).values\n', '\n', 'symbols, names = np.array(list(symbol_dict.items())).T\n', 'i=0; vv=[]\n', 'for symbol in symbols:  # Issue Not same size\n', '   qq= quote_frompanda(filepd, symbol); i+=1\n', '   if isfloat(qq) :  vv.append(symbol)\n', '   else:\n', ""     if i==1: close = qq[['Datetime']]  #new dataframe    \n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', '     if not tmp.isnull().values.all():\n', ""      close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""      close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', ""close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", ""close= close.sort('Datetime')\n"", ""close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", 'close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', 'close= close[(np.abs(stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', ""'''\n"", 'from datetime import datetime\n', 'from dateutil import tz\n', '\n', ""from_zone = tz.gettz('Japan'); to_zone = tz.gettz('UTC')\n"", '\n', ""date1 = datetime.strptime('2011-01-21 09:00:00', '%Y-%m-%d %H:%M:%S')\n"", 'date1 = date1.replace(tzinfo=from_zone)\n', 'dateutc = date1.astimezone(to_zone)\n', 'date1, dateutc\n', '\n', ""Suppose you have a column 'datetime' with your string, then:\n"", ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates=['datetime'], date_parser=dateparse)\n"", ' combine multiple columns into a single datetime column,\n', ""this merges a 'date' and a 'time' column into a single 'datetime' column:\n"", '\n', ""dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", '\n', ""df = pd.read_csv(infile, parse_dates={'datetime': ['date', 'time']}, date_parser=dateparse)\n"", ""'''\n"", '\n', '\n', '#date1 = ""20160302""; inter= 60; tframe=80; name1= ""spy""\n', '#googleIntradayQuoteSave(name1, inter, tframe)\n', '\n', '\n', '\n', 'def ta_mar(close,t,m):  return  100*( np.mean(close[(t-m):(t+1)], axis=0) / close[t] )\n', 'def ta_ma(close,t,m):  return   np.mean(close[(t-m):(t+1)], axis=0)\n', '\n', '\n', '############################################################################\n', '#---------------------Calculate the Statistics         --------------------  \n', 'def calc_statestock(close2, dateref, symfull):\n', ' def sort(x,col,asc): return   util.sortcol(x,col,asc)\n', ' def perf(close,t0,t1):  return  100*( close[:,t1] / close[:,t0] -1)\n', ' def and2(tuple1):  return np.logical_and.reduce(tuple1)\n', ' def mar(close,t,m):  return  100*( np.mean(close[:,(t-m):(t+1)], axis=1) / close[:,t] )\n', ' def ma(close,t,m):  return   np.mean(close[:,(t-m):(t+1)], axis=1)\n', '\n', '\n', ' # a= ma(close2, tmax, 5) / ma(close2, tmax, 50)  \n', '\n', '\n', ' def dd(t) :\n', '  x= util.find(t,dateref)  # 607\n', ""  if x==-1 : print 'Error date not found in dateref '+str(t) ; return np.nan\n"", '  else :  return x\n', '\n', ' def gap(close,t0,t1,lag):   \n', '  ret= getret_fromquotes(close[:,t0:t1],lag)\n', '  rmin= 100*np.amin(ret,axis=1)\n', '  return rmin\n', ' \n', ' #--------------------Size----------------------------------------- \n', ' masset= len(symfull)\n', ' ttmax= util.find(0,close2[0,:])\n', ' if ttmax==-1 : ttmax= np.shape(close2)[1]\n', ' close2= close2[0:masset,0:ttmax]\n', ' m, tmax= masset, ttmax-1\n', ' \n', ' #correl\n', ' #close3= np.array(close2[:,0:ttmax],dtype=np.float16)\n', ' #close2ret= getret_fromquotes(close3)\n', ' #close2ret= np.nan_to_num(close2ret)\n', ' #close2ret= util.np_cleanmatrix(close2ret);  del close3\n', '\n', '##################################################################################\n', '#1: 1d,2:5d,3:10d,4:15d,5:20d,11:50d,12:60d,13:90d,15:1y\n', '#16: YTD,17:From Feb,21: 2015Ret,45: Price,50,51: Min,52,53: Max\n', ' print(""Calcul the Stats "" + str(dateref[-1]))\n', ' stat= np.zeros((2600,200),dtype=np.float16)\n', '\n', ' k=0\n', ' stat[k:(k+m),0]= np.arange(k,k+m)\n', ' stat[k:(k+m),1]=  perf(close2,tmax-1,tmax)  \n', ' stat[k:(k+m),2]=  perf(close2,tmax-5,tmax)  \n', ' stat[k:(k+m),3]=  perf(close2,tmax-10,tmax)  \n', ' stat[k:(k+m),4]=  perf(close2,tmax-15,tmax)  \n', ' stat[k:(k+m),5]=  perf(close2,tmax-20,tmax)  \n', '# stat[k:(k+m),6]=  perf(close2,tmax-25,tmax)  \n', ' stat[k:(k+m),7]=  perf(close2,tmax-30,tmax)  \n', '# stat[k:(k+m),8]=  perf(close2,tmax-35,tmax)  \n', ' stat[k:(k+m),9]=  perf(close2,tmax-40,tmax)  \n', '# stat[k:(k+m),10]=  perf(close2,tmax-45,tmax)  \n', ' stat[k:(k+m),11]=  perf(close2,tmax-50,tmax)  \n', ' stat[k:(k+m),12]=  perf(close2,tmax-60,tmax)  \n', ' stat[k:(k+m),13]=  perf(close2,tmax-90,tmax)  \n', ' stat[k:(k+m),14]=  perf(close2,tmax-120,tmax)  \n', ' stat[k:(k+m),15]=  perf(close2,tmax-250,tmax)  \n', '\n', '\n', '# stat[k:(k+m),16]=  perf(close2, dd(20160105),tmax)   #1Jan 2016\n', '# stat[k:(k+m),17]=  perf(close2, dd(20160222),tmax)   # 22 Feb 2016\n', '# stat[k:(k+m),18]=  perf(close2,dd(20160105),dd(20160222))   # Crash DrawDown\n', ' # stat[k:(k+m),19]=  perf(close2,624,tmax)   #  24 June 2016\n', ' # stat[k:(k+m),20]=  perf(close2,623,625)   #  Crash 24 June 2016\n', ' # stat[k:(k+m),21]=  perf(close2,dd(20151230)-250,dd(20151230))    #2015 Return\n', '\n', ' stat[k:(k+m),22]= gap(close2,tmax-80,tmax,1) #Max 1 days Gap\n', ' stat[k:(k+m),23]= gap(close2,tmax-80,tmax,5) #Max 5 days Gap\n', ' stat[k:(k+m),24]= perf(close2,tmax-2,tmax)  \n', ' stat[k:(k+m),25]= perf(close2,tmax-3,tmax)  \n', ' stat[k:(k+m),26]= perf(close2,tmax-4,tmax)  \n', '\n', ' stat[k:(k+m),27]= perf(close2,tmax-2,tmax-1)   \n', ' stat[k:(k+m),28]= perf(close2,tmax-3,tmax-2)   \n', ' stat[k:(k+m),29]= perf(close2,tmax-4,tmax-3)   \n', ' stat[k:(k+m),30]= perf(close2,tmax-5,tmax-4)\n', ' \n', ' stat[k:(k+m),120]= mar(close2, tmax, 20) \n', ' stat[k:(k+m),121]= mar(close2, tmax, 50) \n', ' stat[k:(k+m),122]= 100*ma(close2, tmax, 5) / ma(close2, tmax, 50)  #OverSold /OverBought\n', ' stat[k:(k+m),123]= mar(close2, tmax, 100)  \n', ' stat[k:(k+m),124]= mar(close2, tmax, 10) \n', '# stat[k:(k+m),35]= 0 \n', '# stat[k:(k+m),36]= 0 \n', '# stat[k:(k+m),37]= 0 \n', '# stat[k:(k+m),38]= 0 \n', '# stat[k:(k+m),39]= 0 \n', '\n', ' # stat[k:(k+m),30]= volume / AvgVol3M\n', ' # stat[k:(k+m),30]= Nbday_to_Earnings\n', ' #Volume/3M AvgVolume\n', ' # stat[k:(k+m),26]=  volume(volume2,tmax-120,tmax)  \n', '\n', ' #==============================================================================\n', ' #-------------- Data Fundamental    -------------------------------------------\n', "" df= util.sql_query(sqlr='SELECT ticker,shortratio,sector1_id, sector2_id, marketcap   FROM stockfundamental ', dburl='/aaserialize/store/finviz.db')\n"", ' npdf= df.values; del df\n', ' npdf0= npdf[:,0]  \n', ' for i in range(0,m):  \n', '   try :\n', '     kid= util.find(symfull[i], npdf0)\n', '     if kid != -1 :\n', '      stat[i,150]=  float(npdf[kid, 1])   # short ratio\n', '      stat[i,151]=  float(npdf[kid, 2])   # sector 1      \n', '      stat[i,152]=  float(npdf[kid, 3])   # sector 2     \n', '      stat[i,153]=  float(npdf[kid, 4] / 100000000.0)   # market Cap    \n', '   except : pass\n', ' del npdf, npdf0\n', '\n', '\n', '#==============================================================================\n', ' ################ Volatility\n', ' stat[k:(k+m),40]= volhisto_fromprice(close2,tmax,20,axis=1)* 100\n', ' stat[k:(k+m),41]= volhisto_fromprice(close2,tmax,60,axis=1)* 100\n', ' stat[k:(k+m),42]= volhisto_fromprice(close2,tmax,252,axis=1)* 100\n', '# stat[k:(k+m),43]= stat[k:(k+m),12] / stat[k:(k+m),41] #Sharpe 3Month\n', '# stat[k:(k+m),44]= stat[k:(k+m),15] / stat[k:(k+m),42] #Sharpe 1Year\n', '\n', ' stat[k:(k+m),45]= close2[:,tmax] #Last Close\n', '\n', '# stat[k:(k+m),46]= 0 \n', '# stat[k:(k+m),47]= 0 \n', '# stat[k:(k+m),48]= 0 \n', '# stat[k:(k+m),49]= 0 \n', '\n', '\n', ' ###############  Technical Indicator\n', ' #Min of last 6 months, Max of last 6months\n', ' for i in range(0,m):\n', '  pp0= stat[i,45]\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-120):tmax])\n', '  stat[i,50]= kmin+(tmax-120);  stat[i,51]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-120):tmax])\n', '  stat[i,52]= kmax+(tmax-120);  stat[i,53]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-10):tmax])\n', '  stat[i,66]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-10):tmax])\n', '  stat[i,67]= 100*pp0 / pmax\n', '\n', '  kmin,pmin= util.np_find_minpos(close2[i,(tmax-5):tmax])\n', '  stat[i,68]= 100*pp0 / pmin\n', '\n', '  kmax,pmax= util.np_find_maxpos(close2[i,(tmax-5):tmax])\n', '  stat[i,69]= 100*pp0 / pmax\n', '\n', ' del kmax,pmax,i,k  \n', '\n', '\n', ' #Regression from Min Price Time\n', ' for i in range(0,m):\n', '  t0= int(stat[i,50])\n', '  try :\n', '    res= regression(close2[i,t0:tmax ]  ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,54]=  res[2]  #R2\n', '    stat[i,55]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from Max Price Time\n', ' for i in range(0,m):  \n', '  t0= stat[i,52]\n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,56]=  res[2]  #R2\n', '    stat[i,57]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', ' #Regression from 5 days ago\n', ' t0= tmax-5\n', ' for i in range(0,m): \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,58]=  res[2]  #R2\n', '    stat[i,59]=  res[0][0]  #Slope\n', '  except : pass\n', '\n', '#Regression from 10 days ago\n', ' t0= tmax-10\n', ' for i in range(0,m):  \n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,60]=  res[2]  #R2\n', '    stat[i,61]=  res[0][0]  #Slope\n', '   except : pass\n', '\n', "" '''\n"", '#Regression from 1 month\n', ' t0= tmax-20   \n', ' for i in range(0,m):\n', '   try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,62]=  res[2]  #R2\n', '    stat[i,63]=  res[0][0]  #Slope\n', '   except : pass\n', "" '''\n"", '\n', "" '''\n"", '#Regression from 2 months ago\n', ' t0= tmax-40\n', ' for i in range(0,m):  \n', '  try :\n', '    res= regression(close2[i,t0:tmax ] ,np.arange(t0,tmax),type1=""linear"")\n', '    stat[i,64]=  res[2]  #R2\n', '    stat[i,65]=  res[0][0]  #Slope\n', '  except : pass\n', "" '''\n"", '\n', '#Nb of Positive days last 5d\n', ' for i in range(0,m):  stat[i,66]=  np_countretsign(close2[i,(tmax-5):tmax])  \n', '\n', '#Nb of Positive days last 10d\n', ' for i in range(0,m):  stat[i,67]=  np_countretsign(close2[i,(tmax-10):tmax])  \n', '\n', '#Nb of Positive days last 20d\n', '# for i in range(0,m):  stat[i,68]=  np_countretsign(close2[i,(tmax-20):tmax])  \n', '\n', '\n', '#Regression from Max Values,200days\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,70]=  res[2]  #R2\n', '    stat[i,71]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmax\n', '\n', '\n', '#Regression from Min Values,200days \n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,72]=  res[2]  #R2\n', '    stat[i,73]=  res[0][0]  #Slope\n', '  except : pass\n', '# del vmin\n', '\n', '\n', '#Regression from Max Values,100days\n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmax[:,1] ,vmax[:,0],type1=""linear"")\n', '    stat[i,74]=  res[2]  #R2\n', '    stat[i,75]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmax\n', '\n', '\n', '#Regression from Min Values,100days \n', ' t0= tmax-20*5\n', ' for i in range(0,m):  \n', '  try :\n', '    vmin= util.np_findlocalmin2(close2[i,t0:tmax ] ,6)\n', '    res= regression(vmin[:,1] ,vmin[:,0],type1=""linear"")\n', '    stat[i,76]=  res[2]  #R2\n', '    stat[i,77]=  res[0][0]  #Slope\n', '  except : pass\n', ' del vmin\n', '\n', '\n', '\n', '# Upside Trend with Higher Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '   vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '   vmax= util.sort(vmax,0,asc=0)\n', '   stat[i,80]=  -1\n', '   if len(vmax) > 1 :\n', '    ss=0\n', '    for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '    if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,80]=  ss  \n', '        stat[i,81]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Upside Trend with Higher High detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  try :\n', '    vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '    vmax= util.sort(vmax,0,asc=0)\n', '    stat[i,82]=  -1\n', '    if len(vmax) > 1 :\n', '      ss=0\n', '      for k in range(0,len(vmax)-1):\n', '        if vmax[k,1] > vmax[k+1,1] : ss+=1   #Higher high\n', '        else : break;\n', '      if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,82]=  ss  \n', '        stat[i,83]=  vmax[0,0] + t0\n', '  except: pass\n', '\n', '\n', '# Downside Trend with lower Lows detection\n', ' t0= tmax-20*10\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmin2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,84]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,84]=  ss  \n', '        stat[i,85]=  vmax[0,0] + t0\n', '\n', '\n', '# Downside Trend  with lower highs detection\n', ' t0= tmax-20*6\n', ' for i in range(0,m):  \n', '  vmax= util.np_findlocalmax2(close2[i,t0:tmax],4)\n', '  vmax= util.sort(vmax,0,asc=0)\n', '  stat[i,80]=  -1\n', '  if len(vmax) > 1 :\n', '   ss=0\n', '   for k in range(0,len(vmax)-1):\n', '     if vmax[k,1] < vmax[k+1,1] : ss+=1   #Higher lows\n', '     else : break;\n', '  \n', '   if tmax - vmax[0,0]-t0 < 30  :  \n', '        stat[i,86]=  ss    #Nb  of lower high consecutive\n', '        stat[i,87]=  vmax[0,0] + t0\n', '\n', "" print('Higher/Lower Band Support')\n"", '#-----higher band Support / Lower Band Support 120days-------------------------------\n', ' t0= tmax-120\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,90]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,91]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,92]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '    # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1]) \n', '    # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 200days-------------------------------\n', ' t0= tmax-200\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,93]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,94]= 100.0 * stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,95]= 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', '#-----higher band Support / Lower Band Support 300days-------------------------------------\n', ' t0= tmax-300\n', ' for i in range(0,m): \n', '  try :\n', '    res1= ta_highbandtrend1(close2[i,t0:tmax])\n', '    pmax= (res1.x[0] * (tmax-t0) + res1.x[1]) \n', '    stat[i,96]= 100.0 * stat[i, 45] / pmax   # Higher Band\n', '\n', '    res2=  ta_lowbandtrend1(close2[i,t0:tmax])\n', '    pmin=  (res2.x[0] * (tmax-t0) + res2.x[1]) \n', '    stat[i,97]= 100.0* stat[i, 45] / pmin    # LowerBand\n', '\n', '    stat[i,98]= 100.0* (pmax - stat[i, 45]) / (pmax - pmin)    # Price inside Range\n', '\n', '  except: pass\n', '\n', '\n', ""  '''\n"", '  # -----higher band Support / Lower Band Support 60days-------------------------------\n', '  t0 = tmax - 60\n', '  for i in range(0, m):\n', '      try:\n', '          res1 = ta_highbandtrend1(close2[i, t0:tmax])\n', '          pmax = (res1.x[0] * (tmax - t0) + res1.x[1])\n', '          stat[i, 99] = 100.0 * stat[i, 45] / pmax  # Higher Band\n', '\n', '          res2 = ta_lowbandtrend1(close2[i, t0:tmax])\n', '          pmin = (res2.x[0] * (tmax - t0) + res2.x[1])\n', '          stat[i, 100] = 100.0 * stat[i, 45] / pmin  # LowerBand\n', '\n', '          stat[i, 101] = 100.0 * (pmax - stat[i, 45]) / (pmax - pmin)  # Price inside Range\n', '\n', '          # pmin=  (res2.x[0] * (np.arange(t0,tmax)-t0) + res2.x[1])\n', '          # breachmin= np.sum(np.sign(close2[i, t0:tmax] - pmin*1.03))\n', '      except:\n', '          pass\n', ""  '''\n"", '\n', '  #-----Technical Indicator------------------------------------------------\n', '# for i in range(0,m): \n', '#  try :\n', '#   res2=0\n', '   # df= pd.read_hdf(dbfile, symfull[i])\n', '   # stat[i,110]= ta.RMI(close2[i,:])\n', '   # stat[i,111]= 100*close2[i,:] / ta.MA(close2[i,:],20)\n', '   # stat[i,112]= 100*close2[i,:] / ta.MA(close2[i,:],50)   \n', '#  except: pass\n', '\n', '\n', ' return np.array(stat, dtype=np.float16) \n', '\n', '\n', ""'''  \n"", 'i=1964  \n', 'stat= s1\n', 'stat[i, 91]  \n', '\n', 'tt= np.arange(t0, tmax)\n', 'plot_price(close2[i,t0:tmax], (res2.x[0] * (tt-t0) + res2.x[1]) )\n', ""'''\n"", '\n', '  \n', '#------------------- Stock Monitoring Tools ------------------------------------------------\n', ""def monitor_addrecommend(string1, dbname='stock_recommend') :\n"", ' ss= string1.replace(""("","" "").replace(\')\',\' \').replace(\':\',\' \')\n', "" ss= ss.replace('\\t', ' ').replace('\\n', ' ')\n"", ' sl1= ss.split("" "")\n', ' print sl1\n', ' aux= [datestring_toint(util.date_now())]\n', ' symfull= copy.deepcopy(a_us_all)\n', ' for x in sl1:\n', '   if len(x) < 5 :\n', '    if util.find(x,symfull) > 0 :   aux.append(x)\n', '\n', ' if len(aux) >  1 :\n', '  stock_recommend= util.load_obj(dbname)\n', '  stock_recommend.append(aux)\n', '  util.save_obj(stock_recommend,dbname)\n', '  print aux\n', ' return stock_recommend\n', '\n', '\n', '\n', '#################### Finviz  ###############################################################\n', 'from bs4 import BeautifulSoup\n', 'import csv,datetime, requests\n', 'def imp_finviz():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Overview Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=111&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(111) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 10].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 10\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockoverview.csv', 'wb') as csvfile:\n"", ""    overview = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    overview.writeheader()\n', '\n', '    for stock in alldata:\n', '        overview.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10] })\n', '\n', ' print ""Finviz Overview Completed""\n', ' return overview\n', ' \n', '\n', 'def imp_finviz_news():\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print ""Finviz Performance Start""\n', ' url = ""http://www.finviz.com/quote.ashx?t=intc""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', ' titleslist = soup.find_all(\'a\',{""class"" : ""tab-link-news""})\n', ' return titleslist\n', '\n', '\n', 'def imp_finviz_financials():\n', ' import datetime\n', ' #pdb.set_trace() - python step by step debugger command\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Start""\n', ' url = ""http://www.finviz.com/screener.ashx?v=161&f=geo_usa""\n', ' response = requests.get(url)\n', ' html = response.content\n', ' soup = BeautifulSoup(html)\n', "" firstcount = soup.find_all('option')\n"", ' lastnum = len(firstcount) - 1\n', "" lastpagenum = firstcount[lastnum].attrs['value']\n"", ' currentpage = int(lastpagenum)\n', '\n', ' alldata = []\n', ' templist = []\n', ' # Overview = 111, Valuation = 121, Financial = 161, Ownership = 131, Performance = 141\n', ' #pagesarray = [111,121,161,131,141]\n', ' titleslist = soup.find_all(\'td\',{""class"" : ""table-top""})\n', ' titleslisttickerid = soup.find_all(\'td\',{""class"" : ""table-top-s""})\n', ' titleticker = titleslisttickerid[0].text\n', ' titlesarray = []\n', ' for title in titleslist:\n', '    titlesarray.append(title.text)\n', '\n', ' titlesarray.insert(1,titleticker)\n', ' i = 0\n', '\n', ' while(currentpage > 0):\n', '    i += 1\n', '    print str(i) + "" page(s) done""\n', '    secondurl = ""http://www.finviz.com/screener.ashx?v="" + str(161) + ""&f=geo_usa"" + ""&r="" + str(currentpage)\n', '    secondresponse = requests.get(secondurl)\n', '    secondhtml = secondresponse.content\n', '    secondsoup = BeautifulSoup(secondhtml)\n', '    stockdata = secondsoup.find_all(\'a\', {""class"" : ""screener-link""})\n', '    stockticker = secondsoup.find_all(\'a\', {""class"" : ""screener-link-primary""})\n', '    datalength = len(stockdata)\n', '    tickerdatalength = len(stockticker)\n', '\n', '    while(datalength > 0):\n', '        templist = [stockdata[datalength - 17].text,stockticker[tickerdatalength-1].text,stockdata[datalength - 16].text,stockdata[datalength - 15].text,stockdata[datalength - 14].text,stockdata[datalength - 13].text,stockdata[datalength - 12].text,stockdata[datalength - 11].text,stockdata[datalength - 10].text,stockdata[datalength - 9].text,stockdata[datalength - 8].text,stockdata[datalength - 7].text,stockdata[datalength - 6].text,stockdata[datalength - 5].text,stockdata[datalength - 4].text,stockdata[datalength - 3].text,stockdata[datalength - 2].text,stockdata[datalength - 1].text,]\n', '        alldata.append(templist)\n', '        templist = []\n', '        datalength -= 17\n', '        tickerdatalength -= 1\n', '    currentpage -= 20\n', '\n', "" with open('stockfinancial.csv', 'wb') as csvfile:\n"", ""    financial = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=titlesarray)\n"", '    financial.writeheader()\n', '\n', '    for stock in alldata:\n', '        financial.writerow({titlesarray[0] : stock[0], titlesarray[1] : stock[1],titlesarray[2] : stock[2],titlesarray[3] : stock[3],titlesarray[4] : stock[4], titlesarray[5] : stock[5], titlesarray[6] : stock[6], titlesarray[7] : stock[7] , titlesarray[8] : stock[8], titlesarray[9] : stock[9], titlesarray[10] : stock[10],titlesarray[11] : stock[11],titlesarray[12] : stock[12],titlesarray[13] : stock[13],titlesarray[14] : stock[14],titlesarray[15] : stock[15],titlesarray[16] : stock[16],titlesarray[17] : stock[17] })\n', '\n', ' print datetime.datetime.now()\n', ' print ""Finviz Financial Completed""\n', '\n', '\n', '\n', 'def get_price2book( symbol ):\n', '   from bs4 import BeautifulSoup as bs\n', '   import urllib as u\n', '   try:\n', ""    \turl = r'http://finviz.com/quote.ashx?t={}'.format(symbol.lower())\n"", '        html = u.request.urlopen(url).read()\n', ""        soup = bs(html, 'lxml')\n"", '        # Change the text below to get a diff metric\n', ""        pb =  soup.find(text = r'P/B')\n"", ""        pb_ = pb.find_next(class_='snapshot-td2').text\n"", ""        print( '{} price to book = {}'.format(symbol, pb_) )\n"", '        return pb_\n', '   except Exception as e:\n', '        print(e)\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ' try:\n', '   q = imp_googleQuote(name1, date1, date2)  #interval, timeframe\n', ""   name1= name1.replace(':','_')\n"", ""   file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(date2) +'.csv'\n"", '   q.write_csv(file1)\n', ' except: print\n', ""'''\n"", '\n', '\n', ""'''\n"", 'def imp_googleQuoteList(symbols, freqsec=300, nday=1, intraday1=True) :\n', ' qlist=[]; sym=[]\n', ' if intraday1:\n', '  for symbol in symbols:\n', '     #try :\n', '        q = imp_googleIntradayQuote(symbol, freqsec, nday)  #interval, timeframe\n', '        qlist.append(q)\n', '        sym.append(symbol)\n', ""     #except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       q = imp_googleQuote(name1, freqsec, num_days)  #interval, timeframe\n', '     except: print(symbol)\n', '\n', ' return qlist, sym\n', ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', '\n', ""'''        \n"", ""stock_list = ['XOM','AMZN','AAPL','SWKS']\n"", 'p2b_series = pd.Series( index=stock_list )\n', '\n', 'for sym in stock_list:\tp2b_series[sym] = get_price2book(sym)\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", "" # dateparse= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n"", ' from dateutil.parser import parse\n', ' if os.path.getsize(file1)> 500 :\n', '  from_zone = tz.gettz(fromzone); tozone = tz.gettz(tozone)\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', ""  # dateparse= lambda x: (pd.datetime.strptime(x,'%m-%d-%Y %H:%M:%S').replace(tzinfo=from_zone).astimezone(tozone))\n"", '\n', '  dateparse= lambda x: (parse(x).replace(tzinfo=from_zone).astimezone(tozone))\n', '\n', '  # dateparse= lambda x: parse(x, tzinfos=from_zone).astimezone(to_zone)\n', '  print file1\n', ""  #df = pd.read_csv(file1,sep=',',header=None, parse_dates={'date': [1]}, date_parser=dateparse)\n"", '\n', ""  df = pd.read_csv(file1,sep=',',header=0)\n"", '  #df.date= [pd.to_datetime((str(x)[:-6])) for x in  df.date]\n', '  #df.date= [x.to_datetime() for x in  df.date]\n', '\n', '\n', '  df.drop(df.columns[[0]], axis=1, inplace=True)\n', ""  df= util.pd_addcol(df, 'symbol')\n"", ""  df['symbol']= dfname\n"", '\n', '  print filenameh5\n', ""  df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", ""  df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", '\n', '  # store = pd.HDFStore(filenameh5);\n', '  # store.append(dfname, df);  store.close()\n', ""'''\n"", '\n', ""'''\n"", ""def imp_csv_toext(file1, filenameh5, dropcol=[], type1='csv', hasheader=True, dfname='sym1', fromzone='Japan', tozone='UTC'):\n"", ' if os.path.getsize(file1)> 500 :\n', '   header= 0 if hasheader else None\n', ""   df = pd.read_csv(file1, sep=',',header=0)\n"", '\n', '   df.drop(df.columns[dropcol], axis=1, inplace=True)\n', ""   df= util.pd_addcol(df, 'symbol');  df['symbol']= dfname\n"", ""   df.columns = ['date', 'open','high','low','close','volume', 'symbol' ]\n"", '\n', ""   if type1=='csv' :\n"", ""     df.to_csv(filenameh5 , index=False)  # , compression='gzip' )\n"", ""'''\n"", '\n', '\n', '\n', '\n', '\n', '\n', ""'''\n"", ""     if i==1: close = qq[['Datetime']]  #new dataframe\n"", '     tmp= pd.DataFrame(data={symbol: qq[close1]});\n', ""     close = close.join(tmp, how='outer', rsuffix='_1')\n"", ""     close= close.drop_duplicates(cols='Datetime', take_last=True)\n"", '\n', "" close= close[close['Datetime'].isin(datefilter)]   #Only date in the range\n"", "" close= close.sort('Datetime')\n"", "" close= close.interpolate(); close= close.fillna(method='backfill')  #Interpolate\n"", '\n', ' close= np.array(close.values[1:,1:]).astype(np.float)  #Only Price\n', ' close= close[(np.abs(sci.stats.zscore(close)) < 3).all(axis=1)] #Remove Outlier\n', ' return close, vv\n', ""'''\n"", '\n', '\n', '\n', ""'''\n"", 'class Quote(object):\n', ""  DATE_FMT = '%Y-%m-%d';  TIME_FMT = '%H:%M:%S'\n"", '\n', '  def __init__(self):\n', ""    self.symbol = '';    self.exchn=''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', '\n', '  def append(self,dt,open_,high,low,close,volume):\n', '    self.date.append(dt.date())\n', '    self.time.append(dt.time())\n', '    self.open_.append(float(open_))\n', '    self.high.append(float(high))\n', '    self.low.append(float(low))\n', '    self.close.append(float(close))\n', '    self.volume.append(int(volume))\n', '\n', '  def to_csv(self):\n', '    return \'\'.join([""{0},{1},{2},{3:.2f},{4:.2f},{5:.2f},{6:.2f},{7}\\n"".format(self.symbol,\n', ""              self.date[bar].strftime('%Y-%m-%d'),self.time[bar].strftime('%H:%M:%S'),\n"", '              self.open_[bar],self.high[bar],self.low[bar],self.close[bar],self.volume[bar])\n', '              for bar in xrange(len(self.close))])\n', '\n', '  def write_csv(self,filename):\n', ""    with open(filename,'w') as f:\n"", '      txt= self.to_csv()\n', '      f.write(txt)\n', '\n', '  def read_csv(self,filename):\n', ""    self.symbol = ''\n"", '    self.date,self.time,self.open_,self.high,self.low,self.close,self.volume = ([] for _ in range(7))\n', ""    for line in open(filename,'r'):\n"", ""      symbol,ds,ts,open_,high,low,close,volume = line.rstrip().split(',')\n"", '      self.symbol = symbol\n', ""      dt = datetime.datetime.strptime(ds+' '+ts,self.DATE_FMT+' '+self.TIME_FMT)\n"", '      self.append(dt,open_,high,low,close,volume)\n', '    return True\n', '\n', '  def __repr__(self):\n', '    return self.to_csv()\n', ""'''\n"", '\n', ' \n', '\n', ""'''\n"", ""def imp_googleIntradayQuoteSave2(name1, date1, inter, tframe, dircsv='', dbname=''):\n"", ' q = imp_googleIntradayQuote(name1, inter, tframe)  #interval, timeframe\n', "" name1= name1.replace(':','_')\n"", '\n', "" if dircsv != '' :\n"", ""    file1= dircsv+ '\\\\'+ name1+'_'+ date1 +'_'+ str(inter) +'_'+ str(tframe) +'.csv'\n"", '    q.to_csv(file1)\n', '\n', "" if dbname != '' :\n"", '    import sqlalchemy as sql\n', '    dbcon= sql.create_engine(dbname)\n', '    if inter== 300 : # 5mins\n', ""      q.to_sql('q5min', dbcon)\n"", '\n', '\n', ""def imp_googleQuoteList_save(symbols, date1, date2, inter=23400, tframe=2000, dircsv='', intraday1=True) :\n"", ' if intraday1:\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleIntradayQuoteSave(symbol, date1, inter, tframe, dircsv)\n', ""     except: print('Error:'+symbol)\n"", '\n', ' else :\n', '  for symbol in symbols:\n', '     try :\n', '       imp_googleQuoteSave(symbol, date1, date2, dircsv)\n', '     except: print(symbol)\n', ""'''\n"", '\n']","['np.shape', 'getret_fromquotes', 'len', 'getlogret_fromquotes', 'np.log', 'getprice_fromret']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:index,index,class,103,300,221,3009,10.03,1,3,[],[],[],1835,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc,folioCalc,class,125,509,332,4736,9.3,2,17,[],[],[],2134,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator,folioRiskIndicator,class,89,306,215,3180,10.39,1,9,[],[],[],2309,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF,folioOptimizationF,class,280,1291,671,10994,8.52,6,39,[],[],[],2487,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity,searchSimilarity,class,173,497,328,4550,9.15,8,17,[],[],[],3934,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1836,[],['date_generatedatetime'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:index:close,index:close,method,0,1,1,4,4.0,0,0,['self'],[None],[None],1841,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:index:updatehisto,index:updatehisto,method,2,12,11,62,5.17,0,0,['self)'],['  #Download Quotespassself) :'],[None],1844,[],['print'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:index:help,index:help,method,2,12,11,62,5.17,0,0,['self'],[None],[None],1848,[],['print'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:index:__init__,index:__init__,method,11,12,12,116,9.67,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]",['date_generatedatetime'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:index:calc_baskettable_pct,index:calc_baskettable_pct,method,37,95,77,782,8.23,1,2,"['self', 'type1', 'showdetail']","[None, None, None]","[None, '""table""', '0']",1913,"[""      '''   Calc Basket Values from Input data '''\n""]","['np.zeros', 'np.sum', 'self._udpate_wwindpct', 'range', 'np.mod', 'self._wwpct_rebal']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:index:_wwpct_rebal,index:_wwpct_rebal,method,3,4,3,41,10.25,0,0,"['self', 'wwpct_actual', 't', 'trebal)', '']","[None, None, None, '  # BskUnit', ']np.abs(wwpct_actual/wwpct_th  -1 )) > self.rebal_trigger:']","[None, None, None, ' 1.0  !!!wwpct_th = self.wwasset[trebal', None]",1940,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:index:_udpate_wwindpct,index:_udpate_wwindpct,method,11,25,17,224,8.96,0,0,"['self', 't', 'bskt', 'hedgecost', 'wwpct_actual', 'wwpct_th']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",1950,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:index:calc_baskettable_unit,index:calc_baskettable_unit,method,0,0,0,0,0.0,0,0,[],[],[],1959,"[""    '''   t           --->  t+1                 ---->   t+2\n"", '            wwactual:    B[t]    -->   B[t+1]   using  w[t+1], B[t] /   S[t]\n', '            wwnew   :    B[t+1]  -->   B[t+2]   using  w[t+2], B[t+1] /   S[t+1]\n', ""    '''\n""]",[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:__init__,folioCalc:__init__,method,21,39,37,356,9.13,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2135,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:set_symclose,folioCalc:set_symclose,method,17,34,33,312,9.18,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2148,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:setcriteria,folioCalc:setcriteria,method,41,76,71,1046,13.76,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2157,"[""        ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '            wwtype:     constant / regime /regimExtra\n', '            initperiod: NbOfDays_initial_Risk_Monitoring\n', '            riskid:     spprice/spperf/multi\n', ""        '''\n""]","['np.array', 'len']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:_weightcalc_generic,folioCalc:_weightcalc_generic,method,5,35,23,396,11.31,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2207,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:_weightcalc_regime,folioCalc:_weightcalc_regime,method,10,37,32,272,7.35,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2218,[],"['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:_regimecalc,folioCalc:_regimecalc,method,3,7,6,83,11.86,0,0,"['self', 't', 'wwextra)', 't - 1]self.riskind[0', 't - 1] / self.riskind[0', 't - 1 - self.nbrange] - 1if self.riskid == ""multi""']","[None, None, '  # Risk Indicatorif self.riskid ', None, None, '']","[None, None, '= ""spprice"":   return self.riskind[0', None, None, '= ""multi"":']",2228,[],['self._mapping_calc_risk'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:_weightcalc_constant,folioCalc:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2237,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:getweight,folioCalc:getweight,method,5,12,9,126,10.5,0,0,['self'],[None],[None],2241,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:calc_baskettable,folioCalc:calc_baskettable,method,33,111,83,811,7.31,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', '0.000', '0']",2248,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:plot,folioCalc:plot,method,10,29,26,295,10.17,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2276,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:multiperiod_ww,folioCalc:multiperiod_ww,method,15,36,29,240,6.67,1,1,"['self', 't']","[None, None]","[None, None]",2287,[],['xrange'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioCalc:help,folioCalc:help,method,1,2,2,13,6.5,0,0,['self'],[None],[None],2300,[],['print'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:__init__,folioRiskIndicator:__init__,method,23,40,38,356,8.9,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:set_symclose,folioRiskIndicator:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2324,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:setcriteria,folioRiskIndicator:setcriteria,method,34,81,70,1006,12.42,0,0,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2334,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'np.zeros']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:calcrisk,folioRiskIndicator:calcrisk,method,13,18,17,220,12.22,1,0,"['self', 'wwvec', 'initval']","[None, None, None]","[None, '[]', '1']",2382,[],"['xrange', 'self._weightcalc_generic', 'np.column_stack']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:_weightcalc_generic,folioRiskIndicator:_weightcalc_generic,method,4,34,24,327,9.62,0,3,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2394,[],"['self._weightcalc_regime', 'print']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:_weightcalc_regime,folioRiskIndicator:_weightcalc_regime,method,3,11,11,68,6.18,0,1,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2403,[],['self._regimecalc'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:_regimecalc,folioRiskIndicator:_regimecalc,method,7,18,17,216,12.0,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )self.riskind', 'wwextra', 't', 'self.riskind_out)self', 'maxiter', 'name1', 'isreset', 'popsize=15) ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, None, None, None, None, None, None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, None, None, None, None, '1', ""''"", '1', '15) :']",2408,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioRiskIndicator:calc_optimal_weight,folioRiskIndicator:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2414,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:__init__,folioOptimizationF:__init__,method,23,39,37,340,8.72,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",1869,"[""    ''' initperiod: NbOfDays_initial_Risk_Monitoring   '''\n""]","['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:set_symclose,folioOptimizationF:set_symclose,method,18,32,32,295,9.22,0,1,"['self', 'sym', 'close', 'dateref']","[None, None, None, None]","[None, None, None, None]",2324,[],"['getret_fromquotes', 'np.shape', 'np.ones', 'len', 'print']",5
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:setcriteria,folioOptimizationF:setcriteria,method,44,128,103,1669,13.04,0,2,"['self', 'lweight', 'lbounds', 'statedata', 'name', 'optimcrit', 'wwtype', 'nbregime', 'initperiod', 'riskid', 'lfun']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None, '""spprice""', 'None']",2334,"[""    ''' optimcrit:  perf / perfyearly / drawdownyearly / sharpe/ volatility/ linear\n"", '        wwtype:     constant / regime /regimExtra\n', '        initperiod: NbOfDays_initial_Risk_Monitoring\n', '        riskid:     spprice/spperf/multi\n', ""    '''    \n""]","['np.array', 'len', 'print', 'list']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:calcbasket_obj2,folioOptimizationF:calcbasket_obj2,method,23,76,63,756,9.95,0,1,"['self', 'wwvec']","[None, None]","[None, None]",2572,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float']",6
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:calcbasket_obj,folioOptimizationF:calcbasket_obj,method,55,157,118,1494,9.52,1,4,"['self', 'wwvec']","[None, None]","[None, None]",2598,[],"['np.reshape', 'np.array', 'np.sum', 'round', 'calcbasket_objext', 'float', 'calcbasket_obj', 'concenfactor=folio_concenfactor2', 'np.zeros', 'xrange', 'np.mod', 'self._weightcalc_generic', 'self._loss_obj', 'self._objective_criteria']",14
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_loss_obj,folioOptimizationF:_loss_obj,method,4,6,6,68,11.33,0,0,"['self', 'ww2', 'wwpenalty']","[None, None, None]","[None, None, None]",2623,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_weightcalc_generic,folioOptimizationF:_weightcalc_generic,method,5,40,26,394,9.85,0,4,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",2394,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'print']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_weightcalc_regime,folioOptimizationF:_weightcalc_regime,method,8,32,28,239,7.47,0,0,"['self', 'wwvec', 'wwextra', 't']","[None, None, None, None]","[None, None, None, None]",2403,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']","['self._regimecalc', 'np.reshape', 'self._mapping_risk_ww']",3
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_regimecalc,folioOptimizationF:_regimecalc,method,4,7,7,83,11.86,0,0,"['self', 't', 'wwextra)', 't-1]self.riskind[0', 't-1] / self.riskind[0', 't-1-self.nbrange] - 1 )if self.riskid== ""multi""   ']","[None, None, '    #Risk Indicatorif self.riskid', None, None, '']","[None, None, '= ""spprice"" :   return  self.riskind[0', None, None, '= ""multi""   :']",2408,"['""""""\n', 'if bsk > maxprice :       maxprice= bsk\n', 'if maxprice-bsk > maxdd : maxdd=    maxprice-bsk\n', '\n', '""""""\n']",['self._mapping_calc_risk'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_weightcalc_constant,folioOptimizationF:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",2662,[],['np.sum'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:calc_optimal_weight,folioOptimizationF:calc_optimal_weight,method,7,18,17,216,12.0,0,0,"['self', 'maxiter', 'name1', 'isreset', 'popsize']","[None, None, None, None, None]","[None, '1', ""''"", '1', '15']",2414,[],['datanalysis.sk_optim_de'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:getweight,folioOptimizationF:getweight,method,6,11,9,126,11.45,0,0,['self'],[None],[None],2671,[],"['np.reshape', 'np.sum']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:calc_baskettable,folioOptimizationF:calc_baskettable,method,36,86,72,827,9.62,1,4,"['self', 'wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps', 'showdetail']","[None, None, None, None, None, None, None, None]","[None, None, None, '""table""', '""constant""', '1', ' 0.000', '0']",2679,[],"['np.shape', 'np.zeros', 'range', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'print']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:plot,folioOptimizationF:plot,method,11,31,30,294,9.48,0,2,"['self', 'wwvec', 'show1', 'tickperday']","[None, None, None, None]","[None, 'None', '1', '60']",2708,[],"['self.calc_baskettable', 'plot_price', 'print', 'np.array']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_objective_criteria,folioOptimizationF:_objective_criteria,method,31,147,78,1105,7.52,2,7,"['self', 'bsk']","[None, None]","[None, None]",2720,[],"['np.std', 'np.sum', 'range', 'np.arange']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:multiperiod_ww,folioOptimizationF:multiperiod_ww,method,18,29,27,238,8.21,1,1,"['self', 't']","[None, None]","[None, None]",2767,[],['xrange'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:help,folioOptimizationF:help,method,50,152,103,1472,9.68,1,6,['self'],[None],[None],2779,[],"['print', 'util.load_obj', 'int', 'copy.deepcopy', 'xrange', 'next', 'util.save_obj', 'np.mod', 'np.abs', 'np.reshape', 'np.sum']",11
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:mapping_risk_ww,folioOptimizationF:mapping_risk_ww,method,12,56,29,245,4.38,0,1,"['self', 'risk', 'wwmat', 'ww2']","[None, None, None, None]","[None, None, None, 'self.wwasset0']",2838,[],"['np.sum', 'np.array']",2
utilmy/zarchive/py2to3/portfolio_withdate.py:folioOptimizationF:_mapping_calc_risk,folioOptimizationF:_mapping_calc_risk,method,27,201,76,831,4.13,0,3,"['self', 'ss', 'tr', 't', 'risk0']","[None, None, None, None, None]","[None, None, None, None, None]",2850,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:__init__,searchSimilarity:__init__,method,15,18,17,193,10.72,0,0,"['self', ""filejpstock=r'E"", 'sym01', 'symname', 'startdate', 'enddate', 'pricetype']","[None, '', None, None, None, None, None]","[None, ""r'E:/_data/stock/daily/20160616/jp'"", ""['7203']"", ""['Toyota']"", ' 20150101', '20160601', '""close""']",3935,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:load_quotes_fromdb,searchSimilarity:load_quotes_fromdb,method,15,35,33,355,10.14,0,1,"['self', 'picklefile']","[None, None]","[None, ""''""]",3940,[],"['util.load_obj', 'imp_txt_getquotes', 'date_align', 'util.a_cleanmemory']",4
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:__generate_return__,searchSimilarity:__generate_return__,method,4,4,4,64,16.0,0,0,"['self', 'nlag']","[None, None]","[None, None]",3951,[],['getret_fromquotes'],1
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:__overweight__,searchSimilarity:__overweight__,method,17,62,41,412,6.65,2,4,"['self', 'px']","[None, None]","[None, None]",3955,[],"['len', 'np.ones', 'util.np_findlocalmax', 'type', 'np.abs', 'wwerr[max', 'util.np_findlocalmin']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:set_searchcriteria,searchSimilarity:set_searchcriteria,method,34,79,63,793,10.04,0,5,"['self', 'name1', 'date1', 'date2', 'nlag', 'searchperiodstart', 'typesearch', '']","[None, None, None, None, None, None, None, None]","[None, ""'7203'"", '20160301', '20160601', '1', '20120101', '""pattern2""', None]",3975,[],"['getret_fromquotes', 'date_finddateid', 'max', 'util.np_findfirst', 'print', 'price_normalize_1d', 'len', 'self.__overweight__']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:launch_search,searchSimilarity:launch_search,method,53,107,81,908,8.49,3,3,['self'],[None],[None],4004,[],"['len', 'np.zeros', 'range', 'price_normalize_1d', 'np_similarity', 'util.np_sortbycolumn', 'enumerate']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:show_comparison_graph,searchSimilarity:show_comparison_graph,method,33,72,63,682,9.47,1,3,"['self', 'maxresult', 'show_only_different_time', 'fromid', 'fromend', 'filenameout']","[None, None, None, None, None, None]","[None, '20', 'True', '0', ' 0', ""''""]",4038,[],"['np.shape', 'range', 'int', 'print', 'price_normalize_1d', 'str', 'plot_price']",7
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:staticmethod,searchSimilarity:staticmethod,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",4067,[],[],0
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:get_rankresult,searchSimilarity:get_rankresult,method,24,63,53,496,7.87,2,1,"['self', 'filetosave']","[None, None]","[None, ""''""]",4071,[],"['len', 'np.savetxt', 'np.shape', 'np.array', 'np.empty', 'range', 'int', 'str']",8
utilmy/zarchive/py2to3/portfolio_withdate.py:searchSimilarity:export_results,searchSimilarity:export_results,method,0,0,0,0,0.0,0,0,[],[],[],4093,"[""'''\n"", '#####################################################################################\n', '#---------Run over all the indexes, with time lag -----------------------------------\n', 'def np_similarity(x,y, wwerr=[], type1=0):\n', '  if type1==2 : return np_distance_l1(x,y, wwerr)\n', '  if type1==1: return sci.spatial.distance.correlation(x, y)  \n', '  if type1==0 : return 1-np.corrcoef(x,y)[0,1]\n', '\n', 'def np_distance_l1(x,y, wwerr) :\n', ' return np.sum(wwerr * np.abs(x-y))  \n', '  \n', '#---------------------  Universe Load         ---------------------------------------\n', ""filejpstock= r'E:/_data/stock/daily/20160616/jp'\n"", 'sym01= nk400list\n', '\n', 'quotes= imp_txt_getquotes(sym01, filejpstock, startdate=20090101, endate=20160616)\n', 'open1, dateref= date_align(quotes, type1=""close"")    #Get the data and align dates\n', 'del quotes; util.a_cleanmemory()\n', '\n', ""#util.save_obj(open1, 'close_nk400_2009_2016')\n"", ""#util.save_obj(dateref, 'dateref_nk400_2009_2016')\n"", '\n', ""open1= util.load_obj('close_nk400_2009_2016')\n"", ""dateref= util.load_obj( 'dateref_nk400_2009_2016')\n"", '\n', 'nlag=1\n', 'ret_open1 =  getdailyret_fromquotes(open1,nlag)\n', 'del open1\n', '\n', '#--------------------  Search Asset Input     ---------------------------------------\n', ""name1= '7203' \n"", 'date1= 20160328\n', 'date2= 20160531\n', 'twindow= util.np_findfirst(date2, dateref) - util.np_findfirst(date1, dateref) \n', '\n', '\n', 'tstartx= util.np_findfirst(date1, dateref)          # Date Index\n', 'stockx= util.np_findfirst(name1, sym01)\n', 'retx= ret_open1[stockx, tstartx:(tstartx+twindow-1)]    # Recent Period\n', 'px= price_normalize_1d(retx)\n', 'nx= len(px)\n', '\n', '\n', '#----OverWeight for Local Min, Local Max         -----------------------------------\n', 'wwerr= np.ones(nx, dtype=np.float16)\n', 'vvmax= util.np_findlocalmax(px); xprev=0\n', 'for x in vvmax:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', 'vvmin= util.np_findlocalmin(px); xprev=0\n', 'for x in vvmin:\n', '  if x[0] !=0 and np.abs(xprev-x[0]) > 6: \n', '    wwerr[max(0,x[0]-1):min(nx,(x[0]+1))]= 1.5;    xprev= x[0] \n', '\n', '\n', '#--------------------  Search the Pattern       -------------------------------------\n', 'tmaxx= len(dateref)-1\n', 'similar_list= np.zeros((nstock*(tmaxx-twindow)+1, 3), np.float16)\n', 'i=0\n', 'for iy in range(0, nstock) :\n', ' for t in range(0, tmaxx-twindow):\n', '   if iy == stockx and t > tstartx : \n', '     pass\n', '   else :\n', '    rety= ret_open1[iy, t:(t+twindow-1)]\n', '    py=   price_normalize_1d(rety)\n', '    ss= np_similarity(px, py, wwerr=wwerr, type1=2)\n', '    i+=1\n', '    similar_list[i,0]= iy\n', '    similar_list[i,1]= t\n', '    similar_list[i,2]= ss\n', '\n', '\n', ' #-------------------Clean the table -------------------------------------------------\n', 'rank= util.np_sortbycolumn(similar_list,2, asc=True)\n', 'for i,x in enumerate(rank) :\n', '  if rank[i,2]==0.0 : rank[i,2]= 1000         # Empty cell\n', '  if rank[i,1]> tstartx-3 : rank[i,2]= 100    # Start Element\n', 'rank= util.np_sortbycolumn(rank,2, asc=True)  \n', '\n', '\n', ' #----- Show Similar Stocks ---------------------------------------------------------\n', 'show_only_different_time= True\n', '\n', 'for i in range(0,10) :\n', ' tstarti= rank[i,1]\n', ' stocki= int(rank[i,0])\n', ' \n', ' if show_only_different_time and tstarti < tstartx-1  :\n', '   py= price_normalize100(ret_open1[stocki, tstarti:(tstarti+twindow-1)]) \n', '\n', '   namei= sym01[stocki]\n', '   namefulli= nk400name[util.np_findfirst(namei, nk400list)]\n', '\n', '   tit= namei+ "" "" +namefulli+ "" "" + str(dateref[tstarti])          \n', ""   plot_price(px-100, py-100, label=('Similar '+tit, 'Time','% Var') )\n"", '\n', '\n', 'kix= util.np_findfirst(name1, statsjp[:,0, ilag])\n', 'stocklist01[390]\n', '\n', '\n', 'stocklist01[157] , nk400name[157] ,  dateref1adj[86]     \n', 'plot_price(price_normalize100(ret_open1[157, 86:86+twindow-1])-100,px-100   )\n', ""'''    \n""]",[],0
utilmy/zarchive/py2to3/report.py:map_show,map_show,function,0,1,1,4,4.0,0,0,[],[],[],36,[],[],0
utilmy/zarchive/py2to3/report.py:xl_create_pivot,xl_create_pivot,function,4,9,9,134,14.89,0,0,"['infile', 'index_list', '""Rep""', '""Product""]', 'value_list', '""Quantity""]']","[None, None, None, None, None, None]","[None, '[""Manager""', None, None, '[""Price""', None]",65,"[""   ''' Read in the Excel file, create a pivot table and return it as a DataFrame '''\n""]",[],0
utilmy/zarchive/py2to3/report.py:xl_save_report,xl_save_report,function,6,10,10,167,16.7,1,0,"['report', 'outfile']","[None, None]","[None, None]",72,"[""   '''  Take a report and save it to a single Excel file\n"", '       sales_report = create_pivot(args.infile.name)\n', '       save_report(sales_report, args.outfile.name)\n', ""   '''\n""]","['temp_df.to_excel', 'writer.save']",2
utilmy/zarchive/py2to3/report.py:xl_create_pdf,xl_create_pdf,function,23,44,39,743,16.89,1,0,[],[],[],97,[],"['sales_report=create_pivot', 'manager_df.append', 'sales_report.xs', 'env=Environment', 'get_summary_stats', 'sales_report.to_html', 'HTML']",7
utilmy/zarchive/py2to3/rstatpy.py:stl,stl,function,32,165,104,1260,7.64,0,11,"['data', 'ns', 'np', 'nt', 'nl', 'isdeg', 'itdeg', 'ildeg', 'nsjump', 'ntjump', 'nljump', 'ni', 'no', 'fulloutput']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', '0', '1', '1', 'None', 'None', 'None', '2', '0', 'False']",9,"['    """"""\n', '    Seasonal-Trend decomposition procedure based on LOESS\n', '    data : pandas.Series\n', '    ns : int\n', '        Length of the seasonal smoother.\n', '        The value of  ns should be an odd integer greater than or equal to 3.\n', '        A value ns>6 is recommended. As ns  increases  the  values  of  the\n', '        seasonal component at a given point in the seasonal cycle (e.g., January\n', '        values of a monthly series with  a  yearly cycle) become smoother.\n', '    np : int\n', '        Period of the seasonal component.\n', '        For example, if  the  time series is monthly with a yearly cycle, then\n', '        np=12.\n', '        If no value is given, then the period will be determined from the\n', '        ``data`` timeseries.\n', '    nt : int\n', '        Length of the trend smoother.\n', '        The  value  of  nt should be an odd integer greater than or equal to 3.\n', '        A value of nt between 1.5*np and 2*np is  recommended. As nt increases,\n', '        the values of the trend component become  smoother.\n', '        If nt is None, it is estimated as the smallest odd integer greater\n', '        or equal to ``(1.5*np)/[1-(1.5/ns)]``\n', '    nl : int\n', '        Length of the low-pass filter.\n', '        The value of nl should  be an odd integer greater than or equal to 3.\n', '        The smallest odd integer greater than or equal to np is used by default.\n', '    isdeg : int\n', '        Degree of locally-fitted polynomial in seasonal smoothing.\n', '        The value is 0 or 1.\n', '    itdeg : int\n', '        Degree of locally-fitted polynomial in trend smoothing.\n', '        The value is 0 or 1.\n', '    ildeg : int\n', '        Degree of locally-fitted polynomial in low-pass smoothing.\n', '        The value is 0 or 1.\n', '    nsjump : int\n', '        Skipping value for seasonal smoothing.\n', '        The seasonal smoother skips ahead nsjump points and then linearly\n', '        interpolates in between.  The value  of nsjump should be a positive\n', '        integer; if nsjump=1, a seasonal smooth is calculated at all n points.\n', '        To make the procedure run faster, a reasonable choice for nsjump is\n', '        10%-20% of ns. By default, nsjump= 0.1*ns.\n', '    ntjump : int\n', '        Skipping value for trend smoothing. If None, ntjump= 0.1*nt\n', '    nljump : int\n', '        Skipping value for low-pass smoothing. If None, nljump= 0.1*nl\n', '    ni :int\n', '        Number of loops for updating the seasonal and trend  components.\n', '        The value of ni should be a positive integer.\n', '        See the next argument for advice on the  choice of ni.\n', '        If ni is None, ni is set to 2 for robust fitting, to 5 otherwise.\n', '    no : int\n', '        Number of iterations of robust fitting. The value of no should\n', '        be a nonnegative integer. If the data are well behaved without\n', '        outliers, then robustness iterations are not needed. In this case\n', '        set no=0, and set ni=2 to 5 depending on how much security\n', '        you want that  the seasonal-trend looping converges.\n', '        If outliers are present then no=3 is a very secure value unless\n', '        the outliers are radical, in which case no=5 or even 10 might\n', '        be better.  If no>0 then set ni to 1 or 2.\n', '        If None, then no is set to 15 for robust fitting, to 0 otherwise.\n', '    fulloutput : bool\n', '        If True, a dictionary holding the full output of the original R routine\n', '        will be returned.\n', '    returns\n', '    data : pandas.DataFrame\n', '        The seasonal, trend, and remainder components\n', '    """"""\n']","['data.copy', '_data.dropna', 'pandas.DateRange', 'pandas.Series', 'ceil', 'robjects.IntVector', 'ts_', 'stl_', 'asarray', 'pandas.DataFrame']",10
utilmy/zarchive/py2to3/utilgeo.py:df_to_geojson,df_to_geojson,function,10,24,21,329,13.71,2,0,"['df', 'col_properties', 'lat', 'lon']","[None, None, None, None]","[None, None, ""'latitude'"", ""'longitude'""]",24,[],['df.iterrows'],1
utilmy/zarchive/py2to3/util_min.py:os_wait_cpu,os_wait_cpu,function,12,31,27,286,9.23,1,0,"['priority', 'cpu_min']","[None, None]","['300', '50']",23,[],"['psutil.cpu_percent', 'print', 'arrow.utcnow', 'sleep']",4
utilmy/zarchive/py2to3/util_min.py:isexist,isexist,function,3,11,10,58,5.27,0,0,['a'],[None],[None],48,[],['print'],1
utilmy/zarchive/py2to3/util_min.py:isfloat,isfloat,function,5,15,13,67,4.47,0,1,['x'],[None],[None],54,[],['float'],1
utilmy/zarchive/py2to3/util_min.py:isint,isint,function,6,14,13,80,5.71,0,1,"['x)', '( int', 'np.int8', 'np.int16', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, None, None, '']","[None, None, None, None, None, None, None]",61,[],['txt.find'],1
utilmy/zarchive/py2to3/util_min.py:a_isanaconda,a_isanaconda,function,6,14,13,80,5.71,0,1,[],[],[],63,[],['txt.find'],1
utilmy/zarchive/py2to3/util_min.py:os_zip_checkintegrity,os_zip_checkintegrity,function,9,33,31,185,5.61,0,1,['filezip1'],[None],[None],72,[],"['zipfile.ZipFile', 'zip_file.testzip', 'print']",3
utilmy/zarchive/py2to3/util_min.py:os_zipfile,os_zipfile,function,23,43,37,397,9.23,2,2,"['folderin', 'folderzipname', 'iscompress']","[None, None, None]","[None, None, 'True']",83,[],"['zipfile.ZipFile', 'os.walk', 'zf.write', 'zf.close', 'os_zip_checkintegrity', 'print']",6
utilmy/zarchive/py2to3/util_min.py:os_zipfolder,os_zipfolder,function,15,35,29,346,9.89,0,3,"['dir_tozip', 'zipname', 'dir_prefix', 'iscompress']","[None, None, None, None]","[""'/zdisks3/output'"", ""'/zdisk3/output.zip'"", 'None', 'True']",99,"["" '''\n"", "" shutil.make_archive('/zdisks3/results/output', 'zip',\n"", ""                     root_dir=/zdisks3/results/',\n"", ""                     base_dir='output')\n"", '\n', "" os_zipfolder('zdisk/test/aapackage', 'zdisk/test/aapackage.zip', 'zdisk/test')'''\n""]","['dir_tozip.split', 'shutil.make_archive', 'os_zip_checkintegrity', 'print']",4
utilmy/zarchive/py2to3/util_min.py:os_zipextractall,os_zipextractall,function,23,59,48,538,9.12,1,3,"['filezip_or_dir', 'tofolderextract', 'isprint']","[None, None, None]","['""folder1/*.zip""', ""'zdisk/test'"", '1']",148,"[""   '''os_zipextractall( 'aapackage.zip','zdisk/test/'      )  '''\n""]","['filezip_or_dir.find', 'os_file_listall', 'os_file_getname', 'zipfile.ZipFile', 'zip_ref.extractall', 'zip_ref.close', 'print']",7
utilmy/zarchive/py2to3/util_min.py:os_folder_copy,os_folder_copy,function,17,36,35,345,9.58,0,1,"['src', 'dst', 'symlinks', 'pattern1', 'fun_file_toignore']","[None, None, None, None, None]","[None, None, 'False', '""*.py""', 'None']",178,"[""   '''\n"", '       callable(src, names) -> ignored_names\n', ""       'src' parameter, which is the directory being visited by copytree(), and\n"", ""       'names' which is the list of `src` contents, as returned by os.listdir():\n"", '\n', '    Since copytree() is called recursively, the callable will be called once for each directory that is copied.\n', '    It returns a  list of names relative to the `src` directory that should not be copied.\n', ""   '''\n""]","['fun_file_toignore', 'fnmatch.filter', 'shutil.copytree', 'shutil.copy']",4
utilmy/zarchive/py2to3/util_min.py:os_folder_create,os_folder_create,function,4,7,7,85,12.14,0,1,['directory'],[None],[None],200,[],"['os.getcwd', 'os.makedirs', 'os.chdir']",3
utilmy/zarchive/py2to3/util_min.py:os_folder_robocopy,os_folder_robocopy,function,3,15,15,166,11.07,0,1,"['from_folder', 'to_folder', ""my_log='H""]","[None, None, '']","[""''"", ""''"", ""'H:/robocopy_log.txt'""]",205,"['    """"""\n', '    Copy files to working directory\n', '    robocopy <Source> <Destination> [<File>[ ...]] [<Options>]\n', '    We want to copy the files to a fast SSD drive\n', '    """"""\n']",['print'],1
utilmy/zarchive/py2to3/util_min.py:os_file_replacestring1,os_file_replacestring1,function,11,25,24,238,9.52,1,0,"['findStr', 'repStr', 'filePath']","[None, None, None]","[None, None, None]",216,[],"['fileinput.FileInput', 'line.replace', 'file1.close', 'print']",4
utilmy/zarchive/py2to3/util_min.py:os_file_replacestring2,os_file_replacestring2,function,6,14,13,161,11.5,1,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",227,"['  \'\'\' #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",    pattern=""*.html"", dirlevel=5  )\n', ""  '''\n""]","['os_file_listall', 'os_file_replacestring1']",2
utilmy/zarchive/py2to3/util_min.py:os_file_getname,os_file_getname,function,8,9,8,75,8.33,0,0,['path'],[None],[None],234,[],"['ntpath.split', 'ntpath.basename']",2
utilmy/zarchive/py2to3/util_min.py:os_file_getpath,os_file_getpath,function,7,7,7,52,7.43,0,0,['path'],[None],[None],239,[],['ntpath.split'],1
utilmy/zarchive/py2to3/util_min.py:os_file_gettext,os_file_gettext,function,4,7,7,56,8.0,0,0,['file1'],[None],[None],244,[],"['open', 'f.read']",2
utilmy/zarchive/py2to3/util_min.py:os_file_listall,os_file_listall,function,28,79,46,902,11.42,4,3,"['dir1', 'pattern', 'dirlevel', 'onlyfolder']","[None, None, None, None]","[None, '""*.*""', '1', '0']",250,"[""  '''\n"", '   # DIRCWD=r""D:\\_devs\\Python01\\project""\n', '   # aa= listallfile(DIRCWD, ""*.*"", 2)\n', '   # aa[0][30];   aa[2][30]\n', '\n', '   :param dir1:\n', '   :param pattern:\n', '   :param dirlevel:\n', '   :param onlyfolder:\n', '   :return:\n', ""  '''\n""]","['dir1.rstrip', 'dir1.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 'np.array']",7
utilmy/zarchive/py2to3/util_min.py:os_file_rename,os_file_rename,function,32,56,48,642,11.46,2,1,"['some_dir', 'pattern', 'pattern2', 'dirlevel']","[None, None, None, None]","[None, '""*.*""', '""""', '1']",287,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 're.sub', 'os.rename', 'np.array']",9
utilmy/zarchive/py2to3/util_min.py:os_print_tofile,os_print_tofile,function,1,2,2,7,3.5,0,0,"['vv', 'file1', ""mode1='a')"", 'mode1) as text_file']","[None, None, '', '  text_file.write(str(vv))) :']","[None, None, ""'a'):  # print into a file='afile1"", None]",309,"[""    '''\n"", '    Here is a list of the different modes of opening a file:\n', 'r\n', 'Opens a file for reading only. The file pointer is placed at the beginning of the file. This is the default mode.\n', '\n', 'rb\n', '\n', 'Opens a file for reading only in binary format. The file pointer is placed at the beginning of the file. This is the default mode.\n', 'r+\n', '\n', 'Opens a file for both reading and writing. The file pointer will be at the beginning of the file.\n', 'rb+\n', '\n', 'Opens a file for both reading and writing in binary format. The file pointer will be at the beginning of the file.\n', 'w\n', '\n', 'Opens a file for writing only. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'wb\n', '\n', 'Opens a file for writing only in binary format. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'w+\n', '\n', 'Opens a file for both writing and reading. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'wb+\n', '\n', 'Opens a file for both writing and reading in binary format. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'a\n', '\n', 'Opens a file for appending. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'ab\n', '\n', 'Opens a file for appending in binary format. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'a+\n', '\n', 'Opens a file for both appending and reading. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'ab+\n', '\n', 'Opens a file for both appending and reading in binary format. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'To open a text file, use:\n', 'fh = open(""hello.txt"", ""r"")\n', '\n', 'To read a text file, use:\n', 'print fh.read()\n', '\n', 'To read one line at a time, use:\n', 'print fh.readline()\n', '\n', 'To read a list of lines use:\n', 'print fh.readlines()\n', '\n', 'To write to a file, use:\n', 'fh = open(""hello.txt"", ""w"")\n', 'lines_of_text = [""a line of text"", ""another line of text"", ""a third line""]\n', 'fh.writelines(lines_of_text)\n', 'fh.close()\n', '\n', 'To append to file, use:\n', 'fh = open(""Hello.txt"", ""a"")\n', 'fh.close()\n', '\n', ""    '''\n""]",[],0
utilmy/zarchive/py2to3/util_min.py:a_get_pythonversion,a_get_pythonversion,function,1,2,2,7,3.5,0,0,[],[],[],374,[],[],0
utilmy/zarchive/py2to3/util_min.py:os_path_norm,os_path_norm,function,8,20,18,174,8.7,0,1,['pth)'],[' #Normalize path for Python directory)'],['=2:'],377,"['    \'\'\' #r""D:\\_devs\\Python01\\project\\03-Connect_Java_CPP_Excel\\PyBindGen\\examples"" \'\'\'\n']","['pth.find', 'b.lstrip']",2
utilmy/zarchive/py2to3/util_min.py:os_path_change,os_path_change,function,4,4,4,34,8.5,0,0,['path1)'],[' path1'],[' os_path_norm(path1); os.chdir(path1)    #Change Working directory path): return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],389,[],"['open', 'fh.read']",2
utilmy/zarchive/py2to3/util_min.py:os_path_current,os_path_current,function,4,4,4,34,8.5,0,0,[')'],[' return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],391,[],"['open', 'fh.read']",2
utilmy/zarchive/py2to3/util_min.py:os_file_exist,os_file_exist,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],393,[],"['open', 'fh.read']",2
utilmy/zarchive/py2to3/util_min.py:os_file_size,os_file_size,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.getsize(file1)file1):'],[None],395,[],"['open', 'fh.read']",2
utilmy/zarchive/py2to3/util_min.py:os_file_read,os_file_read,function,4,4,4,34,8.5,0,0,['file1'],[None],[None],397,[],"['open', 'fh.read']",2
utilmy/zarchive/py2to3/util_min.py:os_file_mergeall,os_file_mergeall,function,10,20,20,185,9.25,1,0,"['nfile', 'dir1', 'pattern1', 'deepness']","[None, None, None, None]","[None, None, None, '2']",401,[],"['os_file_listall', 'open', 'os_file_gettext', 'nfile1.write', 'nfile1.close']",5
utilmy/zarchive/py2to3/util_min.py:os_path_append,os_path_append,function,4,19,11,121,6.37,0,3,"['p1', 'p2', 'p3', 'p4']","[None, None, None, None]","[None, 'None', 'None', 'None']",412,[],[],0
utilmy/zarchive/py2to3/util_min.py:os_split_dir_file,os_split_dir_file,function,6,15,15,112,7.47,0,1,['dirfile'],[None],[None],421,[],"['dirfile.split', 'len']",2
utilmy/zarchive/py2to3/util_min.py:py_importfromfile,py_importfromfile,function,12,21,19,251,11.95,0,1,"['modulename', 'dir1']","[None, None]","[None, None]",430,[],"['a_get_pythonversion', 'SourceFileLoader', 'foo.MyClass', 'imp.load_source']",4
utilmy/zarchive/py2to3/util_min.py:py_memorysize,py_memorysize,function,16,56,38,320,5.71,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",442,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'o.iteritems']",7
utilmy/zarchive/py2to3/util_min.py:save,save,function,2,4,4,64,16.0,0,0,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",470,[],['py_save_obj'],1
utilmy/zarchive/py2to3/util_min.py:load,load,function,2,3,3,60,20.0,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",473,[],['py_load_obj'],1
utilmy/zarchive/py2to3/util_min.py:save_test,save_test,function,6,11,11,124,11.27,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",476,[],"['py_load_obj', 'print', 'str', 'gc.collect']",4
utilmy/zarchive/py2to3/util_min.py:py_save_obj,py_save_obj,function,17,36,35,308,8.56,0,1,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",482,[],"['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.dump']",5
utilmy/zarchive/py2to3/util_min.py:py_load_obj,py_load_obj,function,16,30,28,265,8.83,0,1,"['folder', 'isabsolutpath', 'encoding1']","[None, None, None]","[""'/folder1/keyname'"", '0', ""'utf-8'""]",495,"[""    '''def load_obj(name, encoding1='utf-8' ):\n"", ""         with open('D:/_devs/Python01/aaserialize/' + name + '.pkl', 'rb') as f:\n"", '            return pickle.load(f, encoding=encoding1)\n', ""    '''\n""]","['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.load']",5
utilmy/zarchive/py2to3/util_min.py:z_key_splitinto_dir_name,z_key_splitinto_dir_name,function,6,15,15,112,7.47,0,1,['keyname'],[None],[None],511,[],"['keyname.split', 'len']",2
utilmy/zarchive/py2to3/util_ml.py:create_weight_variable,create_weight_variable,function,5,7,6,129,18.43,0,0,"['name', 'shape']","[None, None]","[None, None]",11,[],['tf.Variable'],1
utilmy/zarchive/py2to3/util_ml.py:create_bias_variable,create_bias_variable,function,4,6,6,112,18.67,0,0,"['name', 'shape']","[None, None]","[None, None]",17,[],"['tf.constant_initializer', 'tf.Variable']",2
utilmy/zarchive/py2to3/util_ml.py:create_adam_optimizer,create_adam_optimizer,function,2,3,3,70,23.33,0,0,"['learning_rate', 'momentum']","[None, None]","[None, None]",22,[],[],0
utilmy/zarchive/py2to3/util_ml.py:tf_check,tf_check,function,32,91,51,915,10.05,0,0,[],[],[],28,[],"['print', 'tf.constant', 'tf.matmul', 'tf.Session', 'sess.run']",5
utilmy/zarchive/py2to3/util_ml.py:parse_args,parse_args,function,11,26,24,196,7.54,1,1,"['ppa', 'args']","[None, None]","['None', ' {}']",59,[],"['argparse.ArgumentParser', 'args.items', 'ppa.add_argument', 'type=type', 'ppa.parse_args', 'parse_args2']",6
utilmy/zarchive/py2to3/util_ml.py:parse_args2,parse_args2,function,5,133,98,1435,10.79,0,1,['ppa'],[None],['None'],70,[],"['argparse.ArgumentParser', 'e:print', 'ppa.add_argument']",3
utilmy/zarchive/py2to3/util_ml.py:tf_global_variables_initializer,tf_global_variables_initializer,function,27,65,46,866,13.32,3,1,['sess'],[None],['None'],108,"['    """"""Initializes all uninitialized variables in correct order. Initializers\n', ""    are only run for uninitialized variables, so it's safe to run this multiple times.\n"", '    Args:   sess: session to use. Use default session if None.\n', '    """"""\n']","['make_initializer', 'f', 'tf.assign', 'make_noop', 'tf.no_op', 'make_safe_initializer', 'tf.cond', 'tf.get_default_session', 'tf.get_default_graph', 'tf.global_variables', 'g.get_operation_by_name', 'sess.run']",12
utilmy/zarchive/py2to3/util_ml.py:visualize_result,visualize_result,function,21,142,111,1132,7.97,2,0,[],[],[],218,[],"['range', 'enumerate', 'pd.read_csv', 'plt.plot', 'train_loss.tolist', 'plt.legend', 'plt.xlabel', 'plt.ylabel', 'plt.show']",9
utilmy/zarchive/py2to3/util_ml.py:TextLoader,TextLoader,class,65,159,120,2143,13.48,0,1,[],[],[],151,[],[],0
utilmy/zarchive/py2to3/util_ml.py:TextLoader:__init__,TextLoader:__init__,method,15,34,31,491,14.44,0,1,"['self', 'data_dir', 'batch_size', 'seq_length']","[None, None, None, None]","[None, None, None, None]",152,[],"['print', 'self.preprocess', 'self.load_preprocessed', 'self.create_batches', 'self.reset_batch_pointer']",5
utilmy/zarchive/py2to3/util_ml.py:TextLoader:preprocess,TextLoader:preprocess,method,17,34,31,404,11.88,0,0,"['self', 'input_file', 'vocab_file', 'tensor_file']","[None, None, None, None]","[None, None, None, None]",170,[],"['codecs.open', 'f.read', 'collections.Counter', 'sorted', 'list', 'len', 'dict', 'range', 'open', 'pickle.dump', 'np.array', 'np.save']",12
utilmy/zarchive/py2to3/util_ml.py:TextLoader:load_preprocessed,TextLoader:load_preprocessed,method,10,19,19,245,12.89,0,0,"['self', 'vocab_file', 'tensor_file']","[None, None, None]","[None, None, None]",183,[],"['open', 'pickle.load', 'len', 'dict', 'range', 'np.load']",6
utilmy/zarchive/py2to3/util_ml.py:TextLoader:create_batches,TextLoader:create_batches,method,20,40,33,665,16.62,0,0,['self'],[None],[None],191,[],"['np.copy', 'np.split', 'int', 'zip']",4
utilmy/zarchive/py2to3/util_ml.py:TextLoader:next_batch,TextLoader:next_batch,method,6,10,8,87,8.7,0,0,['self'],[None],[None],207,[],[],0
utilmy/zarchive/py2to3/util_ml.py:TextLoader:reset_batch_pointer,TextLoader:reset_batch_pointer,method,1,2,2,14,7.0,0,0,['self'],[None],[None],212,[],[],0
utilmy/zarchive/py2to3/_HELP.py:os_compileVSsolution,os_compileVSsolution,function,6,32,21,239,7.47,0,4,"['dir1', 'flags1', 'type1', 'compilerdir']","[None, None, None, None]","[None, '""""', '""devenv""', '""""']",744,[],['os.system'],1
utilmy/zarchive/py2to3/_HELP.py:os_VS_build,os_VS_build,function,16,62,54,614,9.9,1,2,"['self', 'lib_to_build']","[None, None]","[None, None]",773,[],"['print', 'subprocess.Popen', 'process.poll', 'process.communicate']",4
utilmy/zarchive/py2to3/_HELP.py:set_rc_version,set_rc_version,function,12,37,34,502,13.57,0,0,"['rcfile', 'target_version']","[None, None]","[None, None]",810,[],"['open', 'f.seek', 'f.write', 'f.truncate']",4
utilmy/zarchive/py2to3/_HELP.py:os_VS_start,os_VS_start,function,18,56,52,881,15.73,0,2,"['self', 'version']","[None, None]","[None, None]",847,[],"['os.getenv', 'Exception', 'default.append', 'libs.append']",4
utilmy/zarchive/py2to3/_HELP.py:fun_cython,fun_cython,function,5,10,9,34,3.4,1,0,['a'],[None],[None],890,[],['xrange'],1
utilmy/zarchive/py2to3/_HELP.py:fun_python,fun_python,function,5,10,9,34,3.4,1,0,['a'],[None],[None],897,[],['xrange'],1
utilmy/zarchive/py2to3/_HELP.py:LookupTable,LookupTable,class,4,7,7,94,13.43,0,0,[],[],[],207,[],[],0
utilmy/zarchive/py3/util.py:session_save,session_save,function,39,72,64,1007,13.99,0,2,"['filename', 'globals1']","[None, None]","['""/folder1/name1""', 'None']",260,"[""    '''Need to pass globals() Cannot Get Save data to .spydata file\n"", '\n', '   BIG issue with Import, Impor FULL MODULE ----> BIG ISSUE\n', '     BIG ISSUE with DICT, USE LIST INSTEAD\n', '        If you try to put this code in a module and import the function then you will have to pass globals() to the function explicitly as the globals() in the function is not the IPython global namespace. However, you can put the above code inside your ~/.ipython/profile_PROFILE/startup/startup.ipy file and it will work as expected.\n', '       PROFILE is the name of the profile that you plan to start IPython with.\n', ""    '''\n""]","['print', 'spyutil.globalsfilter', 'filters=tuple', 'filename.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'iofunc.save_dictionary', 'os.chdir']",8
utilmy/zarchive/py3/util.py:aa_unicode_ascii_utf8_issue,aa_unicode_ascii_utf8_issue,function,0,0,0,0,0.0,0,0,[],[],[],338,"[""   '''Take All csv in a folder and provide Table, Column Schema, type\n"", '\n', ' METHOD FOR Unicode / ASCII issue\n', '1. Decode early\n', ""Decode to <type 'unicode'> ASAP\n"", ""df['PREF_NAME']=       df['PREF_NAME'].apply(to_unicode)\n"", '\n', '2. Unicode everywhere\n', '\n', '\n', '3. Encode late\n', "">>> f = open('/tmp/ivan_out.txt','w')\n"", "">>> f.write(ivan_uni.encode('utf-8'))\n"", '\n', 'Important methods\n', ""s.decode(encoding)  <type 'str'> to <type 'unicode'>\n"", ""u.encode(encoding)  <type 'unicode'> to <type 'str'>\n"", '\n', 'http://farmdev.com/talks/unicode/\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/py3/util.py:isexist,isexist,function,3,9,8,46,5.11,0,0,['a'],[None],[None],362,[],[],0
utilmy/zarchive/py3/util.py:isfloat,isfloat,function,5,16,14,67,4.19,0,1,['x'],[None],[None],368,[],['float'],1
utilmy/zarchive/py3/util.py:isint,isint,function,6,15,14,80,5.33,0,1,"['x)', '( int', 'np.int', 'np.int64', 'np.int32 ) ))']","[' return isinstance(x', None, None, None, '']","[None, None, None, None, None]",375,[],['txt.find'],1
utilmy/zarchive/py3/util.py:a_isanaconda,a_isanaconda,function,6,15,14,80,5.33,0,1,[],[],[],377,[],['txt.find'],1
utilmy/zarchive/py3/util.py:a_run_ipython,a_run_ipython,function,1,1,1,33,33.0,0,0,['cmd1'],[None],[None],387,"["" ''' Execute Ipython Command in python code\n"", '     run -i :  run including current interprete variable\n', "" '''\n""]",['IPython.get_ipython'],1
utilmy/zarchive/py3/util.py:a_autoreload,a_autoreload,function,1,4,4,64,16.0,0,0,[],[],[],393,[],['a_run_ipython'],1
utilmy/zarchive/py3/util.py:a_get_platform,a_get_platform,function,1,2,2,13,6.5,0,0,[],[],[],396,[],[],0
utilmy/zarchive/py3/util.py:a_start_log,a_start_log,function,1,14,12,98,7.0,0,0,"['id1', 'folder']","[None, None]","[""''"", ""'aaserialize/log/'""]",400,[],"['a_run_ipython', 'str', 'a_get_platform', 'date_now']",4
utilmy/zarchive/py3/util.py:a_cleanmemory,a_cleanmemory,function,3,3,3,21,7.0,0,0,[],[],[],403,[],['gc.collect'],1
utilmy/zarchive/py3/util.py:a_module_codesample,a_module_codesample,function,6,9,9,130,14.44,0,0,['module_str'],[None],"[""'pandas'""]",406,[],"['os_file_read', 'os_gui_popup_show']",2
utilmy/zarchive/py3/util.py:a_module_doc,a_module_doc,function,6,9,9,123,13.67,0,0,['module_str'],[None],"[""'pandas'""]",412,[],"['os_file_read', 'os_gui_popup_show']",2
utilmy/zarchive/py3/util.py:a_module_generatedoc,a_module_generatedoc,function,9,16,16,179,11.19,0,1,"['module_str', 'fileout']","[None, None]","['""pandas""', ""''""]",418,"['  \'\'\' #  getmodule_doc(""jedi"", r""D:\\_devs\\Python01\\aapackage\\doc.txt"")\'\'\'\n']","['os.makedirs', 'ca.getmodule_doc']",2
utilmy/zarchive/py3/util.py:a_info_conda_jupyter,a_info_conda_jupyter,function,61,131,110,1065,8.13,1,3,[],[],[],426,[],"['printProgress', 'shutil.make_archive', 'os_zipfolder', 'dir_tozip.split', 'os_zip_checkintegrity', 'print']",6
utilmy/zarchive/py3/util.py:os_zipextractall,os_zipextractall,function,23,59,48,538,9.12,1,3,"['filezip_or_dir', 'tofolderextract', 'isprint']","[None, None, None]","['""folder1/*.zip""', ""'zdisk/test'"", '1']",697,"[""   '''os_zipextractall( 'aapackage.zip','zdisk/test/'      )  '''\n""]","['filezip_or_dir.find', 'os_file_listall', 'os_file_getname', 'zipfile.ZipFile', 'zip_ref.extractall', 'zip_ref.close', 'print']",7
utilmy/zarchive/py3/util.py:os_folder_copy,os_folder_copy,function,17,35,34,340,9.71,0,1,"['src', 'dst', 'symlinks', 'pattern1', 'fun_file_toignore']","[None, None, None, None, None]","[None, None, 'False', '""*.py""', 'None']",727,"[""   '''\n"", '       callable(src, names) -> ignored_names\n', ""       'src' parameter, which is the directory being visited by copytree(), and\n"", ""       'names' which is the list of `src` contents, as returned by os.listdir():\n"", '\n', '    Since copytree() is called recursively, the callable will be called once for each directory that is copied.\n', '    It returns a  list of names relative to the `src` directory that should not be copied.\n', '   :param fun_ignore:\n', ""   '''\n""]","['fun_file_toignore', 'fnmatch.filter', 'shutil.copytree', 'shutil.copy']",4
utilmy/zarchive/py3/util.py:os_folder_create,os_folder_create,function,4,7,7,85,12.14,0,1,['directory'],[None],[None],750,[],"['os.getcwd', 'os.makedirs', 'os.chdir']",3
utilmy/zarchive/py3/util.py:os_folder_robocopy,os_folder_robocopy,function,3,14,14,157,11.21,0,1,"['from_folder', 'to_folder', ""my_log='H""]","[None, None, '']","[""''"", ""''"", ""'H:/robocopy_log.txt'""]",755,"['    """"""\n', '    Copy files to working directory\n', '    robocopy <Source> <Destination> [<File>[ ...]] [<Options>]\n', '    We want to copy the files to a fast SSD drive\n', '    """"""\n']","['subprocess.call', 'print']",2
utilmy/zarchive/py3/util.py:os_file_replacestring1,os_file_replacestring1,function,11,26,25,238,9.15,1,0,"['findStr', 'repStr', 'filePath']","[None, None, None]","[None, None, None]",766,[],"['fileinput.FileInput', 'line.replace', 'file1.close', 'print']",4
utilmy/zarchive/py3/util.py:os_file_replacestring2,os_file_replacestring2,function,6,14,13,160,11.43,1,0,"['findstr', 'replacestr', 'some_dir', 'pattern', 'dirlevel']","[None, None, None, None, None]","[None, None, None, '""*.*""', '1']",777,"['  \'\'\' #fil_replacestring_files(""logo.png"", ""logonew.png"", r""D:/__Alpaca__details/aiportfolio"",    pattern=""*.html"", dirlevel=5  )\n', ""  '''\n""]","['listallfile', 'fil_replacestring_onefile']",2
utilmy/zarchive/py3/util.py:os_file_getname,os_file_getname,function,8,9,8,75,8.33,0,0,['path'],[None],[None],784,[],"['ntpath.split', 'ntpath.basename']",2
utilmy/zarchive/py3/util.py:os_file_getpath,os_file_getpath,function,7,7,7,52,7.43,0,0,['path'],[None],[None],789,[],['ntpath.split'],1
utilmy/zarchive/py3/util.py:os_file_gettext,os_file_gettext,function,4,8,8,56,7.0,0,0,['file1'],[None],[None],794,[],"['open', 'f.read']",2
utilmy/zarchive/py3/util.py:os_file_listall,os_file_listall,function,28,82,46,904,11.02,4,3,"['dir1', 'pattern', 'dirlevel', 'onlyfolder']","[None, None, None, None]","[None, '""*.*""', '1', '0']",800,"[""  '''\n"", '   # DIRCWD=r""D:\\_devs\\Python01\\project""\n', '   # aa= listallfile(DIRCWD, ""*.*"", 2)\n', '   # aa[0][30];   aa[2][30]\n', '\n', '   :param dir1:\n', '   :param pattern:\n', '   :param dirlevel:\n', '   :param onlyfolder:\n', '   :return:\n', ""  '''\n""]","['dir1.rstrip', 'dir1.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 'np.array']",7
utilmy/zarchive/py3/util.py:os_file_rename,os_file_rename,function,32,60,48,643,10.72,2,1,"['some_dir', 'pattern', 'pattern2', 'dirlevel']","[None, None, None, None]","[None, '""*.*""', '""""', '1']",837,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'matches.append', 'fnmatch.filter', 're.sub', 'os.rename', 'np.array']",9
utilmy/zarchive/py3/util.py:os_gui_popup_show,os_gui_popup_show,function,25,38,37,361,9.5,0,0,['txt'],[None],[None],858,[],"['os_gui_popup_show2', 'Tk', 'Scrollbar', 'Text', 'S.pack', 'T.pack', 'S.config', 'T.config', 'T.insert', 'root.attributes', 'mainloop']",11
utilmy/zarchive/py3/util.py:os_print_tofile,os_print_tofile,function,8,21,19,174,8.29,0,1,"['vv', 'file1', ""mode1='a')"", 'mode1) as text_file']","[None, None, '', '  text_file.write(str(vv))pth): #Normalize path for Python directory)']","[None, None, ""'a'):  # print into a file='afile1"", '=2:']",875,"[""    '''\n"", '    Here is a list of the different modes of opening a file:\n', 'r\n', 'Opens a file for reading only. The file pointer is placed at the beginning of the file. This is the default mode.\n', '\n', 'rb\n', '\n', 'Opens a file for reading only in binary format. The file pointer is placed at the beginning of the file. This is the default mode.\n', 'r+\n', '\n', 'Opens a file for both reading and writing. The file pointer will be at the beginning of the file.\n', 'rb+\n', '\n', 'Opens a file for both reading and writing in binary format. The file pointer will be at the beginning of the file.\n', 'w\n', '\n', 'Opens a file for writing only. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'wb\n', '\n', 'Opens a file for writing only in binary format. Overwrites the file if the file exists. If the file does not exist, creates a new file for writing.\n', 'w+\n', '\n', 'Opens a file for both writing and reading. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'wb+\n', '\n', 'Opens a file for both writing and reading in binary format. Overwrites the existing file if the file exists. If the file does not exist, creates a new file for reading and writing.\n', 'a\n', '\n', 'Opens a file for appending. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'ab\n', '\n', 'Opens a file for appending in binary format. The file pointer is at the end of the file if the file exists. That is, the file is in the append mode. If the file does not exist, it creates a new file for writing.\n', 'a+\n', '\n', 'Opens a file for both appending and reading. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'ab+\n', '\n', 'Opens a file for both appending and reading in binary format. The file pointer is at the end of the file if the file exists. The file opens in the append mode. If the file does not exist, it creates a new file for reading and writing.\n', 'To open a text file, use:\n', 'fh = open(""hello.txt"", ""r"")\n', '\n', 'To read a text file, use:\n', 'print fh.read()\n', '\n', 'To read one line at a time, use:\n', 'print fh.readline()\n', '\n', 'To read a list of lines use:\n', 'print fh.readlines()\n', '\n', 'To write to a file, use:\n', 'fh = open(""hello.txt"", ""w"")\n', 'lines_of_text = [""a line of text"", ""another line of text"", ""a third line""]\n', 'fh.writelines(lines_of_text)\n', 'fh.close()\n', '\n', 'To append to file, use:\n', 'fh = open(""Hello.txt"", ""a"")\n', 'fh.close()\n', '\n', ""    '''\n""]","['pth.find', 'b.lstrip']",2
utilmy/zarchive/py3/util.py:os_path_norm,os_path_norm,function,8,21,19,174,8.29,0,1,['pth)'],[' #Normalize path for Python directory)'],['=2:'],939,"['    \'\'\' #r""D:\\_devs\\Python01\\project\\03-Connect_Java_CPP_Excel\\PyBindGen\\examples"" \'\'\'\n']","['pth.find', 'b.lstrip']",2
utilmy/zarchive/py3/util.py:os_path_change,os_path_change,function,4,4,4,34,8.5,0,0,['path1)'],[' path1'],[' normpath(path1); os.chdir(path1)    #Change Working directory path): return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],951,[],"['open', 'fh.read']",2
utilmy/zarchive/py3/util.py:os_path_current,os_path_current,function,4,4,4,34,8.5,0,0,[')'],[' return DIRCWDfile1): return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],953,[],"['open', 'fh.read']",2
utilmy/zarchive/py3/util.py:os_file_exist,os_file_exist,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.exists(file1)file1): return os.path.getsize(file1)file1):'],[None],955,[],"['open', 'fh.read']",2
utilmy/zarchive/py3/util.py:os_file_size,os_file_size,function,4,4,4,34,8.5,0,0,['file1)'],[' return os.path.getsize(file1)file1):'],[None],957,[],"['open', 'fh.read']",2
utilmy/zarchive/py3/util.py:os_file_read,os_file_read,function,4,4,4,34,8.5,0,0,['file1'],[None],[None],959,[],"['open', 'fh.read']",2
utilmy/zarchive/py3/util.py:os_file_mergeall,os_file_mergeall,function,10,20,20,182,9.1,1,0,"['nfile', 'dir1', 'pattern1', 'deepness']","[None, None, None, None]","[None, None, None, '2']",963,[],"['listallfile', 'open', 'gettext_fromfile', 'nfile1.write', 'nfile1.close']",5
utilmy/zarchive/py3/util.py:os_extracttext_allfile,os_extracttext_allfile,function,15,33,31,282,8.55,1,0,"['nfile', 'dir1', 'pattern1', 'htmltag', 'deepness']","[None, None, None, None, None]","[None, None, '""*.html""', ""'p'"", '2']",972,"["" ''' Extract text from html '''\n""]","['listallfile', 'open', 'gettext_fromfile', 'BeautifulSoup', 'soup.find_all', 'txt2.strip', 'newfile1.write', 'nfile1.close']",8
utilmy/zarchive/py3/util.py:os_path_append,os_path_append,function,4,19,11,121,6.37,0,3,"['p1', 'p2', 'p3', 'p4']","[None, None, None, None]","[None, 'None', 'None', 'None']",986,[],[],0
utilmy/zarchive/py3/util.py:os_split_dir_file,os_split_dir_file,function,6,15,15,112,7.47,0,1,['dirfile'],[None],[None],996,[],"['dirfile.split', 'len']",2
utilmy/zarchive/py3/util.py:os_process_run,os_process_run,function,13,31,31,317,10.23,0,1,"['cmd_list', ""'arg1'"", ""'arg2']"", 'capture_output']","[None, None, None, None]","[""['program'"", None, None, 'False']",1002,[],"['subprocess.Popen', 'proc.communicate', 'print', 'str']",4
utilmy/zarchive/py3/util.py:os_process_2,os_process_2,function,0,1,1,4,4.0,0,0,[],[],[],1018,[],[],0
utilmy/zarchive/py3/util.py:py_importfromfile,py_importfromfile,function,12,21,19,251,11.95,0,1,"['modulename', 'dir1']","[None, None]","[None, None]",1055,[],"['a_get_pythonversion', 'SourceFileLoader', 'foo.MyClass', 'imp.load_source']",4
utilmy/zarchive/py3/util.py:py_memorysize,py_memorysize,function,16,56,38,318,5.68,0,4,"['o', 'ids', 'hint', 'set(']","[None, None, None, None]","[None, None, '"" deep_getsizeof(df_pd', None]",1067,"['    """""" deep_getsizeof(df_pd, set())\n', '    Find the memory footprint of a Python object\n', '    The sys.getsizeof function does a shallow size of only. It counts each\n', '    object inside a container as pointer only regardless of how big it\n', '    """"""\n']","['id', 'getsizeof', 'ids.add', 'isinstance', 'sum', 'd', 'list']",7
utilmy/zarchive/py3/util.py:save,save,function,2,4,4,64,16.0,0,0,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",1095,[],['py_save_obj'],1
utilmy/zarchive/py3/util.py:load,load,function,2,3,3,60,20.0,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",1098,[],['py_load_obj'],1
utilmy/zarchive/py3/util.py:save_test,save_test,function,6,11,11,124,11.27,0,0,"['folder', 'isabsolutpath']","[None, None]","[""'/folder1/keyname'"", '0']",1101,[],"['py_load_obj', 'print', 'str', 'gc.collect']",4
utilmy/zarchive/py3/util.py:py_save_obj,py_save_obj,function,17,36,35,308,8.56,0,1,"['obj', 'folder', 'isabsolutpath']","[None, None, None]","[None, ""'/folder1/keyname'"", '0']",1107,[],"['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.dump']",5
utilmy/zarchive/py3/util.py:py_load_obj,py_load_obj,function,16,30,28,265,8.83,0,1,"['folder', 'isabsolutpath', 'encoding1']","[None, None, None]","[""'/folder1/keyname'"", '0', ""'utf-8'""]",1120,"[""    '''def load_obj(name, encoding1='utf-8' ):\n"", ""         with open('D:/_devs/Python01/aaserialize/' + name + '.pkl', 'rb') as f:\n"", '            return pickle.load(f, encoding=encoding1)\n', ""    '''\n""]","['folder.find', 'z_key_splitinto_dir_name', 'os_folder_create', 'open', 'pickle.load']",5
utilmy/zarchive/py3/util.py:z_key_splitinto_dir_name,z_key_splitinto_dir_name,function,6,15,15,112,7.47,0,1,['keyname'],[None],[None],1136,[],"['keyname.split', 'len']",2
utilmy/zarchive/py3/util.py:sql_getdate,sql_getdate,function,0,1,1,4,4.0,0,0,[],[],[],1146,[],[],0
utilmy/zarchive/py3/util.py:obj_getclass_of_method,obj_getclass_of_method,function,7,15,13,114,7.6,1,1,['meth'],[None],[None],1218,[],['inspect.getmro'],1
utilmy/zarchive/py3/util.py:obj_getclass_property,obj_getclass_property,function,3,9,9,69,7.67,1,0,['pfi'],[None],[None],1226,[],"['list', 'print']",2
utilmy/zarchive/py3/util.py:print_topdf,print_topdf,function,27,114,95,913,8.01,0,0,[],[],[],1243,[],"['PdfPages', 'plt.figure', 'plt.plot', 'plt.title', 'pdf.savefig', 'plt.close', 'plt.rc', 'np.arange', 'np.sin', 'pdf.infodict', 'datetime.datetime']",11
utilmy/zarchive/py3/util.py:os_config_setfile,os_config_setfile,function,8,39,26,235,6.03,1,1,"['dict_params', 'outfile', 'mode1']","[None, None, None]","[None, None, ""'w+'""]",1290,[],"['open', 'list', 'isinstance', 'f1.write', 'str', 'f1.close', 'print']",7
utilmy/zarchive/py3/util.py:os_config_getfile,os_config_getfile,function,7,16,15,73,4.56,1,0,['file1'],[None],[None],1302,[],"['open', 'f1.readlines', 'print']",3
utilmy/zarchive/py3/util.py:os_csv_process,os_csv_process,function,1,2,2,9,4.5,0,0,['file1'],[None],[None],1310,[],['print'],1
utilmy/zarchive/py3/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1336,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/py3/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1336,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/py3/util.py:read_funding_data,read_funding_data,function,5,13,12,79,6.08,1,0,['path'],[None],[None],1336,[],"['open', 'csv.DictReader']",2
utilmy/zarchive/py3/util.py:find_fuzzy,find_fuzzy,function,4,12,11,49,4.08,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1504,"["" ''' if xstring matches partially, add to the list   '''\n""]",['xi.find'],1
utilmy/zarchive/py3/util.py:str_match_fuzzy,str_match_fuzzy,function,4,12,11,64,5.33,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",1509,"["" ''' if any of list_strinf elt matches partially xstring '''\n""]",['xstring.find'],1
utilmy/zarchive/py3/util.py:str_parse_stringcalendar,str_parse_stringcalendar,function,14,39,29,278,7.13,3,1,['cal'],[None],[None],1516,"[""    '''----------Parse Calendar  --------'''\n""]","['cal.split', 'x.find', 'cal4.append', 'np.array', 'print']",5
utilmy/zarchive/py3/util.py:str_make_unicode,str_make_unicode,function,7,16,13,102,6.38,0,1,"['input', 'errors']","[None, None]","[None, ""'replace'""]",1530,[],"['type', 'input.decode']",2
utilmy/zarchive/py3/util.py:str_empty_string_array,str_empty_string_array,function,9,30,23,184,6.13,2,1,"['x', 'y']","[None, None]","[None, '1']",1536,[],"['range', 'str_empty_string_array_numpy', 'np.empty']",3
utilmy/zarchive/py3/util.py:str_empty_string_array_numpy,str_empty_string_array_numpy,function,4,9,8,56,6.22,0,0,"['nx', 'ny']","[None, None]","[None, '1']",1540,[],['np.empty'],1
utilmy/zarchive/py3/util.py:str_isfloat,str_isfloat,function,1,8,7,46,5.75,0,0,['value'],[None],[None],1545,[],['float'],1
utilmy/zarchive/py3/util.py:str_is_azchar,str_is_azchar,function,1,8,7,42,5.25,0,0,['x'],[None],[None],1549,[],['float'],1
utilmy/zarchive/py3/util.py:str_is_az09char,str_is_az09char,function,1,8,7,42,5.25,0,0,['x'],[None],[None],1553,[],['float'],1
utilmy/zarchive/py3/util.py:str_reindent,str_reindent,function,3,8,7,52,6.5,0,0,"['s', 'numSpaces)', ""'\\n')numSpaces * ' ') + string.lstrip(line) for line in s]s"", ""'\\n')return sdelimiters"", 'string', 'maxsplit=0)', 'delimiters))regexPattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, ' #change indentation of multine strings', None, None, None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, None, None, None, '0):  #Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1557,"[""    '''\n"", '   if args:\n', ""       aux= name1+'.'+obj.__name__ +'('+ str(args) +')  \\n' + str(inspect.getdoc(obj))\n"", ""       aux= aux.replace('\\n', '\\n       ')\n"", '       aux= aux.rstrip()\n', ""       aux= aux + ' \\n'\n"", '       wi( aux)\n', ""    '''\n""]",['x.decode'],1
utilmy/zarchive/py3/util.py:str_split2,str_split2,function,3,8,7,52,6.5,0,0,"['delimiters', 'string', 'maxsplit=0)', 'delimiters))regexPattern', 'string', 'maxsplit)sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', None, None, None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, '0):  #Split into Sub-Sentenceimport remap(re.escape', None, None, None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1571,[],['x.decode'],1
utilmy/zarchive/py3/util.py:str_split_pattern,str_split_pattern,function,3,8,7,52,6.5,0,0,"['sep2', 'll', 'maxsplit=0)', 're.S)lambda m', 'll)return llx)']","[None, None, '', ' m.group(1) if m.group(1) else ""P""', '']","[None, None, ""0):  #Find Sentence Patternimport resep2) '(' + regexPat + r')|(?:(?!'+ regexPat +').)*'"", None, None]",1576,[],['x.decode'],1
utilmy/zarchive/py3/util.py:pd_str_isascii,pd_str_isascii,function,3,8,7,52,6.5,0,0,['x'],[None],[None],1584,[],['x.decode'],1
utilmy/zarchive/py3/util.py:str_to_utf8,str_to_utf8,function,2,2,2,23,11.5,0,0,['x'],[None],[None],1590,"['  """""" Do it before saving/output to external printer """"""\n']",['x.encode'],1
utilmy/zarchive/py3/util.py:str_to_unicode,str_to_unicode,function,3,14,11,85,6.07,0,2,"['x', 'encoding']","[None, None]","[None, ""'utf-8'""]",1595,"[""  ''' Do it First after Loading some text '''\n""]","['isinstance', 'str']",2
utilmy/zarchive/py3/util.py:web_restapi_toresp,web_restapi_toresp,function,12,19,18,168,8.84,0,1,['apiurl1'],[None],[None],1696,[],"['requests.get', 'ApiError']",2
utilmy/zarchive/py3/util.py:web_getrawhtml,web_getrawhtml,function,13,20,20,176,8.8,0,1,['url1'],[None],[None],1703,[],"['requests.get', 'ApiError']",2
utilmy/zarchive/py3/util.py:web_importio_todataframe,web_importio_todataframe,function,41,78,61,641,8.22,4,4,"['apiurl1', 'isurl']","[None, None]","[None, '1']",1711,[],"['requests.get', 'ApiError', 'resp.json', 'list', 'colname.append', 'str', 'np.array', 'colmax=len', 'np.empty', 'pd_createdf', 'np.arange', 'len']",12
utilmy/zarchive/py3/util.py:web_getjson_fromurl,web_getjson_fromurl,function,10,12,11,138,11.5,0,0,['url'],[None],[None],1738,[],"['urllib3.connection_from_url', 'http.urlopen', 'print', 'json.loads']",4
utilmy/zarchive/py3/util.py:web_gettext_fromurl,web_gettext_fromurl,function,9,19,18,203,10.68,0,0,"['url', 'htmltag']","[None, None]","[None, ""'p'""]",1753,[],"['urllib3.connection_from_url', 'http.urlopen', 'BeautifulSoup', 'soup.find_all']",4
utilmy/zarchive/py3/util.py:web_gettext_fromhtml,web_gettext_fromhtml,function,8,21,20,176,8.38,0,0,"['file1', 'htmltag']","[None, None]","[None, ""'p'""]",1761,[],"['open', 'BeautifulSoup', 'soup.find_all']",3
utilmy/zarchive/py3/util.py:web_getlink_fromurl,web_getlink_fromurl,function,14,22,21,248,11.27,1,0,['url'],[None],[None],1820,[],"['urllib3.connection_from_url', 'http.urlopen', 'BeautifulSoup', 'soup.prettify', 'soup.findAll', 'links.append', 'set']",7
utilmy/zarchive/py3/util.py:web_send_email,web_send_email,function,33,127,78,1266,9.97,0,0,"['FROM', 'recipient', 'subject', 'body', 'login1', 'pss1', 'server1', 'port1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, '""mizenjapan@gmail.com""', '""sophieelise237""', '""smtp.gmail.com""', '465']",1832,"['    \'\'\'  # send_email(""Kevin"", ""brookm291@gmail.com"", ""JapaneseText:"" , ""txt"") \'\'\'\n']","['MIMEMultipart', 'msg.set_charset', 'MIMEText', 'msg.attach', 'smtplib.SMTP_SSL', 'server_ssl.ehlo', 'login', 'server_ssl.login', 'server_ssl.sendmail', 'msg.as_string', 'server_ssl.close', 'print', 'web_send_email_tls', 'smtplib.SMTP', 'mailserver.ehlo', 'mailserver.starttls', 'mailserver.login', 'mailserver.sendmail', 'mailserver.quit']",19
utilmy/zarchive/py3/util.py:web_send_email_tls,web_send_email_tls,function,25,56,51,568,10.14,0,0,"['FROM', 'recipient', 'subject', 'body', 'login1', 'pss1', 'server1', 'port1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, '""mizenjapan@gmail.com""', '""sophieelise237""', '""smtp.gmail.com""', '465']",1857,[],"['MIMEMultipart', 'msg.set_charset', 'MIMEText', 'msg.attach', 'smtplib.SMTP', 'mailserver.ehlo', 'mailserver.starttls', 'mailserver.login', 'mailserver.sendmail', 'msg.as_string', 'mailserver.quit', 'print']",12
utilmy/zarchive/py3/util.py:web_sendurl,web_sendurl,function,3,11,11,95,8.64,0,0,['url1'],[None],[None],1893,[],"['web_gettext_fromurl', 'send_email']",2
utilmy/zarchive/py3/util.py:np_minimize,np_minimize,function,12,39,35,358,9.18,1,0,"['fun_obj', 'x0', 'argext', '0']","[None, None, None, None]","[None, '[0.0]', '(0', None]",1901,[],"['penalty', 'enumerate', 'max', 'loss', 'fun_obj', 'np_minimizeDE']",6
utilmy/zarchive/py3/util.py:np_minimizeDE,np_minimizeDE,function,16,51,41,422,8.27,1,2,"['fun_obj', 'bounds', 'name1', 'solver']","[None, None, None, None]","[None, None, None, 'None']",1914,[],"['range', 'next', 'print', 'save_obj', 'name1+date_now', 'np.mod', 'np.abs']",7
utilmy/zarchive/py3/util.py:np_remove_NA_INF_2d,np_remove_NA_INF_2d,function,9,22,19,116,5.27,2,1,['X'],[None],[None],1931,[],"['np.shape', 'range', 'np.isnan', 'np.isinf']",4
utilmy/zarchive/py3/util.py:np_addcolumn,np_addcolumn,function,8,11,11,86,7.82,0,0,"['arr', 'nbcol']","[None, None]","[None, None]",1938,[],"['np.shape', 'np.zeros', 'np.column_stack']",3
utilmy/zarchive/py3/util.py:np_addrow,np_addrow,function,9,20,19,139,6.95,0,1,"['arr', 'nbrow']","[None, None]","[None, None]",1944,[],"['np.shape', 'len', 'np.zeros', 'np.row_stack', 'np.append']",5
utilmy/zarchive/py3/util.py:np_int_tostr,np_int_tostr,function,3,17,12,69,4.06,0,1,['i'],[None],[None],1953,[],['str'],1
utilmy/zarchive/py3/util.py:np_dictordered_create,np_dictordered_create,function,5,6,6,52,8.67,0,0,[],[],[],1959,[],['OrderedDict'],1
utilmy/zarchive/py3/util.py:np_list_unique,np_list_unique,function,5,8,8,46,5.75,0,0,['seq'],[None],[None],1963,[],"['Set', 'list']",2
utilmy/zarchive/py3/util.py:np_list_tofreqdict,np_list_tofreqdict,function,10,39,23,162,4.15,2,1,"['l1', 'wweight']","[None, None]","[None, '[]']",1969,[],"['dict', 'len', 'enumerate']",3
utilmy/zarchive/py3/util.py:np_list_flatten,np_list_flatten,function,11,25,19,114,4.56,2,1,['seq'],[None],[None],1986,[],"['type', 'flatten', 'l.append']",3
utilmy/zarchive/py3/util.py:np_dict_tolist,np_dict_tolist,function,5,22,15,100,4.55,2,1,"['dd', 'withkey']","[None, None]","[None, '0']",1997,[],['list'],1
utilmy/zarchive/py3/util.py:np_dict_tostr_val,np_dict_tostr_val,function,1,9,9,52,5.78,0,0,['dd'],[None],[None],2003,[],"['str', 'list']",2
utilmy/zarchive/py3/util.py:np_dict_tostr_key,np_dict_tostr_key,function,1,8,8,52,6.5,0,0,['dd'],[None],[None],2006,[],"['str', 'list']",2
utilmy/zarchive/py3/util.py:np_removelist,np_removelist,function,6,15,15,71,4.73,1,1,"['x0', 'xremove']","[None, None]","[None, '[]']",2011,[],"['np_findfirst', 'xnew.append']",2
utilmy/zarchive/py3/util.py:np_transform2d_int_1d,np_transform2d_int_1d,function,19,31,28,227,7.32,2,0,"['m2d', 'onlyhalf']","[None, None]","[None, 'False']",2017,[],"['np.shape', 'np.zeros', 'range', 'np.abs', 'np_sortbycol']",5
utilmy/zarchive/py3/util.py:np_mergelist,np_mergelist,function,5,10,10,55,5.5,1,0,"['x0', 'x1']","[None, None]","[None, None]",2029,[],"['list', 'xnew.append']",2
utilmy/zarchive/py3/util.py:np_enumerate2,np_enumerate2,function,6,14,14,83,5.93,1,0,['vec_1d'],[None],[None],2035,[],"['np.empty', 'enumerate']",2
utilmy/zarchive/py3/util.py:np_pivottable_count,np_pivottable_count,function,12,24,23,170,7.08,1,0,['mylist'],[None],[None],2041,[],"['np_dict_tolist', 'sorted', 'int']",3
utilmy/zarchive/py3/util.py:np_nan_helper,np_nan_helper,function,2,5,5,40,8.0,0,0,['y'],[None],[None],2049,"['    """""" Input:  - y, 1d numpy array with possible NaNs\n', '        Output - nans, logical indices of NaNs - index, a function, with signature indices= index(logical_indices),\n', ""              to convert logical indices of NaNs to 'equivalent' indices\n"", '    """"""\n']","['np.isnan', 'z.nonzero']",2
utilmy/zarchive/py3/util.py:np_interpolate_nan,np_interpolate_nan,function,7,9,9,76,8.44,0,0,['y'],[None],[None],2056,[],"['np_nan_helper', 'np.interp', 'x']",3
utilmy/zarchive/py3/util.py:np_and1,np_and1,function,8,55,22,356,6.47,0,6,"['x', 'y', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']","[None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None', 'None', 'None']",2061,[],[],0
utilmy/zarchive/py3/util.py:np_sortcol,np_sortcol,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2069,"[' """""" df.sort([\'A\', \'B\'], ascending=[1, 0])  """"""\n']","['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/py3/util.py:np_sort,np_sort,function,7,19,12,184,9.68,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2075,[],"['pd.DataFrame', 'df.sort_values', 'np_sort']",3
utilmy/zarchive/py3/util.py:np_ma,np_ma,function,2,3,3,54,18.0,0,0,"['vv', 'n']","[None, None]","[None, None]",2081,"[""  '''Moving average '''\n""]","['np.convolve', 'old_div']",2
utilmy/zarchive/py3/util.py:np_cleanmatrix,np_cleanmatrix,function,11,22,20,124,5.64,2,1,['m'],[None],[None],2087,[],"['np.nan_to_num', 'np.shape', 'range', 'abs']",4
utilmy/zarchive/py3/util.py:np_torecarray,np_torecarray,function,2,6,6,105,17.5,0,0,"['arr', 'colname']","[None, None]","[None, None]",2095,[],['np.shape'],1
utilmy/zarchive/py3/util.py:np_sortbycolumn,np_sortbycolumn,function,6,8,8,77,9.62,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",2098,[],"['pd.DataFrame', 'df.sort_values']",2
utilmy/zarchive/py3/util.py:np_sortbycol,np_sortbycol,function,8,28,19,251,8.96,0,1,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",2103,[],"['pd.DataFrame', 'df.sort_values', 'np_sortbycol', 'len', 'np.reshape']",5
utilmy/zarchive/py3/util.py:min_kpos,min_kpos,function,2,3,3,36,12.0,0,0,"['arr', 'kth']","[None, None]","[None, None]",2114,"[""   ''' return kth mininimun '''\n""]",['np.partition'],1
utilmy/zarchive/py3/util.py:max_kpos,max_kpos,function,3,5,5,53,10.6,0,0,"['arr', 'kth']","[None, None]","[None, None]",2118,"[""   ''' return kth mininimun '''\n""]","['len', 'np.partition']",2
utilmy/zarchive/py3/util.py:np_findfirst,np_findfirst,function,5,11,10,54,4.91,1,1,"['item', 'vec']","[None, None]","[None, None]",2125,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/py3/util.py:np_find,np_find,function,5,11,10,54,4.91,1,1,"['item', 'vec']","[None, None]","[None, None]",2132,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/py3/util.py:find,find,function,4,12,11,49,4.08,1,1,"['xstring', 'list_string']","[None, None]","[None, None]",2139,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xi.find'],1
utilmy/zarchive/py3/util.py:findnone,findnone,function,4,11,10,54,4.91,1,1,['vec'],[None],[None],2145,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/py3/util.py:findx,findx,function,6,27,18,119,4.41,0,2,"['item', 'vec']","[None, None]","[None, None]",2151,"['    """"""return the index of the first occurence of item in vec""""""\n']","['type', 'vec.index', 'len']",3
utilmy/zarchive/py3/util.py:finds,finds,function,12,34,23,155,4.56,2,3,"['itemlist', 'vec']","[None, None]","[None, None]",2162,"['  """"""return the index of the first occurence of item in vec""""""\n']","['range', 'idlist.append']",2
utilmy/zarchive/py3/util.py:findhigher,findhigher,function,5,13,12,50,3.85,1,1,"['x', 'vec']","[None, None]","[None, None]",2173,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/py3/util.py:findlower,findlower,function,5,12,11,50,4.17,1,1,"['x', 'vec']","[None, None]","[None, None]",2179,"['    """"""return the index of the first occurence of item in vec""""""\n']",['range'],1
utilmy/zarchive/py3/util.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],2187,[],['min'],1
utilmy/zarchive/py3/util.py:np_find_maxpos,np_find_maxpos,function,17,44,33,260,5.91,1,3,['values'],[None],[None],2191,[],"['max', 'np_find_maxpos_2nd', 'float', 'enumerate']",4
utilmy/zarchive/py3/util.py:np_find_maxpos_2nd,np_find_maxpos_2nd,function,13,36,27,132,3.67,1,3,['numbers'],[None],[None],2195,[],"['float', 'enumerate']",2
utilmy/zarchive/py3/util.py:np_findlocalmax2,np_findlocalmax2,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",2207,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/py3/util.py:np_findlocalmin2,np_findlocalmin2,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",2241,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/py3/util.py:np_findlocalmax,np_findlocalmax,function,45,116,77,690,5.95,2,5,"['v', 'trig']","[None, None]","[None, None]",2275,[],"['n=len', 'np.zeros', 'np_find_maxpos', 'enumerate', 'range', 'len', 'findhigher', 'np.abs']",8
utilmy/zarchive/py3/util.py:np_findlocalmin,np_findlocalmin,function,46,119,78,703,5.91,2,6,"['v', 'trig']","[None, None]","[None, None]",2289,[],"['n=len', 'np.zeros', 'np_find_minpos', 'enumerate', 'range', 'len', 'findlower', 'np.abs']",8
utilmy/zarchive/py3/util.py:np_stack,np_stack,function,12,53,25,323,6.09,0,7,"['v1', 'v2', 'v3', 'v4', 'v5']","[None, None, None, None, None]","[None, 'None', 'None', 'None', 'None']",2305,[],"['np.shape', 'np.row_stack', 'np.column_stack']",3
utilmy/zarchive/py3/util.py:np_uniquerows,np_uniquerows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],2320,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/py3/util.py:np_remove_zeros,np_remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",2325,[],[],0
utilmy/zarchive/py3/util.py:np_sort,np_sort,function,7,19,12,184,9.68,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, '1']",2328,"[""'''\n"", 'from sqlalchemy import create_engine\n', 'engine = create_engine(""postgresql://u:p@host/database"")\n', ""'''\n""]","['pd.DataFrame', 'df.sort_values', 'np_sort']",3
utilmy/zarchive/py3/util.py:np_memory_array_adress,np_memory_array_adress,function,2,2,2,38,19.0,0,0,['x'],[None],[None],2331,[],[],0
utilmy/zarchive/py3/util.py:sql_create_dbengine,sql_create_dbengine,function,4,45,26,358,7.96,0,1,"['type1', 'dbname', 'login', 'password', 'url', 'port']","[None, None, None, None, None, None]","[""''"", ""''"", ""''"", ""''"", ""'localhost'"", '5432']",2345,"[""   ''' Return SQL Alchemy Connector\n"", '\n', ""sql_create_dbengine(type1='mysql',  dbname='', login='', password='', url='localhost', port=5432)\n"", '\n', '# psycopg2\n', ""engine = create_engine('postgresql+psycopg2://scott:tiger@localhost/mydatabase')\n"", '\n', '\n', '# MySQL-connector-python  Official one\n', ""engine = create_engine('mysql+mysqlconnector://scott:tiger@localhost/foo')\n"", 'conda install -c anaconda mysql-connector-python=2.0.4\n', ""engine = create_engine('postgresql://%s:%s@localhost:5432/%s' %(myusername, mypassword, mydatabase))\n"", '\n', ""engine = create_engine('sqlite:///  folder/foo.db')\n"", '\n', ""   '''\n""]","['sql.create_engine', 'str']",2
utilmy/zarchive/py3/util.py:sql_query,sql_query,function,6,22,18,155,7.05,0,2,"['sqlr', 'dbengine', 'output', ""dburl='sqlite""]","[None, None, None, '']","[""'SELECT ticker,shortratio,sector1_id, FROM stockfundamental'"", 'None', ""'df'"", ""'sqlite:///aaserialize/store/finviz.db'""]",2377,"["" '''\n"", "" :param sqlr:       'SELECT ticker,shortratio,sector1_id, FROM stockfundamental'\n"", ' :param output:     df   /   file1.csv\n', "" :param dburl:      'sqlite:///aaserialize/store/finviz.db'\n"", "" :param dbengine:   dbengine = sql.create_engine('postgresql+psycopg2://postgres:postgres@localhost/coke')\n"", ' :return:\n', "" '''\n""]","['sql.create_engine', 'pd.read_sql_query', 'output.find', 'df.to_csv']",4
utilmy/zarchive/py3/util.py:sql_get_dbschema,sql_get_dbschema,function,16,37,32,316,8.54,2,2,"[""dburl='sqlite"", 'dbengine', 'isprint']","['', None, None]","[""'sqlite:///aapackage/store/yahoo.db'"", 'None', '0']",2391,[],"['sql.create_engine', 'sql.inspect', 'inspector.get_table_names', 'inspector.get_columns', 'l1.append', 'print', 'np.array']",7
utilmy/zarchive/py3/util.py:sql_delete_table,sql_delete_table,function,1,8,8,89,11.12,0,0,"['name', 'dbengine']","[None, None]","[None, None]",2404,[],[],0
utilmy/zarchive/py3/util.py:sql_insert_excel,sql_insert_excel,function,50,131,97,992,7.57,5,2,"['file1', 'dbengine', 'dbtype']","[None, None, None]","[""'.xls'"", 'None', ""''""]",2411,"["" ''' http://flask-excel.readthedocs.io/en/latest/\n"", ' https://pythonhosted.org/pyexcel/tutorial_data_conversion.html#import-excel-sheet-into-a-database-table\n', ' from sqlalchemy import create_engine\n', 'from sqlalchemy.ext.declarative import declarative_base\n', 'from sqlalchemy import Column , Integer, String, Float, Date\n', 'from sqlalchemy.orm import sessionmaker\n', 'engine = create_engine(""sqlite:///birth.db"")\n', 'Base = declarative_base()\n', 'Session = sessionmaker(bind=engine)\n', '\n', 'class BirthRegister(Base):\n', ""...     __tablename__='birth'\n"", '...     id=Column(Integer, primary_key=True)\n', '...     name=Column(String)\n', '...     weight=Column(Float)\n', '...     birth=Column(Date)\n', '\n', 'Base.metadata.create_all(engine)\n', '\n', 'https://www.digitalocean.com/community/tutorials/how-to-use-celery-with-rabbitmq-to-queue-tasks-on-an-ubuntu-vps\n', 'import os\n', 'import pyexcel\n', 'import datetime\n', '\n', 'from sqlalchemy import create_engine\n', 'from sqlalchemy.ext.declarative import declarative_base\n', 'from sqlalchemy import Column, Integer, String, Float, Date\n', 'from sqlalchemy.orm import sessionmaker\n', '\n', '\n', 'engine = create_engine(""sqlite:///birth.db"")\n', 'Base = declarative_base()\n', 'Session = sessionmaker(bind=engine)\n', '\n', '\n', '# here is the destination table\n', 'class BirthRegister(Base):\n', ""    __tablename__ = 'birth'\n"", '    id = Column(Integer, primary_key=True)\n', '    name = Column(String)\n', '    weight = Column(Float)\n', '    birth = Column(Date)\n', '\n', '\n', 'Base.metadata.create_all(engine)\n', '\n', '\n', '# create fixture\n', 'data = [\n', '    [""name"", ""weight"", ""birth""],\n', '    [""Adam"", 3.4, datetime.date(2015, 2, 3)],\n', '    [""Smith"", 4.2, datetime.date(2014, 11, 12)]\n', ']\n', 'pyexcel.save_as(array=data,\n', '                dest_file_name=""birth.xls"")\n', '\n', '# import the xls file\n', 'session = Session()  # obtain a sql session\n', 'pyexcel.save_as(file_name=""birth.xls"",\n', '                name_columns_by_row=0,\n', '                dest_session=session,\n', '                dest_table=BirthRegister)\n', '\n', '# verify results\n', 'sheet = pyexcel.get_sheet(session=session, table=BirthRegister)\n', 'print(sheet)\n', '\n', 'session.close()\n', ""os.unlink('birth.db')\n"", 'os.unlink(""birth.xls"")\n', '\n', ' This code uses the openpyxl package for playing around with excel using Python code\n', ' to convert complete excel workbook (all sheets) to an SQLite database\n', ' The code assumes that the first row of every sheet is the column name\n', ' Every sheet is stored in a separate table\n', ' The sheet name is assigned as the table name for every sheet\n', "" '''\n""]","['slugify', 'text.strip', 're.sub', 'load_workbook', 'wb.get_sheet_names', 'str', 'columns.append', 'dbengine.execute', 'enumerate', 'tuprow.append', 'tup.append', 'VALUES', 'dbengine.executemany', 'dbengine.commit', 'dbengine.close']",15
utilmy/zarchive/py3/util.py:sql_insert_df,sql_insert_df,function,22,60,52,481,8.02,1,2,"['df', 'dbtable', 'dbengine', 'col_drop', 'verbose']","[None, None, None, None, None]","[None, None, None, ""['id']"", '1']",2534,[],"['df.drop', 'df.to_dict', 'print', 'sql.Table', 'Session', 'dbengine.execute', 'session.commit', 'session.close']",8
utilmy/zarchive/py3/util.py:sql_insert_csv,sql_insert_csv,function,35,159,130,1358,8.54,3,3,"['csvfile', 'dbtable', 'dbengine', 'col_drop']","[None, None, None, None]","[None, None, None, '[]']",2564,[],"['datetime.now', 'pd.read_csv', 'df.rename', 'c.replace', 'df.drop', 'df.to_dict', 'sql.Table', 'Session', 'dbengine.execute', 'session.commit', 'session.close', 'print', 'sql_insert_csv2', 'os.listdir', 'i.endswith', 'i.startswith', 'df.to_sql']",17
utilmy/zarchive/py3/util.py:sql_insert_csv2,sql_insert_csv2,function,11,58,54,463,7.98,1,2,"['csvfile', 'dbtable', 'columns', 'dbengine', 'nrows']","[None, None, None, None, None]","[""''"", ""''"", '[]', 'None', ' 10000']",2636,"['    """"""\n', '    Upload data to a temporary table first using PANDAs to identify optimal data-types for columns\n', '    PANDAS is not speed-efficient as it uses INSERT commands rather than COPY e.g. it took COPY 16mins average\n', '    to get a 15GB CSV into the database (door-to-door) whereas pandas.to_sql took 50mins\n', '    """"""\n']","['os.listdir', 'i.endswith', 'i.startswith', 'print', 'pd.read_csv', 'df.to_sql']",6
utilmy/zarchive/py3/util.py:sql_postgres_create_table,sql_postgres_create_table,function,20,109,73,888,8.15,0,3,"['mytable', 'database', 'username', 'password']","[None, None, None, None]","[""''"", ""''"", ""''"", ""''""]",2669,"['    """""" Create table copying the structure of the temp table created using pandas  Timer to benchmark """"""\n']","['psycopg2.connect', 'con.cursor', 'print', 'sys.exit', 'cur.execute', 'open', 'cur.copy_expert', 'con.close']",8
utilmy/zarchive/py3/util.py:sql_postgres_pivot,sql_postgres_pivot,function,0,1,1,4,4.0,0,0,[],[],[],2755,"[""   '''\n"", 'Enabling the Crosstab Function\n', 'As we previously mentioned, the crosstab function is part of a PostgreSQL extension called tablefunc. To call the crosstab function,\n', 'you must first enable the tablefunc extension by executing the following SQL command:\n', 'CREATE extension tablefunc;\n', '\n', 'SELECT *\n', ""FROM crosstab( 'select student, subject, evaluation_result from evaluations order by 1,2')\n"", 'AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '\n', '##### Correct Even iF there are missing values :\n', 'http://www.vertabelo.com/blog/technical-articles/creating-pivot-tables-in-postgresql-using-the-crosstab-function\n', '\n', 'SELECT *\n', ""FROM crosstab( 'select student, subject, evaluation_result from evaluations\n"", ""                where extract (month from evaluation_day) = 7 order by 1,2',\n"", ""                'select name from subject order by 1')\n"", '     AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/py3/util.py:sql_mysql_insert_excel,sql_mysql_insert_excel,function,30,73,69,712,9.75,1,0,[],[],[],2781,[],"['xlrd.open_workbook', 'list.sheet_by_index', 'database.cursor', 'range', 'sheet.cell', 'cursor.execute', 'cursor.close', 'database.commit', 'database.close', 'print', 'str', 'rows=str']",12
utilmy/zarchive/py3/util.py:sql_pivotable,sql_pivotable,function,1,3,3,10,3.33,0,0,"['dbcon', 'ss']","[None, None]","[None, ""'select  '""]",2814,"[""  '''\n"", '\n', ' 1) get the category\n', '\n', ' 2) Build the Pivot From category\n', '  SELECT *\n', ""  FROM crosstab( 'select student, subject, evaluation_result from evaluations\n"", ""                where extract (month from evaluation_day) = 7 order by 1,2',\n"", ""                'select name from subject order by 1')\n"", '   AS final_result(Student TEXT, Geography NUMERIC,History NUMERIC,Language NUMERIC,Maths NUMERIC,Music NUMERIC);\n', '\n', '  https://www.amazon.com/PostgreSQL-High-Performance-Gregory-Smith/dp/184951030X/ref=as_li_ss_tl?s=books&ie=UTF8&qid=1458352081&sr=1-6&keywords=postgres&linkCode=sl1&tag=postgres-bottom-20&linkId=c981783121cbd5542dc2b44a2297df57\n', '\n', '\n', 'http://blog.brakmic.com/data-science-for-losers-part-2/\n', '\n', 'Here we instruct Pandas to merge two tables by using certain primary keys from both when combining their rows into a new table. The parameter how instructs Pandas to use the inner-join which means it will only combine such rows which belong to both of the tables. Therefore well not receive any NaN-rows. But in some cases this could be desirable. Then use the alternative options like left, right or outer.\n', '\n', 'Pivots with Tables from SQLAlchemy\n', '\n', 'And of course its possible to generate the same pivot tables with data that came from SQLAlchemy.\n', 'Theyre nothing else but DataFrames all the way down. OK, not absolutely all the way down,\n', 'because there are also Series and NumPy arrays etc.,\n', 'but this is a little bit too much of knowledge for Losers like us. Maybe in some later articles.\n', '\n', '\n', ' :return:\n', ""  '''\n""]",[],0
utilmy/zarchive/py3/util.py:np_pivotable_create,np_pivotable_create,function,28,99,61,699,7.06,4,5,"['table', 'left', 'top', 'value']","[None, None, None, None]","[None, None, None, None]",2847,"['    """"""\n', '    Creates a cross-tab or pivot table from a normalised input table. Use this\n', ""    function to 'denormalize' a table of normalized records.\n"", '\n', '    * The table argument can be a list of dictionaries or a Table object.\n', '    (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/334621)\n', '    * The left argument is a tuple of headings which are displayed down the\n', '    left side of the new table.\n', '    * The top argument is a tuple of headings which are displayed across the\n', '    top of the new table.\n', '    Tuples are used so that multiple element headings and columns can be used.\n', '\n', '    E.g. To transform the list (listOfDicts):\n', '\n', '    Name,   Year,  Value\n', '    -----------------------\n', ""    'Simon', 2004, 32\n"", ""    'Simon', 2005, 128\n"", ""    'Russel', 2004, 64\n"", ""    'Eric', 2004, 52\n"", ""    'Russel', 2005, 32\n"", '\n', '    into the new list:\n', '\n', ""    'Name',   2004, 2005\n"", '    ------------------------\n', ""    'Simon',  32,     128\n"", ""    'Russel',  64,     32\n"", ""    'Eric',   52,     NA\n"", '\n', '    you would call pivot with the arguments:\n', '\n', ""    newList = pivot(listOfDicts, ('Name',), ('Year',), 'Value')\n"", '\n', '    """"""\n']","['tuple', 'ysort.append', 'xsort.append', 'len', 'list', 'xsort.sort', 'headings.extend', 'sortedkeys.sort', 'row.extend', 't.append']",10
utilmy/zarchive/py3/util.py:pd_info,pd_info,function,13,25,24,255,10.2,1,2,"['df', 'doreturn']","[None, None]","[None, '1']",2932,[],"['df.info', 'print', 'type', 'pd_info_memsize', 'pd_info', 'df.memory_usage']",6
utilmy/zarchive/py3/util.py:pd_info_memsize,pd_info_memsize,function,5,6,6,84,14.0,0,1,"['df', 'memusage']","[None, None]","[None, '0']",2939,[],"['df.info', 'pd_info', 'df.memory_usage']",3
utilmy/zarchive/py3/util.py:pd_selectrow,pd_selectrow,function,11,99,53,857,8.66,1,3,"['df', '**conditions']","[None, None]","[None, None]",2947,"[""    '''Select rows from a df according to conditions\n"", '    pdselect(data, a=2, b__lt=3) __gt __ge __lte  __in  __not_in\n', ""    will select all rows where 'a' is 2 and 'b' is less than 3\n"", ""    '''\n""]","['type', 'pd.DataFrame', 'list', 'c.endswith', 'np.in1d', 'ValueError']",6
utilmy/zarchive/py3/util.py:pd_csv_randomread,pd_csv_randomread,function,11,41,37,266,6.49,0,1,"['filename', 'nsample', 'filemaxline', 'dtype']","[None, None, None, None]","[None, '10000', '-1', 'None']",2991,[],"['sum', 'open', 'np.sort', 'pd.read_csv']",4
utilmy/zarchive/py3/util.py:pd_array_todataframe,pd_array_todataframe,function,14,46,33,313,6.8,0,2,"['array', 'colname', 'index1', 'dotranspose']","[None, None, None, None]","[None, 'None', 'None', 'False']",3001,[],"['np.shape', 'len', 'pd.DataFrame', 'np.array']",4
utilmy/zarchive/py3/util.py:pd_dataframe_toarray,pd_dataframe_toarray,function,10,10,10,103,10.3,0,0,['df'],[None],[None],3011,[],['df.reset_index'],1
utilmy/zarchive/py3/util.py:pd_createdf,pd_createdf,function,2,4,4,55,13.75,0,0,"['array1', 'col1', 'idx1']","[None, None, None]","[None, 'None', 'None']",3017,[],['pd.DataFrame'],1
utilmy/zarchive/py3/util.py:pd_create_colmapdict_nametoint,pd_create_colmapdict_nametoint,function,9,12,12,77,6.42,1,0,['df'],[None],[None],3020,"[""  ''' 'close' ---> 5    '''\n""]",['enumerate'],1
utilmy/zarchive/py3/util.py:pd_extract_col_idx_val,pd_extract_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],3030,[],[],0
utilmy/zarchive/py3/util.py:pd_extract_col_uniquevalue_tocsv,pd_extract_col_uniquevalue_tocsv,function,5,10,9,101,10.1,0,0,"['df', 'colname', 'csvfile']","[None, None, None]","[None, ""''"", ""''""]",3034,"["" ''' Write one column into a file   '''\n""]","['np.array', 'pd.DataFrame', 'print']",3
utilmy/zarchive/py3/util.py:pd_split_col_idx_val,pd_split_col_idx_val,function,4,4,4,49,12.25,0,0,['df'],[None],[None],3043,[],[],0
utilmy/zarchive/py3/util.py:pd_splitdf_inlist,pd_splitdf_inlist,function,15,34,26,254,7.47,3,2,"['df', 'colid', 'type1']","[None, None, None]","[None, None, '""dict""']",3046,"[""    ''' Split df into dictionnary of dict/list '''\n""]","['list', 'l1.append']",2
utilmy/zarchive/py3/util.py:pd_find,pd_find,function,38,140,82,990,7.07,5,8,"['df', 'regex_pattern', 'col_restrict', 'isnumeric', 'doreturnposition']","[None, None, None, None, None]","[None, ""'*'"", '[]', 'False', 'False']",3061,"["" ''' Find string / numeric values inside df columns, return position where found\n"", ""     col_restrict : restrict to these columns '''\n""]","['str', 'print', 'enumerate', 'np.column_stack', 'len', 'gc.collect', 'np_dictordered_create', 'range', 'np.array']",9
utilmy/zarchive/py3/util.py:pd_dtypes_totype2,pd_dtypes_totype2,function,6,9,9,58,6.44,1,0,"['df', 'columns', 'targetype']","[None, None, None]","[None, '[]', ""'category'""]",3107,[],[],0
utilmy/zarchive/py3/util.py:pd_dtypes,pd_dtypes,function,7,12,11,91,7.58,1,0,"['df', 'columns', 'targetype']","[None, None, None]","[None, '[]', ""'category'""]",3112,[],['pd_dtypes'],1
utilmy/zarchive/py3/util.py:pd_df_todict,pd_df_todict,function,16,30,26,246,8.2,1,2,"['df', 'colkey', 'excludekey', 'onlyfirstelt']","[None, None, None, None]","[None, ""'table'"", ""['']"", ' True']",3127,[],"['df.drop_duplicates', 'range', 'dict0.setdefault']",3
utilmy/zarchive/py3/util.py:pd_applyfun_col,pd_applyfun_col,function,5,11,9,107,9.73,0,1,"['df', 'newcol', 'ff', 'use_colname']","[None, None, None, None]","[None, None, None, '""all/[colname]""']",3174,"[""   ''' use all Columns to compute values '''\n""]",['ff'],1
utilmy/zarchive/py3/util.py:pd_cleanquote,pd_cleanquote,function,10,25,23,173,6.92,1,1,['q'],[None],[None],3180,[],"['pd.to_numeric', 'q.fillna']",2
utilmy/zarchive/py3/util.py:pd_date_intersection,pd_date_intersection,function,7,18,15,157,8.72,1,0,['qlist'],[None],[None],3189,[],"['set', 'set.intersection', 'list', 'sorted']",4
utilmy/zarchive/py3/util.py:pd_is_categorical,pd_is_categorical,function,2,12,10,108,9.0,0,1,['z'],[None],[None],3197,[],['isinstance'],1
utilmy/zarchive/py3/util.py:pd_str_encoding_change,pd_str_encoding_change,function,6,8,8,76,9.5,1,0,"['df', 'cols', 'fromenc', 'toenc']","[None, None, None, None]","[None, None, ""'iso-8859-1'"", ""'utf-8'""]",3204,[],[],0
utilmy/zarchive/py3/util.py:pd_str_unicode_tostr,pd_str_unicode_tostr,function,2,4,4,60,15.0,0,0,"['df', 'targetype']","[None, None]","[None, 'str']",3210,"["" '''\n"", ' https://www.azavea.com/blog/2014/03/24/solving-unicode-problems-in-python-2-7/\n', ' Nearly every Unicode problem can be solved by the proper application of these tools;\n', ' they will help you build an airlock to keep the inside of your code nice and clean:\n', '\n', 'encode(): Gets you from Unicode -> bytes\n', 'decode(): Gets you from bytes -> Unicode\n', 'codecs.open(encoding=utf-8): Read and write files directly to/from Unicode (you can use any encoding,\n', ' not just utf-8, but utf-8 is most common).\n', 'u: Makes your string literals into Unicode objects rather than byte sequences.\n', 'Warning: Dont use encode() on bytes or decode() on Unicode objects\n', '\n', '>>> uni_greeting % utf8_name\n', 'Traceback (most recent call last):\n', ' File ""<stdin>"", line 1, in <module>\n', ""UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 3: ordinal not in range(128)\n"", '# Solution:\n', "">>> uni_greeting % utf8_name.decode('utf-8')\n"", ""u'Hi, my name is Josxe9.'\n"", '\n', "" '''\n""]",['pd_dtypes_type1_totype2'],1
utilmy/zarchive/py3/util.py:pd_dtypes_type1_totype2,pd_dtypes_type1_totype2,function,7,13,12,100,7.69,1,1,"['df', 'fromtype', 'targetype']","[None, None, None]","[None, 'str', 'str']",3234,[],['isinstance'],1
utilmy/zarchive/py3/util.py:pd_resetindex,pd_resetindex,function,3,4,4,50,12.5,0,0,['df'],[None],[None],3243,[],['list'],1
utilmy/zarchive/py3/util.py:pd_insertdatecol,pd_insertdatecol,function,8,11,11,192,17.45,0,0,"['df_insider', 'format1=""%Y-%m-%d %H']","[None, '']","[None, '""%Y-%m-%d %H:%M:%S:%f""']",3247,[],"['pd_addcol', 'date_nowtime']",2
utilmy/zarchive/py3/util.py:pd_replacevalues,pd_replacevalues,function,11,14,14,101,7.21,1,0,"['df', 'matrix']","[None, None]","[None, None]",3253,"["" ''' Matrix replaces df.values  '''\n""]",['np.shape'],1
utilmy/zarchive/py3/util.py:pd_removerow,pd_removerow,function,2,2,2,29,14.5,0,0,"['df', 'row_list_index', '45]']","[None, None, None]","[None, '[23', None]",3262,[],['df.drop'],1
utilmy/zarchive/py3/util.py:pd_removecol,pd_removecol,function,2,3,3,28,9.33,0,0,"['df1', 'name1']","[None, None]","[None, None]",3265,[],['df1.drop'],1
utilmy/zarchive/py3/util.py:pd_addcol,pd_addcol,function,3,6,6,30,5.0,0,0,"['df1', 'name1']","[None, None]","[None, ""'new'""]",3268,[],[],0
utilmy/zarchive/py3/util.py:pd_insertcol,pd_insertcol,function,4,6,6,30,5.0,0,0,"['df', 'colname', 'vec']","[None, None, None]","[None, None, None]",3280,"["" ''' Vec and Colname must be aligned '''\n""]",[],0
utilmy/zarchive/py3/util.py:pd_insertrow,pd_insertrow,function,6,10,10,102,10.2,0,0,"['df', 'rowval', 'index1', 'isreset']","[None, None, None, None]","[None, None, 'None', '1']",3296,[],"['pd_array_todataframe', 'df.append']",2
utilmy/zarchive/py3/util.py:pd_h5_cleanbeforesave,pd_h5_cleanbeforesave,function,5,12,11,91,7.58,0,0,['df'],[None],[None],3304,"[""   '''Clean Column type before Saving in HDFS: Unicode, Datetime  '''\n""]","['pd_resetindex', 'pd_str_unicode_tostr']",2
utilmy/zarchive/py3/util.py:pd_h5_addtable,pd_h5_addtable,function,5,18,17,148,8.22,0,1,"['df', 'tablename', ""dbfile='F""]","[None, None, '']","[None, None, ""'F:\\temp_pandas.h5'""]",3320,[],"['pd.HDFStore', 'find', 'list', 'print', 'store.append', 'store.close']",6
utilmy/zarchive/py3/util.py:pd_h5_tableinfo,pd_h5_tableinfo,function,4,4,4,65,16.25,0,0,"['filenameh5', 'table']","[None, None]","[None, None]",3329,[],"['pd.HDFStore', 'store.get_storer']",2
utilmy/zarchive/py3/util.py:pd_h5_dumpinfo,pd_h5_dumpinfo,function,12,23,23,304,13.22,1,0,"[""dbfile='E""]",[''],"[""'E:\\_data\\stock\\intraday_google.h5'""]",3334,[],"['pd.HDFStore', 'list', 'pd.read_hdf', 'extract.append', 'datetime_tostring', 'errsym.append', 'np.array']",7
utilmy/zarchive/py3/util.py:pd_h5_save,pd_h5_save,function,3,6,6,64,10.67,0,0,"['df', ""filenameh5='E"", 'key']","[None, '', None]","[None, ""'E:/_data/_data_outlier.h5'"", ""'data'""]",3347,"["" ''' File is release after saving it'''\n""]","['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zarchive/py3/util.py:pd_h5_load,pd_h5_load,function,4,22,16,185,8.41,0,2,"[""filenameh5='E"", 'table_id', 'exportype', 'rowstart', 'rowend', 'cols']","['', None, None, None, None, None]","[""'E:/_data/_data_outlier.h5'"", ""'data'"", '""pandas""', '-1', '-1', '[]']",3352,[],['pd.read_hdf'],1
utilmy/zarchive/py3/util.py:pd_h5_fromcsv_tohdfs,pd_h5_fromcsv_tohdfs,function,30,78,65,670,8.59,3,2,"['dircsv', 'filepattern', 'tofilehdfs', 'tablename', 'col_category', 'dtype0', 'encoding', 'chunksize', 'mode', 'format', 'complib']","[None, None, None, None, None, None, None, None, None, None, None]","[""'dir1/dir2/'"", ""'*.csv'"", ""'file1.h5'"", ""'df'"", '[]', 'None', ""'utf-8'"", ' 2000000', ""'a'"", ""'table'"", 'None']",3358,[],"['os_file_listall', 'pd.HDFStore', 'enumerate', 'pd.read_csv', 'print', 'store.append', 'store.close', 'os_file_exist']",8
utilmy/zarchive/py3/util.py:pd_np_toh5file,pd_np_toh5file,function,2,8,8,76,9.5,0,0,"['numpyarr', 'fileout', 'table1']","[None, None, None]","[None, '""file.h5""', ""'data'""]",3395,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zarchive/py3/util.py:date_allinfo,date_allinfo,function,0,0,0,0,0.0,0,0,[],[],[],3403,"[""   '''\n"", '\n', '   https://aboutsimon.com/blog/2016/08/04/datetime-vs-Arrow-vs-Pendulum-vs-Delorean-vs-udatetime.html\n', '\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/py3/util.py:date_convert,date_convert,function,14,52,37,298,5.73,1,1,"['t1', 'fromtype', 'totype']","[None, None, None]","[None, None, None]",3412,[],"['len', 'isinstance', '_dateconvert_from', 'tlist.append']",4
utilmy/zarchive/py3/util.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],3436,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/py3/util.py:date_remove_bdays,date_remove_bdays,function,16,41,28,351,8.56,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",3446,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/py3/util.py:date_add_bdays,date_add_bdays,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",3460,[],"['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/py3/util.py:datenumpy_todatetime,datenumpy_todatetime,function,11,36,22,420,11.67,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",3474,[],['type'],1
utilmy/zarchive/py3/util.py:datetime_tonumpydate,datetime_tonumpydate,function,2,2,2,22,11.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",3490,[],['np.datetime64'],1
utilmy/zarchive/py3/util.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",3494,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py3/util.py:datetime_toint,datetime_toint,function,6,15,13,155,10.33,1,1,['datelist1'],[None],[None],3502,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py3/util.py:date_holiday,date_holiday,function,0,0,0,0,0.0,0,0,[],[],[],3509,"[""   '''\n"", '   https://jakevdp.github.io/blog/2015/07/23/learning-seattles-work-habits-from-bicycle-counts/\n', '\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'cal = USFederalHolidayCalendar()\n', ""holidays = cal.holidays('2012', '2016', return_name=True)\n"", 'holidays.head()\n', '\n', 'holidays_all = pd.concat([holidays, ""Day Before "" + holidays.shift(-1, \'D\'),  ""Day After "" + holidays.shift(1, \'D\')])\n', 'holidays_all = holidays_all.sort_index()\n', 'holidays_all.head()\n', '\n', 'from pandas.tseries.offsets import CustomBusinessDay\n', 'from pandas.tseries.holiday import USFederalHolidayCalendar\n', 'bday_us = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n', 'dateref[-1] - bday_us- bday_us\n', '\n', ""   '''\n""]",[],0
utilmy/zarchive/py3/util.py:date_add_bday,date_add_bday,function,16,40,29,350,8.75,1,3,"['from_date', 'add_days']","[None, None]","[None, None]",3529,"["" ''' str / stamp /  '''\n""]","['isint', 'dateint_todatetime', 'datetime.timedelta', 'current_date.weekday', 'datetime_toint']",5
utilmy/zarchive/py3/util.py:dateint_todatetime,dateint_todatetime,function,6,15,13,135,9.0,1,1,['datelist1'],[None],[None],3542,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/py3/util.py:date_diffinday,date_diffinday,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",3550,[],['dateint_todatetime'],1
utilmy/zarchive/py3/util.py:date_diffinyear,date_diffinyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",3554,[],['date_as_float'],1
utilmy/zarchive/py3/util.py:date_diffinbday,date_diffinbday,function,7,11,9,112,10.18,0,0,"['intd2', 'intd1']","[None, None]","[None, None]",3557,[],"['dateint_todatetime', 'd1.date', 'd2.date', 'np.busday_count']",4
utilmy/zarchive/py3/util.py:date_gencalendar,date_gencalendar,function,9,13,11,233,17.92,0,0,"['start', 'end', 'country']","[None, None, None]","[""'2010-01-01'"", ""'2010-01-15'"", ""'us'""]",3565,[],"['CustomBusinessDay', 'np.arrray']",2
utilmy/zarchive/py3/util.py:date_finddateid,date_finddateid,function,5,75,20,437,5.83,0,10,"['date1', 'dateref']","[None, None]","[None, None]",3571,[],['np_findfirst'],1
utilmy/zarchive/py3/util.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],3585,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/py3/util.py:date_now,date_now,function,15,45,31,396,8.8,0,2,['i'],[None],['0'],3591,[],"['datetime.now', 'date_add_bdays', 'date_remove_bdays', 'str', 'date_nowtime', 'datetime.today', 'd.strftime']",7
utilmy/zarchive/py3/util.py:date_nowtime,date_nowtime,function,8,23,18,205,8.91,0,1,"['type1', 'format1= ""%Y-%m-%d %H']","[None, '']","[""'str'"", ' ""%Y-%m-%d %H:%M:%S:%f""']",3598,"["" ''' str / stamp /  '''\n""]","['datetime.today', 'd.strftime']",2
utilmy/zarchive/py3/util.py:date_tofloat,date_tofloat,function,12,28,24,291,10.39,0,1,['dt'],[None],[None],3607,[],"['old_div', 'datetime.datetime', 'isleap', 'timedelta']",4
utilmy/zarchive/py3/util.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",3615,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/py3/util.py:np_numexpr_vec_calc,np_numexpr_vec_calc,function,13,28,22,214,7.64,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",3628,"["" ''' New= xx*xx  over very large series\n"", ' #numexpr_vect_calc(filename, 0, imax=16384*4096, ""xx*xx"", \'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5\'  ):\n', ""'''\n""]","['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/py3/util.py:np_numexpr_tohdfs,np_numexpr_tohdfs,function,10,28,22,248,8.86,0,0,"['filename', 'expr', 'i0', 'imax', ""fileout='E""]","[None, None, None, None, '']","[None, None, '0', '1000', ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",3642,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/py3/util.py:np_comoment,np_comoment,function,4,6,6,70,11.67,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",3658,[],['old_div'],1
utilmy/zarchive/py3/util.py:np_acf,np_acf,function,12,34,31,253,7.44,0,0,['data'],[None],[None],3664,[],"['len', 'np.mean', 'old_div', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/py3/util.py:plot_XY,plot_XY,function,25,83,60,688,8.29,0,3,"['xx', 'yy', 'zcolor', 'tsize', 'title1', 'xlabel', 'ylabel', 'figsize', '6']","[None, None, None, None, None, None, None, None, None]","[None, None, 'None', 'None', ""''"", ""''"", ""''"", '(8', None]",3680,[],"['isinstance', 'np.array', 'np.abs', 'plt.get_cmap', 'np.min', 'plt.subplots', 'fig.set_size_inches', 'fig.set_dpi', 'fig.tight_layout', 'ax1.scatter', 'ax1.set_xlabel', 'ax1.set_ylabel', 'ax1.set_title', 'ax1.grid', 'plt.savefig', 'plt.clf', 'plt.show']",17
utilmy/zarchive/py3/util.py:plot_heatmap,plot_heatmap,function,15,26,25,364,14.0,0,1,"['frame', 'ax', 'cmap', 'vmin', 'vmax', 'interpolation']","[None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', ""'nearest'""]",3720,[],"['plt.gca', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_yticks', 'ax.set_yticklabels', 'ax.grid', 'ax.set_aspect', 'ax.imshow']",8
utilmy/zarchive/py3/util.py:gc_map_dict_to_bq_schema,gc_map_dict_to_bq_schema,function,13,59,31,714,12.1,3,3,"['source_dict', 'schema', 'dest_dict']","[None, None, None]","[None, None, None]",3737,"[""    '''\n"", '     new_dict = {}\n', '     map_dict_to_bq_schema (my_dict, schema, new_dict)\n', '\n', '     new_dict = {}\n', '     map_dict_to_bq_schema (my_dict, schema, new_dict)\n', '\n', '    :param source_dict:\n', '    :param schema:\n', '    :param dest_dict:\n', '    :return:\n', ""    '''\n""]","['map_dict_to_bq_schema', 'format_value_bq']",2
utilmy/zarchive/py3/util.py:aws_accesskey_get,aws_accesskey_get,function,7,17,13,107,6.29,0,1,"['access', 'key']","[None, None]","[""''"", ""''""]",3782,[],[],0
utilmy/zarchive/py3/util.py:aws_conn_do,aws_conn_do,function,2,3,3,39,13.0,0,0,"['action', 'region']","[None, None]","[""''"", '""ap-northeast-2""']",3790,[],['aws_conn_create'],1
utilmy/zarchive/py3/util.py:aws_conn_getallregions,aws_conn_getallregions,function,2,2,2,28,14.0,0,0,['conn'],[None],['None'],3794,[],['conn.get_all_regions'],1
utilmy/zarchive/py3/util.py:aws_conn_create,aws_conn_create,function,21,36,34,282,7.83,1,2,"['region', 'access', 'key']","[None, None, None]","['""ap-northeast-2""', ""''"", ""''""]",3797,[],"['aws_accesskey_get', 'EC2Connection', 'aws_conn_getallregions', 'conn=EC2Connection', 'print']",5
utilmy/zarchive/py3/util.py:aws_conn_getinfo,aws_conn_getinfo,function,1,2,2,28,14.0,0,0,['conn'],[None],[None],3810,[],['print'],1
utilmy/zarchive/py3/util.py:aws_s3_url_split,aws_s3_url_split,function,4,5,5,52,10.4,0,0,['url'],[None],[None],3850,"[""  '''Split into Bucket, url '''\n""]",['url.split'],1
utilmy/zarchive/py3/util.py:aws_s3_getbucketconn,aws_s3_getbucketconn,function,13,17,16,221,13.0,0,0,['s3dir'],[None],[None],3855,[],"['aws_s3_url_split', 'aws_accesskey_get', 'boto.connect_s3', 'conn.get_bucket']",4
utilmy/zarchive/py3/util.py:aws_s3_puto_s3,aws_s3_puto_s3,function,36,114,102,1158,10.16,3,2,"['fromdir_file', 'todir']","[None, None]","[""'dir/file.zip'"", ""'bucket/folder1/folder2'""]",3863,"["" ''' Copy File or Folder to S3 '''\n""]","['aws_s3_getbucketconn', 'aws_s3_url_split', 'fromdir_file.find', 'os_file_getname', 'fromdir_file=os_file_getpath', 'os.walk', 'uploadFileNames.extend', 'percent_cb', 'print', 'bucket.initiate_multipart_upload', 'open', 'mp.upload_part_from_file', 'mp.complete_upload', 'k.set_contents_from_filename']",14
utilmy/zarchive/py3/util.py:aws_s3_getfrom_s3,aws_s3_getfrom_s3,function,21,45,45,430,9.56,1,1,"['froms3dir', 'todir', 'bucket_name']","[None, None, None]","[""'task01/'"", ""''"", ""'zdisk'""]",3907,"["" ''' Get from S3 file/folder  '''\n""]","['aws_s3_url_split', 'aws_s3_getbucketconn', 'bucket.list', 'str', 'os_file_getname', 'os_file_getpath', 'os.makedirs', 'l.get_contents_to_filename']",8
utilmy/zarchive/py3/util.py:aws_s3_folder_printtall,aws_s3_folder_printtall,function,12,18,17,234,13.0,1,0,['bucket_name'],[None],"[""'zdisk'""]",3926,[],"['aws_accesskey_get', 'boto.connect_s3', 'conn.create_bucket', 'bucket.list', 'print']",5
utilmy/zarchive/py3/util.py:aws_s3_file_read,aws_s3_file_read,function,10,14,13,187,13.36,0,0,"['filepath', 'isbinary']","[None, None]","[None, '1']",3935,"[""  ''' s3_client = boto3.client('s3')\n"", '    #Download private key file from secure S3 bucket\n', ""  s3_client.download_file('s3-key-bucket','keys/keyname.pem', '/tmp/keyname.pem')\n"", ""  '''\n""]","['S3Connection', 'conn.get_object']",2
utilmy/zarchive/py3/util.py:aws_ec2_python_script,aws_ec2_python_script,function,5,20,18,195,9.75,0,0,"['script_path', 'args1', 'host']","[None, None, None]","[None, None, None]",4179,[],['aws_ec2_cmd_ssh'],1
utilmy/zarchive/py3/util.py:aws_ec2_create_con,aws_ec2_create_con,function,35,116,89,1002,8.64,1,9,"['contype', 'host', 'port', 'username', 'keyfilepath', 'password', 'keyfiletype', 'isprint']","[None, None, None, None, None, None, None, None]","[""'sftp/ssh'"", ""'ip'"", '22', ""'ubuntu'"", ""''"", ""''"", ""'RSA'"", '1']",4184,"['    """""" Transfert File  host = \'52.79.79.1\'\n', ""        keyfilepath = 'D:/_devs/aws/keypairs/ec2_instanc'\n"", '\n', '# List files in the default directory on the remote computer.\n', ""dirlist = sftp.listdir('.')\n"", ""sftp.get('remote_file.txt', 'downloaded_file.txt')\n"", ""sftp.put('testfile.txt', 'remote_testfile.txt')\n"", '\n', 'http://docs.paramiko.org/en/2.1/api/sftp.html\n', '    """"""\n']","['paramiko.Transport', 'transport.add_server_key', 'transport.connect', 'print', 'sftp.listdir', 'paramiko.SSHClient', 'ssh.set_missing_host_key_policy', 'ssh.connect', 'ssh.exec_command', 'stdin.flush', 'stdout.read', 'sftp.close', 'transport.close', 'ssh.close']",14
utilmy/zarchive/py3/util.py:aws_ec2_allocate_elastic_ip,aws_ec2_allocate_elastic_ip,function,7,16,16,233,14.56,0,0,"['instance_id', 'region']","[None, None]","[None, '""ap-northeast-2""']",4233,[],"['aws_conn_create', 'con.associate_address', 'print']",3
utilmy/zarchive/py3/util.py:googledrive_get,googledrive_get,function,0,1,1,4,4.0,0,0,[],[],[],4388,"[""   '''\n"", '   https://github.com/ctberthiaume/gdcp\n', '   ... I am using this now to transfer thousands of mp3 files from a ubuntu vps to google drive.\n', '\n', '\n', 'http://olivermarshall.net/how-to-upload-a-file-to-google-drive-from-the-command-line/\n', 'https://github.com/prasmussen/gdrive  : Super Complete\n', '\n', 'gdrive [global] upload [options] <path>\n', '\n', 'global:\n', '  -c, --config <configDir>         Application path, default: /Users/<user>/.gdrive\n', '  --refresh-token <refreshToken>   Oauth refresh token used to get access token (for advanced users)\n', '  --access-token <accessToken>     Oauth access token, only recommended for short-lived requests because of short lifetime (for advanced users)\n', '\n', 'options:\n', '  -r, --recursive           Upload directory recursively\n', '  -p, --parent <parent>     Parent id, used to upload file to a specific directory, can be specified multiple times to give many parents\n', '  --name <name>             Filename\n', '  --no-progress             Hide progress\n', '  --mime <mime>             Force mime type\n', '  --share                   Share file\n', '  --delete                  Delete local file when upload is successful\n', '  --chunksize <chunksize>   Set chunk size in bytes, default: 8388608\n', '\n', '   :return:\n', ""   '''\n""]",[],0
utilmy/zarchive/py3/util.py:googledrive_put,googledrive_put,function,0,1,1,4,4.0,0,0,[],[],[],4418,"[""  '''\n"", '  100 GB: 2USD,  1TB: 10USD\n', '  https://gsuite.google.com/intl/en/pricing.html\n', '\n', '  :return:\n', ""  '''\n""]",[],0
utilmy/zarchive/py3/util.py:googledrive_list,googledrive_list,function,0,1,1,4,4.0,0,0,[],[],[],4428,[],[],0
utilmy/zarchive/py3/util.py:os_processify_fun,os_processify_fun,function,32,78,63,713,9.14,0,1,['func'],[None],[None],4433,"[""    '''Decorator to run a function as a process.\n"", '    Be sure that every argument and the return value is *pickable*.\n', '    The created process is joined, so the code does not  run in parallel.\n', '    @processify\n', '\n', '    def test():\n', '      return os.getpid()\n', '\n', '    @processify\n', '    def test_deadlock():\n', '      return range(30000)\n', '\n', '   @processify\n', '   def test_exception():\n', ""     raise RuntimeError('xyz')\n"", '\n', '   def test():\n', '     print os.getpid()\n', '     print test_function()\n', '     print len(test_deadlock())\n', '     test_exception()\n', '\n', ""   if __name__ == '__main__':\n"", '     test()\n', '\n', ""    '''\n""]","['process_func', 'func', 'sys.exc_info', 'q.put', 'setattr', 'wrapper', 'Queue', 'Process', 'list', 'p.start', 'q.get', 'ex_type']",12
utilmy/zarchive/py3/util.py:ztest_processify,ztest_processify,function,2,2,2,17,8.5,0,0,[],[],[],4500,[],['os.getpid'],1
utilmy/zarchive/py3/util.py:date_getspecificdate,date_getspecificdate,function,21,194,56,1312,6.76,8,19,"['datelist', 'datetype1', 'outputype1', 'includelastdate', 'includefirstdate', '']","[None, None, None, None, None, None]","[None, '""yearend""', '""intdate""', 'True', 'False', None]",4520,[],"['isint', 'dateint_todatetime', 'enumerate', 'vec2.append', 'np.mod', 'np.array']",6
utilmy/zarchive/py3/util.py:testclass,testclass,class,21,51,42,434,8.51,0,3,[],[],[],127,[],[],0
utilmy/zarchive/py3/util.py:FundingRecord,FundingRecord,class,14,59,48,394,6.68,0,0,[],[],[],1391,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh,aws_ec2_ssh,class,129,339,228,4029,11.88,10,10,[],[],[],3950,[],[],0
utilmy/zarchive/py3/util.py:testclass:__init__,testclass:__init__,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",128,[],[],0
utilmy/zarchive/py3/util.py:testclass:z_autotest,testclass:z_autotest,method,19,44,38,387,8.8,0,3,['self'],[None],[None],131,[],"['io.StringIO', 'f', 'self.redirect_internalshell_stdio', 'getopenfilename', '_', 'getcwd', 'self.close']",7
utilmy/zarchive/py3/util.py:FundingRecord:parse,FundingRecord:parse,method,7,35,26,223,6.37,0,0,"['klass', 'row']","[None, None]","[None, None]",1394,[],"['list', 'int', 'datetime.strptime', 'klass']",4
utilmy/zarchive/py3/util.py:FundingRecord:__str__,FundingRecord:__str__,method,6,18,18,118,6.56,0,0,['self'],[None],[None],1401,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh:__init__,aws_ec2_ssh:__init__,method,21,27,25,415,15.37,0,0,"['self', 'hostname', 'username', 'key_file', 'password']","[None, None, None, None, None]","[None, None, ""'ubuntu'"", 'None', 'None']",3966,[],"['socket.socket', 'paramiko.Transport', 'print']",3
utilmy/zarchive/py3/util.py:aws_ec2_ssh:command,aws_ec2_ssh:command,method,12,20,18,247,12.35,1,0,"['self', 'cmd']","[None, None]","[None, None]",4005,[],"['chan.get_pty', 'chan.invoke_shell', 'chan.settimeout', 'chan.send', 'cmd.split']",5
utilmy/zarchive/py3/util.py:aws_ec2_ssh:put,aws_ec2_ssh:put,method,17,33,29,650,19.7,2,2,"['self', 'localfile', 'remotefile']","[None, None, None]","[None, None, None]",4025,[],"['put_all', 'os.chdir', 'os.walk', 'print', 'self.put']",5
utilmy/zarchive/py3/util.py:aws_ec2_ssh:put_all,aws_ec2_ssh:put_all,method,15,30,26,575,19.17,2,2,"['self', 'localpath', 'remotepath']","[None, None, None]","[None, None, None]",4029,[],"['os.chdir', 'os.walk', 'print', 'self.put']",4
utilmy/zarchive/py3/util.py:aws_ec2_ssh:get,aws_ec2_ssh:get,method,1,1,1,35,35.0,0,0,"['self', 'remotefile', 'localfile']","[None, None, None]","[None, None, None]",4045,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh:sftp_walk,aws_ec2_ssh:sftp_walk,method,20,33,26,371,11.24,3,1,"['self', 'remotepath']","[None, None]","[None, None]",4049,[],"['S_ISDIR', 'folders.append', 'files.append', 'print', 'self.sftp_walk']",5
utilmy/zarchive/py3/util.py:aws_ec2_ssh:get_all,aws_ec2_ssh:get_all,method,15,38,30,601,15.82,2,2,"['self', 'remotepath', 'localpath']","[None, None, None]","[None, None, None]",4070,[],"['os.mkdir', 'self.sftp_walk', 'print', 'self.get']",4
utilmy/zarchive/py3/util.py:aws_ec2_ssh:write_command,aws_ec2_ssh:write_command,method,2,2,2,74,37.0,0,0,"['self', 'text', 'remotefile']","[None, None, None]","[None, None, None]",4094,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh:python_script,aws_ec2_ssh:python_script,method,5,12,10,119,9.92,0,0,"['self', 'script_path', 'args1']","[None, None, None]","[None, None, None]",4101,[],['self.cmd2'],1
utilmy/zarchive/py3/util.py:aws_ec2_ssh:command_list,aws_ec2_ssh:command_list,method,5,13,13,116,8.92,1,0,"['self', 'cmdlist']","[None, None]","[None, None]",4107,[],"['print', 'self.command']",2
utilmy/zarchive/py3/util.py:aws_ec2_ssh:listdir,aws_ec2_ssh:listdir,method,2,2,2,34,17.0,0,0,"['self', 'remotedir']","[None, None]","[None, None]",4114,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh:jupyter_kill,aws_ec2_ssh:jupyter_kill,method,3,9,9,130,14.44,0,0,['self'],[None],[None],4117,[],"['aws_ec2_cmd_ssh', 'print']",2
utilmy/zarchive/py3/util.py:aws_ec2_ssh:jupyter_start,aws_ec2_ssh:jupyter_start,method,0,1,1,4,4.0,0,0,['self'],[None],[None],4121,[],[],0
utilmy/zarchive/py3/util.py:aws_ec2_ssh:cmd2,aws_ec2_ssh:cmd2,method,2,5,5,63,12.6,0,0,"['self', 'cmd1']","[None, None]","[None, None]",4124,[],['aws_ec2_cmd_ssh'],1
utilmy/zarchive/py3/util.py:aws_ec2_ssh:_help_ssh,aws_ec2_ssh:_help_ssh,method,18,29,29,132,4.55,0,1,['self'],[None],[None],4129,[],[],0
utilmy/zarchive/storage/allmodule.py:aa_isanaconda,aa_isanaconda,function,6,15,14,80,5.33,0,1,[],[],[],4,[],['txt.find'],1
utilmy/zarchive/storage/benchmarktest.py:payoff1,payoff1,function,4,5,5,61,12.2,0,0,['pricepath'],[None],[None],130,[],"['pricepath[len', 'np.maximum']",2
utilmy/zarchive/storage/benchmarktest.py:payoffeuro1,payoffeuro1,function,2,3,3,30,10.0,0,0,['st'],[None],[None],145,[],['np.maximum'],1
utilmy/zarchive/storage/benchmarktest.py:payoff2,payoff2,function,6,13,13,127,9.77,0,0,['pricepath'],[None],[None],181,[],"['np.shape', 'np.sum', 'np.maximum']",3
utilmy/zarchive/storage/benchmarktest.py:payoffeuro1,payoffeuro1,function,2,3,3,30,10.0,0,0,['st'],[None],[None],145,[],['np.maximum'],1
utilmy/zarchive/storage/codeanalysis.py:wi,wi,function,6,11,9,88,8.0,0,0,['*args)'],['  #Print with indentationaux'],"[""''' '*INDENT)for arg in args:""]",13,[],"['str', 'dx.replace']",2
utilmy/zarchive/storage/codeanalysis.py:printinfile,printinfile,function,5,12,10,53,4.42,1,1,"['vv', 'file2)', '""a"") as text_file']","[None, '  # print vvfile2', '    text_file.write(vv)*args):']","[None, None, None]",24,[],[],0
utilmy/zarchive/storage/codeanalysis.py:wi2,wi2,function,5,12,10,53,4.42,1,1,['*args'],[None],[None],28,[],[],0
utilmy/zarchive/storage/codeanalysis.py:indent,indent,function,17,43,34,344,8.0,0,4,[')'],['     global INDENT; INDENT +'],[' 4):      global INDENT; INDENT -= 4obj):'],33,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/codeanalysis.py:dedent,dedent,function,17,43,34,344,8.0,0,4,[')'],['      global INDENT; INDENT -'],[' 4obj):'],34,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/codeanalysis.py:describe_builtin,describe_builtin,function,17,43,34,344,8.0,0,4,['obj'],[None],[None],38,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/codeanalysis.py:describe_func,describe_func,function,18,59,46,443,7.51,0,5,"['obj', 'method']","[None, None]","[None, 'False']",58,[],"['inspect.getargspec', 'wi', 'str', 'len']",4
utilmy/zarchive/storage/codeanalysis.py:describe_klass,describe_klass,function,12,33,30,238,7.21,1,2,['obj'],[None],[None],81,[],"['wi', 'indent', 'getattr', 'inspect.ismethod', '1;describe_func', 'dedent']",6
utilmy/zarchive/storage/codeanalysis.py:describe,describe,function,61,353,164,2895,8.2,4,21,['obj'],[None],[None],97,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find', 'describe_func', 'inspect.getargspec', 'str', 'len', 'describe_klass', 'indent', 'getattr', 'inspect.ismethod', '1;describe_func', 'dedent', 'describe', 'dir', 'inspect.isclass', 'inspect.isfunction', 'inspect.isbuiltin', 'describe_builtin', 'describe_builtin2', 'describe_func2', 'describe_func3', 'aux.replace', 'aux.rstrip', 'describe_klass2', 'describe2']",27
utilmy/zarchive/storage/codeanalysis.py:describe_builtin2,describe_builtin2,function,16,33,26,272,8.24,0,3,"['obj', 'name1']","[None, None]","[None, None]",118,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/codeanalysis.py:describe_func2,describe_func2,function,9,21,21,143,6.81,0,1,"['obj', 'method', 'name1']","[None, None, None]","[None, 'False', ""''""]",135,[],"['inspect.getargspec', 'wi', 'str']",3
utilmy/zarchive/storage/codeanalysis.py:describe_func3,describe_func3,function,14,34,31,236,6.94,0,1,"['obj', 'method', 'name1']","[None, None, None]","[None, 'False', ""''""]",145,[],"['inspect.getargspec', 'str', 'aux.replace', 'aux.rstrip', 'wi']",5
utilmy/zarchive/storage/codeanalysis.py:describe_klass2,describe_klass2,function,8,18,18,151,8.39,1,1,"['obj', 'name1']","[None, None]","[None, ""''""]",158,[],"['getattr', 'inspect.ismethod', 'describe_func2']",3
utilmy/zarchive/storage/codeanalysis.py:describe2,describe2,function,13,43,33,377,8.77,1,2,"['module', 'type1']","[None, None]","[None, '0']",168,[],"['wi', 'dir', 'getattr', 'inspect.isclass', 'describe_klass2', 'inspect.isfunction', 'describe_func2', 'describe_func3', 'inspect.isbuiltin', 'describe_builtin2']",10
utilmy/zarchive/storage/codeanalysis.py:getmodule_doc,getmodule_doc,function,32,102,69,872,8.55,5,1,"['module1', 'file2']","[None, None]","[None, ""''""]",192,[],"['importlib.import_module', 'pkgutil.walk_packages', 'vv.append', 'wi', 'describe2', 'sys.exc_info', 'describe', 'print']",8
utilmy/zarchive/storage/derivatives.py:loadbrownian,loadbrownian,function,4,4,4,125,31.25,0,0,"['nbasset', 'step', 'nbsimul']","[None, None, None]","[None, None, None]",35,[],['np.load'],1
utilmy/zarchive/storage/derivatives.py:dN,dN,function,1,13,12,63,4.85,0,0,"['d)', 'y)', 'K', 't', 'T', 'r', 'd', 'vol)']","['   return    np.exp(-0.5*d*d)*ONE_SQRT_2PI   # ss.norm.pdf(d)x', '   return  np.exp(-0.5*x*x-0.5*y*y)*ONE_2PI   # ss.norm.pdf(d)d):    return  ss.norm.cdf(d)St', None, None, None, None, None, '']","[None, None, None, None, None, None, None, None]",47,[],['np.sqrt'],1
utilmy/zarchive/storage/derivatives.py:dN2d,dN2d,function,1,13,12,63,4.85,0,0,"['x', 'y)', 'K', 't', 'T', 'r', 'd', 'vol)']","[None, '   return  np.exp(-0.5*x*x-0.5*y*y)*ONE_2PI   # ss.norm.pdf(d)d):    return  ss.norm.cdf(d)St', None, None, None, None, None, '']","[None, None, None, None, None, None, None, None]",49,[],['np.sqrt'],1
utilmy/zarchive/storage/derivatives.py:N,N,function,1,13,12,63,4.85,0,0,"['d)', 'K', 't', 'T', 'r', 'd', 'vol)']","['    return  ss.norm.cdf(d)St', None, None, None, None, None, '']","[None, None, None, None, None, None, None]",54,[],['np.sqrt'],1
utilmy/zarchive/storage/derivatives.py:d1f,d1f,function,1,13,12,63,4.85,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",56,[],['np.sqrt'],1
utilmy/zarchive/storage/derivatives.py:d2f,d2f,function,1,13,12,63,4.85,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",59,[],['np.sqrt'],1
utilmy/zarchive/storage/derivatives.py:bsbinarycall,bsbinarycall,function,4,11,11,64,5.82,0,0,"['S0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",63,[],"['d2f', 'np.exp']",2
utilmy/zarchive/storage/derivatives.py:bscall,bscall,function,6,15,14,118,7.87,0,0,"['S0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",68,[],['d1f'],1
utilmy/zarchive/storage/derivatives.py:bsput,bsput,function,5,15,14,121,8.07,0,0,"['S0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",74,[],['d1f'],1
utilmy/zarchive/storage/derivatives.py:bs,bs,function,30,342,119,2051,6.0,0,2,"['S0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",80,[],"['d2f', 'np.exp', 'bscall', 'd1f', 'bsput', 'bs', 'bsdelta', 'N', 'bsgamma', 'np.sqrt', 'bsstrikedelta', 'bsstrikegamma', 'bstheta', 'bsrho', 'bsvega', 'dN', 'bsdvd', 'bsvanna', 'bsvolga', 'bsgammaspot']",20
utilmy/zarchive/storage/derivatives.py:bsdelta,bsdelta,function,4,19,19,102,5.37,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp1)', 'K', 't', 'T', 'r', 'd', 'vol)-d*(T-t)) * N(d1)-d*(T-t)) * (N(d1)-1)return auxSt', 'K', 't', 'T', 'r', 'd', 'vol', 'cp)']","[None, None, None, None, None, None, None, ' #be careful of equality for booleanSt', None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]",86,[],"['d1f', 'np.exp', 'np.sqrt']",3
utilmy/zarchive/storage/derivatives.py:bsgamma,bsgamma,function,4,19,19,102,5.37,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",93,[],"['d1f', 'np.exp', 'np.sqrt']",3
utilmy/zarchive/storage/derivatives.py:bsstrikedelta,bsstrikedelta,function,4,19,19,102,5.37,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol', 'cp1)', 'K', 't', 'T', 'r', 'd', 'vol)-r*T)*N(d2)-r*T)*N(-d2)return auxs0', 'K', 't', 'T', 'r', 'd', 'vol)']","[None, None, None, None, None, None, None, '  #discounted risk neutral probabilitys0', None, None, None, None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]",98,[],"['d1f', 'np.exp', 'np.sqrt']",3
utilmy/zarchive/storage/derivatives.py:bsstrikegamma,bsstrikegamma,function,4,19,19,102,5.37,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",105,[],"['d1f', 'np.exp', 'np.sqrt']",3
utilmy/zarchive/storage/derivatives.py:bstheta,bstheta,function,3,20,19,104,5.2,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",110,[],"['d1f', 'np.sqrt', 'N']",3
utilmy/zarchive/storage/derivatives.py:bsrho,bsrho,function,4,16,15,72,4.5,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",115,[],"['d2f', 'np.exp', 'N']",3
utilmy/zarchive/storage/derivatives.py:bsvega,bsvega,function,4,13,13,75,5.77,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",120,[],"['d1f', 'np.sqrt', 'dN']",3
utilmy/zarchive/storage/derivatives.py:bsdvd,bsdvd,function,3,22,20,97,4.41,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",125,[],"['d1f', 'np.sqrt', 'np.exp', 'N']",4
utilmy/zarchive/storage/derivatives.py:bsvanna,bsvanna,function,3,16,15,85,5.31,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",130,[],"['d1f', 'np.sqrt', 'dN']",3
utilmy/zarchive/storage/derivatives.py:bsvolga,bsvolga,function,4,18,16,103,5.72,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",135,[],"['d1f', 'np.sqrt', 'dN']",3
utilmy/zarchive/storage/derivatives.py:bsgammaspot,bsgammaspot,function,4,18,18,124,6.89,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",140,[],"['d1f', 'np.exp']",2
utilmy/zarchive/storage/derivatives.py:gdelta,gdelta,function,1,15,10,63,4.2,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'pv']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",149,[],['pv'],1
utilmy/zarchive/storage/derivatives.py:ggamma,ggamma,function,1,21,11,88,4.19,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'pv']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",152,[],"['pv', '2*pv']",2
utilmy/zarchive/storage/derivatives.py:gvega,gvega,function,1,15,11,58,3.87,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'pv']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",155,[],['pv'],1
utilmy/zarchive/storage/derivatives.py:gtheta,gtheta,function,1,15,11,66,4.4,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'pv']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",158,[],['pv'],1
utilmy/zarchive/storage/derivatives.py:genmatrix,genmatrix,function,9,14,12,83,5.93,2,0,"['ni', 'nj', 'gg']","[None, None, None]","[None, None, None]",166,[],"['np.zeros', 'range', 'gg']",3
utilmy/zarchive/storage/derivatives.py:gensymmatrix,gensymmatrix,function,9,19,15,89,4.68,2,1,"['ni', 'nj', 'pp']","[None, None, None]","[None, None, None]",175,[],"['np.zeros', 'range']",2
utilmy/zarchive/storage/derivatives.py:payoff1,payoff1,function,4,5,5,47,9.4,0,0,['pricepath'],[None],[None],434,[],['np.maximum'],1
utilmy/zarchive/storage/derivatives.py:payoffeuro1,payoffeuro1,function,2,3,3,30,10.0,0,0,['st'],[None],[None],439,[],['np.maximum'],1
utilmy/zarchive/storage/derivatives.py:payoff2,payoff2,function,6,13,13,124,9.54,0,0,['pricepath'],[None],[None],605,[],"['np.shape', 'sum', 'np.maximum']",3
utilmy/zarchive/storage/derivatives.py:savebrownian,savebrownian,function,1,8,8,58,7.25,0,0,"['nbasset', 'step', 'nbsimul']","[None, None, None]","[None, None, None]",30,[],[],0
utilmy/zarchive/storage/derivatives.py:plot_greeks,plot_greeks,function,39,78,68,528,6.77,2,0,"['function', 'greek']","[None, None]","[None, None]",1036,[],"['np.linspace', 'np.zeros', 'len', 'range', 'function', 'np.meshgrid', 'plt.figure', 'p3.Axes3D', 'plot.plot_wireframe', 'plot.set_xlabel', 'plot.set_ylabel', 'plot.set_zlabel']",12
utilmy/zarchive/storage/derivatives.py:plot_greeks,plot_greeks,function,39,78,68,528,6.77,2,0,"['function', 'greek']","[None, None]","[None, None]",1036,[],"['np.linspace', 'np.zeros', 'len', 'range', 'function', 'np.meshgrid', 'plt.figure', 'p3.Axes3D', 'plot.plot_wireframe', 'plot.set_xlabel', 'plot.set_ylabel', 'plot.set_zlabel']",12
utilmy/zarchive/storage/derivatives.py:plot_values,plot_values,function,32,125,76,888,7.1,0,0,['function'],[None],[None],1097,[],"['plt.figure', 'plt.subplot', 'np.linspace', 'plt.plot', 'plt.grid', 'plt.xlabel', 'plt.ylabel', 'plt.axis', 'plt.tight_layout']",9
utilmy/zarchive/storage/derivatives.py:CRR_option_value,CRR_option_value,function,32,121,84,518,4.28,1,1,"['S0', 'K', 'T', 'r', 'vol', 'otype', 'M']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, '4']",1153,"[""    ''' Cox-Ross-Rubinstein European option valuation.\n"", ""    otype : string  either 'call' or 'put'\n"", '    M : int  number of time intervals\n', ""    '''\n""]","['np.exp', 'np.sqrt', 'np.arange', 'np.resize', 'np.transpose', 'np.maximum', 'range']",7
utilmy/zarchive/storage/dl_utils.py:save_weights,save_weights,function,1,5,5,42,8.4,0,0,"['file', 'tuple_weights']","[None, None]","[None, None]",21,[],"['pickle.dump', 'open']",2
utilmy/zarchive/storage/dl_utils.py:save_prediction,save_prediction,function,1,5,5,39,7.8,0,0,"['file', 'prediction']","[None, None]","[None, None]",24,[],"['pickle.dump', 'open']",2
utilmy/zarchive/storage/dl_utils.py:log,log,function,4,6,6,91,15.17,0,0,"['msg', 'file']","[None, None]","[None, '""""']",27,[],"['open', 'logfile']",2
utilmy/zarchive/storage/dl_utils.py:logfile,logfile,function,5,8,8,76,9.5,0,0,"['msg', 'file']","[None, None]","[None, None]",30,[],"['open', 'myfile.write']",2
utilmy/zarchive/storage/dl_utils.py:log_p,log_p,function,3,2,2,23,11.5,0,0,"['msg', 'file']","[None, None]","[None, '""""']",34,[],['log'],1
utilmy/zarchive/storage/dl_utils.py:init_weight,init_weight,function,1,4,4,52,13.0,0,0,"['hidden1', 'hidden2', 'acti_type']","[None, None, None]","[None, None, None]",38,[],[],0
utilmy/zarchive/storage/dl_utils.py:get_all_data,get_all_data,function,21,26,25,476,18.31,1,2,['file'],[None],[None],52,[],"['str', 'open', 'line.strip', 'x.split']",4
utilmy/zarchive/storage/dl_utils.py:get_batch_data,get_batch_data,function,7,7,7,195,27.86,0,1,"['file', 'index', 'size)', '5->1', '2', '3', '4', '5array', 'index+size)']","[None, None, '#1', None, None, None, None, None, '']","[None, None, None, None, None, None, None, '[]arrayY=[]index', None]",75,[],"['line.strip', 'x.split']",2
utilmy/zarchive/storage/dl_utils.py:get_xy,get_xy,function,5,6,6,107,17.83,0,0,['line'],[None],[None],95,[],"['y=int', 'x.split']",2
utilmy/zarchive/storage/dl_utils.py:file_len,file_len,function,7,10,10,62,6.2,1,0,['fname'],[None],[None],103,[],"['open', 'enumerate']",2
utilmy/zarchive/storage/dl_utils.py:feats_len,feats_len,function,4,5,5,65,13.0,0,0,['fname'],[None],[None],111,[],['open'],1
utilmy/zarchive/storage/excel.py:get_workbook_name,get_workbook_name,function,3,5,5,48,9.6,0,0,[],[],[],9,"['    """"""Writes the name of the Workbook into Range(""D3"") of Sheet 1""""""\n']","['Workbook.caller', 'Range']",2
utilmy/zarchive/storage/excel.py:double_sum,double_sum,function,1,4,4,13,3.25,0,0,"['x', 'y']","[None, None]","[None, None]",16,"['    """"""Returns twice the sum of the two arguments""""""\n']",[],0
utilmy/zarchive/storage/excel.py:add_one,add_one,function,5,11,9,40,3.64,2,0,['data'],[None],[None],23,"['    """"""Adds 1 to every cell in Range""""""\n']",[],0
utilmy/zarchive/storage/excel.py:matrix_mult,matrix_mult,function,2,2,2,14,7.0,0,0,"['x', 'y']","[None, None]","[None, None]",31,"['    """"""Alternative implementation of Excel\'s MMULT, requires NumPy""""""\n']",['x.dot'],1
utilmy/zarchive/storage/excel.py:npdot,npdot,function,0,0,0,0,0.0,0,0,[],[],[],43,[],[],0
utilmy/zarchive/storage/java.py:importJAR,importJAR,function,7,26,16,261,10.04,0,3,"['path1', 'path2', 'path3', 'path4']","[None, None, None, None]","['""""', '""""', '""""', '""""']",24,[],['jp.startJVM'],1
utilmy/zarchive/storage/java.py:listallfile,listallfile,function,20,36,30,353,9.81,2,1,"['some_dir', 'pattern', 'dirlevel']","[None, None, None]","[None, '""*.*""', '1']",36,[],"['some_dir.rstrip', 'some_dir.count', 'os.walk', 'root.count', 'fnmatch.filter', 'matches.append']",6
utilmy/zarchive/storage/java.py:importFolderJAR,importFolderJAR,function,7,18,17,182,10.11,1,0,"['dir1', 'dirlevel']","[None, None]","['""""', '1']",52,[],"['listallfile', 'jp.startJVM']",2
utilmy/zarchive/storage/java.py:importFromMaven,importFromMaven,function,1,2,2,7,3.5,0,0,[],[],[],62,[],[],0
utilmy/zarchive/storage/java.py:showLoadedClass,showLoadedClass,function,5,10,10,93,9.3,0,0,[')'],[' #Code to see the JAR loaded.); vv'],[' [];):  vv.append(x.toString());return vvdir1) :'],68,[],"['zipfile.ZipFile', 'archive.namelist']",2
utilmy/zarchive/storage/java.py:inspectJAR,inspectJAR,function,5,10,10,93,9.3,0,0,['dir1'],[None],[None],77,[],"['zipfile.ZipFile', 'archive.namelist']",2
utilmy/zarchive/storage/java.py:loadSingleton,loadSingleton,function,6,7,7,102,14.57,0,0,['class1)'],['  single'],[' jp.JClass(class1);  return Single.getInstance()x):  jp.java.lang.System.out.println(x)   #Print in Java Consolejavafile):'],86,[],"['os.getenv', 'subprocess.check_call']",2
utilmy/zarchive/storage/java.py:java_print,java_print,function,6,7,7,102,14.57,0,0,['x)'],['  jp.java.lang.System.out.println(x)   #Print in Java Consolejavafile):'],[None],89,[],"['os.getenv', 'subprocess.check_call']",2
utilmy/zarchive/storage/java.py:compileJAVA,compileJAVA,function,6,7,7,102,14.57,0,0,['javafile'],[None],[None],92,[],"['os.getenv', 'subprocess.check_call']",2
utilmy/zarchive/storage/java.py:writeText,writeText,function,2,5,5,68,13.6,0,0,"['text', 'filename']","[None, None]","[None, None]",98,[],"['open', 'text_file.write', 'text_file.close']",3
utilmy/zarchive/storage/java.py:compileJAVAtext,compileJAVAtext,function,8,15,14,161,10.73,0,1,"['classname', 'javatxt', 'path1']","[None, None, None]","[None, None, '""""']",102,[],"['os.getcwd', 'text_file=open', 'text_file.write', 'text_file.close', 'compileJAVA']",5
utilmy/zarchive/storage/multiprocessfunc.py:multigbm_paralell_func,multigbm_paralell_func,function,34,117,81,913,7.8,1,4,"['nbsimul', 'ww', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price', 'type1', 'strike', 'cp']","[None, None, None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, '0', '0', '1']",20,[],"['np.zeros', 'range', 'np.dot', 'np.multiply', 'np.exp', 'np.cumprod', 'np.maximum', 'sum', 'sum1/float']",9
utilmy/zarchive/storage/multiprocessfunc.py:func,func,function,6,10,10,56,5.6,1,0,"['val', 'lock']","[None, None]","[None, None]",73,[],"['range', 'time.sleep']",2
utilmy/zarchive/storage/multiprocessfunc.py:multigbm_processfast7,multigbm_processfast7,function,24,48,44,419,8.73,3,0,"['nbsimul', 's0', 'voldt', 'drift', 'upper_cholesky', 'nbasset', 'n', 'price']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",150,[],"['range', 'np.dot', 'bm_generator', 'np.exp', 'sum', 'sum1/float']",6
utilmy/zarchive/storage/multiprocessfunc.py:bm_generator,bm_generator,function,5,9,8,43,4.78,0,1,"['bm', 'dt', 'n', 'type1']","[None, None, None, None]","[None, None, None, None]",177,[],[],0
utilmy/zarchive/storage/multiprocessfunc.py:merge,merge,function,6,20,17,106,5.3,1,1,['d2'],[None],[None],211,[],"['time.sleep', 'd2.keys']",2
utilmy/zarchive/storage/multiprocessfunc.py:integratenp2,integratenp2,function,10,29,25,184,6.34,1,0,"['its', 'nchunk']","[None, None]","[None, None]",222,[],"['range', 'ne.evaluate']",2
utilmy/zarchive/storage/multiprocessfunc.py:integratenp,integratenp,function,27,77,47,454,5.9,2,0,"['its', 'nchunk']","[None, None]","[None, None]",234,[],"['range', 'ne.evaluate', 'integratenp', 'np.sum', 'float']",5
utilmy/zarchive/storage/multiprocessfunc.py:integratene,integratene,function,12,44,38,275,6.25,1,0,['its'],[None],[None],247,[],"['range', 'ne.evaluate', 'float']",3
utilmy/zarchive/storage/multiprocessfunc.py:parzen_estimation,parzen_estimation,function,7,30,26,185,6.17,2,1,"['x_samples', 'point_x', 'h']","[None, None, None]","[None, None, None]",268,[],"['np.abs', 'len']",2
utilmy/zarchive/storage/multiprocessfunc.py:init2,init2,function,2,4,4,13,3.25,0,0,['d'],[None],[None],282,[],[],0
utilmy/zarchive/storage/multiprocessfunc.py:init_global1,init_global1,function,2,2,2,37,18.5,0,0,"['l', 'r']","[None, None]","[None, None]",286,[],[],0
utilmy/zarchive/storage/multiprocessfunc.py:np_sin,np_sin,function,2,2,2,19,9.5,0,0,['value'],[None],[None],291,[],['np.sin'],1
utilmy/zarchive/storage/multiprocessfunc.py:ne_sin,ne_sin,function,2,2,2,27,13.5,0,0,['x'],[None],[None],294,[],['ne.evaluate'],1
utilmy/zarchive/storage/multiprocessfunc.py:res_shared2,res_shared2,function,4,16,14,94,5.88,0,0,[],[],[],297,[],['float'],1
utilmy/zarchive/storage/multiprocessfunc.py:list_append,list_append,function,3,4,4,54,13.5,1,0,"['count', 'id', 'out_list']","[None, None, None]","[None, None, None]",261,"['\t""""""Creates an empty list and then appends a random number to the list \'count\' number of times. A CPU-heavy operation!""""""\n']",['range'],1
utilmy/zarchive/storage/panda_util.py:excel_topandas,excel_topandas,function,14,26,26,215,8.27,1,0,"['filein', 'fileout']","[None, None]","[None, None]",72,[],"['pd.ExcelFile', 'xls_file.parse', 'df.to_hdf', 'pd.HDFStore']",4
utilmy/zarchive/storage/panda_util.py:panda_toexcel,panda_toexcel,function,0,0,0,0,0.0,0,0,[],[],[],84,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:panda_todabatase,panda_todabatase,function,0,0,0,0,0.0,0,0,[],[],[],88,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:database_topanda,database_topanda,function,0,0,0,0,0.0,0,0,[],[],[],92,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:sqlquery_topanda,sqlquery_topanda,function,0,0,0,0,0.0,0,0,[],[],[],96,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:folder_topanda,folder_topanda,function,0,0,0,0,0.0,0,0,[],[],[],100,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:panda_tofolder,panda_tofolder,function,0,0,0,0,0.0,0,0,[],[],[],104,"[""'''\n"", '\n', '\n', '\n', '\n', 'from scipy.interpolate import interp1d\n', '\n', ""f2 = interp1d(qq['Datetime'], qq['Open'],bounds_error=False)\n"", 'open =    np.column_stack((open, f2(dater)))\n', '\n', 'f2(qq.Datetime)\n', '\n', '\n', ""open = qq[['Datetime','Close']]  #new dataframe\n"", '\n', ""open = open.join(pd.DataFrame(data={'Close1':qq['Close']}), how='outer', rsuffix='_1')\n"", '\n', '\n', '\n', '\n', ""f2= pd.DataFrame( qq['Close'], index=qq['Datetime'])\n"", '\n', 'pd.concat([df1,df2,df3])\n', '\n', ""qq['Datetime','Close']\n"", '\n', '\n', '\n', '\n', '#------Generate Sequence of date-------------------\n', '# Every 5 hours 10 minutes\n', '\n', 'dater= dater.values\n', ""dater= pd.date_range(start='12/24/2015', end='1/1/2016',   freq='0h05min').values\n"", ""Indexing DatetimeIndex objects. (To get all data from December 2012 through the end of May 2013 data you could do df.ix['December 2012':May 2013'])\n"", '\n', '\n', '\n', 'qq.ix[dater]\n', '\n', '\n', '\n', 'df.ix[datetime.date(year=2014,month=1,day=1):datetime.date(year=2014,month=2,day=1)]\n', '\n', '\n', '#  Get values where Index is not in  \n', ""rpt[~rpt['STK_ID'].isin(stk_list)]\n"", '\n', ""qq['Close'].where( qq['Datetime']= dater)\n"", '\n', '\n', ""qq['Datetime' = dater]\n"", ""qq.resample('5min')\n"", '\n', '\n', '\n', '\n', '\n', '# evenly spaced times\n', 't1 = np.array([0,0.5,1.0,1.5,2.0])\n', 'y1 = t1\n', '\n', '# unevenly spaced times\n', 't2 = np.array([0,0.34,1.01,1.4,1.6,1.7,2.01])\n', 'y2 = 3*t2\n', '\n', ""df1 = pd.DataFrame(data={'y1':y1,'t':t1})\n"", ""df2 = pd.DataFrame(data={'y2':y2,'t':t2})\n"", '\n', 'f2 = interp1d(t2,y2,bounds_error=False)\n', ""df1['y2'] = f2(df1.t)\n"", '\n', ""'''\n""]",[],0
utilmy/zarchive/storage/panda_util.py:numpy_topanda,numpy_topanda,function,2,6,6,65,10.83,0,0,"['vv', 'fileout', 'colname']","[None, None, None]","[None, '""""', '""data""']",354,[],"['pd.DataFrame', 'pd.HDFStore', 'st.append']",3
utilmy/zarchive/storage/panda_util.py:panda_tonumpy,panda_tonumpy,function,6,10,10,92,9.2,0,0,"['filename', 'nsize', 'tablen']","[None, None, None]","[None, None, ""'data'""]",357,[],['pd.read_hdf'],1
utilmy/zarchive/storage/panda_util.py:df_topanda,df_topanda,function,2,5,5,68,13.6,0,0,"[""vv, filenameh5, colname='data')""]",[''],"['\'data\'):  # \'E:\\_data\\_data_outlier.h5\'filenameh5); pdf= pd.DataFrame(vv); store.append(colname, pdf); store.close()filenameh5, colname=""data""):  # \'E:\\_data\\_data_outlier.h5\'fileoutlier,colname); return pdf.values   #to numpy vectorfilein1, filename, tablen=\'data\', lineterminator="",""): #Big CSV in Datachunksize =     10 * 10 ** 6filein1, chunksize=chunksize, lineterminator=lineterminator)for chunk in list01:']",361,[],"['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zarchive/storage/panda_util.py:load_frompanda,load_frompanda,function,2,5,5,68,13.6,0,0,"['filenameh5, colname=""data"")']",[''],"['""data""):  # \'E:\\_data\\_data_outlier.h5\'fileoutlier,colname); return pdf.values   #to numpy vectorfilein1, filename, tablen=\'data\', lineterminator="",""): #Big CSV in Datachunksize =     10 * 10 ** 6filein1, chunksize=chunksize, lineterminator=lineterminator)for chunk in list01:']",364,[],"['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zarchive/storage/panda_util.py:csv_topanda,csv_topanda,function,2,5,5,68,13.6,0,0,"['filein1, filename, tablen=\'data\', lineterminator="","")']",[''],"['\'data\', lineterminator="",""): #Big CSV in Datachunksize =     10 * 10 ** 6filein1, chunksize=chunksize, lineterminator=lineterminator)for chunk in list01:']",368,[],"['pd.HDFStore', 'store.append', 'store.close']",3
utilmy/zarchive/storage/panda_util.py:getrandom_tonumpy,getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample', 'tablen']","[None, None, None, None]","[None, None, None, ""'data'""]",377,[],['pd.read_hdf'],1
utilmy/zarchive/storage/panda_util.py:numexpr_topanda,numexpr_topanda,function,10,28,22,248,8.86,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",385,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/panda_util.py:excel_topanda,excel_topanda,function,14,26,26,215,8.27,1,0,"['filein', 'fileout']","[None, None]","[None, None]",397,"[""'''\n"", '\n', "">>> %timeit df3.reset_index().drop_duplicates(subset='index', keep='first').set_index('index')\n"", '1000 loops, best of 3: 1.54 ms per loop\n', '\n', '>>> %timeit df3.groupby(df3.index).first()\n', '1000 loops, best of 3: 580 s per loop\n', '\n', ""'''\n""]","['pd.ExcelFile', 'xls_file.parse', 'df.to_hdf', 'pd.HDFStore']",4
utilmy/zarchive/storage/panda_util.py:array_toexcel,array_toexcel,function,4,8,8,148,18.5,0,0,"['vv', 'wk', 'r1)subset', 'take_last=True)level=0))a)']","[None, None, None, '']","[None, None, ""'rownum'"", 'True)level=0))a):']",402,"[""'''\n"", '\n', "">>> %timeit df3.reset_index().drop_duplicates(subset='index', keep='first').set_index('index')\n"", '1000 loops, best of 3: 1.54 ms per loop\n', '\n', '>>> %timeit df3.groupby(df3.index).first()\n', '1000 loops, best of 3: 580 s per loop\n', '\n', ""'''\n""]","['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/storage/panda_util.py:unique_rows,unique_rows,function,4,8,8,148,18.5,0,0,['a'],[None],[None],432,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/storage/panda_util.py:remove_zeros,remove_zeros,function,0,0,0,0,0.0,0,0,[],[],[],436,[],[],0
utilmy/zarchive/storage/panda_util.py:sort_array,sort_array,function,0,0,0,0,0.0,0,0,[],[],[],438,[],[],0
utilmy/zarchive/storage/portfolio.py:data_jpsector,data_jpsector,function,3,4,4,47,11.75,0,0,[],[],[],49,[],['util.load_obj'],1
utilmy/zarchive/storage/portfolio.py:date_earningquater,date_earningquater,function,9,103,42,604,5.86,0,5,['t1'],[None],[None],62,[],['datetime.datetime'],1
utilmy/zarchive/storage/portfolio.py:date_is_3rdfriday,date_is_3rdfriday,function,4,14,13,67,4.79,0,0,['s'],[None],[None],81,[],"['datetime.strptime', 'd.weekday']",2
utilmy/zarchive/storage/portfolio.py:date_option_expiry,date_option_expiry,function,10,52,33,360,6.92,0,2,['date'],[None],[None],86,[],['datetime.datetime'],1
utilmy/zarchive/storage/portfolio.py:date_find_kday_fromintradaydate,date_find_kday_fromintradaydate,function,2,3,3,68,22.67,0,0,"['kintraday', 'intradaydate', 'dailydate']","[None, None, None]","[None, None, None]",103,[],['util.np_find'],1
utilmy/zarchive/storage/portfolio.py:date_find_kintraday_fromdate,date_find_kintraday_fromdate,function,4,10,10,88,8.8,0,0,"['d1', 'intradaydate1', 'h1', 'm1']","[None, None, None, None]","[None, None, '9', '30']",107,[],"['datetime.datetime', 'util.np_find']",2
utilmy/zarchive/storage/portfolio.py:date_find_intradateid,date_find_intradateid,function,8,13,13,101,7.77,1,0,"['datetimelist', 'stringdate']","[None, None]","[None, ""['20160420223000']""]",114,[],"['util.datestring_todatetime', 'util.np_find', 'str']",3
utilmy/zarchive/storage/portfolio.py:datetime_convertzone1_tozone2,datetime_convertzone1_tozone2,function,16,29,25,343,11.83,1,1,"['tt', 'fromzone', 'tozone']","[None, None, None]","[None, ""'Japan'"", ""'US/Eastern'""]",125,[],"['pytz.timezone', 'type', 'tz.localize', 't2.append']",4
utilmy/zarchive/storage/portfolio.py:date_extract_dailyopenclosetime,date_extract_dailyopenclosetime,function,23,51,35,431,8.45,2,3,"['spdateref1', 'market']","[None, None]","[None, ""'us'""]",143,[],"['enumerate', 'spdailyopendate.append', 'np.array', 'spdailyclosedate.append']",4
utilmy/zarchive/storage/portfolio.py:datetime_tostring,datetime_tostring,function,8,26,21,244,9.38,1,2,['datelist1'],[None],[None],161,[],"['isinstance', 'datelist1.strftime', 'pd.to_datetime', 't.strftime', 'date2.append']",5
utilmy/zarchive/storage/portfolio.py:datestring_todatetime,datestring_todatetime,function,6,15,13,125,8.33,1,1,"['datelist1', 'format1']","[None, None]","[None, ' ""%Y%m%d""']",172,[],"['isinstance', 'parser.parse', 'date2.append']",3
utilmy/zarchive/storage/portfolio.py:datetime_todate,datetime_todate,function,6,20,18,160,8.0,1,1,['tt'],[None],[None],181,[],"['isinstance', 'datetime.date', 'date2.append']",3
utilmy/zarchive/storage/portfolio.py:datetime_toint,datetime_toint,function,12,37,28,424,11.46,2,2,['datelist1'],[None],[None],190,[],"['isinstance', 'int', 'date2.append', 'datetime_tointhour', 'yy2.append', 'np.array']",6
utilmy/zarchive/storage/portfolio.py:datetime_tointhour,datetime_tointhour,function,7,20,19,234,11.7,1,1,['datelist1'],[None],[None],198,[],"['isinstance', 'int', 'yy2.append', 'np.array']",4
utilmy/zarchive/storage/portfolio.py:dateint_tostring,dateint_tostring,function,7,15,14,183,12.2,1,1,"['datelist1', 'format1']","[None, None]","[None, ""'%b-%y'""]",206,[],"['isinstance', 'dateint_todatetime', 'date2.append', 'np.array']",4
utilmy/zarchive/storage/portfolio.py:dateint_todatetime,dateint_todatetime,function,6,14,12,126,9.0,1,1,['datelist1'],[None],[None],228,[],"['isint', 'parser.parse', 'date2.append']",3
utilmy/zarchive/storage/portfolio.py:datenumpy_todatetime,datenumpy_todatetime,function,9,48,26,381,7.94,0,3,"['tt', 'islocaltime']","[None, None]","[None, 'True']",237,[],['type'],1
utilmy/zarchive/storage/portfolio.py:datetime_tonumpypdate,datetime_tonumpypdate,function,2,2,2,22,11.0,0,0,"['t', 'islocaltime']","[None, None]","[None, 'True']",251,[],['np.datetime64'],1
utilmy/zarchive/storage/portfolio.py:date_diffindays,date_diffindays,function,4,5,5,74,14.8,0,0,"['intdate1', 'intdate2']","[None, None]","[None, None]",257,[],['dateint_todatetime'],1
utilmy/zarchive/storage/portfolio.py:date_finddateid,date_finddateid,function,5,75,20,492,6.56,0,10,"['date1', 'dateref']","[None, None]","[None, None]",262,[],['util.np_findfirst'],1
utilmy/zarchive/storage/portfolio.py:datestring_toint,datestring_toint,function,6,16,14,106,6.62,1,1,['datelist1'],[None],[None],276,[],"['isinstance', 'int', 'date2.append']",3
utilmy/zarchive/storage/portfolio.py:date_as_float,date_as_float,function,12,32,26,311,9.72,0,2,['dt'],[None],[None],283,[],"['isint', 'dateint_todatetime', 'datetime.datetime', 'isleap', 'timedelta']",5
utilmy/zarchive/storage/portfolio.py:datediff_inyear,datediff_inyear,function,2,3,3,53,17.67,0,0,"['startdate', 'enddate']","[None, None]","[None, None]",296,[],['date_as_float'],1
utilmy/zarchive/storage/portfolio.py:date_generatedatetime,date_generatedatetime,function,18,27,27,267,9.89,0,1,"['start', 'nbday', 'end']","[None, None, None]","['""20100101""', '10', '""""']",300,[],"['datestring_todatetime', 'date_add_bdays', 'datetime.timedelta', 'list', 'np.array']",5
utilmy/zarchive/storage/portfolio.py:date_add_bdays,date_add_bdays,function,12,37,30,369,9.97,1,2,"['from_date', 'add_days']","[None, None]","[None, None]",311,[],"['type', 'dateint_todatetime', 'datestring_todatetime', 'datetime.timedelta', 'current_date.weekday']",5
utilmy/zarchive/storage/portfolio.py:date_getspecificdate,date_getspecificdate,function,21,203,58,1312,6.46,8,19,"['datelist', 'datetype1', 'outputype1', 'includelastdate', 'includefirstdate', '']","[None, None, None, None, None, None]","[None, '""yearend""', '""intdate""', 'True', 'False', None]",325,[],"['isint', 'dateint_todatetime', 'enumerate', 'vec2.append', 'np.mod', 'np.array']",6
utilmy/zarchive/storage/portfolio.py:date_alignfromdateref,date_alignfromdateref,function,9,18,14,152,8.44,0,0,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",386,[],['np.float'],1
utilmy/zarchive/storage/portfolio.py:_date_align,_date_align,function,15,35,27,203,5.8,2,2,"['dateref', 'datei', 'tmax', 'closei']","[None, None, None, None]","[None, None, None, None]",411,[],"['np.zeros', 'range', 'len']",3
utilmy/zarchive/storage/portfolio.py:date_align,date_align,function,9,18,14,152,8.44,0,0,"['array1', 'dateref)', 'dataarray1)dateref)( masset', 'tmax)', 'dtype', 'masset)']","[None, '  #2 column array time', None, None, None, '']","[None, None, None, None, '""float32"")1', None]",429,"["" ''' #Aligne the price with the same dates\n"", "" date\tyear\tmonth\tday\td\topen\tclose\thigh\tlow\tvolume\taclose '''\n""]",['np.float'],1
utilmy/zarchive/storage/portfolio.py:min_withposition,min_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],478,[],['min'],1
utilmy/zarchive/storage/portfolio.py:max_withposition,max_withposition,function,4,7,5,95,13.57,0,0,['values'],[None],[None],482,[],['max'],1
utilmy/zarchive/storage/portfolio.py:_reshape,_reshape,function,2,14,12,68,4.86,0,1,['x'],[None],[None],488,[],"['len', 'np.reshape', 'np.size']",3
utilmy/zarchive/storage/portfolio.py:_notnone,_notnone,function,39,213,113,1775,8.33,1,11,"['x)', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5)', 'label', ""'Time'"", ""'Y')"", 'legendloc', 'dpi', 'isband=1) ']","['  return not x is Noneasset', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '']","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None, ""('title'"", None, None, '""upper left""', '150', '1) :']",492,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend']",23
utilmy/zarchive/storage/portfolio.py:plot_price,plot_price,function,86,347,207,3422,9.86,3,15,"['asset', 'y2', 'y3', 'y4', 'y5', 'sym', 'savename1', 'tickperday', 'date1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None, None, None]","[None, 'None', 'None', 'None', 'None', 'None', ""''"", '20', 'None', '(10', None]",496,[],"['_reshape', '_notnone', 'np.concatenate', 'np.shape', 'np.arange', 'np.zeros', 'ta_lowbandtrend1', 'ta_highbandtrend1', 'plt.figure', 'plt.plot', 'plt.grid', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'int', 'plt.xticks', 'len', 'plt.savefig', 'plt.show', 'range', 'min', 'fig.savefig', 'plt.legend', 'plot_priceintraday', 'np.loadtxt', 'np.unique', 'xdays.append', 'np.hstack', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plot_pricedate', 'type', 'datestring_todatetime', 'np.row_stack', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'ax.savefig']",43
utilmy/zarchive/storage/portfolio.py:plot_priceintraday,plot_priceintraday,function,32,59,57,947,16.05,1,0,['data'],[None],[None],575,[],"['np.loadtxt', 'np.unique', 'np.arange', 'xdays.append', 'np.hstack', 'plt.figure', 'fig.add_axes', 'ax.tick_params', 'ax.set_xticks', 'ax.set_xticklabels', 'ax.set_ylabel', 'ax.set_ylim', 'candlestick', 'plt.show']",14
utilmy/zarchive/storage/portfolio.py:plot_pricedate,plot_pricedate,function,19,63,51,550,8.73,1,4,"['date1', 'sym1', 'asset1', 'sym2', 'bsk1', 'verticaldate', 'savename1', 'graphsize', '5']","[None, None, None, None, None, None, None, None, None]","[None, None, None, 'None', 'None', 'None', ""''"", '(10', None]",618,[],"['type', 'datestring_todatetime', 'np.row_stack', 'np.concatenate', 'array_todataframe', 'df_asset.plot', 'ax.axvline', 'len', 'np.arange', 'int', 'ax.savefig']",11
utilmy/zarchive/storage/portfolio.py:generate_sepvertical,generate_sepvertical,function,9,13,12,159,12.23,0,1,"['asset1', 'tt', 'tmax', 'start', 'datebar']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",701,[],"['np.zeros', 'util.datestring_todatetime']",2
utilmy/zarchive/storage/portfolio.py:save_asset_tofile,save_asset_tofile,function,31,129,87,978,7.58,5,9,"['file1', 'asset1', 'asset2', 'asset3', 'date1', 'title1']","[None, None, None, None, None, None]","[None, None, 'None', 'None', 'None', 'None']",716,[],"['np.shape', 'len', 'np.reshape', 'print', 'np.zeros', 'range', 'int', 'np.row_stack', 'np.savetxt']",9
utilmy/zarchive/storage/portfolio.py:load_asset_fromfile,load_asset_fromfile,function,1,4,4,51,12.75,0,0,['file1'],[None],[None],755,[],[],0
utilmy/zarchive/storage/portfolio.py:array_todataframe,array_todataframe,function,11,41,27,259,6.32,0,2,"['price', 'symbols', 'date1']","[None, None, None]","[None, 'None', 'None']",759,[],"['np.shape', 'len', 'pd.DataFrame']",3
utilmy/zarchive/storage/portfolio.py:dataframe_toarray,dataframe_toarray,function,9,10,10,107,10.7,0,0,['df'],[None],[None],770,[],[],0
utilmy/zarchive/storage/portfolio.py:isfloat,isfloat,function,3,17,13,80,4.71,0,1,['value'],[None],[None],779,[],['float'],1
utilmy/zarchive/storage/portfolio.py:isint,isint,function,29,98,56,994,10.14,0,8,"['x)', '( int', 'long', 'np.int', 'np.int64', 'np.int32 ) )matx', 'type1', 'type2=""correl"") ']","[' return isinstance(x', None, None, None, None, None, None, '']","[None, None, None, None, None, None, '""robust""', '""correl"") :']",787,[],"['matx.copy', 'x.mean', 'x.std', 'np.corrcoef', 'correl_inv.copy', 'np.sqrt']",6
utilmy/zarchive/storage/portfolio.py:correlation_mat,correlation_mat,function,29,98,56,994,10.14,0,8,"['matx', 'type1', 'type2']","[None, None, None]","[None, '""robust""', '""correl""']",794,[],"['matx.copy', 'x.mean', 'x.std', 'np.corrcoef', 'correl_inv.copy', 'np.sqrt']",6
utilmy/zarchive/storage/portfolio.py:correl_reducebytrigger,correl_reducebytrigger,function,9,22,18,128,5.82,2,1,"['correl2', 'trigger']","[None, None]","[None, None]",839,"[""  ''' Put Zero below trigger  '''\n""]","['correl2.copy', 'range', 'abs']",3
utilmy/zarchive/storage/portfolio.py:sk_cov_fromcorrel,sk_cov_fromcorrel,function,8,14,13,118,8.43,0,0,"['correl', 'ret_close1']","[None, None]","[None, None]",851,[],"['pf.volhisto_fromret', 'np.diag', 'np.dot']",3
utilmy/zarchive/storage/portfolio.py:cointegration,cointegration,function,18,47,37,385,8.19,0,0,"['x', 'y']","[None, None]","[None, None]",857,"['  """""" Output :\n', '    coint_t :t-statistic of unit-root test on residuals\n', ""    pvalue :   MacKinnon's approximate p-value based on MacKinnon (1994)\n"", '    crit_value : Critical values for the test statistic at the 1 %, 5 %, and 10 %  Signifiance levels.\n', '\n', '    The Null hypothesis is that there is no cointegration, the alt hypothesis is that there is cointegrating relationship. \n', '    If the pvalue is small, below a critical size:  Reject Null Hypothesis -->  Cointegration\n', '           pvalue is high --> No Cointegration    \n', '    \n', '    Significance level, also denoted as alpha or , is the probability of rejecting  the null hypothesis when it is true.\n', '    Probability of incorrectly rejecting a true null hypothesis\n', '\n', '    P=0.05  , At least 23% (and typically close to 50%)\n', '    P=0.01  , At least 7% (and typically close to 15%\n', '\n', '    (-2.9607012342275936,\n', '    0.038730981052330332, 0,\n', '    249,\n', ""    {'1%': -3.4568881317725864,\n"", ""       '10%': -2.5729936189738876,\n"", ""     '5%': -2.8732185133016057},\n"", '      601.96849256295991)\n', '        It can be seen that the calculated test statistic of -2.96 is smaller than the 5% critical value of -2.87, \n', ""        which means that we can reject the null hypothesis that  there isn't a cointegrating relationship at the 5% level.\n"", '  """"""\n']",['np.zeros'],1
utilmy/zarchive/storage/portfolio.py:causality_y1_y2,causality_y1_y2,function,10,14,13,153,10.93,0,0,"['price2', 'price1', 'maxlag']","[None, None, None]","[None, None, None]",895,[],[],0
utilmy/zarchive/storage/portfolio.py:rolling_cointegration,rolling_cointegration,function,13,29,26,280,9.66,0,0,"['x', 'y']","[None, None]","[None, None]",905,[],"['rolling_coint', 'pd.expanding_apply']",2
utilmy/zarchive/storage/portfolio.py:regression,regression,function,117,328,220,3116,9.5,6,7,"['yreturn', 'xreturn', 'type1']","[None, None, None]","[None, None, '""elasticv""']",924,"["" '''Y = X* reg.coef_  +  reg.intercept_, r2 '''\n""]","['len', 'yreturn.ravel', 'xreturn.reshape', 'reg.fit', 'F', 'reg.score', 'regression_fixedsymbolstock', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max', 'regression_getpricefromww', 'np.copy', 'np.zeros', 'regression_allstocks_vs_riskfactors', 'np.shape', 'print', 'np.arange', 'np.empty', 'enumerate', 'pf.getlogret_fromquotes', 'pf.regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",27
utilmy/zarchive/storage/portfolio.py:regression_fixedsymbolstock,regression_fixedsymbolstock,function,30,61,55,597,9.79,1,1,"['sym', 'ret_close2', 'tsstart', 'tsample', 'ret_spy', 'spyclose', 'regonly']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, 'True']",961,"["" ''' Price, Weight, R2, Error  '''\n""]","['len', 'range', 'np.reshape', 'np.column_stack', 'regression', 'getpriceret_fromregression', 'np.max']",7
utilmy/zarchive/storage/portfolio.py:regression_getpricefromww,regression_getpricefromww,function,20,38,30,298,7.84,3,0,"['spyclose', 'ww01', 'regasset01', 'ret_close2', 'tstart', 'tlag']","[None, None, None, None, None, None]","[None, None, None, None, None, '1']",984,[],"['np.copy', 'np.zeros', 'range', 'len']",4
utilmy/zarchive/storage/portfolio.py:regression_allstocks_vs_riskfactors,regression_allstocks_vs_riskfactors,function,65,137,113,1360,9.93,2,1,"['symstock', 'pricestock', 'symriskfac', 'priceriskfac', 'nlaglist']","[None, None, None, None, None]","[None, None, None, None, None]",1005,"["" '''Make Regression on all stocks ''' \n""]","['np.shape', 'print', 'np.arange', 'np.empty', 'len', 'enumerate', 'pf.getlogret_fromquotes', 'range', 'np.reshape', 'pf.regression_fixedsymbolstock', 'util.np_sortbycolumn', 'util.pd_array_todataframe', 'util.print_object']",13
utilmy/zarchive/storage/portfolio.py:getdiff_fromquotes,getdiff_fromquotes,function,4,6,6,73,12.17,0,0,"['close', 'timelag']","[None, None]","[None, None]",1102,[],['np.shape'],1
utilmy/zarchive/storage/portfolio.py:getret_fromquotes,getret_fromquotes,function,7,23,17,159,6.91,0,1,"['close', 'timelag']","[None, None]","[None, '1']",1106,[],"['np.shape', 'len']",2
utilmy/zarchive/storage/portfolio.py:getlogret_fromquotes,getlogret_fromquotes,function,4,7,7,81,11.57,0,0,"['close', 'timelag']","[None, None]","[None, '1']",1117,[],"['np.shape', 'np.log']",2
utilmy/zarchive/storage/portfolio.py:getprice_fromret,getprice_fromret,function,12,23,21,190,8.26,2,0,"['ret', 'normprice']","[None, None]","[None, '100']",1122,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/storage/portfolio.py:price_normalize100,price_normalize100,function,16,43,36,292,6.79,1,1,"['ret', 'normprice']","[None, None]","[None, '100']",1134,[],"['np.shape', 'len', 'np.reshape', 'np.zeros', 'range', 'np.cumprod']",6
utilmy/zarchive/storage/portfolio.py:price_normalize_1d,price_normalize_1d,function,8,22,19,147,6.68,0,0,"['ret', 'normprice', 'dtype1']","[None, None, None]","[None, '100', ' np.float16']",1154,[],"['np.empty', 'np.cumprod']",2
utilmy/zarchive/storage/portfolio.py:norm_fast,norm_fast,function,7,8,8,85,10.62,0,0,"['y', 'ny']","[None, None]","[None, None]",1163,[],['ne.evaluate'],1
utilmy/zarchive/storage/portfolio.py:correl_fast,correl_fast,function,8,13,13,116,8.92,0,0,"['xn', 'y', 'nx']","[None, None, None]","[None, None, None]",1171,[],['ne.evaluate'],1
utilmy/zarchive/storage/portfolio.py:volhisto_fromret,volhisto_fromret,function,2,16,12,174,10.88,0,1,"['retbsk', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1179,[],"['len', 'np.std']",2
utilmy/zarchive/storage/portfolio.py:volhisto_fromprice,volhisto_fromprice,function,6,27,18,251,9.3,0,1,"['price', 't', 'volrange', 'axis']","[None, None, None, None]","[None, None, None, '0']",1186,[],"['len', 'np.shape', 'np.std']",3
utilmy/zarchive/storage/portfolio.py:rsk_calc_all_TA,rsk_calc_all_TA,function,11,76,33,593,7.8,0,0,['df'],[None],"[""'panda_dataframe'""]",1198,"[""  '''Add All TA RMI, RSI To the '''\n""]",[],0
utilmy/zarchive/storage/portfolio.py:ta_lowbandtrend1,ta_lowbandtrend1,function,43,151,76,871,5.77,0,10,"['close2', 'type1']","[None, None]","[None, '0']",1238,"[""  '''Get lower band trend '''\n""]","['linearreg2', 'np.array', 'np.sum', 'util.np_findlocalmin2', 'len', 'util.sort', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",9
utilmy/zarchive/storage/portfolio.py:ta_highbandtrend1,ta_highbandtrend1,function,43,172,76,939,5.46,0,11,"['close2', 'type1']","[None, None]","[None, '0']",1280,[],"['linearreg', 'np.array', 'np.sum', 'util.np_findlocalmax2', 'len', 'util.sort', 'util.np_find_minpos', 'util.np_find_maxpos', 'np.abs']",9
utilmy/zarchive/storage/portfolio.py:pd_transform_asset,pd_transform_asset,function,11,35,27,409,11.69,0,1,"['q0', 'q1', 'type1']","[None, None, None]","[None, None, '""spread""']",1329,[],"['util.pd_date_intersection', 'util.pd_array_todataframe', 'util.pd_insertcol']",3
utilmy/zarchive/storage/portfolio.py:calcbasket_table,calcbasket_table,function,25,59,53,477,8.08,1,2,"['wwvec', 'ret', 'type1', 'wwtype', 'rebfreq', 'costbps']","[None, None, None, None, None, None]","[None, None, '""table""', '""constant""', '1', ' 0.000']",1343,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.mod', 'np.sum']",6
utilmy/zarchive/storage/portfolio.py:folio_lowcorrelation,folio_lowcorrelation,function,145,431,300,3927,9.11,8,7,"['sym01', 'nstock', 'periodlist', 'dateref', 'close1', 'kbenchmark', 'badlist', 'costbppa', 'showgraph']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, '0.02', 'True']",1370,[],"['ww_selection', 'np.corrcoef', 'np.nan_to_num', 'np.zeros', 'range', 'util.np_sortbycol', 'int', 'np.std', 'np.isnan', 'util.find', 'np.sum', 'stk_select.append', 'pf.volhisto_fromret', 'sum', '1/len', 'pf.getret_fromquotes', 'len', 'np.empty', 'np.ones', 'enumerate', 'pf.calcbasket_table', 'pf.price_normalize100', 'np.column_stack', 'np.zeros_like', 'np.array', 'np.concatenate', 'print', 'str', 'pf.plot_price', 'sym01[int', 'pf.volhisto_fromprice', 'xrange', 'folio_inverseetf']",33
utilmy/zarchive/storage/portfolio.py:folio_inverseetf,folio_inverseetf,function,8,18,18,151,8.39,1,0,"['price', 'costpa']","[None, None]","[None, '0.0']",1510,[],"['np.zeros', 'xrange', 'len']",3
utilmy/zarchive/storage/portfolio.py:folio_voltarget,folio_voltarget,function,2,6,6,61,10.17,0,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1519,[],['folio_volta'],1
utilmy/zarchive/storage/portfolio.py:folio_volta,folio_volta,function,17,46,37,443,9.63,2,0,"['bsk', 'targetvol', 'volrange', 'expocap']","[None, None, None, None]","[None, '0.11', ' 90', '1.5']",1523,[],"['folio_volta', 'np.shape', 'np.zeros', 'range', 'np.std', 'min']",6
utilmy/zarchive/storage/portfolio.py:folio_fixedweightprice,folio_fixedweightprice,function,13,36,33,225,6.25,2,0,"['price', 'fixedww', 'costpa']","[None, None, None]","[None, None, '0.0']",1538,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/storage/portfolio.py:folio_fixedweightret,folio_fixedweightret,function,13,31,28,193,6.23,2,0,"['ret', 'fixedww']","[None, None]","[None, None]",1550,[],"['np.shape', 'np.zeros', 'range']",3
utilmy/zarchive/storage/portfolio.py:folio_cost_turnover,folio_cost_turnover,function,17,38,32,278,7.32,1,1,"['wwall', 'bsk', 'dateref']","[None, None, None]","[None, None, None]",1563,[],"['len', 'xrange', 'np.sum']",3
utilmy/zarchive/storage/portfolio.py:folio_riskpa,folio_riskpa,function,21,55,47,437,7.95,2,1,"['ret', 'targetvol', 'volrange']","[None, None, None]","[None, '0.1', '90']",1577,[],"['np.shape', 'np.zeros', 'np.ones', 'range', 'np.sum', 'np.std', 'isfloat']",7
utilmy/zarchive/storage/portfolio.py:objective_criteria,objective_criteria,function,21,82,54,585,7.13,1,6,"['bsk', 'criteria', 'date1']","[None, None, None]","[None, None, 'None']",2009,[],"['np.sum', 'range', 'np.std', 'np.var']",4
utilmy/zarchive/storage/portfolio.py:calcbasket_obj,calcbasket_obj,function,31,76,62,510,6.71,2,3,"['wwvec', '*data']","[None, None]","[None, None]",2037,[],"['np.zeros', 'range', 'np.mod', 'weightcalc_generic', 'np.sum', 'objective_criteria']",6
utilmy/zarchive/storage/portfolio.py:calc_optimal_weight,calc_optimal_weight,function,1,6,6,40,6.67,0,0,"['args', 'bounds', 'maxiter']","[None, None, None]","[None, None, '1']",2062,[],[],0
utilmy/zarchive/storage/portfolio.py:fitness,fitness,function,6,12,12,75,6.25,0,0,['p'],[None],[None],2104,[],['10*cos'],1
utilmy/zarchive/storage/portfolio.py:np_countretsign,np_countretsign,function,6,18,18,80,4.44,1,1,['x'],[None],[None],2860,[],"['range', 'len', 'np.sign']",3
utilmy/zarchive/storage/portfolio.py:np_trendtest,np_trendtest,function,32,96,68,535,5.57,3,3,"['x', 'alpha ']","[None, None]","[None, ' 0.05']",2867,"['    """"""\n', '    This function is derived from code originally posted by Sat Kumar Tomer (satkumartomer@gmail.com)\n', '    See also: http://vsp.pnnl.gov/help/Vsample/Design_Trend_Mann_Kendall.htm\n', '    The purpose of the Mann-Kendall (MK) test (Mann 1945, Kendall 1975, Gilbert 1987) is to statistically assess if there is a monotonic upward or downward trend of the variable of interest over time. A monotonic upward (downward) trend means that the variable consistently increases (decreases) through time, but the trend may or may not be linear. The MK test can be used in place of a parametric linear regression analysis, which can be used to test if the slope of the estimated linear regression line is different from zero. The regression analysis requires that the residuals from the fitted regression line be normally distributed; an assumption not required by the MK test, that is, the MK test is a non-parametric (distribution-free) test.\n', '    Hirsch, Slack and Smith (1982, page 107) indicate that the MK test is best viewed as an exploratory analysis and is most appropriately used to identify stations where changes are significant or of large magnitude and to quantify these findings.\n', '    Input:\n', '        x:   a vector of data\n', '        alpha: significance level (0.05 default)\n', '    \n', '    Output:\n', '        trend: tells the trend (increasing, decreasing or no trend)\n', '        h: True (if trend is present) or False (if trend is absence)\n', '        p: p value of the significance test\n', '        z: normalized test statistics \n', '        \n', '    Examples x = np.random.rand(100) trend,h,p,z = mk_test(x,0.05) \n', '    """"""\n']","['len', 'range', 'np.sign', 'np.unique', 'np.zeros', 'sum', 'np.sum', 'abs', 'norm.ppf']",9
utilmy/zarchive/storage/portfolio.py:correl_rankbystock,correl_rankbystock,function,13,32,28,258,8.06,1,0,"['stkid', '5', '6]', 'correl', '0]', '[0', '1]]']","[None, None, None, None, None, None, None]","['[2', None, None, '[[1', None, None, None]",2922,"[' """""" Ranking of stocks by correlation """"""\n']","['np.zeros', 'enumerate', 'np.sum', 'util.sortcol']",4
utilmy/zarchive/storage/portfolio.py:calc_print_correlrank,calc_print_correlrank,function,25,164,88,1540,9.39,2,2,"['close2', 'symjp1', 'nlag', 'refindexname', 'toprank2', 'customnameid', 'customnameid2']","[None, None, None, None, None, None, None]","[None, None, None, None, '5', '[]', '[]']",2936,"["" ''' Most correlated/Un-correlated from One Risk Factor'''\n""]","['util.np_findfirst', 'pf.calc_ranktable', 'np.shape', 'print', 'util.np_find', 'enumerate', 'int', 'util.np_mergelist', 'pf.getret_fromquotes', 'pf.price_normalize100', 'pf.plot_price']",11
utilmy/zarchive/storage/portfolio.py:calc_ranktable,calc_ranktable,function,20,44,41,354,8.05,1,0,"['close2', 'symjp1', 'nlag', 'refindex', 'funeval', 'funargs']","[None, None, None, None, None, None]","[None, None, None, None, None, None]",2987,[],"['np.zeros', 'pf.getlogret_fromquotes', 'enumerate', 'funeval', 'util.np_sortbycolumn']",5
utilmy/zarchive/storage/portfolio.py:similarity_correl,similarity_correl,function,7,10,9,91,9.1,0,0,"['ret_close2', 'funargs']","[None, None]","[None, None]",3007,[],['pf.correlation_mat'],1
utilmy/zarchive/storage/portfolio.py:np_similarity,np_similarity,function,6,17,12,138,8.12,0,3,"['x', 'y', 'wwerr', 'type1']","[None, None, None, None]","[None, None, '[]', '0']",3062,[],['np_distance_l1'],1
utilmy/zarchive/storage/portfolio.py:np_distance_l1,np_distance_l1,function,2,6,6,37,6.17,0,0,"['x', 'y', 'wwerr']","[None, None, None]","[None, None, None]",3068,[],"['np.sum', 'np.abs']",2
utilmy/zarchive/storage/portfolio.py:imp_findticker,imp_findticker,function,10,16,14,113,7.06,1,0,"['tickerlist', 'sym01', 'symname']","[None, None, None]","[None, None, None]",3354,[],['v.append'],1
utilmy/zarchive/storage/portfolio.py:imp_close_dateref,imp_close_dateref,function,27,72,65,631,8.76,2,1,"['sym01', 'sdate', 'edate', 'datasource', 'typeprice']","[None, None, None, None, None]","[None, '20100101', '20160628', ""''"", '""close""']",3363,[],"['imp_yahooticker', 'start=str', 'str', 'util.listallfile', 'range', 'len', 'liststockname.append', 'pf.imp_txt_getquotes', 'enumerate', 'print', 'pf.date_align', 'util.a_cleanmemory']",12
utilmy/zarchive/storage/portfolio.py:imp_yahooticker,imp_yahooticker,function,23,45,42,485,10.78,1,1,"['symbols', 'start', 'end', 'type1']","[None, None, None, None]","[None, '""20150101""', '""20160101""', '1']",3391,[],"['datetime.datetime', 'int', 'enumerate', 'quotes_historical_yahoo_ochl', 'quotes.append', 'correctlist.append', 'errorlist.append', 'print']",8
utilmy/zarchive/storage/portfolio.py:imp_errorticker,imp_errorticker,function,11,29,27,291,10.03,1,0,"['symbols', 'start', 'end']","[None, None, None]","[None, '""20150101""', '""20160101""']",3414,[],"['datetime.datetime', 'int', 'quotes_historical_yahoo_ochl', 'errorlist.append', 'print']",5
utilmy/zarchive/storage/portfolio.py:imp_yahoo_financials_url,imp_yahoo_financials_url,function,7,32,23,276,8.62,0,2,"['ticker_symbol', 'statement', 'quarterly']","[None, None, None]","[None, '""is""', 'False']",3434,[],"['BeautifulSoup', 'sys.exit']",2
utilmy/zarchive/storage/portfolio.py:imp_yahoo_periodic_figure,imp_yahoo_periodic_figure,function,17,80,60,610,7.62,1,4,"['soup', 'yahoo_figure']","[None, None]","[None, None]",3442,[],"['re.compile', 'soup.find', 'sys.exit', 'row.find_all', 'int', 'values.append']",6
utilmy/zarchive/storage/portfolio.py:imp_googleIntradayQuoteSave,imp_googleIntradayQuoteSave,function,10,19,18,180,9.47,0,0,"['name1', 'date1', 'inter', 'tframe', 'dircsv']","[None, None, None, None, None]","[None, None, None, None, None]",3578,[],"['googleIntradayQuote', 'name1.replace', 'str', 'q.write_csv']",4
utilmy/zarchive/storage/portfolio.py:imp_googleQuoteSave,imp_googleQuoteSave,function,11,21,21,173,8.24,0,0,"['name1', 'date1', 'date2', 'dircsv']","[None, None, None, None]","[None, None, None, None]",3585,[],"['googleQuote', 'name1.replace', 'str', 'q.write_csv']",4
utilmy/zarchive/storage/portfolio.py:imp_googleQuoteList,imp_googleQuoteList,function,6,34,21,228,6.71,2,1,"['symbols', 'date1', 'date2', 'inter', 'tframe', 'dircsv', 'intraday1']","[None, None, None, None, None, None, None]","[None, None, None, '23400', '2000', ""''"", 'True']",3594,[],"['imp_googleIntradayQuoteSave', 'print', 'imp_googleQuoteSave']",3
utilmy/zarchive/storage/portfolio.py:pd_filterbydate,pd_filterbydate,function,6,35,21,318,9.09,0,3,"['df', 'dtref', ""start='2016-06-06 00"", ""end='2016-06-14 00"", 'freq', 'timezone']","[None, None, '', '', None, None]","[None, 'None', ""'2016-06-06 00:00:00'"", ""'2016-06-14 00:00:00'"", ""'0d0h05min'"", ""'Japan'""]",3609,"["" ''' df: DateSeries or TimeSeries of Quotes   '''\n""]","['type', 'pd.date_range']",2
utilmy/zarchive/storage/portfolio.py:imp_panda_db_dumpinfo,imp_panda_db_dumpinfo,function,15,32,28,274,8.56,1,0,"[""dbfile='E""]",[''],"[""'E:\\_data\\stock\\intraday_google.h5'""]",3624,[],"['pd.HDFStore', 'store.keys', 'pd.read_hdf', 'extract.append', 'errsym.append', 'np.array']",6
utilmy/zarchive/storage/portfolio.py:imp_numpyclose_frompandas,imp_numpyclose_frompandas,function,47,129,93,1105,8.57,2,6,"['dbfile', 'symlist', 't0', 't1', 'priceid', 'maxasset', 'tmax2']","[None, None, None, None, None, None, None]","[None, '[]', '20010101', '20010101', '""close""', '2500', '2000']",3639,[],"['print', 'np.zeros', 'pd.HDFStore', 'store.select', 'enumerate', 'len', 'util.find', 'qlist.append', 'sym.append', 'np.mod', 'date_align', 'np.shape', 'pf.date_align', 'xrange']",14
utilmy/zarchive/storage/portfolio.py:imp_quotes_fromtxt,imp_quotes_fromtxt,function,26,76,65,583,7.67,2,2,"['stocklist01', ""filedir='E"", 'startdate', 'endate']","[None, '', None, None]","[None, ""'E:/_data/stock/daily/20160610/jp'"", '20150101', '20160616']",3686,[],"['util.listallfile', 'len', 'x.split', 'util.np_findfirst', 'print', 'pd.read_csv', 'quotes.append']",7
utilmy/zarchive/storage/portfolio.py:imp_quotes_errordate,imp_quotes_errordate,function,8,25,17,222,8.88,2,1,"['quotes', 'dateref']","[None, None]","[None, None]",3716,"["" ''' Show Symbol in Error when importing '''\n""]","['enumerate', 'print', 'util.datetime_tostring', 'util.datetime_toint', 'str']",5
utilmy/zarchive/storage/portfolio.py:imp_getcsvname,imp_getcsvname,function,7,12,11,88,7.33,0,0,"['name1', 'date1', 'inter', 'tframe']","[None, None, None, None]","[None, None, None, None]",3728,[],['str'],1
utilmy/zarchive/storage/portfolio.py:imp_quote_tohdfs,imp_quote_tohdfs,function,20,55,44,510,9.27,1,1,"['sym', 'qqlist', 'filenameh5', 'fromzone', 'tozone']","[None, None, None, None, None]","[None, None, None, ""'Japan'"", ""'UTC'""]",3763,[],"['pd.HDFStore', 'enumerate', 'copy.deepcopy', 'datetime_toint', 'pf.imp_hdfs_getquote', 'type', 'store.append', 'pd.concat', 'qq.drop_duplicates', 'qq.sort', 'print', 'str', 'store.close']",13
utilmy/zarchive/storage/portfolio.py:date_todatetime,date_todatetime,function,1,9,9,58,6.44,0,0,['tlist'],[None],[None],3785,[],[],0
utilmy/zarchive/storage/portfolio.py:date_removetimezone,date_removetimezone,function,1,6,6,63,10.5,0,0,['datelist'],[None],[None],3791,[],[],0
utilmy/zarchive/storage/portfolio.py:imp_csvquote_topanda,imp_csvquote_topanda,function,13,41,35,508,12.39,0,1,"['file1', 'filenameh5', 'dfname', 'fromzone', 'tozone']","[None, None, None, None, None]","[None, None, ""'sym1'"", ""'Japan'"", ""'UTC'""]",3796,[],"['tz.gettz', 'pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",5
utilmy/zarchive/storage/portfolio.py:imp_panda_insertfoldercsv,imp_panda_insertfoldercsv,function,10,34,32,300,8.82,1,2,"['dircsv', ""filepd= r'E"", 'fromtimezone', 'tozone']","[None, '', None, None]","[None, "" r'E:\\_data\\stock\\intraday_google.h5'"", ""'Japan'"", ""'UTC'""]",3813,[],"['util.listallfile', 'util.str_isfloat', 'print', 'imp_csvquote_topanda']",4
utilmy/zarchive/storage/portfolio.py:imp_panda_checkquote,imp_panda_checkquote,function,4,8,8,70,8.75,1,0,['quotes'],[None],[None],3822,[],['np.shape'],1
utilmy/zarchive/storage/portfolio.py:imp_panda_getquote,imp_panda_getquote,function,2,7,6,59,8.43,0,0,"['filenameh5', 'dfname']","[None, None]","[None, '""data""']",3826,[],['pd.read_hdf'],1
utilmy/zarchive/storage/portfolio.py:imp_pd_merge_database,imp_pd_merge_database,function,12,27,22,321,11.89,1,0,"['filepdfrom', 'filepdto']","[None, None]","[None, None]",3831,[],"['pd.HDFStore', 'store0.keys', 'pf.imp_hdfs_getquote', 'store1.append', 'qq.drop_duplicates', 'qq.sort', 'print', 'store0.close', 'store1.close']",9
utilmy/zarchive/storage/portfolio.py:imp_panda_getListquote,imp_panda_getListquote,function,28,58,46,567,9.78,1,3,"['symbols', 'close1', ""start='12/18/2015 00"", ""end='3/1/2016 00"", 'freq', ""filepd= 'E"", 'tozone', 'fillna', 'interpo']","[None, None, '', '', None, '', None, None, None]","[None, ""'close'"", ""'12/18/2015 00:00:00+00:00'"", ""'3/1/2016 00:00:00+00:00'"", ""'0d0h10min'"", "" 'E:\\_data\\stock\\intraday_google.h5'"", ""'Japan'"", 'True', 'True']",3846,[],"['pd.date_range', 'imp_panda_getquote', 'type', 'errorsym.append', 'qq.fillna', 'qq.interpolate', 'quotes.append', 'correctsym.append', 'util.datenumpy_todatetime']",9
utilmy/zarchive/storage/portfolio.py:imp_panda_cleanquotes,imp_panda_cleanquotes,function,9,26,21,295,11.35,0,0,"['df', 'datefilter']","[None, None]","[None, None]",3891,[],"['df.sort', 'df.interpolate', 'close.fillna', 'np.array']",4
utilmy/zarchive/storage/portfolio.py:imp_panda_storecopy,imp_panda_storecopy,function,12,20,20,253,12.65,1,0,[],[],[],3901,[],"['pd.HDFStore', 'store.keys', 'pf.imp_hdfs_getquote', 'store2.append', 'store.close', 'store2.close']",6
utilmy/zarchive/storage/portfolio.py:imp_panda_removeDuplicate,imp_panda_removeDuplicate,function,11,26,20,269,10.35,1,0,"[""filepd=  'E""]",[''],"[""  'E:\\_data\\stock\\intraday_google.h5'""]",3920,[],"['pd.HDFStore', 'store.keys', 'store.select', 'qq.drop_duplicates', 'qq.sort', 'list', 'store.remove', 'store.append', 'store.close']",9
utilmy/zarchive/storage/portfolio.py:calc_statestock,calc_statestock,function,137,805,298,6715,8.34,22,14,"['close2', 'dateref', 'symfull']","[None, None, None]","[None, None, None]",3983,[],"['sort', 'util.sortcol', 'perf', 'and2', 'mar', 'np.mean', 'ma', 'dd', 'util.find', 'gap', 'pf.getret_fromquotes', 'len', 'np.shape', 'print', 'str', 'np.zeros', 'np.arange', '100*ma', 'pf.volhisto_fromprice', 'util.np_find_minpos', 'util.np_find_maxpos', 'range', 'int', 'pf.regression', 'pf.np_countretsign', 'util.np_findlocalmax2', 'util.np_findlocalmin2', 'util.sort', 'ta_highbandtrend1', 'ta_lowbandtrend1', 'pf.ta_highbandtrend1', 'pf.ta_lowbandtrend1', 'np.array']",33
utilmy/zarchive/storage/portfolio.py:imp_screening_addrecommend,imp_screening_addrecommend,function,19,48,40,412,8.58,1,3,"['string1', 'dbname']","[None, None]","[None, ""'stock_recommend'""]",4384,[],"['string1.replace', 'ss.replace', 'ss.split', 'copy.deepcopy', 'len', 'util.find', 'aux.append', 'util.load_obj', 'stock_recommend.append', 'util.save_obj']",10
utilmy/zarchive/storage/portfolio.py:imp_finviz,imp_finviz,function,53,369,159,4708,12.76,8,0,[],[],[],4411,[],"['requests.get', 'BeautifulSoup', 'soup.find_all', 'len', 'int', 'titlesarray.append', 'titlesarray.insert', 'while', 'str', 'page', 'secondsoup.find_all', 'alldata.append', 'open', 'csv.DictWriter', 'overview.writeheader', 'overview.writerow', 'imp_finviz_news', 'imp_finviz_financials', 'financial.writeheader', 'financial.writerow']",20
utilmy/zarchive/storage/portfolio.py:imp_finviz_news,imp_finviz_news,function,11,18,17,222,12.33,0,0,[],[],[],4468,[],"['requests.get', 'BeautifulSoup', 'soup.find_all']",3
utilmy/zarchive/storage/portfolio.py:imp_finviz_financials,imp_finviz_financials,function,47,187,139,2445,13.07,4,0,[],[],[],4479,[],"['requests.get', 'BeautifulSoup', 'soup.find_all', 'len', 'int', 'titlesarray.append', 'titlesarray.insert', 'while', 'str', 'page', 'secondsoup.find_all', 'alldata.append', 'open', 'csv.DictWriter', 'financial.writeheader', 'financial.writerow']",16
utilmy/zarchive/storage/portfolio.py:get_price2book,get_price2book,function,18,38,35,327,8.61,0,0,['symbol'],[None],[None],4539,[],"['bs', 'soup.find', 'pb.find_next', 'print']",4
utilmy/zarchive/storage/portfolio.py:index,index,class,145,447,285,3718,8.32,3,16,[],[],[],1605,[],[],0
utilmy/zarchive/storage/portfolio.py:searchSimilarity,searchSimilarity,class,178,505,335,4637,9.18,8,17,[],[],[],3072,[],[],0
utilmy/zarchive/storage/portfolio.py:Quote,Quote,class,33,73,53,1228,16.82,2,0,[],[],[],3479,[],[],0
utilmy/zarchive/storage/portfolio.py:googleIntradayQuote,googleIntradayQuote,class,23,51,42,757,14.84,1,2,[],[],[],3521,[],[],0
utilmy/zarchive/storage/portfolio.py:googleQuote,googleQuote,class,21,43,39,840,19.53,1,1,[],[],[],3556,[],[],0
utilmy/zarchive/storage/portfolio.py:index:__init__,index:__init__,method,11,12,12,121,10.08,0,0,"['self', 'id1', 'sym', 'ww', 'tstart']","[None, None, None, None, None]","[None, None, None, None, None]",1606,[],['util.date_generatedatetime'],1
utilmy/zarchive/storage/portfolio.py:index:close,index:close,method,0,1,1,4,4.0,0,0,[],[],[],1611,[],[],0
utilmy/zarchive/storage/portfolio.py:index:updatehisto,index:updatehisto,method,2,12,11,62,5.17,0,0,[')'],['  #Download Quotespass) :'],[None],1614,[],['print'],1
utilmy/zarchive/storage/portfolio.py:index:help,index:help,method,2,12,11,62,5.17,0,0,[],[],[],1618,[],['print'],1
utilmy/zarchive/storage/portfolio.py:index:_statecalc,index:_statecalc,method,31,148,79,1115,7.53,2,7,"['self)', 'bsk)']","[' #Calculate Risk State Vector at each time treturn s1self', '']","[None, None]",1672,[],"['np.sum', 'range', 'np.std', 'np.arange']",4
utilmy/zarchive/storage/portfolio.py:index:_objective_criteria,index:_objective_criteria,method,31,148,79,1115,7.53,2,7,"['self', 'bsk']","[None, None]","[None, None]",1685,[],"['np.sum', 'range', 'np.std', 'np.arange']",4
utilmy/zarchive/storage/portfolio.py:index:calcbasket_obj,index:calcbasket_obj,method,31,65,58,547,8.42,1,3,"['self', 'wwvec']","[None, None]","[None, None]",1730,[],"['np.zeros', 'xrange', 'np.mod', 'self._weightcalc_generic', 'np.sum', 'self._objective_criteria']",6
utilmy/zarchive/storage/portfolio.py:index:calc_optimal_weight,index:calc_optimal_weight,method,14,23,22,356,15.48,0,1,"['self', 'maxiter']","[None, None]","[None, '1']",1769,[],"['np.reshape', 'np.sum', 'print']",3
utilmy/zarchive/storage/portfolio.py:index:_weightcalc_generic,index:_weightcalc_generic,method,6,26,17,235,9.04,0,3,"['self', 'wwvec', 't']","[None, None, None]","[None, None, None]",1781,[],"['self._weightcalc_constant', 'self._weightcalc_regime', 'self._weightcalc_regime2', 'print']",4
utilmy/zarchive/storage/portfolio.py:index:_weightcalc_constant,index:_weightcalc_constant,method,3,4,4,28,7.0,0,0,"['self', 'ww2', 't']","[None, None, None]","[None, None, None]",1787,[],['np.sum'],1
utilmy/zarchive/storage/portfolio.py:index:_weightcalc_regime2,index:_weightcalc_regime2,method,2,2,2,14,7.0,0,0,"['self', 'wwvec', 't)']","[None, None, '  #Hyper-Parameters Optimizationnbrange']","[None, None, 'self.nbrange;   nbregime= self.nbregime; masset= self.massetif t < nbrange:']",1791,[],[],0
utilmy/zarchive/storage/portfolio.py:searchSimilarity:__init__,searchSimilarity:__init__,method,15,18,17,193,10.72,0,0,"['self', ""filejpstock=r'E"", 'sym01', 'symname', 'startdate', 'enddate', 'pricetype']","[None, '', None, None, None, None, None]","[None, ""r'E:/_data/stock/daily/20160616/jp'"", ""['7203']"", ""['Toyota']"", ' 20150101', '20160601', '""close""']",3073,[],[],0
utilmy/zarchive/storage/portfolio.py:searchSimilarity:load_quotes_fromdb,searchSimilarity:load_quotes_fromdb,method,15,35,33,361,10.31,0,1,"['self', 'picklefile']","[None, None]","[None, ""''""]",3078,[],"['util.load_obj', 'pf.imp_txt_getquotes', 'pf.date_align', 'util.a_cleanmemory']",4
utilmy/zarchive/storage/portfolio.py:searchSimilarity:__generate_return__,searchSimilarity:__generate_return__,method,4,4,4,67,16.75,0,0,"['self', 'nlag']","[None, None]","[None, None]",3089,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/portfolio.py:searchSimilarity:__overweight__,searchSimilarity:__overweight__,method,17,62,41,412,6.65,2,4,"['self', 'px']","[None, None]","[None, None]",3093,[],"['len', 'np.ones', 'util.np_findlocalmax', 'type', 'np.abs', 'wwerr[max', 'util.np_findlocalmin']",7
utilmy/zarchive/storage/portfolio.py:searchSimilarity:set_searchcriteria,searchSimilarity:set_searchcriteria,method,34,79,63,799,10.11,0,5,"['self', 'name1', 'date1', 'date2', 'nlag', 'searchperiodstart', 'typesearch', '']","[None, None, None, None, None, None, None, None]","[None, ""'7203'"", '20160301', '20160601', '1', '20120101', '""pattern2""', None]",3113,[],"['pf.getret_fromquotes', 'date_finddateid', 'max', 'util.np_findfirst', 'print', 'pf.price_normalize_1d', 'len', 'self.__overweight__']",8
utilmy/zarchive/storage/portfolio.py:searchSimilarity:launch_search,searchSimilarity:launch_search,method,53,108,82,916,8.48,3,3,['self'],[None],[None],3142,[],"['len', 'np.zeros', 'range', 'pf.price_normalize_1d', 'np_similarity', 'util.np_sortbycolumn', 'enumerate']",7
utilmy/zarchive/storage/portfolio.py:searchSimilarity:show_comparison_graph,searchSimilarity:show_comparison_graph,method,33,72,63,688,9.56,1,3,"['self', 'maxresult', 'show_only_different_time', 'fromid', 'fromend', 'filenameout']","[None, None, None, None, None, None]","[None, '20', 'True', '0', ' 0', ""''""]",3176,[],"['np.shape', 'range', 'int', 'print', 'pf.price_normalize_1d', 'str', 'pf.plot_price']",7
utilmy/zarchive/storage/portfolio.py:searchSimilarity:staticmethod,searchSimilarity:staticmethod,method,0,1,1,4,4.0,0,0,"['self', 'x']","[None, None]","[None, None]",3205,[],[],0
utilmy/zarchive/storage/portfolio.py:searchSimilarity:get_rankresult,searchSimilarity:get_rankresult,method,24,63,53,496,7.87,2,1,"['self', 'filetosave']","[None, None]","[None, ""''""]",3209,[],"['len', 'np.savetxt', 'np.shape', 'np.array', 'np.empty', 'range', 'int', 'str']",8
utilmy/zarchive/storage/portfolio.py:searchSimilarity:export_results,searchSimilarity:export_results,method,5,7,7,57,8.14,0,0,"['self', 'filename']","[None, None]","[None, None]",3231,[],"['open', 'self.to_csv', 'f.write']",3
utilmy/zarchive/storage/portfolio.py:Quote:__init__,Quote:__init__,method,3,9,9,120,13.33,0,0,['self'],[None],[None],3483,[],['range'],1
utilmy/zarchive/storage/portfolio.py:Quote:append,Quote:append,method,7,7,7,209,29.86,0,0,"['self', 'dt', 'open_', 'high', 'low', 'close', 'volume']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",3488,[],[],0
utilmy/zarchive/storage/portfolio.py:Quote:to_csv,Quote:to_csv,method,3,9,9,272,30.22,1,0,['self'],[None],[None],3497,[],['xrange'],1
utilmy/zarchive/storage/portfolio.py:Quote:write_csv,Quote:write_csv,method,5,7,7,57,8.14,0,0,"['self', 'filename']","[None, None]","[None, None]",3503,[],"['open', 'self.to_csv', 'f.write']",3
utilmy/zarchive/storage/portfolio.py:Quote:read_csv,Quote:read_csv,method,11,23,20,346,15.04,1,0,"['self', 'filename']","[None, None]","[None, None]",3508,[],"['range', 'open', 'line.rstrip', 'self.append']",4
utilmy/zarchive/storage/portfolio.py:Quote:__repr__,Quote:__repr__,method,2,2,2,19,9.5,0,0,['self'],[None],[None],3518,[],['self.to_csv'],1
utilmy/zarchive/storage/portfolio.py:googleIntradayQuote:__init__,googleIntradayQuote:__init__,method,22,49,40,699,14.27,1,2,"['self', 'symbol', 'interval_seconds', 'num_days']","[None, None, None, None]","[None, None, '300', '5']",3525,[],"['super', 'symbol.upper', 'requests.post', 'print', 'csv.splitlines', 'xrange', 'float', 'self.append']",8
utilmy/zarchive/storage/portfolio.py:googleQuote:__init__,googleQuote:__init__,method,20,41,37,760,18.54,1,1,"['self', 'symbol', 'start_date', 'end_date']","[None, None, None, None]","[None, None, None, 'datetime.date.today(']",3559,[],"['super', 'symbol.upper', 'datetime.date', 'start.strftime', 'urllib.urlopen', 'csv.reverse', 'print', 'xrange', 'isfloat', 'self.append']",10
utilmy/zarchive/storage/rec_data.py:_get_movielens_path,_get_movielens_path,function,2,3,3,79,26.33,0,0,[],[],[],14,"['    """"""\n', '    Get path to the movielens dataset file.\n', '    """"""\n']",[],0
utilmy/zarchive/storage/rec_data.py:_download_movielens,_download_movielens,function,9,18,18,207,11.5,1,0,['dest_path'],[None],[None],23,"['    """"""\n', '    Download the dataset.\n', '    """"""\n']","['requests.get', 'print', 'open', 'req.iter_content', 'fd.write']",5
utilmy/zarchive/storage/rec_data.py:_get_raw_movielens_data,_get_raw_movielens_data,function,8,13,13,233,17.92,0,1,[],[],[],38,"['    """"""\n', '    Return the raw lines of the train and test files.\n', '    """"""\n']","['_get_movielens_path', '_download_movielens', 'zipfile.ZipFile', 'datafile.read']",4
utilmy/zarchive/storage/rec_data.py:_parse,_parse,function,7,22,16,120,5.45,1,1,['data'],[None],[None],53,"['    """"""\n', '    Parse movielens dataset lines.\n', '    """"""\n']",['line.split'],1
utilmy/zarchive/storage/rec_data.py:_build_interaction_matrix,_build_interaction_matrix,function,12,19,19,130,6.84,1,1,"['rows', 'cols', 'data']","[None, None, None]","[None, None, None]",68,[],"['sp.lil_matrix', 'mat.tocoo']",2
utilmy/zarchive/storage/rec_data.py:_get_movie_raw_metadata,_get_movie_raw_metadata,function,8,12,12,190,15.83,0,1,[],[],[],80,"['    """"""\n', '    Get raw lines of the genre file.\n', '    """"""\n']","['_get_movielens_path', '_download_movielens', 'zipfile.ZipFile', 'datafile.read']",4
utilmy/zarchive/storage/rec_data.py:get_movielens_item_metadata,get_movielens_item_metadata,function,25,57,46,474,8.32,5,3,['use_item_ids'],[None],[None],94,"['    """"""\n', '    Build a matrix of genre features (no_items, no_features).\n', '\n', '    If use_item_ids is True, per-item feeatures will also be used.\n', '    """"""\n']","['set', '_get_movie_raw_metadata', 'line.split', 'int', 'zip', 'genres.append', 'genre_set.add', 'sp.lil_matrix', 'len', 'features.items']",10
utilmy/zarchive/storage/rec_data.py:get_dense_triplets,get_dense_triplets,function,7,8,8,139,17.38,0,0,"['uids', 'pids', 'nids', 'num_users', 'num_items']","[None, None, None, None, None]","[None, None, None, None, None]",136,[],['np.identity'],1
utilmy/zarchive/storage/rec_data.py:get_triplets,get_triplets,function,4,5,5,71,14.2,0,0,['mat'],[None],[None],144,[],['size=len'],1
utilmy/zarchive/storage/rec_data.py:get_movielens_data,get_movielens_data,function,18,30,27,335,11.17,1,0,[],[],[],149,"['    """"""\n', '    Return (train_interactions, test_interactions).\n', '    """"""\n']","['_get_raw_movielens_data', 'set', 'itertools.chain', '_parse', 'uids.add', 'iids.add', 'max', '_build_interaction_matrix']",8
utilmy/zarchive/storage/rec_metrics.py:predict,predict,function,3,5,4,131,26.2,0,0,"['model', 'uid', 'pids']","[None, None, None]","[None, None, None]",6,[],[],0
utilmy/zarchive/storage/rec_metrics.py:precision_at_k,precision_at_k,function,21,39,38,538,13.79,1,1,"['model', 'ground_truth', 'k', 'user_features', 'item_features']","[None, None, None, None, None]","[None, None, None, 'None', 'None']",14,"['    """"""\n', '    Measure precision at k for model and ground truth.\n', '\n', '    Arguments:\n', '    - lightFM instance model\n', '    - sparse matrix ground_truth (no_users, no_items)\n', '    - int k\n', '\n', '    Returns:\n', '    - float precision@k\n', '    """"""\n']","['ground_truth.tocsr', 'np.arange', 'enumerate', 'np.empty', 'uid_array.fill', 'model.predict', 'set', 'precisions.append', 'float', 'sum', 'len']",11
utilmy/zarchive/storage/rec_metrics.py:full_auc,full_auc,function,21,34,32,398,11.71,1,1,"['model', 'ground_truth']","[None, None]","[None, None]",52,"['    """"""\n', '    Measure AUC for model and ground truth on all items.\n', '\n', '    Returns:\n', '    - float AUC\n', '    """"""\n']","['ground_truth.tocsr', 'np.arange', 'enumerate', 'predict', 'np.zeros', 'len', 'scores.append', 'sum']",8
utilmy/zarchive/storage/sobol.py:convert_csv2hd5f,convert_csv2hd5f,function,10,21,19,181,8.62,1,0,"['filein1', 'filename']","[None, None]","[None, None]",64,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/storage/sobol.py:getrandom_tonumpy,getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample']","[None, None, None]","[None, None, None]",77,[],['pd.read_hdf'],1
utilmy/zarchive/storage/sobol.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",93,[],['ne.evaluate'],1
utilmy/zarchive/storage/sobol.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],101,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/storage/sobol.py:getdvector,getdvector,function,7,21,20,150,7.14,1,0,"['dimmax', 'istart', 'idimstart']","[None, None, None]","[None, None, None]",130,[],['range'],1
utilmy/zarchive/storage/sobol.py:pathScheme_std,pathScheme_std,function,3,3,3,28,9.33,0,0,"['T', 'n', 'zz)', 'n+1)']","[None, None, '   #Standard Path generationn+1);  sdt', '']","[None, None, ' np.sqrt(T/n);  ww[0]= 01', None]",140,[],[],0
utilmy/zarchive/storage/sobol.py:pathScheme_bb,pathScheme_bb,function,18,32,30,200,6.25,1,0,"['T', 'n', 'zz)', 'kkmax+1)']","[None, None, '  #Brownian Bridge generationn); # sdt', '']","[None, None, ' np.sqrt(T/n);np.round(np.log(n)  * 1.4426950408889634)) # n= 2^kmaxh= n; jmax=1T)1', None]",148,[],"['int', 'range', 'np.sqrt']",3
utilmy/zarchive/storage/sobol.py:pathScheme_,pathScheme_,function,3,3,3,28,9.33,0,0,"['T', 'n', 'zz)', 'n+1)']","[None, None, '   #Standard Path generationn+1);  sdt', '']","[None, None, ' np.sqrt(T/n);  ww[0]= 01', None]",167,"[""'''\n"", 'ttdim=1024  # dim= 2^k\n', '[[500, testdensity(500, ttdim, 400,-1)],\n', '[1000, testdensity(1000, ttdim, 400,-1)],\n', '[2000, testdensity(2000, ttdim, 400,-1)], \n', '[3000, testdensity(3000, ttdim, 400,-1)],\n', '[4000, testdensity(4000, ttdim, 400,-1)]]\n', ""'''\n""]",[],0
utilmy/zarchive/storage/sobol.py:testdensity,testdensity,function,27,59,56,415,7.03,3,0,"['nsample', 'totdim', 'bin01', 'Ti']","[None, None, None, None]","[None, None, None, '-1']",177,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'dx.dN', 'np.sum']",8
utilmy/zarchive/storage/sobol.py:plotdensity,plotdensity,function,29,65,63,531,8.17,1,0,"['nsample', 'totdim', 'bin01', 'tit0', 'Ti']","[None, None, None, None, None]","[None, None, None, None, '-1']",195,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'dx.dN', 'plt.plot', 'plt.axis', 'plt.title']",10
utilmy/zarchive/storage/sobol.py:testdensity2d,testdensity2d,function,39,85,74,702,8.26,2,0,"['nsample', 'totdim', 'bin01', 'nbasset']","[None, None, None, None]","[None, None, None, None]",240,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'np.arange', 'np.histogram2d', 'dx.dN2d', 'np.meshgrid', 'plt.imshow', 'np.sum']",10
utilmy/zarchive/storage/sobol.py:lognormal_process2d,lognormal_process2d,function,2,5,4,49,9.8,0,0,"['a1', 'z1', 'a2', 'z2', 'k']","[None, None, None, None, None]","[None, None, None, None, None]",281,[],"['np.maximum', 'np.exp']",2
utilmy/zarchive/storage/sobol.py:testdensity2d2,testdensity2d2,function,40,91,80,750,8.24,2,0,"['nsample', 'totdim', 'bin01', 'nbasset', 'process01', 'a1', 'a2', 'kk']","[None, None, None, None, None, None, None, None]","[None, None, None, None, 'lognormal_process2d', '0.25', '0.25', '1']",287,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'np.arange', 'np.histogram2d', 'dx.dN2d', 'process01', 'np.meshgrid', 'plt.imshow', 'np.sum']",11
utilmy/zarchive/storage/sobol.py:call_process,call_process,function,15,30,28,245,8.17,1,0,"['a', 'z', 'k)', 'np.exp(a*z)-k)@jita', 'z', 'k)', '[np.exp(a*z) > k]', '[1])@jittotdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt=10)']","[None, None, ' return np.maximum(0', None, None, '  return np.piecewise(z', None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, None, None, None, '0.25', '-1', '10):']",335,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/sobol.py:binary_process,binary_process,function,15,30,28,245,8.17,1,0,"['a', 'z', 'k)', '[np.exp(a*z) > k]', '[1])@jittotdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt=10)']","[None, None, '  return np.piecewise(z', None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, '0.25', '-1', '10):']",339,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/sobol.py:pricing01,pricing01,function,15,30,28,245,8.17,1,0,"['totdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, '0.25', '-1', '10']",345,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/sobol.py:plotdensity2,plotdensity2,function,35,78,74,590,7.56,2,0,"['nsample', 'totdim', 'bin01', 'tit0', 'process01', 'vol', 'tt', 'Ti']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, '0.25', '5', '-1']",369,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'process01', 'call_process', 'plt.plot', 'plt.axis', 'plt.title']",11
utilmy/zarchive/storage/sobol.py:Plot2D_random_show,Plot2D_random_show,function,46,106,80,855,8.07,0,0,"['dir1', 'title1', 'dimxmax', 'dimymax', 'dimstep', 'samplejump', 'nsamplegraph']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",421,[],"['pd.read_hdf', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'plt.show', 'np.mean', 'np.var', 'comoment']",9
utilmy/zarchive/storage/sobol.py:Plot2D_random_save,Plot2D_random_save,function,51,106,77,723,6.82,2,0,"['dir1', 'title1', 'dimxmax', 'dimymax', 'dimstep', 'samplejump', 'nsamplegraph', '']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",468,[],"['range', 'pd.read_hdf', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",8
utilmy/zarchive/storage/sobol.py:getoutlier_fromrandom,getoutlier_fromrandom,function,57,168,111,1242,7.39,2,2,"['filename', 'jmax1', 'imax1', 'isamplejum', 'nsample', ""fileoutlier=   'E""]","[None, None, None, None, None, '']","[None, None, None, None, None, ""   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'""]",518,[],"['range', 'pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'unique_rows', 'store.append', 'store.close']",7
utilmy/zarchive/storage/sobol.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, None, None, None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",586,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/sobol.py:getoutlier_fromrandom_fast,getoutlier_fromrandom_fast,function,71,183,130,1320,7.21,2,2,"['filename', 'jmax1', 'imax1', 'isamplejum', 'nsample', 'trigger1', ""fileoutlier=   'E""]","[None, None, None, None, None, None, '']","[None, None, None, None, None, '0.28', ""   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'""]",606,[],"['np.zeros', 'range', 'ne.evaluate', 'pd.HDFStore', 'store.append', 'store.close']",6
utilmy/zarchive/storage/sobol.py:outlier_clean,outlier_clean,function,7,16,15,98,6.12,1,1,['vv2'],[None],[None],674,[],['range'],1
utilmy/zarchive/storage/sobol.py:overwrite_data,overwrite_data,function,6,11,9,112,10.18,0,0,"['fileoutlier', 'vv2']","[None, None]","[None, None]",682,[],"['pd.HDFStore', 'store.remove', 'store.append', 'store.close']",4
utilmy/zarchive/storage/sobol.py:doublecheck_outlier,doublecheck_outlier,function,69,163,121,1260,7.73,1,1,"['fileoutlier', 'ijump', 'nsample', 'trigger1', '']","[None, None, None, None, None]","[None, None, '4000', '0.1', None]",702,[],"['pd.read_hdf', 'np.zeros', 'np.shape', 'range', 'ne.evaluate', 'pd.HDFStore', 'store.append', 'store.close']",8
utilmy/zarchive/storage/sobol.py:plot_outlier,plot_outlier,function,19,32,32,287,8.97,0,0,"['fileoutlier', 'kk']","[None, None]","[None, None]",762,[],"['pd.read_hdf', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",7
utilmy/zarchive/storage/sobol.py:permute,permute,function,24,64,53,631,9.86,2,0,"['yy', 'kmax']","[None, None]","[None, None]",845,[],"['int', 'np.copy', 'range', 'permute2', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'comoment']",9
utilmy/zarchive/storage/sobol.py:permute2,permute2,function,18,42,41,461,10.98,1,0,"['xx', 'yy', 'kmax']","[None, None, None]","[None, None, None]",858,[],"['int', 'np.copy', 'range', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'comoment']",8
utilmy/zarchive/storage/stateprocessor.py:sort,sort,function,5,8,8,84,10.5,0,0,"['x', 'col', 'asc)', 'col', 'asc)close', 't0', 't1)', 't1] / close2[', 't0] -1)tuple1)', 'symfull=symfull) ', 'symfull)  # 607close', 't0', 't1', 'lag)']","[None, None, ' return   util.sortcol(x', None, None, None, '  return  100*( close2[:', '', '  return np.logical_and.reduce(tuple1)x', '', None, None, None, '']","[None, None, None, None, None, None, None, None, None, 'symfull) : return util.find(x', None, None, None, None]",8,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/stateprocessor.py:perf,perf,function,5,8,8,84,10.5,0,0,"['close', 't0', 't1)', 't1] / close2[', 't0] -1)tuple1)', 'symfull=symfull) ', 'symfull)  # 607close', 't0', 't1', 'lag)']","[None, None, '  return  100*( close2[:', '', '  return np.logical_and.reduce(tuple1)x', '', None, None, None, '']","[None, None, None, None, None, 'symfull) : return util.find(x', None, None, None, None]",9,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/stateprocessor.py:and2,and2,function,5,8,8,84,10.5,0,0,"['tuple1)', 'symfull=symfull) ', 'symfull)  # 607close', 't0', 't1', 'lag)']","['  return np.logical_and.reduce(tuple1)x', '', None, None, None, '']","[None, 'symfull) : return util.find(x', None, None, None, None]",10,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/stateprocessor.py:ff,ff,function,5,8,8,84,10.5,0,0,"['x', 'symfull=symfull) ', 'symfull)  # 607close', 't0', 't1', 'lag)']","[None, '', None, None, None, '']","[None, 'symfull) : return util.find(x', None, None, None, None]",12,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/stateprocessor.py:gap,gap,function,5,8,8,84,10.5,0,0,"['close', 't0', 't1', 'lag']","[None, None, None, None]","[None, None, None, None]",15,[],['pf.getret_fromquotes'],1
utilmy/zarchive/storage/stateprocessor.py:process_stock,process_stock,function,15,41,30,261,6.37,2,2,"['stkstr', 'show1']","[None, None]","[None, '1']",20,[],"['stkstr.split', 'enumerate', 'x.strip', 'list', 'v.sort']",5
utilmy/zarchive/storage/stateprocessor.py:printn,printn,function,19,44,39,364,8.27,1,0,"['ss', 'symfull', 's1']","[None, None, None]","[None, 'symfull', 's1']",33,[],"['util.sortcol', 'range', 'len', 'int', 'aux2.append', 'round']",6
utilmy/zarchive/storage/stateprocessor.py:show,show,function,10,144,88,862,5.99,1,2,"['ll', 's1']","[None, None]","[None, 's1']",50,[],['type'],1
utilmy/zarchive/storage/stateprocessor.py:get_treeselect,get_treeselect,function,48,110,86,745,6.77,2,3,"['stk', 's1', 'xnewdata', 'newsample', 'show1', 'nbtree', 'depthtree']","[None, None, None, None, None, None, None]","[None, 's1', 'None', '5', '1', '5', '10']",82,[],"['process_stock', 'util.find', 'np.array', 'range', 'np.shape', 'np.row_stack', 'np.ones', 'np.concatenate', 'np.max', 'np.min', 'util.sk_tree', 'np.sum', 'clfrf.predict', 'print']",14
utilmy/zarchive/storage/stateprocessor.py:store_patternstate,store_patternstate,function,14,25,25,236,9.44,1,0,"['tree', 'sym1', 'theme', 'symfull']","[None, None, None, None]","[None, None, None, 'symfull']",111,[],"['util.find', 'lstate.append', 'np.array', 'str', 'util.save_obj']",5
utilmy/zarchive/storage/stateprocessor.py:load_patternstate,load_patternstate,function,7,10,7,70,7.0,0,0,['name1'],[None],[None],125,[],['util.load_obj'],1
utilmy/zarchive/storage/stateprocessor.py:get_stocklist,get_stocklist,function,19,40,35,338,8.45,1,2,"['clf', 's11', 'initial', 'show1']","[None, None, None, None]","[None, None, None, '1']",130,[],"['process_stock', 'clf.predict', 'enumerate', 'str', 'laux.append', 'list', 'aux2.sort']",7
utilmy/zarchive/storage/symbolicmath.py:spp,spp,function,19,61,27,221,3.62,0,8,"[')', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', ""a8=''  )""]","[""\tprint'\\n\\n_________________________'a0"", None, None, None, None, None, None, None, '']","[None, ""''"", ""''"", ""''"", ""''"", ""''"", ""''"", ""''"", ""''  ):""]",66,[],['spp'],1
utilmy/zarchive/storage/symbolicmath.py:print2,print2,function,19,61,27,221,3.62,0,8,"['a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8']","[None, None, None, None, None, None, None, None, None]","[None, ""''"", ""''"", ""''"", ""''"", ""''"", ""''"", ""''"", ""''""]",68,[],['spp'],1
utilmy/zarchive/storage/symbolicmath.py:factorpoly,factorpoly,function,7,10,9,75,7.5,1,0,['pp'],[None],[None],87,[],"['rr=roots', 'rr.iteritems']",2
utilmy/zarchive/storage/symbolicmath.py:EEvarbrownian,EEvarbrownian,function,12,114,46,895,7.85,0,0,['ff1d'],[None],[None],104,[],"['symbols', 'factor', 'exp', 'Integral', 'ee.doit', 'simplify', '1/sqrt', 'ee.subs', 'vv.doit', 'vv.subs', 'EEvarbrownian2d']",11
utilmy/zarchive/storage/symbolicmath.py:EEvarbrownian2d,EEvarbrownian2d,function,11,60,36,482,8.03,0,0,['ff'],[None],[None],126,[],"['symbols', 'factor', 'exp', 'Integral', 'ee.doit', 'simplify', 'ee.subs', 'vv.doit', 'vv.subs']",9
utilmy/zarchive/storage/symbolicmath.py:lagrangian2d,lagrangian2d,function,12,50,45,592,11.84,1,0,['ll'],[None],[None],168,[],"['simplify', 'print2', 'solvers.solve', 'range', 'res.__len__', 'str']",6
utilmy/zarchive/storage/symbolicmath.py:decomposecorrel,decomposecorrel,function,16,47,39,402,8.55,0,0,['m1'],[None],[None],195,[],"['factor', 'print2', 'm1.eigenvals', 'm1.eigenvects', 'simplify', 'm1.LDLdecomposition']",6
utilmy/zarchive/storage/symbolicmath.py:nn,nn,function,3,26,21,196,7.54,0,1,['x'],[None],[None],233,[],"['1/sqrt', 'nn2', 'abs', 'Integral']",4
utilmy/zarchive/storage/symbolicmath.py:nn2,nn2,function,2,20,18,129,6.45,0,1,"['x', 'y', 'p']","[None, None, None]","[None, None, None]",236,[],"['abs', 'Integral']",2
utilmy/zarchive/storage/symbolicmath.py:dnn2,dnn2,function,1,3,3,54,18.0,0,0,"['x', 'y', 'p']","[None, None, None]","[None, None, None]",241,[],['exp'],1
utilmy/zarchive/storage/symbolicmath.py:dnn,dnn,function,2,7,6,95,13.57,0,0,"['x', 'y', 'p']","[None, None, None]","[None, None, None]",245,[],"['exp', 'dnn', '1/sqrt']",3
utilmy/zarchive/storage/symbolicmath.py:taylor2,taylor2,function,11,24,22,197,8.21,1,0,"['ff', 'x0', 'n']","[None, None, None]","[None, None, None]",249,[],"['simplify', 'range', 'Derivative', 'dffk.doit']",4
utilmy/zarchive/storage/symbolicmath.py:diffn,diffn,function,7,11,11,111,10.09,0,0,"['ff', 'x0', 'kk']","[None, None, None]","[None, None, None]",260,[],"['Derivative', 'simplify', 'dffk.doit']",3
utilmy/zarchive/storage/symbolicmath.py:dN,dN,function,1,2,2,29,14.5,0,0,['x'],[None],[None],270,[],['1/sqrt'],1
utilmy/zarchive/storage/symbolicmath.py:N,N,function,1,5,5,51,10.2,0,0,['x'],[None],[None],273,[],['1/sqrt'],1
utilmy/zarchive/storage/symbolicmath.py:d1f,d1f,function,2,14,12,68,4.86,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",276,[],"['log', 'sqrt']",2
utilmy/zarchive/storage/symbolicmath.py:d2f,d2f,function,2,14,12,68,4.86,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",281,[],"['log', 'sqrt']",2
utilmy/zarchive/storage/symbolicmath.py:d1xf,d1xf,function,2,8,8,28,3.5,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",286,[],['sqrt'],1
utilmy/zarchive/storage/symbolicmath.py:d2xf,d2xf,function,2,8,8,28,3.5,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",289,[],['sqrt'],1
utilmy/zarchive/storage/symbolicmath.py:bsbinarycall,bsbinarycall,function,6,11,11,61,5.55,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",293,[],"['d2f', 'exp']",2
utilmy/zarchive/storage/symbolicmath.py:bscall,bscall,function,8,15,14,109,7.27,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",299,[],"['d1f', 'vol*sqrt', 's0*exp', 'K*exp']",4
utilmy/zarchive/storage/symbolicmath.py:bsput,bsput,function,7,15,14,112,7.47,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",306,[],"['d1f', 'vol*sqrt', 'K*exp']",3
utilmy/zarchive/storage/symbolicmath.py:bs,bs,function,38,337,112,1970,5.85,1,2,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",313,[],"['d2f', 'exp', 'bscall', 'd1f', 'vol*sqrt', 's0*exp', 'K*exp', 'bsput', 'bs', 'bsdelta', 'N', 'bsstrikedelta', 'bsstrikegamma', 'sqrt', 'bsgamma', 'bstheta', 'St*exp', 'bsrho', 'bsvega', 'dN', 'bsdvd', 'bsvanna', 'bsvolga', 'bsgammaspot']",24
utilmy/zarchive/storage/symbolicmath.py:bsdelta,bsdelta,function,11,27,25,132,4.89,1,1,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",320,[],"['d1f', 'exp', 'N']",3
utilmy/zarchive/storage/symbolicmath.py:bsstrikedelta,bsstrikedelta,function,7,28,22,158,5.64,0,1,"['s0', 'K', 't', 'T', 'r', 'd', 'vol', 'cp1']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",328,[],"['d2f', 'exp']",2
utilmy/zarchive/storage/symbolicmath.py:bsstrikegamma,bsstrikegamma,function,4,19,19,96,5.05,0,0,"['s0', 'K', 't', 'T', 'r', 'd', 'vol']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",337,[],"['d1f', 'exp', 'sqrt']",3
utilmy/zarchive/storage/symbolicmath.py:bsgamma,bsgamma,function,4,19,19,96,5.05,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",341,[],"['d1f', 'exp', 'sqrt']",3
utilmy/zarchive/storage/symbolicmath.py:bstheta,bstheta,function,5,20,19,98,4.9,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",345,[],"['d1f', 'St*exp', 'sqrt', 'N']",4
utilmy/zarchive/storage/symbolicmath.py:bsrho,bsrho,function,6,14,13,65,4.64,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",351,[],"['sqrt', 'exp', 'N']",3
utilmy/zarchive/storage/symbolicmath.py:bsvega,bsvega,function,4,13,13,70,5.38,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",356,[],"['d1f', 'St*exp', 'sqrt', 'dN']",4
utilmy/zarchive/storage/symbolicmath.py:bsdvd,bsdvd,function,3,16,15,72,4.5,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",361,[],"['d1f', 'exp', 'N']",3
utilmy/zarchive/storage/symbolicmath.py:bsvanna,bsvanna,function,6,16,15,79,4.94,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",366,[],"['d1f', 'sqrt', 'dN']",3
utilmy/zarchive/storage/symbolicmath.py:bsvolga,bsvolga,function,7,18,16,94,5.22,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",372,[],"['d1f', 'sqrt', 'St*exp', 'dN']",4
utilmy/zarchive/storage/symbolicmath.py:bsgammaspot,bsgammaspot,function,4,18,18,118,6.56,0,0,"['St', 'K', 't', 'T', 'r', 'd', 'vol', 'cp']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",378,[],"['d1f', 'exp']",2
utilmy/zarchive/storage/technical_indicator.py:np_find,np_find,function,5,11,10,55,5.0,1,1,"['item', 'vec']","[None, None]","[None, None]",5,"['    """"""return the index of the first occurence of item in vec""""""\n']",['xrange'],1
utilmy/zarchive/storage/technical_indicator.py:np_find_minpos,np_find_minpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],12,[],['min'],1
utilmy/zarchive/storage/technical_indicator.py:np_find_maxpos,np_find_maxpos,function,4,7,5,95,13.57,0,0,['values'],[None],[None],16,[],['max'],1
utilmy/zarchive/storage/technical_indicator.py:date_earningquater,date_earningquater,function,4,15,13,96,6.4,0,1,"['t1)', '12] ']","['   #JP Morgan Qearing datet1.month', '']","['=10 and t1.day >= 14) or (t1.month==1 and t1.day < 14) or t1.month in [11', None]",20,[],['datetime'],1
utilmy/zarchive/storage/technical_indicator.py:date_option_expiry,date_option_expiry,function,10,60,33,387,6.45,0,2,['date'],[None],[None],39,[],['datetime'],1
utilmy/zarchive/storage/technical_indicator.py:linearreg,linearreg,function,11,11,11,57,5.18,0,0,"['a', '*args']","[None, None]","[None, None]",57,[],['np.sum'],1
utilmy/zarchive/storage/technical_indicator.py:np_sortbycolumn,np_sortbycolumn,function,6,8,8,70,8.75,0,0,"['arr', 'colid', 'asc']","[None, None, None]","[None, None, 'True']",62,[],"['pd.DataFrame', 'df.sort']",2
utilmy/zarchive/storage/technical_indicator.py:np_findlocalmax,np_findlocalmax,function,22,47,34,233,4.96,1,3,['v'],[None],[None],68,[],"['n=len', 'np.zeros', 'enumerate', 'np_sortbycolumn', 'np_find_maxpos']",5
utilmy/zarchive/storage/technical_indicator.py:findhigher,findhigher,function,5,12,11,54,4.5,1,1,"['item', 'vec']","[None, None]","[None, None]",82,[],['xrange'],1
utilmy/zarchive/storage/technical_indicator.py:findlower,findlower,function,5,12,11,54,4.5,1,1,"['item', 'vec']","[None, None]","[None, None]",87,[],['xrange'],1
utilmy/zarchive/storage/technical_indicator.py:np_findlocalmin,np_findlocalmin,function,24,50,37,250,5.0,1,3,['v'],[None],[None],93,[],"['n=len', 'np.zeros', 'enumerate', 'np_sortbycolumn', 'np_find_minpos']",5
utilmy/zarchive/storage/technical_indicator.py:supportmaxmin1,supportmaxmin1,function,115,500,206,3613,7.23,2,11,['df1'],[None],[None],113,[],"['np_findlocalmax', 'len', 'np_find_maxpos', 'range', 'findhigher', 'np.abs', 'np.shape', 'np.arange', 'min', 'np.zeros', 'max', 'np_findlocalmin', 'np_find_minpos', 'findlower', 'pd.Series', 'df1.join']",16
utilmy/zarchive/storage/technical_indicator.py:RET,RET,function,10,21,16,123,5.86,0,0,"['df', 'n']","[None, None]","[None, None]",265,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:qearning_dist,qearning_dist,function,19,38,32,317,8.34,1,0,['df'],[None],[None],274,[],"['np.zeros', 'enumerate', 'date_earningquater', 'pd.Series', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:optionexpiry_dist,optionexpiry_dist,function,15,26,23,212,8.15,1,0,['df'],[None],[None],287,[],"['np.zeros', 'enumerate', 'date_option_expiry', 'pd.Series', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:nbtime_reachtop,nbtime_reachtop,function,17,34,31,284,8.35,1,0,"['df', 'n', 'trigger']","[None, None, None]","[None, None, '0.005']",298,"[""  '''nb of days from 1 year low '''\n""]","['np.zeros', 'range', 'len', 'np_find_maxpos', 'np.abs', 'np.sign', 'pd.Series', 'str', 'df.join']",9
utilmy/zarchive/storage/technical_indicator.py:nbday_high,nbday_high,function,20,39,32,333,8.54,1,0,"['df', 'n']","[None, None]","[None, None]",312,"[""  '''nb of days from 1 year low '''\n""]","['np.zeros', 'range', 'len', 'np_find_maxpos', 'pd.Series', 'str', 'df.join']",7
utilmy/zarchive/storage/technical_indicator.py:distance_day,distance_day,function,14,28,24,192,6.86,1,0,"['df', 'tk', 'tkname']","[None, None, None]","[None, None, None]",328,[],"['datetime.date', 'np.zeros', 'range', 'len', 'pd.Series', 'df.join']",6
utilmy/zarchive/storage/technical_indicator.py:distance,distance,function,16,44,36,298,6.77,1,0,"['df', 'tk', 'tkname']","[None, None, None]","[None, None, None]",339,[],"['datetime.date', 'np.zeros', 'range', 'len', 'pd.Series', 'df.join', 'distance']",7
utilmy/zarchive/storage/technical_indicator.py:MA,MA,function,5,12,10,86,7.17,0,0,"['df', 'n']","[None, None]","[None, None]",346,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:EMA,EMA,function,5,16,14,102,6.38,0,0,"['df', 'n']","[None, None]","[None, None]",352,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:MOM,MOM,function,5,11,9,79,7.18,0,0,"['df', 'n']","[None, None]","[None, None]",358,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:ROC,ROC,function,9,20,15,111,5.55,0,0,"['df', 'n']","[None, None]","[None, None]",364,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:ATR,ATR,function,12,47,32,280,5.96,1,0,"['df', 'n']","[None, None]","[None, None]",372,[],"['max', 'df.get_value', 'min', 'TR_l.append', 'pd.Series', 'str', 'df.join']",7
utilmy/zarchive/storage/technical_indicator.py:BBANDS,BBANDS,function,10,41,25,261,6.37,0,0,"['df', 'n']","[None, None]","[None, None]",385,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:PPSR,PPSR,function,14,55,37,378,6.87,0,0,['df'],[None],[None],398,[],"['pd.Series', 'pd.DataFrame', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:STOK,STOK,function,5,13,11,98,7.54,0,0,['df'],[None],[None],412,[],"['pd.Series', 'df.join']",2
utilmy/zarchive/storage/technical_indicator.py:STO,STO,function,7,40,24,282,7.05,0,0,['df'],[None],[None],418,[],"['pd.Series', 'df.join', 'STO', 'str']",4
utilmy/zarchive/storage/technical_indicator.py:TRIX,TRIX,function,14,58,33,286,4.93,1,0,"['df', 'n']","[None, None]","[None, None]",425,[],"['pd.ewma', 'ROC_l.append', 'pd.Series', 'str', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:ADX,ADX,function,25,152,68,821,5.4,2,2,"['df', 'n', 'n_ADX']","[None, None, None]","[None, None, None]",440,[],"['df.get_value', 'UpI.append', 'DoI.append', 'max', 'min', 'TR_l.append', 'pd.Series', 'str', 'df.join']",9
utilmy/zarchive/storage/technical_indicator.py:MACD,MACD,function,9,57,32,465,8.16,0,0,"['df', 'n_fast', 'n_slow']","[None, None, None]","[None, None, None]",473,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:MassI,MassI,function,11,34,22,202,5.94,0,0,['df'],[None],[None],485,[],"['pd.ewma', 'pd.Series', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:Vortex,Vortex,function,14,72,36,456,6.33,2,0,"['df', 'n']","[None, None]","[None, None]",495,[],"['max', 'df.get_value', 'min', 'TR.append', 'abs', 'VM.append', 'pd.Series', 'pd.rolling_sum', 'str', 'df.join']",10
utilmy/zarchive/storage/technical_indicator.py:KST,KST,function,13,83,42,485,5.84,0,0,"['df', 'r1', 'r2', 'r3', 'r4', 'n1', 'n2', 'n3', 'n4']","[None, None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None, None]",513,[],"['pd.Series', 'pd.rolling_sum', 'str', 'df.join']",4
utilmy/zarchive/storage/technical_indicator.py:RSI,RSI,function,19,103,46,512,4.97,1,2,"['df', 'n']","[None, None]","[None, '14']",531,[],"['df.get_value', 'UpI.append', 'DoI.append', 'pd.Series', 'str', 'df.join']",6
utilmy/zarchive/storage/technical_indicator.py:RMI,RMI,function,20,102,50,567,5.56,1,2,"['df', 'n', 'm']","[None, None, None]","[None, '14', '10']",558,[],"['list', 'df.get_value', 'UpI.append', 'DoI.append', 'pd.Series', 'str', 'df.join']",7
utilmy/zarchive/storage/technical_indicator.py:TSI,TSI,function,12,52,31,333,6.4,0,0,"['df', 'r', 's']","[None, None, None]","[None, None, None]",588,[],"['pd.Series', 'abs', 'str', 'df.join']",4
utilmy/zarchive/storage/technical_indicator.py:ACCDIST,ACCDIST,function,11,32,22,184,5.75,0,0,"['df', 'n']","[None, None]","[None, None]",600,[],"['ad.diff', 'ad.shift', 'pd.Series', 'str', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:Chaikin,Chaikin,function,6,28,22,205,7.32,0,0,['df'],[None],[None],610,[],"['pd.Series', 'pd.ewma', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:MFI,MFI,function,15,60,40,322,5.37,1,1,"['df', 'n']","[None, None]","[None, None]",617,[],"['PosMF.append', 'df.get_value', 'pd.Series', 'str', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:OBV,OBV,function,10,66,30,404,6.12,1,3,"['df', 'n']","[None, None]","[None, None]",635,[],"['df.get_value', 'OBV.append', 'pd.Series', 'str', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:FORCE,FORCE,function,5,12,10,97,8.08,0,0,"['df', 'n']","[None, None]","[None, None]",652,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:EOM,EOM,function,6,20,17,170,8.5,0,0,"['df', 'n']","[None, None]","[None, None]",658,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:CCI,CCI,function,6,21,18,146,6.95,0,0,"['df', 'n']","[None, None]","[None, None]",665,[],"['pd.Series', 'pd.rolling_mean', 'pd.rolling_std', 'str', 'df.join']",5
utilmy/zarchive/storage/technical_indicator.py:COPP,COPP,function,11,48,24,261,5.44,0,0,"['df', 'n']","[None, None]","[None, None]",672,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:KELCH,KELCH,function,7,45,24,362,8.04,0,0,"['df', 'n']","[None, None]","[None, None]",684,[],"['pd.Series', 'str', 'df.join']",3
utilmy/zarchive/storage/technical_indicator.py:ULTOSC,ULTOSC,function,15,67,40,552,8.24,1,0,['df'],[None],[None],694,[],"['max', 'df.get_value', 'min', 'TR_l.append', 'BP_l.append', 'pd.Series', 'pd.rolling_sum', 'df.join']",8
utilmy/zarchive/storage/technical_indicator.py:DONCH,DONCH,function,13,57,27,249,4.37,2,0,"['df', 'n']","[None, None]","[None, None]",709,[],"['DC_l.append', 'max', 'min', 'pd.Series', 'str', 'DonCh.shift', 'df.join']",7
utilmy/zarchive/storage/technical_indicator.py:STDDEV,STDDEV,function,3,9,8,80,8.89,0,0,"['df', 'n']","[None, None]","[None, None]",726,[],"['df.join', 'str']",2
utilmy/zarchive/storage/technical_indicator.py:RWI,RWI,function,1,2,2,7,3.5,0,0,"['df', 'nn', 'nATR']","[None, None, None]","[None, None, None]",731,[],[],0
utilmy/zarchive/storage/technical_indicator.py:nbday_low,nbday_low,function,20,39,32,331,8.49,1,0,"['df', 'n']","[None, None]","[None, None]",745,"[""  '''nb of days from 1 year low '''\n""]","['np.zeros', 'range', 'len', 'np_find_minpos', 'pd.Series', 'str', 'df.join']",7
utilmy/zarchive/storage/technical_indicator.py:nbday_high,nbday_high,function,20,39,32,333,8.54,1,0,"['df', 'n']","[None, None]","[None, None]",312,"[""  '''nb of days from 1 year low '''\n""]","['np.zeros', 'range', 'len', 'np_find_maxpos', 'pd.Series', 'str', 'df.join']",7
utilmy/zarchive/storage/testmulti.py:mc01,mc01,function,0,0,0,0,0.0,0,0,[],[],[],18,"[""'''\n"", '\n', 'from __future__ import print_function\n', '\n', 'import multiprocessing\n', 'import ctypes\n', 'import numpy as np\n', '\n', 'def shared_array(shape):\n', '    """"""\n', '    Form a shared memory numpy array.\n', '    \n', '    http://stackoverflow.com/questions/5549190/is-shared-readonly-data-copied-to-different-processes-for-python-multiprocessing \n', '    """"""\n', '    \n', '    shared_array_base = multiprocessing.Array(ctypes.c_double, shape[0]*shape[1])\n', '    shared_array = np.ctypeslib.as_array(shared_array_base.get_obj())\n', '    shared_array = shared_array.reshape(*shape)\n', '    return shared_array\n', '\n', '\n', '# Form a shared array and a lock, to protect access to shared memory.\n', 'array = shared_array((1000, 1000))\n', 'lock = multiprocessing.Lock()\n', '\n', '\n', 'def parallel_function(i, def_param=(lock, array)):\n', '    """"""\n', '    Function that operates on shared memory.\n', '    """"""\n', '    \n', '    # Make sure your not modifying data when someone else is.\n', '    lock.acquire()    \n', '    \n', '    array[i, :] = i\n', '    \n', '    # Always release the lock!\n', '    lock.release()\n', '\n', ""if __name__ == '__main__':\n"", '    """"""\n', '    The processing pool needs to be instantiated in the main \n', '    thread of execution. \n', '    """"""\n', '        \n', '    pool = multiprocessing.Pool(processes=4)\n', '        \n', '    # Call the parallel function with different inputs.\n', '    args = [(0), \n', '            (1), \n', '            (2)]\n', '    \n', '    # Use map - blocks until all processes are done.\n', '    pool.map(parallel_function, args )\n', '    \n', '    print(array)\n', '    \n', '    \n', ""    '''\n""]",[],0
utilmy/zarchive/storage/testmulti.py:mc02,mc02,function,0,0,0,0,0.0,0,0,[],[],[],28,"[""'''\n"", '\n', 'from __future__ import print_function\n', '\n', 'import multiprocessing\n', 'import ctypes\n', 'import numpy as np\n', '\n', 'def shared_array(shape):\n', '    """"""\n', '    Form a shared memory numpy array.\n', '    \n', '    http://stackoverflow.com/questions/5549190/is-shared-readonly-data-copied-to-different-processes-for-python-multiprocessing \n', '    """"""\n', '    \n', '    shared_array_base = multiprocessing.Array(ctypes.c_double, shape[0]*shape[1])\n', '    shared_array = np.ctypeslib.as_array(shared_array_base.get_obj())\n', '    shared_array = shared_array.reshape(*shape)\n', '    return shared_array\n', '\n', '\n', '# Form a shared array and a lock, to protect access to shared memory.\n', 'array = shared_array((1000, 1000))\n', 'lock = multiprocessing.Lock()\n', '\n', '\n', 'def parallel_function(i, def_param=(lock, array)):\n', '    """"""\n', '    Function that operates on shared memory.\n', '    """"""\n', '    \n', '    # Make sure your not modifying data when someone else is.\n', '    lock.acquire()    \n', '    \n', '    array[i, :] = i\n', '    \n', '    # Always release the lock!\n', '    lock.release()\n', '\n', ""if __name__ == '__main__':\n"", '    """"""\n', '    The processing pool needs to be instantiated in the main \n', '    thread of execution. \n', '    """"""\n', '        \n', '    pool = multiprocessing.Pool(processes=4)\n', '        \n', '    # Call the parallel function with different inputs.\n', '    args = [(0), \n', '            (1), \n', '            (2)]\n', '    \n', '    # Use map - blocks until all processes are done.\n', '    pool.map(parallel_function, args )\n', '    \n', '    print(array)\n', '    \n', '    \n', ""    '''\n""]",[],0
utilmy/zarchive/storage/testmulti.py:serial,serial,function,1,8,8,54,6.75,0,0,"['samples', 'x', 'widths']","[None, None, None]","[None, None, None]",149,[],[],0
utilmy/zarchive/storage/testmulti.py:multiprocess,multiprocess,function,5,27,22,231,8.56,0,0,"['processes', 'samples', 'x', 'widths']","[None, None, None, None]","[None, None, None, None]",152,[],"['mp.Pool', 'pool.terminate', 'pool.join', 'print']",4
utilmy/zarchive/storage/testmulti.py:test01,test01,function,28,54,39,407,7.54,3,0,[],[],[],209,[],"['range', 'list', 'mp.Process']",3
utilmy/zarchive/storage/testmulti.py:random_tree,random_tree,function,3,3,3,42,14.0,0,0,['Data'],[None],[None],251,[],"['calculation', 'forest.append']",2
utilmy/zarchive/storage/testmulti.py:random_tree,random_tree,function,3,3,3,42,14.0,0,0,['Data'],[None],[None],251,[],"['calculation', 'forest.append']",2
utilmy/zarchive/storage/testmulti.py:test01,test01,function,28,54,39,407,7.54,3,0,[],[],[],209,[],"['range', 'list', 'mp.Process']",3
utilmy/zarchive/storage/theano_imdb.py:prepare_data,prepare_data,function,30,71,54,552,7.77,2,3,"['seqs', 'labels', 'maxlen']","[None, None, None]","[None, None, 'None']",12,"['    """"""Create the matrices from the datasets.\n', '\n', '    This pad each sequence to the same lenght: the lenght of the\n', '    longuest sequence or maxlen.\n', '\n', '    if maxlen is set, we will cut all sequence to this maximum\n', '    lenght.\n', '\n', '    This swap the axis!\n', '    """"""\n']","['zip', 'new_seqs.append', 'new_labels.append', 'new_lengths.append', 'len', 'numpy.max', 'numpy.zeros', 'enumerate']",8
utilmy/zarchive/storage/theano_imdb.py:get_dataset_file,get_dataset_file,function,16,43,35,416,9.67,0,3,"['dataset', 'default_dataset', 'origin']","[None, None, None]","[None, None, None]",54,"[""    '''Look for it as if it was a full path, if not, try local file,\n"", '    if not try in the data directory.\n', '\n', '    Download dataset if it is not present\n', '\n', ""    '''\n""]",['print'],1
utilmy/zarchive/storage/theano_imdb.py:load_data,load_data,function,54,180,103,1753,9.74,13,5,"['path', 'n_words', 'valid_portion', 'maxlen', 'sort_by_len']","[None, None, None, None, None]","['""imdb.pkl""', '100000', '0.1', 'None', 'True']",82,"[""    '''Loads the dataset\n"", '\n', '    :type path: String\n', '    :param path: The path to the dataset (here IMDB)\n', '    :type n_words: int\n', '    :param n_words: The number of word to keep in the vocabulary.\n', '        All extra words are set to unknow (1).\n', '    :type valid_portion: float\n', '    :param valid_portion: The proportion of the full train set used for\n', '        the validation set.\n', '    :type maxlen: None or positive int\n', '    :param maxlen: the max sequence length we use in the train/valid set.\n', '    :type sort_by_len: bool\n', '    :name sort_by_len: Sort by the sequence lenght for the train,\n', '        valid and test set. This allow faster execution as it cause\n', '        less padding per minibatch. Another mechanism must be used to\n', '        shuffle the train set at each epoch.\n', '\n', ""    '''\n""]","['get_dataset_file', 'path.endswith', 'gzip.open', 'open', 'pickle.load', 'f.close', 'zip', 'len', 'new_train_set_x.append', 'new_train_set_y.append', 'int', 'remove_unk', 'len_argsort', 'sorted']",14
utilmy/zarchive/storage/theano_lstm.py:numpy_floatX,numpy_floatX,function,2,3,3,45,15.0,0,0,['data'],[None],[None],26,[],['numpy.asarray'],1
utilmy/zarchive/storage/theano_lstm.py:get_minibatches_idx,get_minibatches_idx,function,11,29,26,373,12.86,1,1,"['n', 'minibatch_size', 'shuffle']","[None, None, None]","[None, None, 'False']",30,"['    """"""\n', '    Used to shuffle the dataset at each iteration.\n', '    """"""\n']","['numpy.arange', 'range', 'minibatches.append', 'zip']",4
utilmy/zarchive/storage/theano_lstm.py:get_dataset,get_dataset,function,3,3,3,41,13.67,0,0,['name'],[None],[None],54,[],[],0
utilmy/zarchive/storage/theano_lstm.py:zipp,zipp,function,4,6,6,51,8.5,1,0,"['params', 'tparams']","[None, None]","[None, None]",58,"['    """"""\n', '    When we reload the model. Needed for the GPU stuff.\n', '    """"""\n']",['params.items'],1
utilmy/zarchive/storage/theano_lstm.py:unzip,unzip,function,8,11,10,97,8.82,1,0,['zipped'],[None],[None],66,"['    """"""\n', '    When we pickle the model. Needed for the GPU stuff.\n', '    """"""\n']","['OrderedDict', 'zipped.items', 'vv.get_value']",3
utilmy/zarchive/storage/theano_lstm.py:dropout_layer,dropout_layer,function,4,12,11,146,12.17,0,0,"['state_before', 'use_noise', 'trng']","[None, None, None]","[None, None, None]",76,[],"['tensor.switch', 'trng.binomial']",2
utilmy/zarchive/storage/theano_lstm.py:_p,_p,function,1,5,5,23,4.6,0,0,"['pp', 'name']","[None, None]","[None, None]",86,[],[],0
utilmy/zarchive/storage/theano_lstm.py:init_params,init_params,function,13,20,18,394,19.7,0,0,['options'],[None],[None],90,"['    """"""\n', '    Global (not LSTM) parameter. For the embeding and the classifier.\n', '    """"""\n']","['OrderedDict', 'get_layer', 'numpy.zeros']",3
utilmy/zarchive/storage/theano_lstm.py:load_params,load_params,function,11,25,22,128,5.12,1,1,"['path', 'params']","[None, None]","[None, None]",110,[],"['numpy.load', 'params.items', 'Warning']",3
utilmy/zarchive/storage/theano_lstm.py:init_tparams,init_tparams,function,8,12,11,107,8.92,1,0,['params'],[None],[None],120,[],"['OrderedDict', 'params.items', 'theano.shared']",3
utilmy/zarchive/storage/theano_lstm.py:get_layer,get_layer,function,3,4,3,26,6.5,0,0,['name'],[None],[None],127,[],[],0
utilmy/zarchive/storage/theano_lstm.py:ortho_weight,ortho_weight,function,8,9,9,87,9.67,0,0,['ndim'],[None],[None],132,[],['u.astype'],1
utilmy/zarchive/storage/theano_lstm.py:param_init_lstm,param_init_lstm,function,9,26,18,487,18.73,0,0,"['options', 'params', 'prefix']","[None, None, None]","[None, None, ""'lstm'""]",138,"['    """"""\n', '    Init the LSTM parameter:\n', '\n', '    :see: init_params\n', '    """"""\n']","['numpy.concatenate', 'ortho_weight', 'params[_p', 'numpy.zeros', 'b.astype']",5
utilmy/zarchive/storage/theano_lstm.py:lstm_layer,lstm_layer,function,41,115,79,988,8.59,0,2,"['tparams', 'state_below', 'options', 'prefix', 'mask']","[None, None, None, None, None]","[None, None, None, ""'lstm'"", 'None']",160,[],"['_slice', '_step', 'tensor.dot', 'tparams[_p', 'tensor.tanh', 'theano.scan', 'tensor.alloc', 'name=_p']",8
utilmy/zarchive/storage/theano_lstm.py:sgd,sgd,function,8,46,38,359,7.8,0,0,"['lr', 'tparams', 'grads', 'x', 'mask', 'y', 'cost']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",213,"['    """""" Stochastic Gradient Descent\n', '\n', '    :note: A more complicated version of sgd then needed.  This is\n', '        done like that for adadelta and rmsprop.\n', '\n', '    """"""\n']","['tparams.items', 'zip', 'theano.function']",3
utilmy/zarchive/storage/theano_lstm.py:adadelta,adadelta,function,12,112,70,907,8.1,0,0,"['lr', 'tparams', 'grads', 'x', 'mask', 'y', 'cost']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",241,"['    """"""\n', '    An adaptive learning rate optimizer\n', '\n', '    Parameters\n', '    ----------\n', '    lr : Theano SharedVariable\n', '        Initial learning rate\n', '    tpramas: Theano SharedVariable\n', '        Model parameters\n', '    grads: Theano variable\n', '        Gradients of cost w.r.t to parameres\n', '    x: Theano variable\n', '        Model inputs\n', '    mask: Theano variable\n', '        Sequence mask\n', '    y: Theano variable\n', '        Targets\n', '    cost: Theano variable\n', '        Objective fucntion to minimize\n', '\n', '    Notes\n', '    -----\n', '    For more information, see [ADADELTA]_.\n', '\n', '    .. [ADADELTA] Matthew D. Zeiler, *ADADELTA: An Adaptive Learning\n', '       Rate Method*, arXiv:1212.5701.\n', '    """"""\n']","['numpy_floatX', 'tparams.items', 'zip', 'theano.function', 'tensor.sqrt']",5
utilmy/zarchive/storage/theano_lstm.py:rmsprop,rmsprop,function,16,129,77,1028,7.97,1,0,"['lr', 'tparams', 'grads', 'x', 'mask', 'y', 'cost']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",302,"['    """"""\n', '    A variant of  SGD that scales the step size by running average of the\n', '    recent step norms.\n', '\n', '    Parameters\n', '    ----------\n', '    lr : Theano SharedVariable\n', '        Initial learning rate\n', '    tpramas: Theano SharedVariable\n', '        Model parameters\n', '    grads: Theano variable\n', '        Gradients of cost w.r.t to parameres\n', '    x: Theano variable\n', '        Model inputs\n', '    mask: Theano variable\n', '        Sequence mask\n', '    y: Theano variable\n', '        Targets\n', '    cost: Theano variable\n', '        Objective fucntion to minimize\n', '\n', '    Notes\n', '    -----\n', '    For more information, see [Hint2014]_.\n', '\n', '    .. [Hint2014] Geoff Hinton, *Neural Networks for Machine Learning*,\n', '       lecture 6a,\n', '       http://cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf\n', '    """"""\n']","['numpy_floatX', 'tparams.items', 'zip', 'theano.function', 'tensor.sqrt']",5
utilmy/zarchive/storage/theano_lstm.py:build_model,build_model,function,39,78,66,934,11.97,0,3,"['tparams', 'options']","[None, None]","[None, None]",367,[],"['RandomStreams', 'theano.shared', 'tensor.matrix', 'tensor.vector', 'get_layer', 'mask.sum', 'dropout_layer', 'theano.function', 'pred.argmax']",9
utilmy/zarchive/storage/theano_lstm.py:pred_probs,pred_probs,function,18,41,37,377,9.2,1,1,"['f_pred_prob', 'prepare_data', 'data', 'iterator', 'verbose']","[None, None, None, None, None]","[None, None, None, None, 'False']",406,"['    """""" If you want to use a trained model, this is useful to compute\n', '    the probabilities of new examples.\n', '    """"""\n']","['len', 'numpy.zeros', 'prepare_data', 'numpy.array', 'f_pred_prob', 'print']",6
utilmy/zarchive/storage/theano_lstm.py:pred_error,pred_error,function,15,32,27,303,9.47,1,0,"['f_pred', 'prepare_data', 'data', 'iterator', 'verbose']","[None, None, None, None, None]","[None, None, None, None, 'False']",429,"['    """"""\n', '    Just compute the error\n', '    f_pred: Theano fct computing the prediction\n', '    prepare_data: usual prepare_data for that dataset.\n', '    """"""\n']","['prepare_data', 'numpy.array', 'f_pred', 'numpy_floatX', 'len']",5
utilmy/zarchive/storage/theano_lstm.py:train_lstm,train_lstm,function,95,417,264,3684,8.83,3,16,"['dim_proj', '# word embeding dimension and LSTM number of hidden units.patience', '# Number of epoch to wait before early stop if no progressmax_epochs', '# The maximum number of epoch to rundispFreq', '# Display to stdout the training progress every N updatesdecay_c', '# Weight decay for the classifier applied to the U weights.not used for adadelta and rmsprop)n_words', '# Vocabulary sizeprobably need momentum and decaying learning rate).encoder', '# TODO', '# The best model will be saved therevalidFreq', '# Compute the validation error after this number of update.saveFreq', '# Save the parameters after every saveFreq updatesmaxlen', '# Sequence longer then this get ignoredbatch_size', '# The batch size during training.valid_batch_size', '# The batch size used for validation/test set.dataset', 'noise_std', 'use_dropout', '# if False slightly faster', 'but worst test errorreload_model', '# Path to a saved model we want to start from.test_size', '# If >0', 'we keep only this number of test example.']","[None, None, None, None, None, None, None, ' can be removed must be lstm.saveto', None, None, None, None, None, None, None, None, None, None, None, None, None]","['128', '10', '5000', '10', '0.', '10000', ""'lstm'"", ""'lstm_model.npz'"", '370', '1110', '100', '16', '64', ""'imdb'"", '0.', 'True', None, 'None', '-1', None, None]",448,[],"['locals', 'print', 'get_dataset', 'load_data', 'numpy.arange', 'numpy.max', 'init_params', 'load_params', 'init_tparams', 'build_model', 'theano.shared', 'theano.function', 'tensor.grad', 'wrt=list', 'tensor.scalar', 'optimizer', 'get_minibatches_idx', 'len', 'time.time', 'range', 'use_noise.set_value', 'prepare_data', 'f_grad_shared', 'f_update', 'numpy.isnan', 'numpy.isinf', 'numpy.mod', 'unzip', 'numpy.savez', 'pickle.dump', 'open', 'pred_error', 'history_errs.append', 'numpy.array', 'zipp']",35
utilmy/templates/templist/pypi_package/run_pipy.py:get_current_githash,get_current_githash,function,6,10,8,126,12.6,0,0,[],[],[],39,[],"['subprocess.check_output', 'label.decode']",2
utilmy/templates/templist/pypi_package/run_pipy.py:update_version,update_version,function,12,30,28,315,10.5,0,0,"['path', 'n']","[None, None]","[None, '1']",46,[],"['open', 'Version.parse', 'print', 'int', 'file.write', 'version.new_version']",6
utilmy/templates/templist/pypi_package/run_pipy.py:git_commit,git_commit,function,3,29,19,164,5.66,0,2,['message'],[None],[None],65,[],"['ask', 'exit', 'os.system']",3
utilmy/templates/templist/pypi_package/run_pipy.py:ask,ask,function,2,3,3,42,14.0,0,0,"['question', 'ans']","[None, None]","[None, ""'yes'""]",77,[],"['input', 'ans.lower']",2
utilmy/templates/templist/pypi_package/run_pipy.py:pypi_upload,pypi_upload,function,5,40,35,391,9.78,1,1,[],[],[],81,"['    """"""\n', '      It requires credential in .pypirc  files\n', '      __token__\n', '      or in github SECRETS\n', '\n', '    """"""\n']","['os.system', 'print', 'os.listdir', 'item.endswith']",4
utilmy/templates/templist/pypi_package/run_pipy.py:main,main,function,2,6,6,75,12.5,0,0,['*args'],[None],[None],102,[],"['print', 'update_version']",2
utilmy/templates/templist/pypi_package/run_pipy.py:Version,Version,class,21,58,48,650,11.21,0,1,[],[],[],10,[],[],0
utilmy/templates/templist/pypi_package/run_pipy.py:Version:__init__,Version:__init__,method,6,6,6,50,8.33,0,0,"['self', 'major', 'minor', 'patch']","[None, None, None, None]","[None, None, None, None]",13,[],[],0
utilmy/templates/templist/pypi_package/run_pipy.py:Version:__str__,Version:__str__,method,2,2,2,36,18.0,0,0,['self'],[None],[None],18,[],"[""f'Version""]",1
utilmy/templates/templist/pypi_package/run_pipy.py:Version:__repr__,Version:__repr__,method,2,2,2,20,10.0,0,0,['self'],[None],[None],21,[],['self.__str__'],1
utilmy/templates/templist/pypi_package/run_pipy.py:Version:stringify,Version:stringify,method,1,2,2,51,25.5,0,0,['self'],[None],[None],24,[],[],0
utilmy/templates/templist/pypi_package/run_pipy.py:Version:new_version,Version:new_version,method,1,3,3,53,17.67,0,0,"['self', 'orig']","[None, None]","[None, None]",27,[],['self.stringify'],1
utilmy/templates/templist/pypi_package/run_pipy.py:Version:parse,Version:parse,method,5,23,22,192,8.35,0,1,"['cls', 'string']","[None, None]","[None, None]",31,[],"['re.findall', 'len', 'Exception', 'cls']",4
utilmy/templates/templist/pypi_package/setup.py:get_current_githash,get_current_githash,function,6,10,8,123,12.3,0,0,[],[],[],17,[],"['subprocess.check_output', 'label.decode']",2
utilmy/zarchive/storage/aapackagedev/random.py:convert_csv2hd5f,convert_csv2hd5f,function,10,21,19,181,8.62,1,0,"['filein1', 'filename']","[None, None]","[None, None]",61,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/storage/aapackagedev/random.py:getrandom_tonumpy,getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample']","[None, None, None]","[None, None, None]",74,[],['pd.read_hdf'],1
utilmy/zarchive/storage/aapackagedev/random.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",90,[],['ne.evaluate'],1
utilmy/zarchive/storage/aapackagedev/random.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],98,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/storage/aapackagedev/random.py:getdvector,getdvector,function,7,21,20,141,6.71,1,0,"['dimmax', 'istart', 'idimstart']","[None, None, None]","[None, None, None]",126,[],['range'],1
utilmy/zarchive/storage/aapackagedev/random.py:pathScheme_std,pathScheme_std,function,3,3,3,28,9.33,0,0,"['T', 'n', 'zz)', 'n+1)']","[None, None, '   #Standard Path generationn+1);  sdt', '']","[None, None, ' np.sqrt(T/n);  ww[0]= 01', None]",136,[],[],0
utilmy/zarchive/storage/aapackagedev/random.py:pathScheme_bb,pathScheme_bb,function,18,32,30,200,6.25,1,0,"['T', 'n', 'zz)', 'kkmax+1)']","[None, None, '  #Brownian Bridge generationn); # sdt', '']","[None, None, ' np.sqrt(T/n);np.round(np.log(n)  * 1.4426950408889634)) # n= 2^kmaxh= n; jmax=1T)1', None]",144,[],"['int', 'range', 'np.sqrt']",3
utilmy/zarchive/storage/aapackagedev/random.py:pathScheme_,pathScheme_,function,3,3,3,28,9.33,0,0,"['T', 'n', 'zz)', 'n+1)']","[None, None, '   #Standard Path generationn+1);  sdt', '']","[None, None, ' np.sqrt(T/n);  ww[0]= 01', None]",163,"[""'''\n"", 'ttdim=1024  # dim= 2^k\n', '[[500, testdensity(500, ttdim, 400,-1)],\n', '[1000, testdensity(1000, ttdim, 400,-1)],\n', '[2000, testdensity(2000, ttdim, 400,-1)], \n', '[3000, testdensity(3000, ttdim, 400,-1)],\n', '[4000, testdensity(4000, ttdim, 400,-1)]]\n', ""'''\n""]",[],0
utilmy/zarchive/storage/aapackagedev/random.py:testdensity,testdensity,function,27,57,54,404,7.09,3,0,"['nsample', 'totdim', 'bin01', 'Ti']","[None, None, None, None]","[None, None, None, '-1']",173,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'dx.dN', 'np.sum']",8
utilmy/zarchive/storage/aapackagedev/random.py:plotdensity,plotdensity,function,29,65,63,531,8.17,1,0,"['nsample', 'totdim', 'bin01', 'tit0', 'Ti']","[None, None, None, None, None]","[None, None, None, None, '-1']",191,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'dx.dN', 'plt.plot', 'plt.axis', 'plt.title']",10
utilmy/zarchive/storage/aapackagedev/random.py:testdensity2d,testdensity2d,function,39,85,74,702,8.26,2,0,"['nsample', 'totdim', 'bin01', 'nbasset']","[None, None, None, None]","[None, None, None, None]",236,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'np.arange', 'np.histogram2d', 'dx.dN2d', 'np.meshgrid', 'plt.imshow', 'np.sum']",10
utilmy/zarchive/storage/aapackagedev/random.py:lognormal_process2d,lognormal_process2d,function,2,5,4,49,9.8,0,0,"['a1', 'z1', 'a2', 'z2', 'k']","[None, None, None, None, None]","[None, None, None, None, None]",277,[],"['np.maximum', 'np.exp']",2
utilmy/zarchive/storage/aapackagedev/random.py:testdensity2d2,testdensity2d2,function,40,91,80,750,8.24,2,0,"['nsample', 'totdim', 'bin01', 'nbasset', 'process01', 'a1', 'a2', 'kk']","[None, None, None, None, None, None, None, None]","[None, None, None, None, 'lognormal_process2d', '0.25', '0.25', '1']",283,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'np.arange', 'np.histogram2d', 'dx.dN2d', 'process01', 'np.meshgrid', 'plt.imshow', 'np.sum']",11
utilmy/zarchive/storage/aapackagedev/random.py:call_process,call_process,function,15,30,28,245,8.17,1,0,"['a', 'z', 'k)', 'np.exp(a*z)-k)@jita', 'z', 'k)', '[np.exp(a*z) > k]', '[1])@jittotdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt=10)']","[None, None, ' return np.maximum(0', None, None, '  return np.piecewise(z', None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, None, None, None, '0.25', '-1', '10):']",331,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/aapackagedev/random.py:binary_process,binary_process,function,15,30,28,245,8.17,1,0,"['a', 'z', 'k)', '[np.exp(a*z) > k]', '[1])@jittotdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt=10)']","[None, None, '  return np.piecewise(z', None, None, None, None, None, None, None, None, '']","[None, None, None, None, None, None, None, None, None, '0.25', '-1', '10):']",335,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/aapackagedev/random.py:pricing01,pricing01,function,15,30,28,245,8.17,1,0,"['totdim', 'nsample', 'a', 'strike', 'process01', 'aa', 'itmax', 'tt']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, '0.25', '-1', '10']",341,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_std', 'process01', 'np.var']",6
utilmy/zarchive/storage/aapackagedev/random.py:plotdensity2,plotdensity2,function,35,78,74,590,7.56,2,0,"['nsample', 'totdim', 'bin01', 'tit0', 'process01', 'vol', 'tt', 'Ti']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, '0.25', '5', '-1']",365,[],"['np.zeros', 'range', 'getdvector', 'pathScheme_', 'np.arange', 'np.histogram', 'process01', 'call_process', 'plt.plot', 'plt.axis', 'plt.title']",11
utilmy/zarchive/storage/aapackagedev/random.py:Plot2D_random_show,Plot2D_random_show,function,46,106,80,855,8.07,0,0,"['dir1', 'title1', 'dimxmax', 'dimymax', 'dimstep', 'samplejump', 'nsamplegraph']","[None, None, None, None, None, None, None]","[None, None, None, None, None, None, None]",417,[],"['pd.read_hdf', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'plt.show', 'np.mean', 'np.var', 'comoment']",9
utilmy/zarchive/storage/aapackagedev/random.py:Plot2D_random_save,Plot2D_random_save,function,51,106,77,723,6.82,2,0,"['dir1', 'title1', 'dimxmax', 'dimymax', 'dimstep', 'samplejump', 'nsamplegraph', '']","[None, None, None, None, None, None, None, None]","[None, None, None, None, None, None, None, None]",464,[],"['range', 'pd.read_hdf', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",8
utilmy/zarchive/storage/aapackagedev/random.py:getoutlier_fromrandom,getoutlier_fromrandom,function,57,168,111,1242,7.39,2,2,"['filename', 'jmax1', 'imax1', 'isamplejum', 'nsample', ""fileoutlier=   'E""]","[None, None, None, None, None, '']","[None, None, None, None, None, ""   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'""]",514,[],"['range', 'pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'unique_rows', 'store.append', 'store.close']",7
utilmy/zarchive/storage/aapackagedev/random.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",582,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/aapackagedev/random.py:getoutlier_fromrandom_fast,getoutlier_fromrandom_fast,function,71,183,130,1320,7.21,2,2,"['filename', 'jmax1', 'imax1', 'isamplejum', 'nsample', 'trigger1', ""fileoutlier=   'E""]","[None, None, None, None, None, None, '']","[None, None, None, None, None, '0.28', ""   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'""]",602,[],"['np.zeros', 'range', 'ne.evaluate', 'pd.HDFStore', 'store.append', 'store.close']",6
utilmy/zarchive/storage/aapackagedev/random.py:outlier_clean,outlier_clean,function,7,16,15,98,6.12,1,1,['vv2'],[None],[None],670,[],['range'],1
utilmy/zarchive/storage/aapackagedev/random.py:overwrite_data,overwrite_data,function,6,11,9,112,10.18,0,0,"['fileoutlier', 'vv2']","[None, None]","[None, None]",678,[],"['pd.HDFStore', 'store.remove', 'store.append', 'store.close']",4
utilmy/zarchive/storage/aapackagedev/random.py:doublecheck_outlier,doublecheck_outlier,function,8,12,11,100,8.33,0,0,"['fileoutlier', 'ijump', 'nsample', 'trigger1', "")fileoutlier=   'E"", ""'data')    #from filevv5"", '4)', 'dtype', 'kkmax1', '1) ', '0];   dimy', '1]y0= dimy * ijump + istartyym= dimy* ijump + nsample + istartyyyu1= yy1[y0']","[None, None, None, None, '', None, None, None, None, '  #Decrasing: dimy0 to dimmindimx', None, '']","[None, None, '4000', '0.1', ""   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'fileoutlier"", ' pdf.values   #to numpy vectordel pdfistartx= 0; istarty= 0nsample= 4000trigger1=  0.1crrmax = 250000kk=0(crrmax', None, ""'int')  #empty listvv5)[0]0"", None, ' vv5[kk', ' vv5[kk', ' dimy * ijump + istartyym= dimy* ijump + nsample + istartyyyu1= yy1[y0:ym];   yyu2= yy2[y0:ym];   yyu3= yy3[y0:ym]x0= dimx * ijump + istartxxm= dimx* ijump + nsample + istartxxxu1= yy1[x0:xm];   xxu2= yy2[x0:xm];   xxu3= yy3[x0:xm]""sum( xxu3 * yyu1)"") / (nsample) # X3.Y moments""sum( xxu1 * yyu3)"") / (nsample)""sum( xxu2 * yyu2)"") / (nsample)abs(c22) > trigger1)  :']",698,[],[],0
utilmy/zarchive/storage/aapackagedev/random.py:plot_outlier,plot_outlier,function,13,20,19,144,7.2,1,0,"['fileoutlier', 'kk)fileoutlier', ""'data')    #from filevv"", '0]yy', '1]xx', 'yy', 's', '1000', '00', ""1000])nsample)+'sampl D_'+str(dimx)+' X D_'+str(dimy)tit1)'_img/'+tit1+'_outlier.jpg'"", 'dpi', 'kmax)']","[None, None, None, None, None, None, None, None, None, None, None, '']","[None, None, ' df.values   #to numpy vectordel dfxx= vv[kk', ' vv[kk', None, None, '1 )[00', None, None, None, '100))yy', None]",758,"[""'''\n"", ""fileoutlier=   'E:\\_data\\_QUASI_SOBOL_gaussian_outlier.h5'   \n"", ""df=  pd.read_hdf(fileoutlier,'data')    #from file\n"", '\n', 'nn= len(vv)\n', 'vv1= np.zeros((10001,2))\n', 'for ii in range(0,   nn ):\n', '    \n', '  ix1= vv[ii,0]  \n', '  ix2= vv[ii,1]  \n', '  \n', '  vv1[ix1,0]= ix1\n', '  vv1[ix2,0]= ix2\n', '  vv1[ix1,1]+= 1\n', '  vv1[ix2,1]+= 1\n', '  \n', '\n', 'plt.scatter(xx, yy, s=1 )\n', 'plt.axis([0, 3500, 0, 100])  \n', '\n', '\n', 'np.mean(yy[:3000])    :65.163333333333327\n', 'np.var(yy[:3000])   : 66.519322222222229\n', '\n', 'np.mean(yy[3001:10000])    :29.998285469352766    35.16504786398056\n', '\n', '\n', 'xx= vv1[:,0]\n', 'yy= vv1[:,1]\n', '\n', 'yy[3001:10000] = yy[3001:10000] +  np.random.normal(35.16,6, 6999)\n', '\n', '\n', 'plt.scatter(xx, yy, s=1 )\n', 'plt.axis([0, 10000, 0, 100]) \n', '\n', 'tit1= ""Histogram of outliers per dim 1 to 10000""\n', 'plt.title(tit1)\n', ""plt.savefig('_img/'+'histogram of outliers per dim 1 to 10000.jpg',dpi=100)\n"", 'plt.clf()\n', '\n', '0.006  0.6% are defective...\n', ""'''\n""]","['int', 'np.copy', 'range']",3
utilmy/zarchive/storage/aapackagedev/random.py:permute,permute,function,24,64,53,631,9.86,2,0,"['yy', 'kmax']","[None, None]","[None, None]",841,[],"['int', 'np.copy', 'range', 'permute2', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'comoment']",9
utilmy/zarchive/storage/aapackagedev/random.py:permute2,permute2,function,18,42,41,461,10.98,1,0,"['xx', 'yy', 'kmax']","[None, None, None]","[None, None, None]",854,[],"['int', 'np.copy', 'range', 'plt.scatter', 'plt.axis', 'title1+str', 'plt.title', 'comoment']",8
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:wi,wi,function,10,24,21,160,6.67,1,1,['*args'],[None],[None],27,[],"['str', 'dx.replace', 'printinfile']",3
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:printinfile,printinfile,function,3,6,6,51,8.5,0,0,"['vv', 'file1']","[None, None]","[None, None]",38,[],"['open', 'text_file.write']",2
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:wi2,wi2,function,4,10,10,57,5.7,1,1,['*args'],[None],[None],44,[],['print'],1
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:indent,indent,function,17,43,34,344,8.0,0,4,[')'],['     global INDENT; INDENT +'],[' 4):      global INDENT; INDENT -= 4obj):'],49,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:dedent,dedent,function,17,43,34,344,8.0,0,4,[')'],['      global INDENT; INDENT -'],[' 4obj):'],50,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_builtin,describe_builtin,function,17,43,34,344,8.0,0,4,['obj'],[None],[None],54,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_func,describe_func,function,18,59,45,444,7.53,0,5,"['obj', 'method']","[None, None]","[None, 'False']",74,[],"['inspect.getargspec', 'wi', 'str', 'len']",4
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_klass,describe_klass,function,12,32,30,240,7.5,1,2,['obj'],[None],[None],99,[],"['wi', 'indent', 'getattr', 'inspect.ismethod', '1;describe_func', 'print', 'dedent']",7
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe,describe,function,54,315,151,2625,8.33,4,20,['obj'],[None],[None],116,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find', 'describe_func', 'inspect.getargspec', 'str', 'len', 'describe_klass', 'indent', 'getattr', 'inspect.ismethod', '1;describe_func', 'print', 'dedent', 'describe', 'dir', 'inspect.isclass', 'inspect.isfunction', 'inspect.isbuiltin', 'describe_builtin', 'describe_builtin2', 'describe_func2', 'describe_klass2', 'describe2']",25
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_builtin2,describe_builtin2,function,16,33,26,272,8.24,0,3,"['obj', 'name1']","[None, None]","[None, None]",143,[],"['wi', 'docstr.split', 'func_descr.replace', 's.find']",4
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_func2,describe_func2,function,10,29,23,203,7.0,0,2,"['obj', 'method', 'name1']","[None, None, None]","[None, 'False', ""''""]",162,[],"['inspect.getargspec', 'wi', 'str']",3
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe_klass2,describe_klass2,function,9,21,21,169,8.05,1,1,"['obj', 'name1']","[None, None]","[None, ""''""]",174,[],"['getattr', 'inspect.ismethod', 'describe_func2']",3
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:describe2,describe2,function,9,33,30,313,9.48,1,1,['module'],[None],[None],184,[],"['wi', 'dir', 'getattr', 'inspect.isclass', 'describe_klass2', 'print', 'inspect.isfunction', 'describe_func2', 'inspect.isbuiltin', 'describe_builtin2']",10
utilmy/zarchive/storage/aapackage_gen/codeanalysis.py:getmodule_doc,getmodule_doc,function,19,60,42,623,10.38,3,0,"['module1', 'file1']","[None, None]","[None, ""'moduledoc.txt'""]",200,[],"['importlib.import_module', 'pkgutil.walk_packages', 'vv.append', 'wi', 'describe2', 'print', 'describe']",7
utilmy/zarchive/storage/aapackage_gen/util.py:getmodule_doc,getmodule_doc,function,4,6,6,56,9.33,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",35,[],['ca.getmodule_doc'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:dataset_build_meta_mnist,dataset_build_meta_mnist,function,16,51,38,409,8.02,2,3,"['path', 'pathlib.Path]] ', 'get_image_fn', 'meta', 'image_suffix', '**kwargs', '']","[' Optional[Union[str', None, None, None, None, None, None]","[None, ' None', 'None', 'None', '""*.png""', None, None]",230,"['    """"""\n', '    Args:\n', '    * path - directory of the dataset or meta-data\n', '    * get_image_fn - function for getting i-th image of the dataset\n', '    directly metadat part\n', '\n', '    """"""\n']","['isinstance', 'pathlib.Path', 'path.exists', 'path.is_dir', 'path.iterdir', 'label_dir.is_dir', 'label_dir.glob', 'meta_rows.append', 'str', 'pd.DataFrame', 'len', 'meta.to_csv']",12
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:NlpDataset,NlpDataset,class,16,63,44,471,7.48,0,1,[],[],[],34,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:PhoneNlpDataset,PhoneNlpDataset,class,19,58,43,564,9.72,2,1,[],[],[],72,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset,ImageDataset,class,47,185,129,1631,8.82,3,8,[],[],[],116,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:NlpDataset:__init__,NlpDataset:__init__,method,8,32,26,209,6.53,0,1,"['self', 'meta']","[None, ' pd.DataFrame']","[None, None]",40,[],"['is_int', 'int', 'len', 'logw']",4
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:NlpDataset:__len__,NlpDataset:__len__,method,1,2,2,20,10.0,0,0,['self'],[None],[None],57,"['        """"""Return number of elements in this dataset.""""""\n']",['len'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:NlpDataset:get_sample,NlpDataset:get_sample,method,4,5,4,59,11.8,0,0,"['self', 'idx']","[None, ' int']","[None, None]",61,[],['self.get_text_only'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:NlpDataset:get_text_only,NlpDataset:get_text_only,method,5,6,5,54,9.0,0,0,"['self', 'idx']","[None, ' int']","[None, None]",65,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:PhoneNlpDataset:__init__,PhoneNlpDataset:__init__,method,12,33,24,373,11.3,2,0,"['self', 'size']","[None, ' int ']","[None, ' 1']",77,[],"['PhoneNumber', 'int', 'range', 'self.get_phone_number', 'meta_rows.append', 'super']",6
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:PhoneNlpDataset:__len__,PhoneNlpDataset:__len__,method,1,2,2,20,10.0,0,0,['self'],[None],[None],57,"['        """"""Return number of elements in this dataset.""""""\n']",['len'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:PhoneNlpDataset:get_phone_number,PhoneNlpDataset:get_phone_number,method,5,10,8,71,7.1,0,1,"['self', 'idx', 'islocal']","[None, None, None]","[None, None, 'False']",105,[],['s.replace'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:__init__,ImageDataset:__init__,method,17,50,39,396,7.92,2,3,"['self', 'path', 'pathlib.Path]] ', 'get_image_fn', 'meta', 'image_suffix', '**kwargs', '']","[None, ' Optional[Union[str', None, None, None, None, None, None]","[None, None, ' None', 'None', 'None', '""*.png""', None, None]",125,"['        """"""\n', '        Args:\n', '        * path - directory of the dataset or meta-data\n', '        * get_image_fn - function for getting i-th image of the dataset\n', '          directly from metadata part\n', '\n', '        """"""\n']","['isinstance', 'pathlib.Path', 'path.is_dir', 'path.iterdir', 'label_dir.is_dir', 'label_dir.glob', 'meta_rows.append', 'str', 'pd.DataFrame', 'len']",10
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:__len__,ImageDataset:__len__,method,1,2,2,20,10.0,0,0,['self'],[None],[None],57,"['        """"""Return number of elements in this dataset.""""""\n']",['len'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:get_image_only,ImageDataset:get_image_only,method,5,11,10,134,12.18,0,1,"['self', 'idx']","[None, ' int']","[None, None]",167,"['        """"""Return image of the single element of the dataset""""""\n']","['self.read_image', 'self.get_image_fn']",2
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:get_sample,ImageDataset:get_sample,method,6,18,15,121,6.72,0,1,"['self', 'idx']","[None, ' int']","[None, None]",177,[],['self.get_image_only'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:get_label_list,ImageDataset:get_label_list,method,6,11,10,123,11.18,0,1,"['self', 'label']","[None, ' Any']","[None, None]",190,"['        """"""Return indices of the elements which have certain label.""""""\n']","['isinstance', 'np.asarray', 'np.flatnonzero']",3
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:read_image,ImageDataset:read_image,method,2,2,2,47,23.5,0,0,"['self', 'filepath_or_buffer', 'io.BytesIO]']","[None, ' Union[str', None]","[None, None, None]",198,"['        """"""\n', '        Read a file into an image object\n', '        Args:\n', '            filepath_or_buffer: The path to the file, a URL, or any object\n', '                with a `read` method (such as `io.BytesIO`)\n', '        """"""\n']",['util_image.image_read'],1
utilmy/templates/templist/pypi_package/mygenerator/dataset.py:ImageDataset:save,ImageDataset:save,method,13,36,33,306,8.5,1,2,"['self', 'path', 'prefix', 'suffix', 'nrows']","[None, ' str', ' str ', ' str ', ' int ']","[None, None, ' ""img""', ' ""png""', ' -1']",209,"['        """"""Serialize on Disk the dataset elements\n', '        Args:\n', '            path:\n', '        Returns: None\n', '\n', '        """"""\n']","['os.makedirs', 'len', 'min', 'range', 'self.get_sample', 'cv2.imwrite']",6
utilmy/templates/templist/pypi_package/mygenerator/pipeline.py:run_generate_numbers_sequence,run_generate_numbers_sequence,function,25,80,53,756,9.45,0,0,"['sequence', 'min_spacing', 'max_spacing', 'image_width', '### image_widthoutput_path', 'config_file', '']","[' str', ' int ', ' int ', ' int ', ' str ', ' str ', None]","[None, ' 1', ' 10', ' 280', ' ""./""', ' ""config/config.yaml""', None]",14,[],"['len', 'config_load', 'pathlib.Path', 'dataset.NlpDataset', 'transform.TextToImage', 'tf.fit_transform', 'ds_img.save']",7
utilmy/templates/templist/pypi_package/mygenerator/pipeline.py:run_generate_phone_numbers,run_generate_phone_numbers,function,27,76,57,697,9.17,0,0,"['num_images', 'min_spacing', 'max_spacing', 'image_width', 'output_path', 'config_file', '']","[' int ', ' int ', ' int ', ' int ', ' str ', ' str ', None]","[' 10', ' 1', ' 10', ' 280', ' ""./""', ' ""config/config.yaml""', None]",60,[],"['config_load', 'pathlib.Path', 'dataset.PhoneNlpDataset', 'transform.TextToImage', 'tf.fit_transform', 'ds_img.save']",6
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ImageTransform,ImageTransform,class,7,24,14,245,10.21,0,0,[],[],[],14,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CharToImages,CharToImages,class,23,53,41,636,12.0,1,1,[],[],[],56,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:RemoveWhitePadding,RemoveWhitePadding,class,9,23,18,319,13.87,0,0,[],[],[],112,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CombineImagesHorizontally,CombineImagesHorizontally,class,68,234,178,2451,10.47,1,3,[],[],[],145,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ScaleImage,ScaleImage,class,17,47,40,567,12.06,0,0,[],[],[],307,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:TextToImage,TextToImage,class,18,59,46,619,10.49,1,0,[],[],[],337,[],[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ImageTransform:__init__,ImageTransform:__init__,method,6,22,13,226,10.27,0,0,['self'],[None],[None],20,"['        """"""\n', '        Parameters\n', '        ----------\n', '        """"""\n']","['transform', 'fit', 'fit_transform', 'self.fit']",4
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ImageTransform:transform,ImageTransform:transform,method,2,2,2,8,4.0,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",26,"['        """"""\n', '        Transform Dataset into Dataset\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']",[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ImageTransform:fit,ImageTransform:fit,method,3,10,9,113,11.3,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",35,"['        """"""\n', '        fit the transformation\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns: Object\n', '        """"""\n']","['fit_transform', 'self.fit']",2
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ImageTransform:fit_transform,ImageTransform:fit_transform,method,2,2,2,32,16.0,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",44,"['        """"""\n', '        Updates internal parameters of this transformation and then\n', '        applies it to the provided dataset.\n', '\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']",['self.fit'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CharToImages:__init__,CharToImages:__init__,method,2,2,2,22,11.0,0,0,"['self', 'font']","[None, ' dataset.ImageDataset']","[None, None]",62,"['        """"""\n', '        Parameters\n', '        ----------\n', '        font: dataset which contains images of characters. Images are features\n', ""        of the font dataset and characters are it's labels. Each character\n"", '        can have more than one image.\n', '        """"""\n']",[],0
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CharToImages:transform,CharToImages:transform,method,16,27,26,356,13.19,1,1,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",72,"['        """"""\n', '        Replaces features of the input dataset by mapping feature (string type)\n', '        to a list of character images (List[np.array] type)\n', '        """"""\n']","['_get_image_fn', 'ds.get_text_only', 'len', 'img_list.append', 'dataset.ImageDataset']",5
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CharToImages:fit,CharToImages:fit,method,3,10,9,111,11.1,0,0,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",96,"['        """"""\n', '        Args:\n', '            ds: dataset.NlpDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']","['fit_transform', 'self.fit']",2
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CharToImages:fit_transform,CharToImages:fit_transform,method,2,2,2,32,16.0,0,0,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",104,"['        """"""\n', '        Updates internal parameters of this transformation and then\n', '        applies it to the provided dataset.\n', '        """"""\n']",['self.fit'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:RemoveWhitePadding:transform,RemoveWhitePadding:transform,method,8,17,13,253,14.88,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",26,"['        """"""\n', '        Transform Dataset into Dataset\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']","['_get_image_fn', 'ds.get_image_only', 'self.transform_sample', 'dataset.ImageDataset', 'transform_sample', 'util_image.image_remove_extra_padding']",6
utilmy/templates/templist/pypi_package/mygenerator/transform.py:RemoveWhitePadding:transform_sample,RemoveWhitePadding:transform_sample,method,2,2,2,50,25.0,0,0,"['self', 'image']","[None, ' np.ndarray']","[None, None]",129,"['        """"""\n', '        Remove surrounding white spaces in digit image\n', '\n', '        Parameters\n', '        ----------\n', '        image: image of the digit\n', '\n', '        returns\n', '        -------\n', '        crop: cropped image\n', '        """"""\n']",['util_image.image_remove_extra_padding'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CombineImagesHorizontally:__init__,CombineImagesHorizontally:__init__,method,5,5,5,86,17.2,0,0,"['self', 'padding_range', 'int]', 'combined_width']","[None, ' Tuple[int', None, ' int']","[None, None, None, None]",152,"['        """"""\n', '        Parameters\n', '        ----------\n', '        spacing_range:\n', '            a (minimum, maximum) int pair (tuple), representing the min and max spacing\n', '            between digits. Unit should be pixel.\n', '        image_width:\n', '            specifies the width of the image in pixels.\n', '        """"""\n']",['super'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CombineImagesHorizontally:transform,CombineImagesHorizontally:transform,method,13,26,24,415,15.96,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",26,"['        """"""\n', '        Transform Dataset into Dataset\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']","['_get_image_fn', 'ds.get_image_only', 'self.transform_sample', 'dataset.ImageDataset', 'transform_sample']",5
utilmy/templates/templist/pypi_package/mygenerator/transform.py:CombineImagesHorizontally:transform_sample,CombineImagesHorizontally:transform_sample,method,51,189,141,1812,9.59,1,3,"['self', 'image_list', '1', '1)', 'combined_width', 'min_image_width', 'validate', '']","[None, ' List[np.ndarray]', None, None, None, None, None, None]","[None, None, None, None, '10', '2', 'True', None]",176,"['        """"""\n', '        Combine images of individual digits horizontally to make image of the complete number\n', '        Parameters\n', '        ----------\n', '        image_list: list of np.ndarray containing images of each digit\n', '        padding_range: (minimum space between two digits, maximum space between two digits)\n', '        combined_width: total width of the image\n', '        returns\n', '        -------\n', '        final_image: combined image of number\n', '        padding_size: padding between each digits in a number\n', '        """"""\n']","['len', 'util_image.padding_generate', 'np.sum', 'int', 'enumerate', 'cv2.resize', 'new_img_list.append', 'Exception', 'util_image.image_merge', 'cv2.bitwise_not', 'image_padding_validate', 'logw', 'np.zeros']",13
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ScaleImage:__init__,ScaleImage:__init__,method,7,7,7,71,10.14,0,0,"['self', 'width', 'height', 'inter']","[None, ' Optional[int] ', ' Optional[int] ', None]","[None, ' None', ' None', 'cv2.INTER_AREA']",312,"['        """"""\n', '        width and height specify output image dimensions\n', '        """"""\n']",['super'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ScaleImage:transform,ScaleImage:transform,method,8,23,20,336,14.61,0,0,"['self', 'ds']","[None, ' dataset.ImageDataset']","[None, None]",26,"['        """"""\n', '        Transform Dataset into Dataset\n', '        Args:\n', '            ds: dataset.ImageDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']","['_get_image_fn', 'ds.get_image_only', 'self.transform_sample', 'dataset.ImageDataset', 'transform_sample', 'util_image.image_resize']",6
utilmy/templates/templist/pypi_package/mygenerator/transform.py:ScaleImage:transform_sample,ScaleImage:transform_sample,method,2,5,5,70,14.0,0,0,"['self', 'image', 'width', 'height', 'inter']","[None, None, None, None, None]","[None, None, 'None', 'None', 'cv2.INTER_AREA']",330,"['        """"""\n', '        Resizes a image and maintains aspect ratio.\n', '        """"""\n']",['util_image.image_resize'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:TextToImage:__init__,TextToImage:__init__,method,9,19,16,255,13.42,0,0,"['self', 'font_dir', 'pathlib.Path]', 'spacing_range', 'int]', 'image_width']","[None, ' Union[str', None, ' Tuple[int', None, ' int']","[None, None, None, None, None, None]",312,"['        """"""\n', '        width and height specify output image dimensions\n', '        """"""\n']","['dataset.ImageDataset', 'RemoveWhitePadding', 'CharToImages', 'CombineImagesHorizontally']",4
utilmy/templates/templist/pypi_package/mygenerator/transform.py:TextToImage:transform,TextToImage:transform,method,5,8,7,52,6.5,1,0,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",72,"['        """"""\n', '        Replaces features of the input dataset by mapping feature (string type)\n', '        to a list of character images (List[np.array] type)\n', '        """"""\n']",['tr.transform'],1
utilmy/templates/templist/pypi_package/mygenerator/transform.py:TextToImage:fit,TextToImage:fit,method,3,10,9,111,11.1,0,0,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",96,"['        """"""\n', '        Args:\n', '            ds: dataset.NlpDataset\n', '        Returns:dataset.ImageDataset\n', '        """"""\n']","['fit_transform', 'self.fit']",2
utilmy/templates/templist/pypi_package/mygenerator/transform.py:TextToImage:fit_transform,TextToImage:fit_transform,method,2,2,2,32,16.0,0,0,"['self', 'ds']","[None, ' dataset.NlpDataset']","[None, None]",104,"['        """"""\n', '        Updates internal parameters of this transformation and then\n', '        applies it to the provided dataset.\n', '        """"""\n']",['self.fit'],1
utilmy/templates/templist/pypi_package/mygenerator/utils.py:log,log,function,10,39,25,357,9.15,0,0,['*s'],[None],[None],19,[],"['logger.info', 'log2', 'logger.debug', 'logw', 'logger.warning', 'loge', 'logger.error', 'logger_setup', 'logger.configure']",9
utilmy/templates/templist/pypi_package/mygenerator/utils.py:log2,log2,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],23,[],['logger.debug'],1
utilmy/templates/templist/pypi_package/mygenerator/utils.py:logw,logw,function,1,5,5,41,8.2,0,0,['*s'],[None],[None],27,[],['logger.warning'],1
utilmy/templates/templist/pypi_package/mygenerator/utils.py:loge,loge,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],31,[],['logger.error'],1
utilmy/templates/templist/pypi_package/mygenerator/utils.py:logger_setup,logger_setup,function,2,15,13,138,9.2,0,0,[],[],[],35,[],['logger.configure'],1
utilmy/templates/templist/pypi_package/mygenerator/utils.py:config_load,config_load,function,16,73,62,816,11.18,0,1,"['config_path', 'pathlib.Path]] ']","[' Optional[Union[str', None]","[None, ' None']",52,"['    """"""Load Config file into a dict\n', '    1) load config_path\n', '    2) If not, load in HOME USER\n', '    3) If not, create default one\n', '    Args:\n', ""        config_path: path of config or 'default' tag value\n"", '    Returns: dict config\n', '    """"""\n']","['logw', 'log2', 'yaml.load', 'str', 'log', 'os.makedirs', 'open', 'yaml.dump']",8
utilmy/templates/templist/pypi_package/mygenerator/utils.py:dataset_donwload,dataset_donwload,function,9,19,17,246,12.95,0,0,"['url', 'path_target']","[None, None]","[None, None]",96,"['    """"""Donwload on disk the tar.gz file\n', '    Args:\n', '        url:\n', '        path_target:\n', '    Returns:\n', '\n', '    """"""\n']","['log', 'os.makedirs', 'wget.download', 'url.split', 'os_extract_archive', 'log2']",6
utilmy/templates/templist/pypi_package/mygenerator/utils.py:dataset_get_path,dataset_get_path,function,17,53,44,527,9.94,0,3,['cfg'],[' dict'],[None],113,[],"['cfg.get', 'cfgd.get', 'glob.glob', 'log2', 'len', 'dataset_donwload', 'Exception']",7
utilmy/templates/templist/pypi_package/mygenerator/utils.py:os_extract_archive,os_extract_archive,function,19,63,47,671,10.65,1,8,"['file_path', 'path', 'archive_format']","[None, None, None]","[None, '"".""', '""auto""']",142,"['    """"""Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n', '    Args:\n', '        file_path: path to the archive file\n', '        path: path to extract the archive file\n', '        archive_format: Archive format to try for extracting the file.\n', ""            Options are 'auto', 'tar', 'zip', and None.\n"", ""            'tar' includes tar, tar.gz, and tar.bz files.\n"", ""            The default 'auto' is ['tar', 'zip'].\n"", '            None or an empty list will return no matches found.\n', '    Returns:\n', '        True if a match was found and an archive extraction was completed,\n', '        False otherwise.\n', '    """"""\n']","['isinstance', 'is_match_fn', 'open_fn', 'archive.extractall', 'os.remove', 'shutil.rmtree']",6
utilmy/templates/templist/pypi_package/mygenerator/utils.py:to_file,to_file,function,3,7,7,51,7.29,0,0,"['s', 'filep']","[None, None]","[None, None]",189,[],"['open', 'fp.write']",2
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:log,log,function,10,39,25,357,9.15,0,0,['*s'],[None],[None],19,[],"['logger.info', 'log2', 'logger.debug', 'logw', 'logger.warning', 'loge', 'logger.error', 'logger_setup', 'logger.configure']",9
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:log2,log2,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],23,[],['logger.debug'],1
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:logw,logw,function,1,5,5,41,8.2,0,0,['*s'],[None],[None],27,[],['logger.warning'],1
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:loge,loge,function,1,5,5,39,7.8,0,0,['*s'],[None],[None],31,[],['logger.error'],1
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:logger_setup,logger_setup,function,2,15,13,138,9.2,0,0,[],[],[],35,[],['logger.configure'],1
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:config_load,config_load,function,16,73,62,816,11.18,0,1,"['config_path', 'pathlib.Path]] ']","[' Optional[Union[str', None]","[None, ' None']",52,"['    """"""Load Config file into a dict\n', '    1) load config_path\n', '    2) If not, load in HOME USER\n', '    3) If not, create default one\n', '    Args:\n', ""        config_path: path of config or 'default' tag value\n"", '    Returns: dict config\n', '    """"""\n']","['logw', 'log2', 'yaml.load', 'str', 'log', 'os.makedirs', 'open', 'yaml.dump']",8
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:dataset_donwload,dataset_donwload,function,9,19,17,246,12.95,0,0,"['url', 'path_target']","[None, None]","[None, None]",96,"['    """"""Donwload on disk the tar.gz file\n', '    Args:\n', '        url:\n', '        path_target:\n', '    Returns:\n', '\n', '    """"""\n']","['log', 'os.makedirs', 'wget.download', 'url.split', 'os_extract_archive', 'log2']",6
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:dataset_get_path,dataset_get_path,function,17,53,44,527,9.94,0,3,['cfg'],[' dict'],[None],113,[],"['cfg.get', 'cfgd.get', 'glob.glob', 'log2', 'len', 'dataset_donwload', 'Exception']",7
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:os_extract_archive,os_extract_archive,function,19,63,47,671,10.65,1,8,"['file_path', 'path', 'archive_format']","[None, None, None]","[None, '"".""', '""auto""']",142,"['    """"""Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n', '    Args:\n', '        file_path: path to the archive file\n', '        path: path to extract the archive file\n', '        archive_format: Archive format to try for extracting the file.\n', ""            Options are 'auto', 'tar', 'zip', and None.\n"", ""            'tar' includes tar, tar.gz, and tar.bz files.\n"", ""            The default 'auto' is ['tar', 'zip'].\n"", '            None or an empty list will return no matches found.\n', '    Returns:\n', '        True if a match was found and an archive extraction was completed,\n', '        False otherwise.\n', '    """"""\n']","['isinstance', 'is_match_fn', 'open_fn', 'archive.extractall', 'os.remove', 'shutil.rmtree']",6
utilmy/templates/templist/pypi_package/mygenerator/util_exceptions.py:to_file,to_file,function,3,7,7,51,7.29,0,0,"['s', 'filep']","[None, None]","[None, None]",189,[],"['open', 'fp.write']",2
utilmy/templates/templist/pypi_package/mygenerator/util_image.py:padding_generate,padding_generate,function,2,5,5,80,16.0,0,0,"['paddings_number', 'min_padding', 'max_padding']","[' int ', ' int ', ' int ']","[' 1', ' 1', ' 1']",12,"['    """"""\n', '    Args:\n', '        paddings_number:  4\n', '        min_padding:      1\n', '        max_padding:    100\n', '\n', '    Returns: padding list\n', '    """"""\n']",[],0
utilmy/templates/templist/pypi_package/mygenerator/util_image.py:image_merge,image_merge,function,32,73,51,554,7.59,1,3,"['image_list', 'n_dim', 'padding_size', 'max_height', 'total_width']","[None, None, None, None, None]","[None, None, None, None, None]",26,"['    """"""\n', '    Args:\n', '        image_list:  list of image\n', '        n_dim:\n', '        padding_size: padding size max\n', '        max_height:   max height\n', '        total_width:  total width\n', '\n', '    Returns:\n', '\n', '    """"""\n']","['np.zeros', 'len', 'enumerate']",3
utilmy/templates/templist/pypi_package/mygenerator/util_image.py:image_remove_extra_padding,image_remove_extra_padding,function,31,73,63,518,7.1,0,2,"['img', 'inverse', 'removedot']","[None, None, None]","[None, 'False', 'True']",62,"['    """"""TODO: Issue with small dot noise points : noise or not ?\n', '              Padding calc has also issues with small blobs.\n', '    Args:\n', '        img: image\n', '    Returns: image cropped of extra padding\n', '    """"""\n']","['cv2.cvtColor', 'max', 'int', 'np.where', 'morphology.remove_small_objects', 'graybin.astype', 'cv2.findNonZero', 'cv2.boundingRect']",8
utilmy/templates/templist/pypi_package/mygenerator/util_image.py:image_resize,image_resize,function,8,38,27,219,5.76,0,2,"['image', 'width', 'height', 'inter']","[None, None, None, None]","[None, 'None', 'None', 'cv2.INTER_AREA']",92,"['    """"""Resizes a image and maintains aspect ratio.\n', '    Args:\n', '        image:\n', '        width:\n', '        height:\n', '        inter:\n', '\n', '    Returns:\n', '\n', '    """"""\n']","['float', 'int', 'cv2.resize']",3
utilmy/templates/templist/pypi_package/mygenerator/util_image.py:image_read,image_read,function,12,45,34,578,12.84,0,3,"['filepath_or_buffer', 'io.BytesIO]']","[' Union[str', None]","[None, None]",126,"['    """"""\n', '    Read a file into an image object\n', '    Args:\n', '        filepath_or_buffer: The path to the file, a URL, or any object\n', '            with a `read` method (such as `io.BytesIO`)\n', '    """"""\n']","['isinstance', 'hasattr', 'np.asarray', 'cv2.imdecode', 'filepath_or_buffer.endswith', 'tifffile.imread', 'cv2.imread', 'cv2.cvtColor']",8
utilmy/templates/templist/pypi_package/mygenerator/validate.py:image_padding_validate,image_padding_validate,function,6,30,28,259,8.63,0,1,"['final_image', 'min_padding', 'max_padding']","[None, None, None]","[None, None, None]",12,"['    """"""\n', '    Args:\n', '        final_image:\n', '        min_padding:\n', '        max_padding:\n', '\n', '    Returns:\n', '\n', '    """"""\n']","['image_padding_get', 'sum', 'len', 'logw']",4
utilmy/templates/templist/pypi_package/mygenerator/validate.py:image_padding_load,image_padding_load,function,6,9,7,117,13.0,0,0,"['img_path', 'threshold']","[None, None]","[None, '15']",34,"['    """"""\n', '    Args:\n', '        img_path:\n', '        threshold:\n', '\n', '    Returns number of consecutive blank columns in the image.\n', '    Example return value: [4, 8, 3] means that image contains\n', '    3 blank columns. The size of each corresponding column in pixels\n', '    is 4, 8 and 3.\n', '    """"""\n']","['util_image.image_read', 'image_padding_get']",2
utilmy/templates/templist/pypi_package/mygenerator/validate.py:image_padding_get,image_padding_get,function,21,81,40,476,5.88,1,7,"['img', 'threshold', 'inverse']","[None, None, None]","[None, '0', 'True']",50,"['    """"""\n', '    Args:\n', '         img_path:\n', '         threshold:\n', '      Returns number of consecutive blank columns in the image.\n', '      Example return value: [4, 8, 3] means that image contains\n', '      3 blank columns. The size of each corresponding column in pixels\n', '      is 4, 8 and 3.\n', '    """"""\n']","['cv2.bitwise_not', 'range', 'np.sum', 'xpad_list.append', 'xchar_list.append']",5
utilmy/templates/templist/pypi_package/mygenerator/validate.py:run_image_padding_validate,run_image_padding_validate,function,14,59,47,463,7.85,1,2,"['min_spacing', 'max_spacing', 'image_width', 'input_path', 'inverse_image', 'config_file', '**kwargs', '']","[' int ', ' int ', ' int ', ' str ', ' bool ', ' str ', None, None]","[' 1', ' 1', ' 5', ' """"', ' True', ' ""default""', None, None]",104,"['    """"""\n', '    Args:\n', '        min_spacing:\n', '        max_spacing:\n', '        image_width:\n', '        input_path:\n', '        config_file:\n', '        **kwargs:\n', '    Returns: None\n', '\n', '    """"""\n']","['sorted', 'log', 'len', 'util_image.image_read', 'image_padding_get', 'logw', 'sum']",7
utilmy/templates/templist/pypi_package/tests/test_dataset.py:test_image_dataset_get_label_list,test_image_dataset_get_label_list,function,5,12,12,161,13.42,0,0,[],[],[],7,[],"['dataset.ImageDataset', 'ds.get_label_list', 'np.asarray']",3
utilmy/templates/templist/pypi_package/tests/test_dataset.py:test_image_dataset_len,test_image_dataset_len,function,3,11,10,92,8.36,0,0,[],[],[],15,[],"['dataset.ImageDataset', 'len']",2
utilmy/templates/templist/pypi_package/tests/test_dataset.py:test_image_dataset_get_sampe,test_image_dataset_get_sampe,function,11,37,31,318,8.59,0,0,[],[],[],23,[],"['_dummy_get_image_fn', 'dataset.ImageDataset', 'ds.get_sample']",3
utilmy/templates/templist/pypi_package/tests/test_dataset.py:test_image_dataset_get_image_only,test_image_dataset_get_image_only,function,12,35,31,351,10.03,0,0,[],[],[],40,[],"['_get_image_fn', 'np.asarray', 'dataset.ImageDataset', 'ds.get_image_only']",4
utilmy/templates/templist/pypi_package/tests/test_dataset.py:test_nlp_dataset_len,test_nlp_dataset_len,function,2,10,10,96,9.6,0,0,[],[],[],61,[],"['dataset.NlpDataset', 'range', 'len']",3
utilmy/templates/templist/pypi_package/tests/test_import.py:test_import,test_import,function,13,26,16,175,6.73,0,0,[],[],[],3,[],[],0
utilmy/templates/templist/pypi_package/tests/test_pipeline.py:test_generate_phone_numbers,test_generate_phone_numbers,function,19,51,42,579,11.35,1,0,['tmp_path'],[None],[None],10,[],"['random.seed', 'pipeline.run_generate_phone_numbers', 'output_path=str', 'meta_file.exists', 'meta_file.is_file', 'pd.read_csv', 'len', 'output_path.glob', 'cv2.imread']",9
utilmy/templates/templist/pypi_package/tests/test_transform.py:test_chars_to_images_transform,test_chars_to_images_transform,function,20,92,66,803,8.73,0,0,[],[],[],13,[],"['_get_image_fn', 'np.asarray', 'dataset.ImageDataset', 'dataset.NlpDataset', 'transform.CharToImages', 'tr.fit_transform', 'len', 'ds.get_sample', 'meta.to_dict']",9
utilmy/templates/templist/pypi_package/tests/test_transform.py:test_combine_images_horizontally_transform,test_combine_images_horizontally_transform,function,22,67,53,566,8.45,0,0,[],[],[],50,[],"['_get_image_fn', 'np.zeros', 'dataset.ImageDataset', 'transform.CombineImagesHorizontally', 'len', 'ds.get_sample', 'meta.to_dict']",7
utilmy/templates/templist/pypi_package/tests/test_transform.py:test_scale_image_transform,test_scale_image_transform,function,9,78,52,571,7.32,0,0,[],[],[],88,[],"['_get_image_fn', 'np.asarray', 'dataset.ImageDataset', 'transform.ScaleImage', 'len', 'ds.get_image_only']",6
utilmy/templates/templist/pypi_package/tests/test_transform.py:create_font_files,create_font_files,function,19,44,42,425,9.66,1,0,['font_dir'],[None],[None],143,"['    """"""\n', '    Args:\n', '        font_dir:  image directory\n', '    Returns:\n', '\n', '    """"""\n']","['range', 'str', 'dig_folder.mkdir', 'np.zeros', 'cv2.putText', 'cv2.imwrite']",6
utilmy/templates/templist/pypi_package/tests/test_transform.py:test_text_to_image_transform,test_text_to_image_transform,function,23,75,50,742,9.89,0,0,['tmp_path'],[None],[None],169,[],"['random.seed', 'create_font_files', 'dataset.NlpDataset', 'transform.TextToImage', 'len', 'ds.get_sample', 'np.mean', 'meta.to_dict']",8
utilmy/templates/templist/pypi_package/tests/test_util_image.py:create_blank_image,create_blank_image,function,6,11,10,101,9.18,0,0,"['width', 'height', 'rgb_color', '0', '0']","[None, None, None, None, None]","[None, None, '(0', None, None]",8,"['    """"""Create new image(numpy array) filled with certain color in RGB""""""\n']","['np.zeros', 'tuple']",2
utilmy/templates/templist/pypi_package/tests/test_util_image.py:test_image_merge,test_image_merge,function,6,93,36,395,4.25,0,0,[],[],[],23,[],"['np.asarray', 'util_image.image_merge']",2
utilmy/templates/templist/pypi_package/tests/test_util_image.py:test_image_remove_extra_padding,test_image_remove_extra_padding,function,15,39,34,472,12.1,0,0,[],[],[],63,[],"['create_blank_image', 'cv2.rectangle', 'util_image.image_remove_extra_padding', 'log2']",4
utilmy/templates/templist/pypi_package/tests/test_util_image.py:test_image_resize,test_image_resize,function,4,38,21,223,5.87,0,0,[],[],[],80,[],"['np.asarray', 'util_image.image_resize']",2
utilmy/templates/templist/pypi_package/tests/test_util_image.py:test_image_read,test_image_read,function,8,12,12,203,16.92,0,0,['tmp_path'],[None],[None],107,[],"['create_blank_image', 'str', 'cv2.imwrite', 'util_image.image_read']",4
utilmy/templates/templist/pypi_package/tests/test_validate.py:test_image_padding_get,test_image_padding_get,function,8,43,31,295,6.86,0,0,[],[],[],8,[],"['np.zeros', 'image_padding_get']",2
utilmy/zarchive/storage/aapackage_gen/34/util34.py:getmodule_doc,getmodule_doc,function,6,8,8,69,8.62,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",18,[],['ca.getmodule_doc'],1
utilmy/zarchive/storage/aapackage_gen/34/Working Copy of util34.py:getmodule_doc,getmodule_doc,function,6,8,8,69,8.62,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",18,[],['ca.getmodule_doc'],1
utilmy/zarchive/storage/aapackage_gen/old/util27.py:getmodule_doc,getmodule_doc,function,6,8,8,69,8.62,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",20,[],['ca.getmodule_doc'],1
utilmy/zarchive/storage/aapackage_gen/old/util34.py:getmodule_doc,getmodule_doc,function,6,8,8,69,8.62,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",18,[],['ca.getmodule_doc'],1
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",14,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:numexpr_topanda,numexpr_topanda,function,10,28,22,248,8.86,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",27,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:convertcsv_topanda,convertcsv_topanda,function,9,22,19,182,8.27,1,0,"['filein1', 'filename', 'tablen']","[None, None, None]","[None, None, ""'data'""]",39,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:getpanda_tonumpy,getpanda_tonumpy,function,6,10,10,92,9.2,0,0,"['filename', 'nsize', 'tablen']","[None, None, None]","[None, None, ""'data'""]",51,[],['pd.read_hdf'],1
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:getrandom_tonumpy,getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample', 'tablen']","[None, None, None, None]","[None, None, None, ""'data'""]",56,[],['pd.read_hdf'],1
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",87,[],['ne.evaluate'],1
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],95,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:unique_rows,unique_rows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],116,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:remove_zeros,remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",121,[],[],0
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:sort_array,sort_array,function,2,8,8,74,9.25,0,0,['vv'],[None],[None],124,[],[],0
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:save_topanda,save_topanda,function,7,16,16,199,12.44,0,0,"['vv', 'filenameh5)', 'pdf); store.close()filenameh5)', ""'data')    #from filereturn pdf.values   #to numpy vectorxx"", 'yy', 'title1="""")']","[None, ""  # 'E:\\_data\\_data_outlier.h5'filenameh5)vv); store.append('data'"", ""  # 'E:\\_data\\_data_outlier.h5'fileoutlier"", None, None, '']","[None, None, None, None, None, '""""):']",129,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:load_frompanda,load_frompanda,function,7,16,16,199,12.44,0,0,"['filenameh5)', ""'data')    #from filereturn pdf.values   #to numpy vectorxx"", 'yy', 'title1="""")']","[""  # 'E:\\_data\\_data_outlier.h5'fileoutlier"", None, None, '']","[None, None, None, '""""):']",134,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:plotsave,plotsave,function,7,16,16,199,12.44,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",145,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:plotshow,plotshow,function,6,15,15,159,10.6,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",156,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.show']",5
utilmy/zarchive/storage/aapackage_gen/old/utils27.py:parsePDF,parsePDF,function,38,80,69,838,10.47,1,0,['url'],[None],[None],320,[],"['urllib2.urlopen', 'StringIO', 'PDFParser', 'PDFDocument', 'PDFResourceManager', 'LAParams', 'TextConverter', 'PDFPageInterpreter', 'PDFPage.create_pages', 'interpreter.process_page', 'retstr.getvalue', 're.findall', 're.search', 'float', 'match.group']",15
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:numexpr_vect_calc,numexpr_vect_calc,function,13,28,22,214,7.64,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",14,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:numexpr_topanda,numexpr_topanda,function,10,28,22,248,8.86,0,0,"['filename', 'i0', 'imax', 'expr', ""fileout='E""]","[None, None, None, None, '']","[None, '0', '1000', None, ""'E:\\_data\\_QUASI_SOBOL_gaussian_xx3.h5'""]",27,[],"['pd.read_hdf', 'ne.evaluate', 'pd.HDFStore', 'store.append']",4
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:convertcsv_topanda,convertcsv_topanda,function,9,22,19,182,8.27,1,0,"['filein1', 'filename', 'tablen']","[None, None, None]","[None, None, ""'data'""]",39,[],"['pd.read_csv', 'pd.HDFStore', 'store.append', 'store.close']",4
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:getpanda_tonumpy,getpanda_tonumpy,function,6,10,10,92,9.2,0,0,"['filename', 'nsize', 'tablen']","[None, None, None]","[None, None, ""'data'""]",51,[],['pd.read_hdf'],1
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:getrandom_tonumpy,getrandom_tonumpy,function,6,9,9,101,11.22,0,0,"['filename', 'nbdim', 'nbsample', 'tablen']","[None, None, None, None]","[None, None, None, ""'data'""]",56,[],['pd.read_hdf'],1
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:comoment,comoment,function,4,6,6,61,10.17,0,0,"['xx', 'yy', 'nsample', 'kx', 'ky']","[None, None, None, None, None]","[None, None, None, None, None]",87,[],['ne.evaluate'],1
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:acf,acf,function,12,34,31,244,7.18,0,0,['data'],[None],[None],95,[],"['len', 'np.mean', 'np.sum', 'float', 'r', 'np.arange', 'np.asarray']",7
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:unique_rows,unique_rows,function,6,8,8,148,18.5,0,0,['a'],[None],[None],116,[],"['np.ascontiguousarray', 'np.unique', 'unique_a.view']",3
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:remove_zeros,remove_zeros,function,2,4,4,35,8.75,0,0,"['vv', 'axis1']","[None, None]","[None, '1']",121,[],[],0
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:sort_array,sort_array,function,2,8,8,74,9.25,0,0,['vv'],[None],[None],124,[],[],0
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:save_topanda,save_topanda,function,7,16,16,199,12.44,0,0,"['vv', 'filenameh5)', 'pdf); store.close()filenameh5)', ""'data')    #from filereturn pdf.values   #to numpy vectorxx"", 'yy', 'title1="""")']","[None, ""  # 'E:\\_data\\_data_outlier.h5'filenameh5)vv); store.append('data'"", ""  # 'E:\\_data\\_data_outlier.h5'fileoutlier"", None, None, '']","[None, None, None, None, None, '""""):']",129,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:load_frompanda,load_frompanda,function,7,16,16,199,12.44,0,0,"['filenameh5)', ""'data')    #from filereturn pdf.values   #to numpy vectorxx"", 'yy', 'title1="""")']","[""  # 'E:\\_data\\_data_outlier.h5'fileoutlier"", None, None, '']","[None, None, None, '""""):']",134,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:plotsave,plotsave,function,7,16,16,199,12.44,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",145,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.savefig', 'plt.clf']",6
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:plotshow,plotshow,function,6,15,15,159,10.6,0,0,"['xx', 'yy', 'title1']","[None, None, None]","[None, None, '""""']",156,[],"['plt.scatter', 'plt.autoscale', 'title1+str', 'plt.title', 'plt.show']",5
utilmy/zarchive/storage/aapackage_gen/old/utils34.py:parsePDF,parsePDF,function,38,80,69,838,10.47,1,0,['url'],[None],[None],320,[],"['urllib2.urlopen', 'StringIO', 'PDFParser', 'PDFDocument', 'PDFResourceManager', 'LAParams', 'TextConverter', 'PDFPageInterpreter', 'PDFPage.create_pages', 'interpreter.process_page', 'retstr.getvalue', 're.findall', 're.search', 'float', 'match.group']",15
utilmy/zarchive/storage/aapackage_gen/old/Working Copy of util34.py:getmodule_doc,getmodule_doc,function,6,8,8,69,8.62,0,0,"['module1', 'fileout']","[None, None]","[None, ""''""]",18,[],['ca.getmodule_doc'],1
